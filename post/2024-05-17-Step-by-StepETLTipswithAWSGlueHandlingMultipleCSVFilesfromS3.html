<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>AWS Glue로 다수의 CSV 파일을 처리하는 ETL 단계별 팁 | allround-coder</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://allround-coder.github.io///post/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="AWS Glue로 다수의 CSV 파일을 처리하는 ETL 단계별 팁 | allround-coder" data-gatsby-head="true"/><meta property="og:title" content="AWS Glue로 다수의 CSV 파일을 처리하는 ETL 단계별 팁 | allround-coder" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://allround-coder.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://allround-coder.github.io///post/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3" data-gatsby-head="true"/><meta name="twitter:title" content="AWS Glue로 다수의 CSV 파일을 처리하는 ETL 단계별 팁 | allround-coder" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | allround-coder" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-17 20:37" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZFDEQ947R4"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
  
            gtag('config', 'G-ZFDEQ947R4');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-b088bc509ff5c497.js" defer=""></script><script src="/_next/static/t9N7vwmpvBMQnO2PSctoH/_buildManifest.js" defer=""></script><script src="/_next/static/t9N7vwmpvBMQnO2PSctoH/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Allround Coder</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">AWS Glue로 다수의 CSV 파일을 처리하는 ETL 단계별 팁</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="AWS Glue로 다수의 CSV 파일을 처리하는 ETL 단계별 팁" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">Allround Coder</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 17, 2024</span><span class="posts_reading_time__f7YPP">5<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>이건 훌륭한 이미지입니다! 이 디지털 시대에 데이터는 기업에게 귀중한 자산이 되었습니다. 데이터를 효과적으로 처리하고 분석하는 것이 유용한 통찰력을 얻고 스마트한 의사결정을 하는 데 중요합니다. AWS Glue는 데이터를 쉽고 효율적으로 관리하고 분석하는 데 도움이 되는 포괄적인 솔루션이 됩니다.</p>
<p>이 세션에서는 AWS Glue, 데이터 카탈로그, 및 크롤러가 하나의 버킷에 있는 여러 CSV 파일을 단일 데이터 세트로 읽는 방법에 대해 논의할 것입니다. 아래는 아키텍처 요약입니다:</p>
<p><img src="/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_1.png" alt="아키텍처 이미지"></p>
<h1>S3 버킷 준비하기</h1>
<p>처리하려는 모든 CSV 파일이 아마존 S3의 단일 버킷에 저장되어 있는지 확인하세요.</p>
<p><img src="/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_2.png" alt="이미지"></p>
<h1>AWS Glue 데이터 카탈로그에서 데이터베이스 생성하기</h1>
<p>AWS Management Console에서 AWS Glue를 열고, "데이터베이스" 섹션으로 이동하여 메타데이터를 저장할 새 데이터베이스를 생성하세요.</p>
<p><img src="/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_3.png" alt="이미지"></p>
<h1>크롤러 생성</h1>
<p>이전에 생성한 데이터베이스를 선택하여 크롤러에 의해 생성된 테이블을 저장하세요. 크롤러를 사용하여 테이블 추가를 선택하세요. 크롤러에 이름을 지정하고 CSV 파일을 포함하는 S3 버킷 위치를 선택하여 데이터 원본을 지정하세요. S3의 데이터 원본에 액세스할 수 있는 IAM 역할을 지정하고 Glue 데이터 카탈로그에 항목을 생성할 수 있는 권한이 있는 IAM 역할을 지정하세요. 필요에 따라 크롤러 옵션을 구성하세요. 크롤러를 주기적으로 실행하려면 빈도를 설정하세요. 구성을 완료한 후 크롤러를 실행하세요. 크롤러는 지정된 버킷의 모든 CSV 파일을 읽고 Glue 데이터 카탈로그에 하나 이상의 테이블을 생성합니다.</p>
<p><img src="/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_4.png" alt="Step-by-Step ETL Tips with AWS Glue: Handling Multiple CSV Files from S3"></p>
<p><img src="/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_5.png" alt="Step-by-Step ETL Tips with AWS Glue: Handling Multiple CSV Files from S3"></p>
<p>Once the crawler status is complete you can preview the table data that has been created using Athena</p>
<p><img src="/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_6.png" alt="Step-by-Step ETL Tips with AWS Glue: Handling Multiple CSV Files from S3"></p>
<h1>AWS Glue에서 ETL 작업 만들기</h1>
<p><img src="/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_7.png" alt="ETL image"></p>
<p>AWS Glue은 데이터 변환의 핵심 프로세스인 ETL(추출, 변환, 로드)을 수행하는 다양한 방법을 제공합니다. 시각적 ETL, 주피터, 또는 스크립팅을 통해 가장 적합한 방법을 선택할 수 있습니다.</p>
<h2>시각적 ETL</h2>
<p>기술적 배경이 없는 분들에게 시각적 ETL은 이상적인 선택지입니다. 직관적인 드래그 앤 드롭 인터페이스를 통해 코드 작성 없이도 ETL 워크플로를 구축할 수 있습니다. 다양한 데이터 원본을 쉽게 연결하고 데이터 변환을 적용하며 처리된 데이터를 원하는 대상에로 로드할 수 있습니다.</p>
<p>여기 AWS Glue로 Data Catalog에서 S3로 시각적 ETL을 구축하는 단계별 안내서가 있습니다.</p>
<ul>
<li>AWS Glue Studio에 액세스</li>
<li>새 워크플로 생성</li>
<li>데이터 원본 선택</li>
<li>변환 추가</li>
<li>데이터 대상 선택</li>
<li>작업 구성</li>
<li>작업 검토 및 실행</li>
</ul>
<h2>Jupyter Notebook</h2>
<p><img src="/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_9.png" alt="Image"></p>
<p>보다 경험 많은 데이터 전문가들에게 Jupyter는 더 많은 유연성과 파워를 제공합니다. Jupyter 노트북을 사용하면 Python 코드와 텍스트, 시각화를 결합하여 복잡한 데이터 분석을 수행할 수 있습니다.</p>
<p>다음은 AWS Glue를 사용하여 Jupyter Notebook을 사용하는 단계입니다. Data Catalog에서 S3로 콘솔에서 사용하세요.</p>
<ul>
<li>AWS Glue Studio를 열어주세요.</li>
<li>새로운 주피터 노트북을 생성해주세요.</li>
<li>주피터 노트북에 파이썬 코드를 작성해주세요.</li>
<li>작성한 파이썬 코드를 실행해주세요.</li>
<li>주피터 노트북을 저장하고 공유해주세요.</li>
</ul>
<h2>스크립팅</h2>
<p>ETL 프로세스를 완전히 제어하고 싶은 경우, AWS Glue를 사용하여 Python 및 Scala와 같은 다양한 프로그래밍 언어로 스크립트를 작성할 수 있습니다. 이러한 스크립트는 귀하의 특정 요구에 맞게 설계된 복잡한 데이터 변환을 수행하는 데 사용될 수 있습니다.</p>
<p>아래는 데이터 카탈로그부터 S3까지 콘솔에서 AWS Glue를 스크립팅과 함께 사용하는 단계입니다.</p>
<ul>
<li>AWS Glue 콘솔을 열어주세요.</li>
<li>좌측 탐색 패널에서 Glue를 선택합니다.</li>
<li>메인 패널 상단에서 Jobs를 선택합니다.</li>
<li>'Create job'을 클릭합니다.</li>
<li>작업의 이름을 입력해주세요. 예를 들어 "TransferDataFromCatalogToS3"와 같이 지정합니다.</li>
<li>Script location 섹션에서 Glue 스크립트를 선택합니다.</li>
<li>Glue 스크립트 상자에 다음과 같은 Python 스크립트를 입력하세요. 이는 예시입니다.</li>
</ul>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">from</span> awsglue.<span class="hljs-property">transforms</span> <span class="hljs-keyword">import</span> *
<span class="hljs-keyword">from</span> awsglue.<span class="hljs-property">utils</span> <span class="hljs-keyword">import</span> getResolvedOptions
<span class="hljs-keyword">from</span> pyspark.<span class="hljs-property">context</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">SparkContext</span>
<span class="hljs-keyword">from</span> awsglue.<span class="hljs-property">context</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">GlueContext</span>
<span class="hljs-keyword">from</span> awsglue.<span class="hljs-property">job</span> <span class="hljs-keyword">import</span> <span class="hljs-title class_">Job</span>
  
sc = <span class="hljs-title class_">SparkContext</span>.<span class="hljs-title function_">getOrCreate</span>()
glueContext = <span class="hljs-title class_">GlueContext</span>(sc)
spark = glueContext.<span class="hljs-property">spark_session</span>
job = <span class="hljs-title class_">Job</span>(glueContext)

# <span class="hljs-title class_">Read</span>
dyf = glueContext.<span class="hljs-property">create_dynamic_frame</span>.<span class="hljs-title function_">from_catalog</span>(database=<span class="hljs-string">'db-s3-glue '</span>, 
                                                    table_name=<span class="hljs-string">'1_source'</span>
                                                   )

# <span class="hljs-title class_">Store</span>
output_dyf = glueContext.<span class="hljs-property">write_dynamic_frame</span>.<span class="hljs-title function_">from_options</span>(frame=dyf, 
                                                          connection_type=<span class="hljs-string">"s3"</span>, 
                                                          format=<span class="hljs-string">"glueparquet"</span>, 
                                                          connection_options={<span class="hljs-string">"path"</span>: <span class="hljs-string">"s3://s3-glue/2-target/"</span>, <span class="hljs-string">"partitionKeys"</span>: []}, 
                                                          format_options={<span class="hljs-string">"compression"</span>: <span class="hljs-string">"uncompressed"</span>}
                                                         )

job.<span class="hljs-title function_">commit</span>()
</code></pre>
<h1>다음은 무엇이 있을까요?</h1>
<ul>
<li>MySQL, SQL Server, Aurora와 같은 RDBMS 소스 탐색하기.</li>
<li>Redshift와 같은 데이터 웨어하우스로의 대상 데이터 탐색하기.</li>
<li>Workflows(오케스트레이션)를 사용하여 작업 자동화하기.</li>
<li>스트림 처리.</li>
</ul>
<h2>최선의 인사</h2>
<p>린탕 길랑</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"AWS Glue로 다수의 CSV 파일을 처리하는 ETL 단계별 팁","description":"","date":"2024-05-17 20:37","slug":"2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3","content":"\n\n이건 훌륭한 이미지입니다! 이 디지털 시대에 데이터는 기업에게 귀중한 자산이 되었습니다. 데이터를 효과적으로 처리하고 분석하는 것이 유용한 통찰력을 얻고 스마트한 의사결정을 하는 데 중요합니다. AWS Glue는 데이터를 쉽고 효율적으로 관리하고 분석하는 데 도움이 되는 포괄적인 솔루션이 됩니다.\n\n이 세션에서는 AWS Glue, 데이터 카탈로그, 및 크롤러가 하나의 버킷에 있는 여러 CSV 파일을 단일 데이터 세트로 읽는 방법에 대해 논의할 것입니다. 아래는 아키텍처 요약입니다:\n\n![아키텍처 이미지](/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# S3 버킷 준비하기\n\n처리하려는 모든 CSV 파일이 아마존 S3의 단일 버킷에 저장되어 있는지 확인하세요.\n\n![이미지](/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_2.png)\n\n# AWS Glue 데이터 카탈로그에서 데이터베이스 생성하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAWS Management Console에서 AWS Glue를 열고, \"데이터베이스\" 섹션으로 이동하여 메타데이터를 저장할 새 데이터베이스를 생성하세요.\n\n![이미지](/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_3.png)\n\n# 크롤러 생성\n\n이전에 생성한 데이터베이스를 선택하여 크롤러에 의해 생성된 테이블을 저장하세요. 크롤러를 사용하여 테이블 추가를 선택하세요. 크롤러에 이름을 지정하고 CSV 파일을 포함하는 S3 버킷 위치를 선택하여 데이터 원본을 지정하세요. S3의 데이터 원본에 액세스할 수 있는 IAM 역할을 지정하고 Glue 데이터 카탈로그에 항목을 생성할 수 있는 권한이 있는 IAM 역할을 지정하세요. 필요에 따라 크롤러 옵션을 구성하세요. 크롤러를 주기적으로 실행하려면 빈도를 설정하세요. 구성을 완료한 후 크롤러를 실행하세요. 크롤러는 지정된 버킷의 모든 CSV 파일을 읽고 Glue 데이터 카탈로그에 하나 이상의 테이블을 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Step-by-Step ETL Tips with AWS Glue: Handling Multiple CSV Files from S3](/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_4.png)\n\n![Step-by-Step ETL Tips with AWS Glue: Handling Multiple CSV Files from S3](/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_5.png)\n\nOnce the crawler status is complete you can preview the table data that has been created using Athena\n\n![Step-by-Step ETL Tips with AWS Glue: Handling Multiple CSV Files from S3](/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_6.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# AWS Glue에서 ETL 작업 만들기\n\n![ETL image](/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_7.png)\n\nAWS Glue은 데이터 변환의 핵심 프로세스인 ETL(추출, 변환, 로드)을 수행하는 다양한 방법을 제공합니다. 시각적 ETL, 주피터, 또는 스크립팅을 통해 가장 적합한 방법을 선택할 수 있습니다.\n\n## 시각적 ETL\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_8.png\" /\u003e\n\n기술적 배경이 없는 분들에게 시각적 ETL은 이상적인 선택지입니다. 직관적인 드래그 앤 드롭 인터페이스를 통해 코드 작성 없이도 ETL 워크플로를 구축할 수 있습니다. 다양한 데이터 원본을 쉽게 연결하고 데이터 변환을 적용하며 처리된 데이터를 원하는 대상에로 로드할 수 있습니다.\n\n여기 AWS Glue로 Data Catalog에서 S3로 시각적 ETL을 구축하는 단계별 안내서가 있습니다.\n\n- AWS Glue Studio에 액세스\n- 새 워크플로 생성\n- 데이터 원본 선택\n- 변환 추가\n- 데이터 대상 선택\n- 작업 구성\n- 작업 검토 및 실행\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## Jupyter Notebook\n\n![Image](/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_9.png)\n\n보다 경험 많은 데이터 전문가들에게 Jupyter는 더 많은 유연성과 파워를 제공합니다. Jupyter 노트북을 사용하면 Python 코드와 텍스트, 시각화를 결합하여 복잡한 데이터 분석을 수행할 수 있습니다.\n\n다음은 AWS Glue를 사용하여 Jupyter Notebook을 사용하는 단계입니다. Data Catalog에서 S3로 콘솔에서 사용하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- AWS Glue Studio를 열어주세요.\n- 새로운 주피터 노트북을 생성해주세요.\n- 주피터 노트북에 파이썬 코드를 작성해주세요.\n- 작성한 파이썬 코드를 실행해주세요.\n- 주피터 노트북을 저장하고 공유해주세요.\n\n## 스크립팅\n\nETL 프로세스를 완전히 제어하고 싶은 경우, AWS Glue를 사용하여 Python 및 Scala와 같은 다양한 프로그래밍 언어로 스크립트를 작성할 수 있습니다. 이러한 스크립트는 귀하의 특정 요구에 맞게 설계된 복잡한 데이터 변환을 수행하는 데 사용될 수 있습니다.\n\n아래는 데이터 카탈로그부터 S3까지 콘솔에서 AWS Glue를 스크립팅과 함께 사용하는 단계입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- AWS Glue 콘솔을 열어주세요.\n- 좌측 탐색 패널에서 Glue를 선택합니다.\n- 메인 패널 상단에서 Jobs를 선택합니다.\n- 'Create job'을 클릭합니다.\n- 작업의 이름을 입력해주세요. 예를 들어 \"TransferDataFromCatalogToS3\"와 같이 지정합니다.\n- Script location 섹션에서 Glue 스크립트를 선택합니다.\n- Glue 스크립트 상자에 다음과 같은 Python 스크립트를 입력하세요. 이는 예시입니다.\n\n```js\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)\n\n# Read\ndyf = glueContext.create_dynamic_frame.from_catalog(database='db-s3-glue ', \n                                                    table_name='1_source'\n                                                   )\n\n# Store\noutput_dyf = glueContext.write_dynamic_frame.from_options(frame=dyf, \n                                                          connection_type=\"s3\", \n                                                          format=\"glueparquet\", \n                                                          connection_options={\"path\": \"s3://s3-glue/2-target/\", \"partitionKeys\": []}, \n                                                          format_options={\"compression\": \"uncompressed\"}\n                                                         )\n\njob.commit()\n```\n\n# 다음은 무엇이 있을까요?\n\n- MySQL, SQL Server, Aurora와 같은 RDBMS 소스 탐색하기.\n- Redshift와 같은 데이터 웨어하우스로의 대상 데이터 탐색하기.\n- Workflows(오케스트레이션)를 사용하여 작업 자동화하기.\n- 스트림 처리.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 최선의 인사\n\n린탕 길랑","ogImage":{"url":"/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_0.png"},"coverImage":"/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_0.png","tag":["Tech"],"readingTime":5},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e이건 훌륭한 이미지입니다! 이 디지털 시대에 데이터는 기업에게 귀중한 자산이 되었습니다. 데이터를 효과적으로 처리하고 분석하는 것이 유용한 통찰력을 얻고 스마트한 의사결정을 하는 데 중요합니다. AWS Glue는 데이터를 쉽고 효율적으로 관리하고 분석하는 데 도움이 되는 포괄적인 솔루션이 됩니다.\u003c/p\u003e\n\u003cp\u003e이 세션에서는 AWS Glue, 데이터 카탈로그, 및 크롤러가 하나의 버킷에 있는 여러 CSV 파일을 단일 데이터 세트로 읽는 방법에 대해 논의할 것입니다. 아래는 아키텍처 요약입니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_1.png\" alt=\"아키텍처 이미지\"\u003e\u003c/p\u003e\n\u003ch1\u003eS3 버킷 준비하기\u003c/h1\u003e\n\u003cp\u003e처리하려는 모든 CSV 파일이 아마존 S3의 단일 버킷에 저장되어 있는지 확인하세요.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_2.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003ch1\u003eAWS Glue 데이터 카탈로그에서 데이터베이스 생성하기\u003c/h1\u003e\n\u003cp\u003eAWS Management Console에서 AWS Glue를 열고, \"데이터베이스\" 섹션으로 이동하여 메타데이터를 저장할 새 데이터베이스를 생성하세요.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_3.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003ch1\u003e크롤러 생성\u003c/h1\u003e\n\u003cp\u003e이전에 생성한 데이터베이스를 선택하여 크롤러에 의해 생성된 테이블을 저장하세요. 크롤러를 사용하여 테이블 추가를 선택하세요. 크롤러에 이름을 지정하고 CSV 파일을 포함하는 S3 버킷 위치를 선택하여 데이터 원본을 지정하세요. S3의 데이터 원본에 액세스할 수 있는 IAM 역할을 지정하고 Glue 데이터 카탈로그에 항목을 생성할 수 있는 권한이 있는 IAM 역할을 지정하세요. 필요에 따라 크롤러 옵션을 구성하세요. 크롤러를 주기적으로 실행하려면 빈도를 설정하세요. 구성을 완료한 후 크롤러를 실행하세요. 크롤러는 지정된 버킷의 모든 CSV 파일을 읽고 Glue 데이터 카탈로그에 하나 이상의 테이블을 생성합니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_4.png\" alt=\"Step-by-Step ETL Tips with AWS Glue: Handling Multiple CSV Files from S3\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_5.png\" alt=\"Step-by-Step ETL Tips with AWS Glue: Handling Multiple CSV Files from S3\"\u003e\u003c/p\u003e\n\u003cp\u003eOnce the crawler status is complete you can preview the table data that has been created using Athena\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_6.png\" alt=\"Step-by-Step ETL Tips with AWS Glue: Handling Multiple CSV Files from S3\"\u003e\u003c/p\u003e\n\u003ch1\u003eAWS Glue에서 ETL 작업 만들기\u003c/h1\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_7.png\" alt=\"ETL image\"\u003e\u003c/p\u003e\n\u003cp\u003eAWS Glue은 데이터 변환의 핵심 프로세스인 ETL(추출, 변환, 로드)을 수행하는 다양한 방법을 제공합니다. 시각적 ETL, 주피터, 또는 스크립팅을 통해 가장 적합한 방법을 선택할 수 있습니다.\u003c/p\u003e\n\u003ch2\u003e시각적 ETL\u003c/h2\u003e\n\u003cp\u003e기술적 배경이 없는 분들에게 시각적 ETL은 이상적인 선택지입니다. 직관적인 드래그 앤 드롭 인터페이스를 통해 코드 작성 없이도 ETL 워크플로를 구축할 수 있습니다. 다양한 데이터 원본을 쉽게 연결하고 데이터 변환을 적용하며 처리된 데이터를 원하는 대상에로 로드할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e여기 AWS Glue로 Data Catalog에서 S3로 시각적 ETL을 구축하는 단계별 안내서가 있습니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAWS Glue Studio에 액세스\u003c/li\u003e\n\u003cli\u003e새 워크플로 생성\u003c/li\u003e\n\u003cli\u003e데이터 원본 선택\u003c/li\u003e\n\u003cli\u003e변환 추가\u003c/li\u003e\n\u003cli\u003e데이터 대상 선택\u003c/li\u003e\n\u003cli\u003e작업 구성\u003c/li\u003e\n\u003cli\u003e작업 검토 및 실행\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eJupyter Notebook\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_9.png\" alt=\"Image\"\u003e\u003c/p\u003e\n\u003cp\u003e보다 경험 많은 데이터 전문가들에게 Jupyter는 더 많은 유연성과 파워를 제공합니다. Jupyter 노트북을 사용하면 Python 코드와 텍스트, 시각화를 결합하여 복잡한 데이터 분석을 수행할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e다음은 AWS Glue를 사용하여 Jupyter Notebook을 사용하는 단계입니다. Data Catalog에서 S3로 콘솔에서 사용하세요.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAWS Glue Studio를 열어주세요.\u003c/li\u003e\n\u003cli\u003e새로운 주피터 노트북을 생성해주세요.\u003c/li\u003e\n\u003cli\u003e주피터 노트북에 파이썬 코드를 작성해주세요.\u003c/li\u003e\n\u003cli\u003e작성한 파이썬 코드를 실행해주세요.\u003c/li\u003e\n\u003cli\u003e주피터 노트북을 저장하고 공유해주세요.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e스크립팅\u003c/h2\u003e\n\u003cp\u003eETL 프로세스를 완전히 제어하고 싶은 경우, AWS Glue를 사용하여 Python 및 Scala와 같은 다양한 프로그래밍 언어로 스크립트를 작성할 수 있습니다. 이러한 스크립트는 귀하의 특정 요구에 맞게 설계된 복잡한 데이터 변환을 수행하는 데 사용될 수 있습니다.\u003c/p\u003e\n\u003cp\u003e아래는 데이터 카탈로그부터 S3까지 콘솔에서 AWS Glue를 스크립팅과 함께 사용하는 단계입니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAWS Glue 콘솔을 열어주세요.\u003c/li\u003e\n\u003cli\u003e좌측 탐색 패널에서 Glue를 선택합니다.\u003c/li\u003e\n\u003cli\u003e메인 패널 상단에서 Jobs를 선택합니다.\u003c/li\u003e\n\u003cli\u003e'Create job'을 클릭합니다.\u003c/li\u003e\n\u003cli\u003e작업의 이름을 입력해주세요. 예를 들어 \"TransferDataFromCatalogToS3\"와 같이 지정합니다.\u003c/li\u003e\n\u003cli\u003eScript location 섹션에서 Glue 스크립트를 선택합니다.\u003c/li\u003e\n\u003cli\u003eGlue 스크립트 상자에 다음과 같은 Python 스크립트를 입력하세요. 이는 예시입니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e sys\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e awsglue.\u003cspan class=\"hljs-property\"\u003etransforms\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e *\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e awsglue.\u003cspan class=\"hljs-property\"\u003eutils\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e getResolvedOptions\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e pyspark.\u003cspan class=\"hljs-property\"\u003econtext\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eSparkContext\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e awsglue.\u003cspan class=\"hljs-property\"\u003econtext\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eGlueContext\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e awsglue.\u003cspan class=\"hljs-property\"\u003ejob\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eJob\u003c/span\u003e\n  \nsc = \u003cspan class=\"hljs-title class_\"\u003eSparkContext\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003egetOrCreate\u003c/span\u003e()\nglueContext = \u003cspan class=\"hljs-title class_\"\u003eGlueContext\u003c/span\u003e(sc)\nspark = glueContext.\u003cspan class=\"hljs-property\"\u003espark_session\u003c/span\u003e\njob = \u003cspan class=\"hljs-title class_\"\u003eJob\u003c/span\u003e(glueContext)\n\n# \u003cspan class=\"hljs-title class_\"\u003eRead\u003c/span\u003e\ndyf = glueContext.\u003cspan class=\"hljs-property\"\u003ecreate_dynamic_frame\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_catalog\u003c/span\u003e(database=\u003cspan class=\"hljs-string\"\u003e'db-s3-glue '\u003c/span\u003e, \n                                                    table_name=\u003cspan class=\"hljs-string\"\u003e'1_source'\u003c/span\u003e\n                                                   )\n\n# \u003cspan class=\"hljs-title class_\"\u003eStore\u003c/span\u003e\noutput_dyf = glueContext.\u003cspan class=\"hljs-property\"\u003ewrite_dynamic_frame\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003efrom_options\u003c/span\u003e(frame=dyf, \n                                                          connection_type=\u003cspan class=\"hljs-string\"\u003e\"s3\"\u003c/span\u003e, \n                                                          format=\u003cspan class=\"hljs-string\"\u003e\"glueparquet\"\u003c/span\u003e, \n                                                          connection_options={\u003cspan class=\"hljs-string\"\u003e\"path\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"s3://s3-glue/2-target/\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"partitionKeys\"\u003c/span\u003e: []}, \n                                                          format_options={\u003cspan class=\"hljs-string\"\u003e\"compression\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"uncompressed\"\u003c/span\u003e}\n                                                         )\n\njob.\u003cspan class=\"hljs-title function_\"\u003ecommit\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003e다음은 무엇이 있을까요?\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eMySQL, SQL Server, Aurora와 같은 RDBMS 소스 탐색하기.\u003c/li\u003e\n\u003cli\u003eRedshift와 같은 데이터 웨어하우스로의 대상 데이터 탐색하기.\u003c/li\u003e\n\u003cli\u003eWorkflows(오케스트레이션)를 사용하여 작업 자동화하기.\u003c/li\u003e\n\u003cli\u003e스트림 처리.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003e최선의 인사\u003c/h2\u003e\n\u003cp\u003e린탕 길랑\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3"},"buildId":"t9N7vwmpvBMQnO2PSctoH","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>