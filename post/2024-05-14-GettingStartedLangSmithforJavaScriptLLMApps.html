<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>시작하기 JavaScript LLM 앱용 LangSmith | allround-coder</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://allround-coder.github.io///post/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="시작하기 JavaScript LLM 앱용 LangSmith | allround-coder" data-gatsby-head="true"/><meta property="og:title" content="시작하기 JavaScript LLM 앱용 LangSmith | allround-coder" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://allround-coder.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://allround-coder.github.io///post/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps" data-gatsby-head="true"/><meta name="twitter:title" content="시작하기 JavaScript LLM 앱용 LangSmith | allround-coder" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | allround-coder" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-14 14:14" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZFDEQ947R4"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
  
            gtag('config', 'G-ZFDEQ947R4');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-b088bc509ff5c497.js" defer=""></script><script src="/_next/static/t9N7vwmpvBMQnO2PSctoH/_buildManifest.js" defer=""></script><script src="/_next/static/t9N7vwmpvBMQnO2PSctoH/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Allround Coder</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">시작하기 JavaScript LLM 앱용 LangSmith</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="시작하기 JavaScript LLM 앱용 LangSmith" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">Allround Coder</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 14, 2024</span><span class="posts_reading_time__f7YPP">6<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>대용량 언어 모델(Large Language Models, LLM)의 파워를 LangSmith와 함께 발휘하세요: 시작부터 끝까지 AI 개발을 최적화해보세요!</p>
<p>대용량 언어 모델(LLM) 위에 챗봇을 구축하고 있다고 상상해보세요. 감정 분석, RAG 검색 또는 문맥 이해와 같은 복잡한 기능을 통합할 때 예기치 않은 오류에 직면합니다. 이러한 문제를 해결하더라도 새로운 도전이 나타나고 앱에 작은 변경 사항이나 LLM의 업데이트로 인해 발생할 수 있습니다. LLM과 작업하면 마법 상자에 연결된 것처럼 느껴지기도 합니다. 때로는 결과가 놀라울 정도로 훌륭하고 때로는 그렇지 않을 수도 있습니다. 그들이 왜 그렇게 행동하는지, 그것이 앱에 어떤 영향을 미치는지 알기 어려울 때가 있습니다.</p>
<p>LangSmith는 개발부터 모니터링까지 LLM 애플리케이션의 전체 라이프사이클을 최적화하는 포괄적인 데브옵스 플랫폼으로 이 문제를 해결합니다. 이 통합은 개발을 단순화하는 것뿐만 아니라 개발자들 사이의 신뢰를 높이고 품질을 보장하며 비용을 관리하고 지연 시간을 줄여, LLM 애플리케이션 개발을 더욱 접근 가능하고 효율적으로 만듭니다.</p>
<p>본 문서에서는 LangSmith가 무엇인지, 왜 사용해야 하는지, 어떻게 사용해야 하는지, 그리고 런 트레이스 기능의 빠른 데모를 진행하겠습니다.</p>
<p>LangSmith을 사용해야 하는 이유는 무엇일까요?</p>
<ul>
<li>포괄적인 개발 도구: LangSmith는 LLM 애플리케이션을 위한 맞춤형 개발 도구를 제공하여 상세한 호출 순서 가시성, 실시간 디버깅, 및 성능 최적화 기능을 제공합니다.</li>
<li>고급 테스팅 및 평가: 이 플랫폼은 강력한 테스트 프레임워크와 AI 지원 평가를 제공하여 응답의 품질을 보장하며, 관련성, 정확성, 민감성을 포괄합니다.</li>
<li>배포 및 확장성: LangSmith는 리소스 집약적인 LLM 애플리케이션의 배포와 확장을 간소화하여 성능 저하 없이 증가된 부하를 관리합니다.</li>
<li>실시간 모니터링 및 분석: 종합적인 모니터링은 비용, 지연 시간, 품질을 추적하며, 실시간 분석을 통해 신속한 결정을 내릴 수 있도록 지원합니다.</li>
<li>비용 관리: LangSmith는 LLM 프로젝트의 재정 측면을 관리하는 데 도움을 줌으로써 지출을 최적화하고 애플리케이션 효율성을 극대화하는 통찰을 제공합니다.</li>
<li>협업 기능: 이 플랫폼은 공유 작업 공간, 버전 관리, 그리고 커뮤니케이션 도구로 팀워크를 강화하여, 지역 간 원활한 협업을 지원합니다.</li>
</ul>
<h1>주요 기능</h1>
<p>LangSmith에는 많은 기능이 있으며 새로운 기능을 지속적으로 추가합니다. 여기 몇 가지 주요 기능을 살펴보세요:</p>
<h2>실행 추적</h2>
<p>추적은 LLM 애플리케이션의 동작을 이해하는 데 도움이 되는 강력한 도구입니다. 추적을 사용하면 예기치 않은 결과나 에이전트가 루프를 도는 이유, 실행이 느린 이유, 비용이 얼마나 드는지, 또는 고객이 최적의 응답을 받지 못하는 이유 등의 문제를 진단할 수 있습니다.</p>
<h2>주석이 달린 큐</h2>
<p>주석이 달린 큐는 데이터를 빠르게 순환하고 주석을 달 수 있는 사용자 친화적인 방법입니다. 사람들이나 LLM이 결과를 평가할 수 있는 워크플로우를 만들 수 있습니다. 이 데이터는 애플리케이션의 테스트 및 개선에 사용될 수 있습니다.</p>
<h2>데이터셋 및 테스트</h2>
<p>데이터셋은 업로드할 수도 있고 실제 실행에서 파생될 수도 있습니다. 그런 다음 이 데이터를 사용하여 응용 프로그램의 성능과 정확도를 측정하는 평가자를 사용하여 테스트를 실행할 수 있습니다.</p>
<h2>허브</h2>
<p>허브를 사용하면 LLM 프롬프트용 GitHub과 같은 협업, 테스트 및 공유가 가능합니다. 프롬프트를 효과적으로 작성하는 방법을 확인하는 데 도움되는 것뿐만 아니라 프롬프트를 관리하는 훌륭한 방법이기도 합니다.</p>
<p>이 기사에서는 실시간 디버깅에 대해 자세히 살펴보겠습니다.</p>
<h1>LangChain과 프로젝트 통합</h1>
<p>LangChain.js를 사용하여 간단한 앱을 만들었는데, 이는 LangSmith와의 통합 설정에 좋은 시작점을 제공할 것입니다.</p>
<ul>
<li>저장소 복제: git clone <a href="mailto:git@github.com">git@github.com</a>:kenzic/simple-langsmith-demo.git</li>
<li>의존성 설치: yarn</li>
<li>LangSmith 계정 등록</li>
<li>API 키 받기</li>
<li>OpenAI API 키 받기</li>
<li>.env.example을 .env로 이동하고 다음 값을 채워 넣으세요:</li>
</ul>
<pre><code class="hljs language-js"><span class="hljs-variable constant_">LANGCHAIN_PROJECT</span>=<span class="hljs-string">"langsmith-demo"</span>
<span class="hljs-variable constant_">LANGCHAIN_TRACING_V2</span>=<span class="hljs-literal">true</span>
<span class="hljs-variable constant_">LANGCHAIN_API_KEY</span>=&#x3C;your-api-key>

# <span class="hljs-title class_">OpenAI</span> <span class="hljs-variable constant_">API</span>를 사용하여 <span class="hljs-variable constant_">LLM</span>에 호출을 하지만, <span class="hljs-title class_">LangSmith</span>를 사용하는 데 필수적이지는 않습니다
<span class="hljs-variable constant_">OPENAI_API_KEY</span>=&#x3C;your-openai-api-key>
</code></pre>
<p>시작하기 전에 코드를 이해하는 데 1 ~ 2분 정도 소요되도록 사전에 시간을 투자해보세요. 이 코드는 높은 수준에서 다음과 같은 작업을 수행합니다:</p>
<ul>
<li>입력값 "프랑스의 수도는 무엇인가요?"로 앱을 호출합니다.</li>
<li>대화 검색 체인 (RunnableSequence):
<ul>
<li>문서 검색 체인을 호출하여 컨텍스트를 추가합니다. 이는 사용자의 질문에 답변하기 위해 데이터를 가져오는 사용자 지정 검색기를 사용합니다 (RunnableMap).</li>
<li>문서 검색 체인에서 가져온 컨텍스트를 사용하여 사용자 질문에 대한 LLM 답변을 Mr. Burns의 억양으로 작성하는 프롬프트를 생성합니다 (ChatPromptTemplate).</li>
<li>LLM을 호출합니다 (ChatOpenAI).</li>
<li>응답을 구문 분석하여 문자열로 반환합니다 (StrOutputParser).</li>
</ul>
</li>
</ul>
<h1>실습하기</h1>
<p>이 기사에서는 아마도 가장 강력한 기능인 실행 추적 및 디버깅 기능에 초점을 맞출 것입니다.</p>
<p>이제 우리 앱을 테스트하고 디버깅할 준비가 되었어요!</p>
<p>다음을 실행하여 시작하십시오: yarn start</p>
<p>스크립트는 앱에 "프랑스의 수도는 어디인가요?"라고 묻습니다.</p>
<p>우리가 받은 결과가 상당히 예상치 못한 것 같아요. 프랑스의 수도가 스프링필드라고 생각하고 있는 것 같아요. 이상하죠.</p>
<p>우리 중 일부는 프랑스의 수도가 스프링필드가 아니라 파리임을 알고 있죠. 그래서 왜 이런 결과를 받는 걸까요? 게다가 앱이 답변을 제대로 주기까지 오래 걸리는 것 같아요. 이 부분을 빨리 처리할 수는 없을까요?</p>
<p><a href="https://smith.langchain.com/" rel="nofollow" target="_blank">https://smith.langchain.com/</a> 로 이동해서 "langsmith-demo" 프로젝트를 클릭해주세요. 프로젝트 내부에 들어가면 실행 기록을 볼 수 있어요. 최근 실행부터 시작해서 무슨 일이 일어나고 있는지 힌트가 있는지 확인해보겠어요.</p>
<p><img src="/assets/img/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps_0.png" alt="이미지"></p>
<p>최상위 수준의 추적 결과 (RunnableSequence)를 살펴보면, 앱이 실행되는 데 3.33초가 걸리고 입력과 출력이 일치함을 볼 수 있지만 출력물은 명백히 잘못되었습니다.</p>
<p><img src="/assets/img/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps_1.png" alt="이미지"></p>
<p>다음 수준인 (RunnableMap)로 이동하면, 앱의 일부분이 LLM이 답변을 안내하는 데 사용할 문맥이나 지식을 검색하는 역할을 살펴볼 수 있습니다.</p>
<p><img src="/assets/img/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps_2.png" alt="이미지"></p>
<p>여기에서 무슨 일이 일어나고 있는지 빠르게 파악할 수 있어요. 저희 리트리버가 사실과 다른 정보를 제공하고 있네요. 이 데모에서는 "프랑스의 수도는 파리입니다"라는 내용으로 문서 내용을 바꿔서 수정할 수 있어요.</p>
<p>쉬웠죠! 하지만 아직 앱이 조금 느린 것 같아요. 왜 그럴까요? 계속 추적해보면 ChatPromptTemplate은 잘 보이고 실행 시간은 0.00초가 걸리므로, 그 부분은 아닌 것 같아요.</p>
<p><img src="/assets/img/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps_3.png" alt="image"></p>
<p>다음으로, ChatOpenAI 단계는 조금 느린데, 인터넷을 통해 요청을 보내고 있기 때문에 예상대로 그럴 수 있어요. 또한 OpenAI에 대한 호출이 총 139개의 토큰을 사용하여 총 $0.0001165를 소비했다는 점을 알려드릴게요. 앱이 더 복잡해지면 이 비용을 이해하기 위해 이 숫자에 주의해야 할 거예요.</p>
<p>마침내 StrOutputParser로 이동합니다. 실행 시간이 0.00초이고 출력을 올바르게 구문 분석했으므로 여기서 모든 것이 정상인 것 같습니다.</p>
<p>그래서 앱에서 병목 현상이 어디에 있는지 궁금하신가요? RunnableMap으로 돌아가 봅시다. 이 부분이 2.01초가 걸리는 것을 볼 수 있습니다. 한 개의 하드코딩된 문서를 반환하는 간단한 작업에 대해 이 시간은 높아 보입니다. 코드를 살펴보면 기능 slowLookupTask이 있음을 알 수 있습니다. 이 기능은 데모를 위해 인위적으로 만들어졌지만, 실제 시나리오에서는 검색기가 응용 프로그램의 지연 원인이 될 수 있으며, 종종 제어할 수 있는 부분 중 하나입니다.</p>
<p>마침내 스크립트를 다시 실행합시다. 어떻게나! 이제 쿼리에 올바른 답변을 받아, 2초를 절약했습니다!</p>
<h2>다음 단계</h2>
<p>LangSmith의 능력의 일부에 불과하지만, 이 짧은 글이 어떤 가능성을 밝혀주기를 바랍니다.</p>
<p>LangSmith의 디버깅 기능을 활용하여 더욱 탐험하면, 그 가능성을 최대로 발휘할 수 있습니다:</p>
<ul>
<li>고급 테스트 및 평가 도구를 활용하여 응답 품질을 지속적으로 확인합니다.</li>
<li>비용 관리 통찰력을 활용하여 리소스 사용량 및 비용을 최적화합니다.</li>
<li>공동 작업 공간, 버전 관리 및 빠른 라이브러리를 활용하여 협업을 촉진합니다.</li>
<li>감정 분석 및 맥락 이해와 같은 고급 기능을 통합합니다.</li>
<li>LangSmith의 미래를 형성하기 위해 새로운 릴리스에 주목하고 LangSmith 커뮤니티에 참여하세요.</li>
</ul>
<p>LLM 애플리케이션은 발전함에 따라 LangSmith가 개발을 간소화하고 성능을 보장하며 AI 혁신을 이끌어내는 도구를 제공합니다.</p>
<h1>마무리</h1>
<p>LangSmith 소개를 마치고 대형 언어 모델 애플리케이션 개발 마스터에 한 발짝 다가가셨습니다. 이 안내서에서는 고대형 언어 모델 프로젝트의 개발 및 유지 관리를 간소화하기 위해 LangSmith와 LangChain을 설정하고 사용하는 방법을 개요로 설명했습니다.</p>
<p>다룬 내용을 간단히 요약해 드리겠습니다:</p>
<ul>
<li>프로젝트를 LangChain과 LangSmith와 통합 설정하는 방법.</li>
<li>애플리케이션을 이해하고 최적화하기 위해 실시간 디버깅 및 실행 추적을 활용하는 방법.</li>
</ul>
<p>LangSmith로 수행할 수 있는 많은 작업이 있습니다. 이에 관한 내용은 나중에 다룰 것이지만, 오늘 LangSmith를 사용하고 있지 않다면 기술 스택에 추가할 가치가 있다는 것을 확신시켜 드릴 수 있기를 바랍니다.</p>
<p>연결 유지하고 여정을 공유하기 위해 아래 채널을 통해 언제든지 연락해 주세요:</p>
<ul>
<li>👨‍💼 LinkedIn: LLM 개발 및 기술 혁신에 대한 자세한 통찰력을 얻으려면 저와 함께하세요.</li>
<li>💻 GitHub: 제 프로젝트를 살펴보고 지속적인 작업에 기여하세요.</li>
<li>📚 Medium: LangSmith, LangChain 및 기타 AI 기술에 대한 보다 심층적인 토론을 위해 제 기사를 팔로우하세요.</li>
</ul>
<p>귀하의 피드백 및 협업은 귀중합니다. 행복한 개발하고 LangSmith로 만드는 놀라운 응용 프로그램을 기대하겠습니다!</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"시작하기 JavaScript LLM 앱용 LangSmith","description":"","date":"2024-05-14 14:14","slug":"2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps","content":"\n\n대용량 언어 모델(Large Language Models, LLM)의 파워를 LangSmith와 함께 발휘하세요: 시작부터 끝까지 AI 개발을 최적화해보세요!\n\n대용량 언어 모델(LLM) 위에 챗봇을 구축하고 있다고 상상해보세요. 감정 분석, RAG 검색 또는 문맥 이해와 같은 복잡한 기능을 통합할 때 예기치 않은 오류에 직면합니다. 이러한 문제를 해결하더라도 새로운 도전이 나타나고 앱에 작은 변경 사항이나 LLM의 업데이트로 인해 발생할 수 있습니다. LLM과 작업하면 마법 상자에 연결된 것처럼 느껴지기도 합니다. 때로는 결과가 놀라울 정도로 훌륭하고 때로는 그렇지 않을 수도 있습니다. 그들이 왜 그렇게 행동하는지, 그것이 앱에 어떤 영향을 미치는지 알기 어려울 때가 있습니다.\n\nLangSmith는 개발부터 모니터링까지 LLM 애플리케이션의 전체 라이프사이클을 최적화하는 포괄적인 데브옵스 플랫폼으로 이 문제를 해결합니다. 이 통합은 개발을 단순화하는 것뿐만 아니라 개발자들 사이의 신뢰를 높이고 품질을 보장하며 비용을 관리하고 지연 시간을 줄여, LLM 애플리케이션 개발을 더욱 접근 가능하고 효율적으로 만듭니다.\n\n본 문서에서는 LangSmith가 무엇인지, 왜 사용해야 하는지, 어떻게 사용해야 하는지, 그리고 런 트레이스 기능의 빠른 데모를 진행하겠습니다.\n\n\n\nLangSmith을 사용해야 하는 이유는 무엇일까요?\n\n- 포괄적인 개발 도구: LangSmith는 LLM 애플리케이션을 위한 맞춤형 개발 도구를 제공하여 상세한 호출 순서 가시성, 실시간 디버깅, 및 성능 최적화 기능을 제공합니다.\n- 고급 테스팅 및 평가: 이 플랫폼은 강력한 테스트 프레임워크와 AI 지원 평가를 제공하여 응답의 품질을 보장하며, 관련성, 정확성, 민감성을 포괄합니다.\n- 배포 및 확장성: LangSmith는 리소스 집약적인 LLM 애플리케이션의 배포와 확장을 간소화하여 성능 저하 없이 증가된 부하를 관리합니다.\n- 실시간 모니터링 및 분석: 종합적인 모니터링은 비용, 지연 시간, 품질을 추적하며, 실시간 분석을 통해 신속한 결정을 내릴 수 있도록 지원합니다.\n- 비용 관리: LangSmith는 LLM 프로젝트의 재정 측면을 관리하는 데 도움을 줌으로써 지출을 최적화하고 애플리케이션 효율성을 극대화하는 통찰을 제공합니다.\n- 협업 기능: 이 플랫폼은 공유 작업 공간, 버전 관리, 그리고 커뮤니케이션 도구로 팀워크를 강화하여, 지역 간 원활한 협업을 지원합니다.\n\n# 주요 기능\n\nLangSmith에는 많은 기능이 있으며 새로운 기능을 지속적으로 추가합니다. 여기 몇 가지 주요 기능을 살펴보세요:\n\n\n\n## 실행 추적\n\n추적은 LLM 애플리케이션의 동작을 이해하는 데 도움이 되는 강력한 도구입니다. 추적을 사용하면 예기치 않은 결과나 에이전트가 루프를 도는 이유, 실행이 느린 이유, 비용이 얼마나 드는지, 또는 고객이 최적의 응답을 받지 못하는 이유 등의 문제를 진단할 수 있습니다.\n\n## 주석이 달린 큐\n\n주석이 달린 큐는 데이터를 빠르게 순환하고 주석을 달 수 있는 사용자 친화적인 방법입니다. 사람들이나 LLM이 결과를 평가할 수 있는 워크플로우를 만들 수 있습니다. 이 데이터는 애플리케이션의 테스트 및 개선에 사용될 수 있습니다.\n\n\n\n## 데이터셋 및 테스트\n\n데이터셋은 업로드할 수도 있고 실제 실행에서 파생될 수도 있습니다. 그런 다음 이 데이터를 사용하여 응용 프로그램의 성능과 정확도를 측정하는 평가자를 사용하여 테스트를 실행할 수 있습니다.\n\n## 허브\n\n허브를 사용하면 LLM 프롬프트용 GitHub과 같은 협업, 테스트 및 공유가 가능합니다. 프롬프트를 효과적으로 작성하는 방법을 확인하는 데 도움되는 것뿐만 아니라 프롬프트를 관리하는 훌륭한 방법이기도 합니다.\n\n\n\n이 기사에서는 실시간 디버깅에 대해 자세히 살펴보겠습니다.\n\n# LangChain과 프로젝트 통합\n\nLangChain.js를 사용하여 간단한 앱을 만들었는데, 이는 LangSmith와의 통합 설정에 좋은 시작점을 제공할 것입니다.\n\n- 저장소 복제: git clone git@github.com:kenzic/simple-langsmith-demo.git\n- 의존성 설치: yarn\n- LangSmith 계정 등록\n- API 키 받기\n- OpenAI API 키 받기\n- .env.example을 .env로 이동하고 다음 값을 채워 넣으세요:\n\n\n\n```js\nLANGCHAIN_PROJECT=\"langsmith-demo\"\nLANGCHAIN_TRACING_V2=true\nLANGCHAIN_API_KEY=\u003cyour-api-key\u003e\n\n# OpenAI API를 사용하여 LLM에 호출을 하지만, LangSmith를 사용하는 데 필수적이지는 않습니다\nOPENAI_API_KEY=\u003cyour-openai-api-key\u003e\r\n```\n\n시작하기 전에 코드를 이해하는 데 1 ~ 2분 정도 소요되도록 사전에 시간을 투자해보세요. 이 코드는 높은 수준에서 다음과 같은 작업을 수행합니다:\n\n- 입력값 \"프랑스의 수도는 무엇인가요?\"로 앱을 호출합니다.\n- 대화 검색 체인 (RunnableSequence):\n  - 문서 검색 체인을 호출하여 컨텍스트를 추가합니다. 이는 사용자의 질문에 답변하기 위해 데이터를 가져오는 사용자 지정 검색기를 사용합니다 (RunnableMap).\n  - 문서 검색 체인에서 가져온 컨텍스트를 사용하여 사용자 질문에 대한 LLM 답변을 Mr. Burns의 억양으로 작성하는 프롬프트를 생성합니다 (ChatPromptTemplate).\n  - LLM을 호출합니다 (ChatOpenAI).\n  - 응답을 구문 분석하여 문자열로 반환합니다 (StrOutputParser).\n\n# 실습하기\n\n\n\n이 기사에서는 아마도 가장 강력한 기능인 실행 추적 및 디버깅 기능에 초점을 맞출 것입니다.\n\n이제 우리 앱을 테스트하고 디버깅할 준비가 되었어요!\n\n다음을 실행하여 시작하십시오: yarn start\n\n스크립트는 앱에 \"프랑스의 수도는 어디인가요?\"라고 묻습니다.\n\n\n\n우리가 받은 결과가 상당히 예상치 못한 것 같아요. 프랑스의 수도가 스프링필드라고 생각하고 있는 것 같아요. 이상하죠.\n\n우리 중 일부는 프랑스의 수도가 스프링필드가 아니라 파리임을 알고 있죠. 그래서 왜 이런 결과를 받는 걸까요? 게다가 앱이 답변을 제대로 주기까지 오래 걸리는 것 같아요. 이 부분을 빨리 처리할 수는 없을까요?\n\nhttps://smith.langchain.com/ 로 이동해서 \"langsmith-demo\" 프로젝트를 클릭해주세요. 프로젝트 내부에 들어가면 실행 기록을 볼 수 있어요. 최근 실행부터 시작해서 무슨 일이 일어나고 있는지 힌트가 있는지 확인해보겠어요.\n\n![이미지](/assets/img/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps_0.png)\n\n\n\n최상위 수준의 추적 결과 (RunnableSequence)를 살펴보면, 앱이 실행되는 데 3.33초가 걸리고 입력과 출력이 일치함을 볼 수 있지만 출력물은 명백히 잘못되었습니다.\n\n![이미지](/assets/img/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps_1.png)\n\n다음 수준인 (RunnableMap)로 이동하면, 앱의 일부분이 LLM이 답변을 안내하는 데 사용할 문맥이나 지식을 검색하는 역할을 살펴볼 수 있습니다.\n\n![이미지](/assets/img/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps_2.png)\n\n\n\n여기에서 무슨 일이 일어나고 있는지 빠르게 파악할 수 있어요. 저희 리트리버가 사실과 다른 정보를 제공하고 있네요. 이 데모에서는 \"프랑스의 수도는 파리입니다\"라는 내용으로 문서 내용을 바꿔서 수정할 수 있어요.\n\n쉬웠죠! 하지만 아직 앱이 조금 느린 것 같아요. 왜 그럴까요? 계속 추적해보면 ChatPromptTemplate은 잘 보이고 실행 시간은 0.00초가 걸리므로, 그 부분은 아닌 것 같아요.\n\n![image](/assets/img/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps_3.png)\n\n다음으로, ChatOpenAI 단계는 조금 느린데, 인터넷을 통해 요청을 보내고 있기 때문에 예상대로 그럴 수 있어요. 또한 OpenAI에 대한 호출이 총 139개의 토큰을 사용하여 총 $0.0001165를 소비했다는 점을 알려드릴게요. 앱이 더 복잡해지면 이 비용을 이해하기 위해 이 숫자에 주의해야 할 거예요.\n\n\n\n\u003cimg src=\"/assets/img/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps_4.png\" /\u003e\n\n마침내 StrOutputParser로 이동합니다. 실행 시간이 0.00초이고 출력을 올바르게 구문 분석했으므로 여기서 모든 것이 정상인 것 같습니다.\n\n\u003cimg src=\"/assets/img/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps_5.png\" /\u003e\n\n그래서 앱에서 병목 현상이 어디에 있는지 궁금하신가요? RunnableMap으로 돌아가 봅시다. 이 부분이 2.01초가 걸리는 것을 볼 수 있습니다. 한 개의 하드코딩된 문서를 반환하는 간단한 작업에 대해 이 시간은 높아 보입니다. 코드를 살펴보면 기능 slowLookupTask이 있음을 알 수 있습니다. 이 기능은 데모를 위해 인위적으로 만들어졌지만, 실제 시나리오에서는 검색기가 응용 프로그램의 지연 원인이 될 수 있으며, 종종 제어할 수 있는 부분 중 하나입니다.\n\n\n\n마침내 스크립트를 다시 실행합시다. 어떻게나! 이제 쿼리에 올바른 답변을 받아, 2초를 절약했습니다!\n\n## 다음 단계\n\nLangSmith의 능력의 일부에 불과하지만, 이 짧은 글이 어떤 가능성을 밝혀주기를 바랍니다.\n\nLangSmith의 디버깅 기능을 활용하여 더욱 탐험하면, 그 가능성을 최대로 발휘할 수 있습니다:\n\n\n\n- 고급 테스트 및 평가 도구를 활용하여 응답 품질을 지속적으로 확인합니다.\n- 비용 관리 통찰력을 활용하여 리소스 사용량 및 비용을 최적화합니다.\n- 공동 작업 공간, 버전 관리 및 빠른 라이브러리를 활용하여 협업을 촉진합니다.\n- 감정 분석 및 맥락 이해와 같은 고급 기능을 통합합니다.\n- LangSmith의 미래를 형성하기 위해 새로운 릴리스에 주목하고 LangSmith 커뮤니티에 참여하세요.\n\nLLM 애플리케이션은 발전함에 따라 LangSmith가 개발을 간소화하고 성능을 보장하며 AI 혁신을 이끌어내는 도구를 제공합니다.\n\n# 마무리\n\nLangSmith 소개를 마치고 대형 언어 모델 애플리케이션 개발 마스터에 한 발짝 다가가셨습니다. 이 안내서에서는 고대형 언어 모델 프로젝트의 개발 및 유지 관리를 간소화하기 위해 LangSmith와 LangChain을 설정하고 사용하는 방법을 개요로 설명했습니다.\n\n\n\n다룬 내용을 간단히 요약해 드리겠습니다:\n\n- 프로젝트를 LangChain과 LangSmith와 통합 설정하는 방법.\n- 애플리케이션을 이해하고 최적화하기 위해 실시간 디버깅 및 실행 추적을 활용하는 방법.\n\nLangSmith로 수행할 수 있는 많은 작업이 있습니다. 이에 관한 내용은 나중에 다룰 것이지만, 오늘 LangSmith를 사용하고 있지 않다면 기술 스택에 추가할 가치가 있다는 것을 확신시켜 드릴 수 있기를 바랍니다.\n\n연결 유지하고 여정을 공유하기 위해 아래 채널을 통해 언제든지 연락해 주세요:\n\n\n\n- 👨‍💼 LinkedIn: LLM 개발 및 기술 혁신에 대한 자세한 통찰력을 얻으려면 저와 함께하세요.\n- 💻 GitHub: 제 프로젝트를 살펴보고 지속적인 작업에 기여하세요.\n- 📚 Medium: LangSmith, LangChain 및 기타 AI 기술에 대한 보다 심층적인 토론을 위해 제 기사를 팔로우하세요.\n\n귀하의 피드백 및 협업은 귀중합니다. 행복한 개발하고 LangSmith로 만드는 놀라운 응용 프로그램을 기대하겠습니다!","ogImage":{"url":"/assets/img/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps_0.png"},"coverImage":"/assets/img/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps_0.png","tag":["Tech"],"readingTime":6},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e대용량 언어 모델(Large Language Models, LLM)의 파워를 LangSmith와 함께 발휘하세요: 시작부터 끝까지 AI 개발을 최적화해보세요!\u003c/p\u003e\n\u003cp\u003e대용량 언어 모델(LLM) 위에 챗봇을 구축하고 있다고 상상해보세요. 감정 분석, RAG 검색 또는 문맥 이해와 같은 복잡한 기능을 통합할 때 예기치 않은 오류에 직면합니다. 이러한 문제를 해결하더라도 새로운 도전이 나타나고 앱에 작은 변경 사항이나 LLM의 업데이트로 인해 발생할 수 있습니다. LLM과 작업하면 마법 상자에 연결된 것처럼 느껴지기도 합니다. 때로는 결과가 놀라울 정도로 훌륭하고 때로는 그렇지 않을 수도 있습니다. 그들이 왜 그렇게 행동하는지, 그것이 앱에 어떤 영향을 미치는지 알기 어려울 때가 있습니다.\u003c/p\u003e\n\u003cp\u003eLangSmith는 개발부터 모니터링까지 LLM 애플리케이션의 전체 라이프사이클을 최적화하는 포괄적인 데브옵스 플랫폼으로 이 문제를 해결합니다. 이 통합은 개발을 단순화하는 것뿐만 아니라 개발자들 사이의 신뢰를 높이고 품질을 보장하며 비용을 관리하고 지연 시간을 줄여, LLM 애플리케이션 개발을 더욱 접근 가능하고 효율적으로 만듭니다.\u003c/p\u003e\n\u003cp\u003e본 문서에서는 LangSmith가 무엇인지, 왜 사용해야 하는지, 어떻게 사용해야 하는지, 그리고 런 트레이스 기능의 빠른 데모를 진행하겠습니다.\u003c/p\u003e\n\u003cp\u003eLangSmith을 사용해야 하는 이유는 무엇일까요?\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e포괄적인 개발 도구: LangSmith는 LLM 애플리케이션을 위한 맞춤형 개발 도구를 제공하여 상세한 호출 순서 가시성, 실시간 디버깅, 및 성능 최적화 기능을 제공합니다.\u003c/li\u003e\n\u003cli\u003e고급 테스팅 및 평가: 이 플랫폼은 강력한 테스트 프레임워크와 AI 지원 평가를 제공하여 응답의 품질을 보장하며, 관련성, 정확성, 민감성을 포괄합니다.\u003c/li\u003e\n\u003cli\u003e배포 및 확장성: LangSmith는 리소스 집약적인 LLM 애플리케이션의 배포와 확장을 간소화하여 성능 저하 없이 증가된 부하를 관리합니다.\u003c/li\u003e\n\u003cli\u003e실시간 모니터링 및 분석: 종합적인 모니터링은 비용, 지연 시간, 품질을 추적하며, 실시간 분석을 통해 신속한 결정을 내릴 수 있도록 지원합니다.\u003c/li\u003e\n\u003cli\u003e비용 관리: LangSmith는 LLM 프로젝트의 재정 측면을 관리하는 데 도움을 줌으로써 지출을 최적화하고 애플리케이션 효율성을 극대화하는 통찰을 제공합니다.\u003c/li\u003e\n\u003cli\u003e협업 기능: 이 플랫폼은 공유 작업 공간, 버전 관리, 그리고 커뮤니케이션 도구로 팀워크를 강화하여, 지역 간 원활한 협업을 지원합니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e주요 기능\u003c/h1\u003e\n\u003cp\u003eLangSmith에는 많은 기능이 있으며 새로운 기능을 지속적으로 추가합니다. 여기 몇 가지 주요 기능을 살펴보세요:\u003c/p\u003e\n\u003ch2\u003e실행 추적\u003c/h2\u003e\n\u003cp\u003e추적은 LLM 애플리케이션의 동작을 이해하는 데 도움이 되는 강력한 도구입니다. 추적을 사용하면 예기치 않은 결과나 에이전트가 루프를 도는 이유, 실행이 느린 이유, 비용이 얼마나 드는지, 또는 고객이 최적의 응답을 받지 못하는 이유 등의 문제를 진단할 수 있습니다.\u003c/p\u003e\n\u003ch2\u003e주석이 달린 큐\u003c/h2\u003e\n\u003cp\u003e주석이 달린 큐는 데이터를 빠르게 순환하고 주석을 달 수 있는 사용자 친화적인 방법입니다. 사람들이나 LLM이 결과를 평가할 수 있는 워크플로우를 만들 수 있습니다. 이 데이터는 애플리케이션의 테스트 및 개선에 사용될 수 있습니다.\u003c/p\u003e\n\u003ch2\u003e데이터셋 및 테스트\u003c/h2\u003e\n\u003cp\u003e데이터셋은 업로드할 수도 있고 실제 실행에서 파생될 수도 있습니다. 그런 다음 이 데이터를 사용하여 응용 프로그램의 성능과 정확도를 측정하는 평가자를 사용하여 테스트를 실행할 수 있습니다.\u003c/p\u003e\n\u003ch2\u003e허브\u003c/h2\u003e\n\u003cp\u003e허브를 사용하면 LLM 프롬프트용 GitHub과 같은 협업, 테스트 및 공유가 가능합니다. 프롬프트를 효과적으로 작성하는 방법을 확인하는 데 도움되는 것뿐만 아니라 프롬프트를 관리하는 훌륭한 방법이기도 합니다.\u003c/p\u003e\n\u003cp\u003e이 기사에서는 실시간 디버깅에 대해 자세히 살펴보겠습니다.\u003c/p\u003e\n\u003ch1\u003eLangChain과 프로젝트 통합\u003c/h1\u003e\n\u003cp\u003eLangChain.js를 사용하여 간단한 앱을 만들었는데, 이는 LangSmith와의 통합 설정에 좋은 시작점을 제공할 것입니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e저장소 복제: git clone \u003ca href=\"mailto:git@github.com\"\u003egit@github.com\u003c/a\u003e:kenzic/simple-langsmith-demo.git\u003c/li\u003e\n\u003cli\u003e의존성 설치: yarn\u003c/li\u003e\n\u003cli\u003eLangSmith 계정 등록\u003c/li\u003e\n\u003cli\u003eAPI 키 받기\u003c/li\u003e\n\u003cli\u003eOpenAI API 키 받기\u003c/li\u003e\n\u003cli\u003e.env.example을 .env로 이동하고 다음 값을 채워 넣으세요:\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-variable constant_\"\u003eLANGCHAIN_PROJECT\u003c/span\u003e=\u003cspan class=\"hljs-string\"\u003e\"langsmith-demo\"\u003c/span\u003e\n\u003cspan class=\"hljs-variable constant_\"\u003eLANGCHAIN_TRACING_V2\u003c/span\u003e=\u003cspan class=\"hljs-literal\"\u003etrue\u003c/span\u003e\n\u003cspan class=\"hljs-variable constant_\"\u003eLANGCHAIN_API_KEY\u003c/span\u003e=\u0026#x3C;your-api-key\u003e\n\n# \u003cspan class=\"hljs-title class_\"\u003eOpenAI\u003c/span\u003e \u003cspan class=\"hljs-variable constant_\"\u003eAPI\u003c/span\u003e를 사용하여 \u003cspan class=\"hljs-variable constant_\"\u003eLLM\u003c/span\u003e에 호출을 하지만, \u003cspan class=\"hljs-title class_\"\u003eLangSmith\u003c/span\u003e를 사용하는 데 필수적이지는 않습니다\n\u003cspan class=\"hljs-variable constant_\"\u003eOPENAI_API_KEY\u003c/span\u003e=\u0026#x3C;your-openai-api-key\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e시작하기 전에 코드를 이해하는 데 1 ~ 2분 정도 소요되도록 사전에 시간을 투자해보세요. 이 코드는 높은 수준에서 다음과 같은 작업을 수행합니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e입력값 \"프랑스의 수도는 무엇인가요?\"로 앱을 호출합니다.\u003c/li\u003e\n\u003cli\u003e대화 검색 체인 (RunnableSequence):\n\u003cul\u003e\n\u003cli\u003e문서 검색 체인을 호출하여 컨텍스트를 추가합니다. 이는 사용자의 질문에 답변하기 위해 데이터를 가져오는 사용자 지정 검색기를 사용합니다 (RunnableMap).\u003c/li\u003e\n\u003cli\u003e문서 검색 체인에서 가져온 컨텍스트를 사용하여 사용자 질문에 대한 LLM 답변을 Mr. Burns의 억양으로 작성하는 프롬프트를 생성합니다 (ChatPromptTemplate).\u003c/li\u003e\n\u003cli\u003eLLM을 호출합니다 (ChatOpenAI).\u003c/li\u003e\n\u003cli\u003e응답을 구문 분석하여 문자열로 반환합니다 (StrOutputParser).\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e실습하기\u003c/h1\u003e\n\u003cp\u003e이 기사에서는 아마도 가장 강력한 기능인 실행 추적 및 디버깅 기능에 초점을 맞출 것입니다.\u003c/p\u003e\n\u003cp\u003e이제 우리 앱을 테스트하고 디버깅할 준비가 되었어요!\u003c/p\u003e\n\u003cp\u003e다음을 실행하여 시작하십시오: yarn start\u003c/p\u003e\n\u003cp\u003e스크립트는 앱에 \"프랑스의 수도는 어디인가요?\"라고 묻습니다.\u003c/p\u003e\n\u003cp\u003e우리가 받은 결과가 상당히 예상치 못한 것 같아요. 프랑스의 수도가 스프링필드라고 생각하고 있는 것 같아요. 이상하죠.\u003c/p\u003e\n\u003cp\u003e우리 중 일부는 프랑스의 수도가 스프링필드가 아니라 파리임을 알고 있죠. 그래서 왜 이런 결과를 받는 걸까요? 게다가 앱이 답변을 제대로 주기까지 오래 걸리는 것 같아요. 이 부분을 빨리 처리할 수는 없을까요?\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://smith.langchain.com/\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://smith.langchain.com/\u003c/a\u003e 로 이동해서 \"langsmith-demo\" 프로젝트를 클릭해주세요. 프로젝트 내부에 들어가면 실행 기록을 볼 수 있어요. 최근 실행부터 시작해서 무슨 일이 일어나고 있는지 힌트가 있는지 확인해보겠어요.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e최상위 수준의 추적 결과 (RunnableSequence)를 살펴보면, 앱이 실행되는 데 3.33초가 걸리고 입력과 출력이 일치함을 볼 수 있지만 출력물은 명백히 잘못되었습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps_1.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e다음 수준인 (RunnableMap)로 이동하면, 앱의 일부분이 LLM이 답변을 안내하는 데 사용할 문맥이나 지식을 검색하는 역할을 살펴볼 수 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps_2.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e여기에서 무슨 일이 일어나고 있는지 빠르게 파악할 수 있어요. 저희 리트리버가 사실과 다른 정보를 제공하고 있네요. 이 데모에서는 \"프랑스의 수도는 파리입니다\"라는 내용으로 문서 내용을 바꿔서 수정할 수 있어요.\u003c/p\u003e\n\u003cp\u003e쉬웠죠! 하지만 아직 앱이 조금 느린 것 같아요. 왜 그럴까요? 계속 추적해보면 ChatPromptTemplate은 잘 보이고 실행 시간은 0.00초가 걸리므로, 그 부분은 아닌 것 같아요.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps_3.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e다음으로, ChatOpenAI 단계는 조금 느린데, 인터넷을 통해 요청을 보내고 있기 때문에 예상대로 그럴 수 있어요. 또한 OpenAI에 대한 호출이 총 139개의 토큰을 사용하여 총 $0.0001165를 소비했다는 점을 알려드릴게요. 앱이 더 복잡해지면 이 비용을 이해하기 위해 이 숫자에 주의해야 할 거예요.\u003c/p\u003e\n\u003cp\u003e마침내 StrOutputParser로 이동합니다. 실행 시간이 0.00초이고 출력을 올바르게 구문 분석했으므로 여기서 모든 것이 정상인 것 같습니다.\u003c/p\u003e\n\u003cp\u003e그래서 앱에서 병목 현상이 어디에 있는지 궁금하신가요? RunnableMap으로 돌아가 봅시다. 이 부분이 2.01초가 걸리는 것을 볼 수 있습니다. 한 개의 하드코딩된 문서를 반환하는 간단한 작업에 대해 이 시간은 높아 보입니다. 코드를 살펴보면 기능 slowLookupTask이 있음을 알 수 있습니다. 이 기능은 데모를 위해 인위적으로 만들어졌지만, 실제 시나리오에서는 검색기가 응용 프로그램의 지연 원인이 될 수 있으며, 종종 제어할 수 있는 부분 중 하나입니다.\u003c/p\u003e\n\u003cp\u003e마침내 스크립트를 다시 실행합시다. 어떻게나! 이제 쿼리에 올바른 답변을 받아, 2초를 절약했습니다!\u003c/p\u003e\n\u003ch2\u003e다음 단계\u003c/h2\u003e\n\u003cp\u003eLangSmith의 능력의 일부에 불과하지만, 이 짧은 글이 어떤 가능성을 밝혀주기를 바랍니다.\u003c/p\u003e\n\u003cp\u003eLangSmith의 디버깅 기능을 활용하여 더욱 탐험하면, 그 가능성을 최대로 발휘할 수 있습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e고급 테스트 및 평가 도구를 활용하여 응답 품질을 지속적으로 확인합니다.\u003c/li\u003e\n\u003cli\u003e비용 관리 통찰력을 활용하여 리소스 사용량 및 비용을 최적화합니다.\u003c/li\u003e\n\u003cli\u003e공동 작업 공간, 버전 관리 및 빠른 라이브러리를 활용하여 협업을 촉진합니다.\u003c/li\u003e\n\u003cli\u003e감정 분석 및 맥락 이해와 같은 고급 기능을 통합합니다.\u003c/li\u003e\n\u003cli\u003eLangSmith의 미래를 형성하기 위해 새로운 릴리스에 주목하고 LangSmith 커뮤니티에 참여하세요.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLLM 애플리케이션은 발전함에 따라 LangSmith가 개발을 간소화하고 성능을 보장하며 AI 혁신을 이끌어내는 도구를 제공합니다.\u003c/p\u003e\n\u003ch1\u003e마무리\u003c/h1\u003e\n\u003cp\u003eLangSmith 소개를 마치고 대형 언어 모델 애플리케이션 개발 마스터에 한 발짝 다가가셨습니다. 이 안내서에서는 고대형 언어 모델 프로젝트의 개발 및 유지 관리를 간소화하기 위해 LangSmith와 LangChain을 설정하고 사용하는 방법을 개요로 설명했습니다.\u003c/p\u003e\n\u003cp\u003e다룬 내용을 간단히 요약해 드리겠습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e프로젝트를 LangChain과 LangSmith와 통합 설정하는 방법.\u003c/li\u003e\n\u003cli\u003e애플리케이션을 이해하고 최적화하기 위해 실시간 디버깅 및 실행 추적을 활용하는 방법.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLangSmith로 수행할 수 있는 많은 작업이 있습니다. 이에 관한 내용은 나중에 다룰 것이지만, 오늘 LangSmith를 사용하고 있지 않다면 기술 스택에 추가할 가치가 있다는 것을 확신시켜 드릴 수 있기를 바랍니다.\u003c/p\u003e\n\u003cp\u003e연결 유지하고 여정을 공유하기 위해 아래 채널을 통해 언제든지 연락해 주세요:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e👨‍💼 LinkedIn: LLM 개발 및 기술 혁신에 대한 자세한 통찰력을 얻으려면 저와 함께하세요.\u003c/li\u003e\n\u003cli\u003e💻 GitHub: 제 프로젝트를 살펴보고 지속적인 작업에 기여하세요.\u003c/li\u003e\n\u003cli\u003e📚 Medium: LangSmith, LangChain 및 기타 AI 기술에 대한 보다 심층적인 토론을 위해 제 기사를 팔로우하세요.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e귀하의 피드백 및 협업은 귀중합니다. 행복한 개발하고 LangSmith로 만드는 놀라운 응용 프로그램을 기대하겠습니다!\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-14-GettingStartedLangSmithforJavaScriptLLMApps"},"buildId":"t9N7vwmpvBMQnO2PSctoH","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>