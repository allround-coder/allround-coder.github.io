<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>자체제작 스파이 군사 작전에서 YOLOv8 객체 검출 활용하기 | allround-coder</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://allround-coder.github.io///post/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="자체제작 스파이 군사 작전에서 YOLOv8 객체 검출 활용하기 | allround-coder" data-gatsby-head="true"/><meta property="og:title" content="자체제작 스파이 군사 작전에서 YOLOv8 객체 검출 활용하기 | allround-coder" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://allround-coder.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://allround-coder.github.io///post/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations" data-gatsby-head="true"/><meta name="twitter:title" content="자체제작 스파이 군사 작전에서 YOLOv8 객체 검출 활용하기 | allround-coder" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | allround-coder" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-15 04:57" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZFDEQ947R4"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
  
            gtag('config', 'G-ZFDEQ947R4');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/cd012fc8787133d0.css" as="style"/><link rel="stylesheet" href="/_next/static/css/cd012fc8787133d0.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/551-3069cf29fe274aab.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-a8eda6c93e0b14fe.js" defer=""></script><script src="/_next/static/7rKODeu6chWTLgXf6auoL/_buildManifest.js" defer=""></script><script src="/_next/static/7rKODeu6chWTLgXf6auoL/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Allround Coder</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">자체제작 스파이 군사 작전에서 YOLOv8 객체 검출 활용하기</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="자체제작 스파이 군사 작전에서 YOLOv8 객체 검출 활용하기" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/assets/profile.jpg"/></div><div class="posts_textarea__w_iKT"><span class="writer">Allround Coder</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 15, 2024</span><span class="posts_reading_time__f7YPP">8<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><p>적군 항공기를 계산하기 위해 YOLOv8 Object Detection과 정찰 드론에서 촬영한 항공 영상을 활용하여 군사 작전을 계획하기 위해서 지리공간 정보를 활용하세요.</p>
<p><img src="/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_0.png" alt="image"/></p>
<p>몇몇 분들께서는 이전에 작성한 제 글 중 하나인 &quot;마음대로 쓰는 이용사나 ‘머신’에 대해 읽으셨을 것입니다. 그 글에서는 &#x27;머신&#x27;이라고 하는 세계 감시 복합체의 다양한 구성 요소를 소개했습니다. 이 인프라는 전 세계에 배치된 다양한 수단을 포함하여 정부가 개인, 사회 행동 및 심지어 전 세계의 군사 시설을 모니터링할 수 있게 해주는 종합 감시를 가능하게합니다. 지리공간 정보(GEOINT)는 이러한 노력에서 중요한 역할을 합니다.</p>
<p>이 글에서는 적대적 군사 비행기 기지를 추적하는 도구로서의 지리공간 정보(GEOINT)에 대해 다뤄보겠습니다. 이러한 위치와 그들의 비행기를 효과적으로 모니터링함으로써 그들에 대한 전투 작전 계획을 철저히 준비할 수 있습니다.</p>
<h2>YOLOv8 Object Detection</h2>
<p>YOLOv8는 Ultralytics에서 개발한 유명한 실시간 객체 검출 시스템으로, 광범위한 응용 분야에서 널리 사용되고 있습니다. 군사 감시 및 정찰을 포함한 다양한 분야에서 사용되며, 이미지나 비디오 프레임 내의 객체를 실시간으로 감지하기 위해 설계되었습니다. 차량, 인원 또는 장비와 같은 객체들을 신속하고 정확하게 특정하여 상황 인식 및 대상 추적에 중요한 역할을 합니다.</p>
<p>딥러닝과 합성곱 신경망(CNN)과 함께 PyTorch를 활용함으로써, YOLOv8은 한 장면 내에서 여러 객체를 동시에 감지하는 능력을 보여주며 높은 속도와 정확도를 달성합니다. 이것이 바로 저희 미션에서 사용하기로 결정한 이유입니다.</p>
<h2>Prerequisites</h2>
<p>우선, 코드 실행을 위해 Google Compute Engine 백엔드에 Python 3을 사용하기로 결정했고, Google Colab을 사용할 것입니다. 따라서 우리는 먼저 의존성을 설치해야 합니다.</p>
<pre><code class="hljs language-js">!pip install ultralytics
</code></pre>
<p>이 설치 중에는 opencv-python, torch, pandas 및 이 패키지에서 사용해야 하는 기타 필수 의존성들이 설치됩니다.</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> cv2
<span class="hljs-keyword">import</span> urllib.<span class="hljs-property">request</span>

<span class="hljs-keyword">from</span> ultralytics <span class="hljs-keyword">import</span> <span class="hljs-variable constant_">YOLO</span>, checks, hub
<span class="hljs-keyword">from</span> google.<span class="hljs-property">colab</span>.<span class="hljs-property">patches</span> <span class="hljs-keyword">import</span> cv2_imshow
</code></pre>
<p>위 목록에서 볼 수 있듯이, 실험 중에 사용될 모든 필요한 라이브러리를 가져옵니다. 울트랠라틱스 모듈 외에도 Google Colab에서 올바르게 작동하는 cv2의 핫픽스인 cv2_imshow도 포함됩니다. urllib.request는 공개 저장소에서 이미지 예제를 다운로드하는 데 사용됩니다.</p>
<h2>YOLOv8 모델</h2>
<p>객체 감지를 위해 설계된 딥 러닝 모델 YOLOv8는 입력 이미지를 그리드로 분할하여 작동합니다. 그런 다음 각 그리드 셀 내의 객체에 대한 바운딩 박스와 클래스 확률을 예측합니다. 이 모델의 효율성은 신경망을 통한 전체 이미지의 단일 피드포워드 패스를 처리할 수 있는 능력에서 나옵니다.</p>
<p>일반적으로 모델을 만들려면 각 이미지에 대한 이미지와 레이블을 추가하여 데이터 세트를 올바르게 준비해야 합니다. 그러나 초기 단계 프로젝트에 필요한 대부분의 데이터 세트를 포함하는 데이터베이스가 이미 존재합니다. 오늘은 이를 실험에 활용할 것입니다. Roboflow 웹사이트로 이동해봅시다.</p>
<p><img src="/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_1.png" alt="DIY for a Spy: Utilizing YOLOv8 Object Detection in Military Operations - Image 1"/></p>
<p>위의 그림에서 보는 것처럼 프로젝트를 위한 적합한 DataSet를 찾아야 합니다. 이 예시에서는 모델 유형으로 yolov8를 선택했고, 프로젝트 유형으로 객체 감지를 선택하고, 검색어로 공중을 입력했습니다. 시스템은 다양한 데이터 세트 목록을 제공하며, 이미지 수가 1192개이고 클래스가 1개인 것을 고려하여 우리의 요구에 더 잘 맞는 하나를 선택했습니다.</p>
<p><img src="/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_2.png" alt="DIY for a Spy: Utilizing YOLOv8 Object Detection in Military Operations - Image 2"/></p>
<p>데이터 세트가 미션에 적합하다고 판단했다면, 적절한 내보내기 형식을 선택하여 다운로드해야 합니다. 우리의 시나리오에서는 이미 사용하기로 한 YOLOv8 형식을 선택했습니다.</p>
<p>아래의 표를 Markdown 형식으로 변경하세요.</p>
<p>위의 그림에서 볼 수 있듯이, 저는 프로젝트 이름 AER_AIR_04s, 항공 기지에서 항공기 감지하는 짧은 설명, 심지어 샘플 이미지까지 입력했습니다. 다른 프로젝트들 중에서도 이 프로젝트를 쉽게 식별할 수 있도록 도와주죠.</p>
<p>다음 단계로 진행할 때는 &#x27;데이터 세트&#x27;로 이동하셔서 다음과 같이 Detect 데이터 세트 유형, 데이터 세트 이름, 그리고 설명을 선택해야 합니다.</p>
<p><img src="/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_5.png" alt="image"/></p>
<p>&#x27;Create&#x27; 버튼을 클릭한 후 파일 업로드가 완료되면 데이터 세트 목록 중에 새로운 데이터 세트가 표시됩니다.</p>
<p><img src="/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_6.png" alt="image1"/></p>
<p>그냥 들어가서 이미지와 라벨을 확인하고 &#x27;모델 훈련&#x27; 버튼을 눌러 YOLOv8 모델 훈련을 계속하세요.</p>
<p><img src="/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_7.png" alt="image2"/></p>
<p>다음 창에서는 목록에서 프로젝트를 선택하고, 예제에서 나온 모델명 YOLOv8sAir을 입력하고, 속도 최적화된 YOLOv8 아키텍처 YOLOv8를 선택한 후 &#x27;계속&#x27; 버튼을 클릭해야 합니다.</p>
<p><img src="/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_8.png" alt="이미지"/></p>
<p>Ultralytics Hub에는 모델을 훈련하는 데 사용할 수 있는 다양한 옵션이 있지만, 우리는 다음을 활용할 것입니다 - &#x27;Google Colab&#x27;.</p>
<p><img src="/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_9.png" alt="이미지"/></p>
<p>위의 그림과 같이 모델 훈련을 위한 인증 키와 URL(https://hub.ultralytics.com/models/BN8V8tA1pOt6thjZKq6V)이 제공됩니다.</p>
<p>그냥 전체 코드를 복사해서 Google Colab에 붙여넣기하세요.</p>
<pre><code class="hljs language-js">hub.<span class="hljs-title function_">login</span>(<span class="hljs-string">&#x27;[YOUR_AUTH_KEY]&#x27;</span>)

model = <span class="hljs-title function_">YOLO</span>(<span class="hljs-string">&#x27;https://hub.ultralytics.com/models/BN8V8tA1pOt6thjZKq6V&#x27;</span>)
results = model.<span class="hljs-title function_">train</span>()
</code></pre>
<p>그런 다음 &#x27;런타임&#x27; 메뉴로 이동하여 &#x27;런타임 유형 변경&#x27;을 선택하고 &#x27;T4 GPU&#x27;를 선택하여 NVIDIA T4 GPU 가속기로 훈련을 가속화하세요.</p>
<p><img src="/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_10.png" alt="image"/></p>
<p>번역:
이미지 태그를 Markdown 형식으로 변경해주세요.</p>
<p>작업이 완료되었으면, Google Colab 스크립트에서 일반적으로 하는 것처럼 YOLOv8 모델 훈련 프로세스를 시작할 수 있습니다.</p>
<p><img src="/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_11.png" alt="image"/></p>
<p>해당 큰 데이터 세트에 대한 훈련 프로세스는 대략 3-4시간이 소요될 것입니다. 그러나 진행 상황은 Google Colab 목록에서만 확인하는 것이 적합하지 않을 수 있기 때문에 YOLOv8 모델 웹페이지의 특별 진행률 표시줄을 사용하여 모니터링할 수 있습니다.</p>
<img src="/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_12.png"/>
<p>이미 이전에 말씀드렸듯이, 시간이 걸릴 수 있습니다. 완료되면 &#x27;배포&#x27; 탭으로 이동하여 최종 모델 (*.pt) 파일을 다운로드하세요. 이 모델을 활용하여 라즈베리 파이를 비롯한 모든 기기에서 YOLOv8 패키지를 사용하여 물체를 감지할 수 있습니다. 공군기지나 전술에서 또는 요청된 작전을 위해 정찰 드론에서 공중 또는 지면의 물체를 인지할 수 있습니다.</p>
<h2>YOLOv8 사용법</h2>
<p>이 시점에서 이미 원하는 PyTorch (*.pt) 파일과 YOLOv8 모델의 가중치를 갖고 있는 상태입니다. 이 파일은 예시에서 21.4MB 크기입니다. 몇 줄의 코드만 추가하면 어떤 애플리케이션에서도 사용할 수 있게 됩니다.</p>
<p>편의를 위해 PT 파일과 실험 중에 사용할 이미지 및 비디오 소스를 지속적인 블록체인 저장소 Arweave에 업로드했습니다. 이 세 개의 파일을 다운로드하여 Google Compute Engine의 작업 디렉토리에 저장하려면 다음 코드를 작성하고 실행해야 합니다.</p>
<pre><code class="hljs language-js">yolov8sair_url = <span class="hljs-string">&#x27;https://6bq43uyscbhniu4kvl6hayy3zosqjnl5x2v2jm7zlfse6nnqrqsa.arweave.net/8GHN0xIQTtRTiqr8cGMby6UEtX2-q6Sz-VlkTzWwjCQ&#x27;</span>
urllib.<span class="hljs-property">request</span>.<span class="hljs-title function_">urlretrieve</span>(yolov8sair_url, <span class="hljs-string">&#x27;yolov8sair.pt&#x27;</span>)

source_file = <span class="hljs-string">&#x27;https://6x77tjsjpqn6ze2k7izx36xgtipzff6yi2jfnp2xxf6lvmtyy7oa.arweave.net/9f_5pkl8G-yTSvozffrmmh-Sl9hGkla_V7l8urJ4x9w&#x27;</span>
urllib.<span class="hljs-property">request</span>.<span class="hljs-title function_">urlretrieve</span>(source_file, <span class="hljs-string">&#x27;Aerial_AirBase.jpg&#x27;</span>)

source_video = <span class="hljs-string">&#x27;https://3tghzdwlhmyajv5eadufzesdo7epc5queknepym6hv2p737mgvxa.arweave.net/3Mx8jss7MATXpADoXJJDd8jxdhQimkfhnj10_-_sNW4&#x27;</span>
urllib.<span class="hljs-property">request</span>.<span class="hljs-title function_">urlretrieve</span>(source_video, <span class="hljs-string">&#x27;airport_video_source.mp4&#x27;</span>)
</code></pre>
<p>세 개의 파일이 있음을 알아차릴 수 있을 것입니다: yolov8sair.pt는 모델 가중치 파일, Aerial_AirBase.jpg는 정찰 드론에서 가져온 예제 이미지로 객체 감지에 사용될 것이며, airport_video_source.mp4는 추후 객체 인식을 위해 사용할 비디오 소스의 예제입니다.</p>
<pre><code class="hljs language-js">model = <span class="hljs-title function_">YOLO</span>(<span class="hljs-string">&#x27;yolov8sair.pt&#x27;</span>)

results = model.<span class="hljs-title function_">predict</span>(<span class="hljs-string">&#x27;Aerial_AirBase.jpg&#x27;</span>)
annotated_frame = results[<span class="hljs-number">0</span>].<span class="hljs-title function_">plot</span>()
<span class="hljs-title function_">cv2_imshow</span>(annotated_frame)
</code></pre>
<p>위에 표시된 이미지에서, 다양한 확률로 각각 약 84% 정도의 신뢰 수준을 나타내며, 세 대의 비행기가 감지되었습니다. 이와 같은 상황에서는 결과[] 배열의 객체 목록을 자동으로 계산하여 손쉽게 수를 세어볼 수 있습니다.</p>
<p>신뢰도와 확률 수준은 날씨 조건에 따라 다를 수 있습니다. 그러나 구리게 날씨 같은 명시적 단점에도 불구하고, 이 정찰 방법은 군사 작전을 계획하고 전투 활동을 지원하는 데 중요하다는 것이 증명되었습니다.</p>
<p>방금 보신 것처럼 몇 줄의 코드만으로 사용하기 쉬운 것이 이 기술의 장점입니다. 이를 활용하여 소형 비행 컨트롤러를 갖춘 자율 비행 드론을 포함한 다양한 애플리케이션에 적용할 수 있습니다.</p>
<p>이 객체 감지 메커니즘을 통합하여 만들 수 있는 스마트 애플리케이션을 상상해보세요. 비행 경로를 추적하고 목표물을 감지하여 파괴하는 자동 비행기와 같은 전투 드론을 생각해보세요. 상상력을 발휘해 보세요.</p>
<p>군사 솔루션에 활용할 수 있는 또 다른 좋은 예시인데요:</p>
<pre><code class="hljs language-js">model = <span class="hljs-title function_">YOLO</span>(<span class="hljs-string">&#x27;yolov8sair.pt&#x27;</span>)

# 비디오 스트림 내 객체 감지
cap = cv2.<span class="hljs-title class_">VideoCapture</span>(f<span class="hljs-string">&quot;airport_video_source.mp4&quot;</span>)
img_array = []

<span class="hljs-keyword">while</span> cap.<span class="hljs-title function_">isOpened</span>():
    success, frame = cap.<span class="hljs-title function_">read</span>()

    <span class="hljs-keyword">if</span> <span class="hljs-attr">success</span>:
        results = <span class="hljs-title function_">model</span>(frame)
        annotated_frame = results[<span class="hljs-number">0</span>].<span class="hljs-title function_">plot</span>()
        img_array.<span class="hljs-title function_">append</span>(annotated_frame)
    <span class="hljs-attr">else</span>:
        <span class="hljs-keyword">break</span>

cap.<span class="hljs-title function_">release</span>()

# 출력 비디오 파일로 저장
size = img_array[<span class="hljs-number">0</span>].<span class="hljs-property">shape</span>[<span class="hljs-number">1</span>], img_array[<span class="hljs-number">0</span>].<span class="hljs-property">shape</span>[<span class="hljs-number">0</span>]  # (<span class="hljs-number">384</span>, <span class="hljs-number">640</span>)
writer = cv2.<span class="hljs-title class_">VideoWriter</span>(f<span class="hljs-string">&quot;airport_video_output.mp4&quot;</span>, cv2.<span class="hljs-title class_">VideoWriter</span>_fourcc(*<span class="hljs-string">&quot;mp4v&quot;</span>), <span class="hljs-number">25</span>, size)
<span class="hljs-keyword">for</span> frame <span class="hljs-keyword">in</span> <span class="hljs-attr">img_array</span>:
    img_n = cv2.<span class="hljs-title function_">resize</span>(frame, size)
    writer.<span class="hljs-title function_">write</span>(img_n)
writer.<span class="hljs-title function_">release</span>()
</code></pre>
<p>이 문제는 비디오 스트림에서 Object Detection이 포함되어 있으며, 여기서는 airport_video_source.mp4 파일에서 추출됩니다. 그런 다음 비디오를 프레임으로 나누어 각 프레임에서 항공기를 감지하고 이를 airport_video_output.mp4 파일로 편집합니다.</p>
<p>Google Compute Engine의 작업 디렉토리에서이 파일을 다운로드 할 수 있습니다. 이미 이에 익숙한 것으로 알고 있습니다.</p>
<p><img src="/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_14.png" alt="이미지"/></p>
<p>위의 비디오 파일을 확인해보세요. 비행기 대부분이 감지되었지만 일부는 인식되지 않았습니다. 모델의 정확도를 향상시킬 방법에 대해 고려하고, 의견을 공유하려면 아래의 댓글란을 이용해 주세요.</p>
<h2>X-Files</h2>
<p>이 기사에서 시연 목적으로 사용한 YOLOv8 Object Detection의 모든 파일 목록은 아래에 나와 있습니다.</p>
<p>PyTorch 모델: YOLOv8sAir</p>
<p>드론 소스:</p>
<ul>
<li>정적 이미지: Aerial_AirBase.jpg</li>
<li>공항 동영상: AirBase_Video.mp4</li>
</ul>
<p>소스 코드: 구글 연구 Colab</p>
<p>당신의 상상력을 발휘하여 놀라운 솔루션을 만들어보세요!</p>
<h2>연락처</h2>
<p>이 기사에서 설명된 내용 또는 다른 아이디어에 대해 궁금한 점이 있으면 — 트위터에서 언제든지 저에게 질문해주세요.</p>
<p>트위터: https://twitter.com/dmytro_sazonov</p>
<p><img src="/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_15.png" alt="image"/></p></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"자체제작 스파이 군사 작전에서 YOLOv8 객체 검출 활용하기","description":"","date":"2024-05-15 04:57","slug":"2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations","content":"\n\n적군 항공기를 계산하기 위해 YOLOv8 Object Detection과 정찰 드론에서 촬영한 항공 영상을 활용하여 군사 작전을 계획하기 위해서 지리공간 정보를 활용하세요.\n\n![image](/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_0.png)\n\n몇몇 분들께서는 이전에 작성한 제 글 중 하나인 \"마음대로 쓰는 이용사나 ‘머신’에 대해 읽으셨을 것입니다. 그 글에서는 '머신'이라고 하는 세계 감시 복합체의 다양한 구성 요소를 소개했습니다. 이 인프라는 전 세계에 배치된 다양한 수단을 포함하여 정부가 개인, 사회 행동 및 심지어 전 세계의 군사 시설을 모니터링할 수 있게 해주는 종합 감시를 가능하게합니다. 지리공간 정보(GEOINT)는 이러한 노력에서 중요한 역할을 합니다.\n\n이 글에서는 적대적 군사 비행기 기지를 추적하는 도구로서의 지리공간 정보(GEOINT)에 대해 다뤄보겠습니다. 이러한 위치와 그들의 비행기를 효과적으로 모니터링함으로써 그들에 대한 전투 작전 계획을 철저히 준비할 수 있습니다.\n\n\n\n## YOLOv8 Object Detection\n\nYOLOv8는 Ultralytics에서 개발한 유명한 실시간 객체 검출 시스템으로, 광범위한 응용 분야에서 널리 사용되고 있습니다. 군사 감시 및 정찰을 포함한 다양한 분야에서 사용되며, 이미지나 비디오 프레임 내의 객체를 실시간으로 감지하기 위해 설계되었습니다. 차량, 인원 또는 장비와 같은 객체들을 신속하고 정확하게 특정하여 상황 인식 및 대상 추적에 중요한 역할을 합니다.\n\n딥러닝과 합성곱 신경망(CNN)과 함께 PyTorch를 활용함으로써, YOLOv8은 한 장면 내에서 여러 객체를 동시에 감지하는 능력을 보여주며 높은 속도와 정확도를 달성합니다. 이것이 바로 저희 미션에서 사용하기로 결정한 이유입니다.\n\n## Prerequisites\n\n\n\n우선, 코드 실행을 위해 Google Compute Engine 백엔드에 Python 3을 사용하기로 결정했고, Google Colab을 사용할 것입니다. 따라서 우리는 먼저 의존성을 설치해야 합니다.\n\n```js\n!pip install ultralytics\n```\n\n이 설치 중에는 opencv-python, torch, pandas 및 이 패키지에서 사용해야 하는 기타 필수 의존성들이 설치됩니다.\n\n```js\nimport cv2\nimport urllib.request\n\nfrom ultralytics import YOLO, checks, hub\nfrom google.colab.patches import cv2_imshow\n```\n\n\n\n위 목록에서 볼 수 있듯이, 실험 중에 사용될 모든 필요한 라이브러리를 가져옵니다. 울트랠라틱스 모듈 외에도 Google Colab에서 올바르게 작동하는 cv2의 핫픽스인 cv2_imshow도 포함됩니다. urllib.request는 공개 저장소에서 이미지 예제를 다운로드하는 데 사용됩니다.\n\n## YOLOv8 모델\n\n객체 감지를 위해 설계된 딥 러닝 모델 YOLOv8는 입력 이미지를 그리드로 분할하여 작동합니다. 그런 다음 각 그리드 셀 내의 객체에 대한 바운딩 박스와 클래스 확률을 예측합니다. 이 모델의 효율성은 신경망을 통한 전체 이미지의 단일 피드포워드 패스를 처리할 수 있는 능력에서 나옵니다.\n\n일반적으로 모델을 만들려면 각 이미지에 대한 이미지와 레이블을 추가하여 데이터 세트를 올바르게 준비해야 합니다. 그러나 초기 단계 프로젝트에 필요한 대부분의 데이터 세트를 포함하는 데이터베이스가 이미 존재합니다. 오늘은 이를 실험에 활용할 것입니다. Roboflow 웹사이트로 이동해봅시다.\n\n\n\n![DIY for a Spy: Utilizing YOLOv8 Object Detection in Military Operations - Image 1](/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_1.png)\n\n위의 그림에서 보는 것처럼 프로젝트를 위한 적합한 DataSet를 찾아야 합니다. 이 예시에서는 모델 유형으로 yolov8를 선택했고, 프로젝트 유형으로 객체 감지를 선택하고, 검색어로 공중을 입력했습니다. 시스템은 다양한 데이터 세트 목록을 제공하며, 이미지 수가 1192개이고 클래스가 1개인 것을 고려하여 우리의 요구에 더 잘 맞는 하나를 선택했습니다.\n\n![DIY for a Spy: Utilizing YOLOv8 Object Detection in Military Operations - Image 2](/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_2.png)\n\n데이터 세트가 미션에 적합하다고 판단했다면, 적절한 내보내기 형식을 선택하여 다운로드해야 합니다. 우리의 시나리오에서는 이미 사용하기로 한 YOLOv8 형식을 선택했습니다.\n\n\n\n\n아래의 표를 Markdown 형식으로 변경하세요.\n\n\n\n위의 그림에서 볼 수 있듯이, 저는 프로젝트 이름 AER_AIR_04s, 항공 기지에서 항공기 감지하는 짧은 설명, 심지어 샘플 이미지까지 입력했습니다. 다른 프로젝트들 중에서도 이 프로젝트를 쉽게 식별할 수 있도록 도와주죠. \n\n다음 단계로 진행할 때는 '데이터 세트'로 이동하셔서 다음과 같이 Detect 데이터 세트 유형, 데이터 세트 이름, 그리고 설명을 선택해야 합니다.\n\n![image](/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_5.png)\n\n\n\n'Create' 버튼을 클릭한 후 파일 업로드가 완료되면 데이터 세트 목록 중에 새로운 데이터 세트가 표시됩니다.\n\n![image1](/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_6.png)\n\n그냥 들어가서 이미지와 라벨을 확인하고 '모델 훈련' 버튼을 눌러 YOLOv8 모델 훈련을 계속하세요.\n\n![image2](/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_7.png)\n\n\n\n다음 창에서는 목록에서 프로젝트를 선택하고, 예제에서 나온 모델명 YOLOv8sAir을 입력하고, 속도 최적화된 YOLOv8 아키텍처 YOLOv8를 선택한 후 '계속' 버튼을 클릭해야 합니다.\n\n![이미지](/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_8.png)\n\nUltralytics Hub에는 모델을 훈련하는 데 사용할 수 있는 다양한 옵션이 있지만, 우리는 다음을 활용할 것입니다 - 'Google Colab'.\n\n![이미지](/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_9.png)\n\n\n\n위의 그림과 같이 모델 훈련을 위한 인증 키와 URL(https://hub.ultralytics.com/models/BN8V8tA1pOt6thjZKq6V)이 제공됩니다.\n\n그냥 전체 코드를 복사해서 Google Colab에 붙여넣기하세요.\n\n```js\nhub.login('[YOUR_AUTH_KEY]')\n\nmodel = YOLO('https://hub.ultralytics.com/models/BN8V8tA1pOt6thjZKq6V')\nresults = model.train()\n```\n\n그런 다음 '런타임' 메뉴로 이동하여 '런타임 유형 변경'을 선택하고 'T4 GPU'를 선택하여 NVIDIA T4 GPU 가속기로 훈련을 가속화하세요.\n\n\n\n\n![image](/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_10.png)\n\n\n번역:\n이미지 태그를 Markdown 형식으로 변경해주세요.\n\n작업이 완료되었으면, Google Colab 스크립트에서 일반적으로 하는 것처럼 YOLOv8 모델 훈련 프로세스를 시작할 수 있습니다.\n\n\n![image](/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_11.png)\n\n\n해당 큰 데이터 세트에 대한 훈련 프로세스는 대략 3-4시간이 소요될 것입니다. 그러나 진행 상황은 Google Colab 목록에서만 확인하는 것이 적합하지 않을 수 있기 때문에 YOLOv8 모델 웹페이지의 특별 진행률 표시줄을 사용하여 모니터링할 수 있습니다.\n\n\n\n\u003cimg src=\"/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_12.png\" /\u003e\n\n이미 이전에 말씀드렸듯이, 시간이 걸릴 수 있습니다. 완료되면 '배포' 탭으로 이동하여 최종 모델 (*.pt) 파일을 다운로드하세요. 이 모델을 활용하여 라즈베리 파이를 비롯한 모든 기기에서 YOLOv8 패키지를 사용하여 물체를 감지할 수 있습니다. 공군기지나 전술에서 또는 요청된 작전을 위해 정찰 드론에서 공중 또는 지면의 물체를 인지할 수 있습니다.\n\n## YOLOv8 사용법\n\n이 시점에서 이미 원하는 PyTorch (*.pt) 파일과 YOLOv8 모델의 가중치를 갖고 있는 상태입니다. 이 파일은 예시에서 21.4MB 크기입니다. 몇 줄의 코드만 추가하면 어떤 애플리케이션에서도 사용할 수 있게 됩니다.\n\n\n\n편의를 위해 PT 파일과 실험 중에 사용할 이미지 및 비디오 소스를 지속적인 블록체인 저장소 Arweave에 업로드했습니다. 이 세 개의 파일을 다운로드하여 Google Compute Engine의 작업 디렉토리에 저장하려면 다음 코드를 작성하고 실행해야 합니다.\n\n```js\nyolov8sair_url = 'https://6bq43uyscbhniu4kvl6hayy3zosqjnl5x2v2jm7zlfse6nnqrqsa.arweave.net/8GHN0xIQTtRTiqr8cGMby6UEtX2-q6Sz-VlkTzWwjCQ'\nurllib.request.urlretrieve(yolov8sair_url, 'yolov8sair.pt')\n\nsource_file = 'https://6x77tjsjpqn6ze2k7izx36xgtipzff6yi2jfnp2xxf6lvmtyy7oa.arweave.net/9f_5pkl8G-yTSvozffrmmh-Sl9hGkla_V7l8urJ4x9w'\nurllib.request.urlretrieve(source_file, 'Aerial_AirBase.jpg')\n\nsource_video = 'https://3tghzdwlhmyajv5eadufzesdo7epc5queknepym6hv2p737mgvxa.arweave.net/3Mx8jss7MATXpADoXJJDd8jxdhQimkfhnj10_-_sNW4'\nurllib.request.urlretrieve(source_video, 'airport_video_source.mp4')\n```\n\n세 개의 파일이 있음을 알아차릴 수 있을 것입니다: yolov8sair.pt는 모델 가중치 파일, Aerial_AirBase.jpg는 정찰 드론에서 가져온 예제 이미지로 객체 감지에 사용될 것이며, airport_video_source.mp4는 추후 객체 인식을 위해 사용할 비디오 소스의 예제입니다.\n\n```js\nmodel = YOLO('yolov8sair.pt')\n\nresults = model.predict('Aerial_AirBase.jpg')\nannotated_frame = results[0].plot()\ncv2_imshow(annotated_frame)\n```\n\n\n\n위에 표시된 이미지에서, 다양한 확률로 각각 약 84% 정도의 신뢰 수준을 나타내며, 세 대의 비행기가 감지되었습니다. 이와 같은 상황에서는 결과[] 배열의 객체 목록을 자동으로 계산하여 손쉽게 수를 세어볼 수 있습니다.\n\n신뢰도와 확률 수준은 날씨 조건에 따라 다를 수 있습니다. 그러나 구리게 날씨 같은 명시적 단점에도 불구하고, 이 정찰 방법은 군사 작전을 계획하고 전투 활동을 지원하는 데 중요하다는 것이 증명되었습니다.\n\n\n\n방금 보신 것처럼 몇 줄의 코드만으로 사용하기 쉬운 것이 이 기술의 장점입니다. 이를 활용하여 소형 비행 컨트롤러를 갖춘 자율 비행 드론을 포함한 다양한 애플리케이션에 적용할 수 있습니다.\n\n이 객체 감지 메커니즘을 통합하여 만들 수 있는 스마트 애플리케이션을 상상해보세요. 비행 경로를 추적하고 목표물을 감지하여 파괴하는 자동 비행기와 같은 전투 드론을 생각해보세요. 상상력을 발휘해 보세요.\n\n군사 솔루션에 활용할 수 있는 또 다른 좋은 예시인데요:\n\n```js\nmodel = YOLO('yolov8sair.pt')\n\n# 비디오 스트림 내 객체 감지\ncap = cv2.VideoCapture(f\"airport_video_source.mp4\")\nimg_array = []\n\nwhile cap.isOpened():\n    success, frame = cap.read()\n\n    if success:\n        results = model(frame)\n        annotated_frame = results[0].plot()\n        img_array.append(annotated_frame)\n    else:\n        break\n\ncap.release()\n\n# 출력 비디오 파일로 저장\nsize = img_array[0].shape[1], img_array[0].shape[0]  # (384, 640)\nwriter = cv2.VideoWriter(f\"airport_video_output.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), 25, size)\nfor frame in img_array:\n    img_n = cv2.resize(frame, size)\n    writer.write(img_n)\nwriter.release()\n```\n\n\n\n이 문제는 비디오 스트림에서 Object Detection이 포함되어 있으며, 여기서는 airport_video_source.mp4 파일에서 추출됩니다. 그런 다음 비디오를 프레임으로 나누어 각 프레임에서 항공기를 감지하고 이를 airport_video_output.mp4 파일로 편집합니다.\n\nGoogle Compute Engine의 작업 디렉토리에서이 파일을 다운로드 할 수 있습니다. 이미 이에 익숙한 것으로 알고 있습니다.\n\n![이미지](/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_14.png)\n\n위의 비디오 파일을 확인해보세요. 비행기 대부분이 감지되었지만 일부는 인식되지 않았습니다. 모델의 정확도를 향상시킬 방법에 대해 고려하고, 의견을 공유하려면 아래의 댓글란을 이용해 주세요.\n\n\n\n## X-Files\n\n이 기사에서 시연 목적으로 사용한 YOLOv8 Object Detection의 모든 파일 목록은 아래에 나와 있습니다.\n\nPyTorch 모델: YOLOv8sAir\n\n드론 소스:\n\n\n\n- 정적 이미지: Aerial_AirBase.jpg\n- 공항 동영상: AirBase_Video.mp4\n\n소스 코드: 구글 연구 Colab\n\n당신의 상상력을 발휘하여 놀라운 솔루션을 만들어보세요!\n\n## 연락처\n\n\n\n이 기사에서 설명된 내용 또는 다른 아이디어에 대해 궁금한 점이 있으면 — 트위터에서 언제든지 저에게 질문해주세요.\n\n트위터: https://twitter.com/dmytro_sazonov\n\n![image](/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_15.png)","ogImage":{"url":"/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_0.png"},"coverImage":"/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_0.png","tag":["Tech"],"readingTime":8},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    img: \"img\",\n    h2: \"h2\",\n    pre: \"pre\",\n    code: \"code\",\n    span: \"span\",\n    ul: \"ul\",\n    li: \"li\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: \"적군 항공기를 계산하기 위해 YOLOv8 Object Detection과 정찰 드론에서 촬영한 항공 영상을 활용하여 군사 작전을 계획하기 위해서 지리공간 정보를 활용하세요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_0.png\",\n        alt: \"image\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"몇몇 분들께서는 이전에 작성한 제 글 중 하나인 \\\"마음대로 쓰는 이용사나 ‘머신’에 대해 읽으셨을 것입니다. 그 글에서는 '머신'이라고 하는 세계 감시 복합체의 다양한 구성 요소를 소개했습니다. 이 인프라는 전 세계에 배치된 다양한 수단을 포함하여 정부가 개인, 사회 행동 및 심지어 전 세계의 군사 시설을 모니터링할 수 있게 해주는 종합 감시를 가능하게합니다. 지리공간 정보(GEOINT)는 이러한 노력에서 중요한 역할을 합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 글에서는 적대적 군사 비행기 기지를 추적하는 도구로서의 지리공간 정보(GEOINT)에 대해 다뤄보겠습니다. 이러한 위치와 그들의 비행기를 효과적으로 모니터링함으로써 그들에 대한 전투 작전 계획을 철저히 준비할 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"YOLOv8 Object Detection\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"YOLOv8는 Ultralytics에서 개발한 유명한 실시간 객체 검출 시스템으로, 광범위한 응용 분야에서 널리 사용되고 있습니다. 군사 감시 및 정찰을 포함한 다양한 분야에서 사용되며, 이미지나 비디오 프레임 내의 객체를 실시간으로 감지하기 위해 설계되었습니다. 차량, 인원 또는 장비와 같은 객체들을 신속하고 정확하게 특정하여 상황 인식 및 대상 추적에 중요한 역할을 합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"딥러닝과 합성곱 신경망(CNN)과 함께 PyTorch를 활용함으로써, YOLOv8은 한 장면 내에서 여러 객체를 동시에 감지하는 능력을 보여주며 높은 속도와 정확도를 달성합니다. 이것이 바로 저희 미션에서 사용하기로 결정한 이유입니다.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"Prerequisites\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"우선, 코드 실행을 위해 Google Compute Engine 백엔드에 Python 3을 사용하기로 결정했고, Google Colab을 사용할 것입니다. 따라서 우리는 먼저 의존성을 설치해야 합니다.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsx(_components.code, {\n        className: \"hljs language-js\",\n        children: \"!pip install ultralytics\\n\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 설치 중에는 opencv-python, torch, pandas 및 이 패키지에서 사용해야 하는 기타 필수 의존성들이 설치됩니다.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" cv2\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" urllib.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"request\"\n        }), \"\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"from\"\n        }), \" ultralytics \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-variable constant_\",\n          children: \"YOLO\"\n        }), \", checks, hub\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"from\"\n        }), \" google.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"colab\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"patches\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"import\"\n        }), \" cv2_imshow\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"위 목록에서 볼 수 있듯이, 실험 중에 사용될 모든 필요한 라이브러리를 가져옵니다. 울트랠라틱스 모듈 외에도 Google Colab에서 올바르게 작동하는 cv2의 핫픽스인 cv2_imshow도 포함됩니다. urllib.request는 공개 저장소에서 이미지 예제를 다운로드하는 데 사용됩니다.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"YOLOv8 모델\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"객체 감지를 위해 설계된 딥 러닝 모델 YOLOv8는 입력 이미지를 그리드로 분할하여 작동합니다. 그런 다음 각 그리드 셀 내의 객체에 대한 바운딩 박스와 클래스 확률을 예측합니다. 이 모델의 효율성은 신경망을 통한 전체 이미지의 단일 피드포워드 패스를 처리할 수 있는 능력에서 나옵니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"일반적으로 모델을 만들려면 각 이미지에 대한 이미지와 레이블을 추가하여 데이터 세트를 올바르게 준비해야 합니다. 그러나 초기 단계 프로젝트에 필요한 대부분의 데이터 세트를 포함하는 데이터베이스가 이미 존재합니다. 오늘은 이를 실험에 활용할 것입니다. Roboflow 웹사이트로 이동해봅시다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_1.png\",\n        alt: \"DIY for a Spy: Utilizing YOLOv8 Object Detection in Military Operations - Image 1\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"위의 그림에서 보는 것처럼 프로젝트를 위한 적합한 DataSet를 찾아야 합니다. 이 예시에서는 모델 유형으로 yolov8를 선택했고, 프로젝트 유형으로 객체 감지를 선택하고, 검색어로 공중을 입력했습니다. 시스템은 다양한 데이터 세트 목록을 제공하며, 이미지 수가 1192개이고 클래스가 1개인 것을 고려하여 우리의 요구에 더 잘 맞는 하나를 선택했습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_2.png\",\n        alt: \"DIY for a Spy: Utilizing YOLOv8 Object Detection in Military Operations - Image 2\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"데이터 세트가 미션에 적합하다고 판단했다면, 적절한 내보내기 형식을 선택하여 다운로드해야 합니다. 우리의 시나리오에서는 이미 사용하기로 한 YOLOv8 형식을 선택했습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"아래의 표를 Markdown 형식으로 변경하세요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"위의 그림에서 볼 수 있듯이, 저는 프로젝트 이름 AER_AIR_04s, 항공 기지에서 항공기 감지하는 짧은 설명, 심지어 샘플 이미지까지 입력했습니다. 다른 프로젝트들 중에서도 이 프로젝트를 쉽게 식별할 수 있도록 도와주죠.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"다음 단계로 진행할 때는 '데이터 세트'로 이동하셔서 다음과 같이 Detect 데이터 세트 유형, 데이터 세트 이름, 그리고 설명을 선택해야 합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_5.png\",\n        alt: \"image\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"'Create' 버튼을 클릭한 후 파일 업로드가 완료되면 데이터 세트 목록 중에 새로운 데이터 세트가 표시됩니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_6.png\",\n        alt: \"image1\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"그냥 들어가서 이미지와 라벨을 확인하고 '모델 훈련' 버튼을 눌러 YOLOv8 모델 훈련을 계속하세요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_7.png\",\n        alt: \"image2\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"다음 창에서는 목록에서 프로젝트를 선택하고, 예제에서 나온 모델명 YOLOv8sAir을 입력하고, 속도 최적화된 YOLOv8 아키텍처 YOLOv8를 선택한 후 '계속' 버튼을 클릭해야 합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_8.png\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Ultralytics Hub에는 모델을 훈련하는 데 사용할 수 있는 다양한 옵션이 있지만, 우리는 다음을 활용할 것입니다 - 'Google Colab'.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_9.png\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"위의 그림과 같이 모델 훈련을 위한 인증 키와 URL(https://hub.ultralytics.com/models/BN8V8tA1pOt6thjZKq6V)이 제공됩니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"그냥 전체 코드를 복사해서 Google Colab에 붙여넣기하세요.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [\"hub.\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"login\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'[YOUR_AUTH_KEY]'\"\n        }), \")\\n\\nmodel = \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"YOLO\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'https://hub.ultralytics.com/models/BN8V8tA1pOt6thjZKq6V'\"\n        }), \")\\nresults = model.\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"train\"\n        }), \"()\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"그런 다음 '런타임' 메뉴로 이동하여 '런타임 유형 변경'을 선택하고 'T4 GPU'를 선택하여 NVIDIA T4 GPU 가속기로 훈련을 가속화하세요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_10.png\",\n        alt: \"image\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"번역:\\n이미지 태그를 Markdown 형식으로 변경해주세요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"작업이 완료되었으면, Google Colab 스크립트에서 일반적으로 하는 것처럼 YOLOv8 모델 훈련 프로세스를 시작할 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_11.png\",\n        alt: \"image\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"해당 큰 데이터 세트에 대한 훈련 프로세스는 대략 3-4시간이 소요될 것입니다. 그러나 진행 상황은 Google Colab 목록에서만 확인하는 것이 적합하지 않을 수 있기 때문에 YOLOv8 모델 웹페이지의 특별 진행률 표시줄을 사용하여 모니터링할 수 있습니다.\"\n    }), \"\\n\", _jsx(\"img\", {\n      src: \"/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_12.png\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이미 이전에 말씀드렸듯이, 시간이 걸릴 수 있습니다. 완료되면 '배포' 탭으로 이동하여 최종 모델 (*.pt) 파일을 다운로드하세요. 이 모델을 활용하여 라즈베리 파이를 비롯한 모든 기기에서 YOLOv8 패키지를 사용하여 물체를 감지할 수 있습니다. 공군기지나 전술에서 또는 요청된 작전을 위해 정찰 드론에서 공중 또는 지면의 물체를 인지할 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"YOLOv8 사용법\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 시점에서 이미 원하는 PyTorch (*.pt) 파일과 YOLOv8 모델의 가중치를 갖고 있는 상태입니다. 이 파일은 예시에서 21.4MB 크기입니다. 몇 줄의 코드만 추가하면 어떤 애플리케이션에서도 사용할 수 있게 됩니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"편의를 위해 PT 파일과 실험 중에 사용할 이미지 및 비디오 소스를 지속적인 블록체인 저장소 Arweave에 업로드했습니다. 이 세 개의 파일을 다운로드하여 Google Compute Engine의 작업 디렉토리에 저장하려면 다음 코드를 작성하고 실행해야 합니다.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [\"yolov8sair_url = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'https://6bq43uyscbhniu4kvl6hayy3zosqjnl5x2v2jm7zlfse6nnqrqsa.arweave.net/8GHN0xIQTtRTiqr8cGMby6UEtX2-q6Sz-VlkTzWwjCQ'\"\n        }), \"\\nurllib.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"request\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"urlretrieve\"\n        }), \"(yolov8sair_url, \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'yolov8sair.pt'\"\n        }), \")\\n\\nsource_file = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'https://6x77tjsjpqn6ze2k7izx36xgtipzff6yi2jfnp2xxf6lvmtyy7oa.arweave.net/9f_5pkl8G-yTSvozffrmmh-Sl9hGkla_V7l8urJ4x9w'\"\n        }), \"\\nurllib.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"request\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"urlretrieve\"\n        }), \"(source_file, \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'Aerial_AirBase.jpg'\"\n        }), \")\\n\\nsource_video = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'https://3tghzdwlhmyajv5eadufzesdo7epc5queknepym6hv2p737mgvxa.arweave.net/3Mx8jss7MATXpADoXJJDd8jxdhQimkfhnj10_-_sNW4'\"\n        }), \"\\nurllib.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"request\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"urlretrieve\"\n        }), \"(source_video, \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'airport_video_source.mp4'\"\n        }), \")\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"세 개의 파일이 있음을 알아차릴 수 있을 것입니다: yolov8sair.pt는 모델 가중치 파일, Aerial_AirBase.jpg는 정찰 드론에서 가져온 예제 이미지로 객체 감지에 사용될 것이며, airport_video_source.mp4는 추후 객체 인식을 위해 사용할 비디오 소스의 예제입니다.\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [\"model = \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"YOLO\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'yolov8sair.pt'\"\n        }), \")\\n\\nresults = model.\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"predict\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'Aerial_AirBase.jpg'\"\n        }), \")\\nannotated_frame = results[\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \"].\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"plot\"\n        }), \"()\\n\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"cv2_imshow\"\n        }), \"(annotated_frame)\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"위에 표시된 이미지에서, 다양한 확률로 각각 약 84% 정도의 신뢰 수준을 나타내며, 세 대의 비행기가 감지되었습니다. 이와 같은 상황에서는 결과[] 배열의 객체 목록을 자동으로 계산하여 손쉽게 수를 세어볼 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"신뢰도와 확률 수준은 날씨 조건에 따라 다를 수 있습니다. 그러나 구리게 날씨 같은 명시적 단점에도 불구하고, 이 정찰 방법은 군사 작전을 계획하고 전투 활동을 지원하는 데 중요하다는 것이 증명되었습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"방금 보신 것처럼 몇 줄의 코드만으로 사용하기 쉬운 것이 이 기술의 장점입니다. 이를 활용하여 소형 비행 컨트롤러를 갖춘 자율 비행 드론을 포함한 다양한 애플리케이션에 적용할 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 객체 감지 메커니즘을 통합하여 만들 수 있는 스마트 애플리케이션을 상상해보세요. 비행 경로를 추적하고 목표물을 감지하여 파괴하는 자동 비행기와 같은 전투 드론을 생각해보세요. 상상력을 발휘해 보세요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"군사 솔루션에 활용할 수 있는 또 다른 좋은 예시인데요:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [\"model = \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"YOLO\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'yolov8sair.pt'\"\n        }), \")\\n\\n# 비디오 스트림 내 객체 감지\\ncap = cv2.\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"VideoCapture\"\n        }), \"(f\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"airport_video_source.mp4\\\"\"\n        }), \")\\nimg_array = []\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"while\"\n        }), \" cap.\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"isOpened\"\n        }), \"():\\n    success, frame = cap.\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"read\"\n        }), \"()\\n\\n    \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"if\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"success\"\n        }), \":\\n        results = \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"model\"\n        }), \"(frame)\\n        annotated_frame = results[\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \"].\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"plot\"\n        }), \"()\\n        img_array.\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"append\"\n        }), \"(annotated_frame)\\n    \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"else\"\n        }), \":\\n        \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"break\"\n        }), \"\\n\\ncap.\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"release\"\n        }), \"()\\n\\n# 출력 비디오 파일로 저장\\nsize = img_array[\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \"].\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"shape\"\n        }), \"[\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"1\"\n        }), \"], img_array[\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \"].\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"shape\"\n        }), \"[\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \"]  # (\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"384\"\n        }), \", \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"640\"\n        }), \")\\nwriter = cv2.\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"VideoWriter\"\n        }), \"(f\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"airport_video_output.mp4\\\"\"\n        }), \", cv2.\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"VideoWriter\"\n        }), \"_fourcc(*\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"mp4v\\\"\"\n        }), \"), \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"25\"\n        }), \", size)\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"for\"\n        }), \" frame \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"in\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"img_array\"\n        }), \":\\n    img_n = cv2.\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"resize\"\n        }), \"(frame, size)\\n    writer.\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"write\"\n        }), \"(img_n)\\nwriter.\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"release\"\n        }), \"()\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 문제는 비디오 스트림에서 Object Detection이 포함되어 있으며, 여기서는 airport_video_source.mp4 파일에서 추출됩니다. 그런 다음 비디오를 프레임으로 나누어 각 프레임에서 항공기를 감지하고 이를 airport_video_output.mp4 파일로 편집합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Google Compute Engine의 작업 디렉토리에서이 파일을 다운로드 할 수 있습니다. 이미 이에 익숙한 것으로 알고 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_14.png\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"위의 비디오 파일을 확인해보세요. 비행기 대부분이 감지되었지만 일부는 인식되지 않았습니다. 모델의 정확도를 향상시킬 방법에 대해 고려하고, 의견을 공유하려면 아래의 댓글란을 이용해 주세요.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"X-Files\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 기사에서 시연 목적으로 사용한 YOLOv8 Object Detection의 모든 파일 목록은 아래에 나와 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"PyTorch 모델: YOLOv8sAir\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"드론 소스:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"정적 이미지: Aerial_AirBase.jpg\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"공항 동영상: AirBase_Video.mp4\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"소스 코드: 구글 연구 Colab\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"당신의 상상력을 발휘하여 놀라운 솔루션을 만들어보세요!\"\n    }), \"\\n\", _jsx(_components.h2, {\n      children: \"연락처\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 기사에서 설명된 내용 또는 다른 아이디어에 대해 궁금한 점이 있으면 — 트위터에서 언제든지 저에게 질문해주세요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"트위터: https://twitter.com/dmytro_sazonov\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations_15.png\",\n        alt: \"image\"\n      })\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-15-DIYforaSpyUtilizingYOLOv8ObjectDetectioninMilitaryOperations"},"buildId":"7rKODeu6chWTLgXf6auoL","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>