<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>GPT4 Omni - 그저 음성 어시스턴트 이상의 무언가 | allround-coder</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://allround-coder.github.io///post/2024-05-15-GPT4OmniSomuchmorethanjustavoiceassistant" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="GPT4 Omni - 그저 음성 어시스턴트 이상의 무언가 | allround-coder" data-gatsby-head="true"/><meta property="og:title" content="GPT4 Omni - 그저 음성 어시스턴트 이상의 무언가 | allround-coder" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-15-GPT4OmniSomuchmorethanjustavoiceassistant_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://allround-coder.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://allround-coder.github.io///post/2024-05-15-GPT4OmniSomuchmorethanjustavoiceassistant" data-gatsby-head="true"/><meta name="twitter:title" content="GPT4 Omni - 그저 음성 어시스턴트 이상의 무언가 | allround-coder" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-15-GPT4OmniSomuchmorethanjustavoiceassistant_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | allround-coder" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-15 11:33" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZFDEQ947R4"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
  
            gtag('config', 'G-ZFDEQ947R4');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/cd012fc8787133d0.css" as="style"/><link rel="stylesheet" href="/_next/static/css/cd012fc8787133d0.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/551-3069cf29fe274aab.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-a8eda6c93e0b14fe.js" defer=""></script><script src="/_next/static/7rKODeu6chWTLgXf6auoL/_buildManifest.js" defer=""></script><script src="/_next/static/7rKODeu6chWTLgXf6auoL/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Allround Coder</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">GPT4 Omni - 그저 음성 어시스턴트 이상의 무언가</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="GPT4 Omni - 그저 음성 어시스턴트 이상의 무언가" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/assets/profile.jpg"/></div><div class="posts_textarea__w_iKT"><span class="writer">Allround Coder</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 15, 2024</span><span class="posts_reading_time__f7YPP">2<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-15-GPT4OmniSomuchmorethanjustavoiceassistant&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><p><img src="/assets/img/2024-05-15-GPT4OmniSomuchmorethanjustavoiceassistant_0.png" alt="image"/></p>
<p>오늘은 OpenAI의 봄 발표일이었고, 정말 놀라운 소식이었어요. 여러분도 동의하실 거라고 생각해요. 이번 밤 대부분을 새 음성 어시스턴트와 노는 데에 보냈거든요. (영화 HER에 언급된 것과 매우 정확한 시나리오입니다).</p>
<p>그런데 혁명적이고 놀라운 음성 기능이 있을 뿐만 아니라, GPT4o 모델은 그 이상을 제공해요.</p>
<p>솔직히 말하자면, 음성 기능에 정말 매료되어서 현실감을 느꼈죠. 그래서 한참을 걸려서 모델의 기술적 공지사항을 정말 자세히 읽어 보았는데, 방금 그것을 듣고 다시 놀라버렸어요.</p>
<p>GPT4o를 생각했을 때는 기본적으로 GPT-4 Turbo의 최적화된 버전일 뿐이라고 생각했어요. 이번에는 더 나은 추론 능력, 더 작은 지연 시간 및 음성 대화용으로 훈련되었어요. 그들은 이미 보유한 기술을 Whisper와 TTS와 함께 최적화된 새 모델과 통화를 결합하여 ChatGPT에 매우 효과적으로 통합했다고 생각했었어요.</p>
<p>그러나 모델의 기술 보고서를 읽은 후에, 이렇게 발견했어요:</p>
<p>텍스트, 오디오 및 비전 멀티모달리티가 모두 포함된 단일 새 모델!!</p>
<p>텍스트/오디오/이미지를 입력으로 받아 텍스트/오디오/이미지로 출력하는 단일 모델이 있어요.</p>
<p>저는 지난 번에 GenAI의 미래는 모든 모달리티를 고루 보유한 다중 모델링에 있을 것이라고 언급했다는 것을 알고 있어요. 그리고 우리는 그런 의도로 이니셔티브를 볼 수 있어요.</p>
<p>하지만 2024년 5월에 그 미래가 될 줄은 상상도 못했고, 우리는 어떠한 주요 모델도 처리하고 생성할 수 있는 능력을 가진 모델을 보유하고 있는 상황이에요. 그런데 여전히 빠른 응답 시간을 유지하죠.</p>
<p>지금 이것이 혁명적인 것을 넘어섰어요. OpenAI가 또 한 번 선방했죠. 여기에 가까운 것을 갖고 있는 사람은 아무도 없으며, 그러한 모델의 가능성은 너무 커서 우리 마음으로는 처리하기 어렵습니다.</p>
<p>우리는 이전의 개념과 아이디어를 다시 검토해야 해요. 왜냐하면 이전에 현실이 될 수 없었던 제한 사항이 오늘날에는 존재하지 않을 수 있기 때문이죠. 그리고 우리 마음을 새롭게 개조된 아이디어로 준비해야 하며, 그 전에는 상상조차 할 수 없었던 해결책에 대한 새로운 아이디어에 대비해야 해요.</p>
<p>PS1: 그들의 API에서 모든 모드에 대한 액세스를 아직 공개하지 않았습니다, 현재는 텍스트와 이미지만 사용할 수 있습니다. 그래서 다른 방법을 고민해볼 수 있지만, 지금까지 아직 정해진 날짜가 없는 출시를 기다려야 합니다.</p>
<p>PS2: 예시로 모델은 3D 이미지도 생성합니다.</p>
<p>PS3: 이 모델은 오늘날 GPT-4 Turbo의 절반 가격에 판매되고 있는데, 따라서 Turbo보다 훨씬 더 저렴하면서 효율적입니다.</p>
<p>아래는 최신 최고 모델과 비슷한 성능을 보여주는 일부 벤치마크입니다:</p>
<p><img src="/assets/img/2024-05-15-GPT4OmniSomuchmorethanjustavoiceassistant_1.png" alt="image"/></p>
<p>You can learn more about this model and see examples of its use on <a href="https://example.com">OpenAI’s website</a>.
Hello GPT-4o | OpenAI</p></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"GPT4 Omni - 그저 음성 어시스턴트 이상의 무언가","description":"","date":"2024-05-15 11:33","slug":"2024-05-15-GPT4OmniSomuchmorethanjustavoiceassistant","content":"\n\n![image](/assets/img/2024-05-15-GPT4OmniSomuchmorethanjustavoiceassistant_0.png)\n\n오늘은 OpenAI의 봄 발표일이었고, 정말 놀라운 소식이었어요. 여러분도 동의하실 거라고 생각해요. 이번 밤 대부분을 새 음성 어시스턴트와 노는 데에 보냈거든요. (영화 HER에 언급된 것과 매우 정확한 시나리오입니다).\n\n그런데 혁명적이고 놀라운 음성 기능이 있을 뿐만 아니라, GPT4o 모델은 그 이상을 제공해요.\n\n솔직히 말하자면, 음성 기능에 정말 매료되어서 현실감을 느꼈죠. 그래서 한참을 걸려서 모델의 기술적 공지사항을 정말 자세히 읽어 보았는데, 방금 그것을 듣고 다시 놀라버렸어요. \n\n\n\nGPT4o를 생각했을 때는 기본적으로 GPT-4 Turbo의 최적화된 버전일 뿐이라고 생각했어요. 이번에는 더 나은 추론 능력, 더 작은 지연 시간 및 음성 대화용으로 훈련되었어요. 그들은 이미 보유한 기술을 Whisper와 TTS와 함께 최적화된 새 모델과 통화를 결합하여 ChatGPT에 매우 효과적으로 통합했다고 생각했었어요.\n\n그러나 모델의 기술 보고서를 읽은 후에, 이렇게 발견했어요:\n\n텍스트, 오디오 및 비전 멀티모달리티가 모두 포함된 단일 새 모델!!\n\n텍스트/오디오/이미지를 입력으로 받아 텍스트/오디오/이미지로 출력하는 단일 모델이 있어요.\n\n\n\n저는 지난 번에 GenAI의 미래는 모든 모달리티를 고루 보유한 다중 모델링에 있을 것이라고 언급했다는 것을 알고 있어요. 그리고 우리는 그런 의도로 이니셔티브를 볼 수 있어요.\n\n하지만 2024년 5월에 그 미래가 될 줄은 상상도 못했고, 우리는 어떠한 주요 모델도 처리하고 생성할 수 있는 능력을 가진 모델을 보유하고 있는 상황이에요. 그런데 여전히 빠른 응답 시간을 유지하죠.\n\n지금 이것이 혁명적인 것을 넘어섰어요. OpenAI가 또 한 번 선방했죠. 여기에 가까운 것을 갖고 있는 사람은 아무도 없으며, 그러한 모델의 가능성은 너무 커서 우리 마음으로는 처리하기 어렵습니다.\n\n우리는 이전의 개념과 아이디어를 다시 검토해야 해요. 왜냐하면 이전에 현실이 될 수 없었던 제한 사항이 오늘날에는 존재하지 않을 수 있기 때문이죠. 그리고 우리 마음을 새롭게 개조된 아이디어로 준비해야 하며, 그 전에는 상상조차 할 수 없었던 해결책에 대한 새로운 아이디어에 대비해야 해요.\n\n\n\nPS1: 그들의 API에서 모든 모드에 대한 액세스를 아직 공개하지 않았습니다, 현재는 텍스트와 이미지만 사용할 수 있습니다. 그래서 다른 방법을 고민해볼 수 있지만, 지금까지 아직 정해진 날짜가 없는 출시를 기다려야 합니다.\n\nPS2: 예시로 모델은 3D 이미지도 생성합니다.\n\nPS3: 이 모델은 오늘날 GPT-4 Turbo의 절반 가격에 판매되고 있는데, 따라서 Turbo보다 훨씬 더 저렴하면서 효율적입니다.\n\n아래는 최신 최고 모델과 비슷한 성능을 보여주는 일부 벤치마크입니다:\n\n\n\n\n![image](/assets/img/2024-05-15-GPT4OmniSomuchmorethanjustavoiceassistant_1.png)\n\nYou can learn more about this model and see examples of its use on [OpenAI’s website](https://example.com).\nHello GPT-4o | OpenAI\n","ogImage":{"url":"/assets/img/2024-05-15-GPT4OmniSomuchmorethanjustavoiceassistant_0.png"},"coverImage":"/assets/img/2024-05-15-GPT4OmniSomuchmorethanjustavoiceassistant_0.png","tag":["Tech"],"readingTime":2},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    p: \"p\",\n    img: \"img\",\n    a: \"a\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-15-GPT4OmniSomuchmorethanjustavoiceassistant_0.png\",\n        alt: \"image\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"오늘은 OpenAI의 봄 발표일이었고, 정말 놀라운 소식이었어요. 여러분도 동의하실 거라고 생각해요. 이번 밤 대부분을 새 음성 어시스턴트와 노는 데에 보냈거든요. (영화 HER에 언급된 것과 매우 정확한 시나리오입니다).\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"그런데 혁명적이고 놀라운 음성 기능이 있을 뿐만 아니라, GPT4o 모델은 그 이상을 제공해요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"솔직히 말하자면, 음성 기능에 정말 매료되어서 현실감을 느꼈죠. 그래서 한참을 걸려서 모델의 기술적 공지사항을 정말 자세히 읽어 보았는데, 방금 그것을 듣고 다시 놀라버렸어요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"GPT4o를 생각했을 때는 기본적으로 GPT-4 Turbo의 최적화된 버전일 뿐이라고 생각했어요. 이번에는 더 나은 추론 능력, 더 작은 지연 시간 및 음성 대화용으로 훈련되었어요. 그들은 이미 보유한 기술을 Whisper와 TTS와 함께 최적화된 새 모델과 통화를 결합하여 ChatGPT에 매우 효과적으로 통합했다고 생각했었어요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"그러나 모델의 기술 보고서를 읽은 후에, 이렇게 발견했어요:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"텍스트, 오디오 및 비전 멀티모달리티가 모두 포함된 단일 새 모델!!\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"텍스트/오디오/이미지를 입력으로 받아 텍스트/오디오/이미지로 출력하는 단일 모델이 있어요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"저는 지난 번에 GenAI의 미래는 모든 모달리티를 고루 보유한 다중 모델링에 있을 것이라고 언급했다는 것을 알고 있어요. 그리고 우리는 그런 의도로 이니셔티브를 볼 수 있어요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"하지만 2024년 5월에 그 미래가 될 줄은 상상도 못했고, 우리는 어떠한 주요 모델도 처리하고 생성할 수 있는 능력을 가진 모델을 보유하고 있는 상황이에요. 그런데 여전히 빠른 응답 시간을 유지하죠.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"지금 이것이 혁명적인 것을 넘어섰어요. OpenAI가 또 한 번 선방했죠. 여기에 가까운 것을 갖고 있는 사람은 아무도 없으며, 그러한 모델의 가능성은 너무 커서 우리 마음으로는 처리하기 어렵습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"우리는 이전의 개념과 아이디어를 다시 검토해야 해요. 왜냐하면 이전에 현실이 될 수 없었던 제한 사항이 오늘날에는 존재하지 않을 수 있기 때문이죠. 그리고 우리 마음을 새롭게 개조된 아이디어로 준비해야 하며, 그 전에는 상상조차 할 수 없었던 해결책에 대한 새로운 아이디어에 대비해야 해요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"PS1: 그들의 API에서 모든 모드에 대한 액세스를 아직 공개하지 않았습니다, 현재는 텍스트와 이미지만 사용할 수 있습니다. 그래서 다른 방법을 고민해볼 수 있지만, 지금까지 아직 정해진 날짜가 없는 출시를 기다려야 합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"PS2: 예시로 모델은 3D 이미지도 생성합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"PS3: 이 모델은 오늘날 GPT-4 Turbo의 절반 가격에 판매되고 있는데, 따라서 Turbo보다 훨씬 더 저렴하면서 효율적입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"아래는 최신 최고 모델과 비슷한 성능을 보여주는 일부 벤치마크입니다:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-15-GPT4OmniSomuchmorethanjustavoiceassistant_1.png\",\n        alt: \"image\"\n      })\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"You can learn more about this model and see examples of its use on \", _jsx(_components.a, {\n        href: \"https://example.com\",\n        children: \"OpenAI’s website\"\n      }), \".\\nHello GPT-4o | OpenAI\"]\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-15-GPT4OmniSomuchmorethanjustavoiceassistant"},"buildId":"7rKODeu6chWTLgXf6auoL","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>