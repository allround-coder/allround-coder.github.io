<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>GPT-4 대 GPT-4 대 Gemini 15   성능 분석 | allround-coder</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://allround-coder.github.io///post/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="GPT-4 대 GPT-4 대 Gemini 15   성능 분석 | allround-coder" data-gatsby-head="true"/><meta property="og:title" content="GPT-4 대 GPT-4 대 Gemini 15   성능 분석 | allround-coder" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://allround-coder.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://allround-coder.github.io///post/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis" data-gatsby-head="true"/><meta name="twitter:title" content="GPT-4 대 GPT-4 대 Gemini 15   성능 분석 | allround-coder" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | allround-coder" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-15 11:37" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZFDEQ947R4"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
  
            gtag('config', 'G-ZFDEQ947R4');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/acd99c507555fdc6.css" as="style"/><link rel="stylesheet" href="/_next/static/css/acd99c507555fdc6.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/162-4172e84c8e2aa747.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-742e6c91a18eb160.js" defer=""></script><script src="/_next/static/6w6Yg3qJxLtqeXNguENru/_buildManifest.js" defer=""></script><script src="/_next/static/6w6Yg3qJxLtqeXNguENru/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Allround Coder</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">GPT-4 대 GPT-4 대 Gemini 15   성능 분석</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="GPT-4 대 GPT-4 대 Gemini 15   성능 분석" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">Allround Coder</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 15, 2024</span><span class="posts_reading_time__f7YPP">5<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<h2>오픈에이아이(OpenAI)의 새로운 프래그십 모델의 영어 언어 이해 능력 측정</h2>
<p><img src="/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_0.png" alt="이미지"></p>
<p>오픈에이아이의 GPT-4o 최근 공개로 인공지능 언어 모델과 그들과의 상호작용에 새로운 시대가 열렸습니다.</p>
<p>가장 인상적인 부분은 대화 중단과 함께 ChatGPT와의 실시간 상호작용을 지원하는 것이었습니다.</p>
<p>실시간 데모 중 일부 키크는 사건이 있었지만, 팀이 이룬 성과에 놀랍지 않을 수가 없어요.</p>
<p>더 좋은 소식은, 데모 직후 OpenAI가 GPT-4o API에 접속 권한을 부여했어요.</p>
<p>본 기사에서는, 제가 만든 영어 데이터셋을 사용해 GPT-4o 대 GPT-4 대 Google의 Gemini 및 Unicorn 모델의 분류 능력을 측정한 독립적인 분석을 제시할 거에요.</p>
<p>이 모델 중 어떤 것이 영어 이해력에서 가장 강한지 알아볼까요?</p>
<p><img src="/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_1.png" alt="image"></p>
<h1>GPT-4o에 대한 새로운 소식</h1>
<p>제일 먼저 소개하는 것은 OmnI 모델 개념으로, 텍스트, 오디오, 비디오를 매끄럽게 이해하고 처리하도록 설계되었습니다.</p>
<p>OpenAI의 초점은 GPT-4 수준의 지능을 대중들에게 민주화 하는 방향으로 바뀌어, GPT-4 수준의 언어 모델 지능을 무료 사용자에게도 접근 가능하게 만드는 것을 중심으로 이루어지는 것으로 보입니다.</p>
<p>OpenAI가 GPT-4o에 향상된 품질과 속도로 50개 이상의 언어에 대해 더 포괄적이고 전 세계적으로 접근 가능한 AI 경험을 제공한다고 발표했습니다. 더 저렴한 가격으로!</p>
<p>그들은 또한 유료 구독자들이 비유료 사용자들과 비교하여 5배 용량을 제공받게 될 것이라고 언급했습니다.</p>
<p>게다가 대중을 위해 오디오, 비전, 텍스트 인터페이스를 통해 실시간 추론을 용이하게 하는 ChatGPT의 데스크톱 버전을 출시할 예정입니다.</p>
<h1>GPT-4o API 사용 방법</h1>
<p>새로운 GPT-4o 모델은 OpenAI의 기존 채팅 완성 API를 따르며, 역호환성을 유지하고 사용하기 간단합니다.</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> <span class="hljs-title class_">AsyncOpenAI</span>


<span class="hljs-variable constant_">OPENAI_API_KEY</span> = <span class="hljs-string">"&#x3C;your-api-key>"</span>


def <span class="hljs-title function_">openai_chat_resolve</span>(<span class="hljs-attr">response</span>: dict, strip_tokens = <span class="hljs-title class_">None</span>) -> <span class="hljs-attr">str</span>:
    <span class="hljs-keyword">if</span> strip_tokens is <span class="hljs-title class_">None</span>:
        strip_tokens = []
    <span class="hljs-keyword">if</span> response and response.<span class="hljs-property">choices</span> and <span class="hljs-title function_">len</span>(response.<span class="hljs-property">choices</span>) > <span class="hljs-number">0</span>:
        content = response.<span class="hljs-property">choices</span>[<span class="hljs-number">0</span>].<span class="hljs-property">message</span>.<span class="hljs-property">content</span>.<span class="hljs-title function_">strip</span>()
        <span class="hljs-keyword">if</span> content is not <span class="hljs-title class_">None</span> or content != <span class="hljs-string">''</span>:
            <span class="hljs-keyword">if</span> <span class="hljs-attr">strip_tokens</span>:
                <span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> <span class="hljs-attr">strip_tokens</span>:
                    content = content.<span class="hljs-title function_">replace</span>(token, <span class="hljs-string">''</span>)
            <span class="hljs-keyword">return</span> content
    raise <span class="hljs-title class_">Exception</span>(f<span class="hljs-string">'응답을 해결할 수 없습니다: {response}'</span>)


<span class="hljs-keyword">async</span> def <span class="hljs-title function_">openai_chat_request</span>(<span class="hljs-attr">prompt</span>: str, <span class="hljs-attr">model_nane</span>: str, temperature=<span class="hljs-number">0.0</span>):
    message = {<span class="hljs-string">'role'</span>: <span class="hljs-string">'user'</span>, <span class="hljs-string">'content'</span>: prompt}
    client = <span class="hljs-title class_">AsyncOpenAI</span>(api_key=<span class="hljs-variable constant_">OPENAI_API_KEY</span>)
    <span class="hljs-keyword">return</span> <span class="hljs-keyword">await</span> client.<span class="hljs-property">chat</span>.<span class="hljs-property">completions</span>.<span class="hljs-title function_">create</span>(
        model=model_nane,
        messages=[message],
        temperature=temperature,
    )


<span class="hljs-title function_">openai_chat_request</span>(prompt=<span class="hljs-string">"안녕하세요!"</span>, model_nane=<span class="hljs-string">"gpt-4o-2024–05–13"</span>)
</code></pre>
<p>GPT-4o는 ChatGPT 인터페이스를 통해도 이용 가능합니다:</p>
<h1>공식 평가</h1>
<p>OpenAI의 블로그 게시물에는 MMLU 및 HumanEval과 같은 알려진 데이터셋의 평가 점수가 포함되어 있습니다.</p>
<p><img src="/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_3.png" alt="그래프"></p>
<p>그래프에서 확인할 수 있듯이, GPT-4o의 성능은 이 분야에서 최첨단으로 분류될 수 있으며 — 새로운 모델이 더 저렴하고 빠르다는 것을 고려하면 매우 유망하게 들립니다.</p>
<p>지난 해 동안 여러 모델들을 보았는데, State-of-the-art 언어 성능을 주장하는 모델들이 많았어요. 하지만 실제로는 이러한 모델들 중 일부가 이러한 공개 데이터셋에서 부분적으로 학습되었거나 (또는 오버핏팅)하여 리더보드에서 현실적이지 않은 점수를 보여주기도 했어요.</p>
<p>그러므로, 이러한 모델들의 성능을 독립적으로 분석하고, 제가 만든 데이터셋과 같은 잘 알려지지 않은 데이터셋을 사용하여 성능을 평가하는 것이 중요합니다 😄</p>
<h1>제 평가 데이터셋 🔢</h1>
<p>이전 글에서 설명했듯이, 저는 다양한 LLMs를 통해 분류 성능을 측정할 수 있는 토픽 데이터셋을 만들었어요.</p>
<p>데이터셋은 50가지 주제로 분류된 200개의 문장으로 구성되어 있습니다. 일부는 분류 작업을 더 어렵게 만들기 위해 밀접하게 관련되어 있습니다.</p>
<p>전체 데이터셋은 저가 수작업으로 영어로 작성하고 레이블을 지정했습니다.</p>
<p>그런 다음 GPT4 (gpt-4-0613)를 사용하여 데이터셋을 여러 언어로 번역했습니다.</p>
<p>그러나 이 평가 중에는 데이터셋의 영어 버전만 평가할 것이며, 데이터셋 생성과 주제 예측에 동일한 언어 모델을 사용함으로 인해 발생할 수 있는 잠재적인 편향으로 인해 결과에 영향을 미치지 않아야 합니다.</p>
<p>지금 당장 데이터셋을 확인해보세요: 주제 데이터셋.</p>
<h1>성능 결과 📊</h1>
<p>다음 모델들을 평가하기로 결정했어요:</p>
<ul>
<li>GPT-4o: gpt-4o-2024–05–13</li>
<li>GPT-4: gpt-4–0613</li>
<li>GPT-4-Turbo: gpt-4-turbo-2024–04–09</li>
<li>Gemini 1.5 Pro: gemini-1.5-pro-preview-0409</li>
<li>Gemini 1.0: gemini-1.0-pro-002</li>
<li>Palm 2 Unicorn: text-unicorn@001</li>
</ul>
<p>언어 모델에 주어진 작업은 데이터셋의 각 문장을 올바른 주제와 일치시키는 것입니다. 이를 통해 각 언어와 각 모델의 정확도 점수 및 오류율을 계산할 수 있습니다.</p>
<p>대부분의 모델이 올바르게 분류되기 때문에 각 모델의 오류율을 그래프로 플로팅하고 있습니다.</p>
<p>낮은 오류율은 더 나은 모델 성능을 나타냅니다.</p>
<p>그래프에서 볼 수 있듯이, GPT-4o는 모든 모델 중에서 가장 낮은 오류율을 보여 2개의 실수만 발생했습니다.</p>
<p>GPT-4, Gemini 1.5, and Palm 2 Unicorn는 GPT-4o보다 한 가지 더 실수가 있었음을 알 수도 있습니다. 이들은 강력한 성능을 보여주고 있습니다. 흥미로운 점은 GPT-4 Turbo가 GPT-4-0613보다 약간 성능이 떨어진다는 것인데, 이는 OpenAI가 모델 페이지에 작성한 내용과는 다른 결과입니다.</p>
<p>마지막으로, Gemini 1.0은 가격대를 고려하면 예상대로 다소 뒤처지고 있습니다.</p>
<h1>결론 💡</h1>
<p>이 독특한 영어 데이터셋을 활용한 이 분석은 이러한 고급 언어 모델의 최첨단 능력에 대한 통찰을 제공합니다.</p>
<p>GPT-4, OpenAI의 최신 모델은 테스트된 모델 중에서 가장 낮은 오류율로 놀랍습니다. 이는 OpenAI가 성능에 관한 주장을 확증합니다.</p>
<p>인공지능 커뮤니티와 사용자들은 서로 독립적인 평가를 계속해야 합니다. 이를 통해 표준화된 벤치마킹만으로는 실용적인 효과를 제공하는 모델에 대해 더 명확한 그림을 제시할 수 있습니다.</p>
<p>데이터셋이 상당히 작기 때문에 결과는 데이터셋에 따라 달라질 수 있습니다. 성능은 영어 데이터셋만을 사용했으며, 다국어 비교는 다음 기회를 기다려야 할 것입니다.</p>
<p>읽어 주셔서 감사합니다!</p>
<p>향후 유사한 콘텐츠를 받으려면 팔로우하세요!</p>
<p>문의 사항이 있으시면 언제든지 연락해주세요!</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"GPT-4 대 GPT-4 대 Gemini 15   성능 분석","description":"","date":"2024-05-15 11:37","slug":"2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis","content":"\n\n## 오픈에이아이(OpenAI)의 새로운 프래그십 모델의 영어 언어 이해 능력 측정\n\n![이미지](/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_0.png)\n\n오픈에이아이의 GPT-4o 최근 공개로 인공지능 언어 모델과 그들과의 상호작용에 새로운 시대가 열렸습니다.\n\n가장 인상적인 부분은 대화 중단과 함께 ChatGPT와의 실시간 상호작용을 지원하는 것이었습니다.\n\n\n\n실시간 데모 중 일부 키크는 사건이 있었지만, 팀이 이룬 성과에 놀랍지 않을 수가 없어요.\n\n더 좋은 소식은, 데모 직후 OpenAI가 GPT-4o API에 접속 권한을 부여했어요.\n\n본 기사에서는, 제가 만든 영어 데이터셋을 사용해 GPT-4o 대 GPT-4 대 Google의 Gemini 및 Unicorn 모델의 분류 능력을 측정한 독립적인 분석을 제시할 거에요.\n\n이 모델 중 어떤 것이 영어 이해력에서 가장 강한지 알아볼까요?\n\n\n\n![image](/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_1.png)\n\n# GPT-4o에 대한 새로운 소식\n\n제일 먼저 소개하는 것은 OmnI 모델 개념으로, 텍스트, 오디오, 비디오를 매끄럽게 이해하고 처리하도록 설계되었습니다.\n\nOpenAI의 초점은 GPT-4 수준의 지능을 대중들에게 민주화 하는 방향으로 바뀌어, GPT-4 수준의 언어 모델 지능을 무료 사용자에게도 접근 가능하게 만드는 것을 중심으로 이루어지는 것으로 보입니다.\n\n\n\nOpenAI가 GPT-4o에 향상된 품질과 속도로 50개 이상의 언어에 대해 더 포괄적이고 전 세계적으로 접근 가능한 AI 경험을 제공한다고 발표했습니다. 더 저렴한 가격으로!\n\n그들은 또한 유료 구독자들이 비유료 사용자들과 비교하여 5배 용량을 제공받게 될 것이라고 언급했습니다.\n\n게다가 대중을 위해 오디오, 비전, 텍스트 인터페이스를 통해 실시간 추론을 용이하게 하는 ChatGPT의 데스크톱 버전을 출시할 예정입니다.\n\n# GPT-4o API 사용 방법\n\n\n\n새로운 GPT-4o 모델은 OpenAI의 기존 채팅 완성 API를 따르며, 역호환성을 유지하고 사용하기 간단합니다.\n\n```js\nfrom openai import AsyncOpenAI\n\n\nOPENAI_API_KEY = \"\u003cyour-api-key\u003e\"\n\n\ndef openai_chat_resolve(response: dict, strip_tokens = None) -\u003e str:\n    if strip_tokens is None:\n        strip_tokens = []\n    if response and response.choices and len(response.choices) \u003e 0:\n        content = response.choices[0].message.content.strip()\n        if content is not None or content != '':\n            if strip_tokens:\n                for token in strip_tokens:\n                    content = content.replace(token, '')\n            return content\n    raise Exception(f'응답을 해결할 수 없습니다: {response}')\n\n\nasync def openai_chat_request(prompt: str, model_nane: str, temperature=0.0):\n    message = {'role': 'user', 'content': prompt}\n    client = AsyncOpenAI(api_key=OPENAI_API_KEY)\n    return await client.chat.completions.create(\n        model=model_nane,\n        messages=[message],\n        temperature=temperature,\n    )\n\n\nopenai_chat_request(prompt=\"안녕하세요!\", model_nane=\"gpt-4o-2024–05–13\")\n```\n\nGPT-4o는 ChatGPT 인터페이스를 통해도 이용 가능합니다:\n\n\u003cimg src=\"/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_2.png\" /\u003e\n\n\n\n# 공식 평가\n\nOpenAI의 블로그 게시물에는 MMLU 및 HumanEval과 같은 알려진 데이터셋의 평가 점수가 포함되어 있습니다.\n\n![그래프](/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_3.png)\n\n그래프에서 확인할 수 있듯이, GPT-4o의 성능은 이 분야에서 최첨단으로 분류될 수 있으며 — 새로운 모델이 더 저렴하고 빠르다는 것을 고려하면 매우 유망하게 들립니다.\n\n\n\n지난 해 동안 여러 모델들을 보았는데, State-of-the-art 언어 성능을 주장하는 모델들이 많았어요. 하지만 실제로는 이러한 모델들 중 일부가 이러한 공개 데이터셋에서 부분적으로 학습되었거나 (또는 오버핏팅)하여 리더보드에서 현실적이지 않은 점수를 보여주기도 했어요.\n\n그러므로, 이러한 모델들의 성능을 독립적으로 분석하고, 제가 만든 데이터셋과 같은 잘 알려지지 않은 데이터셋을 사용하여 성능을 평가하는 것이 중요합니다 😄\n\n# 제 평가 데이터셋 🔢\n\n이전 글에서 설명했듯이, 저는 다양한 LLMs를 통해 분류 성능을 측정할 수 있는 토픽 데이터셋을 만들었어요.\n\n\n\n데이터셋은 50가지 주제로 분류된 200개의 문장으로 구성되어 있습니다. 일부는 분류 작업을 더 어렵게 만들기 위해 밀접하게 관련되어 있습니다.\n\n전체 데이터셋은 저가 수작업으로 영어로 작성하고 레이블을 지정했습니다.\n\n그런 다음 GPT4 (gpt-4-0613)를 사용하여 데이터셋을 여러 언어로 번역했습니다.\n\n그러나 이 평가 중에는 데이터셋의 영어 버전만 평가할 것이며, 데이터셋 생성과 주제 예측에 동일한 언어 모델을 사용함으로 인해 발생할 수 있는 잠재적인 편향으로 인해 결과에 영향을 미치지 않아야 합니다.\n\n\n\n지금 당장 데이터셋을 확인해보세요: 주제 데이터셋.\n\n# 성능 결과 📊\n\n다음 모델들을 평가하기로 결정했어요:\n\n- GPT-4o: gpt-4o-2024–05–13\n- GPT-4: gpt-4–0613\n- GPT-4-Turbo: gpt-4-turbo-2024–04–09\n- Gemini 1.5 Pro: gemini-1.5-pro-preview-0409\n- Gemini 1.0: gemini-1.0-pro-002\n- Palm 2 Unicorn: text-unicorn@001\n\n\n\n언어 모델에 주어진 작업은 데이터셋의 각 문장을 올바른 주제와 일치시키는 것입니다. 이를 통해 각 언어와 각 모델의 정확도 점수 및 오류율을 계산할 수 있습니다.\n\n대부분의 모델이 올바르게 분류되기 때문에 각 모델의 오류율을 그래프로 플로팅하고 있습니다.\n\n낮은 오류율은 더 나은 모델 성능을 나타냅니다.\n\n그래프에서 볼 수 있듯이, GPT-4o는 모든 모델 중에서 가장 낮은 오류율을 보여 2개의 실수만 발생했습니다.\n\n\n\nGPT-4, Gemini 1.5, and Palm 2 Unicorn는 GPT-4o보다 한 가지 더 실수가 있었음을 알 수도 있습니다. 이들은 강력한 성능을 보여주고 있습니다. 흥미로운 점은 GPT-4 Turbo가 GPT-4-0613보다 약간 성능이 떨어진다는 것인데, 이는 OpenAI가 모델 페이지에 작성한 내용과는 다른 결과입니다.\n\n마지막으로, Gemini 1.0은 가격대를 고려하면 예상대로 다소 뒤처지고 있습니다.\n\n# 결론 💡\n\n이 독특한 영어 데이터셋을 활용한 이 분석은 이러한 고급 언어 모델의 최첨단 능력에 대한 통찰을 제공합니다.\n\n\n\nGPT-4, OpenAI의 최신 모델은 테스트된 모델 중에서 가장 낮은 오류율로 놀랍습니다. 이는 OpenAI가 성능에 관한 주장을 확증합니다.\n\n인공지능 커뮤니티와 사용자들은 서로 독립적인 평가를 계속해야 합니다. 이를 통해 표준화된 벤치마킹만으로는 실용적인 효과를 제공하는 모델에 대해 더 명확한 그림을 제시할 수 있습니다.\n\n데이터셋이 상당히 작기 때문에 결과는 데이터셋에 따라 달라질 수 있습니다. 성능은 영어 데이터셋만을 사용했으며, 다국어 비교는 다음 기회를 기다려야 할 것입니다.\n\n읽어 주셔서 감사합니다!\n\n\n\n향후 유사한 콘텐츠를 받으려면 팔로우하세요!\n\n문의 사항이 있으시면 언제든지 연락해주세요!","ogImage":{"url":"/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_0.png"},"coverImage":"/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_0.png","tag":["Tech"],"readingTime":5},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003ch2\u003e오픈에이아이(OpenAI)의 새로운 프래그십 모델의 영어 언어 이해 능력 측정\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e오픈에이아이의 GPT-4o 최근 공개로 인공지능 언어 모델과 그들과의 상호작용에 새로운 시대가 열렸습니다.\u003c/p\u003e\n\u003cp\u003e가장 인상적인 부분은 대화 중단과 함께 ChatGPT와의 실시간 상호작용을 지원하는 것이었습니다.\u003c/p\u003e\n\u003cp\u003e실시간 데모 중 일부 키크는 사건이 있었지만, 팀이 이룬 성과에 놀랍지 않을 수가 없어요.\u003c/p\u003e\n\u003cp\u003e더 좋은 소식은, 데모 직후 OpenAI가 GPT-4o API에 접속 권한을 부여했어요.\u003c/p\u003e\n\u003cp\u003e본 기사에서는, 제가 만든 영어 데이터셋을 사용해 GPT-4o 대 GPT-4 대 Google의 Gemini 및 Unicorn 모델의 분류 능력을 측정한 독립적인 분석을 제시할 거에요.\u003c/p\u003e\n\u003cp\u003e이 모델 중 어떤 것이 영어 이해력에서 가장 강한지 알아볼까요?\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_1.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003ch1\u003eGPT-4o에 대한 새로운 소식\u003c/h1\u003e\n\u003cp\u003e제일 먼저 소개하는 것은 OmnI 모델 개념으로, 텍스트, 오디오, 비디오를 매끄럽게 이해하고 처리하도록 설계되었습니다.\u003c/p\u003e\n\u003cp\u003eOpenAI의 초점은 GPT-4 수준의 지능을 대중들에게 민주화 하는 방향으로 바뀌어, GPT-4 수준의 언어 모델 지능을 무료 사용자에게도 접근 가능하게 만드는 것을 중심으로 이루어지는 것으로 보입니다.\u003c/p\u003e\n\u003cp\u003eOpenAI가 GPT-4o에 향상된 품질과 속도로 50개 이상의 언어에 대해 더 포괄적이고 전 세계적으로 접근 가능한 AI 경험을 제공한다고 발표했습니다. 더 저렴한 가격으로!\u003c/p\u003e\n\u003cp\u003e그들은 또한 유료 구독자들이 비유료 사용자들과 비교하여 5배 용량을 제공받게 될 것이라고 언급했습니다.\u003c/p\u003e\n\u003cp\u003e게다가 대중을 위해 오디오, 비전, 텍스트 인터페이스를 통해 실시간 추론을 용이하게 하는 ChatGPT의 데스크톱 버전을 출시할 예정입니다.\u003c/p\u003e\n\u003ch1\u003eGPT-4o API 사용 방법\u003c/h1\u003e\n\u003cp\u003e새로운 GPT-4o 모델은 OpenAI의 기존 채팅 완성 API를 따르며, 역호환성을 유지하고 사용하기 간단합니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e openai \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eAsyncOpenAI\u003c/span\u003e\n\n\n\u003cspan class=\"hljs-variable constant_\"\u003eOPENAI_API_KEY\u003c/span\u003e = \u003cspan class=\"hljs-string\"\u003e\"\u0026#x3C;your-api-key\u003e\"\u003c/span\u003e\n\n\ndef \u003cspan class=\"hljs-title function_\"\u003eopenai_chat_resolve\u003c/span\u003e(\u003cspan class=\"hljs-attr\"\u003eresponse\u003c/span\u003e: dict, strip_tokens = \u003cspan class=\"hljs-title class_\"\u003eNone\u003c/span\u003e) -\u003e \u003cspan class=\"hljs-attr\"\u003estr\u003c/span\u003e:\n    \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e strip_tokens is \u003cspan class=\"hljs-title class_\"\u003eNone\u003c/span\u003e:\n        strip_tokens = []\n    \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e response and response.\u003cspan class=\"hljs-property\"\u003echoices\u003c/span\u003e and \u003cspan class=\"hljs-title function_\"\u003elen\u003c/span\u003e(response.\u003cspan class=\"hljs-property\"\u003echoices\u003c/span\u003e) \u003e \u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e:\n        content = response.\u003cspan class=\"hljs-property\"\u003echoices\u003c/span\u003e[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e].\u003cspan class=\"hljs-property\"\u003emessage\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003econtent\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003estrip\u003c/span\u003e()\n        \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e content is not \u003cspan class=\"hljs-title class_\"\u003eNone\u003c/span\u003e or content != \u003cspan class=\"hljs-string\"\u003e''\u003c/span\u003e:\n            \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003estrip_tokens\u003c/span\u003e:\n                \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e token \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003estrip_tokens\u003c/span\u003e:\n                    content = content.\u003cspan class=\"hljs-title function_\"\u003ereplace\u003c/span\u003e(token, \u003cspan class=\"hljs-string\"\u003e''\u003c/span\u003e)\n            \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e content\n    raise \u003cspan class=\"hljs-title class_\"\u003eException\u003c/span\u003e(f\u003cspan class=\"hljs-string\"\u003e'응답을 해결할 수 없습니다: {response}'\u003c/span\u003e)\n\n\n\u003cspan class=\"hljs-keyword\"\u003easync\u003c/span\u003e def \u003cspan class=\"hljs-title function_\"\u003eopenai_chat_request\u003c/span\u003e(\u003cspan class=\"hljs-attr\"\u003eprompt\u003c/span\u003e: str, \u003cspan class=\"hljs-attr\"\u003emodel_nane\u003c/span\u003e: str, temperature=\u003cspan class=\"hljs-number\"\u003e0.0\u003c/span\u003e):\n    message = {\u003cspan class=\"hljs-string\"\u003e'role'\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'user'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'content'\u003c/span\u003e: prompt}\n    client = \u003cspan class=\"hljs-title class_\"\u003eAsyncOpenAI\u003c/span\u003e(api_key=\u003cspan class=\"hljs-variable constant_\"\u003eOPENAI_API_KEY\u003c/span\u003e)\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eawait\u003c/span\u003e client.\u003cspan class=\"hljs-property\"\u003echat\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003ecompletions\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003ecreate\u003c/span\u003e(\n        model=model_nane,\n        messages=[message],\n        temperature=temperature,\n    )\n\n\n\u003cspan class=\"hljs-title function_\"\u003eopenai_chat_request\u003c/span\u003e(prompt=\u003cspan class=\"hljs-string\"\u003e\"안녕하세요!\"\u003c/span\u003e, model_nane=\u003cspan class=\"hljs-string\"\u003e\"gpt-4o-2024–05–13\"\u003c/span\u003e)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eGPT-4o는 ChatGPT 인터페이스를 통해도 이용 가능합니다:\u003c/p\u003e\n\u003ch1\u003e공식 평가\u003c/h1\u003e\n\u003cp\u003eOpenAI의 블로그 게시물에는 MMLU 및 HumanEval과 같은 알려진 데이터셋의 평가 점수가 포함되어 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_3.png\" alt=\"그래프\"\u003e\u003c/p\u003e\n\u003cp\u003e그래프에서 확인할 수 있듯이, GPT-4o의 성능은 이 분야에서 최첨단으로 분류될 수 있으며 — 새로운 모델이 더 저렴하고 빠르다는 것을 고려하면 매우 유망하게 들립니다.\u003c/p\u003e\n\u003cp\u003e지난 해 동안 여러 모델들을 보았는데, State-of-the-art 언어 성능을 주장하는 모델들이 많았어요. 하지만 실제로는 이러한 모델들 중 일부가 이러한 공개 데이터셋에서 부분적으로 학습되었거나 (또는 오버핏팅)하여 리더보드에서 현실적이지 않은 점수를 보여주기도 했어요.\u003c/p\u003e\n\u003cp\u003e그러므로, 이러한 모델들의 성능을 독립적으로 분석하고, 제가 만든 데이터셋과 같은 잘 알려지지 않은 데이터셋을 사용하여 성능을 평가하는 것이 중요합니다 😄\u003c/p\u003e\n\u003ch1\u003e제 평가 데이터셋 🔢\u003c/h1\u003e\n\u003cp\u003e이전 글에서 설명했듯이, 저는 다양한 LLMs를 통해 분류 성능을 측정할 수 있는 토픽 데이터셋을 만들었어요.\u003c/p\u003e\n\u003cp\u003e데이터셋은 50가지 주제로 분류된 200개의 문장으로 구성되어 있습니다. 일부는 분류 작업을 더 어렵게 만들기 위해 밀접하게 관련되어 있습니다.\u003c/p\u003e\n\u003cp\u003e전체 데이터셋은 저가 수작업으로 영어로 작성하고 레이블을 지정했습니다.\u003c/p\u003e\n\u003cp\u003e그런 다음 GPT4 (gpt-4-0613)를 사용하여 데이터셋을 여러 언어로 번역했습니다.\u003c/p\u003e\n\u003cp\u003e그러나 이 평가 중에는 데이터셋의 영어 버전만 평가할 것이며, 데이터셋 생성과 주제 예측에 동일한 언어 모델을 사용함으로 인해 발생할 수 있는 잠재적인 편향으로 인해 결과에 영향을 미치지 않아야 합니다.\u003c/p\u003e\n\u003cp\u003e지금 당장 데이터셋을 확인해보세요: 주제 데이터셋.\u003c/p\u003e\n\u003ch1\u003e성능 결과 📊\u003c/h1\u003e\n\u003cp\u003e다음 모델들을 평가하기로 결정했어요:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGPT-4o: gpt-4o-2024–05–13\u003c/li\u003e\n\u003cli\u003eGPT-4: gpt-4–0613\u003c/li\u003e\n\u003cli\u003eGPT-4-Turbo: gpt-4-turbo-2024–04–09\u003c/li\u003e\n\u003cli\u003eGemini 1.5 Pro: gemini-1.5-pro-preview-0409\u003c/li\u003e\n\u003cli\u003eGemini 1.0: gemini-1.0-pro-002\u003c/li\u003e\n\u003cli\u003ePalm 2 Unicorn: text-unicorn@001\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e언어 모델에 주어진 작업은 데이터셋의 각 문장을 올바른 주제와 일치시키는 것입니다. 이를 통해 각 언어와 각 모델의 정확도 점수 및 오류율을 계산할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e대부분의 모델이 올바르게 분류되기 때문에 각 모델의 오류율을 그래프로 플로팅하고 있습니다.\u003c/p\u003e\n\u003cp\u003e낮은 오류율은 더 나은 모델 성능을 나타냅니다.\u003c/p\u003e\n\u003cp\u003e그래프에서 볼 수 있듯이, GPT-4o는 모든 모델 중에서 가장 낮은 오류율을 보여 2개의 실수만 발생했습니다.\u003c/p\u003e\n\u003cp\u003eGPT-4, Gemini 1.5, and Palm 2 Unicorn는 GPT-4o보다 한 가지 더 실수가 있었음을 알 수도 있습니다. 이들은 강력한 성능을 보여주고 있습니다. 흥미로운 점은 GPT-4 Turbo가 GPT-4-0613보다 약간 성능이 떨어진다는 것인데, 이는 OpenAI가 모델 페이지에 작성한 내용과는 다른 결과입니다.\u003c/p\u003e\n\u003cp\u003e마지막으로, Gemini 1.0은 가격대를 고려하면 예상대로 다소 뒤처지고 있습니다.\u003c/p\u003e\n\u003ch1\u003e결론 💡\u003c/h1\u003e\n\u003cp\u003e이 독특한 영어 데이터셋을 활용한 이 분석은 이러한 고급 언어 모델의 최첨단 능력에 대한 통찰을 제공합니다.\u003c/p\u003e\n\u003cp\u003eGPT-4, OpenAI의 최신 모델은 테스트된 모델 중에서 가장 낮은 오류율로 놀랍습니다. 이는 OpenAI가 성능에 관한 주장을 확증합니다.\u003c/p\u003e\n\u003cp\u003e인공지능 커뮤니티와 사용자들은 서로 독립적인 평가를 계속해야 합니다. 이를 통해 표준화된 벤치마킹만으로는 실용적인 효과를 제공하는 모델에 대해 더 명확한 그림을 제시할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e데이터셋이 상당히 작기 때문에 결과는 데이터셋에 따라 달라질 수 있습니다. 성능은 영어 데이터셋만을 사용했으며, 다국어 비교는 다음 기회를 기다려야 할 것입니다.\u003c/p\u003e\n\u003cp\u003e읽어 주셔서 감사합니다!\u003c/p\u003e\n\u003cp\u003e향후 유사한 콘텐츠를 받으려면 팔로우하세요!\u003c/p\u003e\n\u003cp\u003e문의 사항이 있으시면 언제든지 연락해주세요!\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis"},"buildId":"6w6Yg3qJxLtqeXNguENru","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>