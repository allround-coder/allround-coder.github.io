<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>네이드 포 스피드 C, NET 8 SSE  채널을 활용한 LLMs Beyond OpenAI, Llama3 및 Fireworksai | allround-coder</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://allround-coder.github.io///post/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="네이드 포 스피드 C, NET 8 SSE  채널을 활용한 LLMs Beyond OpenAI, Llama3 및 Fireworksai | allround-coder" data-gatsby-head="true"/><meta property="og:title" content="네이드 포 스피드 C, NET 8 SSE  채널을 활용한 LLMs Beyond OpenAI, Llama3 및 Fireworksai | allround-coder" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://allround-coder.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://allround-coder.github.io///post/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai" data-gatsby-head="true"/><meta name="twitter:title" content="네이드 포 스피드 C, NET 8 SSE  채널을 활용한 LLMs Beyond OpenAI, Llama3 및 Fireworksai | allround-coder" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | allround-coder" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-13 00:03" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZFDEQ947R4"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
  
            gtag('config', 'G-ZFDEQ947R4');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/cd012fc8787133d0.css" as="style"/><link rel="stylesheet" href="/_next/static/css/cd012fc8787133d0.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/551-3069cf29fe274aab.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-985df180e46efe53.js" defer=""></script><script src="/_next/static/z1a6VTi5qHH9JJH7jaxL3/_buildManifest.js" defer=""></script><script src="/_next/static/z1a6VTi5qHH9JJH7jaxL3/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Allround Coder</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">네이드 포 스피드 C, NET 8 SSE  채널을 활용한 LLMs Beyond OpenAI, Llama3 및 Fireworksai</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="네이드 포 스피드 C, NET 8 SSE  채널을 활용한 LLMs Beyond OpenAI, Llama3 및 Fireworksai" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/assets/profile.jpg"/></div><div class="posts_textarea__w_iKT"><span class="writer">Allround Coder</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 13, 2024</span><span class="posts_reading_time__f7YPP">13<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><img src="https://miro.medium.com/v2/resize:fit:1400/1*YtK6hvB_PrUvd7uwqrk0-w.gif"/>
<h1>요약</h1>
<ul>
<li>OpenAI의 GTP-4는 일반적인 목적의 작업에 있어 압도적인 성능을 보여주지만, 전체적인 처리량(또는 오히려 그 부족함)이 많이 부족하다는 점이 매우 아쉽습니다. 이는 &quot;오프라인&quot; 작업에는 훌륭하지만, 사용자들이 더 많은 응답성을 기대하는 응용 프로그램에서는 적합하지 않을 수 있으며, 몇몇 사용 사례들은 하위 UX로 인해 배제될 수도 있습니다.</li>
<li>TheFastest.ai 팀의 최근 Hackernews 게시물은 모델과 플랫폼 모두에 대해 이런 차이가 얼마나 클 수 있는지를 강조하고 있습니다. 특히, Groq.com(Musk의 Grok와 혼동하지 말아야 합니다)와 Meta의 Llama 3 70B를 사용한 Fireworks.ai는 일부 작업에서 GPT-4와 비교했을 때 출력에 거의 희생 없이 빠른 처리량을 제공합니다.</li>
<li>C#/.NET 8 System.Threading.Channels와 서버 전송 이벤트(SSE)를 결합하면, OpenAI의 처리량과 높은 지연 시간으로 잘 동작하지 않은 작업을 구성할 수 있습니다.</li>
</ul>
<h1>소개</h1>
<p>GPT-5를 기다리는 동안, 2024년 5월 OpenAI의 GPT-4가 여전히 LLM으로서 전반적인 성능 면에서 우수하다는 것에 대해 논쟁하는 사람은 거의 없을 것입니다. 그러나 해당 모델은 비교적 낮은 처리량과 높은 대기 시간으로 인해 UX가 더 상호 작용적인 경험을 요구하는 경우에는 최적이 아닐 수 있습니다.</p>
<p>가장 빠른 LLM과 현재 사용 가능한 플랫폼과 OpenAI 간의 대기 시간 차이의 규모가 얼마나 큰지는 명백하지 않을 수 있습니다.</p>
<p>최근 Hackernews 스레드를 통해 TheFastest.ai로 이동하게 되었고, Meta의 Llama 3의 높은 처리량과 Groq.com 및 Fireworks.ai라는 두 플랫폼에 흥미로웠습니다.</p>
<p>(전자는 종종 머스크의 Grok AI와 혼동되기 때문에 불행합니다).</p>
<p>이 기사에서는 Fireworks.ai, Meta Llama 3 8B/70B, .NET 8, System.Threading.Channels 및 Server Sent Events (SSE)를 사용하여 앱을 만드는 방법을 살펴볼 것입니다.</p>
<h1>차이를 측정하기</h1>
<p>스택의 상단은 Llama-3과 Groq가 지배하고 Fireworks.ai가 상위 5위를 차지하고 있습니다(각 팀이 Fireworks를 선택해야 할 이유에 대해 조금 뒤에 설명하겠습니다).</p>
<p><img src="/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_0.png" alt="이미지"/></p>
<p>대조적으로, OpenAI의 GPT-4는 거의 맨 아래쪽에 위치합니다.</p>
<p><img src="/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_1.png" alt="이미지"/></p>
<p>OpenAI의 GPT-4를 사용해본 사람이라면 이미 처리량이 얼마나 낮은지를 알고 있을 것입니다. 하지만 이렇게 측정된 값을 보면 그 간격이 얼마나 큰지 더욱 부각됩니다. Groq의 Llama-3 70B는 GPT-4보다 거의 10배 더 높은 처리량을 가지고 있습니다!</p>
<p>이에 따라, GPT-4는 상호 작용이 필요하지 않은 경우에, 작업이 큰 문맥 창을 요구하는 경우에, 또는 복잡한 프롬프트와 문맥을 사용하여 &quot;벤치마크 품질&quot;의 결과가 필요한 경우에 실제로 매우 좋다고 생각했습니다.</p>
<p>하지만 사용 사례에 다른 요구 사항이 있는 경우는 어떨까요? 속도가 필요한 경우는 어떨까요?</p>
<h1>Groq와 Fireworks를 이용해 시동 걸기</h1>
<p>OpenAI의 처리량이 떨어져 사용자 경험을 나빠지게 만들 수 있는 문제 중 하나는, 최종적으로 콘텐츠가 가치를 추가한다 해도 주관적으로 사용자 경험을 나빠지게 할 수 있다는 것입니다.</p>
<p>OpenAI의 ChatGPT를 사용할 때, 채팅 응답에 몇 초가 걸릴 수도 있다는 사실을 SSE가 가려버리기 때문에 명확하게 드러나지 않을 수 있습니다. GPT-4의 처리량이 낮다는 것은 다른 대안을 시도해보기 전까지는 쉽게 알아챌 수 없습니다.</p>
<h1>Groq.com</h1>
<p>Groq는 LLM에 특별히 설계된 사용자 정의 하드웨어로 알려진 &quot;LPU&quot; 또는 &quot;언어 처리 유닛&quot;을 갖춘 흥미로운 플랫폼입니다:</p>
<p>적어도 문서로 보면, 이것은 마케팅 허세 이상으로 보이며 플랫폼은 객관적으로 고 처리량을 자랑합니다.</p>
<p>하지만 주요 문제는 현재의 SaaS 제공으로 이어집니다:</p>
<p><img src="/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_2.png" alt="이미지"/></p>
<p>무료 티어는 실험 용도로만 사용 가능하며, 그것도 겨우 가능할 뿐입니다.</p>
<p><img src="/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_3.png" alt="이미지"/></p>
<p>그래서 Groq은 꽤 빠르지만, 샌드박싱 용도 외에는 사용할 수 없으며, 가능하다면 엔터프라이즈 과금을 통해 사용할 수 있습니다.</p>
<h1>Fireworks.ai</h1>
<p>현재 시점에서 Fireworks의 Llama-3 70B는 전체적으로 9위에 랭크되어 있으며 두 번째로 빠른 Llama-3 70B입니다:</p>
<p><img src="/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_4.png" alt="이미지"/></p>
<p>마지막 토큰까지 260ms가 소요되며, 여전히 매우 빠르며 GPT-3.5와 GPT-4 사이의 성능을 제공하여 내 사용 사례에 대한 LLM 성능이 매우 좋습니다.</p>
<p>Fireworks.ai에는 중간 유료 티어가 없지만, 600 RPM은 작은 앱에 사용하기 적합하며 하드 토큰 제한이 없습니다.</p>
<p><img src="/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_5.png" alt="이미지"/></p>
<p>오늘 빠르게 무언가를 구축하려는 팀들에게는 Fireworks.ai가 아마도 최선의 선택일 것입니다. (아니, 나는 그들로부터 돈을 받고 있지 않아요)</p>
<h1>.NET 8, System.Threading.Channels 및 Server Sent Events (SSE)와 함께 실용적인 예제</h1>
<p>이 놀라운 처리량을 활용하기 위해서는 한 번에 여러 개의 스트림을 통해 생성한 다음 하나의 최종 출력 스트림으로 병합하는 동시 처리 전략이 필요합니다.</p>
<p>이는 .NET의 System.Threading.Channels를 Server Sent Events (SSE)와 결합하여 이 처리량을 완전히 활용하고 높은 반응성을 갖는 생성 AI 경험을 구축하는 완벽한 사용 사례입니다.</p>
<p>이전에 이 두 주제에 대해 별도로 다뤘었습니다:</p>
<ul>
<li>.NET Task Parallel Library vs System.Threading.Channels</li>
<li>.NET 6의 System.Threading.Channels를 이용한 동시 처리 (보너스: 간격 트리)</li>
<li>.NET 7과 함께하는 Server Sent Events</li>
</ul>
<p>오늘은 .NET 8 채널, Semantic Kernel 및 gen AI와 함께 어떤 대화형 경험을 만들 수 있는지 함께 살펴보겠습니다!</p>
<p><img src="/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_6.png" alt="image"/></p>
<p>저희 샘플 응용 프로그램은 준비된 재료 목록과 목표 조리 시간을 받아들여서 다음을 할 것입니다:</p>
<ul>
<li>해당 재료로 만들 수 있는 레시피 목록 생성</li>
<li>레시피 중 하나를 무작위로 선택</li>
<li>레시피를 위해 필요한 모든 재료 목록 생성</li>
<li>레시피를 위한 소개 단락 생성</li>
<li>준비된 각 재료에 대한 영양 정보에 대한 간략한 설명 생성</li>
<li>제안된 사이드 디시 목록 생성</li>
<li>순서 목록 생성</li>
</ul>
<p>단계 3~6은 병렬로 실행될 수 있지만, 레시피를 먼저 선택해야 하기 때문에 단계 1~2가 먼저 실행됩니다. 그리고 단계를 생성하기 전에 재료 전체 목록을 기다려야 합니다.</p>
<h1>.NET 채널을 이용한 병행 실행</h1>
<p>API 호출의 진입점은 요청을 받을 단일 POST 엔드포인트입니다:</p>
<pre><code class="hljs language-js"><span class="hljs-comment">// 👇 메인 진입점.</span>
app.<span class="hljs-title class_">MapPost</span>(<span class="hljs-string">&quot;/generate&quot;</span>, <span class="hljs-keyword">async</span> (
  <span class="hljs-title class_">HttpContext</span> context,          <span class="hljs-comment">// 의존성 주입에서 가져옴</span>
  <span class="hljs-title class_">RecipeGenerator</span> generator,    <span class="hljs-comment">// 의존성 주입에서 가져옴</span>
  <span class="hljs-title class_">RecipeRequest</span> request,        <span class="hljs-comment">// 바디에서 가져옴</span>
  <span class="hljs-title class_">CancellationToken</span> cancellation = <span class="hljs-keyword">default</span>
) =&gt;
{
  context.<span class="hljs-property">Response</span>.<span class="hljs-property">Headers</span>.<span class="hljs-property">ContentType</span> = <span class="hljs-string">&quot;text/event-stream&quot;</span>;

  <span class="hljs-keyword">await</span> generator.<span class="hljs-title class_">GenerateAsync</span>(
    request,
    <span class="hljs-comment">// 각 단편에 대한 스트리밍 응답을 작성하는 핸들러</span>
    <span class="hljs-keyword">async</span> (<span class="hljs-title class_">Fragment</span> f) =&gt; {
      <span class="hljs-keyword">await</span> context.<span class="hljs-property">Response</span>.<span class="hljs-title class_">WriteAsync</span>(
        $<span class="hljs-string">&quot;data: {f.Part}|{f.Content}{Environment.NewLine}{Environment.NewLine}&quot;</span>,
        cancellation
      );
      <span class="hljs-keyword">await</span> context.<span class="hljs-property">Response</span>.<span class="hljs-property">Body</span>.<span class="hljs-title class_">FlushAsync</span>(cancellation);
    }
  );
});
</code></pre>
<p>RecipeGenerator.GenerateAsync 메서드에는 메인 플로우가 포함되어 있어요:</p>
<pre><code class="hljs language-js"><span class="hljs-comment">/// &lt;summary&gt;</span>
<span class="hljs-comment">/// 주요 시작점</span>
<span class="hljs-comment">/// &lt;/summary&gt;</span>
public <span class="hljs-keyword">async</span> <span class="hljs-title class_">Task</span> <span class="hljs-title class_">GenerateAsync</span>(
  <span class="hljs-title class_">RecipeRequest</span> request,
  <span class="hljs-title class_">Func</span>&lt;<span class="hljs-title class_">Fragment</span>, <span class="hljs-title class_">Task</span>&gt; handler, <span class="hljs-comment">// 👈 이것은 HTTP 응답 스트림에 연결된 후크에요</span>
  <span class="hljs-title class_">CancellationToken</span> cancellation = <span class="hljs-keyword">default</span>
) {

  <span class="hljs-keyword">var</span> (ingredientsOnHand, prepTime) = request;

  <span class="hljs-comment">// 👇 (1) 3개의 레시피 목록을 생성하고 무작위로 하나를 선택</span>
  <span class="hljs-keyword">var</span> recipes = <span class="hljs-keyword">await</span> <span class="hljs-title class_">GenerateRecipesAsync</span>(ingredientsOnHand, prepTime, cancellation);

  <span class="hljs-title class_">Console</span>.<span class="hljs-title class_">WriteLine</span>($<span class="hljs-string">&quot;생성된 레시피 수: {recipes.Length}.&quot;</span>);

  <span class="hljs-keyword">var</span> recipe = recipes[<span class="hljs-title class_">Random</span>.<span class="hljs-property">Shared</span>.<span class="hljs-title class_">Next</span>(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>)];

  <span class="hljs-comment">// 👇 (2) 모든 레시피를 보유하여 HTML 문자열로 집계</span>
  <span class="hljs-keyword">var</span> alternates = recipes
    .<span class="hljs-title class_">Where</span>(<span class="hljs-function"><span class="hljs-params">r</span> =&gt;</span> r.<span class="hljs-property">Name</span> != recipe.<span class="hljs-property">Name</span>)
    .<span class="hljs-title class_">Aggregate</span>(<span class="hljs-keyword">new</span> <span class="hljs-title class_">StringBuilder</span>(), <span class="hljs-function">(<span class="hljs-params">html, r</span>) =&gt;</span> {
      html.<span class="hljs-title class_">Append</span>($<span class="hljs-string">&quot;&lt;li&gt;&lt;b&gt;{r.Name}&lt;/b&gt; &amp;nbsp;&quot;</span>);
      html.<span class="hljs-title class_">Append</span>($<span class="hljs-string">&quot;&lt;i&gt;{r.Intro}&lt;/i&gt;&lt;/li&gt;&quot;</span>);

      <span class="hljs-keyword">return</span> html;
    }).<span class="hljs-title class_">ToString</span>();

  <span class="hljs-comment">// 👇 (3) 읽기 채널의 리더 측에 대한 반복 작업입니다; 먼저 시작해야 해요</span>
  <span class="hljs-keyword">var</span> <span class="hljs-title function_">fragmentHandler</span> = <span class="hljs-keyword">async</span> (<span class="hljs-params"></span>) =&gt; {
    <span class="hljs-keyword">while</span> (<span class="hljs-keyword">await</span> _channel.<span class="hljs-property">Reader</span>.<span class="hljs-title class_">WaitToReadAsync</span>()) {
      <span class="hljs-keyword">if</span> (_channel.<span class="hljs-property">Reader</span>.<span class="hljs-title class_">TryRead</span>(out <span class="hljs-keyword">var</span> fragment)) {
        <span class="hljs-keyword">await</span> <span class="hljs-title function_">handler</span>(fragment);
      }
    }
  };

  <span class="hljs-keyword">var</span> completion = <span class="hljs-title function_">fragmentHandler</span>();

  <span class="hljs-comment">// 👇 (4) 이제 세대 프롬프트를 동시에 실행해요</span>
  <span class="hljs-title class_">Task</span>.<span class="hljs-title class_">WaitAll</span>([
    <span class="hljs-title function_">handler</span>(<span class="hljs-keyword">new</span> (<span class="hljs-string">&quot;alt&quot;</span>, alternates)),
    <span class="hljs-title class_">GenerateIngredientsAsync</span>(recipe, ingredientsOnHand, request.<span class="hljs-property">PrepTime</span>, cancellation),
    <span class="hljs-title class_">GenerateIntroAsync</span>(recipe, cancellation),
    <span class="hljs-title class_">GenerateIngredientIntroAsync</span>(ingredientsOnHand, cancellation),
    <span class="hljs-title class_">GenerateSidesAsync</span>(recipe, cancellation)
  ]);

  <span class="hljs-comment">// 👇 (5) 그리고 모든 작업이 완료될 때까지 기다려요.</span>
  _channel.<span class="hljs-property">Writer</span>.<span class="hljs-title class_">Complete</span>();

  <span class="hljs-keyword">await</span> completion;
}
</code></pre>
<p>여기서 Task.WaitAll의 중요한 차이점은 JavaScript의 Promise.all과 개념적으로 비슷하지만, .NET에서는 멀티 스레드인 .NET 런타임 때문에 동시성과 병렬로 실행될 수 있어요. 이 경우 스레드 풀 스케줄러가 각 작업이 다른 스레드에서 실행될지 여부를 결정할 거에요. 채널을 사용하면 출력을 하나의 스레드에 바인딩된 리더에 병합하여 동기화된 액세스가 필요 없어졌어요.</p>
<p>각 세대 작업은 비슷한 패턴을 따라가요:</p>
<pre><code class="hljs language-js">private <span class="hljs-keyword">async</span> <span class="hljs-title class_">Task</span> <span class="hljs-title class_">GenerateIntroAsync</span>(
  <span class="hljs-title class_">RecipeSummary</span> recipe,
  <span class="hljs-title class_">CancellationToken</span> cancellation = <span class="hljs-keyword">default</span>
) {
  <span class="hljs-keyword">var</span> prompt = <span class="hljs-string">&quot;...&quot;</span>;

  <span class="hljs-keyword">await</span> <span class="hljs-title class_">ExecutePromptAsync</span>(
    <span class="hljs-string">&quot;int&quot;</span>, <span class="hljs-comment">// 👈 이것은 프론트엔드 출력 대상의 ID와 일치합니다</span>
    prompt,
    <span class="hljs-keyword">new</span> () {
      <span class="hljs-title class_">MaxTokens</span> = <span class="hljs-number">250</span>,
      <span class="hljs-title class_">Temperature</span> = <span class="hljs-number">0.55</span>,
      <span class="hljs-title class_">TopP</span> = <span class="hljs-number">0</span>
    },
    <span class="hljs-attr">cancellation</span>: cancellation
  );
}
</code></pre>
<p>그리고 프롬프트를 실행하는 메서드:</p>
<pre><code class="hljs language-js"><span class="hljs-comment">/// &lt;summary&gt;</span>
<span class="hljs-comment">/// 프롬프트를 실행하고 결과를 채널에 작성합니다.</span>
<span class="hljs-comment">/// &lt;/summary&gt;</span>
private <span class="hljs-keyword">async</span> <span class="hljs-title class_">Task</span> <span class="hljs-title class_">ExecutePromptAsync</span>(
  string part,
  string prompt,
  <span class="hljs-title class_">OpenAIPromptExecutionSettings</span> settings,
  <span class="hljs-title class_">Action</span>&lt;string&gt;? resultHandler = <span class="hljs-literal">null</span>,
  string? modelOverride = <span class="hljs-literal">null</span>,
  <span class="hljs-title class_">CancellationToken</span> cancellation = <span class="hljs-keyword">default</span>
) {
  <span class="hljs-comment">// 👇 대화를 초기화합니다</span>
  <span class="hljs-keyword">var</span> chat = _kernel.<span class="hljs-property">GetRequiredService</span>&lt;<span class="hljs-title class_">IChatCompletionService</span>&gt;(
    modelOverride ?? <span class="hljs-string">&quot;70b&quot;</span> <span class="hljs-comment">// 명시된 오버라이드가 없으면 70b를 사용합니다.</span>
  );

  <span class="hljs-keyword">var</span> history = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ChatHistory</span>();
  <span class="hljs-keyword">var</span> buffer = <span class="hljs-keyword">new</span> <span class="hljs-title class_">StringBuilder</span>();

  history.<span class="hljs-title class_">AddUserMessage</span>(prompt);

  <span class="hljs-comment">// 👇 응답을 스트리밍하고 각 부분을 채널에 작성합니다</span>
  <span class="hljs-keyword">await</span> foreach (<span class="hljs-keyword">var</span> message <span class="hljs-keyword">in</span> chat.<span class="hljs-title class_">GetStreamingChatMessageContentsAsync</span>(
      history, settings, _kernel, cancellation
    )
  ) {
      <span class="hljs-keyword">await</span> _channel.<span class="hljs-property">Writer</span>.<span class="hljs-title class_">WriteAsync</span>( <span class="hljs-comment">// 👈 채널의 라이터 엔드</span>
        <span class="hljs-title function_">new</span>(part, message.<span class="hljs-property">Content</span> ?? <span class="hljs-string">&quot;&quot;</span>),
        cancellation
      );

      buffer.<span class="hljs-title class_">Append</span>(message.<span class="hljs-property">Content</span>); <span class="hljs-comment">// 👈 전체 출력을 보유하는 버퍼</span>
  }

  <span class="hljs-keyword">var</span> output = buffer.<span class="hljs-title class_">ToString</span>();

  <span class="hljs-comment">// 👇 호출자가 전체 결과를 원하는 경우 여기에서 사용할 수 있습니다</span>
  resultHandler?.<span class="hljs-title class_">Invoke</span>(output);
}
</code></pre>
<p>애플리케이션 실행 중 의존성 주입을 통해 커널 인스턴스가 구성됩니다:```</p>
<pre><code class="hljs language-js"><span class="hljs-comment">// Program.cs</span>
<span class="hljs-keyword">var</span> builder = <span class="hljs-title class_">WebApplication</span>.<span class="hljs-title class_">CreateBuilder</span>(args);

<span class="hljs-keyword">var</span> fireworksEndpoint = <span class="hljs-keyword">new</span> <span class="hljs-title class_">Uri</span>(<span class="hljs-string">&quot;https://api.fireworks.ai/inference/v1/chat/completions&quot;</span>);
<span class="hljs-keyword">var</span> groqEndpoint = <span class="hljs-keyword">new</span> <span class="hljs-title class_">Uri</span>(<span class="hljs-string">&quot;https://api.groq.com/openai/v1/chat/completions&quot;</span>);

<span class="hljs-keyword">var</span> config = builder.<span class="hljs-property">Configuration</span>
  .<span class="hljs-title class_">GetSection</span>(<span class="hljs-title function_">nameof</span>(<span class="hljs-title class_">RecipesConfig</span>))
  .<span class="hljs-property">Get</span>&lt;<span class="hljs-title class_">RecipesConfig</span>&gt;();

<span class="hljs-comment">// Semantic Kernel을 설정하여 필요한만큼의 LLM을 등록합니다.</span>
<span class="hljs-keyword">var</span> kernelBuilder = <span class="hljs-title class_">Kernel</span>.<span class="hljs-title class_">CreateBuilder</span>();
<span class="hljs-keyword">var</span> kernel = kernelBuilder
  .<span class="hljs-title class_">AddOpenAIChatCompletion</span>(
    <span class="hljs-attr">modelId</span>: <span class="hljs-string">&quot;accounts/fireworks/models/llama-v3-70b-instruct&quot;</span>,
    <span class="hljs-attr">apiKey</span>: config!.<span class="hljs-property">FireworksKey</span>,
    <span class="hljs-attr">endpoint</span>: fireworksEndpoint,
    <span class="hljs-attr">serviceId</span>: <span class="hljs-string">&quot;70b&quot;</span> <span class="hljs-comment">// 👈 더 나은 결과를 위해 기본적으로 이 serviceId를 사용합니다</span>
  )
  .<span class="hljs-title class_">AddOpenAIChatCompletion</span>(
    <span class="hljs-attr">modelId</span>: <span class="hljs-string">&quot;accounts/fireworks/models/llama-v3-8b-instruct&quot;</span>,
    <span class="hljs-attr">apiKey</span>: config!.<span class="hljs-property">FireworksKey</span>,
    <span class="hljs-attr">endpoint</span>: fireworksEndpoint,
    <span class="hljs-attr">serviceId</span>: <span class="hljs-string">&quot;8b&quot;</span> <span class="hljs-comment">// 👈 더 빠른 속도가 필요한 경우 이 serviceId를 사용합니다</span>
  )
  .<span class="hljs-title class_">AddOpenAIChatCompletion</span>(
    <span class="hljs-attr">modelId</span>: <span class="hljs-string">&quot;llama3-8b-8192&quot;</span>,
    <span class="hljs-attr">apiKey</span>: config!.<span class="hljs-property">GroqKey</span>,
    <span class="hljs-attr">endpoint</span>: groqEndpoint,
    <span class="hljs-attr">serviceId</span>: <span class="hljs-string">&quot;groq-8b&quot;</span> <span class="hljs-comment">// 👈 최대 처리량을 위해 이 serviceId를 사용합니다</span>
  )
  <span class="hljs-comment">// 다른 LLM을 여기에 등록합니다.</span>
  .<span class="hljs-title class_">Build</span>();

builder.<span class="hljs-property">Services</span>
  .<span class="hljs-property">Configure</span>&lt;<span class="hljs-title class_">RecipesConfig</span>&gt;(
    builder.<span class="hljs-property">Configuration</span>.<span class="hljs-title class_">GetSection</span>(<span class="hljs-title function_">nameof</span>(<span class="hljs-title class_">RecipesConfig</span>))
  )
  .<span class="hljs-title class_">AddCors</span>()
  .<span class="hljs-title class_">AddSingleton</span>(kernel)  <span class="hljs-comment">// 👈 설정된 kernel을 싱글톤으로 추가합니다</span>
  .<span class="hljs-property">AddScoped</span>&lt;<span class="hljs-title class_">RecipeGenerator</span>&gt;();
</code></pre>
<p>Semantic Kernel을 통해 여러 LLM 엔드포인트를 구성할 수 있습니다. 이를 사용하여 작은 빠른 LLM이 프로세스를 가속화할 수 있는 플로 구현을 단순화할 수 있습니다.</p>
<h1>SSE를 활용한 동시 스트림</h1>
<p>컨텐츠가 생성되면 백엔드는 즉시 프론트엔드로 스트리밍하여 매우 반응이 뛰어난 사용자 경험을 제공합니다. 이 과정은 동시에(그리고 스레드 풀 스케줄러에 따라 확장하여 병렬로) 발생하며, 채널에 수집되어 클라이언트에서 소비될 응답 스트림으로 작성됩니다.```</p>
<p>이 흐름을 시각화하기 위해 아래 다이어그램을 확인해보세요:</p>
<p><img src="/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_7.png" alt="다이어그램"/></p>
<p>Task.WaitAll 코드 블록은 채널의 공유 가능하고 스레드 안전한 writer 엔드를 전달받은 상태이며, reader 엔드는 HTTP 응답 스트림과 콜백을 통해 연결됩니다.</p>
<p>해당 콜백은 간단히 EventSource의 필요한 형식 명세에 따라 Fragment를 서식화합니다.</p>
<p>이 경우:</p>
<pre><code class="hljs language-js"><span class="hljs-attr">data</span>: ing|tomatoes

<span class="hljs-attr">data</span>: ing|basil

<span class="hljs-attr">data</span>: ste|<span class="hljs-number">3.</span> <span class="hljs-title class_">Chop</span> the
</code></pre>
<p>프론트엔드는 이러한 메시지 스트림을 받아 UI의 서로 다른 섹션에 누적합니다.</p>
<ul>
<li>첫 번째 부분인 ing은 이 내용이 속하는 프론트엔드 부분을 식별합니다 (이 경우에는 &quot;재료&quot;)</li>
<li>| 이후의 텍스트는 LLM에 의해 작성된 출력 토큰 세트를 의미합니다.</li>
</ul>
<p>프론트엔드에서 @microsoft/fetch-event-source는 기본 EventSource를 대체하여 POST 사용을 가능하게 하는 폴리필(polyfill)로 사용됩니다.</p>
<p>수신자는 각 메시지를 가져와 디코드합니다:</p>
<pre><code class="hljs language-js"><span class="hljs-attr">onmessage</span>: <span class="hljs-function">(<span class="hljs-params">msg</span>) =&gt;</span> {
  <span class="hljs-keyword">var</span> payload = msg.<span class="hljs-property">data</span>

  <span class="hljs-keyword">var</span> [part, content] = payload.<span class="hljs-title function_">split</span>(<span class="hljs-string">&#x27;|&#x27;</span>)

  <span class="hljs-keyword">if</span> (!part || !$el(<span class="hljs-string">`#<span class="hljs-subst">${part}</span>`</span>)) {
    <span class="hljs-keyword">return</span> <span class="hljs-comment">// 이 메시지는 버립니다</span>
  }

  <span class="hljs-comment">// 👇 이 부분은 새 줄을 인코딩하고 여기서 대체하는 해킹입니다.</span>
  content = content.<span class="hljs-title function_">replace</span>(<span class="hljs-regexp">/⮑/gi</span>, <span class="hljs-string">&quot;\n&quot;</span>)

  $el(<span class="hljs-string">`#<span class="hljs-subst">${part}</span>`</span>).<span class="hljs-property">innerHTML</span> += content
},
</code></pre>
<p>text/event-stream의 특이점은 이중 줄바꿈이 메시지 블록의 끝을 나타낸다는 것입니다. 그래서 줄바꿈은 어떤 방식으로든 인코딩되어야 합니다 (다양한 방법이 있습니다). 이 경우, 단일 문자 ⮑을 사용하여 해당 문자를 찾아 \n으로 대체하는 것이 간답습니다.</p>
<p>CSS는 그냥 이 부분을 고려하면 됩니다:</p>
<pre><code class="hljs language-js">#add, #ing, #ste {
  white-<span class="hljs-attr">space</span>: pre-line;
}
</code></pre>
<p>HTML 자체는 간단합니다:</p>
<pre><code class="hljs language-js">&lt;!-- 이 블록은 추가 재료를 보관합니다 --&gt;
<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;additional&quot;</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">h2</span>&gt;</span>필요한 재료<span class="hljs-tag">&lt;/<span class="hljs-name">h2</span>&gt;</span>
  <span class="hljs-comment">&lt;!-- 👇 이 ID는 Fragment.Part와 일치합니다 --&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;add&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span></span>

&lt;!-- 이 블록은 단계를 보관합니다 --&gt;
<span class="xml"><span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">class</span>=<span class="hljs-string">&quot;recipe&quot;</span>&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">h2</span>&gt;</span>조리 단계<span class="hljs-tag">&lt;/<span class="hljs-name">h2</span>&gt;</span>
  <span class="hljs-comment">&lt;!-- 👇 이 ID는 Fragment.Part와 일치합니다 --&gt;</span>
  <span class="hljs-tag">&lt;<span class="hljs-name">div</span> <span class="hljs-attr">id</span>=<span class="hljs-string">&quot;ste&quot;</span>&gt;</span><span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span>
<span class="hljs-tag">&lt;/<span class="hljs-name">div</span>&gt;</span></span>
</code></pre>
<h1>모두가 준비되었으니 이제 앱을 실행하면 다음과 같은 경험을 할 수 있습니다:</h1>
<p><img src="https://miro.medium.com/v2/resize:fit:1400/0*uCMJGy8UoyaC4rFX.gif" alt="recipe app"/></p>
<p>레시피 목록을 생성하는 호출이 차단되므로 약간의 초기 지연이 있습니다.</p>
<p>그러나 한 번 목록이 생성되고 무작위로 선택된 후, 추가적인 생성은 전체 재료 목록에 의해 차단되는 단계만 동시에 발생합니다. (전체 재료 목록을 사용하여 정확한 단계를 생성해야 하기 때문입니다).</p>
<h1>결론</h1>
<p>사용자 경험(UX)이 높은 처리량을 필요로 하며 작은 컨텍스트 창을 통해 작동할 수 있는 애플리케이션의 경우, Fireworks.ai와 Llama-3 8B/70B는 절대적으로 게임 체인저입니다. 그것은 팀이 OpenAI의 GPT 모델의 높은 지연 때문에 전반적인 UX를 희생시키지 않고 사용 사례에 대해 빌드할 수 있도록 해줍니다.</p>
<p>System.Threading.Channels를 사용한 .NET 8 웹 API에 그것을 플러그인하고 SSE와 결합하면, 여러 콘텐츠 청크를 동시에 생성하고, 상호작용적인 생성 AI 경험을 더 많이 구축하거나 생성적인 워크플로우를 간단히 가속화하는 새로운 가능성을 열 수 있습니다.</p>
<p>동일한 기술을 사용하면 (SSE를 제외하고) 낮은 지연 시간 + 높은 처리량 모델 및 플랫폼을 사용하여 여러 프롬프트를 병렬로 처리하여 서버 생성 워크로드의 처리량을 늘릴 수 있습니다.</p>
<p>전체 repository:</p></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"네이드 포 스피드 C, NET 8 SSE  채널을 활용한 LLMs Beyond OpenAI, Llama3 및 Fireworksai","description":"","date":"2024-05-13 00:03","slug":"2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai","content":"\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1400/1*YtK6hvB_PrUvd7uwqrk0-w.gif\" /\u003e\n\n# 요약\n\n- OpenAI의 GTP-4는 일반적인 목적의 작업에 있어 압도적인 성능을 보여주지만, 전체적인 처리량(또는 오히려 그 부족함)이 많이 부족하다는 점이 매우 아쉽습니다. 이는 \"오프라인\" 작업에는 훌륭하지만, 사용자들이 더 많은 응답성을 기대하는 응용 프로그램에서는 적합하지 않을 수 있으며, 몇몇 사용 사례들은 하위 UX로 인해 배제될 수도 있습니다.\n- TheFastest.ai 팀의 최근 Hackernews 게시물은 모델과 플랫폼 모두에 대해 이런 차이가 얼마나 클 수 있는지를 강조하고 있습니다. 특히, Groq.com(Musk의 Grok와 혼동하지 말아야 합니다)와 Meta의 Llama 3 70B를 사용한 Fireworks.ai는 일부 작업에서 GPT-4와 비교했을 때 출력에 거의 희생 없이 빠른 처리량을 제공합니다.\n- C#/.NET 8 System.Threading.Channels와 서버 전송 이벤트(SSE)를 결합하면, OpenAI의 처리량과 높은 지연 시간으로 잘 동작하지 않은 작업을 구성할 수 있습니다.\n\n# 소개\n\n\n\nGPT-5를 기다리는 동안, 2024년 5월 OpenAI의 GPT-4가 여전히 LLM으로서 전반적인 성능 면에서 우수하다는 것에 대해 논쟁하는 사람은 거의 없을 것입니다. 그러나 해당 모델은 비교적 낮은 처리량과 높은 대기 시간으로 인해 UX가 더 상호 작용적인 경험을 요구하는 경우에는 최적이 아닐 수 있습니다.\n\n가장 빠른 LLM과 현재 사용 가능한 플랫폼과 OpenAI 간의 대기 시간 차이의 규모가 얼마나 큰지는 명백하지 않을 수 있습니다.\n\n최근 Hackernews 스레드를 통해 TheFastest.ai로 이동하게 되었고, Meta의 Llama 3의 높은 처리량과 Groq.com 및 Fireworks.ai라는 두 플랫폼에 흥미로웠습니다.\n\n(전자는 종종 머스크의 Grok AI와 혼동되기 때문에 불행합니다).\n\n\n\n이 기사에서는 Fireworks.ai, Meta Llama 3 8B/70B, .NET 8, System.Threading.Channels 및 Server Sent Events (SSE)를 사용하여 앱을 만드는 방법을 살펴볼 것입니다.\n\n# 차이를 측정하기\n\n스택의 상단은 Llama-3과 Groq가 지배하고 Fireworks.ai가 상위 5위를 차지하고 있습니다(각 팀이 Fireworks를 선택해야 할 이유에 대해 조금 뒤에 설명하겠습니다).\n\n![이미지](/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_0.png)\n\n\n\n대조적으로, OpenAI의 GPT-4는 거의 맨 아래쪽에 위치합니다.\n\n![이미지](/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_1.png)\n\nOpenAI의 GPT-4를 사용해본 사람이라면 이미 처리량이 얼마나 낮은지를 알고 있을 것입니다. 하지만 이렇게 측정된 값을 보면 그 간격이 얼마나 큰지 더욱 부각됩니다. Groq의 Llama-3 70B는 GPT-4보다 거의 10배 더 높은 처리량을 가지고 있습니다!\n\n이에 따라, GPT-4는 상호 작용이 필요하지 않은 경우에, 작업이 큰 문맥 창을 요구하는 경우에, 또는 복잡한 프롬프트와 문맥을 사용하여 \"벤치마크 품질\"의 결과가 필요한 경우에 실제로 매우 좋다고 생각했습니다.\n\n\n\n하지만 사용 사례에 다른 요구 사항이 있는 경우는 어떨까요? 속도가 필요한 경우는 어떨까요?\n\n# Groq와 Fireworks를 이용해 시동 걸기\n\nOpenAI의 처리량이 떨어져 사용자 경험을 나빠지게 만들 수 있는 문제 중 하나는, 최종적으로 콘텐츠가 가치를 추가한다 해도 주관적으로 사용자 경험을 나빠지게 할 수 있다는 것입니다.\n\nOpenAI의 ChatGPT를 사용할 때, 채팅 응답에 몇 초가 걸릴 수도 있다는 사실을 SSE가 가려버리기 때문에 명확하게 드러나지 않을 수 있습니다. GPT-4의 처리량이 낮다는 것은 다른 대안을 시도해보기 전까지는 쉽게 알아챌 수 없습니다.\n\n\n\n# Groq.com\n\nGroq는 LLM에 특별히 설계된 사용자 정의 하드웨어로 알려진 \"LPU\" 또는 \"언어 처리 유닛\"을 갖춘 흥미로운 플랫폼입니다:\n\n적어도 문서로 보면, 이것은 마케팅 허세 이상으로 보이며 플랫폼은 객관적으로 고 처리량을 자랑합니다.\n\n하지만 주요 문제는 현재의 SaaS 제공으로 이어집니다:\n\n\n\n![이미지](/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_2.png)\n\n무료 티어는 실험 용도로만 사용 가능하며, 그것도 겨우 가능할 뿐입니다.\n\n![이미지](/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_3.png)\n\n그래서 Groq은 꽤 빠르지만, 샌드박싱 용도 외에는 사용할 수 없으며, 가능하다면 엔터프라이즈 과금을 통해 사용할 수 있습니다.\n\n\n\n# Fireworks.ai\n\n현재 시점에서 Fireworks의 Llama-3 70B는 전체적으로 9위에 랭크되어 있으며 두 번째로 빠른 Llama-3 70B입니다:\n\n![이미지](/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_4.png)\n\n마지막 토큰까지 260ms가 소요되며, 여전히 매우 빠르며 GPT-3.5와 GPT-4 사이의 성능을 제공하여 내 사용 사례에 대한 LLM 성능이 매우 좋습니다.\n\n\n\nFireworks.ai에는 중간 유료 티어가 없지만, 600 RPM은 작은 앱에 사용하기 적합하며 하드 토큰 제한이 없습니다.\n\n![이미지](/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_5.png)\n\n오늘 빠르게 무언가를 구축하려는 팀들에게는 Fireworks.ai가 아마도 최선의 선택일 것입니다. (아니, 나는 그들로부터 돈을 받고 있지 않아요)\n\n# .NET 8, System.Threading.Channels 및 Server Sent Events (SSE)와 함께 실용적인 예제\n\n\n\n이 놀라운 처리량을 활용하기 위해서는 한 번에 여러 개의 스트림을 통해 생성한 다음 하나의 최종 출력 스트림으로 병합하는 동시 처리 전략이 필요합니다.\n\n이는 .NET의 System.Threading.Channels를 Server Sent Events (SSE)와 결합하여 이 처리량을 완전히 활용하고 높은 반응성을 갖는 생성 AI 경험을 구축하는 완벽한 사용 사례입니다.\n\n이전에 이 두 주제에 대해 별도로 다뤘었습니다:\n\n- .NET Task Parallel Library vs System.Threading.Channels\n- .NET 6의 System.Threading.Channels를 이용한 동시 처리 (보너스: 간격 트리)\n- .NET 7과 함께하는 Server Sent Events\n\n\n\n오늘은 .NET 8 채널, Semantic Kernel 및 gen AI와 함께 어떤 대화형 경험을 만들 수 있는지 함께 살펴보겠습니다!\n\n![image](/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_6.png)\n\n저희 샘플 응용 프로그램은 준비된 재료 목록과 목표 조리 시간을 받아들여서 다음을 할 것입니다:\n\n- 해당 재료로 만들 수 있는 레시피 목록 생성\n- 레시피 중 하나를 무작위로 선택\n- 레시피를 위해 필요한 모든 재료 목록 생성\n- 레시피를 위한 소개 단락 생성\n- 준비된 각 재료에 대한 영양 정보에 대한 간략한 설명 생성\n- 제안된 사이드 디시 목록 생성\n- 순서 목록 생성\n\n\n\n단계 3~6은 병렬로 실행될 수 있지만, 레시피를 먼저 선택해야 하기 때문에 단계 1~2가 먼저 실행됩니다. 그리고 단계를 생성하기 전에 재료 전체 목록을 기다려야 합니다.\n\n# .NET 채널을 이용한 병행 실행\n\nAPI 호출의 진입점은 요청을 받을 단일 POST 엔드포인트입니다:\n\n```js\n// 👇 메인 진입점.\napp.MapPost(\"/generate\", async (\n  HttpContext context,          // 의존성 주입에서 가져옴\n  RecipeGenerator generator,    // 의존성 주입에서 가져옴\n  RecipeRequest request,        // 바디에서 가져옴\n  CancellationToken cancellation = default\n) =\u003e\n{\n  context.Response.Headers.ContentType = \"text/event-stream\";\n\n  await generator.GenerateAsync(\n    request,\n    // 각 단편에 대한 스트리밍 응답을 작성하는 핸들러\n    async (Fragment f) =\u003e {\n      await context.Response.WriteAsync(\n        $\"data: {f.Part}|{f.Content}{Environment.NewLine}{Environment.NewLine}\",\n        cancellation\n      );\n      await context.Response.Body.FlushAsync(cancellation);\n    }\n  );\n});\n```\n\n\n\nRecipeGenerator.GenerateAsync 메서드에는 메인 플로우가 포함되어 있어요:\n\n```js\n/// \u003csummary\u003e\n/// 주요 시작점\n/// \u003c/summary\u003e\npublic async Task GenerateAsync(\n  RecipeRequest request,\n  Func\u003cFragment, Task\u003e handler, // 👈 이것은 HTTP 응답 스트림에 연결된 후크에요\n  CancellationToken cancellation = default\n) {\n\n  var (ingredientsOnHand, prepTime) = request;\n\n  // 👇 (1) 3개의 레시피 목록을 생성하고 무작위로 하나를 선택\n  var recipes = await GenerateRecipesAsync(ingredientsOnHand, prepTime, cancellation);\n\n  Console.WriteLine($\"생성된 레시피 수: {recipes.Length}.\");\n\n  var recipe = recipes[Random.Shared.Next(0, 2)];\n\n  // 👇 (2) 모든 레시피를 보유하여 HTML 문자열로 집계\n  var alternates = recipes\n    .Where(r =\u003e r.Name != recipe.Name)\n    .Aggregate(new StringBuilder(), (html, r) =\u003e {\n      html.Append($\"\u003cli\u003e\u003cb\u003e{r.Name}\u003c/b\u003e \u0026nbsp;\");\n      html.Append($\"\u003ci\u003e{r.Intro}\u003c/i\u003e\u003c/li\u003e\");\n\n      return html;\n    }).ToString();\n\n  // 👇 (3) 읽기 채널의 리더 측에 대한 반복 작업입니다; 먼저 시작해야 해요\n  var fragmentHandler = async () =\u003e {\n    while (await _channel.Reader.WaitToReadAsync()) {\n      if (_channel.Reader.TryRead(out var fragment)) {\n        await handler(fragment);\n      }\n    }\n  };\n\n  var completion = fragmentHandler();\n\n  // 👇 (4) 이제 세대 프롬프트를 동시에 실행해요\n  Task.WaitAll([\n    handler(new (\"alt\", alternates)),\n    GenerateIngredientsAsync(recipe, ingredientsOnHand, request.PrepTime, cancellation),\n    GenerateIntroAsync(recipe, cancellation),\n    GenerateIngredientIntroAsync(ingredientsOnHand, cancellation),\n    GenerateSidesAsync(recipe, cancellation)\n  ]);\n\n  // 👇 (5) 그리고 모든 작업이 완료될 때까지 기다려요.\n  _channel.Writer.Complete();\n\n  await completion;\n}\n```\n\n여기서 Task.WaitAll의 중요한 차이점은 JavaScript의 Promise.all과 개념적으로 비슷하지만, .NET에서는 멀티 스레드인 .NET 런타임 때문에 동시성과 병렬로 실행될 수 있어요. 이 경우 스레드 풀 스케줄러가 각 작업이 다른 스레드에서 실행될지 여부를 결정할 거에요. 채널을 사용하면 출력을 하나의 스레드에 바인딩된 리더에 병합하여 동기화된 액세스가 필요 없어졌어요.\n\n각 세대 작업은 비슷한 패턴을 따라가요:\n\n\n\n```js\nprivate async Task GenerateIntroAsync(\n  RecipeSummary recipe,\n  CancellationToken cancellation = default\n) {\n  var prompt = \"...\";\n\n  await ExecutePromptAsync(\n    \"int\", // 👈 이것은 프론트엔드 출력 대상의 ID와 일치합니다\n    prompt,\n    new () {\n      MaxTokens = 250,\n      Temperature = 0.55,\n      TopP = 0\n    },\n    cancellation: cancellation\n  );\n}\n```\n\n그리고 프롬프트를 실행하는 메서드:\n\n```js\n/// \u003csummary\u003e\n/// 프롬프트를 실행하고 결과를 채널에 작성합니다.\n/// \u003c/summary\u003e\nprivate async Task ExecutePromptAsync(\n  string part,\n  string prompt,\n  OpenAIPromptExecutionSettings settings,\n  Action\u003cstring\u003e? resultHandler = null,\n  string? modelOverride = null,\n  CancellationToken cancellation = default\n) {\n  // 👇 대화를 초기화합니다\n  var chat = _kernel.GetRequiredService\u003cIChatCompletionService\u003e(\n    modelOverride ?? \"70b\" // 명시된 오버라이드가 없으면 70b를 사용합니다.\n  );\n\n  var history = new ChatHistory();\n  var buffer = new StringBuilder();\n\n  history.AddUserMessage(prompt);\n\n  // 👇 응답을 스트리밍하고 각 부분을 채널에 작성합니다\n  await foreach (var message in chat.GetStreamingChatMessageContentsAsync(\n      history, settings, _kernel, cancellation\n    )\n  ) {\n      await _channel.Writer.WriteAsync( // 👈 채널의 라이터 엔드\n        new(part, message.Content ?? \"\"),\n        cancellation\n      );\n\n      buffer.Append(message.Content); // 👈 전체 출력을 보유하는 버퍼\n  }\n\n  var output = buffer.ToString();\n\n  // 👇 호출자가 전체 결과를 원하는 경우 여기에서 사용할 수 있습니다\n  resultHandler?.Invoke(output);\n}\n```\n\n애플리케이션 실행 중 의존성 주입을 통해 커널 인스턴스가 구성됩니다:```\n\n\n\n```js\r\n// Program.cs\nvar builder = WebApplication.CreateBuilder(args);\n\nvar fireworksEndpoint = new Uri(\"https://api.fireworks.ai/inference/v1/chat/completions\");\nvar groqEndpoint = new Uri(\"https://api.groq.com/openai/v1/chat/completions\");\n\nvar config = builder.Configuration\n  .GetSection(nameof(RecipesConfig))\n  .Get\u003cRecipesConfig\u003e();\n\n// Semantic Kernel을 설정하여 필요한만큼의 LLM을 등록합니다.\nvar kernelBuilder = Kernel.CreateBuilder();\nvar kernel = kernelBuilder\n  .AddOpenAIChatCompletion(\n    modelId: \"accounts/fireworks/models/llama-v3-70b-instruct\",\n    apiKey: config!.FireworksKey,\n    endpoint: fireworksEndpoint,\n    serviceId: \"70b\" // 👈 더 나은 결과를 위해 기본적으로 이 serviceId를 사용합니다\n  )\n  .AddOpenAIChatCompletion(\n    modelId: \"accounts/fireworks/models/llama-v3-8b-instruct\",\n    apiKey: config!.FireworksKey,\n    endpoint: fireworksEndpoint,\n    serviceId: \"8b\" // 👈 더 빠른 속도가 필요한 경우 이 serviceId를 사용합니다\n  )\n  .AddOpenAIChatCompletion(\n    modelId: \"llama3-8b-8192\",\n    apiKey: config!.GroqKey,\n    endpoint: groqEndpoint,\n    serviceId: \"groq-8b\" // 👈 최대 처리량을 위해 이 serviceId를 사용합니다\n  )\n  // 다른 LLM을 여기에 등록합니다.\n  .Build();\n\nbuilder.Services\n  .Configure\u003cRecipesConfig\u003e(\n    builder.Configuration.GetSection(nameof(RecipesConfig))\n  )\n  .AddCors()\n  .AddSingleton(kernel)  // 👈 설정된 kernel을 싱글톤으로 추가합니다\n  .AddScoped\u003cRecipeGenerator\u003e();\r\n```\n\nSemantic Kernel을 통해 여러 LLM 엔드포인트를 구성할 수 있습니다. 이를 사용하여 작은 빠른 LLM이 프로세스를 가속화할 수 있는 플로 구현을 단순화할 수 있습니다.\n\n# SSE를 활용한 동시 스트림\n\n컨텐츠가 생성되면 백엔드는 즉시 프론트엔드로 스트리밍하여 매우 반응이 뛰어난 사용자 경험을 제공합니다. 이 과정은 동시에(그리고 스레드 풀 스케줄러에 따라 확장하여 병렬로) 발생하며, 채널에 수집되어 클라이언트에서 소비될 응답 스트림으로 작성됩니다.```\n\n\n\n이 흐름을 시각화하기 위해 아래 다이어그램을 확인해보세요:\n\n![다이어그램](/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_7.png)\n\nTask.WaitAll 코드 블록은 채널의 공유 가능하고 스레드 안전한 writer 엔드를 전달받은 상태이며, reader 엔드는 HTTP 응답 스트림과 콜백을 통해 연결됩니다.\n\n해당 콜백은 간단히 EventSource의 필요한 형식 명세에 따라 Fragment를 서식화합니다.\n\n\n\n이 경우:\n\n```js\ndata: ing|tomatoes\n\ndata: ing|basil\n\ndata: ste|3. Chop the\n```\n\n프론트엔드는 이러한 메시지 스트림을 받아 UI의 서로 다른 섹션에 누적합니다.\n\n- 첫 번째 부분인 ing은 이 내용이 속하는 프론트엔드 부분을 식별합니다 (이 경우에는 \"재료\")\n- | 이후의 텍스트는 LLM에 의해 작성된 출력 토큰 세트를 의미합니다.\n\n\n\n프론트엔드에서 @microsoft/fetch-event-source는 기본 EventSource를 대체하여 POST 사용을 가능하게 하는 폴리필(polyfill)로 사용됩니다.\n\n수신자는 각 메시지를 가져와 디코드합니다:\n\n```js\nonmessage: (msg) =\u003e {\n  var payload = msg.data\n\n  var [part, content] = payload.split('|')\n\n  if (!part || !$el(`#${part}`)) {\n    return // 이 메시지는 버립니다\n  }\n\n  // 👇 이 부분은 새 줄을 인코딩하고 여기서 대체하는 해킹입니다.\n  content = content.replace(/⮑/gi, \"\\n\")\n\n  $el(`#${part}`).innerHTML += content\n},\n```\n\ntext/event-stream의 특이점은 이중 줄바꿈이 메시지 블록의 끝을 나타낸다는 것입니다. 그래서 줄바꿈은 어떤 방식으로든 인코딩되어야 합니다 (다양한 방법이 있습니다). 이 경우, 단일 문자 ⮑을 사용하여 해당 문자를 찾아 \\n으로 대체하는 것이 간답습니다.\n\n\n\nCSS는 그냥 이 부분을 고려하면 됩니다:\n\n```js\n#add, #ing, #ste {\n  white-space: pre-line;\n}\n```\n\nHTML 자체는 간단합니다:\n\n```js\n\u003c!-- 이 블록은 추가 재료를 보관합니다 --\u003e\n\u003cdiv class=\"additional\"\u003e\n  \u003ch2\u003e필요한 재료\u003c/h2\u003e\n  \u003c!-- 👇 이 ID는 Fragment.Part와 일치합니다 --\u003e\n  \u003cdiv id=\"add\"\u003e\u003c/div\u003e\n\u003c/div\u003e\n\n\u003c!-- 이 블록은 단계를 보관합니다 --\u003e\n\u003cdiv class=\"recipe\"\u003e\n  \u003ch2\u003e조리 단계\u003c/h2\u003e\n  \u003c!-- 👇 이 ID는 Fragment.Part와 일치합니다 --\u003e\n  \u003cdiv id=\"ste\"\u003e\u003c/div\u003e\n\u003c/div\u003e\n```\n\n\n\n# 모두가 준비되었으니 이제 앱을 실행하면 다음과 같은 경험을 할 수 있습니다:\n\n![recipe app](https://miro.medium.com/v2/resize:fit:1400/0*uCMJGy8UoyaC4rFX.gif)\n\n레시피 목록을 생성하는 호출이 차단되므로 약간의 초기 지연이 있습니다.\n\n\n\n그러나 한 번 목록이 생성되고 무작위로 선택된 후, 추가적인 생성은 전체 재료 목록에 의해 차단되는 단계만 동시에 발생합니다. (전체 재료 목록을 사용하여 정확한 단계를 생성해야 하기 때문입니다).\n\n# 결론\n\n사용자 경험(UX)이 높은 처리량을 필요로 하며 작은 컨텍스트 창을 통해 작동할 수 있는 애플리케이션의 경우, Fireworks.ai와 Llama-3 8B/70B는 절대적으로 게임 체인저입니다. 그것은 팀이 OpenAI의 GPT 모델의 높은 지연 때문에 전반적인 UX를 희생시키지 않고 사용 사례에 대해 빌드할 수 있도록 해줍니다.\n\nSystem.Threading.Channels를 사용한 .NET 8 웹 API에 그것을 플러그인하고 SSE와 결합하면, 여러 콘텐츠 청크를 동시에 생성하고, 상호작용적인 생성 AI 경험을 더 많이 구축하거나 생성적인 워크플로우를 간단히 가속화하는 새로운 가능성을 열 수 있습니다.\n\n\n\n동일한 기술을 사용하면 (SSE를 제외하고) 낮은 지연 시간 + 높은 처리량 모델 및 플랫폼을 사용하여 여러 프롬프트를 병렬로 처리하여 서버 생성 워크로드의 처리량을 늘릴 수 있습니다.\n\n전체 repository:","ogImage":{"url":"/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_0.png"},"coverImage":"/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_0.png","tag":["Tech"],"readingTime":13},"content":{"compiledSource":"/*@jsxRuntime automatic @jsxImportSource react*/\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = Object.assign({\n    h1: \"h1\",\n    ul: \"ul\",\n    li: \"li\",\n    p: \"p\",\n    img: \"img\",\n    pre: \"pre\",\n    code: \"code\",\n    span: \"span\"\n  }, _provideComponents(), props.components);\n  return _jsxs(_Fragment, {\n    children: [_jsx(\"img\", {\n      src: \"https://miro.medium.com/v2/resize:fit:1400/1*YtK6hvB_PrUvd7uwqrk0-w.gif\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"요약\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"OpenAI의 GTP-4는 일반적인 목적의 작업에 있어 압도적인 성능을 보여주지만, 전체적인 처리량(또는 오히려 그 부족함)이 많이 부족하다는 점이 매우 아쉽습니다. 이는 \\\"오프라인\\\" 작업에는 훌륭하지만, 사용자들이 더 많은 응답성을 기대하는 응용 프로그램에서는 적합하지 않을 수 있으며, 몇몇 사용 사례들은 하위 UX로 인해 배제될 수도 있습니다.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"TheFastest.ai 팀의 최근 Hackernews 게시물은 모델과 플랫폼 모두에 대해 이런 차이가 얼마나 클 수 있는지를 강조하고 있습니다. 특히, Groq.com(Musk의 Grok와 혼동하지 말아야 합니다)와 Meta의 Llama 3 70B를 사용한 Fireworks.ai는 일부 작업에서 GPT-4와 비교했을 때 출력에 거의 희생 없이 빠른 처리량을 제공합니다.\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"C#/.NET 8 System.Threading.Channels와 서버 전송 이벤트(SSE)를 결합하면, OpenAI의 처리량과 높은 지연 시간으로 잘 동작하지 않은 작업을 구성할 수 있습니다.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"소개\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"GPT-5를 기다리는 동안, 2024년 5월 OpenAI의 GPT-4가 여전히 LLM으로서 전반적인 성능 면에서 우수하다는 것에 대해 논쟁하는 사람은 거의 없을 것입니다. 그러나 해당 모델은 비교적 낮은 처리량과 높은 대기 시간으로 인해 UX가 더 상호 작용적인 경험을 요구하는 경우에는 최적이 아닐 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"가장 빠른 LLM과 현재 사용 가능한 플랫폼과 OpenAI 간의 대기 시간 차이의 규모가 얼마나 큰지는 명백하지 않을 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"최근 Hackernews 스레드를 통해 TheFastest.ai로 이동하게 되었고, Meta의 Llama 3의 높은 처리량과 Groq.com 및 Fireworks.ai라는 두 플랫폼에 흥미로웠습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"(전자는 종종 머스크의 Grok AI와 혼동되기 때문에 불행합니다).\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 기사에서는 Fireworks.ai, Meta Llama 3 8B/70B, .NET 8, System.Threading.Channels 및 Server Sent Events (SSE)를 사용하여 앱을 만드는 방법을 살펴볼 것입니다.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"차이를 측정하기\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"스택의 상단은 Llama-3과 Groq가 지배하고 Fireworks.ai가 상위 5위를 차지하고 있습니다(각 팀이 Fireworks를 선택해야 할 이유에 대해 조금 뒤에 설명하겠습니다).\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_0.png\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"대조적으로, OpenAI의 GPT-4는 거의 맨 아래쪽에 위치합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_1.png\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"OpenAI의 GPT-4를 사용해본 사람이라면 이미 처리량이 얼마나 낮은지를 알고 있을 것입니다. 하지만 이렇게 측정된 값을 보면 그 간격이 얼마나 큰지 더욱 부각됩니다. Groq의 Llama-3 70B는 GPT-4보다 거의 10배 더 높은 처리량을 가지고 있습니다!\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이에 따라, GPT-4는 상호 작용이 필요하지 않은 경우에, 작업이 큰 문맥 창을 요구하는 경우에, 또는 복잡한 프롬프트와 문맥을 사용하여 \\\"벤치마크 품질\\\"의 결과가 필요한 경우에 실제로 매우 좋다고 생각했습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"하지만 사용 사례에 다른 요구 사항이 있는 경우는 어떨까요? 속도가 필요한 경우는 어떨까요?\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Groq와 Fireworks를 이용해 시동 걸기\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"OpenAI의 처리량이 떨어져 사용자 경험을 나빠지게 만들 수 있는 문제 중 하나는, 최종적으로 콘텐츠가 가치를 추가한다 해도 주관적으로 사용자 경험을 나빠지게 할 수 있다는 것입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"OpenAI의 ChatGPT를 사용할 때, 채팅 응답에 몇 초가 걸릴 수도 있다는 사실을 SSE가 가려버리기 때문에 명확하게 드러나지 않을 수 있습니다. GPT-4의 처리량이 낮다는 것은 다른 대안을 시도해보기 전까지는 쉽게 알아챌 수 없습니다.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Groq.com\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Groq는 LLM에 특별히 설계된 사용자 정의 하드웨어로 알려진 \\\"LPU\\\" 또는 \\\"언어 처리 유닛\\\"을 갖춘 흥미로운 플랫폼입니다:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"적어도 문서로 보면, 이것은 마케팅 허세 이상으로 보이며 플랫폼은 객관적으로 고 처리량을 자랑합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"하지만 주요 문제는 현재의 SaaS 제공으로 이어집니다:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_2.png\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"무료 티어는 실험 용도로만 사용 가능하며, 그것도 겨우 가능할 뿐입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_3.png\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"그래서 Groq은 꽤 빠르지만, 샌드박싱 용도 외에는 사용할 수 없으며, 가능하다면 엔터프라이즈 과금을 통해 사용할 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"Fireworks.ai\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"현재 시점에서 Fireworks의 Llama-3 70B는 전체적으로 9위에 랭크되어 있으며 두 번째로 빠른 Llama-3 70B입니다:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_4.png\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"마지막 토큰까지 260ms가 소요되며, 여전히 매우 빠르며 GPT-3.5와 GPT-4 사이의 성능을 제공하여 내 사용 사례에 대한 LLM 성능이 매우 좋습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Fireworks.ai에는 중간 유료 티어가 없지만, 600 RPM은 작은 앱에 사용하기 적합하며 하드 토큰 제한이 없습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_5.png\",\n        alt: \"이미지\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"오늘 빠르게 무언가를 구축하려는 팀들에게는 Fireworks.ai가 아마도 최선의 선택일 것입니다. (아니, 나는 그들로부터 돈을 받고 있지 않아요)\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \".NET 8, System.Threading.Channels 및 Server Sent Events (SSE)와 함께 실용적인 예제\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 놀라운 처리량을 활용하기 위해서는 한 번에 여러 개의 스트림을 통해 생성한 다음 하나의 최종 출력 스트림으로 병합하는 동시 처리 전략이 필요합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이는 .NET의 System.Threading.Channels를 Server Sent Events (SSE)와 결합하여 이 처리량을 완전히 활용하고 높은 반응성을 갖는 생성 AI 경험을 구축하는 완벽한 사용 사례입니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이전에 이 두 주제에 대해 별도로 다뤘었습니다:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \".NET Task Parallel Library vs System.Threading.Channels\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \".NET 6의 System.Threading.Channels를 이용한 동시 처리 (보너스: 간격 트리)\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \".NET 7과 함께하는 Server Sent Events\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"오늘은 .NET 8 채널, Semantic Kernel 및 gen AI와 함께 어떤 대화형 경험을 만들 수 있는지 함께 살펴보겠습니다!\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_6.png\",\n        alt: \"image\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"저희 샘플 응용 프로그램은 준비된 재료 목록과 목표 조리 시간을 받아들여서 다음을 할 것입니다:\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"해당 재료로 만들 수 있는 레시피 목록 생성\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"레시피 중 하나를 무작위로 선택\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"레시피를 위해 필요한 모든 재료 목록 생성\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"레시피를 위한 소개 단락 생성\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"준비된 각 재료에 대한 영양 정보에 대한 간략한 설명 생성\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"제안된 사이드 디시 목록 생성\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"순서 목록 생성\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"단계 3~6은 병렬로 실행될 수 있지만, 레시피를 먼저 선택해야 하기 때문에 단계 1~2가 먼저 실행됩니다. 그리고 단계를 생성하기 전에 재료 전체 목록을 기다려야 합니다.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \".NET 채널을 이용한 병행 실행\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"API 호출의 진입점은 요청을 받을 단일 POST 엔드포인트입니다:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 👇 메인 진입점.\"\n        }), \"\\napp.\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"MapPost\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"/generate\\\"\"\n        }), \", \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"async\"\n        }), \" (\\n  \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"HttpContext\"\n        }), \" context,          \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 의존성 주입에서 가져옴\"\n        }), \"\\n  \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"RecipeGenerator\"\n        }), \" generator,    \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 의존성 주입에서 가져옴\"\n        }), \"\\n  \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"RecipeRequest\"\n        }), \" request,        \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 바디에서 가져옴\"\n        }), \"\\n  \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"CancellationToken\"\n        }), \" cancellation = \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"default\"\n        }), \"\\n) =\u003e\\n{\\n  context.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Response\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Headers\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"ContentType\"\n        }), \" = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"text/event-stream\\\"\"\n        }), \";\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"await\"\n        }), \" generator.\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"GenerateAsync\"\n        }), \"(\\n    request,\\n    \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 각 단편에 대한 스트리밍 응답을 작성하는 핸들러\"\n        }), \"\\n    \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"async\"\n        }), \" (\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Fragment\"\n        }), \" f) =\u003e {\\n      \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"await\"\n        }), \" context.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Response\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"WriteAsync\"\n        }), \"(\\n        $\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"data: {f.Part}|{f.Content}{Environment.NewLine}{Environment.NewLine}\\\"\"\n        }), \",\\n        cancellation\\n      );\\n      \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"await\"\n        }), \" context.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Response\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Body\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"FlushAsync\"\n        }), \"(cancellation);\\n    }\\n  );\\n});\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"RecipeGenerator.GenerateAsync 메서드에는 메인 플로우가 포함되어 있어요:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"/// \u003csummary\u003e\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"/// 주요 시작점\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"/// \u003c/summary\u003e\"\n        }), \"\\npublic \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"async\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Task\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"GenerateAsync\"\n        }), \"(\\n  \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"RecipeRequest\"\n        }), \" request,\\n  \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Func\"\n        }), \"\u003c\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Fragment\"\n        }), \", \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Task\"\n        }), \"\u003e handler, \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 👈 이것은 HTTP 응답 스트림에 연결된 후크에요\"\n        }), \"\\n  \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"CancellationToken\"\n        }), \" cancellation = \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"default\"\n        }), \"\\n) {\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" (ingredientsOnHand, prepTime) = request;\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 👇 (1) 3개의 레시피 목록을 생성하고 무작위로 하나를 선택\"\n        }), \"\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" recipes = \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"await\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"GenerateRecipesAsync\"\n        }), \"(ingredientsOnHand, prepTime, cancellation);\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Console\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"WriteLine\"\n        }), \"($\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"생성된 레시피 수: {recipes.Length}.\\\"\"\n        }), \");\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" recipe = recipes[\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Random\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Shared\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Next\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \", \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"2\"\n        }), \")];\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 👇 (2) 모든 레시피를 보유하여 HTML 문자열로 집계\"\n        }), \"\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" alternates = recipes\\n    .\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Where\"\n        }), \"(\", _jsxs(_components.span, {\n          className: \"hljs-function\",\n          children: [_jsx(_components.span, {\n            className: \"hljs-params\",\n            children: \"r\"\n          }), \" =\u003e\"]\n        }), \" r.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Name\"\n        }), \" != recipe.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Name\"\n        }), \")\\n    .\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Aggregate\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"new\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"StringBuilder\"\n        }), \"(), \", _jsxs(_components.span, {\n          className: \"hljs-function\",\n          children: [\"(\", _jsx(_components.span, {\n            className: \"hljs-params\",\n            children: \"html, r\"\n          }), \") =\u003e\"]\n        }), \" {\\n      html.\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Append\"\n        }), \"($\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"\u003cli\u003e\u003cb\u003e{r.Name}\u003c/b\u003e \u0026nbsp;\\\"\"\n        }), \");\\n      html.\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Append\"\n        }), \"($\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"\u003ci\u003e{r.Intro}\u003c/i\u003e\u003c/li\u003e\\\"\"\n        }), \");\\n\\n      \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"return\"\n        }), \" html;\\n    }).\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"ToString\"\n        }), \"();\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 👇 (3) 읽기 채널의 리더 측에 대한 반복 작업입니다; 먼저 시작해야 해요\"\n        }), \"\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"fragmentHandler\"\n        }), \" = \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"async\"\n        }), \" (\", _jsx(_components.span, {\n          className: \"hljs-params\"\n        }), \") =\u003e {\\n    \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"while\"\n        }), \" (\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"await\"\n        }), \" _channel.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Reader\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"WaitToReadAsync\"\n        }), \"()) {\\n      \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"if\"\n        }), \" (_channel.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Reader\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"TryRead\"\n        }), \"(out \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" fragment)) {\\n        \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"await\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"handler\"\n        }), \"(fragment);\\n      }\\n    }\\n  };\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" completion = \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"fragmentHandler\"\n        }), \"();\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 👇 (4) 이제 세대 프롬프트를 동시에 실행해요\"\n        }), \"\\n  \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Task\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"WaitAll\"\n        }), \"([\\n    \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"handler\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"new\"\n        }), \" (\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"alt\\\"\"\n        }), \", alternates)),\\n    \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"GenerateIngredientsAsync\"\n        }), \"(recipe, ingredientsOnHand, request.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"PrepTime\"\n        }), \", cancellation),\\n    \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"GenerateIntroAsync\"\n        }), \"(recipe, cancellation),\\n    \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"GenerateIngredientIntroAsync\"\n        }), \"(ingredientsOnHand, cancellation),\\n    \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"GenerateSidesAsync\"\n        }), \"(recipe, cancellation)\\n  ]);\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 👇 (5) 그리고 모든 작업이 완료될 때까지 기다려요.\"\n        }), \"\\n  _channel.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Writer\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Complete\"\n        }), \"();\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"await\"\n        }), \" completion;\\n}\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"여기서 Task.WaitAll의 중요한 차이점은 JavaScript의 Promise.all과 개념적으로 비슷하지만, .NET에서는 멀티 스레드인 .NET 런타임 때문에 동시성과 병렬로 실행될 수 있어요. 이 경우 스레드 풀 스케줄러가 각 작업이 다른 스레드에서 실행될지 여부를 결정할 거에요. 채널을 사용하면 출력을 하나의 스레드에 바인딩된 리더에 병합하여 동기화된 액세스가 필요 없어졌어요.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"각 세대 작업은 비슷한 패턴을 따라가요:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [\"private \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"async\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Task\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"GenerateIntroAsync\"\n        }), \"(\\n  \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"RecipeSummary\"\n        }), \" recipe,\\n  \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"CancellationToken\"\n        }), \" cancellation = \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"default\"\n        }), \"\\n) {\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" prompt = \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"...\\\"\"\n        }), \";\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"await\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"ExecutePromptAsync\"\n        }), \"(\\n    \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"int\\\"\"\n        }), \", \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 👈 이것은 프론트엔드 출력 대상의 ID와 일치합니다\"\n        }), \"\\n    prompt,\\n    \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"new\"\n        }), \" () {\\n      \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"MaxTokens\"\n        }), \" = \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"250\"\n        }), \",\\n      \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Temperature\"\n        }), \" = \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0.55\"\n        }), \",\\n      \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"TopP\"\n        }), \" = \", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"0\"\n        }), \"\\n    },\\n    \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"cancellation\"\n        }), \": cancellation\\n  );\\n}\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"그리고 프롬프트를 실행하는 메서드:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"/// \u003csummary\u003e\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"/// 프롬프트를 실행하고 결과를 채널에 작성합니다.\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"/// \u003c/summary\u003e\"\n        }), \"\\nprivate \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"async\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Task\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"ExecutePromptAsync\"\n        }), \"(\\n  string part,\\n  string prompt,\\n  \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"OpenAIPromptExecutionSettings\"\n        }), \" settings,\\n  \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Action\"\n        }), \"\u003cstring\u003e? resultHandler = \", _jsx(_components.span, {\n          className: \"hljs-literal\",\n          children: \"null\"\n        }), \",\\n  string? modelOverride = \", _jsx(_components.span, {\n          className: \"hljs-literal\",\n          children: \"null\"\n        }), \",\\n  \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"CancellationToken\"\n        }), \" cancellation = \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"default\"\n        }), \"\\n) {\\n  \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 👇 대화를 초기화합니다\"\n        }), \"\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" chat = _kernel.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"GetRequiredService\"\n        }), \"\u003c\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"IChatCompletionService\"\n        }), \"\u003e(\\n    modelOverride ?? \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"70b\\\"\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 명시된 오버라이드가 없으면 70b를 사용합니다.\"\n        }), \"\\n  );\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" history = \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"new\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"ChatHistory\"\n        }), \"();\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" buffer = \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"new\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"StringBuilder\"\n        }), \"();\\n\\n  history.\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"AddUserMessage\"\n        }), \"(prompt);\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 👇 응답을 스트리밍하고 각 부분을 채널에 작성합니다\"\n        }), \"\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"await\"\n        }), \" foreach (\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" message \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"in\"\n        }), \" chat.\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"GetStreamingChatMessageContentsAsync\"\n        }), \"(\\n      history, settings, _kernel, cancellation\\n    )\\n  ) {\\n      \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"await\"\n        }), \" _channel.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Writer\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"WriteAsync\"\n        }), \"( \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 👈 채널의 라이터 엔드\"\n        }), \"\\n        \", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"new\"\n        }), \"(part, message.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Content\"\n        }), \" ?? \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"\\\"\"\n        }), \"),\\n        cancellation\\n      );\\n\\n      buffer.\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Append\"\n        }), \"(message.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Content\"\n        }), \"); \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 👈 전체 출력을 보유하는 버퍼\"\n        }), \"\\n  }\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" output = buffer.\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"ToString\"\n        }), \"();\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 👇 호출자가 전체 결과를 원하는 경우 여기에서 사용할 수 있습니다\"\n        }), \"\\n  resultHandler?.\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Invoke\"\n        }), \"(output);\\n}\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"애플리케이션 실행 중 의존성 주입을 통해 커널 인스턴스가 구성됩니다:```\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// Program.cs\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" builder = \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"WebApplication\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"CreateBuilder\"\n        }), \"(args);\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" fireworksEndpoint = \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"new\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Uri\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"https://api.fireworks.ai/inference/v1/chat/completions\\\"\"\n        }), \");\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" groqEndpoint = \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"new\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Uri\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"https://api.groq.com/openai/v1/chat/completions\\\"\"\n        }), \");\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" config = builder.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Configuration\"\n        }), \"\\n  .\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"GetSection\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"nameof\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"RecipesConfig\"\n        }), \"))\\n  .\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Get\"\n        }), \"\u003c\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"RecipesConfig\"\n        }), \"\u003e();\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// Semantic Kernel을 설정하여 필요한만큼의 LLM을 등록합니다.\"\n        }), \"\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" kernelBuilder = \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Kernel\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"CreateBuilder\"\n        }), \"();\\n\", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" kernel = kernelBuilder\\n  .\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"AddOpenAIChatCompletion\"\n        }), \"(\\n    \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"modelId\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"accounts/fireworks/models/llama-v3-70b-instruct\\\"\"\n        }), \",\\n    \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"apiKey\"\n        }), \": config!.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"FireworksKey\"\n        }), \",\\n    \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"endpoint\"\n        }), \": fireworksEndpoint,\\n    \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"serviceId\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"70b\\\"\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 👈 더 나은 결과를 위해 기본적으로 이 serviceId를 사용합니다\"\n        }), \"\\n  )\\n  .\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"AddOpenAIChatCompletion\"\n        }), \"(\\n    \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"modelId\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"accounts/fireworks/models/llama-v3-8b-instruct\\\"\"\n        }), \",\\n    \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"apiKey\"\n        }), \": config!.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"FireworksKey\"\n        }), \",\\n    \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"endpoint\"\n        }), \": fireworksEndpoint,\\n    \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"serviceId\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"8b\\\"\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 👈 더 빠른 속도가 필요한 경우 이 serviceId를 사용합니다\"\n        }), \"\\n  )\\n  .\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"AddOpenAIChatCompletion\"\n        }), \"(\\n    \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"modelId\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"llama3-8b-8192\\\"\"\n        }), \",\\n    \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"apiKey\"\n        }), \": config!.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"GroqKey\"\n        }), \",\\n    \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"endpoint\"\n        }), \": groqEndpoint,\\n    \", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"serviceId\"\n        }), \": \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"groq-8b\\\"\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 👈 최대 처리량을 위해 이 serviceId를 사용합니다\"\n        }), \"\\n  )\\n  \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 다른 LLM을 여기에 등록합니다.\"\n        }), \"\\n  .\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Build\"\n        }), \"();\\n\\nbuilder.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Services\"\n        }), \"\\n  .\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Configure\"\n        }), \"\u003c\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"RecipesConfig\"\n        }), \"\u003e(\\n    builder.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"Configuration\"\n        }), \".\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"GetSection\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"nameof\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"RecipesConfig\"\n        }), \"))\\n  )\\n  .\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"AddCors\"\n        }), \"()\\n  .\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"AddSingleton\"\n        }), \"(kernel)  \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 👈 설정된 kernel을 싱글톤으로 추가합니다\"\n        }), \"\\n  .\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"AddScoped\"\n        }), \"\u003c\", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"RecipeGenerator\"\n        }), \"\u003e();\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Semantic Kernel을 통해 여러 LLM 엔드포인트를 구성할 수 있습니다. 이를 사용하여 작은 빠른 LLM이 프로세스를 가속화할 수 있는 플로 구현을 단순화할 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"SSE를 활용한 동시 스트림\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"컨텐츠가 생성되면 백엔드는 즉시 프론트엔드로 스트리밍하여 매우 반응이 뛰어난 사용자 경험을 제공합니다. 이 과정은 동시에(그리고 스레드 풀 스케줄러에 따라 확장하여 병렬로) 발생하며, 채널에 수집되어 클라이언트에서 소비될 응답 스트림으로 작성됩니다.```\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 흐름을 시각화하기 위해 아래 다이어그램을 확인해보세요:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_7.png\",\n        alt: \"다이어그램\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Task.WaitAll 코드 블록은 채널의 공유 가능하고 스레드 안전한 writer 엔드를 전달받은 상태이며, reader 엔드는 HTTP 응답 스트림과 콜백을 통해 연결됩니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"해당 콜백은 간단히 EventSource의 필요한 형식 명세에 따라 Fragment를 서식화합니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"이 경우:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"data\"\n        }), \": ing|tomatoes\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"data\"\n        }), \": ing|basil\\n\\n\", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"data\"\n        }), \": ste|\", _jsx(_components.span, {\n          className: \"hljs-number\",\n          children: \"3.\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-title class_\",\n          children: \"Chop\"\n        }), \" the\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"프론트엔드는 이러한 메시지 스트림을 받아 UI의 서로 다른 섹션에 누적합니다.\"\n    }), \"\\n\", _jsxs(_components.ul, {\n      children: [\"\\n\", _jsx(_components.li, {\n        children: \"첫 번째 부분인 ing은 이 내용이 속하는 프론트엔드 부분을 식별합니다 (이 경우에는 \\\"재료\\\")\"\n      }), \"\\n\", _jsx(_components.li, {\n        children: \"| 이후의 텍스트는 LLM에 의해 작성된 출력 토큰 세트를 의미합니다.\"\n      }), \"\\n\"]\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"프론트엔드에서 @microsoft/fetch-event-source는 기본 EventSource를 대체하여 POST 사용을 가능하게 하는 폴리필(polyfill)로 사용됩니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"수신자는 각 메시지를 가져와 디코드합니다:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [_jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"onmessage\"\n        }), \": \", _jsxs(_components.span, {\n          className: \"hljs-function\",\n          children: [\"(\", _jsx(_components.span, {\n            className: \"hljs-params\",\n            children: \"msg\"\n          }), \") =\u003e\"]\n        }), \" {\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" payload = msg.\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"data\"\n        }), \"\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"var\"\n        }), \" [part, content] = payload.\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"split\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"'|'\"\n        }), \")\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"if\"\n        }), \" (!part || !$el(\", _jsxs(_components.span, {\n          className: \"hljs-string\",\n          children: [\"`#\", _jsx(_components.span, {\n            className: \"hljs-subst\",\n            children: \"${part}\"\n          }), \"`\"]\n        }), \")) {\\n    \", _jsx(_components.span, {\n          className: \"hljs-keyword\",\n          children: \"return\"\n        }), \" \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 이 메시지는 버립니다\"\n        }), \"\\n  }\\n\\n  \", _jsx(_components.span, {\n          className: \"hljs-comment\",\n          children: \"// 👇 이 부분은 새 줄을 인코딩하고 여기서 대체하는 해킹입니다.\"\n        }), \"\\n  content = content.\", _jsx(_components.span, {\n          className: \"hljs-title function_\",\n          children: \"replace\"\n        }), \"(\", _jsx(_components.span, {\n          className: \"hljs-regexp\",\n          children: \"/⮑/gi\"\n        }), \", \", _jsx(_components.span, {\n          className: \"hljs-string\",\n          children: \"\\\"\\\\n\\\"\"\n        }), \")\\n\\n  $el(\", _jsxs(_components.span, {\n          className: \"hljs-string\",\n          children: [\"`#\", _jsx(_components.span, {\n            className: \"hljs-subst\",\n            children: \"${part}\"\n          }), \"`\"]\n        }), \").\", _jsx(_components.span, {\n          className: \"hljs-property\",\n          children: \"innerHTML\"\n        }), \" += content\\n},\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"text/event-stream의 특이점은 이중 줄바꿈이 메시지 블록의 끝을 나타낸다는 것입니다. 그래서 줄바꿈은 어떤 방식으로든 인코딩되어야 합니다 (다양한 방법이 있습니다). 이 경우, 단일 문자 ⮑을 사용하여 해당 문자를 찾아 \\\\n으로 대체하는 것이 간답습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"CSS는 그냥 이 부분을 고려하면 됩니다:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [\"#add, #ing, #ste {\\n  white-\", _jsx(_components.span, {\n          className: \"hljs-attr\",\n          children: \"space\"\n        }), \": pre-line;\\n}\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"HTML 자체는 간단합니다:\"\n    }), \"\\n\", _jsx(_components.pre, {\n      children: _jsxs(_components.code, {\n        className: \"hljs language-js\",\n        children: [\"\u003c!-- 이 블록은 추가 재료를 보관합니다 --\u003e\\n\", _jsxs(_components.span, {\n          className: \"xml\",\n          children: [_jsxs(_components.span, {\n            className: \"hljs-tag\",\n            children: [\"\u003c\", _jsx(_components.span, {\n              className: \"hljs-name\",\n              children: \"div\"\n            }), \" \", _jsx(_components.span, {\n              className: \"hljs-attr\",\n              children: \"class\"\n            }), \"=\", _jsx(_components.span, {\n              className: \"hljs-string\",\n              children: \"\\\"additional\\\"\"\n            }), \"\u003e\"]\n          }), \"\\n  \", _jsxs(_components.span, {\n            className: \"hljs-tag\",\n            children: [\"\u003c\", _jsx(_components.span, {\n              className: \"hljs-name\",\n              children: \"h2\"\n            }), \"\u003e\"]\n          }), \"필요한 재료\", _jsxs(_components.span, {\n            className: \"hljs-tag\",\n            children: [\"\u003c/\", _jsx(_components.span, {\n              className: \"hljs-name\",\n              children: \"h2\"\n            }), \"\u003e\"]\n          }), \"\\n  \", _jsx(_components.span, {\n            className: \"hljs-comment\",\n            children: \"\u003c!-- 👇 이 ID는 Fragment.Part와 일치합니다 --\u003e\"\n          }), \"\\n  \", _jsxs(_components.span, {\n            className: \"hljs-tag\",\n            children: [\"\u003c\", _jsx(_components.span, {\n              className: \"hljs-name\",\n              children: \"div\"\n            }), \" \", _jsx(_components.span, {\n              className: \"hljs-attr\",\n              children: \"id\"\n            }), \"=\", _jsx(_components.span, {\n              className: \"hljs-string\",\n              children: \"\\\"add\\\"\"\n            }), \"\u003e\"]\n          }), _jsxs(_components.span, {\n            className: \"hljs-tag\",\n            children: [\"\u003c/\", _jsx(_components.span, {\n              className: \"hljs-name\",\n              children: \"div\"\n            }), \"\u003e\"]\n          }), \"\\n\", _jsxs(_components.span, {\n            className: \"hljs-tag\",\n            children: [\"\u003c/\", _jsx(_components.span, {\n              className: \"hljs-name\",\n              children: \"div\"\n            }), \"\u003e\"]\n          })]\n        }), \"\\n\\n\u003c!-- 이 블록은 단계를 보관합니다 --\u003e\\n\", _jsxs(_components.span, {\n          className: \"xml\",\n          children: [_jsxs(_components.span, {\n            className: \"hljs-tag\",\n            children: [\"\u003c\", _jsx(_components.span, {\n              className: \"hljs-name\",\n              children: \"div\"\n            }), \" \", _jsx(_components.span, {\n              className: \"hljs-attr\",\n              children: \"class\"\n            }), \"=\", _jsx(_components.span, {\n              className: \"hljs-string\",\n              children: \"\\\"recipe\\\"\"\n            }), \"\u003e\"]\n          }), \"\\n  \", _jsxs(_components.span, {\n            className: \"hljs-tag\",\n            children: [\"\u003c\", _jsx(_components.span, {\n              className: \"hljs-name\",\n              children: \"h2\"\n            }), \"\u003e\"]\n          }), \"조리 단계\", _jsxs(_components.span, {\n            className: \"hljs-tag\",\n            children: [\"\u003c/\", _jsx(_components.span, {\n              className: \"hljs-name\",\n              children: \"h2\"\n            }), \"\u003e\"]\n          }), \"\\n  \", _jsx(_components.span, {\n            className: \"hljs-comment\",\n            children: \"\u003c!-- 👇 이 ID는 Fragment.Part와 일치합니다 --\u003e\"\n          }), \"\\n  \", _jsxs(_components.span, {\n            className: \"hljs-tag\",\n            children: [\"\u003c\", _jsx(_components.span, {\n              className: \"hljs-name\",\n              children: \"div\"\n            }), \" \", _jsx(_components.span, {\n              className: \"hljs-attr\",\n              children: \"id\"\n            }), \"=\", _jsx(_components.span, {\n              className: \"hljs-string\",\n              children: \"\\\"ste\\\"\"\n            }), \"\u003e\"]\n          }), _jsxs(_components.span, {\n            className: \"hljs-tag\",\n            children: [\"\u003c/\", _jsx(_components.span, {\n              className: \"hljs-name\",\n              children: \"div\"\n            }), \"\u003e\"]\n          }), \"\\n\", _jsxs(_components.span, {\n            className: \"hljs-tag\",\n            children: [\"\u003c/\", _jsx(_components.span, {\n              className: \"hljs-name\",\n              children: \"div\"\n            }), \"\u003e\"]\n          })]\n        }), \"\\n\"]\n      })\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"모두가 준비되었으니 이제 앱을 실행하면 다음과 같은 경험을 할 수 있습니다:\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"https://miro.medium.com/v2/resize:fit:1400/0*uCMJGy8UoyaC4rFX.gif\",\n        alt: \"recipe app\"\n      })\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"레시피 목록을 생성하는 호출이 차단되므로 약간의 초기 지연이 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"그러나 한 번 목록이 생성되고 무작위로 선택된 후, 추가적인 생성은 전체 재료 목록에 의해 차단되는 단계만 동시에 발생합니다. (전체 재료 목록을 사용하여 정확한 단계를 생성해야 하기 때문입니다).\"\n    }), \"\\n\", _jsx(_components.h1, {\n      children: \"결론\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"사용자 경험(UX)이 높은 처리량을 필요로 하며 작은 컨텍스트 창을 통해 작동할 수 있는 애플리케이션의 경우, Fireworks.ai와 Llama-3 8B/70B는 절대적으로 게임 체인저입니다. 그것은 팀이 OpenAI의 GPT 모델의 높은 지연 때문에 전반적인 UX를 희생시키지 않고 사용 사례에 대해 빌드할 수 있도록 해줍니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"System.Threading.Channels를 사용한 .NET 8 웹 API에 그것을 플러그인하고 SSE와 결합하면, 여러 콘텐츠 청크를 동시에 생성하고, 상호작용적인 생성 AI 경험을 더 많이 구축하거나 생성적인 워크플로우를 간단히 가속화하는 새로운 가능성을 열 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"동일한 기술을 사용하면 (SSE를 제외하고) 낮은 지연 시간 + 높은 처리량 모델 및 플랫폼을 사용하여 여러 프롬프트를 병렬로 처리하여 서버 생성 워크로드의 처리량을 늘릴 수 있습니다.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"전체 repository:\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = Object.assign({}, _provideComponents(), props.components);\n  return MDXLayout ? _jsx(MDXLayout, Object.assign({}, props, {\n    children: _jsx(_createMdxContent, props)\n  })) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{}}},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai"},"buildId":"z1a6VTi5qHH9JJH7jaxL3","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>