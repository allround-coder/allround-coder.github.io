<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>데이터 과학자가 알아야 할 선형 대수학 개념 | allround-coder</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://allround-coder.github.io///post/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="데이터 과학자가 알아야 할 선형 대수학 개념 | allround-coder" data-gatsby-head="true"/><meta property="og:title" content="데이터 과학자가 알아야 할 선형 대수학 개념 | allround-coder" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://allround-coder.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://allround-coder.github.io///post/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow" data-gatsby-head="true"/><meta name="twitter:title" content="데이터 과학자가 알아야 할 선형 대수학 개념 | allround-coder" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | allround-coder" data-gatsby-head="true"/><meta name="article:published_time" content="2024-06-19 23:27" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZFDEQ947R4"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
  
            gtag('config', 'G-ZFDEQ947R4');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-b088bc509ff5c497.js" defer=""></script><script src="/_next/static/aCCUs-qPrLLLWRnkN0AOd/_buildManifest.js" defer=""></script><script src="/_next/static/aCCUs-qPrLLLWRnkN0AOd/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Allround Coder</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">데이터 과학자가 알아야 할 선형 대수학 개념</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="데이터 과학자가 알아야 할 선형 대수학 개념" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">Allround Coder</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On Jun 19, 2024</span><span class="posts_reading_time__f7YPP">9<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<h2>데이터 과학</h2>
<p><img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_0.png" alt="이미지"></p>
<p>선형 대수는 모든 데이터 과학 및 머신 러닝 작업의 기반입니다.</p>
<p>이것은 이론적 모델을 실용적인 솔루션으로 변환하는 언어입니다.</p>
<div class="content-ad"></div>
<p>데이터에서 학습할 수 있도록 하는 원칙을 내포하고 있어요.</p>
<p><img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_1.png" alt="이미지"></p>
<p>이것들은 다음과 같이 사용됩니다.</p>
<ul>
<li>데이터의 표현: 데이터를 구조화하고 조작하는 구조화된 방법으로, 복잡한 데이터셋을 행렬로 표현할 수 있도록 합니다.</li>
<li>차원 축소: PCA와 같은 기법은 중요한 정보를 잃지 않으면서 모델 효율성을 높이기 위해 변수의 수를 줄이는 데 선형대수를 활용합니다.</li>
<li>최적화: 그래디언트 디센트는 ML의 핵심 엔진으로, 함수의 최솟값을 찾기 위해 선형대수를 사용합니다.</li>
<li>피쳐 엔지니어링: 선형 변환과 행렬 연산을 통해 기존 데이터에서 새로운 피처를 생성합니다.</li>
<li>유사성 측정: 임베딩은 벡터로 저장되며, 오늘날 추천 시스템과 AI 챗봇에서 사용됩니다.</li>
<li>그 밖에도 많아요!</li>
</ul>
<div class="content-ad"></div>
<p>이 기사에서는 선형 대수학 개념, 시각적 설명 및 코드 예제를 살펴볼 거에요.</p>
<p>시작해 봅시다!</p>
<p>코드 → Deepnote 노트북</p>
<h1>목차</h1>
<div class="content-ad"></div>
<h3>벡터</h3>
<ul>
<li><strong>단위 벡터</strong>: 단위 벡터</li>
<li><strong>벡터 연산</strong>
<ul>
<li><strong>벡터 덧셈</strong></li>
<li><strong>스칼라 곱</strong></li>
<li><strong>닷 프로덕트</strong></li>
</ul>
</li>
<li><strong>벡터 공간</strong>
<ul>
<li><strong>영 공간 (커널)</strong></li>
<li><strong>Span</strong></li>
<li><strong>기저</strong></li>
<li><strong>선형 독립성</strong></li>
</ul>
</li>
</ul>
<h1>행렬</h1>
<ul>
<li><strong>함수로서의 행렬</strong></li>
<li><strong>선형 변환</strong></li>
<li><strong>역행렬</strong></li>
<li><strong>특이 행렬</strong></li>
<li><strong>항등 행렬</strong></li>
<li><strong>대각 행렬</strong></li>
<li><strong>직교 행렬</strong></li>
<li><strong>행렬 곱셈</strong></li>
<li><strong>트레이스</strong></li>
<li><strong>행렬식</strong></li>
<li><strong>랭크</strong></li>
<li><strong>고유 벡터와 고유값</strong></li>
</ul>
<p><img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_2.png" alt="선형 대수학 개념"></p>
<p>이것이 선형 대수학의 기본적인 구성 요소입니다.</p>
<div class="content-ad"></div>
<p>벡터를 생각하는 방법은 3가지가 있어요.</p>
<p>첫 번째는 물리학적인 시각입니다. 벡터는 공간에 향하는 화살표로 정의되며, 길이와 방향에 의해 결정됩니다. 평면상의 벡터는 2차원이고, 우리가 사는 공간에 있는 벡터는 3차원입니다.</p>
<p>두 번째는 컴퓨터 과학적 시각입니다. 벡터는 숫자의 순서대로 나열된 목록입니다. 이 목록의 길이가 차원을 결정합니다.</p>
<p>세 번째는 수학자의 시각입니다. 벡터는 서로 더해지거나 숫자로 곱해지는 모든 것이 될 수 있어요.</p>
<div class="content-ad"></div>
<h2>단위 벡터</h2>
<p>단위 벡터는 크기가 1인 벡터입니다. 종종 크기에 관계없이 벡터의 방향을 나타내는 데 사용됩니다.</p>
<h1>벡터 연산</h1>
<h2>벡터 덧셈</h2>
<div class="content-ad"></div>
<img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_3.png">
<p>두 벡터를 요소별로 더하여 새로운 벡터를 형성하는 것을 의미합니다.</p>
<img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_4.png">
<h2>스칼라 곱</h2>
<div class="content-ad"></div>
<p>표 태그를 마크다운 형식으로 변경하세요.</p>
<h2>내적</h2>
<p>형식적으로는 두 벡터의 유클리드 크기와 사이의 각도의 코사인의 곱으로, 벡터의 길이와 방향 관계를 모두 반영한다.</p>
<p><img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_5.png" alt="image"></p>
<div class="content-ad"></div>
<p>직관적으로 생각해보면 한 벡터의 방향성 성장을 다른 벡터에 적용하는 것이라고 생각할 수 있습니다. 또는 "한 벡터가 다른 벡터에게 얼마나 많은 밀어내기/에너지를 주는가?"라고 생각할 수도 있습니다. 결과는 우리가 원래의 벡터를 얼마나 더 강하게 만들었는지를 보여줍니다 (양수, 음수 또는 0).</p>
<p><img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_6.png" alt="Image 6"></p>
<p>만약 내적이 0이라면, 그것은 벡터들이 직교한다는 것을 말해줍니다.</p>
<p><img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_7.png" alt="Image 7"></p>
<div class="content-ad"></div>
<p>반가운 비유를 하나 소개하겠습니다.</p>
<p>빨간 화살표 벡터는 당신의 속도를 나타내고, 파란 화살표 벡터는 부스터 패드의 방향을 나타냅니다. 숫자가 클수록 더 강력한 파워를 의미합니다. 점곱은 당신이 받을 부스터 양을 나타냅니다.</p>
<p>이 공식을 사용하면, |a|는 당신의 진입 속도, |b|는 최대 부스트이며, 받게 되는 부스트의 백분율은 cos(𝛉)이며, 전체 부스트는 |a| |b| cos(𝛉)가 됩니다.</p>
<p><img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_8.png" alt="이미지"></p>
<div class="content-ad"></div>
<h1>벡터 공간</h1>
<p>벡터(또는 선형) 공간은 더하고 숫자로 곱할 수 있는 벡터의 모음입니다. 이 숫자는 이 문맥에서 스칼라라고 불립니다.</p>
<p>V가 벡터 공간이라고 불리기 위해서는 공리 목록을 만족해야 합니다.</p>
<p>이미지를 표시하는 대신 Markdown 형식으로 표를 변경했습니다.</p>
<p><img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_9.png" alt="Vector Space Table"></p>
<div class="content-ad"></div>
<h2>널 공간 (커널)</h2>
<p>널 공간은 행렬과 곱해졌을 때 영벡터가 되는 벡터들의 집합입니다.</p>
<p>이는 방정식 Ax = 0의 해를 나타냅니다. 여기서 A는 주어진 행렬입니다.</p>
<p>주어진 행렬에 곱해졌을 때 두 벡터를 원점(영벡터)으로 수렴시키는 부분공간으로서 행렬의 널 공간을 시각화할 수 있습니다.</p>
<div class="content-ad"></div>
<h2>Span</h2>
<p>주어진 두 벡터 v와 w의 선형 결합인 av + bw를 통해 도달할 수 있는 모든 가능한 벡터의 집합이며, 여기서 a와 b는 모든 실수입니다.</p>
<p>대부분의 벡터 쌍에 대해, 2차원 벡터 평면의 모든 점에 도달할 수 있습니다.</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_10.png" alt="image"></p>
<p>두 벡터가 일치하는 경우, 원점을 지나는 단일 선에 제한됩니다.</p>
<p>span의 개념은 basis의 개념에 기초합니다.</p>
<h2>Basis</h2>
<div class="content-ad"></div>
<p>기저는 전체 벡터 공간을 구성하는 선형 독립적인 벡터들의 모임입니다. 이는 벡터 공간 내의 모든 벡터를 기저 벡터의 선형 조합으로 표현할 수 있다는 것을 의미합니다.</p>
<p>이들을 공간 내 모든 다른 벡터들을 위한 기본 요소로 생각해보세요.</p>
<p>하나의 벡터를 화살표로 생각하는 것이 도움이 되지만, 벡터들의 집합에 대해서는 점으로 생각해보세요. 대부분의 기저 벡터 쌍은 공간의 전체 2차원 시트를 채울 수 있습니다.</p>
<h2>선형 독립성</h2>
<div class="content-ad"></div>
<p>일련의 벡터가 선형 독립적인 경우 집합 내의 벡터들이 결과적으로 ax + by 형태인 어떤 식으로도 나타낼 수 없는 경우입니다.</p>
<h2>행렬</h2>
<p>행렬은 입력과 연산을 행과 열로 구성하는 방법입니다.</p>
<p><img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_11.png" alt="이미지"></p>
<div class="content-ad"></div>
<p>여기 2행 2열의 행렬이 있어요.</p>
<p>구조화된 방식으로 문제를 해결할 수 있는 수학적 도구입니다.</p>
<h2>함수로서의 행렬</h2>
<p>행렬을 함수로 생각할 수 있어요. 파이썬 함수가 입력 매개변수를 받아 처리하고 출력을 반환하는 것처럼, 행렬 변환은 선형 변환을 통해 입력 벡터를 출력 벡터로 변환합니다.</p>
<div class="content-ad"></div>
<p><img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_12.png" alt="Linear Transformation"></p>
<h2>선형 변환</h2>
<p><img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_13.png" alt="선형 변환"></p>
<p>선형 변환은 두 벡터 공간 간의 매핑 V → W로, 벡터 덧셈과 스칼라 곱셈의 연산을 보존하는 것을 말합니다.</p>
<div class="content-ad"></div>
<p>실제로 행렬 A를 벡터 x에 적용하여 다른 벡터 y를 얻는 것(Ax = y 작업을 통해)은 선형 변환입니다.</p>
<p>이것은 데이터 과학에서 많이 사용됩니다:</p>
<ul>
<li>차원 축소: PCA는 선형 변환을 사용하여 고차원 데이터를 낮은 차원 공간으로 매핑합니다.</li>
<li>데이터 변환: 데이터 집합을 정규화하거나 표준화하는 것은 선형 변환이다.</li>
<li>피처 엔지니어링: 기존 피처의 조합을 통해 새로운 피처를 생성하는 것.</li>
</ul>
<p>다음은 몇 가지 형태의 행렬입니다:</p>
<div class="content-ad"></div>
<h2>역행렬</h2>
<p>행렬은 그 역행렬과 곱해지면 항등 행렬이 됩니다.</p>
<h2>특이 행렬</h2>
<p>특이 행렬은 역행렬을 가지지 않는 정방 행렬입니다. 이는 행렬의 행렬식이 0이거나 랭크가 크기보다 작은 것과 동일합니다.</p>
<div class="content-ad"></div>
<h2>항등 행렬.</h2>
<p>항등 행렬은 주 대각선에는 1의 값을, 그 외의 곳에는 0의 값을 갖는 정사각 행렬입니다. 행렬 곱셈에서 곱셈 항등원으로 작용하여 어떤 행렬에 적용해도 그 행렬을 변경시키지 않습니다. 그냥 숫자 1과 마찬가지로 작용합니다.</p>
<h2>대각 행렬</h2>
<p>대각 행렬은 모든 주 대각선을 제외한 항목이 0인 정사각 행렬입니다. 고유값을 찾거나 행렬식을 계산하는 데 사용됩니다.</p>
<div class="content-ad"></div>
<h2>직교 행렬</h2>
<p><img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_14.png" alt="직교 행렬"></p>
<p>실수 요소를 갖는 정방 행렬은 전치가 역행렬과 같으면 '직교'로 간주됩니다.</p>
<p>형식적으로, 행렬 A가 AᵀA=AAᵀ = I를 만족하면 A는 직교 행렬입니다. 여기서 I는 항등 행렬입니다.</p>
<div class="content-ad"></div>
<p>기하학적으로, 행렬은 그 열과 행이 직교하는 단위 벡터인 경우 직교합니다. 다시 말해, 서로 수직이며 크기가 1인 벡터입니다.</p>
<p>두 벡터가 서로 직교하고(90도) 그들 사이의 내적이 0이면 두 벡터는 직교한다는 것을 기억하세요.</p>
<h2>행렬 곱셈</h2>
<p>행렬 곱셈을 수행하는 데에 행렬을 사용합니다.</p>
<div class="content-ad"></div>
<p>안녕하세요! 아래는 선형대수에 관한 직관적인 가이드에서 가져온 멋진 시각화입니다.</p>
<p><img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_15.png" alt="Visualization"></p>
<p>각 입력 데이터를 각 연산을 통해 흘리는 것을 상상해 보세요.</p>
<p><img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_16.png" alt="Operations"></p>
<div class="content-ad"></div>
<p>여기 작업의 예시가 있어요.</p>
<p><img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_17.png" alt="이미지"></p>
<p>작업을 수행한 결과는 다음과 같아요.</p>
<p><img src="/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_18.png" alt="이미지"></p>
<div class="content-ad"></div>
<p>입력은 [3 x 2] 행렬이며, 우리의 작업 행렬은 [2 x 3]입니다. 그 결과는 [2 x 3] [3 x 2] = [2 x 2]입니다.</p>
<p>입력의 크기는 작업의 크기와 일치해야 합니다.</p>
<h2>Trace</h2>
<p>행렬의 Trace는 모든 대각 요소의 합입니다. 기저 변경에 불변이며, 행렬에 대한 고유값의 합인 행렬에 대한 정보적인 값을 제공합니다.</p>
<div class="content-ad"></div>
<h2>행렬식</h2>
<p>행렬식은 출력 변환의 크기를 의미해요.</p>
<p>입력이 단위 벡터인 경우(면적이나 부피가 1일 때), 행렬식은 변환된 면적이나 부피의 크기를 나타냅니다.</p>
<p>예를 들어 이 행렬을 살펴보죠. A의 면적이 6배로 스케일링된 경우, 변환의 행렬식은 6이 되는 거죠.</p>
<div class="content-ad"></div>
<p>음수 determinant는 전체 공간이 뒤집혔음을 알려줍니다. 이 변환은 종이 더미를 뒤집는 것과 비슷합니다.</p>
<p>빨간색과 녹색 축의 방향이 뒤바뀐 것을 주목하세요.</p>
<p>Determinant가 0이면 행렬이 "파괴적"이며 뒤집을 수 없습니다. 0으로 곱하는 것과 비슷하게 정보가 손실됩니다.</p>
<p>Determinant는 행렬이 역행렬인지를 알려줄 수 있습니다. det(A)가 0이면 역행렬이 존재하지 않으며 행렬은 특이합니다.</p>
<div class="content-ad"></div>
<h2>Rank</h2>
<p>행렬에서 선형 독립 열/행 벡터의 최대 개수를 나타내는 것입니다. 그것은 행 또는 열에 의해 만들어진 벡터 공간의 차원을 나타냅니다.</p>
<p>또한 선형 변환 후 출력 차원의 개수를 알려줍니다.</p>
<p>변환의 출력이 단일 선 (일차원이라고 함)인 경우, 해당 변환이 1의 순위를 가진다고 말합니다.</p>
<div class="content-ad"></div>
<p>만약 모든 벡터가 일부 2차원 평면에 있을 경우, 해당 변환은 랭크 2를 가졌다고 말합니다.</p>
<p>2x2 행렬의 경우 랭크 2가 가장 좋습니다. 이것이 full rank로 알려져 있죠. 이것은 기저 벡터가 전체 2차원 공간과 0이 아닌 determinant를 표현할 수 있다는 것을 의미합니다.</p>
<p>그러나 3x3 행렬의 경우, 랭크 2는 더 안 좋은데, 완전히 무너진 것은 아닙니다. 하지만, 랭크 1보다는 낫다고 볼 수 있죠.</p>
<h2>고유벡터와 고유값</h2>
<div class="content-ad"></div>
<p>고유 벡터와 고유 값은 변환의 "축"을 나타냅니다.</p>
<p>고유 벡터는 선형 변환 후에도 방향이 변하지 않는 입력값입니다. 방향은 변하지 않지만 크기는 변할 수 있습니다. 이 크기, 즉 고유 벡터가 확대되거나 축소되는 정도가 고유 값입니다.</p>
<p>지구본을 회전시킬 때 생각해보세요; 극을 제외한 모든 위치가 새로운 방향을 향합니다. 그들의 방향은 변하지 않습니다.</p>
<p>여기 고유 벡터의 시각적 예시가 있습니다.</p>
<div class="content-ad"></div>
<p><img src="https://miro.medium.com/v2/resize:fit:600/1*d34D2o-Gx1IOgFnuuJ2kog.gif" alt="image"></p>
<p>행렬 A와 벡터 v에 대해, Av = λv이면 λ가 고유값이고, v가 행렬 A의 고유벡터입니다.</p>
<p>다른 말로, 정방 행렬 A의 고유벡터는 행렬 곱셈 = 스칼라 곱셈인 벡터입니다.</p>
<h1>읽어 주셔서 감사합니다!</h1>
<div class="content-ad"></div>
<h1>자원</h1>
<p>해커들 방식</p>
<ul>
<li>코더를 위한 계산 선형 대수학</li>
<li>파이썬을 활용한 응용 기계 학습을 위한 선형 대수학 소개</li>
</ul>
<p>시각화</p>
<div class="content-ad"></div>
<ul>
<li>그래픽 선형 대수학 — LA를 수행하는 새로운 방법</li>
<li>3Blue1Brown의 선형대수학 본질 — 놀라운 애니메이션, 개념 시각화</li>
<li>인벡터라이즈</li>
<li>직관적인 수학</li>
</ul>
<p>논문/강의/교재</p>
<ul>
<li>딥 러닝에 필요한 행렬 미적분</li>
<li>데이터 분석, 신호 처리 및 머신 러닝을 위한 행렬 방법 | 수학 | MIT 오픈코스웨어</li>
<li>올바르게 수행하는 선형 대수학</li>
<li>선형대수학 4페이지로 알아보기.pdf</li>
</ul>
<h1>연락을 유지하세요!</h1>
<div class="content-ad"></div>
<p>비트그릿 데이터 사이언스 퍼블리케이션을 팔로우하면 최신 소식을 받아보실 수 있어요!</p>
<p>데이터 사이언스 및 인공지능 최신 동향을 다른 데이터 과학자들과 함께 논의하고 싶나요? 저희 디스코드 서버에 가입해보세요!</p>
<p>워크숍 및 다가오는 대회 정보를 받아보려면 비트그릿을 팔로우하세요!</p>
<p>디스코드 | 웹사이트 | 트위터 | 링크드인 | 인스타그램 | 페이스북 | 유튜브</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"데이터 과학자가 알아야 할 선형 대수학 개념","description":"","date":"2024-06-19 23:27","slug":"2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow","content":"\n\n## 데이터 과학\n\n![이미지](/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_0.png)\n\n선형 대수는 모든 데이터 과학 및 머신 러닝 작업의 기반입니다.\n\n이것은 이론적 모델을 실용적인 솔루션으로 변환하는 언어입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터에서 학습할 수 있도록 하는 원칙을 내포하고 있어요.\n\n![이미지](/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_1.png)\n\n이것들은 다음과 같이 사용됩니다.\n\n- 데이터의 표현: 데이터를 구조화하고 조작하는 구조화된 방법으로, 복잡한 데이터셋을 행렬로 표현할 수 있도록 합니다.\n- 차원 축소: PCA와 같은 기법은 중요한 정보를 잃지 않으면서 모델 효율성을 높이기 위해 변수의 수를 줄이는 데 선형대수를 활용합니다.\n- 최적화: 그래디언트 디센트는 ML의 핵심 엔진으로, 함수의 최솟값을 찾기 위해 선형대수를 사용합니다.\n- 피쳐 엔지니어링: 선형 변환과 행렬 연산을 통해 기존 데이터에서 새로운 피처를 생성합니다.\n- 유사성 측정: 임베딩은 벡터로 저장되며, 오늘날 추천 시스템과 AI 챗봇에서 사용됩니다.\n- 그 밖에도 많아요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사에서는 선형 대수학 개념, 시각적 설명 및 코드 예제를 살펴볼 거에요.\n\n시작해 봅시다!\n\n코드 → Deepnote 노트북\n\n# 목차\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n### 벡터\n\n- **단위 벡터**: 단위 벡터\n- **벡터 연산**\n  - **벡터 덧셈**\n  - **스칼라 곱**\n  - **닷 프로덕트**\n- **벡터 공간**\n  - **영 공간 (커널)**\n  - **Span**\n  - **기저**\n  - **선형 독립성**\n\n# 행렬\n\n- **함수로서의 행렬**\n- **선형 변환**\n- **역행렬**\n- **특이 행렬**\n- **항등 행렬**\n- **대각 행렬**\n- **직교 행렬**\n- **행렬 곱셈**\n- **트레이스**\n- **행렬식**\n- **랭크**\n- **고유 벡터와 고유값**\n\n![선형 대수학 개념](/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_2.png)\n\n이것이 선형 대수학의 기본적인 구성 요소입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n벡터를 생각하는 방법은 3가지가 있어요.\n\n첫 번째는 물리학적인 시각입니다. 벡터는 공간에 향하는 화살표로 정의되며, 길이와 방향에 의해 결정됩니다. 평면상의 벡터는 2차원이고, 우리가 사는 공간에 있는 벡터는 3차원입니다.\n\n두 번째는 컴퓨터 과학적 시각입니다. 벡터는 숫자의 순서대로 나열된 목록입니다. 이 목록의 길이가 차원을 결정합니다.\n\n세 번째는 수학자의 시각입니다. 벡터는 서로 더해지거나 숫자로 곱해지는 모든 것이 될 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 단위 벡터\n\n단위 벡터는 크기가 1인 벡터입니다. 종종 크기에 관계없이 벡터의 방향을 나타내는 데 사용됩니다.\n\n# 벡터 연산\n\n## 벡터 덧셈\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_3.png\" /\u003e\n\n두 벡터를 요소별로 더하여 새로운 벡터를 형성하는 것을 의미합니다.\n\n\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_4.png\" /\u003e\n\n## 스칼라 곱\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n표 태그를 마크다운 형식으로 변경하세요. \n\n## 내적\n\n형식적으로는 두 벡터의 유클리드 크기와 사이의 각도의 코사인의 곱으로, 벡터의 길이와 방향 관계를 모두 반영한다.\n\n![image](/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n직관적으로 생각해보면 한 벡터의 방향성 성장을 다른 벡터에 적용하는 것이라고 생각할 수 있습니다. 또는 \"한 벡터가 다른 벡터에게 얼마나 많은 밀어내기/에너지를 주는가?\"라고 생각할 수도 있습니다. 결과는 우리가 원래의 벡터를 얼마나 더 강하게 만들었는지를 보여줍니다 (양수, 음수 또는 0).\n\n![Image 6](/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_6.png)\n\n만약 내적이 0이라면, 그것은 벡터들이 직교한다는 것을 말해줍니다.\n\n![Image 7](/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_7.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n반가운 비유를 하나 소개하겠습니다.\n\n빨간 화살표 벡터는 당신의 속도를 나타내고, 파란 화살표 벡터는 부스터 패드의 방향을 나타냅니다. 숫자가 클수록 더 강력한 파워를 의미합니다. 점곱은 당신이 받을 부스터 양을 나타냅니다.\n\n이 공식을 사용하면, |a|는 당신의 진입 속도, |b|는 최대 부스트이며, 받게 되는 부스트의 백분율은 cos(𝛉)이며, 전체 부스트는 |a| |b| cos(𝛉)가 됩니다.\n\n![이미지](/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_8.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 벡터 공간\n\n벡터(또는 선형) 공간은 더하고 숫자로 곱할 수 있는 벡터의 모음입니다. 이 숫자는 이 문맥에서 스칼라라고 불립니다.\n\nV가 벡터 공간이라고 불리기 위해서는 공리 목록을 만족해야 합니다.\n\n이미지를 표시하는 대신 Markdown 형식으로 표를 변경했습니다.\n\n![Vector Space Table](/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_9.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 널 공간 (커널)\n\n널 공간은 행렬과 곱해졌을 때 영벡터가 되는 벡터들의 집합입니다.\n\n이는 방정식 Ax = 0의 해를 나타냅니다. 여기서 A는 주어진 행렬입니다.\n\n주어진 행렬에 곱해졌을 때 두 벡터를 원점(영벡터)으로 수렴시키는 부분공간으로서 행렬의 널 공간을 시각화할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## Span\n\n주어진 두 벡터 v와 w의 선형 결합인 av + bw를 통해 도달할 수 있는 모든 가능한 벡터의 집합이며, 여기서 a와 b는 모든 실수입니다.\n\n대부분의 벡터 쌍에 대해, 2차원 벡터 평면의 모든 점에 도달할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_10.png)\n\n두 벡터가 일치하는 경우, 원점을 지나는 단일 선에 제한됩니다.\n\nspan의 개념은 basis의 개념에 기초합니다.\n\n## Basis\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기저는 전체 벡터 공간을 구성하는 선형 독립적인 벡터들의 모임입니다. 이는 벡터 공간 내의 모든 벡터를 기저 벡터의 선형 조합으로 표현할 수 있다는 것을 의미합니다.\n\n이들을 공간 내 모든 다른 벡터들을 위한 기본 요소로 생각해보세요.\n\n하나의 벡터를 화살표로 생각하는 것이 도움이 되지만, 벡터들의 집합에 대해서는 점으로 생각해보세요. 대부분의 기저 벡터 쌍은 공간의 전체 2차원 시트를 채울 수 있습니다.\n\n## 선형 독립성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n일련의 벡터가 선형 독립적인 경우 집합 내의 벡터들이 결과적으로 ax + by 형태인 어떤 식으로도 나타낼 수 없는 경우입니다.\n\n## 행렬\n\n행렬은 입력과 연산을 행과 열로 구성하는 방법입니다.\n\n![이미지](/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_11.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기 2행 2열의 행렬이 있어요.\n\n구조화된 방식으로 문제를 해결할 수 있는 수학적 도구입니다.\n\n## 함수로서의 행렬\n\n행렬을 함수로 생각할 수 있어요. 파이썬 함수가 입력 매개변수를 받아 처리하고 출력을 반환하는 것처럼, 행렬 변환은 선형 변환을 통해 입력 벡터를 출력 벡터로 변환합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Linear Transformation](/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_12.png)\n\n## 선형 변환\n\n![선형 변환](/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_13.png)\n\n선형 변환은 두 벡터 공간 간의 매핑 V → W로, 벡터 덧셈과 스칼라 곱셈의 연산을 보존하는 것을 말합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n실제로 행렬 A를 벡터 x에 적용하여 다른 벡터 y를 얻는 것(Ax = y 작업을 통해)은 선형 변환입니다.\n\n이것은 데이터 과학에서 많이 사용됩니다:\n\n- 차원 축소: PCA는 선형 변환을 사용하여 고차원 데이터를 낮은 차원 공간으로 매핑합니다.\n- 데이터 변환: 데이터 집합을 정규화하거나 표준화하는 것은 선형 변환이다.\n- 피처 엔지니어링: 기존 피처의 조합을 통해 새로운 피처를 생성하는 것.\n\n다음은 몇 가지 형태의 행렬입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 역행렬\n\n행렬은 그 역행렬과 곱해지면 항등 행렬이 됩니다.\n\n## 특이 행렬\n\n특이 행렬은 역행렬을 가지지 않는 정방 행렬입니다. 이는 행렬의 행렬식이 0이거나 랭크가 크기보다 작은 것과 동일합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 항등 행렬.\n\n항등 행렬은 주 대각선에는 1의 값을, 그 외의 곳에는 0의 값을 갖는 정사각 행렬입니다. 행렬 곱셈에서 곱셈 항등원으로 작용하여 어떤 행렬에 적용해도 그 행렬을 변경시키지 않습니다. 그냥 숫자 1과 마찬가지로 작용합니다.\n\n## 대각 행렬\n\n대각 행렬은 모든 주 대각선을 제외한 항목이 0인 정사각 행렬입니다. 고유값을 찾거나 행렬식을 계산하는 데 사용됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 직교 행렬\n\n![직교 행렬](/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_14.png)\n\n실수 요소를 갖는 정방 행렬은 전치가 역행렬과 같으면 '직교'로 간주됩니다.\n\n형식적으로, 행렬 A가 AᵀA=AAᵀ = I를 만족하면 A는 직교 행렬입니다. 여기서 I는 항등 행렬입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기하학적으로, 행렬은 그 열과 행이 직교하는 단위 벡터인 경우 직교합니다. 다시 말해, 서로 수직이며 크기가 1인 벡터입니다.\n\n두 벡터가 서로 직교하고(90도) 그들 사이의 내적이 0이면 두 벡터는 직교한다는 것을 기억하세요.\n\n## 행렬 곱셈\n\n행렬 곱셈을 수행하는 데에 행렬을 사용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n안녕하세요! 아래는 선형대수에 관한 직관적인 가이드에서 가져온 멋진 시각화입니다.\n\n![Visualization](/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_15.png)\n\n각 입력 데이터를 각 연산을 통해 흘리는 것을 상상해 보세요.\n\n![Operations](/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_16.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기 작업의 예시가 있어요.\n\n![이미지](/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_17.png)\n\n작업을 수행한 결과는 다음과 같아요.\n\n![이미지](/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_18.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n입력은 [3 x 2] 행렬이며, 우리의 작업 행렬은 [2 x 3]입니다. 그 결과는 [2 x 3] [3 x 2] = [2 x 2]입니다.\n\n입력의 크기는 작업의 크기와 일치해야 합니다.\n\n## Trace\n\n행렬의 Trace는 모든 대각 요소의 합입니다. 기저 변경에 불변이며, 행렬에 대한 고유값의 합인 행렬에 대한 정보적인 값을 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 행렬식\n\n행렬식은 출력 변환의 크기를 의미해요.\n\n입력이 단위 벡터인 경우(면적이나 부피가 1일 때), 행렬식은 변환된 면적이나 부피의 크기를 나타냅니다.\n\n예를 들어 이 행렬을 살펴보죠. A의 면적이 6배로 스케일링된 경우, 변환의 행렬식은 6이 되는 거죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n음수 determinant는 전체 공간이 뒤집혔음을 알려줍니다. 이 변환은 종이 더미를 뒤집는 것과 비슷합니다.\n\n빨간색과 녹색 축의 방향이 뒤바뀐 것을 주목하세요.\n\nDeterminant가 0이면 행렬이 \"파괴적\"이며 뒤집을 수 없습니다. 0으로 곱하는 것과 비슷하게 정보가 손실됩니다.\n\nDeterminant는 행렬이 역행렬인지를 알려줄 수 있습니다. det(A)가 0이면 역행렬이 존재하지 않으며 행렬은 특이합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## Rank\n\n행렬에서 선형 독립 열/행 벡터의 최대 개수를 나타내는 것입니다. 그것은 행 또는 열에 의해 만들어진 벡터 공간의 차원을 나타냅니다.\n\n또한 선형 변환 후 출력 차원의 개수를 알려줍니다.\n\n변환의 출력이 단일 선 (일차원이라고 함)인 경우, 해당 변환이 1의 순위를 가진다고 말합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 모든 벡터가 일부 2차원 평면에 있을 경우, 해당 변환은 랭크 2를 가졌다고 말합니다.\n\n2x2 행렬의 경우 랭크 2가 가장 좋습니다. 이것이 full rank로 알려져 있죠. 이것은 기저 벡터가 전체 2차원 공간과 0이 아닌 determinant를 표현할 수 있다는 것을 의미합니다.\n\n그러나 3x3 행렬의 경우, 랭크 2는 더 안 좋은데, 완전히 무너진 것은 아닙니다. 하지만, 랭크 1보다는 낫다고 볼 수 있죠.\n\n## 고유벡터와 고유값\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n고유 벡터와 고유 값은 변환의 \"축\"을 나타냅니다.\n\n고유 벡터는 선형 변환 후에도 방향이 변하지 않는 입력값입니다. 방향은 변하지 않지만 크기는 변할 수 있습니다. 이 크기, 즉 고유 벡터가 확대되거나 축소되는 정도가 고유 값입니다.\n\n지구본을 회전시킬 때 생각해보세요; 극을 제외한 모든 위치가 새로운 방향을 향합니다. 그들의 방향은 변하지 않습니다.\n\n여기 고유 벡터의 시각적 예시가 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](https://miro.medium.com/v2/resize:fit:600/1*d34D2o-Gx1IOgFnuuJ2kog.gif)\n\n행렬 A와 벡터 v에 대해, Av = λv이면 λ가 고유값이고, v가 행렬 A의 고유벡터입니다.\n\n다른 말로, 정방 행렬 A의 고유벡터는 행렬 곱셈 = 스칼라 곱셈인 벡터입니다.\n\n# 읽어 주셔서 감사합니다!\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 자원\n\n해커들 방식\n\n- 코더를 위한 계산 선형 대수학\n- 파이썬을 활용한 응용 기계 학습을 위한 선형 대수학 소개\n\n시각화\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 그래픽 선형 대수학 — LA를 수행하는 새로운 방법\n- 3Blue1Brown의 선형대수학 본질 — 놀라운 애니메이션, 개념 시각화\n- 인벡터라이즈\n- 직관적인 수학\n\n논문/강의/교재\n\n- 딥 러닝에 필요한 행렬 미적분\n- 데이터 분석, 신호 처리 및 머신 러닝을 위한 행렬 방법 | 수학 | MIT 오픈코스웨어\n- 올바르게 수행하는 선형 대수학\n- 선형대수학 4페이지로 알아보기.pdf\n\n# 연락을 유지하세요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n비트그릿 데이터 사이언스 퍼블리케이션을 팔로우하면 최신 소식을 받아보실 수 있어요!\n\n데이터 사이언스 및 인공지능 최신 동향을 다른 데이터 과학자들과 함께 논의하고 싶나요? 저희 디스코드 서버에 가입해보세요!\n\n워크숍 및 다가오는 대회 정보를 받아보려면 비트그릿을 팔로우하세요!\n\n디스코드 | 웹사이트 | 트위터 | 링크드인 | 인스타그램 | 페이스북 | 유튜브","ogImage":{"url":"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_0.png"},"coverImage":"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_0.png","tag":["Tech"],"readingTime":9},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003ch2\u003e데이터 과학\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e선형 대수는 모든 데이터 과학 및 머신 러닝 작업의 기반입니다.\u003c/p\u003e\n\u003cp\u003e이것은 이론적 모델을 실용적인 솔루션으로 변환하는 언어입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e데이터에서 학습할 수 있도록 하는 원칙을 내포하고 있어요.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_1.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e이것들은 다음과 같이 사용됩니다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e데이터의 표현: 데이터를 구조화하고 조작하는 구조화된 방법으로, 복잡한 데이터셋을 행렬로 표현할 수 있도록 합니다.\u003c/li\u003e\n\u003cli\u003e차원 축소: PCA와 같은 기법은 중요한 정보를 잃지 않으면서 모델 효율성을 높이기 위해 변수의 수를 줄이는 데 선형대수를 활용합니다.\u003c/li\u003e\n\u003cli\u003e최적화: 그래디언트 디센트는 ML의 핵심 엔진으로, 함수의 최솟값을 찾기 위해 선형대수를 사용합니다.\u003c/li\u003e\n\u003cli\u003e피쳐 엔지니어링: 선형 변환과 행렬 연산을 통해 기존 데이터에서 새로운 피처를 생성합니다.\u003c/li\u003e\n\u003cli\u003e유사성 측정: 임베딩은 벡터로 저장되며, 오늘날 추천 시스템과 AI 챗봇에서 사용됩니다.\u003c/li\u003e\n\u003cli\u003e그 밖에도 많아요!\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이 기사에서는 선형 대수학 개념, 시각적 설명 및 코드 예제를 살펴볼 거에요.\u003c/p\u003e\n\u003cp\u003e시작해 봅시다!\u003c/p\u003e\n\u003cp\u003e코드 → Deepnote 노트북\u003c/p\u003e\n\u003ch1\u003e목차\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch3\u003e벡터\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e단위 벡터\u003c/strong\u003e: 단위 벡터\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e벡터 연산\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e벡터 덧셈\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e스칼라 곱\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e닷 프로덕트\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e벡터 공간\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e영 공간 (커널)\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSpan\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e기저\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e선형 독립성\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e행렬\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003e함수로서의 행렬\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e선형 변환\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e역행렬\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e특이 행렬\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e항등 행렬\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e대각 행렬\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e직교 행렬\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e행렬 곱셈\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e트레이스\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e행렬식\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e랭크\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e고유 벡터와 고유값\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_2.png\" alt=\"선형 대수학 개념\"\u003e\u003c/p\u003e\n\u003cp\u003e이것이 선형 대수학의 기본적인 구성 요소입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e벡터를 생각하는 방법은 3가지가 있어요.\u003c/p\u003e\n\u003cp\u003e첫 번째는 물리학적인 시각입니다. 벡터는 공간에 향하는 화살표로 정의되며, 길이와 방향에 의해 결정됩니다. 평면상의 벡터는 2차원이고, 우리가 사는 공간에 있는 벡터는 3차원입니다.\u003c/p\u003e\n\u003cp\u003e두 번째는 컴퓨터 과학적 시각입니다. 벡터는 숫자의 순서대로 나열된 목록입니다. 이 목록의 길이가 차원을 결정합니다.\u003c/p\u003e\n\u003cp\u003e세 번째는 수학자의 시각입니다. 벡터는 서로 더해지거나 숫자로 곱해지는 모든 것이 될 수 있어요.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e단위 벡터\u003c/h2\u003e\n\u003cp\u003e단위 벡터는 크기가 1인 벡터입니다. 종종 크기에 관계없이 벡터의 방향을 나타내는 데 사용됩니다.\u003c/p\u003e\n\u003ch1\u003e벡터 연산\u003c/h1\u003e\n\u003ch2\u003e벡터 덧셈\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_3.png\"\u003e\n\u003cp\u003e두 벡터를 요소별로 더하여 새로운 벡터를 형성하는 것을 의미합니다.\u003c/p\u003e\n\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_4.png\"\u003e\n\u003ch2\u003e스칼라 곱\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e표 태그를 마크다운 형식으로 변경하세요.\u003c/p\u003e\n\u003ch2\u003e내적\u003c/h2\u003e\n\u003cp\u003e형식적으로는 두 벡터의 유클리드 크기와 사이의 각도의 코사인의 곱으로, 벡터의 길이와 방향 관계를 모두 반영한다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_5.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e직관적으로 생각해보면 한 벡터의 방향성 성장을 다른 벡터에 적용하는 것이라고 생각할 수 있습니다. 또는 \"한 벡터가 다른 벡터에게 얼마나 많은 밀어내기/에너지를 주는가?\"라고 생각할 수도 있습니다. 결과는 우리가 원래의 벡터를 얼마나 더 강하게 만들었는지를 보여줍니다 (양수, 음수 또는 0).\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_6.png\" alt=\"Image 6\"\u003e\u003c/p\u003e\n\u003cp\u003e만약 내적이 0이라면, 그것은 벡터들이 직교한다는 것을 말해줍니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_7.png\" alt=\"Image 7\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e반가운 비유를 하나 소개하겠습니다.\u003c/p\u003e\n\u003cp\u003e빨간 화살표 벡터는 당신의 속도를 나타내고, 파란 화살표 벡터는 부스터 패드의 방향을 나타냅니다. 숫자가 클수록 더 강력한 파워를 의미합니다. 점곱은 당신이 받을 부스터 양을 나타냅니다.\u003c/p\u003e\n\u003cp\u003e이 공식을 사용하면, |a|는 당신의 진입 속도, |b|는 최대 부스트이며, 받게 되는 부스트의 백분율은 cos(𝛉)이며, 전체 부스트는 |a| |b| cos(𝛉)가 됩니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_8.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e벡터 공간\u003c/h1\u003e\n\u003cp\u003e벡터(또는 선형) 공간은 더하고 숫자로 곱할 수 있는 벡터의 모음입니다. 이 숫자는 이 문맥에서 스칼라라고 불립니다.\u003c/p\u003e\n\u003cp\u003eV가 벡터 공간이라고 불리기 위해서는 공리 목록을 만족해야 합니다.\u003c/p\u003e\n\u003cp\u003e이미지를 표시하는 대신 Markdown 형식으로 표를 변경했습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_9.png\" alt=\"Vector Space Table\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e널 공간 (커널)\u003c/h2\u003e\n\u003cp\u003e널 공간은 행렬과 곱해졌을 때 영벡터가 되는 벡터들의 집합입니다.\u003c/p\u003e\n\u003cp\u003e이는 방정식 Ax = 0의 해를 나타냅니다. 여기서 A는 주어진 행렬입니다.\u003c/p\u003e\n\u003cp\u003e주어진 행렬에 곱해졌을 때 두 벡터를 원점(영벡터)으로 수렴시키는 부분공간으로서 행렬의 널 공간을 시각화할 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003eSpan\u003c/h2\u003e\n\u003cp\u003e주어진 두 벡터 v와 w의 선형 결합인 av + bw를 통해 도달할 수 있는 모든 가능한 벡터의 집합이며, 여기서 a와 b는 모든 실수입니다.\u003c/p\u003e\n\u003cp\u003e대부분의 벡터 쌍에 대해, 2차원 벡터 평면의 모든 점에 도달할 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_10.png\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e두 벡터가 일치하는 경우, 원점을 지나는 단일 선에 제한됩니다.\u003c/p\u003e\n\u003cp\u003espan의 개념은 basis의 개념에 기초합니다.\u003c/p\u003e\n\u003ch2\u003eBasis\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e기저는 전체 벡터 공간을 구성하는 선형 독립적인 벡터들의 모임입니다. 이는 벡터 공간 내의 모든 벡터를 기저 벡터의 선형 조합으로 표현할 수 있다는 것을 의미합니다.\u003c/p\u003e\n\u003cp\u003e이들을 공간 내 모든 다른 벡터들을 위한 기본 요소로 생각해보세요.\u003c/p\u003e\n\u003cp\u003e하나의 벡터를 화살표로 생각하는 것이 도움이 되지만, 벡터들의 집합에 대해서는 점으로 생각해보세요. 대부분의 기저 벡터 쌍은 공간의 전체 2차원 시트를 채울 수 있습니다.\u003c/p\u003e\n\u003ch2\u003e선형 독립성\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e일련의 벡터가 선형 독립적인 경우 집합 내의 벡터들이 결과적으로 ax + by 형태인 어떤 식으로도 나타낼 수 없는 경우입니다.\u003c/p\u003e\n\u003ch2\u003e행렬\u003c/h2\u003e\n\u003cp\u003e행렬은 입력과 연산을 행과 열로 구성하는 방법입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_11.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e여기 2행 2열의 행렬이 있어요.\u003c/p\u003e\n\u003cp\u003e구조화된 방식으로 문제를 해결할 수 있는 수학적 도구입니다.\u003c/p\u003e\n\u003ch2\u003e함수로서의 행렬\u003c/h2\u003e\n\u003cp\u003e행렬을 함수로 생각할 수 있어요. 파이썬 함수가 입력 매개변수를 받아 처리하고 출력을 반환하는 것처럼, 행렬 변환은 선형 변환을 통해 입력 벡터를 출력 벡터로 변환합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_12.png\" alt=\"Linear Transformation\"\u003e\u003c/p\u003e\n\u003ch2\u003e선형 변환\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_13.png\" alt=\"선형 변환\"\u003e\u003c/p\u003e\n\u003cp\u003e선형 변환은 두 벡터 공간 간의 매핑 V → W로, 벡터 덧셈과 스칼라 곱셈의 연산을 보존하는 것을 말합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e실제로 행렬 A를 벡터 x에 적용하여 다른 벡터 y를 얻는 것(Ax = y 작업을 통해)은 선형 변환입니다.\u003c/p\u003e\n\u003cp\u003e이것은 데이터 과학에서 많이 사용됩니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e차원 축소: PCA는 선형 변환을 사용하여 고차원 데이터를 낮은 차원 공간으로 매핑합니다.\u003c/li\u003e\n\u003cli\u003e데이터 변환: 데이터 집합을 정규화하거나 표준화하는 것은 선형 변환이다.\u003c/li\u003e\n\u003cli\u003e피처 엔지니어링: 기존 피처의 조합을 통해 새로운 피처를 생성하는 것.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e다음은 몇 가지 형태의 행렬입니다:\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e역행렬\u003c/h2\u003e\n\u003cp\u003e행렬은 그 역행렬과 곱해지면 항등 행렬이 됩니다.\u003c/p\u003e\n\u003ch2\u003e특이 행렬\u003c/h2\u003e\n\u003cp\u003e특이 행렬은 역행렬을 가지지 않는 정방 행렬입니다. 이는 행렬의 행렬식이 0이거나 랭크가 크기보다 작은 것과 동일합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e항등 행렬.\u003c/h2\u003e\n\u003cp\u003e항등 행렬은 주 대각선에는 1의 값을, 그 외의 곳에는 0의 값을 갖는 정사각 행렬입니다. 행렬 곱셈에서 곱셈 항등원으로 작용하여 어떤 행렬에 적용해도 그 행렬을 변경시키지 않습니다. 그냥 숫자 1과 마찬가지로 작용합니다.\u003c/p\u003e\n\u003ch2\u003e대각 행렬\u003c/h2\u003e\n\u003cp\u003e대각 행렬은 모든 주 대각선을 제외한 항목이 0인 정사각 행렬입니다. 고유값을 찾거나 행렬식을 계산하는 데 사용됩니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e직교 행렬\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_14.png\" alt=\"직교 행렬\"\u003e\u003c/p\u003e\n\u003cp\u003e실수 요소를 갖는 정방 행렬은 전치가 역행렬과 같으면 '직교'로 간주됩니다.\u003c/p\u003e\n\u003cp\u003e형식적으로, 행렬 A가 AᵀA=AAᵀ = I를 만족하면 A는 직교 행렬입니다. 여기서 I는 항등 행렬입니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e기하학적으로, 행렬은 그 열과 행이 직교하는 단위 벡터인 경우 직교합니다. 다시 말해, 서로 수직이며 크기가 1인 벡터입니다.\u003c/p\u003e\n\u003cp\u003e두 벡터가 서로 직교하고(90도) 그들 사이의 내적이 0이면 두 벡터는 직교한다는 것을 기억하세요.\u003c/p\u003e\n\u003ch2\u003e행렬 곱셈\u003c/h2\u003e\n\u003cp\u003e행렬 곱셈을 수행하는 데에 행렬을 사용합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e안녕하세요! 아래는 선형대수에 관한 직관적인 가이드에서 가져온 멋진 시각화입니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_15.png\" alt=\"Visualization\"\u003e\u003c/p\u003e\n\u003cp\u003e각 입력 데이터를 각 연산을 통해 흘리는 것을 상상해 보세요.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_16.png\" alt=\"Operations\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e여기 작업의 예시가 있어요.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_17.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e작업을 수행한 결과는 다음과 같아요.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow_18.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e입력은 [3 x 2] 행렬이며, 우리의 작업 행렬은 [2 x 3]입니다. 그 결과는 [2 x 3] [3 x 2] = [2 x 2]입니다.\u003c/p\u003e\n\u003cp\u003e입력의 크기는 작업의 크기와 일치해야 합니다.\u003c/p\u003e\n\u003ch2\u003eTrace\u003c/h2\u003e\n\u003cp\u003e행렬의 Trace는 모든 대각 요소의 합입니다. 기저 변경에 불변이며, 행렬에 대한 고유값의 합인 행렬에 대한 정보적인 값을 제공합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003e행렬식\u003c/h2\u003e\n\u003cp\u003e행렬식은 출력 변환의 크기를 의미해요.\u003c/p\u003e\n\u003cp\u003e입력이 단위 벡터인 경우(면적이나 부피가 1일 때), 행렬식은 변환된 면적이나 부피의 크기를 나타냅니다.\u003c/p\u003e\n\u003cp\u003e예를 들어 이 행렬을 살펴보죠. A의 면적이 6배로 스케일링된 경우, 변환의 행렬식은 6이 되는 거죠.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e음수 determinant는 전체 공간이 뒤집혔음을 알려줍니다. 이 변환은 종이 더미를 뒤집는 것과 비슷합니다.\u003c/p\u003e\n\u003cp\u003e빨간색과 녹색 축의 방향이 뒤바뀐 것을 주목하세요.\u003c/p\u003e\n\u003cp\u003eDeterminant가 0이면 행렬이 \"파괴적\"이며 뒤집을 수 없습니다. 0으로 곱하는 것과 비슷하게 정보가 손실됩니다.\u003c/p\u003e\n\u003cp\u003eDeterminant는 행렬이 역행렬인지를 알려줄 수 있습니다. det(A)가 0이면 역행렬이 존재하지 않으며 행렬은 특이합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch2\u003eRank\u003c/h2\u003e\n\u003cp\u003e행렬에서 선형 독립 열/행 벡터의 최대 개수를 나타내는 것입니다. 그것은 행 또는 열에 의해 만들어진 벡터 공간의 차원을 나타냅니다.\u003c/p\u003e\n\u003cp\u003e또한 선형 변환 후 출력 차원의 개수를 알려줍니다.\u003c/p\u003e\n\u003cp\u003e변환의 출력이 단일 선 (일차원이라고 함)인 경우, 해당 변환이 1의 순위를 가진다고 말합니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e만약 모든 벡터가 일부 2차원 평면에 있을 경우, 해당 변환은 랭크 2를 가졌다고 말합니다.\u003c/p\u003e\n\u003cp\u003e2x2 행렬의 경우 랭크 2가 가장 좋습니다. 이것이 full rank로 알려져 있죠. 이것은 기저 벡터가 전체 2차원 공간과 0이 아닌 determinant를 표현할 수 있다는 것을 의미합니다.\u003c/p\u003e\n\u003cp\u003e그러나 3x3 행렬의 경우, 랭크 2는 더 안 좋은데, 완전히 무너진 것은 아닙니다. 하지만, 랭크 1보다는 낫다고 볼 수 있죠.\u003c/p\u003e\n\u003ch2\u003e고유벡터와 고유값\u003c/h2\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e고유 벡터와 고유 값은 변환의 \"축\"을 나타냅니다.\u003c/p\u003e\n\u003cp\u003e고유 벡터는 선형 변환 후에도 방향이 변하지 않는 입력값입니다. 방향은 변하지 않지만 크기는 변할 수 있습니다. 이 크기, 즉 고유 벡터가 확대되거나 축소되는 정도가 고유 값입니다.\u003c/p\u003e\n\u003cp\u003e지구본을 회전시킬 때 생각해보세요; 극을 제외한 모든 위치가 새로운 방향을 향합니다. 그들의 방향은 변하지 않습니다.\u003c/p\u003e\n\u003cp\u003e여기 고유 벡터의 시각적 예시가 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e\u003cimg src=\"https://miro.medium.com/v2/resize:fit:600/1*d34D2o-Gx1IOgFnuuJ2kog.gif\" alt=\"image\"\u003e\u003c/p\u003e\n\u003cp\u003e행렬 A와 벡터 v에 대해, Av = λv이면 λ가 고유값이고, v가 행렬 A의 고유벡터입니다.\u003c/p\u003e\n\u003cp\u003e다른 말로, 정방 행렬 A의 고유벡터는 행렬 곱셈 = 스칼라 곱셈인 벡터입니다.\u003c/p\u003e\n\u003ch1\u003e읽어 주셔서 감사합니다!\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e자원\u003c/h1\u003e\n\u003cp\u003e해커들 방식\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e코더를 위한 계산 선형 대수학\u003c/li\u003e\n\u003cli\u003e파이썬을 활용한 응용 기계 학습을 위한 선형 대수학 소개\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e시각화\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e그래픽 선형 대수학 — LA를 수행하는 새로운 방법\u003c/li\u003e\n\u003cli\u003e3Blue1Brown의 선형대수학 본질 — 놀라운 애니메이션, 개념 시각화\u003c/li\u003e\n\u003cli\u003e인벡터라이즈\u003c/li\u003e\n\u003cli\u003e직관적인 수학\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e논문/강의/교재\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e딥 러닝에 필요한 행렬 미적분\u003c/li\u003e\n\u003cli\u003e데이터 분석, 신호 처리 및 머신 러닝을 위한 행렬 방법 | 수학 | MIT 오픈코스웨어\u003c/li\u003e\n\u003cli\u003e올바르게 수행하는 선형 대수학\u003c/li\u003e\n\u003cli\u003e선형대수학 4페이지로 알아보기.pdf\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e연락을 유지하세요!\u003c/h1\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e비트그릿 데이터 사이언스 퍼블리케이션을 팔로우하면 최신 소식을 받아보실 수 있어요!\u003c/p\u003e\n\u003cp\u003e데이터 사이언스 및 인공지능 최신 동향을 다른 데이터 과학자들과 함께 논의하고 싶나요? 저희 디스코드 서버에 가입해보세요!\u003c/p\u003e\n\u003cp\u003e워크숍 및 다가오는 대회 정보를 받아보려면 비트그릿을 팔로우하세요!\u003c/p\u003e\n\u003cp\u003e디스코드 | 웹사이트 | 트위터 | 링크드인 | 인스타그램 | 페이스북 | 유튜브\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-06-19-LinearAlgebraConceptsEveryDataScientistShouldKnow"},"buildId":"aCCUs-qPrLLLWRnkN0AOd","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>