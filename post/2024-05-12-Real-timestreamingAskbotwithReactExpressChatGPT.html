<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>리얼타임 스트리밍 Askbot을 React, Express, ChatGPT로 개발하기 | allround-coder</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://allround-coder.github.io///post/2024-05-12-Real-timestreamingAskbotwithReactExpressChatGPT" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="리얼타임 스트리밍 Askbot을 React, Express, ChatGPT로 개발하기 | allround-coder" data-gatsby-head="true"/><meta property="og:title" content="리얼타임 스트리밍 Askbot을 React, Express, ChatGPT로 개발하기 | allround-coder" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-12-Real-timestreamingAskbotwithReactExpressChatGPT_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://allround-coder.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://allround-coder.github.io///post/2024-05-12-Real-timestreamingAskbotwithReactExpressChatGPT" data-gatsby-head="true"/><meta name="twitter:title" content="리얼타임 스트리밍 Askbot을 React, Express, ChatGPT로 개발하기 | allround-coder" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-12-Real-timestreamingAskbotwithReactExpressChatGPT_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | allround-coder" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-12 20:32" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZFDEQ947R4"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
  
            gtag('config', 'G-ZFDEQ947R4');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-b088bc509ff5c497.js" defer=""></script><script src="/_next/static/aCCUs-qPrLLLWRnkN0AOd/_buildManifest.js" defer=""></script><script src="/_next/static/aCCUs-qPrLLLWRnkN0AOd/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Allround Coder</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">리얼타임 스트리밍 Askbot을 React, Express, ChatGPT로 개발하기</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="리얼타임 스트리밍 Askbot을 React, Express, ChatGPT로 개발하기" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">Allround Coder</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 12, 2024</span><span class="posts_reading_time__f7YPP">6<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-12-Real-timestreamingAskbotwithReactExpressChatGPT&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p><img src="https://miro.medium.com/v2/resize:fit:1244/1*pgF3zoeDTN7tEbUP67AzaA.gif" alt="이미지"></p>
<p>이 블로그는 React를 사용하여 ChatGPT 앱을 안전하게 설정하는 데 초점을 맞춥니다.</p>
<p>OpenAI는 클라이언트 라이브러리를 제공하여 React 앱에서 ChatGPT를 직접 사용할 수 있지만, 라이브러리 자체가 경고하는 대로:</p>
<p>그러므로 이상적인 방법은 서버가 ChatGPT와 통신하여 원하는 응답을 받은 다음 해당 응답을 다시 React 앱으로 전달하는 것입니다.</p>
<p>하지만 위 스크린샷에 나와 있는 것처럼 ChatGPT와 같은 스트리밍 응답을 어떻게 구현할 수 있을까요?</p>
<p>이를 달성하기 위한 세 가지 단계는 다음과 같습니다:</p>
<ul>
<li>NodeJS-Express 서버 설정</li>
<li>OpenAI 및 스트리밍 응답 설정</li>
<li>React 앱에서 작동시키기</li>
</ul>
<h1>NodeJS-Express 서버 설정</h1>
<p>첫 번째로, React 앱과 OpenAI ChatGPT API 사이에서 중계 역할을 하는 Express 서버를 만들어야 합니다. 이 서버는 OpenAI로의 API 호출을 처리하고 응답을 React 앱으로 스트리밍합니다.</p>
<p>먼저 Node.js와 npm이 설치되어 있는지 확인하세요. 그런 다음 프로젝트 디렉토리에서 다음 명령을 실행하세요:</p>
<pre><code class="hljs language-js">npm install express cors body-parser
</code></pre>
<p>아래 코드를 사용하여 app.js에 빠른 Express 서버 설정을해보세요:</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> express <span class="hljs-keyword">from</span> <span class="hljs-string">"express"</span>;
<span class="hljs-keyword">import</span> bodyParser <span class="hljs-keyword">from</span> <span class="hljs-string">"body-parser"</span>;
<span class="hljs-keyword">import</span> cors <span class="hljs-keyword">from</span> <span class="hljs-string">"cors"</span>;

<span class="hljs-keyword">const</span> app = <span class="hljs-title function_">express</span>();
<span class="hljs-keyword">const</span> port = <span class="hljs-number">2000</span>;
app.<span class="hljs-title function_">use</span>(bodyParser.<span class="hljs-title function_">json</span>());
app.<span class="hljs-title function_">use</span>(bodyParser.<span class="hljs-title function_">urlencoded</span>({ <span class="hljs-attr">extended</span>: <span class="hljs-literal">false</span> }));
app.<span class="hljs-title function_">use</span>(<span class="hljs-title function_">cors</span>());

app.<span class="hljs-title function_">get</span>(<span class="hljs-string">"/"</span>, <span class="hljs-function">(<span class="hljs-params">req, res</span>) =></span> {
  <span class="hljs-keyword">return</span> res.<span class="hljs-title function_">json</span>({ <span class="hljs-attr">data</span>: <span class="hljs-string">"success"</span> });
});


app.<span class="hljs-title function_">listen</span>(port, <span class="hljs-function">() =></span> {
  <span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(<span class="hljs-string">`Example app listening on port <span class="hljs-subst">${port}</span>`</span>);
});
</code></pre>
<p>다음 명령어를 사용하여 서버를 실행하세요:</p>
<pre><code class="hljs language-js">node app.<span class="hljs-property">js</span>
</code></pre>
<p>팁: 언제든지 변경 사항을 만들 때마다 Express 서버를 다시로드하려면 nodemon을 사용할 수 있습니다.</p>
<h1>OpenAI 및 스트리밍 응답 설정</h1>
<h2>OpenAI 설정하기</h2>
<p>오픈에이아이 라이브러리를 설치하고 시작하세요!</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> <span class="hljs-title class_">OpenAI</span> <span class="hljs-keyword">from</span> <span class="hljs-string">"openai"</span>;

<span class="hljs-keyword">const</span> client = <span class="hljs-keyword">new</span> <span class="hljs-title class_">OpenAI</span>({
  <span class="hljs-attr">apiKey</span>: <span class="hljs-string">'YOUR_OPENAI_API_KEY'</span>,
});

<span class="hljs-keyword">const</span> systemMessage = {
  <span class="hljs-attr">role</span>: <span class="hljs-string">"system"</span>,
  <span class="hljs-attr">content</span>:
    <span class="hljs-string">"You are a Askbot. You are supposed to answer the questions asked by the users. Validate the prompts to be a question and it should not in approprite. Give funky responses"</span>,
};

<span class="hljs-keyword">export</span> <span class="hljs-keyword">const</span> <span class="hljs-title function_">getStreamingCompletion</span> = <span class="hljs-keyword">async</span> (<span class="hljs-params">{ userPrompt }</span>) => {
  <span class="hljs-keyword">return</span> client.<span class="hljs-property">chat</span>.<span class="hljs-property">completions</span>.<span class="hljs-title function_">create</span>({
    <span class="hljs-attr">model</span>: <span class="hljs-string">"gpt-3.5-turbo"</span>,
    <span class="hljs-attr">messages</span>: [systemMessage, { <span class="hljs-attr">role</span>: <span class="hljs-string">"user"</span>, <span class="hljs-attr">content</span>: userPrompt }],
    <span class="hljs-attr">stream</span>: <span class="hljs-literal">true</span>,
  });
};
</code></pre>
<p>OpenAI 웹사이트에서 실제 OpenAI API 키를 얻을 수 있습니다.</p>
<p>작성 시점에서 현재 안정 버전인 openai 라이브러리(3.3.0)에서는 스트리밍이 제대로 작동하지 않습니다. 여기에 설명된 대로.</p>
<p>라이브러리의 곧 출시될 v4 버전에서는 이를 지원할 것입니다. 베타 버전을 통해 이미 사용 가능합니다. 그럼 설치해봅시다:
npm install openai@4.0.0-beta.6 . 코드는 그대로 유지됩니다.</p>
<h2>ChatGPT에서 스트리밍 패치 설정</h2>
<p>스트리밍 응답의 큰 장점은 응답이 도착하는 대로 표시될 수 있어 사용자가 완전한 응답을 기다릴 필요가 없다는 것입니다. 이것은 프롬프트에 따라 시간이 오래 소요될 수 있기 때문에 중요합니다.</p>
<p>스트리밍 응답을 소비하려면 아래 코드를 확인해보세요:</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">let</span> starttime = <span class="hljs-title class_">Date</span>.<span class="hljs-title function_">now</span>();
<span class="hljs-keyword">const</span> stream = <span class="hljs-keyword">await</span> <span class="hljs-title function_">getStreamingCompletion</span>({ <span class="hljs-attr">userPrompt</span>: userPrompt });
 <span class="hljs-keyword">for</span> <span class="hljs-keyword">await</span> (<span class="hljs-keyword">const</span> part <span class="hljs-keyword">of</span> stream) {
    <span class="hljs-keyword">const</span> chunkTime = (<span class="hljs-title class_">Date</span>.<span class="hljs-title function_">now</span>() - starttime) / <span class="hljs-number">1000</span>;
    process.<span class="hljs-property">stdout</span>.<span class="hljs-title function_">write</span>(<span class="hljs-title class_">JSON</span>.<span class="hljs-title function_">stringify</span>(part.<span class="hljs-property">choices</span>[<span class="hljs-number">0</span>]?.<span class="hljs-property">delta</span> || <span class="hljs-string">""</span>));
    <span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(<span class="hljs-string">" chunk time:"</span>, chunkTime);
}
</code></pre>
<p>해보세요. 델타와 해당 델타가 표시되기까지 걸린 시간을 볼 수 있어야 합니다. 델타는 결과에서 다음 토큰입니다. 사용자가 "안녕"이라는 프롬프트를 제시하면 다음과 유사한 응답을 받게 될 것입니다:</p>
<p><img src="/assets/img/2024-05-12-Real-timestreamingAskbotwithReactExpressChatGPT_0.png" alt="이미지"></p>
<h2>Express API로부터의 스트리밍 응답</h2>
<p>Express에는 응답을 스트림으로 반환하는 API가 이미 준비되어 있습니다.</p>
<p>아래는 Express 서버의 전체 코드입니다:</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">import</span> express <span class="hljs-keyword">from</span> <span class="hljs-string">"express"</span>;
<span class="hljs-keyword">import</span> bodyParser <span class="hljs-keyword">from</span> <span class="hljs-string">"body-parser"</span>;
<span class="hljs-keyword">import</span> cors <span class="hljs-keyword">from</span> <span class="hljs-string">"cors"</span>;
<span class="hljs-keyword">import</span> { getStreamingCompletion } <span class="hljs-keyword">from</span> <span class="hljs-string">"./src/modules/openai/index.js"</span>;

<span class="hljs-keyword">const</span> app = <span class="hljs-title function_">express</span>();
<span class="hljs-keyword">const</span> port = <span class="hljs-number">2000</span>;
app.<span class="hljs-title function_">use</span>(bodyParser.<span class="hljs-title function_">json</span>());
app.<span class="hljs-title function_">use</span>(bodyParser.<span class="hljs-title function_">urlencoded</span>({ <span class="hljs-attr">extended</span>: <span class="hljs-literal">false</span> }));
app.<span class="hljs-title function_">use</span>(<span class="hljs-title function_">cors</span>());

app.<span class="hljs-title function_">get</span>(<span class="hljs-string">"/"</span>, <span class="hljs-function">(<span class="hljs-params">req, res</span>) =></span> {
  <span class="hljs-keyword">return</span> res.<span class="hljs-title function_">json</span>({ <span class="hljs-attr">data</span>: <span class="hljs-string">"success"</span> });
});

app.<span class="hljs-title function_">post</span>(<span class="hljs-string">"/aiCompletion"</span>, <span class="hljs-keyword">async</span> (req, res) => {
  <span class="hljs-keyword">const</span> data = req.<span class="hljs-property">body</span>;
  <span class="hljs-keyword">let</span> starttime = <span class="hljs-title class_">Date</span>.<span class="hljs-title function_">now</span>();
  <span class="hljs-keyword">const</span> stream = <span class="hljs-keyword">await</span> <span class="hljs-title function_">getStreamingCompletion</span>({ <span class="hljs-attr">userPrompt</span>: data?.<span class="hljs-property">userPrompt</span> });
  <span class="hljs-keyword">for</span> <span class="hljs-keyword">await</span> (<span class="hljs-keyword">const</span> part <span class="hljs-keyword">of</span> stream) {
    <span class="hljs-comment">// here express will stream the response</span>
    res.<span class="hljs-title function_">write</span>(part.<span class="hljs-property">choices</span>[<span class="hljs-number">0</span>]?.<span class="hljs-property">delta</span>.<span class="hljs-property">content</span> || <span class="hljs-string">""</span>);
  }
  <span class="hljs-comment">// here express sends the closing/done/end signal for the stream consumer</span>
  res.<span class="hljs-title function_">end</span>();
});

app.<span class="hljs-title function_">listen</span>(port, <span class="hljs-function">() =></span> {
  <span class="hljs-variable language_">console</span>.<span class="hljs-title function_">log</span>(<span class="hljs-string">`Example app listening on port <span class="hljs-subst">${port}</span>`</span>);
});
</code></pre>
<h1>리액트 앱에서 작동시키는 방법</h1>
<p>프론트 엔드를 설정해 봅시다. 나는 React SPA를 사용하고 있어요. 왜 SPA를 사용하냐고요? Next나 Remix가 제공하는 풀 스택 기능이 필요하지 않기 때문에 ExpressJS 기반의 백엔드를 이미 사용하고 있어요.</p>
<p>Vite를 사용해서 빠르게 설정해 보세요 (당연한 이유로 CRA는 사용하지 않는 것이 좋아요).</p>
<p>스트리밍 데이터를 읽기 위해 응답으로부터 리더를 사용해야 하며, 그 데이터를 바이트 스트림에서 문자열로 변환하기 위해 디코딩해야 합니다. 아래는 그에 대한 샘플 코드입니다:</p>
<pre><code class="hljs language-js">  <span class="hljs-comment">// 사용자 프롬프트에 기반한 서버 응답 가져오기</span>
  <span class="hljs-keyword">const</span> response = <span class="hljs-keyword">await</span> <span class="hljs-title function_">fetch</span>(<span class="hljs-string">"http://localhost:2000/aiCompletion"</span>, {
    <span class="hljs-attr">method</span>: <span class="hljs-string">"post"</span>,
    <span class="hljs-attr">headers</span>: {
      <span class="hljs-title class_">Accept</span>: <span class="hljs-string">"application/json, text/plain, */*"</span>,
      <span class="hljs-string">"Content-Type"</span>: <span class="hljs-string">"application/json"</span>,
    },
    <span class="hljs-attr">body</span>: <span class="hljs-title class_">JSON</span>.<span class="hljs-title function_">stringify</span>({ <span class="hljs-attr">userPrompt</span>: prompt }),
  });
  <span class="hljs-keyword">if</span> (!response.<span class="hljs-property">ok</span> || !response.<span class="hljs-property">body</span>) {
    <span class="hljs-keyword">throw</span> response.<span class="hljs-property">statusText</span>;
  }

  <span class="hljs-comment">// 여기서 스트리밍 응답 준비를 시작합니다</span>
  <span class="hljs-keyword">const</span> reader = response.<span class="hljs-property">body</span>.<span class="hljs-title function_">getReader</span>();
  <span class="hljs-keyword">const</span> decoder = <span class="hljs-keyword">new</span> <span class="hljs-title class_">TextDecoder</span>();
  <span class="hljs-keyword">const</span> loopRunner = <span class="hljs-literal">true</span>;

  <span class="hljs-keyword">while</span> (loopRunner) {
    <span class="hljs-comment">// 여기서 스트림을 읽기 시작합니다. 완료될 때까지.</span>
    <span class="hljs-keyword">const</span> { value, done } = <span class="hljs-keyword">await</span> reader.<span class="hljs-title function_">read</span>();
    <span class="hljs-keyword">if</span> (done) {
      <span class="hljs-keyword">break</span>;
    }
    <span class="hljs-keyword">const</span> decodedChunk = decoder.<span class="hljs-title function_">decode</span>(value, { <span class="hljs-attr">stream</span>: <span class="hljs-literal">true</span> });
    <span class="hljs-title function_">setAnswer</span>(<span class="hljs-function"><span class="hljs-params">answer</span> =></span> answer + decodedChunk); <span class="hljs-comment">// 새 청크로 상태 업데이트</span>
  }
</code></pre>
<p>React에서 useState를 사용하여 decodedChunk를 추가해 실시간 스트리밍 응답을 형성할 수 있습니다.</p>
<p>이 예제는 ReactJS, Express, 그리고 OpenAI ChatGPT API를 사용하여 스트리밍 채팅 응답을 구현하는 기본적인 예제를 보여줍니다. 사용 사례 및 요구 사항에 따라 오류 처리를 개선하거나 스타일을 추가하고 대화 흐름을 세밀하게 조정해야 할 수 있습니다.</p>
<p>당신은 이 레포지토리를 사용하여 직접 askbot을 실행하고 실험해볼 수 있어요.</p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"리얼타임 스트리밍 Askbot을 React, Express, ChatGPT로 개발하기","description":"","date":"2024-05-12 20:32","slug":"2024-05-12-Real-timestreamingAskbotwithReactExpressChatGPT","content":"\n\n![이미지](https://miro.medium.com/v2/resize:fit:1244/1*pgF3zoeDTN7tEbUP67AzaA.gif)\n\n이 블로그는 React를 사용하여 ChatGPT 앱을 안전하게 설정하는 데 초점을 맞춥니다.\n\nOpenAI는 클라이언트 라이브러리를 제공하여 React 앱에서 ChatGPT를 직접 사용할 수 있지만, 라이브러리 자체가 경고하는 대로:\n\n그러므로 이상적인 방법은 서버가 ChatGPT와 통신하여 원하는 응답을 받은 다음 해당 응답을 다시 React 앱으로 전달하는 것입니다.\n\n\n\n하지만 위 스크린샷에 나와 있는 것처럼 ChatGPT와 같은 스트리밍 응답을 어떻게 구현할 수 있을까요?\n\n이를 달성하기 위한 세 가지 단계는 다음과 같습니다:\n\n- NodeJS-Express 서버 설정\n- OpenAI 및 스트리밍 응답 설정\n- React 앱에서 작동시키기\n\n# NodeJS-Express 서버 설정\n\n\n\n첫 번째로, React 앱과 OpenAI ChatGPT API 사이에서 중계 역할을 하는 Express 서버를 만들어야 합니다. 이 서버는 OpenAI로의 API 호출을 처리하고 응답을 React 앱으로 스트리밍합니다.\n\n먼저 Node.js와 npm이 설치되어 있는지 확인하세요. 그런 다음 프로젝트 디렉토리에서 다음 명령을 실행하세요:\n\n```js\nnpm install express cors body-parser\n```\n\n아래 코드를 사용하여 app.js에 빠른 Express 서버 설정을해보세요:\n\n\n\n```js\nimport express from \"express\";\nimport bodyParser from \"body-parser\";\nimport cors from \"cors\";\n\nconst app = express();\nconst port = 2000;\napp.use(bodyParser.json());\napp.use(bodyParser.urlencoded({ extended: false }));\napp.use(cors());\n\napp.get(\"/\", (req, res) =\u003e {\n  return res.json({ data: \"success\" });\n});\n\n\napp.listen(port, () =\u003e {\n  console.log(`Example app listening on port ${port}`);\n});\n```\n\n다음 명령어를 사용하여 서버를 실행하세요:\n\n```js\nnode app.js\n```\n\n팁: 언제든지 변경 사항을 만들 때마다 Express 서버를 다시로드하려면 nodemon을 사용할 수 있습니다.\n\n\n\n# OpenAI 및 스트리밍 응답 설정\n\n## OpenAI 설정하기\n\n오픈에이아이 라이브러리를 설치하고 시작하세요!\n\n```js\nimport OpenAI from \"openai\";\n\nconst client = new OpenAI({\n  apiKey: 'YOUR_OPENAI_API_KEY',\n});\n\nconst systemMessage = {\n  role: \"system\",\n  content:\n    \"You are a Askbot. You are supposed to answer the questions asked by the users. Validate the prompts to be a question and it should not in approprite. Give funky responses\",\n};\n\nexport const getStreamingCompletion = async ({ userPrompt }) =\u003e {\n  return client.chat.completions.create({\n    model: \"gpt-3.5-turbo\",\n    messages: [systemMessage, { role: \"user\", content: userPrompt }],\n    stream: true,\n  });\n};\n```\n\n\n\nOpenAI 웹사이트에서 실제 OpenAI API 키를 얻을 수 있습니다.\n\n작성 시점에서 현재 안정 버전인 openai 라이브러리(3.3.0)에서는 스트리밍이 제대로 작동하지 않습니다. 여기에 설명된 대로.\n\n라이브러리의 곧 출시될 v4 버전에서는 이를 지원할 것입니다. 베타 버전을 통해 이미 사용 가능합니다. 그럼 설치해봅시다:\nnpm install openai@4.0.0-beta.6 . 코드는 그대로 유지됩니다.\n\n## ChatGPT에서 스트리밍 패치 설정\n\n\n\n스트리밍 응답의 큰 장점은 응답이 도착하는 대로 표시될 수 있어 사용자가 완전한 응답을 기다릴 필요가 없다는 것입니다. 이것은 프롬프트에 따라 시간이 오래 소요될 수 있기 때문에 중요합니다.\n\n스트리밍 응답을 소비하려면 아래 코드를 확인해보세요:\n\n```js\nlet starttime = Date.now();\nconst stream = await getStreamingCompletion({ userPrompt: userPrompt });\n for await (const part of stream) {\n    const chunkTime = (Date.now() - starttime) / 1000;\n    process.stdout.write(JSON.stringify(part.choices[0]?.delta || \"\"));\n    console.log(\" chunk time:\", chunkTime);\n}\n```\n\n해보세요. 델타와 해당 델타가 표시되기까지 걸린 시간을 볼 수 있어야 합니다. 델타는 결과에서 다음 토큰입니다. 사용자가 \"안녕\"이라는 프롬프트를 제시하면 다음과 유사한 응답을 받게 될 것입니다:\n\n\n\n\n![이미지](/assets/img/2024-05-12-Real-timestreamingAskbotwithReactExpressChatGPT_0.png)\n\n## Express API로부터의 스트리밍 응답\n\nExpress에는 응답을 스트림으로 반환하는 API가 이미 준비되어 있습니다.\n\n아래는 Express 서버의 전체 코드입니다:\n\n\n\n```js\nimport express from \"express\";\nimport bodyParser from \"body-parser\";\nimport cors from \"cors\";\nimport { getStreamingCompletion } from \"./src/modules/openai/index.js\";\n\nconst app = express();\nconst port = 2000;\napp.use(bodyParser.json());\napp.use(bodyParser.urlencoded({ extended: false }));\napp.use(cors());\n\napp.get(\"/\", (req, res) =\u003e {\n  return res.json({ data: \"success\" });\n});\n\napp.post(\"/aiCompletion\", async (req, res) =\u003e {\n  const data = req.body;\n  let starttime = Date.now();\n  const stream = await getStreamingCompletion({ userPrompt: data?.userPrompt });\n  for await (const part of stream) {\n    // here express will stream the response\n    res.write(part.choices[0]?.delta.content || \"\");\n  }\n  // here express sends the closing/done/end signal for the stream consumer\n  res.end();\n});\n\napp.listen(port, () =\u003e {\n  console.log(`Example app listening on port ${port}`);\n});\n```\n# 리액트 앱에서 작동시키는 방법\n\n프론트 엔드를 설정해 봅시다. 나는 React SPA를 사용하고 있어요. 왜 SPA를 사용하냐고요? Next나 Remix가 제공하는 풀 스택 기능이 필요하지 않기 때문에 ExpressJS 기반의 백엔드를 이미 사용하고 있어요.\n\nVite를 사용해서 빠르게 설정해 보세요 (당연한 이유로 CRA는 사용하지 않는 것이 좋아요).\n\n\n\n스트리밍 데이터를 읽기 위해 응답으로부터 리더를 사용해야 하며, 그 데이터를 바이트 스트림에서 문자열로 변환하기 위해 디코딩해야 합니다. 아래는 그에 대한 샘플 코드입니다:\n\n```js\n  // 사용자 프롬프트에 기반한 서버 응답 가져오기\n  const response = await fetch(\"http://localhost:2000/aiCompletion\", {\n    method: \"post\",\n    headers: {\n      Accept: \"application/json, text/plain, */*\",\n      \"Content-Type\": \"application/json\",\n    },\n    body: JSON.stringify({ userPrompt: prompt }),\n  });\n  if (!response.ok || !response.body) {\n    throw response.statusText;\n  }\n\n  // 여기서 스트리밍 응답 준비를 시작합니다\n  const reader = response.body.getReader();\n  const decoder = new TextDecoder();\n  const loopRunner = true;\n\n  while (loopRunner) {\n    // 여기서 스트림을 읽기 시작합니다. 완료될 때까지.\n    const { value, done } = await reader.read();\n    if (done) {\n      break;\n    }\n    const decodedChunk = decoder.decode(value, { stream: true });\n    setAnswer(answer =\u003e answer + decodedChunk); // 새 청크로 상태 업데이트\n  }\n```\n\nReact에서 useState를 사용하여 decodedChunk를 추가해 실시간 스트리밍 응답을 형성할 수 있습니다.\n\n이 예제는 ReactJS, Express, 그리고 OpenAI ChatGPT API를 사용하여 스트리밍 채팅 응답을 구현하는 기본적인 예제를 보여줍니다. 사용 사례 및 요구 사항에 따라 오류 처리를 개선하거나 스타일을 추가하고 대화 흐름을 세밀하게 조정해야 할 수 있습니다.\n\n\n\n당신은 이 레포지토리를 사용하여 직접 askbot을 실행하고 실험해볼 수 있어요.","ogImage":{"url":"/assets/img/2024-05-12-Real-timestreamingAskbotwithReactExpressChatGPT_0.png"},"coverImage":"/assets/img/2024-05-12-Real-timestreamingAskbotwithReactExpressChatGPT_0.png","tag":["Tech"],"readingTime":6},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1244/1*pgF3zoeDTN7tEbUP67AzaA.gif\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cp\u003e이 블로그는 React를 사용하여 ChatGPT 앱을 안전하게 설정하는 데 초점을 맞춥니다.\u003c/p\u003e\n\u003cp\u003eOpenAI는 클라이언트 라이브러리를 제공하여 React 앱에서 ChatGPT를 직접 사용할 수 있지만, 라이브러리 자체가 경고하는 대로:\u003c/p\u003e\n\u003cp\u003e그러므로 이상적인 방법은 서버가 ChatGPT와 통신하여 원하는 응답을 받은 다음 해당 응답을 다시 React 앱으로 전달하는 것입니다.\u003c/p\u003e\n\u003cp\u003e하지만 위 스크린샷에 나와 있는 것처럼 ChatGPT와 같은 스트리밍 응답을 어떻게 구현할 수 있을까요?\u003c/p\u003e\n\u003cp\u003e이를 달성하기 위한 세 가지 단계는 다음과 같습니다:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eNodeJS-Express 서버 설정\u003c/li\u003e\n\u003cli\u003eOpenAI 및 스트리밍 응답 설정\u003c/li\u003e\n\u003cli\u003eReact 앱에서 작동시키기\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003eNodeJS-Express 서버 설정\u003c/h1\u003e\n\u003cp\u003e첫 번째로, React 앱과 OpenAI ChatGPT API 사이에서 중계 역할을 하는 Express 서버를 만들어야 합니다. 이 서버는 OpenAI로의 API 호출을 처리하고 응답을 React 앱으로 스트리밍합니다.\u003c/p\u003e\n\u003cp\u003e먼저 Node.js와 npm이 설치되어 있는지 확인하세요. 그런 다음 프로젝트 디렉토리에서 다음 명령을 실행하세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003enpm install express cors body-parser\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e아래 코드를 사용하여 app.js에 빠른 Express 서버 설정을해보세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e express \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"express\"\u003c/span\u003e;\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e bodyParser \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"body-parser\"\u003c/span\u003e;\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e cors \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"cors\"\u003c/span\u003e;\n\n\u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e app = \u003cspan class=\"hljs-title function_\"\u003eexpress\u003c/span\u003e();\n\u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e port = \u003cspan class=\"hljs-number\"\u003e2000\u003c/span\u003e;\napp.\u003cspan class=\"hljs-title function_\"\u003euse\u003c/span\u003e(bodyParser.\u003cspan class=\"hljs-title function_\"\u003ejson\u003c/span\u003e());\napp.\u003cspan class=\"hljs-title function_\"\u003euse\u003c/span\u003e(bodyParser.\u003cspan class=\"hljs-title function_\"\u003eurlencoded\u003c/span\u003e({ \u003cspan class=\"hljs-attr\"\u003eextended\u003c/span\u003e: \u003cspan class=\"hljs-literal\"\u003efalse\u003c/span\u003e }));\napp.\u003cspan class=\"hljs-title function_\"\u003euse\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003ecors\u003c/span\u003e());\n\napp.\u003cspan class=\"hljs-title function_\"\u003eget\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"/\"\u003c/span\u003e, \u003cspan class=\"hljs-function\"\u003e(\u003cspan class=\"hljs-params\"\u003ereq, res\u003c/span\u003e) =\u003e\u003c/span\u003e {\n  \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e res.\u003cspan class=\"hljs-title function_\"\u003ejson\u003c/span\u003e({ \u003cspan class=\"hljs-attr\"\u003edata\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"success\"\u003c/span\u003e });\n});\n\n\napp.\u003cspan class=\"hljs-title function_\"\u003elisten\u003c/span\u003e(port, \u003cspan class=\"hljs-function\"\u003e() =\u003e\u003c/span\u003e {\n  \u003cspan class=\"hljs-variable language_\"\u003econsole\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003elog\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e`Example app listening on port \u003cspan class=\"hljs-subst\"\u003e${port}\u003c/span\u003e`\u003c/span\u003e);\n});\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e다음 명령어를 사용하여 서버를 실행하세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003enode app.\u003cspan class=\"hljs-property\"\u003ejs\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e팁: 언제든지 변경 사항을 만들 때마다 Express 서버를 다시로드하려면 nodemon을 사용할 수 있습니다.\u003c/p\u003e\n\u003ch1\u003eOpenAI 및 스트리밍 응답 설정\u003c/h1\u003e\n\u003ch2\u003eOpenAI 설정하기\u003c/h2\u003e\n\u003cp\u003e오픈에이아이 라이브러리를 설치하고 시작하세요!\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eOpenAI\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"openai\"\u003c/span\u003e;\n\n\u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e client = \u003cspan class=\"hljs-keyword\"\u003enew\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eOpenAI\u003c/span\u003e({\n  \u003cspan class=\"hljs-attr\"\u003eapiKey\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e'YOUR_OPENAI_API_KEY'\u003c/span\u003e,\n});\n\n\u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e systemMessage = {\n  \u003cspan class=\"hljs-attr\"\u003erole\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"system\"\u003c/span\u003e,\n  \u003cspan class=\"hljs-attr\"\u003econtent\u003c/span\u003e:\n    \u003cspan class=\"hljs-string\"\u003e\"You are a Askbot. You are supposed to answer the questions asked by the users. Validate the prompts to be a question and it should not in approprite. Give funky responses\"\u003c/span\u003e,\n};\n\n\u003cspan class=\"hljs-keyword\"\u003eexport\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003egetStreamingCompletion\u003c/span\u003e = \u003cspan class=\"hljs-keyword\"\u003easync\u003c/span\u003e (\u003cspan class=\"hljs-params\"\u003e{ userPrompt }\u003c/span\u003e) =\u003e {\n  \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e client.\u003cspan class=\"hljs-property\"\u003echat\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003ecompletions\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003ecreate\u003c/span\u003e({\n    \u003cspan class=\"hljs-attr\"\u003emodel\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"gpt-3.5-turbo\"\u003c/span\u003e,\n    \u003cspan class=\"hljs-attr\"\u003emessages\u003c/span\u003e: [systemMessage, { \u003cspan class=\"hljs-attr\"\u003erole\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"user\"\u003c/span\u003e, \u003cspan class=\"hljs-attr\"\u003econtent\u003c/span\u003e: userPrompt }],\n    \u003cspan class=\"hljs-attr\"\u003estream\u003c/span\u003e: \u003cspan class=\"hljs-literal\"\u003etrue\u003c/span\u003e,\n  });\n};\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOpenAI 웹사이트에서 실제 OpenAI API 키를 얻을 수 있습니다.\u003c/p\u003e\n\u003cp\u003e작성 시점에서 현재 안정 버전인 openai 라이브러리(3.3.0)에서는 스트리밍이 제대로 작동하지 않습니다. 여기에 설명된 대로.\u003c/p\u003e\n\u003cp\u003e라이브러리의 곧 출시될 v4 버전에서는 이를 지원할 것입니다. 베타 버전을 통해 이미 사용 가능합니다. 그럼 설치해봅시다:\nnpm install openai@4.0.0-beta.6 . 코드는 그대로 유지됩니다.\u003c/p\u003e\n\u003ch2\u003eChatGPT에서 스트리밍 패치 설정\u003c/h2\u003e\n\u003cp\u003e스트리밍 응답의 큰 장점은 응답이 도착하는 대로 표시될 수 있어 사용자가 완전한 응답을 기다릴 필요가 없다는 것입니다. 이것은 프롬프트에 따라 시간이 오래 소요될 수 있기 때문에 중요합니다.\u003c/p\u003e\n\u003cp\u003e스트리밍 응답을 소비하려면 아래 코드를 확인해보세요:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003elet\u003c/span\u003e starttime = \u003cspan class=\"hljs-title class_\"\u003eDate\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enow\u003c/span\u003e();\n\u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e stream = \u003cspan class=\"hljs-keyword\"\u003eawait\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003egetStreamingCompletion\u003c/span\u003e({ \u003cspan class=\"hljs-attr\"\u003euserPrompt\u003c/span\u003e: userPrompt });\n \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eawait\u003c/span\u003e (\u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e part \u003cspan class=\"hljs-keyword\"\u003eof\u003c/span\u003e stream) {\n    \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e chunkTime = (\u003cspan class=\"hljs-title class_\"\u003eDate\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enow\u003c/span\u003e() - starttime) / \u003cspan class=\"hljs-number\"\u003e1000\u003c/span\u003e;\n    process.\u003cspan class=\"hljs-property\"\u003estdout\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003ewrite\u003c/span\u003e(\u003cspan class=\"hljs-title class_\"\u003eJSON\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003estringify\u003c/span\u003e(part.\u003cspan class=\"hljs-property\"\u003echoices\u003c/span\u003e[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]?.\u003cspan class=\"hljs-property\"\u003edelta\u003c/span\u003e || \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e));\n    \u003cspan class=\"hljs-variable language_\"\u003econsole\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003elog\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\" chunk time:\"\u003c/span\u003e, chunkTime);\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e해보세요. 델타와 해당 델타가 표시되기까지 걸린 시간을 볼 수 있어야 합니다. 델타는 결과에서 다음 토큰입니다. 사용자가 \"안녕\"이라는 프롬프트를 제시하면 다음과 유사한 응답을 받게 될 것입니다:\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-12-Real-timestreamingAskbotwithReactExpressChatGPT_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003ch2\u003eExpress API로부터의 스트리밍 응답\u003c/h2\u003e\n\u003cp\u003eExpress에는 응답을 스트림으로 반환하는 API가 이미 준비되어 있습니다.\u003c/p\u003e\n\u003cp\u003e아래는 Express 서버의 전체 코드입니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e express \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"express\"\u003c/span\u003e;\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e bodyParser \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"body-parser\"\u003c/span\u003e;\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e cors \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"cors\"\u003c/span\u003e;\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e { getStreamingCompletion } \u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"./src/modules/openai/index.js\"\u003c/span\u003e;\n\n\u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e app = \u003cspan class=\"hljs-title function_\"\u003eexpress\u003c/span\u003e();\n\u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e port = \u003cspan class=\"hljs-number\"\u003e2000\u003c/span\u003e;\napp.\u003cspan class=\"hljs-title function_\"\u003euse\u003c/span\u003e(bodyParser.\u003cspan class=\"hljs-title function_\"\u003ejson\u003c/span\u003e());\napp.\u003cspan class=\"hljs-title function_\"\u003euse\u003c/span\u003e(bodyParser.\u003cspan class=\"hljs-title function_\"\u003eurlencoded\u003c/span\u003e({ \u003cspan class=\"hljs-attr\"\u003eextended\u003c/span\u003e: \u003cspan class=\"hljs-literal\"\u003efalse\u003c/span\u003e }));\napp.\u003cspan class=\"hljs-title function_\"\u003euse\u003c/span\u003e(\u003cspan class=\"hljs-title function_\"\u003ecors\u003c/span\u003e());\n\napp.\u003cspan class=\"hljs-title function_\"\u003eget\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"/\"\u003c/span\u003e, \u003cspan class=\"hljs-function\"\u003e(\u003cspan class=\"hljs-params\"\u003ereq, res\u003c/span\u003e) =\u003e\u003c/span\u003e {\n  \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e res.\u003cspan class=\"hljs-title function_\"\u003ejson\u003c/span\u003e({ \u003cspan class=\"hljs-attr\"\u003edata\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"success\"\u003c/span\u003e });\n});\n\napp.\u003cspan class=\"hljs-title function_\"\u003epost\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"/aiCompletion\"\u003c/span\u003e, \u003cspan class=\"hljs-keyword\"\u003easync\u003c/span\u003e (req, res) =\u003e {\n  \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e data = req.\u003cspan class=\"hljs-property\"\u003ebody\u003c/span\u003e;\n  \u003cspan class=\"hljs-keyword\"\u003elet\u003c/span\u003e starttime = \u003cspan class=\"hljs-title class_\"\u003eDate\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003enow\u003c/span\u003e();\n  \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e stream = \u003cspan class=\"hljs-keyword\"\u003eawait\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003egetStreamingCompletion\u003c/span\u003e({ \u003cspan class=\"hljs-attr\"\u003euserPrompt\u003c/span\u003e: data?.\u003cspan class=\"hljs-property\"\u003euserPrompt\u003c/span\u003e });\n  \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003eawait\u003c/span\u003e (\u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e part \u003cspan class=\"hljs-keyword\"\u003eof\u003c/span\u003e stream) {\n    \u003cspan class=\"hljs-comment\"\u003e// here express will stream the response\u003c/span\u003e\n    res.\u003cspan class=\"hljs-title function_\"\u003ewrite\u003c/span\u003e(part.\u003cspan class=\"hljs-property\"\u003echoices\u003c/span\u003e[\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e]?.\u003cspan class=\"hljs-property\"\u003edelta\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003econtent\u003c/span\u003e || \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e);\n  }\n  \u003cspan class=\"hljs-comment\"\u003e// here express sends the closing/done/end signal for the stream consumer\u003c/span\u003e\n  res.\u003cspan class=\"hljs-title function_\"\u003eend\u003c/span\u003e();\n});\n\napp.\u003cspan class=\"hljs-title function_\"\u003elisten\u003c/span\u003e(port, \u003cspan class=\"hljs-function\"\u003e() =\u003e\u003c/span\u003e {\n  \u003cspan class=\"hljs-variable language_\"\u003econsole\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003elog\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e`Example app listening on port \u003cspan class=\"hljs-subst\"\u003e${port}\u003c/span\u003e`\u003c/span\u003e);\n});\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch1\u003e리액트 앱에서 작동시키는 방법\u003c/h1\u003e\n\u003cp\u003e프론트 엔드를 설정해 봅시다. 나는 React SPA를 사용하고 있어요. 왜 SPA를 사용하냐고요? Next나 Remix가 제공하는 풀 스택 기능이 필요하지 않기 때문에 ExpressJS 기반의 백엔드를 이미 사용하고 있어요.\u003c/p\u003e\n\u003cp\u003eVite를 사용해서 빠르게 설정해 보세요 (당연한 이유로 CRA는 사용하지 않는 것이 좋아요).\u003c/p\u003e\n\u003cp\u003e스트리밍 데이터를 읽기 위해 응답으로부터 리더를 사용해야 하며, 그 데이터를 바이트 스트림에서 문자열로 변환하기 위해 디코딩해야 합니다. 아래는 그에 대한 샘플 코드입니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e  \u003cspan class=\"hljs-comment\"\u003e// 사용자 프롬프트에 기반한 서버 응답 가져오기\u003c/span\u003e\n  \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e response = \u003cspan class=\"hljs-keyword\"\u003eawait\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003efetch\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"http://localhost:2000/aiCompletion\"\u003c/span\u003e, {\n    \u003cspan class=\"hljs-attr\"\u003emethod\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"post\"\u003c/span\u003e,\n    \u003cspan class=\"hljs-attr\"\u003eheaders\u003c/span\u003e: {\n      \u003cspan class=\"hljs-title class_\"\u003eAccept\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"application/json, text/plain, */*\"\u003c/span\u003e,\n      \u003cspan class=\"hljs-string\"\u003e\"Content-Type\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"application/json\"\u003c/span\u003e,\n    },\n    \u003cspan class=\"hljs-attr\"\u003ebody\u003c/span\u003e: \u003cspan class=\"hljs-title class_\"\u003eJSON\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003estringify\u003c/span\u003e({ \u003cspan class=\"hljs-attr\"\u003euserPrompt\u003c/span\u003e: prompt }),\n  });\n  \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e (!response.\u003cspan class=\"hljs-property\"\u003eok\u003c/span\u003e || !response.\u003cspan class=\"hljs-property\"\u003ebody\u003c/span\u003e) {\n    \u003cspan class=\"hljs-keyword\"\u003ethrow\u003c/span\u003e response.\u003cspan class=\"hljs-property\"\u003estatusText\u003c/span\u003e;\n  }\n\n  \u003cspan class=\"hljs-comment\"\u003e// 여기서 스트리밍 응답 준비를 시작합니다\u003c/span\u003e\n  \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e reader = response.\u003cspan class=\"hljs-property\"\u003ebody\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003egetReader\u003c/span\u003e();\n  \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e decoder = \u003cspan class=\"hljs-keyword\"\u003enew\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eTextDecoder\u003c/span\u003e();\n  \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e loopRunner = \u003cspan class=\"hljs-literal\"\u003etrue\u003c/span\u003e;\n\n  \u003cspan class=\"hljs-keyword\"\u003ewhile\u003c/span\u003e (loopRunner) {\n    \u003cspan class=\"hljs-comment\"\u003e// 여기서 스트림을 읽기 시작합니다. 완료될 때까지.\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e { value, done } = \u003cspan class=\"hljs-keyword\"\u003eawait\u003c/span\u003e reader.\u003cspan class=\"hljs-title function_\"\u003eread\u003c/span\u003e();\n    \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e (done) {\n      \u003cspan class=\"hljs-keyword\"\u003ebreak\u003c/span\u003e;\n    }\n    \u003cspan class=\"hljs-keyword\"\u003econst\u003c/span\u003e decodedChunk = decoder.\u003cspan class=\"hljs-title function_\"\u003edecode\u003c/span\u003e(value, { \u003cspan class=\"hljs-attr\"\u003estream\u003c/span\u003e: \u003cspan class=\"hljs-literal\"\u003etrue\u003c/span\u003e });\n    \u003cspan class=\"hljs-title function_\"\u003esetAnswer\u003c/span\u003e(\u003cspan class=\"hljs-function\"\u003e\u003cspan class=\"hljs-params\"\u003eanswer\u003c/span\u003e =\u003e\u003c/span\u003e answer + decodedChunk); \u003cspan class=\"hljs-comment\"\u003e// 새 청크로 상태 업데이트\u003c/span\u003e\n  }\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eReact에서 useState를 사용하여 decodedChunk를 추가해 실시간 스트리밍 응답을 형성할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e이 예제는 ReactJS, Express, 그리고 OpenAI ChatGPT API를 사용하여 스트리밍 채팅 응답을 구현하는 기본적인 예제를 보여줍니다. 사용 사례 및 요구 사항에 따라 오류 처리를 개선하거나 스타일을 추가하고 대화 흐름을 세밀하게 조정해야 할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e당신은 이 레포지토리를 사용하여 직접 askbot을 실행하고 실험해볼 수 있어요.\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-12-Real-timestreamingAskbotwithReactExpressChatGPT"},"buildId":"aCCUs-qPrLLLWRnkN0AOd","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>