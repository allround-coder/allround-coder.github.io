<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>챗봇 치트 코드 Qwen110B로 스트림릿에서 돈을 쓰지 않고 활용하는 방법 | allround-coder</title><meta name="description" content=""/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://allround-coder.github.io///post/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="챗봇 치트 코드 Qwen110B로 스트림릿에서 돈을 쓰지 않고 활용하는 방법 | allround-coder" data-gatsby-head="true"/><meta property="og:title" content="챗봇 치트 코드 Qwen110B로 스트림릿에서 돈을 쓰지 않고 활용하는 방법 | allround-coder" data-gatsby-head="true"/><meta property="og:description" content="" data-gatsby-head="true"/><meta property="og:image" content="/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_0.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://allround-coder.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://allround-coder.github.io///post/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2" data-gatsby-head="true"/><meta name="twitter:title" content="챗봇 치트 코드 Qwen110B로 스트림릿에서 돈을 쓰지 않고 활용하는 방법 | allround-coder" data-gatsby-head="true"/><meta name="twitter:description" content="" data-gatsby-head="true"/><meta name="twitter:image" content="/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_0.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | allround-coder" data-gatsby-head="true"/><meta name="article:published_time" content="2024-05-17 03:23" data-gatsby-head="true"/><meta name="next-head-count" content="19"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZFDEQ947R4"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
  
            gtag('config', 'G-ZFDEQ947R4');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/b8ef307c9aee1e34.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b8ef307c9aee1e34.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/pages/post/%5Bslug%5D-b088bc509ff5c497.js" defer=""></script><script src="/_next/static/OFpTzInQeZKWBaqJEukNX/_buildManifest.js" defer=""></script><script src="/_next/static/OFpTzInQeZKWBaqJEukNX/_ssgManifest.js" defer=""></script></head><body><div id="__next"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Allround Coder</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><main class="posts_container__NyRU3"><div class="posts_inner__i3n_i"><h1 class="posts_post_title__EbxNx">챗봇 치트 코드 Qwen110B로 스트림릿에서 돈을 쓰지 않고 활용하는 방법</h1><div class="posts_meta__cR7lu"><div class="posts_profile_wrap__mslMl"><div class="posts_profile_image_wrap__kPikV"><img alt="챗봇 치트 코드 Qwen110B로 스트림릿에서 돈을 쓰지 않고 활용하는 방법" loading="lazy" width="44" height="44" decoding="async" data-nimg="1" class="profile" style="color:transparent" src="/favicons/apple-icon-114x114.png"/></div><div class="posts_textarea__w_iKT"><span class="writer">Allround Coder</span><span class="posts_info__5KJdN"><span class="posts_date__ctqHI">Posted On May 17, 2024</span><span class="posts_reading_time__f7YPP">9<!-- --> min read</span></span></div></div><img alt="" loading="lazy" width="50" height="50" decoding="async" data-nimg="1" class="posts_view_badge__tcbfm" style="color:transparent" src="https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fallround-coder.github.io/post/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=views&amp;edge_flat=false"/></div><article class="posts_post_content__n_L6j"><div><!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta content="width=device-width, initial-scale=1" name="viewport">
</head>
<body>
<p>제1부에서는 수십억 개의 매개변수를 가진 큰 언어 모델에 무료로 액세스하고 활용할 수 있다는 것을 발견했어요. 제처럼 여러분도 하드웨어 한정으로 고민 중이라면, 이 해킹 방법은 하이엔드 GPU나 유료 구독 없이도 Qwen-110B-chat과 같은 대규모 모델과 상호 작용할 수 있는 기쁨을 선사할 거예요.</p>
<p>제2부에서는 지금부터 체험을 더 향상시키기 위해 스트림릿 인터페이스로 동일한 개념을 적용하여 챗봇에 시각적으로 매력적인 스트리밍 효과를 추가할 거예요.</p>
<p>과정을 되짚어보자면, Python, Gradio_client 및 코딩 능력이 필요해요. AI 챗봇을 텍스트 인터페이스를 통해 만드는 데 초점을 맞추었어요:</p>
<ul>
<li>환경 설정: 먼저 가상 환경을 만들고 필요한 패키지(huggingface_hub, gradio-client 및 streamlit)를 설치하세요. PyTorch나 TensorFlow가 필요하지 않으며, 상호 작용은 API를 통해 이루어질 거예요.</li>
<li>Hugging Face API 토큰: 사용자는 Hugging Face에 등록하고 모델 추론 API에 액세스하기 위해 API 토큰을 생성해야 해요.</li>
<li>챗봇 코딩: Hugging Face Spaces에서 Gradio의 "API를 통해 사용" 기능을 활용하여 이러한 강력한 모델에 Python 코드로 연결하는 방법을 배웠어요. 특히 여러 언어로 상업적 이용을 위한 라이선스가 허용되는 Qwen 시리즈 모델에 초점을 맞췄어요.</li>
<li>스트리밍 효과: 코드 구조를 살펴보면, 모델과 상호 작용할 수 있는 함수를 만드는 방법을 설명했어요. predict() 및 submit() 메서드 중에서 선택하여 스트리밍 효과와 함께 또는 없이 응답을 생성하는 방법을 강조했어요.</li>
</ul>
<div class="content-ad"></div>
<p>조금 헤매고 있다면 part 1부터 시작하는 것을 제안해요:</p>
<h2>핵심 코드부터 Streamlit 인터페이스까지</h2>
<p>이걸 꼭 말해야 해요: 터미널에서 모든 앱이 정상 작동하지 않으면 그래픽 인터페이스를 시작하지 말아야 해요.</p>
<p>이건 필수 조건이에요! 그래서 Streamlit 인터페이스를 만드는 것이 아주 쉬울 거에요: 이미 이전 파트에서 라이브러리와 상호작용이 어떻게 작동하는지 확인했기 때문이죠.</p>
<div class="content-ad"></div>
<p>모든 것은 이 핵심을 중심으로 움직입니다:</p>
<pre><code class="hljs language-js"><span class="hljs-keyword">from</span> gradio_client <span class="hljs-keyword">import</span> <span class="hljs-title class_">Client</span>

client = <span class="hljs-title class_">Client</span>(<span class="hljs-string">"Qwen/Qwen1.5-110B-Chat-demo"</span>)
result = client.<span class="hljs-title function_">submit</span>(
        query=<span class="hljs-string">'What is Science?'</span>,
        history=[],
        system=<span class="hljs-string">"You are a helpful assistant."</span>,
        api_name=<span class="hljs-string">"/model_chat"</span>
)
<span class="hljs-title function_">print</span>(result)
</code></pre>
<p>그리고 submit() 메소드를 사용하여 스트리밍 객체/반복자를 얻을 수 있다는 것을 알고 있습니다. Streamlit을 사용하면 스트림을 다루기가 훨씬 쉬워집니다. 사실, 애플리케이션은 항상 페이지 위젯을 새로 고치기 때문에 텍스트 애플리케이션에서 사용되는 지루한 알고리즘을 무시할 수 있습니다. 기억하시나요?</p>
<pre><code class="hljs language-js">    final = <span class="hljs-string">''</span>
    <span class="hljs-keyword">for</span> chunk <span class="hljs-keyword">in</span> <span class="hljs-attr">result</span>:
        <span class="hljs-keyword">if</span> final == <span class="hljs-string">''</span>:
            final=chunk[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]
            <span class="hljs-title function_">print</span>(chunk[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>][<span class="hljs-number">1</span>], end=<span class="hljs-string">""</span>, flush=<span class="hljs-title class_">True</span>)
        <span class="hljs-attr">else</span>:
            <span class="hljs-attr">try</span>:
                <span class="hljs-title function_">print</span>(chunk[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>][<span class="hljs-number">1</span>].<span class="hljs-title function_">replace</span>(final,<span class="hljs-string">''</span>), end=<span class="hljs-string">""</span>, flush=<span class="hljs-title class_">True</span>)
                final = chunk[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]
            <span class="hljs-attr">except</span>:
                pass    
</code></pre>
<div class="content-ad"></div>
<p>string.replace()을 사용하여 이미 생성된 것에서 새로운 단어를 빼내는 작업을 했었는데, 더이상 필요하지 않아요.🥳</p>
<h1>Streamlit 앱</h1>
<p>습관적인 사람이라... 그래서 내 코드가 다른 프로젝트와 매우 비슷하다는 사실을 발견할 수 있을 거에요. 그런데 괜찮아요! 결국, 템플릿을 적용하고 수정하는 것이 매번 처음부터 시작하는 것보다 쉽고 빠를 수 있거든.</p>
<p>새 파일을 만들어보세요: 제 파일은 st-Qwen1.5–110B-Chat.py라고 해요. 주요 라이브러리를 가져와 세션 상태 전역 변수를 생성하는 것부터 시작해볼까요?</p>
<div class="content-ad"></div>
<pre><code class="hljs language-python"><span class="hljs-keyword">import</span> streamlit <span class="hljs-keyword">as</span> st
<span class="hljs-keyword">import</span> time
<span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">from</span> gradio_client <span class="hljs-keyword">import</span> Client
<span class="hljs-comment"># Internal usage</span>
<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">from</span> time <span class="hljs-keyword">import</span> sleep


<span class="hljs-keyword">if</span> <span class="hljs-string">"hf_model"</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> st.session_state:
    st.session_state.hf_model = <span class="hljs-string">"Qwen1.5-110B-Chat"</span>
<span class="hljs-comment"># Initialize chat history</span>
<span class="hljs-keyword">if</span> <span class="hljs-string">"messages"</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> st.session_state:
    st.session_state.messages = []
</code></pre>
<p>프로그램에서 전역 변수는 공유되어 사용될 수 있습니다. 또한 session_state라고 불리는 이러한 객체들이 streamlit의 매 실행마다 변경되지 않는 것을 필요로합니다.</p>
<p>그리고 2가지 주요 함수를 정의합니다:</p>
<pre><code class="hljs language-python"><span class="hljs-meta">@st.cache_resource</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">create_client</span>():   
    yourHFtoken = <span class="hljs-string">"hf_xxxxxxxxxxxxxxxxxxxxxxx"</span> <span class="hljs-comment">#여기에 여러분의 HF 토큰을 넣으세요</span>
    <span class="hljs-built_in">print</span>(<span class="hljs-string">f'<span class="hljs-subst">{st.session_state.hf_model}</span>에 대한 API Gradio 클라이언트를 로딩 중입니다.'</span>)
    client = Client(<span class="hljs-string">"Qwen/Qwen1.5-110B-Chat-demo"</span>, hf_token=yourHFtoken)
    <span class="hljs-keyword">return</span> client

<span class="hljs-comment"># 모든 채팅 메시지를 chathistory.txt에 기록하는 함수</span>
<span class="hljs-keyword">def</span> <span class="hljs-title function_">writehistory</span>(<span class="hljs-params">text</span>):
    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">'chathistorywen110b.txt'</span>, <span class="hljs-string">'a'</span>, encoding=<span class="hljs-string">'utf-8'</span>) <span class="hljs-keyword">as</span> f:
        f.write(text)
        f.write(<span class="hljs-string">'\n'</span>)
    f.close()
</code></pre>
<div class="content-ad"></div>
<p>저희는 @st.cache_resource 데코레이터를 사용하고 있습니다. 이는 Qwen1.5-110에 대한 API gradio 클라이언트를 Streamlit이 매 실행마다 로딩하지 않기를 원하기 때문입니다 (이는 분당 1회 이상 발생할 수 있습니다): Gradio 클라이언트 연결이 실행 중에 변경되지 않을 것이기 때문에, 이 리소스를 특별한 메모리에 캐싱하고 있습니다 (@st.cache_resource). 자세한 내용은 여기에서 확인하실 수 있습니다.</p>
<h2>일부 그래픽 조정</h2>
<p>이제 기본 Streamlit 페이지 요소와 챗봇에 사용할 아이콘을 설정할 수 있습니다.</p>
<pre><code class="hljs language-js">#아바타
av_us = <span class="hljs-string">'🧑‍💻'</span>  # <span class="hljs-string">'./man.png'</span>  #<span class="hljs-string">"🦖"</span>  # <span class="hljs-string">"🧑‍💻"</span>, <span class="hljs-string">"🤖"</span>, <span class="hljs-string">"🦖"</span>과 같은 단일 이모지입니다. <span class="hljs-title class_">Shortcut</span>은 지원되지 않습니다.
av_ass = <span class="hljs-string">"🤖"</span>   #<span class="hljs-string">'./robot.png'</span>
# 기본 모델 설정

### <span class="hljs-variable constant_">STREAMLIT</span> <span class="hljs-variable constant_">UI</span> 시작
st.<span class="hljs-title function_">image</span>(<span class="hljs-string">'https://github.com/fabiomatricardi/ChatBOTMastery/raw/main/qwen100logo.png'</span>, )
st.<span class="hljs-title function_">markdown</span>(<span class="hljs-string">"### *Streamlit &#x26; Gradio_client로 구동됨*"</span>, unsafe_allow_html=<span class="hljs-title class_">True</span> )
st.<span class="hljs-title function_">markdown</span>(<span class="hljs-string">'---'</span>)

client = <span class="hljs-title function_">create_client</span>()
</code></pre>
<div class="content-ad"></div>
<ul>
<li>채팅 인터페이스에 로컬 이미지를 사용할 수도 있어요 (코드의 주석을 참고하세요!)</li>
<li>마지막으로, create_client()로 클라이언트 연결을 인스턴스화해요.</li>
</ul>
<h1>본문 — 채팅 인터페이스</h1>
<p>Streamlit은 자신의 위젯에 변경이 발생할 때마다 또는 입력(버튼, 선택기, 라디오 요소 등)으로 사용자 조작이 호출될 때마다 코드를 맨 위부터 다시 실행해요.</p>
<p>그래서 저희는 대화 기록을 맨 위에 먼저 렌더링하기 시작했어요. 여기서는 뭐라도 새롭게 발명한 건 없어요: Streamlit 블로그의 공식 자습서에서 모두 배웠거든요.</p>
<div class="content-ad"></div>
<p>이것은 표준 렌더링입니다. OpenAI API와 호환되는 chat_completion 형식에 모두 적용 가능합니다.</p>
<p>코드로 돌아가서, 우리는 chat_template 메시지들을 표시하고, 메시지 목록을 반복하며 사용자 프롬프트(myprompt)가 제출되기를 기다립니다.</p>
<pre><code class="hljs language-js"># 앱 재실행 시 이전 대화 내용을 보여줍니다
<span class="hljs-keyword">for</span> message <span class="hljs-keyword">in</span> st.<span class="hljs-property">session_state</span>.<span class="hljs-property">messages</span>:
    <span class="hljs-keyword">if</span> message[<span class="hljs-string">"role"</span>] == <span class="hljs-string">"user"</span>:
        <span class="hljs-keyword">with</span> st.<span class="hljs-title function_">chat_message</span>(message[<span class="hljs-string">"role"</span>],avatar=av_us):
            st.<span class="hljs-title function_">markdown</span>(message[<span class="hljs-string">"content"</span>])
    <span class="hljs-attr">else</span>:
        <span class="hljs-keyword">with</span> st.<span class="hljs-title function_">chat_message</span>(message[<span class="hljs-string">"role"</span>],avatar=av_ass):
            st.<span class="hljs-title function_">markdown</span>(message[<span class="hljs-string">"content"</span>])
# 사용자 입력 받기
<span class="hljs-keyword">if</span> myprompt := st.<span class="hljs-title function_">chat_input</span>(<span class="hljs-string">"인공지능 모델이란 무엇인가요?"</span>):
    # 사용자 메시지를 대화 내역에 추가
    st.<span class="hljs-property">session_state</span>.<span class="hljs-property">messages</span>.<span class="hljs-title function_">append</span>({<span class="hljs-string">"role"</span>: <span class="hljs-string">"user"</span>, <span class="hljs-string">"content"</span>: myprompt})
    # 대화 메시지 컨테이너에 사용자 메시지 표시
    <span class="hljs-keyword">with</span> st.<span class="hljs-title function_">chat_message</span>(<span class="hljs-string">"user"</span>, avatar=av_us):
        st.<span class="hljs-title function_">markdown</span>(myprompt)
        usertext = f<span class="hljs-string">"user: {myprompt}"</span>
        <span class="hljs-title function_">writehistory</span>(usertext)
        # 차후 사용을 위해 대화 상대의 응답을 표시
</code></pre>
<p>여기에 이상한 writehistory(usertext) 지시문을 추가하고 있는 것을 볼 수 있습니다. 기억하시나요? 처음에 이 함수를 선언했던 거죠? 저는 모든 대화 내용을 로컬 텍스트 파일에 저장하는 버릇이 있어요. 이는 프롬프트를 분석하거나 미래 활용을 위해 자료를 조직화할 때 매우 편리합니다.🙂</p>
<div class="content-ad"></div>
<p>프롬프트에서 제출된 내용을 확인한 후, gradio 클라이언트 인스턴스(client.submit)를 호출하고 스트리밍을 시작합니다 (message_placeholder.markdown(r[1][0][1]+ "▌"))</p>
<pre><code class="hljs language-js">    # 채팅 메시지 컨테이너에 어시스턴트 응답 표시
    <span class="hljs-keyword">with</span> st.<span class="hljs-title function_">chat_message</span>(<span class="hljs-string">"assistant"</span>):
        message_placeholder = st.<span class="hljs-title function_">empty</span>()
        full_response = <span class="hljs-string">""</span>
        res  =  client.<span class="hljs-title function_">submit</span>(
                query=myprompt,
                history=[],
                system=<span class="hljs-string">"You are a helpful assistant."</span>,
                api_name=<span class="hljs-string">"/model_chat"</span>
                )        
        <span class="hljs-keyword">for</span> r <span class="hljs-keyword">in</span> <span class="hljs-attr">res</span>:
            full_response=r[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]
            message_placeholder.<span class="hljs-title function_">markdown</span>(r[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>][<span class="hljs-number">1</span>]+ <span class="hljs-string">"▌"</span>)

        message_placeholder.<span class="hljs-title function_">markdown</span>(full_response)
        asstext = f<span class="hljs-string">"assistant: {full_response}"</span>
        <span class="hljs-title function_">writehistory</span>(asstext)       
        st.<span class="hljs-property">session_state</span>.<span class="hljs-property">messages</span>.<span class="hljs-title function_">append</span>({<span class="hljs-string">"role"</span>: <span class="hljs-string">"assistant"</span>, <span class="hljs-string">"content"</span>: full_response})
</code></pre>
<p>이게 전부에요. full_response는 최종 텍스트가 들어 있는 변수이므로 대화 기록에도 추가하여 표시합니다.</p>
<p>해결했으면 댓글에 알려주세요 👍</p>
<div class="content-ad"></div>
<p>파이썬 파일을 저장한 후 터미널에서 가상 환경을 활성화한 상태에서 다음과 같이 실행하세요.</p>
<pre><code class="hljs language-js">streamlit run .\st-<span class="hljs-title class_">Qwen1</span><span class="hljs-number">.5</span>-110B-<span class="hljs-title class_">Chat</span>.<span class="hljs-property">py</span>
</code></pre>
<p>아래처럼 나와야 합니다... 그리고 기본 브라우저가 로컬 URL인 <a href="http://localhost:8501%EB%A1%9C" rel="nofollow" target="_blank">http://localhost:8501로</a> 열리게 됩니다.</p>
<p><img src="/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_0.png" alt="이미지"></p>
<div class="content-ad"></div>
<p>Streamlit은 로컬 네트워크로의 편리한 라우팅을 제공합니다. 예를 들어, 핸드폰이 동일한 액세스 포인트에 연결되어 있으면 Network URL로 표시된 주소인 <a href="http://192.168.2.6:8501%EC%9D%84" rel="nofollow" target="_blank">http://192.168.2.6:8501을</a> 통해 핸드폰에서도 이 애플리케이션을 사용할 수 있습니다.</p>
<p><img src="/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_1.png" alt="이미지"></p>
<h1>다른 모델 실행에 대한 참고 사항</h1>
<p>GitHub 리포지토리에서도 Streamlit Python 파일을 실행하는 방법을 찾을 수 있습니다.</p>
<div class="content-ad"></div>
<ul>
<li>OpenELM 3B</li>
<li>Phi-3-mini-Instruct 128k</li>
<li>QwenMoE</li>
</ul>
<p>고객 구성이 변경될 예정입니다 (물론...) 그리고 스트리밍 지침도 변경될 것입니다. 이는 API 엔드포인트가 다른 데이터 유형을 반환하기 때문에 발생합니다. OpenELM 및 Phi-3의 경우 순수한 문자열이 반환되므로 어떠한 사전/튜플 위치에 있는 LLM 응답을 추출할 필요가 없습니다. 여기를 살펴보세요:</p>
<p>그리고 또한 PLEASE, 기억해주세요...</p>
<p><img src="/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_2.png" alt="이미지"></p>
<div class="content-ad"></div>
<h1>결론</h1>
<p>이 모든 복잡성을 다루는 이유는 무엇일까요? 우리는 어떻게 일하는지 배우고, 나만의 AI 비서를 만드는 방법을 알고 싶기 때문입니다. 내가 상상할 수 있는 최고의 목적을 위해 콘텐츠 생성, 학습 자료, 프레젠테이션, 교육 지원 등.</p>
<p>어디에 사용할 건가요?</p>
<p>글이 마음에 드셨으면 좋겣습니다. 이 이야기가 가치를 제공했고 조금이라도 지원하고 싶다면 다음을 해볼 수 있습니다 :</p>
<div class="content-ad"></div>
<ul>
<li>이 이야기에 대해 많이 박수를 쳐 주세요</li>
<li>기억할 가치가 있는 부분을 강조하십시오 (나중에 찾기 쉽고, 더 나은 기사를 쓰는 데 도움이 될 것입니다)</li>
<li>Build Your Own AI를 시작하는 방법을 배우려면, 무료 eBook을 다운로드하세요</li>
<li>내 링크를 사용하여 Medium 멤버십 가입하기 - (무제한 Medium 이야기를 읽으려면 매달 $5)</li>
<li>Medium에서 나를 팔로우하기</li>
<li>내 최신 기사 읽기 <a href="https://medium.com/@fabio.matricardi" rel="nofollow" target="_blank">https://medium.com/@fabio.matricardi</a></li>
</ul>
<p>여기 몇 가지 더 흥미로운 읽을거리:</p>
<p>추가 학습 자료</p>
<p><img src="/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_3.png" alt="이미지"></p>
<div class="content-ad"></div>
<p>이 이야기는 Generative AI Publication에서 발행되었습니다.</p>
<p>최신 AI 이야기를 놓치지 않으려면 Substack, LinkedIn 및 Zeniteq에서 저희와 연락하여 AI의 미래를 함께 창조해보세요!</p>
<p><img src="/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_4.png" alt="이미지"></p>
</body>
</html>
</div></article></div></main></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"title":"챗봇 치트 코드 Qwen110B로 스트림릿에서 돈을 쓰지 않고 활용하는 방법","description":"","date":"2024-05-17 03:23","slug":"2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2","content":"\n\n제1부에서는 수십억 개의 매개변수를 가진 큰 언어 모델에 무료로 액세스하고 활용할 수 있다는 것을 발견했어요. 제처럼 여러분도 하드웨어 한정으로 고민 중이라면, 이 해킹 방법은 하이엔드 GPU나 유료 구독 없이도 Qwen-110B-chat과 같은 대규모 모델과 상호 작용할 수 있는 기쁨을 선사할 거예요.\n\n제2부에서는 지금부터 체험을 더 향상시키기 위해 스트림릿 인터페이스로 동일한 개념을 적용하여 챗봇에 시각적으로 매력적인 스트리밍 효과를 추가할 거예요.\n\n과정을 되짚어보자면, Python, Gradio_client 및 코딩 능력이 필요해요. AI 챗봇을 텍스트 인터페이스를 통해 만드는 데 초점을 맞추었어요:\n\n- 환경 설정: 먼저 가상 환경을 만들고 필요한 패키지(huggingface_hub, gradio-client 및 streamlit)를 설치하세요. PyTorch나 TensorFlow가 필요하지 않으며, 상호 작용은 API를 통해 이루어질 거예요.\n- Hugging Face API 토큰: 사용자는 Hugging Face에 등록하고 모델 추론 API에 액세스하기 위해 API 토큰을 생성해야 해요.\n- 챗봇 코딩: Hugging Face Spaces에서 Gradio의 \"API를 통해 사용\" 기능을 활용하여 이러한 강력한 모델에 Python 코드로 연결하는 방법을 배웠어요. 특히 여러 언어로 상업적 이용을 위한 라이선스가 허용되는 Qwen 시리즈 모델에 초점을 맞췄어요.\n- 스트리밍 효과: 코드 구조를 살펴보면, 모델과 상호 작용할 수 있는 함수를 만드는 방법을 설명했어요. predict() 및 submit() 메서드 중에서 선택하여 스트리밍 효과와 함께 또는 없이 응답을 생성하는 방법을 강조했어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n조금 헤매고 있다면 part 1부터 시작하는 것을 제안해요:\n\n## 핵심 코드부터 Streamlit 인터페이스까지\n\n이걸 꼭 말해야 해요: 터미널에서 모든 앱이 정상 작동하지 않으면 그래픽 인터페이스를 시작하지 말아야 해요.\n\n이건 필수 조건이에요! 그래서 Streamlit 인터페이스를 만드는 것이 아주 쉬울 거에요: 이미 이전 파트에서 라이브러리와 상호작용이 어떻게 작동하는지 확인했기 때문이죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모든 것은 이 핵심을 중심으로 움직입니다:\n\n```js\nfrom gradio_client import Client\n\nclient = Client(\"Qwen/Qwen1.5-110B-Chat-demo\")\nresult = client.submit(\n        query='What is Science?',\n        history=[],\n        system=\"You are a helpful assistant.\",\n        api_name=\"/model_chat\"\n)\nprint(result)\n```\n\n그리고 submit() 메소드를 사용하여 스트리밍 객체/반복자를 얻을 수 있다는 것을 알고 있습니다. Streamlit을 사용하면 스트림을 다루기가 훨씬 쉬워집니다. 사실, 애플리케이션은 항상 페이지 위젯을 새로 고치기 때문에 텍스트 애플리케이션에서 사용되는 지루한 알고리즘을 무시할 수 있습니다. 기억하시나요?\n\n```js\n    final = ''\n    for chunk in result:\n        if final == '':\n            final=chunk[1][0][1]\n            print(chunk[1][0][1], end=\"\", flush=True)\n        else:\n            try:\n                print(chunk[1][0][1].replace(final,''), end=\"\", flush=True)\n                final = chunk[1][0][1]\n            except:\n                pass    \n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nstring.replace()을 사용하여 이미 생성된 것에서 새로운 단어를 빼내는 작업을 했었는데, 더이상 필요하지 않아요.🥳\n\n# Streamlit 앱\n\n습관적인 사람이라... 그래서 내 코드가 다른 프로젝트와 매우 비슷하다는 사실을 발견할 수 있을 거에요. 그런데 괜찮아요! 결국, 템플릿을 적용하고 수정하는 것이 매번 처음부터 시작하는 것보다 쉽고 빠를 수 있거든.\n\n새 파일을 만들어보세요: 제 파일은 st-Qwen1.5–110B-Chat.py라고 해요. 주요 라이브러리를 가져와 세션 상태 전역 변수를 생성하는 것부터 시작해볼까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nimport streamlit as st\nimport time\nimport sys\nfrom gradio_client import Client\n# Internal usage\nimport os\nfrom time import sleep\n\n\nif \"hf_model\" not in st.session_state:\n    st.session_state.hf_model = \"Qwen1.5-110B-Chat\"\n# Initialize chat history\nif \"messages\" not in st.session_state:\n    st.session_state.messages = []\n```\n\n프로그램에서 전역 변수는 공유되어 사용될 수 있습니다. 또한 session_state라고 불리는 이러한 객체들이 streamlit의 매 실행마다 변경되지 않는 것을 필요로합니다.\n\n그리고 2가지 주요 함수를 정의합니다:\n\n```python\n@st.cache_resource\ndef create_client():   \n    yourHFtoken = \"hf_xxxxxxxxxxxxxxxxxxxxxxx\" #여기에 여러분의 HF 토큰을 넣으세요\n    print(f'{st.session_state.hf_model}에 대한 API Gradio 클라이언트를 로딩 중입니다.')\n    client = Client(\"Qwen/Qwen1.5-110B-Chat-demo\", hf_token=yourHFtoken)\n    return client\n\n# 모든 채팅 메시지를 chathistory.txt에 기록하는 함수\ndef writehistory(text):\n    with open('chathistorywen110b.txt', 'a', encoding='utf-8') as f:\n        f.write(text)\n        f.write('\\n')\n    f.close()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저희는 @st.cache_resource 데코레이터를 사용하고 있습니다. 이는 Qwen1.5-110에 대한 API gradio 클라이언트를 Streamlit이 매 실행마다 로딩하지 않기를 원하기 때문입니다 (이는 분당 1회 이상 발생할 수 있습니다): Gradio 클라이언트 연결이 실행 중에 변경되지 않을 것이기 때문에, 이 리소스를 특별한 메모리에 캐싱하고 있습니다 (@st.cache_resource). 자세한 내용은 여기에서 확인하실 수 있습니다.\n\n## 일부 그래픽 조정\n\n이제 기본 Streamlit 페이지 요소와 챗봇에 사용할 아이콘을 설정할 수 있습니다.\n\n```js\n#아바타\nav_us = '🧑‍💻'  # './man.png'  #\"🦖\"  # \"🧑‍💻\", \"🤖\", \"🦖\"과 같은 단일 이모지입니다. Shortcut은 지원되지 않습니다.\nav_ass = \"🤖\"   #'./robot.png'\n# 기본 모델 설정\n\n### STREAMLIT UI 시작\nst.image('https://github.com/fabiomatricardi/ChatBOTMastery/raw/main/qwen100logo.png', )\nst.markdown(\"### *Streamlit \u0026 Gradio_client로 구동됨*\", unsafe_allow_html=True )\nst.markdown('---')\n\nclient = create_client()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 채팅 인터페이스에 로컬 이미지를 사용할 수도 있어요 (코드의 주석을 참고하세요!)\n- 마지막으로, create_client()로 클라이언트 연결을 인스턴스화해요.\n\n# 본문 — 채팅 인터페이스\n\nStreamlit은 자신의 위젯에 변경이 발생할 때마다 또는 입력(버튼, 선택기, 라디오 요소 등)으로 사용자 조작이 호출될 때마다 코드를 맨 위부터 다시 실행해요.\n\n그래서 저희는 대화 기록을 맨 위에 먼저 렌더링하기 시작했어요. 여기서는 뭐라도 새롭게 발명한 건 없어요: Streamlit 블로그의 공식 자습서에서 모두 배웠거든요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이것은 표준 렌더링입니다. OpenAI API와 호환되는 chat_completion 형식에 모두 적용 가능합니다.\n\n코드로 돌아가서, 우리는 chat_template 메시지들을 표시하고, 메시지 목록을 반복하며 사용자 프롬프트(myprompt)가 제출되기를 기다립니다.\n\n```js\n# 앱 재실행 시 이전 대화 내용을 보여줍니다\nfor message in st.session_state.messages:\n    if message[\"role\"] == \"user\":\n        with st.chat_message(message[\"role\"],avatar=av_us):\n            st.markdown(message[\"content\"])\n    else:\n        with st.chat_message(message[\"role\"],avatar=av_ass):\n            st.markdown(message[\"content\"])\n# 사용자 입력 받기\nif myprompt := st.chat_input(\"인공지능 모델이란 무엇인가요?\"):\n    # 사용자 메시지를 대화 내역에 추가\n    st.session_state.messages.append({\"role\": \"user\", \"content\": myprompt})\n    # 대화 메시지 컨테이너에 사용자 메시지 표시\n    with st.chat_message(\"user\", avatar=av_us):\n        st.markdown(myprompt)\n        usertext = f\"user: {myprompt}\"\n        writehistory(usertext)\n        # 차후 사용을 위해 대화 상대의 응답을 표시\n```\n\n여기에 이상한 writehistory(usertext) 지시문을 추가하고 있는 것을 볼 수 있습니다. 기억하시나요? 처음에 이 함수를 선언했던 거죠? 저는 모든 대화 내용을 로컬 텍스트 파일에 저장하는 버릇이 있어요. 이는 프롬프트를 분석하거나 미래 활용을 위해 자료를 조직화할 때 매우 편리합니다.🙂\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프롬프트에서 제출된 내용을 확인한 후, gradio 클라이언트 인스턴스(client.submit)를 호출하고 스트리밍을 시작합니다 (message_placeholder.markdown(r[1][0][1]+ \"▌\"))\n\n```js\n    # 채팅 메시지 컨테이너에 어시스턴트 응답 표시\n    with st.chat_message(\"assistant\"):\n        message_placeholder = st.empty()\n        full_response = \"\"\n        res  =  client.submit(\n                query=myprompt,\n                history=[],\n                system=\"You are a helpful assistant.\",\n                api_name=\"/model_chat\"\n                )        \n        for r in res:\n            full_response=r[1][0][1]\n            message_placeholder.markdown(r[1][0][1]+ \"▌\")\n\n        message_placeholder.markdown(full_response)\n        asstext = f\"assistant: {full_response}\"\n        writehistory(asstext)       \n        st.session_state.messages.append({\"role\": \"assistant\", \"content\": full_response})\n```\n\n이게 전부에요. full_response는 최종 텍스트가 들어 있는 변수이므로 대화 기록에도 추가하여 표시합니다.\n\n해결했으면 댓글에 알려주세요 👍\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이썬 파일을 저장한 후 터미널에서 가상 환경을 활성화한 상태에서 다음과 같이 실행하세요.\n\n```js\nstreamlit run .\\st-Qwen1.5-110B-Chat.py\n```\n\n아래처럼 나와야 합니다... 그리고 기본 브라우저가 로컬 URL인 http://localhost:8501로 열리게 됩니다.\n\n![이미지](/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nStreamlit은 로컬 네트워크로의 편리한 라우팅을 제공합니다. 예를 들어, 핸드폰이 동일한 액세스 포인트에 연결되어 있으면 Network URL로 표시된 주소인 http://192.168.2.6:8501을 통해 핸드폰에서도 이 애플리케이션을 사용할 수 있습니다.\n\n![이미지](/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_1.png)\n\n# 다른 모델 실행에 대한 참고 사항\n\nGitHub 리포지토리에서도 Streamlit Python 파일을 실행하는 방법을 찾을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- OpenELM 3B\n- Phi-3-mini-Instruct 128k\n- QwenMoE\n\n고객 구성이 변경될 예정입니다 (물론...) 그리고 스트리밍 지침도 변경될 것입니다. 이는 API 엔드포인트가 다른 데이터 유형을 반환하기 때문에 발생합니다. OpenELM 및 Phi-3의 경우 순수한 문자열이 반환되므로 어떠한 사전/튜플 위치에 있는 LLM 응답을 추출할 필요가 없습니다. 여기를 살펴보세요:\n\n그리고 또한 PLEASE, 기억해주세요...\n\n![이미지](/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n이 모든 복잡성을 다루는 이유는 무엇일까요? 우리는 어떻게 일하는지 배우고, 나만의 AI 비서를 만드는 방법을 알고 싶기 때문입니다. 내가 상상할 수 있는 최고의 목적을 위해 콘텐츠 생성, 학습 자료, 프레젠테이션, 교육 지원 등.\n\n어디에 사용할 건가요?\n\n글이 마음에 드셨으면 좋겣습니다. 이 이야기가 가치를 제공했고 조금이라도 지원하고 싶다면 다음을 해볼 수 있습니다 :\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 이 이야기에 대해 많이 박수를 쳐 주세요\n- 기억할 가치가 있는 부분을 강조하십시오 (나중에 찾기 쉽고, 더 나은 기사를 쓰는 데 도움이 될 것입니다)\n- Build Your Own AI를 시작하는 방법을 배우려면, 무료 eBook을 다운로드하세요\n- 내 링크를 사용하여 Medium 멤버십 가입하기 - (무제한 Medium 이야기를 읽으려면 매달 $5)\n- Medium에서 나를 팔로우하기\n- 내 최신 기사 읽기 https://medium.com/@fabio.matricardi\n\n여기 몇 가지 더 흥미로운 읽을거리:\n\n추가 학습 자료\n\n![이미지](/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 이야기는 Generative AI Publication에서 발행되었습니다.\n\n최신 AI 이야기를 놓치지 않으려면 Substack, LinkedIn 및 Zeniteq에서 저희와 연락하여 AI의 미래를 함께 창조해보세요!\n\n![이미지](/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_4.png)","ogImage":{"url":"/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_0.png"},"coverImage":"/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_0.png","tag":["Tech"],"readingTime":9},"content":"\u003c!doctype html\u003e\n\u003chtml lang=\"en\"\u003e\n\u003chead\u003e\n\u003cmeta charset=\"utf-8\"\u003e\n\u003cmeta content=\"width=device-width, initial-scale=1\" name=\"viewport\"\u003e\n\u003c/head\u003e\n\u003cbody\u003e\n\u003cp\u003e제1부에서는 수십억 개의 매개변수를 가진 큰 언어 모델에 무료로 액세스하고 활용할 수 있다는 것을 발견했어요. 제처럼 여러분도 하드웨어 한정으로 고민 중이라면, 이 해킹 방법은 하이엔드 GPU나 유료 구독 없이도 Qwen-110B-chat과 같은 대규모 모델과 상호 작용할 수 있는 기쁨을 선사할 거예요.\u003c/p\u003e\n\u003cp\u003e제2부에서는 지금부터 체험을 더 향상시키기 위해 스트림릿 인터페이스로 동일한 개념을 적용하여 챗봇에 시각적으로 매력적인 스트리밍 효과를 추가할 거예요.\u003c/p\u003e\n\u003cp\u003e과정을 되짚어보자면, Python, Gradio_client 및 코딩 능력이 필요해요. AI 챗봇을 텍스트 인터페이스를 통해 만드는 데 초점을 맞추었어요:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e환경 설정: 먼저 가상 환경을 만들고 필요한 패키지(huggingface_hub, gradio-client 및 streamlit)를 설치하세요. PyTorch나 TensorFlow가 필요하지 않으며, 상호 작용은 API를 통해 이루어질 거예요.\u003c/li\u003e\n\u003cli\u003eHugging Face API 토큰: 사용자는 Hugging Face에 등록하고 모델 추론 API에 액세스하기 위해 API 토큰을 생성해야 해요.\u003c/li\u003e\n\u003cli\u003e챗봇 코딩: Hugging Face Spaces에서 Gradio의 \"API를 통해 사용\" 기능을 활용하여 이러한 강력한 모델에 Python 코드로 연결하는 방법을 배웠어요. 특히 여러 언어로 상업적 이용을 위한 라이선스가 허용되는 Qwen 시리즈 모델에 초점을 맞췄어요.\u003c/li\u003e\n\u003cli\u003e스트리밍 효과: 코드 구조를 살펴보면, 모델과 상호 작용할 수 있는 함수를 만드는 방법을 설명했어요. predict() 및 submit() 메서드 중에서 선택하여 스트리밍 효과와 함께 또는 없이 응답을 생성하는 방법을 강조했어요.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e조금 헤매고 있다면 part 1부터 시작하는 것을 제안해요:\u003c/p\u003e\n\u003ch2\u003e핵심 코드부터 Streamlit 인터페이스까지\u003c/h2\u003e\n\u003cp\u003e이걸 꼭 말해야 해요: 터미널에서 모든 앱이 정상 작동하지 않으면 그래픽 인터페이스를 시작하지 말아야 해요.\u003c/p\u003e\n\u003cp\u003e이건 필수 조건이에요! 그래서 Streamlit 인터페이스를 만드는 것이 아주 쉬울 거에요: 이미 이전 파트에서 라이브러리와 상호작용이 어떻게 작동하는지 확인했기 때문이죠.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e모든 것은 이 핵심을 중심으로 움직입니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e gradio_client \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e \u003cspan class=\"hljs-title class_\"\u003eClient\u003c/span\u003e\n\nclient = \u003cspan class=\"hljs-title class_\"\u003eClient\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"Qwen/Qwen1.5-110B-Chat-demo\"\u003c/span\u003e)\nresult = client.\u003cspan class=\"hljs-title function_\"\u003esubmit\u003c/span\u003e(\n        query=\u003cspan class=\"hljs-string\"\u003e'What is Science?'\u003c/span\u003e,\n        history=[],\n        system=\u003cspan class=\"hljs-string\"\u003e\"You are a helpful assistant.\"\u003c/span\u003e,\n        api_name=\u003cspan class=\"hljs-string\"\u003e\"/model_chat\"\u003c/span\u003e\n)\n\u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(result)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e그리고 submit() 메소드를 사용하여 스트리밍 객체/반복자를 얻을 수 있다는 것을 알고 있습니다. Streamlit을 사용하면 스트림을 다루기가 훨씬 쉬워집니다. 사실, 애플리케이션은 항상 페이지 위젯을 새로 고치기 때문에 텍스트 애플리케이션에서 사용되는 지루한 알고리즘을 무시할 수 있습니다. 기억하시나요?\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e    final = \u003cspan class=\"hljs-string\"\u003e''\u003c/span\u003e\n    \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e chunk \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003eresult\u003c/span\u003e:\n        \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e final == \u003cspan class=\"hljs-string\"\u003e''\u003c/span\u003e:\n            final=chunk[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e][\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e][\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]\n            \u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(chunk[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e][\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e][\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e], end=\u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e, flush=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e)\n        \u003cspan class=\"hljs-attr\"\u003eelse\u003c/span\u003e:\n            \u003cspan class=\"hljs-attr\"\u003etry\u003c/span\u003e:\n                \u003cspan class=\"hljs-title function_\"\u003eprint\u003c/span\u003e(chunk[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e][\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e][\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e].\u003cspan class=\"hljs-title function_\"\u003ereplace\u003c/span\u003e(final,\u003cspan class=\"hljs-string\"\u003e''\u003c/span\u003e), end=\u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e, flush=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e)\n                final = chunk[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e][\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e][\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]\n            \u003cspan class=\"hljs-attr\"\u003eexcept\u003c/span\u003e:\n                pass    \n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003estring.replace()을 사용하여 이미 생성된 것에서 새로운 단어를 빼내는 작업을 했었는데, 더이상 필요하지 않아요.🥳\u003c/p\u003e\n\u003ch1\u003eStreamlit 앱\u003c/h1\u003e\n\u003cp\u003e습관적인 사람이라... 그래서 내 코드가 다른 프로젝트와 매우 비슷하다는 사실을 발견할 수 있을 거에요. 그런데 괜찮아요! 결국, 템플릿을 적용하고 수정하는 것이 매번 처음부터 시작하는 것보다 쉽고 빠를 수 있거든.\u003c/p\u003e\n\u003cp\u003e새 파일을 만들어보세요: 제 파일은 st-Qwen1.5–110B-Chat.py라고 해요. 주요 라이브러리를 가져와 세션 상태 전역 변수를 생성하는 것부터 시작해볼까요?\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e streamlit \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e st\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e time\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e sys\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e gradio_client \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e Client\n\u003cspan class=\"hljs-comment\"\u003e# Internal usage\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e os\n\u003cspan class=\"hljs-keyword\"\u003efrom\u003c/span\u003e time \u003cspan class=\"hljs-keyword\"\u003eimport\u003c/span\u003e sleep\n\n\n\u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"hf_model\"\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003enot\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e st.session_state:\n    st.session_state.hf_model = \u003cspan class=\"hljs-string\"\u003e\"Qwen1.5-110B-Chat\"\u003c/span\u003e\n\u003cspan class=\"hljs-comment\"\u003e# Initialize chat history\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e \u003cspan class=\"hljs-string\"\u003e\"messages\"\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003enot\u003c/span\u003e \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e st.session_state:\n    st.session_state.messages = []\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e프로그램에서 전역 변수는 공유되어 사용될 수 있습니다. 또한 session_state라고 불리는 이러한 객체들이 streamlit의 매 실행마다 변경되지 않는 것을 필요로합니다.\u003c/p\u003e\n\u003cp\u003e그리고 2가지 주요 함수를 정의합니다:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-python\"\u003e\u003cspan class=\"hljs-meta\"\u003e@st.cache_resource\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003ecreate_client\u003c/span\u003e():   \n    yourHFtoken = \u003cspan class=\"hljs-string\"\u003e\"hf_xxxxxxxxxxxxxxxxxxxxxxx\"\u003c/span\u003e \u003cspan class=\"hljs-comment\"\u003e#여기에 여러분의 HF 토큰을 넣으세요\u003c/span\u003e\n    \u003cspan class=\"hljs-built_in\"\u003eprint\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003ef'\u003cspan class=\"hljs-subst\"\u003e{st.session_state.hf_model}\u003c/span\u003e에 대한 API Gradio 클라이언트를 로딩 중입니다.'\u003c/span\u003e)\n    client = Client(\u003cspan class=\"hljs-string\"\u003e\"Qwen/Qwen1.5-110B-Chat-demo\"\u003c/span\u003e, hf_token=yourHFtoken)\n    \u003cspan class=\"hljs-keyword\"\u003ereturn\u003c/span\u003e client\n\n\u003cspan class=\"hljs-comment\"\u003e# 모든 채팅 메시지를 chathistory.txt에 기록하는 함수\u003c/span\u003e\n\u003cspan class=\"hljs-keyword\"\u003edef\u003c/span\u003e \u003cspan class=\"hljs-title function_\"\u003ewritehistory\u003c/span\u003e(\u003cspan class=\"hljs-params\"\u003etext\u003c/span\u003e):\n    \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e \u003cspan class=\"hljs-built_in\"\u003eopen\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'chathistorywen110b.txt'\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e'a'\u003c/span\u003e, encoding=\u003cspan class=\"hljs-string\"\u003e'utf-8'\u003c/span\u003e) \u003cspan class=\"hljs-keyword\"\u003eas\u003c/span\u003e f:\n        f.write(text)\n        f.write(\u003cspan class=\"hljs-string\"\u003e'\\n'\u003c/span\u003e)\n    f.close()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e저희는 @st.cache_resource 데코레이터를 사용하고 있습니다. 이는 Qwen1.5-110에 대한 API gradio 클라이언트를 Streamlit이 매 실행마다 로딩하지 않기를 원하기 때문입니다 (이는 분당 1회 이상 발생할 수 있습니다): Gradio 클라이언트 연결이 실행 중에 변경되지 않을 것이기 때문에, 이 리소스를 특별한 메모리에 캐싱하고 있습니다 (@st.cache_resource). 자세한 내용은 여기에서 확인하실 수 있습니다.\u003c/p\u003e\n\u003ch2\u003e일부 그래픽 조정\u003c/h2\u003e\n\u003cp\u003e이제 기본 Streamlit 페이지 요소와 챗봇에 사용할 아이콘을 설정할 수 있습니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e#아바타\nav_us = \u003cspan class=\"hljs-string\"\u003e'🧑‍💻'\u003c/span\u003e  # \u003cspan class=\"hljs-string\"\u003e'./man.png'\u003c/span\u003e  #\u003cspan class=\"hljs-string\"\u003e\"🦖\"\u003c/span\u003e  # \u003cspan class=\"hljs-string\"\u003e\"🧑‍💻\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"🤖\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"🦖\"\u003c/span\u003e과 같은 단일 이모지입니다. \u003cspan class=\"hljs-title class_\"\u003eShortcut\u003c/span\u003e은 지원되지 않습니다.\nav_ass = \u003cspan class=\"hljs-string\"\u003e\"🤖\"\u003c/span\u003e   #\u003cspan class=\"hljs-string\"\u003e'./robot.png'\u003c/span\u003e\n# 기본 모델 설정\n\n### \u003cspan class=\"hljs-variable constant_\"\u003eSTREAMLIT\u003c/span\u003e \u003cspan class=\"hljs-variable constant_\"\u003eUI\u003c/span\u003e 시작\nst.\u003cspan class=\"hljs-title function_\"\u003eimage\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'https://github.com/fabiomatricardi/ChatBOTMastery/raw/main/qwen100logo.png'\u003c/span\u003e, )\nst.\u003cspan class=\"hljs-title function_\"\u003emarkdown\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"### *Streamlit \u0026#x26; Gradio_client로 구동됨*\"\u003c/span\u003e, unsafe_allow_html=\u003cspan class=\"hljs-title class_\"\u003eTrue\u003c/span\u003e )\nst.\u003cspan class=\"hljs-title function_\"\u003emarkdown\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e'---'\u003c/span\u003e)\n\nclient = \u003cspan class=\"hljs-title function_\"\u003ecreate_client\u003c/span\u003e()\n\u003c/code\u003e\u003c/pre\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e채팅 인터페이스에 로컬 이미지를 사용할 수도 있어요 (코드의 주석을 참고하세요!)\u003c/li\u003e\n\u003cli\u003e마지막으로, create_client()로 클라이언트 연결을 인스턴스화해요.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1\u003e본문 — 채팅 인터페이스\u003c/h1\u003e\n\u003cp\u003eStreamlit은 자신의 위젯에 변경이 발생할 때마다 또는 입력(버튼, 선택기, 라디오 요소 등)으로 사용자 조작이 호출될 때마다 코드를 맨 위부터 다시 실행해요.\u003c/p\u003e\n\u003cp\u003e그래서 저희는 대화 기록을 맨 위에 먼저 렌더링하기 시작했어요. 여기서는 뭐라도 새롭게 발명한 건 없어요: Streamlit 블로그의 공식 자습서에서 모두 배웠거든요.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이것은 표준 렌더링입니다. OpenAI API와 호환되는 chat_completion 형식에 모두 적용 가능합니다.\u003c/p\u003e\n\u003cp\u003e코드로 돌아가서, 우리는 chat_template 메시지들을 표시하고, 메시지 목록을 반복하며 사용자 프롬프트(myprompt)가 제출되기를 기다립니다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e# 앱 재실행 시 이전 대화 내용을 보여줍니다\n\u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e message \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e st.\u003cspan class=\"hljs-property\"\u003esession_state\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003emessages\u003c/span\u003e:\n    \u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e message[\u003cspan class=\"hljs-string\"\u003e\"role\"\u003c/span\u003e] == \u003cspan class=\"hljs-string\"\u003e\"user\"\u003c/span\u003e:\n        \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e st.\u003cspan class=\"hljs-title function_\"\u003echat_message\u003c/span\u003e(message[\u003cspan class=\"hljs-string\"\u003e\"role\"\u003c/span\u003e],avatar=av_us):\n            st.\u003cspan class=\"hljs-title function_\"\u003emarkdown\u003c/span\u003e(message[\u003cspan class=\"hljs-string\"\u003e\"content\"\u003c/span\u003e])\n    \u003cspan class=\"hljs-attr\"\u003eelse\u003c/span\u003e:\n        \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e st.\u003cspan class=\"hljs-title function_\"\u003echat_message\u003c/span\u003e(message[\u003cspan class=\"hljs-string\"\u003e\"role\"\u003c/span\u003e],avatar=av_ass):\n            st.\u003cspan class=\"hljs-title function_\"\u003emarkdown\u003c/span\u003e(message[\u003cspan class=\"hljs-string\"\u003e\"content\"\u003c/span\u003e])\n# 사용자 입력 받기\n\u003cspan class=\"hljs-keyword\"\u003eif\u003c/span\u003e myprompt := st.\u003cspan class=\"hljs-title function_\"\u003echat_input\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"인공지능 모델이란 무엇인가요?\"\u003c/span\u003e):\n    # 사용자 메시지를 대화 내역에 추가\n    st.\u003cspan class=\"hljs-property\"\u003esession_state\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003emessages\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e({\u003cspan class=\"hljs-string\"\u003e\"role\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"user\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"content\"\u003c/span\u003e: myprompt})\n    # 대화 메시지 컨테이너에 사용자 메시지 표시\n    \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e st.\u003cspan class=\"hljs-title function_\"\u003echat_message\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"user\"\u003c/span\u003e, avatar=av_us):\n        st.\u003cspan class=\"hljs-title function_\"\u003emarkdown\u003c/span\u003e(myprompt)\n        usertext = f\u003cspan class=\"hljs-string\"\u003e\"user: {myprompt}\"\u003c/span\u003e\n        \u003cspan class=\"hljs-title function_\"\u003ewritehistory\u003c/span\u003e(usertext)\n        # 차후 사용을 위해 대화 상대의 응답을 표시\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e여기에 이상한 writehistory(usertext) 지시문을 추가하고 있는 것을 볼 수 있습니다. 기억하시나요? 처음에 이 함수를 선언했던 거죠? 저는 모든 대화 내용을 로컬 텍스트 파일에 저장하는 버릇이 있어요. 이는 프롬프트를 분석하거나 미래 활용을 위해 자료를 조직화할 때 매우 편리합니다.🙂\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e프롬프트에서 제출된 내용을 확인한 후, gradio 클라이언트 인스턴스(client.submit)를 호출하고 스트리밍을 시작합니다 (message_placeholder.markdown(r[1][0][1]+ \"▌\"))\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003e    # 채팅 메시지 컨테이너에 어시스턴트 응답 표시\n    \u003cspan class=\"hljs-keyword\"\u003ewith\u003c/span\u003e st.\u003cspan class=\"hljs-title function_\"\u003echat_message\u003c/span\u003e(\u003cspan class=\"hljs-string\"\u003e\"assistant\"\u003c/span\u003e):\n        message_placeholder = st.\u003cspan class=\"hljs-title function_\"\u003eempty\u003c/span\u003e()\n        full_response = \u003cspan class=\"hljs-string\"\u003e\"\"\u003c/span\u003e\n        res  =  client.\u003cspan class=\"hljs-title function_\"\u003esubmit\u003c/span\u003e(\n                query=myprompt,\n                history=[],\n                system=\u003cspan class=\"hljs-string\"\u003e\"You are a helpful assistant.\"\u003c/span\u003e,\n                api_name=\u003cspan class=\"hljs-string\"\u003e\"/model_chat\"\u003c/span\u003e\n                )        \n        \u003cspan class=\"hljs-keyword\"\u003efor\u003c/span\u003e r \u003cspan class=\"hljs-keyword\"\u003ein\u003c/span\u003e \u003cspan class=\"hljs-attr\"\u003eres\u003c/span\u003e:\n            full_response=r[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e][\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e][\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]\n            message_placeholder.\u003cspan class=\"hljs-title function_\"\u003emarkdown\u003c/span\u003e(r[\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e][\u003cspan class=\"hljs-number\"\u003e0\u003c/span\u003e][\u003cspan class=\"hljs-number\"\u003e1\u003c/span\u003e]+ \u003cspan class=\"hljs-string\"\u003e\"▌\"\u003c/span\u003e)\n\n        message_placeholder.\u003cspan class=\"hljs-title function_\"\u003emarkdown\u003c/span\u003e(full_response)\n        asstext = f\u003cspan class=\"hljs-string\"\u003e\"assistant: {full_response}\"\u003c/span\u003e\n        \u003cspan class=\"hljs-title function_\"\u003ewritehistory\u003c/span\u003e(asstext)       \n        st.\u003cspan class=\"hljs-property\"\u003esession_state\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003emessages\u003c/span\u003e.\u003cspan class=\"hljs-title function_\"\u003eappend\u003c/span\u003e({\u003cspan class=\"hljs-string\"\u003e\"role\"\u003c/span\u003e: \u003cspan class=\"hljs-string\"\u003e\"assistant\"\u003c/span\u003e, \u003cspan class=\"hljs-string\"\u003e\"content\"\u003c/span\u003e: full_response})\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e이게 전부에요. full_response는 최종 텍스트가 들어 있는 변수이므로 대화 기록에도 추가하여 표시합니다.\u003c/p\u003e\n\u003cp\u003e해결했으면 댓글에 알려주세요 👍\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e파이썬 파일을 저장한 후 터미널에서 가상 환경을 활성화한 상태에서 다음과 같이 실행하세요.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"hljs language-js\"\u003estreamlit run .\\st-\u003cspan class=\"hljs-title class_\"\u003eQwen1\u003c/span\u003e\u003cspan class=\"hljs-number\"\u003e.5\u003c/span\u003e-110B-\u003cspan class=\"hljs-title class_\"\u003eChat\u003c/span\u003e.\u003cspan class=\"hljs-property\"\u003epy\u003c/span\u003e\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e아래처럼 나와야 합니다... 그리고 기본 브라우저가 로컬 URL인 \u003ca href=\"http://localhost:8501%EB%A1%9C\" rel=\"nofollow\" target=\"_blank\"\u003ehttp://localhost:8501로\u003c/a\u003e 열리게 됩니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_0.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003eStreamlit은 로컬 네트워크로의 편리한 라우팅을 제공합니다. 예를 들어, 핸드폰이 동일한 액세스 포인트에 연결되어 있으면 Network URL로 표시된 주소인 \u003ca href=\"http://192.168.2.6:8501%EC%9D%84\" rel=\"nofollow\" target=\"_blank\"\u003ehttp://192.168.2.6:8501을\u003c/a\u003e 통해 핸드폰에서도 이 애플리케이션을 사용할 수 있습니다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_1.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003ch1\u003e다른 모델 실행에 대한 참고 사항\u003c/h1\u003e\n\u003cp\u003eGitHub 리포지토리에서도 Streamlit Python 파일을 실행하는 방법을 찾을 수 있습니다.\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003eOpenELM 3B\u003c/li\u003e\n\u003cli\u003ePhi-3-mini-Instruct 128k\u003c/li\u003e\n\u003cli\u003eQwenMoE\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e고객 구성이 변경될 예정입니다 (물론...) 그리고 스트리밍 지침도 변경될 것입니다. 이는 API 엔드포인트가 다른 데이터 유형을 반환하기 때문에 발생합니다. OpenELM 및 Phi-3의 경우 순수한 문자열이 반환되므로 어떠한 사전/튜플 위치에 있는 LLM 응답을 추출할 필요가 없습니다. 여기를 살펴보세요:\u003c/p\u003e\n\u003cp\u003e그리고 또한 PLEASE, 기억해주세요...\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_2.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003ch1\u003e결론\u003c/h1\u003e\n\u003cp\u003e이 모든 복잡성을 다루는 이유는 무엇일까요? 우리는 어떻게 일하는지 배우고, 나만의 AI 비서를 만드는 방법을 알고 싶기 때문입니다. 내가 상상할 수 있는 최고의 목적을 위해 콘텐츠 생성, 학습 자료, 프레젠테이션, 교육 지원 등.\u003c/p\u003e\n\u003cp\u003e어디에 사용할 건가요?\u003c/p\u003e\n\u003cp\u003e글이 마음에 드셨으면 좋겣습니다. 이 이야기가 가치를 제공했고 조금이라도 지원하고 싶다면 다음을 해볼 수 있습니다 :\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cul\u003e\n\u003cli\u003e이 이야기에 대해 많이 박수를 쳐 주세요\u003c/li\u003e\n\u003cli\u003e기억할 가치가 있는 부분을 강조하십시오 (나중에 찾기 쉽고, 더 나은 기사를 쓰는 데 도움이 될 것입니다)\u003c/li\u003e\n\u003cli\u003eBuild Your Own AI를 시작하는 방법을 배우려면, 무료 eBook을 다운로드하세요\u003c/li\u003e\n\u003cli\u003e내 링크를 사용하여 Medium 멤버십 가입하기 - (무제한 Medium 이야기를 읽으려면 매달 $5)\u003c/li\u003e\n\u003cli\u003eMedium에서 나를 팔로우하기\u003c/li\u003e\n\u003cli\u003e내 최신 기사 읽기 \u003ca href=\"https://medium.com/@fabio.matricardi\" rel=\"nofollow\" target=\"_blank\"\u003ehttps://medium.com/@fabio.matricardi\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e여기 몇 가지 더 흥미로운 읽을거리:\u003c/p\u003e\n\u003cp\u003e추가 학습 자료\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_3.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\u003cp\u003e이 이야기는 Generative AI Publication에서 발행되었습니다.\u003c/p\u003e\n\u003cp\u003e최신 AI 이야기를 놓치지 않으려면 Substack, LinkedIn 및 Zeniteq에서 저희와 연락하여 AI의 미래를 함께 창조해보세요!\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/assets/img/2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2_4.png\" alt=\"이미지\"\u003e\u003c/p\u003e\n\u003c/body\u003e\n\u003c/html\u003e\n"},"__N_SSG":true},"page":"/post/[slug]","query":{"slug":"2024-05-17-ChatbotcheatcodeQwen110BonStreamlitwithoutspendingapennyPart2"},"buildId":"OFpTzInQeZKWBaqJEukNX","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>