<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>allround-coder</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://allround-coder.github.io///posts/89" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="allround-coder" data-gatsby-head="true"/><meta property="og:title" content="allround-coder" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://allround-coder.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://allround-coder.github.io///posts/89" data-gatsby-head="true"/><meta name="twitter:title" content="allround-coder" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | allround-coder" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZFDEQ947R4"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
  
            gtag('config', 'G-ZFDEQ947R4');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-ec7535a55e788b31.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/t9N7vwmpvBMQnO2PSctoH/_buildManifest.js" defer=""></script><script src="/_next/static/t9N7vwmpvBMQnO2PSctoH/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Allround Coder</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="이미지 선명도를 평가하여 OCR 정확도 향상 기술" href="/post/2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="이미지 선명도를 평가하여 OCR 정확도 향상 기술" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="이미지 선명도를 평가하여 OCR 정확도 향상 기술" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">이미지 선명도를 평가하여 OCR 정확도 향상 기술</strong><div class="PostList_meta__VCFLX"><span class="date">May 15, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Nodejs 20 버전으로 업그레이드하기 - 성능과 효율성을 끌어올리는 다음 단계를 열다" href="/post/2024-05-15-UpgradingtoNodejsv20UnlockingtheNextLevelofPerformanceandEfficiency"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Nodejs 20 버전으로 업그레이드하기 - 성능과 효율성을 끌어올리는 다음 단계를 열다" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-15-UpgradingtoNodejsv20UnlockingtheNextLevelofPerformanceandEfficiency_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Nodejs 20 버전으로 업그레이드하기 - 성능과 효율성을 끌어올리는 다음 단계를 열다" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">Nodejs 20 버전으로 업그레이드하기 - 성능과 효율성을 끌어올리는 다음 단계를 열다</strong><div class="PostList_meta__VCFLX"><span class="date">May 15, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Astro와 Storyblok을 활용해 나만의 블로그 사이트를 만들어 본 경험 공유" href="/post/2024-05-15-HowIsetupmyBlogSitewithAstroandStoryblok"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Astro와 Storyblok을 활용해 나만의 블로그 사이트를 만들어 본 경험 공유" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-15-HowIsetupmyBlogSitewithAstroandStoryblok_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Astro와 Storyblok을 활용해 나만의 블로그 사이트를 만들어 본 경험 공유" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">Astro와 Storyblok을 활용해 나만의 블로그 사이트를 만들어 본 경험 공유</strong><div class="PostList_meta__VCFLX"><span class="date">May 15, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="자바에서의 지도 지향 프로그래밍" href="/post/2024-05-15-Map-OrientedProgramminginJava"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="자바에서의 지도 지향 프로그래밍" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-15-Map-OrientedProgramminginJava_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="자바에서의 지도 지향 프로그래밍" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">자바에서의 지도 지향 프로그래밍</strong><div class="PostList_meta__VCFLX"><span class="date">May 15, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="사이버 보안과 2024년 호주 연방 예산" href="/post/2024-05-15-CybersecurityandtheAustralianFederalBudget2024"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="사이버 보안과 2024년 호주 연방 예산" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-15-CybersecurityandtheAustralianFederalBudget2024_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="사이버 보안과 2024년 호주 연방 예산" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">사이버 보안과 2024년 호주 연방 예산</strong><div class="PostList_meta__VCFLX"><span class="date">May 15, 2024</span><span class="PostList_reading_time__6CBMQ">1<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="첫 번째 RCE를 발견한 방법" href="/post/2024-05-15-HowIFoundMyFirstRCE"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="첫 번째 RCE를 발견한 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-15-HowIFoundMyFirstRCE_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="첫 번째 RCE를 발견한 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">첫 번째 RCE를 발견한 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 15, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="플러터 프로젝트에 조금의 창조적 예술 추가하기" href="/post/2024-05-15-AddingabitofGenerativeArttoaFlutterproject"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="플러터 프로젝트에 조금의 창조적 예술 추가하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-15-AddingabitofGenerativeArttoaFlutterproject_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="플러터 프로젝트에 조금의 창조적 예술 추가하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">플러터 프로젝트에 조금의 창조적 예술 추가하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 15, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="대용량 언어 모델을 제공하는 도커 이미지 크기를 줄이기 파트 1" href="/post/2024-05-15-ReducingtheSizeofDockerImagesServingLargeLanguageModelspart1"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="대용량 언어 모델을 제공하는 도커 이미지 크기를 줄이기 파트 1" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-15-ReducingtheSizeofDockerImagesServingLargeLanguageModelspart1_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="대용량 언어 모델을 제공하는 도커 이미지 크기를 줄이기 파트 1" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">대용량 언어 모델을 제공하는 도커 이미지 크기를 줄이기 파트 1</strong><div class="PostList_meta__VCFLX"><span class="date">May 15, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Kolmogorov-Arnold Networks KANs를 사용한 시계열 예측" href="/post/2024-05-15-Kolmogorov-ArnoldNetworksKANsforTimeSeriesForecasting"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Kolmogorov-Arnold Networks KANs를 사용한 시계열 예측" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-15-Kolmogorov-ArnoldNetworksKANsforTimeSeriesForecasting_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Kolmogorov-Arnold Networks KANs를 사용한 시계열 예측" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">Kolmogorov-Arnold Networks KANs를 사용한 시계열 예측</strong><div class="PostList_meta__VCFLX"><span class="date">May 15, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="GPT-4 대 GPT-4 대 Gemini 15   성능 분석" href="/post/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="GPT-4 대 GPT-4 대 Gemini 15   성능 분석" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="GPT-4 대 GPT-4 대 Gemini 15   성능 분석" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">GPT-4 대 GPT-4 대 Gemini 15   성능 분석</strong><div class="PostList_meta__VCFLX"><span class="date">May 15, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/81">81</a><a class="link" href="/posts/82">82</a><a class="link" href="/posts/83">83</a><a class="link" href="/posts/84">84</a><a class="link" href="/posts/85">85</a><a class="link" href="/posts/86">86</a><a class="link" href="/posts/87">87</a><a class="link" href="/posts/88">88</a><a class="link posts_-active__YVJEi" href="/posts/89">89</a><a class="link" href="/posts/90">90</a><a class="link" href="/posts/91">91</a><a class="link" href="/posts/92">92</a><a class="link" href="/posts/93">93</a><a class="link" href="/posts/94">94</a><a class="link" href="/posts/95">95</a><a class="link" href="/posts/96">96</a><a class="link" href="/posts/97">97</a><a class="link" href="/posts/98">98</a><a class="link" href="/posts/99">99</a><a class="link" href="/posts/100">100</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"이미지 선명도를 평가하여 OCR 정확도 향상 기술","description":"","date":"2024-05-15 15:24","slug":"2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness","content":"\n\n\n![Image](/assets/img/2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness_0.png)\n\n광학 문자 인식(OCR) 기술은 이미지에서 텍스트를 디지털화하는 방법을 혁신적으로 바꿨습니다. 그러나 OCR 시스템이 직면한 지속적인 어려움 중 하나는 흐린 이미지에서 텍스트를 정확하게 해독하는 것입니다. 흐림은 OCR 정확도를 심각하게 저하시켜 추출된 텍스트에서 해석 오류를 일으킬 수 있습니다. 이 기사에서는 OCR 애플리케이션용 이미지의 흐림 문제를 제시하고 이미지 선명도를 평가하기 위한 세 가지 기술을 탐색하여 OCR 정확도를 향상시키겠습니다.\n\n# 이미지에서의 흐림이란?\n\n이미지에서의 흐림은 모션 블러, 초점이 맞지 않은 블러 또는 낮은 이미지 해상도와 같은 다양한 요인 때문에 발생합니다. 이러한 요인은 텍스트의 세부사항과 가장자리를 왜곡시켜 OCR 시스템이 문자를 정확하게 인식하고 추출하는 것을 어렵게 만듭니다.\n\n\n\n\n# OCR은 기업에 어떤 이점을 줄까요?\n\nOCR은 많은 다른 용도 중에서도 기업에서 널리 사용되는 다음과 같은 응용 프로그램에 사용됩니다:\n\n- 문서 디지털화: 인쇄 또는 손으로 쓴 문서, 양식 및 영수증을 디지털 텍스트로 변환하는 작업입니다.\n- 데이터 추출: 금융, 소매 및 의료 분야와 같은 산업에서, OCR은 양식, 가격표 및 처방전에서 데이터나 중요 정보를 자동으로 추출합니다.\n- 접근성 및 보조 기술: 텍스트 인식 소프트웨어는 인쇄된 텍스트를 청각적 발음이나 점자 출력으로 변환하여 시각 장애가 있는 사용자가 텍스트 콘텐츠에 접근하고 상호 작용할 수 있도록 합니다.\n\n# 왜 OCR 모델의 데이터 정확도가 매우 중요한가요?\n\n\n\n흐려진 이미지에서 모델을 평가하면 모델의 정확도를 잘못 나타낼 수 있습니다. 정확도는 다음과 같은 이유로 매우 중요합니다:\n\n- 데이터 신뢰성: 높은 정확도는 추출된 텍스트가 원본 콘텐츠를 정확하게 반영하여 기업이 데이터 분석, 의사 결정 및 규정 준수에 OCR 출력에 의존할 수 있도록 보장합니다.\n- 오류 최소화: 부정확한 OCR 결과는 데이터 입력, 문서 처리 및 정보 검색에서 오류를 초래할 수 있으며, 이는 재정적 손실, 규정 위반, 명예 훼손 및 법적 책임으로 이어질 수 있습니다.\n- 효율성: OCR 출력의 수동 확인 및 수정 필요성을 제거함으로써 기업에 시간과 자원을 절약시킵니다.\n\nOCR 기술을 도입하면 많은 기업이 추가 수익을 창출할 가능성이 높습니다. 또한 자원 활용의 효율화를 통해 더 나은 비용 절감 효과를 가져오며, 데이터 오류나 준수 위반으로 인한 벌금, 처벌 및 법적 책임 위험을 줄입니다.\n\n# 이미지 선명도 평가 기술\n\n\n\n\n200개의 텍스트를 포함한 잘린 이미지 샘플을 대상으로 이미지의 선명도를 결정하는 최상의 메트릭을 정하는 실험을 진행했습니다. 샘플 이미지에는 일부 흐린 이미지와 카메라 농도가 많이 섞인 이미지도 포함되어 있습니다. 여기서 OpenCV를 사용하여 이미지의 흐림을 식별하는 세 가지 기술을 탐색했습니다: 라플라시안 연산자, 그래디언트 크기법 및 고속 푸리에 변환입니다. 다양한 기술을 비교하기 위해 각 기술에 대한 가장 날카로운 이미지와 가장 흐린 이미지를 참조로 추가했습니다.\n\n이 섹션에서는 다음 기술을 자세히 살펴봅니다.\n\n## 라플라시안 연산자 방법\n\n라플라시안 연산자는 이미지 처리에서 가장자리를 감지하고 이미지의 선명도를 평가하는 데 사용되는 고전적인 기술입니다. 이미지의 두 번째 도함수를 계산하여 가장자리를 감지하고 이미지의 선명도를 평가합니다.\n\n\n\n수학적으로 라플라스 연산자 ∇²은 이미지 함수 f(x, y)의 그래디언트의 발산으로 정의됩니다. 여기서 (x, y)는 이미지의 공간 좌표를 나타냅니다:\n\n![image](/assets/img/2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness_1.png)\n\n라플라스 연산자는 각 픽셀에서 이미지 강도 함수의 지역 곡률을 측정합니다. 높은 양수 값은 빠른 강도 변화(가장자리)를 나타내며, 낮은 값은 부드러운 영역을 나타냅니다.\n\n라플라스 연산자의 분산을 계산함으로써 이미지의 선명도를 측정할 수 있습니다. 더 높은 분산 값은 더 날카로운 가장자리와 뚜렷한 특징을 나타냅니다.\n\n\n\n다음은 라플라시안 연산자를 구현한 Python 코드입니다:\n\n\n![Code](/assets/img/2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness_2.png)\n\n\n이 기술을 샘플 데이터셋에 적용하면 Figure 1의 이미지가 날카로운 점수가 가장 낮지만 더 선명하게 보이고, 실제로 왜곡된 Figure 2의 이미지가 더 높은 날카로운 점수를 가지게 됨을 관찰할 수 있습니다.\n\n\n![Sample Dataset](/assets/img/2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness_3.png)\n\n\n\n\n![이미지](/assets/img/2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness_4.png)\n\n노이즈에 민감한 한계: 노이즈가 많은 이미지에서는 라플라시안 연산자가 노이즈를 가장자리로 감지할 수 있으므로 높은 분산과 오해가능한 선명도 측정을 야기할 수 있습니다. 결과적으로 선명한 이미지와 흐린 이미지는 대부분 잘못 분류됩니다.\n\n# 그래디언트 크기 방법\n\n가장자리 감지는 이미지의 구조 정보를 공개하는 이미지의 가장자리를 찾는 과정입니다. Sobel 필터는 이미지 처리에서 일반적으로 사용되는 가장자리 검출 필터 유형입니다. 그들은 이미지 내에서 그래디언트 크기를 계산하여 이미지의 가장자리를 감지하는 데 자주 사용됩니다.\n\n\n\n그라디언트는 이미지에서 픽셀 강도의 변화율을 나타냅니다. 그라디언트 크기는 이 그라디언트 벡터의 크기로, 이미지에서 한 지점에서 다른 지점으로 픽셀 강도가 얼마나 빨리 변하는지를 나타냅니다.\n\n수학적으로, 이미지 함수 f(x, y)의 그라디언트는 공간 좌표 (x, y)에 대한 픽셀 강도의 변화율을 나타냅니다:\n\n![그래픽](/assets/img/2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness_5.png)\n\n그라디언트의 크기 ∥∇f(x, y)∥는 그라디언트 벡터의 유클리드 노름으로 계산됩니다:\n\n\n\n\n![Sobel Operator](/assets/img/2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness_6.png)\n\n이 값은 각 픽셀에서 모든 방향으로 픽셀 강도의 변화율을 나타냅니다. 높은 값은 가장자리와 질감과 같은 빠른 강도 변화 영역을 나타내고, 낮은 값은 부드러운 영역을 나타냅니다.\n\n그런 다음 전체 이미지에서 이러한 그래디언트 크기의 평균(평균) 값을 계산합니다. 이 평균 그래디언트 크기는 이미지의 선명도나 가장자리의 존재를 전반적으로 측정하는 지표를 제공합니다. 높은 평균 또는 합계 값은 더 날카로운 가장자리와 뚜렷한 특징을 나타냅니다.\n\n다음은 Sobel 연산자를 구현하는 Python 코드입니다:\n\n\n\n\n![image1](/assets/img/2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness_7.png)\n\n본 기술을 샘플 데이터셋에 적용하면, 아래 그림 3에 있는 이미지가 실제로 왜곡되었을 때 더 높은 선명도 점수를 갖는 반면, 선명도 점수가 가장 낮은 이미지들은 정확하게 식별됨을 관찰할 수 있습니다.\n\n![image2](/assets/img/2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness_8.png)\n\n![image3](/assets/img/2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness_9.png)\n\n\n\n제한 사항: 균일한 영역이나 낮은 대비 특징을 가진 이미지의 경우, 그레디언트 크기는 낮은 크기의 값으로 나타날 수 있어 날카로움을 과소평가할 수 있습니다. 반면 복잡한 질감이나 높은 대비 가장자리를 가진 이미지의 경우, 그레디언트 크기는 더 높은 크기의 값을 생성할 수 있습니다. 따라서 전체적으로 이미지가 깨끗하다고 해도 높은 크기의 값이 나타날 수 있습니다.\n\n# Fast Fourier Transformation 방법\n\n푸리에 변환은 이미지의 주파수 성분을 분석하기 위해 사용되는 수학적 기술입니다.\n\n이미지 함수 f(x, y)의 푸리에 변환 F(u, v)는 다음과 같이 정의됩니다:\n\n\n\n\n![image](/assets/img/2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness_10.png)\n\n(u, v)은 주파수 도메인의 공간 주파수 좌표를 나타냅니다.\n\nFourier 변환의 크기 스펙트럼 |F(u, v)|은 이미지에 존재하는 공간 주파수의 분포를 나타냅니다. 높은 크기 값은 가장자리 및 질감과 같은 고주파 구성 요소에 해당하고, 낮은 값은 부드러운 영역과 같은 저주파 구성 요소에 해당합니다.\n\n고속 푸리에 변환(FFT) 방법을 사용하여 이미지 선명도를 평가할 때, 일반적으로 크기 스펙트럼을 분석하고 관련 통계량(평균과 같은)을 계산하여 이미지 전체에서 고주파 콘텐츠의 분포를 양적으로 측정합니다. 높은 통계량 값은 더 날카로운 가장자리와 뚜렷한 특징을 나타냅니다.\n\n\n\n\n여기에 Fourier 변환을 구현하는 Python 코드가 있습니다:\n\n\n![Python code](/assets/img/2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness_11.png)\n\n\n이 기술을 샘플 데이터 집합에 적용한 결과, Figure 5의 이미지는 낮은 선명도 점수로 흐린 것으로 올바르게 식별되었으며 Figure 6의 이미지는 높은 선명도 점수로 날카로운 것으로 올바르게 식별되었습니다.\n\n\n![Sample dataset application](/assets/img/2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness_12.png)\n\n\n\n\n![이미지](/assets/img/2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness_13.png)\n\n# 우리의 비즈니스 문제에서 가장 잘 작동한 방법은 무엇인가요?\n\n사용된 이미지 샘플에서 Fast Fourier 변환은 다음과 같은 이유로 가장 잘 작동했습니다:\n\n- 고주파 요소에 대한 민감도: Fast Fourier Transform은 고주파 요소에 매우 민감하여 날카로운 이미지 특징을 탐지하는 데 특히 효과적입니다. 고주파 요소는 푸리에 변환의 크기 스펙트럼에 상당한 기여를 하기 때문에 이미지의 날카로움을 정확하게 식별하고 측정할 수 있습니다.\n- 이동 불변성 특성: 이미지의 위치나 방향에 상관없이 푸리에 변환은 일관되게 주파수 내용을 캡처하므로 이미지의 날카로움을 평가하는 강력하고 안정적인 방법입니다.\n\n\n\n# 임계값을 결정하는 방법\n\n임계값은 이미지의 선명도 점수를 기반으로 선명하고 흐린 이미지를 구별하는 기준점 역할을 합니다. 이미지의 품질, 텍스트의 특성(글꼴 크기, 스타일, 배경과의 대비) 및 애플리케이션의 특정 요구 사항 등 여러 요소에 따라 이미지 내 텍스트가 선명한지 흐린지를 결정하기 위한 이상적인 임계값이 달라집니다. 임계값을 초과하는 선명도 점수를 가진 이미지는 선명하다고 간주되며, 임계값 이하의 이미지는 흐린 것으로 간주됩니다. 임계값을 조정하면 OCR 처리에 적합한 선명도 수준을 유연하게 결정할 수 있습니다.\n\n임계값을 결정하는 몇 가지 방법은 다음과 같습니다:\n\n- 시각적 검사: 선명한 이미지와 흐린 이미지를 분리하는 방법으로 이미지를 검사하여 임계값을 찾아보는 것.\n- 경험적 테스트: 선명한지 흐린지를 나타내는 진실 레이블이 있는 이미지 세트로 테스트 하는 것.\n- 반복적 개선: 보수적 임계값부터 시작하여 성능에 따라 임계값을 조정하는 것을 통해 개선하는 것이 있습니다.\n\n\n\n# 결론\n\n결론적으로, 이미지에서의 흐림은 OCR 시스템에 중요한 도전 과제를 제공합니다. 이미지 처리의 기본 원리를 활용하고 임계값 기술을 통합함으로써, 푸리에 변환 방법은 이미지 선명도를 평가하는 믿을 수 있는 방법을 제공하여 OCR 정확성과 성능을 향상시킬 수 있습니다.\n\nMonica Kadlay는 LinkedIn에서 활동 중입니다.","ogImage":{"url":"/assets/img/2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness_0.png"},"coverImage":"/assets/img/2024-05-15-TechniquesforenhancingOCRaccuracybyassessingimagesharpness_0.png","tag":["Tech"],"readingTime":7},{"title":"Nodejs 20 버전으로 업그레이드하기 - 성능과 효율성을 끌어올리는 다음 단계를 열다","description":"","date":"2024-05-15 15:22","slug":"2024-05-15-UpgradingtoNodejsv20UnlockingtheNextLevelofPerformanceandEfficiency","content":"\n\n\u003cimg src=\"/assets/img/2024-05-15-UpgradingtoNodejsv20UnlockingtheNextLevelofPerformanceandEfficiency_0.png\" /\u003e\n\n웹 개발 분야는 끊임없이 진화하고 있는데, 최신 기술에 대한 업데이트는 경쟁력을 유지하고 응용 프로그램의 최적 성능을 보장하는 데 중요합니다. Node.js라는 중추적인 기술이 바로 그것인데요. Node.js는 확장성, 효율성 및 다양성으로 유명한 런타임 환경으로, 응용 프로그램을 구축하는 데 필수적입니다.\n\n금일은 노드 버전을 업그레이드하는 방법과 직면한 도전을 살펴보겠습니다.\n\n# 노드 버전 업그레이드가 중요한 이유 🤔\n\n\n\n보안 취약점: Node.js의 오래된 버전은 알려진 보안 취약점을 가지고 있을 수 있습니다. 더 최신 릴리스에서 수정된 새로운 버전은 이러한 취약점을 해결했습니다. 오래된 버전을 사용하면 응용 프로그램이 잠재적인 악용에 노출될 수 있습니다.\n\n지원 부족: Node.js가 진화함에 따라 오래된 버전은 점차적으로 지원이 줄어들어 응용 프로그램이 업데이트나 커뮤니티 지원 없이 버그에 노출됩니다.\n\n장기적인 유지 관리 과제: 오래된 Node.js 버전에서 응용 프로그램을 관리하는 것은 시간이 지날수록 점점 복잡하고 비용이 많이 소요됩니다. 이는 중요한 조정을 요구하며 기능적인 간격을 가져다 줄 수 있습니다.\n\n의존성 관리: Node.js 응용 프로그램의 의존성은 Node.js 버전과의 호환성에 의존합니다. 오래된 버전을 사용하면 최소 지원 버전이 필요한 의존성의 설치 또는 업데이트에 제한을 받을 수 있습니다.\n\n\n\n# 업그레이드 전략📈\n\n- 시스템에 Node.js v20을 다운로드하여 Node.js 버전을 v20으로 전환하세요\n   i. node_modules 및 package-lock.json을 삭제합니다\n   ii. 애플리케이션에서 npm install 명령을 실행하세요.\n- 아래 다이어그램처럼 의존성이 중첩되어 있어서 개인 의존성의 종속성 트리를 루트부터 리프까지 해결하세요.\n\n![다이어그램](/assets/img/2024-05-15-UpgradingtoNodejsv20UnlockingtheNextLevelofPerformanceandEfficiency_1.png)\n\n3. 호환되지 않는 의존성은 설치 중에 오류를 발생시키며, 해당 의존성을 지원되는 버전으로 대체하세요.\n\n\n\n\n![이미지](/assets/img/2024-05-15-UpgradingtoNodejsv20UnlockingtheNextLevelofPerformanceandEfficiency_2.png)\n\n예: 위 스크린샷에서 node-sass가 지원되지 않아 sass로 업그레이드했습니다.\n\n4. 모든 비공개 종속성이 Node.js v20과 호환되고 빌드할 수 있는지 확인합니다.\n\n5. Node.js v20에서 실행되도록 비공개 종속성을 업데이트합니다.\n\n\n\n\n6. 소비자 애플리케이션의 개인 종속성 버전을 업데이트하세요.\n\n7. npm install 명령어를 실행하세요.\n\n쉽죠!!! 그래도 우리에겐 쉽지 않았어요. 왜일까요??? ⤵️\n\n# 업그레이드 중에 마주한 도전들 🤯\n\n\n\n문제 1:\nNode.js v20으로 전환할 때 Babel, Jest와 같은 호환되지 않는 종속성을 해결하는 문제가 있습니다.\n\n문제 2:\nnpm install 프로세스 실행 중에 개인 종속성을 Git URL을 통해 소비할 때 여러 스레드의 npm install 명령이 자동으로 생성되어 문제가 발생했습니다. 따라서 개인 종속성을 아트펙토리를 통해 관리하도록 전환했고, 이를 통해 문제가 해결되었습니다.\n\n![이미지](/assets/img/2024-05-15-UpgradingtoNodejsv20UnlockingtheNextLevelofPerformanceandEfficiency_3.png)\n\n관련 문제가 참조 섹션에 링크되어 있습니다.\n\n\n\n문제 3:\nCI/CD 파이프라인에서 Node.js v16 이상과의 호환성 문제를 관리하면서 운영 체제를 업그레이드했습니다(예: CentOS 7).\n\n# 위의 도전 과제에 대한 구현된 솔루션🛠️\n\n솔루션 1:\n소비자 응용 프로그램의 모든 패키지를 Node.js v20과 호환되는 버전으로 업데이트하였습니다.\n\n솔루션 2:\ni. 소비자 응용 프로그램에서 .npmrc 파일에 artifactory URL을 구성하여 모든 비공개 종속성을 artifactory를 통해 제공하고, 비공개 종속성의 package.json에 \"publishConfig\"를 추가하여 artifactory로 게시하였습니다.\n\n\n\n\n![image 1](/assets/img/2024-05-15-UpgradingtoNodejsv20UnlockingtheNextLevelofPerformanceandEfficiency_4.png)\n\n![image 2](/assets/img/2024-05-15-UpgradingtoNodejsv20UnlockingtheNextLevelofPerformanceandEfficiency_5.png)\n\nii. 올바른 Node.js 버전을 사용하도록 개발자들이 패키지를 게시할 때 .npmrc 파일 맨 위에 \"engine-strict=true\"를 설정하고 package.json에 필요한 Node.js 버전을 명시하세요.\n\n```js\nengine-strict=true\nmy-packages:registry=\"http://localhost:8081\" \n```\n  ‍‍\n\n\n\n이미지 태그를 마크다운 형식으로 변경해주세요.\n\n![이미지](/assets/img/2024-05-15-UpgradingtoNodejsv20UnlockingtheNextLevelofPerformanceandEfficiency_6.png)\n\n해결책 3:\nCI/CD 파이프라인을 위해 운영 체제를 업그레이드하세요. 우리는 Rocky 8을 사용했습니다.\n\n# 아티펙터리에서 의존성을 사용하기 위한 애플리케이션 구성 변경 사항:\n\n- 개인 의존성에서 코드가 아티펙터리에 발행될 수 있도록 보장하려면 다음을 추가해야 합니다:\n\n\n\n```js\n// 샘플 package.json\n{ \n\"version\":\"1.0.0\",\n\"name\" : \"my-packages/package1\",  // scope/packageName\n \"publishConfig\":{ \n \"registry\": \"http://localhost:8081\"\n } \n}\n```\n\n패키지 이름은 scope와 함께 입력되어야 합니다.\n\n2. npm publish 명령어를 실행하면, package.json의 version 키에 지정된 버전이 artifactory에 발행됩니다.\n\n참고: 발행하기 전에 package.json의 버전을 업데이트하거나 자체 스크립트를 작성하여 이 작업을 자동화하는 것을 잊지 마세요.\n\n\n\n3. 소비자 애플리케이션에서 개인 종속성을 위한 아티팩토리(호스트)의 URL은 .npmrc 파일에 정의할 수 있습니다(가능하다면 프로젝트 수준에서 생성하는 것이 좋습니다).\n예: .npmrc 파일 예시:\n\n```js\nmy-packages:registry = \"http://localhost:8081\" //(패키지 이름을 위한 정규식): registry = 아티팩토리 URL \n```\n\n모든 개인 종속성이 아티팩토리의 my-packages 스코프 아래로 푸시되었다고 가정합니다.\n만약 공통 스코프가 없다면, 하나를 생성하거나 각 패키지를 URL과 매핑해야 합니다.\n\n4. npm install 명령을 실행할 때마다, namespace 및 아티팩토리 URL을 정의한 .npmrc 파일을 확인합니다. .npmrc 파일에서 namespace가 일치하면 해당 종속성은 .npmrc에 언급된 URL에서 다운로드되고, 그렇지 않으면 기본 URL인 npm 레지스트리에서 제공됩니다.\n\n\n\n5. 소비자 애플리케이션에서 Artifactory에 발행된 버전을 사용하여 개인 패키지를 소비하세요.\n\n다음 예시를 통해 이해해 봅시다:\n\n- `예를 들어, package.json에 다음과 같이 개인 종속성이 정의되어 있다고 가정해 봅시다:\n\n```js\nmy-internal-dependencies/some-dependency: \"git+//git RepositoryUrl#v1.0.0\n```\n\n\n\n- 먼저 ‘some-dependency' 코드 베이스로 이동하여 package.json에 위와 같이 publishConfig를 정의하고 이 패키지의 모든 버전을 Node.js v20과 호환되게 만들기 위해 업그레이드하세요; 또한 package.json의 버전도 업그레이드한 다음 npm publish 명령을 실행하세요.\n\n- 소비자 애플리케이션에서 .npmrc 파일을 다음과 같이 생성하세요.\n\n```js\nmy-internal-dependencies:registry = \"http://localhost:8081\" //(package name을 위한 정규식): registry = 아티팩토리의 URL\n```\n\n- 그런 다음, 소비자 애플리케이션에서 새 버전으로 개인 의존성 항목을 업데이트하세요.\n\n\n\n```js\nmy-internal-dependencies/some-dependency: 1.0.0\n```\n\n- npm install 명령어를 사용하여 소비자 응용 프로그램에서 실행하세요.\n\n만세 🎉, 모든 비공개 종속성이 npm 레지스트리에서 다른 종속성과 함께 아티펙토리에서 다운로드됩니다.\n\n# 추가 팁 💡\n\n\n\n\n- 버전 관리를 자동화할 수 있습니다. 사용자 정의 스크립트를 작성하고 package.json에 다음 내용을 추가하여 애플리케이션에 추가할 수 있습니다.\n\n```js\n{ \n \"scripts\":{ \n \"customCommandForPublish\":\"./bin/myScripts/publishScript.js\" \n } \n}\n```\n\n2. 아티팩토리에서 태그를 생성할 때는 세맨틱 버전팅을 따르는지 확인하십시오. 그렇지 않으면 npm 버전 관리 표준이 깨질 수 있고 ~/^으로 시작하는 태그가 깨질 수 있습니다.\n\n참고: 📝\n\n\n\n만약 npm을 배포하기 위해 자체 스크립트를 사용 중이라면, 스크립트 키에서 명령어 이름을 \"publish\"로 정의하지 않도록 주의하세요. 왜냐하면 npm의 기본 명령어가 \"publish\"이기 때문에, 이렇게 하면 기본적인 배포 명령어와 스크립트에서 정의한 사용자 지정 명령어 두 번 실행됩니다.\n\n# 결론\n\n요약하자면, Node.js 버전을 업그레이드하는 것은 애플리케이션의 보안, 호환성, 그리고 장기적인 지속 가능성을 유지하는 데 중요합니다. 도전에 대처하고 효과적인 해결책을 구현함으로써, 새로운 Node.js 버전으로의 전환을 효과적으로 관리할 수 있어, 애플리케이션의 지속적인 안정성과 지원을 보장할 수 있습니다.\n\n# 참고 자료:\n\n\n\n- [https://github.com/npm/cli/issues/4895](https://github.com/npm/cli/issues/4895)\n- [https://github.com/npm/cli/issues/4028](https://github.com/npm/cli/issues/4028)\n- [https://github.com/npm/cli/issues/4896](https://github.com/npm/cli/issues/4896)","ogImage":{"url":"/assets/img/2024-05-15-UpgradingtoNodejsv20UnlockingtheNextLevelofPerformanceandEfficiency_0.png"},"coverImage":"/assets/img/2024-05-15-UpgradingtoNodejsv20UnlockingtheNextLevelofPerformanceandEfficiency_0.png","tag":["Tech"],"readingTime":6},{"title":"Astro와 Storyblok을 활용해 나만의 블로그 사이트를 만들어 본 경험 공유","description":"","date":"2024-05-15 15:19","slug":"2024-05-15-HowIsetupmyBlogSitewithAstroandStoryblok","content":"\n\n\u003cimg src=\"/assets/img/2024-05-15-HowIsetupmyBlogSitewithAstroandStoryblok_0.png\" /\u003e\n\n이제부터 블로그를 쓴 지 꽤 시간이 지났죠. 대부분의 시간은 다음에 무엇에 집중해야 할지 고민하면서 게을리했습니다. 마침내 나만의 포트폴리오 웹사이트를 만들기로 결정했습니다. 단 하나의 문제는... 지금이 2024년이고 이를 달성할 수 있는 다양한 기술 스택이 있다는 것입니다. 처음에는 새로운 스위스 아미 나이프인 Next JS를 사용하여 빠르게 템플릿을 활용해 포트폴리오를 구축할 생각이었습니다. 그러나 Astro JS에 대해 읽게 되었고 완전히 사로잡혔습니다.\n\n하지만 Next JS도 여전히 정말 대단한 프레임워크라고 생각합니다. 때로는 스위스 나이프를 사용하는 대신 빛을 내는 레이저 칼 (Astro JS)을 사용하는 것이 낫다고 생각합니다. 이 경우에는 Astro를 사용하는 것이 더 나은 이유는 Astro가 정적 사이트를 빠르게 프로토타이핑하는 데 특히 적합하기 때문입니다.\n\n\u003cimg src=\"/assets/img/2024-05-15-HowIsetupmyBlogSitewithAstroandStoryblok_1.png\" /\u003e\n\n\n\n# Astro JS를 사용해야 하는 이유\n\n개발에 들어가기 전에 Astro가 무엇이고, 언제 Astro를 선택해야 하는지를 이해해 보겠습니다.\n\n공식 문서에서:\n\n# 성능과 복잡성 사이의 교환\n\n\n\n일반적으로 대부분의 현대 웹 프레임워크는 관리자 대시보드, 역할 관리, 인사 포탈 등과 같이 복잡한 기능을 갖춘 애플리케이션을 구축하는 데 우수합니다. 그러나 이러한 복잡성은 성능에 큰 비용이 들며 콘텐츠를 제공하기 위해 많은 최적화가 필요합니다.\n\n그러나 모든 사이트가 요구 사항을 충족하기 위해 복잡할 필요는 없습니다. 블로그, 포트폴리오, 매력적인 랜딩 페이지와 같이 정적 콘텐츠를 제공하는 사이트는 사용자와 상호 작용할 필요 없이 콘텐츠를 쇼케이스하는데 이상적입니다. 여기서 Astro가 빛을 발합니다.\n\nAstro는 기본적으로 빠른 웹사이트를 제공합니다. Astro 문서에 언급된대로:\n\n이것은 Astro가 기본적으로 브라우저로 아무런 JavaScript 없이 웹사이트를 제공하기 때문에 순전히 서버 측에서 사전 렌더링되어 성능을 향상시키기 위해 순수한 HTML을 제공하려고 한다는 의미입니다. 문서에 명시된대로:\n\n\n\n## 그러나 만약 모든 것이 HTML이라면 JavaScript에 의존하는 대화형 구성 요소는 어떨까요?\n\n여기에서 Astro의 마법이 진정으로 발휘됩니다. Astro 컴포넌트는 기본적으로 서버에서 렌더링되지만, 클라이언트 측에서 렌더링할 컴포넌트를 선택하여 활성화할 수 있습니다. 이를 통해 웹 사이트에서 성능과 상호 작용을 유지하면서 최소한의 JavaScript를 브라우저로 전송할 수 있습니다. 정적 및 동적 렌더링을 필요에 따라 활성화하는 능력은 Astro의 가장 큰 장점이며, 이 아키텍처는 Islands로 알려져 있습니다.\n\n# Astro Islands\n\n![Astro Islands](/assets/img/2024-05-15-HowIsetupmyBlogSitewithAstroandStoryblok_2.png)\n\n\n\n간단히 말해서, 웹 사이트를 여러분의 상호 작용하는 다양한 구성 요소가 가벼운, 미리 렌더링된 정적 HTML의 바다 속을 떠다니는 여러 섬으로 구성된 군도인 '아키텍처라 생각해 보세요. 이 디자인 패턴을 통해 개발자는 Astro와 함께 다양한 UI 프레임워크를 사용할 수 있습니다. 이것이 다음으로 이어지는 내 포인트인데...\n\n# Astro는 다른 프론트엔드 프레임워크와 경쟁하지 않고 함께 작동합니다\n\n섬 아키텍처를 통해 Astro는 React, Preact, Svelte, Vue 및 SolidJS와 같은 다양한 UI 프레임워크를 지원할 수 있습니다. 개발자들은 주로 특정 프레임워크에 충실하지만 이 유연성은 프로젝트 내에서 동시에 모든 이들을 사용할 수 있도록 허용합니다!\n\n![이미지](/assets/img/2024-05-15-HowIsetupmyBlogSitewithAstroandStoryblok_3.png)\n\n\n\n```js\n---\n// 예시: 동일한 페이지에서 여러 프레임워크 구성 요소 혼합.\nimport MyReactComponent from '../components/MyReactComponent.jsx';\nimport MySvelteComponent from '../components/MySvelteComponent.svelte';\nimport MyVueComponent from '../components/MyVueComponent.vue';\n---\n\u003cdiv\u003e\n  \u003cMySvelteComponent /\u003e\n  \u003cMyReactComponent /\u003e\n  \u003cMyVueComponent /\u003e\n\u003c/div\u003e\n```\n\n# 웹사이트 설정하기\n\n## 포트폴리오/랜딩 페이지\n\n이제 우리가 Astro가 무엇인지 알았으니:\n\n\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:900/1*qtLLXKOJJjKKNbLcTEzWpg.gif\" /\u003e\n\n일단 Astro Themes로 이동하여 프로젝트를 시작할 템플릿을 선택해보세요. 처음부터 만들 필요 없이 프로젝트용 새로운 레포지토리를 만들고 로컬 머신에 클론한 다음 npm install을 실행하여 package.json에서 필요한 모든 종속성을 설치합니다. npm run dev를 실행하여 시작하면 됩니다!\n\n포트폴리오/랜딩 페이지의 콘텐츠를 간단히 수정하여 개인 정보를 빠르게 표시하거나 모든 구성 요소 중 일부 또는 모두를 버리고 나만의 사용자 정의 구성 요소를 추가하여 웹 사이트를 스타일링할 수도 있습니다.\n\n# 블로그 페이지 설정\n\n\n\n이제 이게 좀 더 흥미로운 부분이고 조금 까다로울 수도 있어요, 거짓말 안 할게요, 그래서 제가 이 과정을 가장 간단하게 설명하려고 노력할게요. 하지만 블로그 페이지를 디자인하기 전에 CMS를 선택하고 설정해야 합니다. CMS가 뭔지 궁금하다고요? 걱정하지 마세요. 제가 설명해줄게요 🙃\n\n# CMS (콘텐츠 관리 시스템)\n\n첫 번째로 CMS가 왜 필요한지를 간단한 예시로 설명해보죠. 일단 당신이 근무하는 회사를 상상해보세요 (지속적인 불황으로 인해 상상만 할 수 있는 상황이지만 😅). 회사가 블로그 페이지를 시작하려고 하는데, 여러분의 상사가 여러분을 포함한 3~4명의 팀을 구성했습니다. 아쉽게도 나머지 팀원들은 코딩을 몰라 웹사이트를 위한 HTML과 함께 블로그를 작성하는 방법에 대해 전혀 모릅니다. 하지만 그들은 창의적인 작가들과 UI 디자이너로 있습니다. 그런데 여기서 문제가 발생합니다. 작가들은 코딩을 하지 몰라 웹페이지에 콘텐츠를 작성할 수 없고, 심지어 알고 있더라도 순수한 HTML로 콘텐츠를 작성하는 것은 어려운 일이죠.\n\n\u003cimg src=\"/assets/img/2024-05-15-HowIsetupmyBlogSitewithAstroandStoryblok_4.png\" /\u003e\n\n\n\nCMS로 만들어진 웹사이트에서는 여러 관리자가 콘텐츠를 생성, 편집 및 발행하는 데 사용되는 응용 프로그램인 콘텐츠 관리 시스템(CMS)이 필요해요. 이는 주로 두 가지 주요 구성 요소로 나뉩니다:\n\n- CMA(콘텐츠 관리 응용 프로그램): 이는 저자가 사용자 친화적 인 인터페이스에서 콘텐츠를 작성할 수 있는 미디어 저장 및 편집기로 설명됩니다. 이를 마이크로소프트 워드의 확장판으로 생각해보세요.\n- CDA(콘텐츠 전달 응용 프로그램): 이는 정적 콘텐츠를 처리하고 웹페이지로 표시하는 모든 백그라운드 처리 작업을 다룹니다.\n\n![이미지](/assets/img/2024-05-15-HowIsetupmyBlogSitewithAstroandStoryblok_5.png)\n\n# 적절한 CMS 선택하기\n\n\n\nCMS를 선택하려면 시장에서 선택할 수있는 다양한 옵션이 있지만이 블로그를 위해 나는 내 웹 사이트에 사용한 훌륭한 Headless CMS 옵션 인 Storyblok에 대해 이야기하겠습니다. Storyblok은 재사용 가능한 구성 요소인 Bloks를 사용하여 콘텐츠를 관리하도록 허용하는 구성 요소 기반 Headless CMS입니다. Astro는 다양한 CMS 옵션에 대한 안내를 제공하지만 공식 CMS 통합으로 Storyblok을 발표했으며 이것이 정말 그 가치가 있다고 말할 때 믿어 주십시오.\n\n# Storyblok과 Astro 통합\n\n- 먼저, Storyblok 계정을 등록하고 자체 공간을 설정해야합니다. 저는 무료 플랜을 선택했는데 아주 잘 작동합니다. 설정에서 미리보기 토큰을 복사하여 .env 파일에 붙여 넣어 나중에 사용할 수 있도록합니다.\n- 이제 공식 Storyblok 통합 패키지를 설치해야합니다.\n\n```js\nnpm install @storyblok/astro vite\n```  \n\n\n\n# Storyblok Space에 Astro를 연결하기\n\n우리의 Astro 프로젝트를 Storyblok 공간에 연결하기 위해서는 astro.config.mjs 파일을 아래와 같이 수정하고 .env 파일에서 미리 보기 토큰을 추가하기만 하면 됩니다.\n\n```js\nimport { defineConfig } from 'astro/config';\nimport storyblok from '@storyblok/astro';\nimport { loadEnv } from 'vite';\n\nconst env = loadEnv(\"\", process.cwd(), 'STORYBLOK');\n\nexport default defineConfig({\n  integrations: [\n    storyblok({\n      accessToken: env.STORYBLOK_TOKEN,\n      components: {\n        // 여기에 컴포넌트를 추가하세요\n      },\n      apiOptions: {\n        // Storyblok 공간 지역을 선택하세요\n        region: 'us', // 옵션, 'eu' (기본값)으로 설정할 수 있습니다\n      },\n    })\n  ],\n});\n```\n\n# Storyblok에서 블록 만들기\n\n\n\n블록은 실제로 Storyblok을 통합할 때 웹 페이지의 \"구성 요소\"이며, 여러분의 공간에 있는 블록 라이브러리에 저장됩니다. 웹 페이지의 콘텐츠를 서로 다른 청크(블록)으로 분할하여 생각해 보세요. 이 블록들은 이동하거나 변경하거나 필요에 따라 다른 블록에 삽입할 수 있습니다.\n\n지금은 콘텐츠를 작성하기 위해 세 개의 블록이 필요합니다. 즉, 블로그 게시물, 블로그 게시물 목록, 그리고 다른 하나인 페이지입니다. 우리가 생성하는 각 블록에 대해 해당하는 Astro 컴포넌트를 생성해야 합니다. 따라서 storyblok이라는 디렉터리를 만들어 그 안에 이러한 컴포넌트들을 저장합니다.\n\n- BlogPost: 이는 콘텐츠 유형 블록으로, 블로그의 레이아웃 역할을 하는 곳으로 생각할 수 있습니다. 여기에서는 타이틀, 설명, 이미지, 콘텐츠와 같이 몇 가지 고정 필드를 정의하거나 배너 이미지, 테이블 등과 같은 다른 중첩 가능한 블록을 추가할 수 있습니다.\n\n```js\nsrc/pages/storyblok/BlogPost.astro\n\n---\nimport { storyblokEditable, renderRichText } from '@storyblok/astro'\nconst { blok } = Astro.props\nconst content = renderRichText(blok.content)\n---\n\n\u003carticle {...storyblokEditable(blok)}\u003e\n  \u003ch1\u003e{blok.title}\u003c/h1\u003e\n  \u003cp\u003e{blok.description}\u003c/p\u003e\n  \u003cimg\n      class=\"w-full h-[360px] lg:h- [450px] object-cover\"\n      src={`${blok.image.filename}/m/1600x0`}\n   /\u003e\n  \u003cFragment set:html={content} /\u003e \n\u003c/article\u003e\n```\n\n\n\n위 코드는 BlogPost.astro 컴포넌트를 위한 것입니다. 이 컴포넌트는 모든 필드에서 내용을 렌더링하며, 우리의 content 필드는 Richtext 유형이므로 먼저 HTML로 변환한 다음 `Fragment set:html='content' /`로 전달하여 HTML로 렌더링합니다.\n\n- BlogPostList: 이는 BlogPost 유형의 모든 블록을 포함하고 카드로 표시할 수 있는 중첩 가능한 블록입니다. useStoryblokApi 훅을 사용하여 blogPost 콘텐츠 유형을 가진 모든 스토리를 가져와서 필요에 따라 draft/published로 필터링합니다.\n\n```js\nsrc/pages/storyblok/BlogPostList.astro\n\n---\nimport { storyblokEditable } from '@storyblok/astro'\nimport { useStoryblokApi } from '@storyblok/astro'\n\nconst storyblokApi = useStoryblokApi();\n\nconst { data } = await storyblokApi.get('cdn/stories', {\n  version: import.meta.env.DEV ? \"draft\" : \"published\",\n  content_type: 'blogPost',\n})\n\nconst posts = data.stories.map(story =\u003e {\n  return {\n    title: story.content.title,\n    date: new Date(story.published_at).toLocaleDateString(\"en-US\", {dateStyle: \"full\"}),\n    description: story.content.description,\n    slug: story.full_slug,\n  }\n})\n\nconst { blok } = Astro.props\n---\n\n- Blog 포스트 목록\n\n\u003cul {...storyblokEditable(blok)}\u003e\n  {posts.map(post =\u003e (\n    \u003cli\u003e\n      \u003ctime\u003e{post.date}\u003c/time\u003e\n      \u003ca href={post.slug}\u003e{post.title}\u003c/a\u003e\n      \u003cp\u003e{post.description}\u003c/p\u003e\n    \u003c/li\u003e\n  ))}\n\u003c/ul\u003e\n```\n\n- Page: 이 또한 본문 필드 내의 모든 컴포넌트/블록을 렌더링하는 중첩 가능한 유형 블록입니다. 또한 부모 요소에 storyblokEditable 속성을 추가하여 Storyblok에서 페이지를 편집할 수 있습니다.\n\n\n\n\nsrc/pages/storyblok/Page.astro\n\n---\nimport { storyblokEditable } from '@storyblok/astro'\nimport StoryblokComponent from \"@storyblok/astro/StoryblokComponent.astro\";\nconst { blok } = Astro.props\n---\n\n\u003cmain {...storyblokEditable(blok)}\u003e\n  {\n    blok.body?.map((blok) =\u003e {\n      return \u003cStoryblokComponent blok={blok} /\u003e\n    })\n  }\n\u003c/main\u003e\n\n\n이제, 우리가 블록을 만들었으니, 블로그용 각 웹페이지에 대한 동적 경로를 처리해야 합니다. Astro를 사용하여 동적 경로를 구성하는 것은 매우 간단합니다. 페이지 디렉토리 안에 blog라는 새 디렉토리를 만들고 그 안에 아래 코드가 있는 [...slug].astro라는 새 파일을 만들어주기만 하면 됩니다:\n\n```js\nsrc/pages/blog/[...slug].astro\n\n---\nimport { useStoryblokApi } from '@storyblok/astro'\nimport StoryblokComponent from '@storyblok/astro/StoryblokComponent.astro'\n\nexport async function getStaticPaths() {\n  const sbApi = useStoryblokApi();\n\n  const { data } = await sbApi.get(\"cdn/stories\", {\n    content_type: \"blogPost\",\n    version: import.meta.env.DEV ? \"draft\" : \"published\",\n  });\n\n  const stories = Object.values(data.stories);\n\n  return stories.map((story) =\u003e {\n    return {\n      params: { slug: story.slug },\n    };\n  });\n}\n\nconst sbApi = useStoryblokApi();\nconst { slug } = Astro.params;\nconst { data } = await sbApi.get(`cdn/stories/blog/${slug}`, {\n  version: import.meta.env.DEV ? \"draft\" : \"published\",\n});\n\nconst story = data.story;\n\n---\n\n\u003chtml lang=\"en\"\u003e\n  \u003chead\u003e\n    \u003cmeta charset=\"UTF-8\" /\u003e\n    \u003ctitle\u003eStoryblok \u0026 Astro\u003c/title\u003e\n  \u003c/head\u003e\n  \u003cbody\u003e\n    \u003cStoryblokComponent blok={story.content} tags={story.tag_list}/\u003e    {/* 각 Story에 대한 콘텐츠와 함께 Story 태그목록을 전달합니다. */}\n  \u003c/body\u003e\n\u003c/html\u003e\n```\n\n이렇게 하면 blog/로 시작하는 모든 요청은 이 파일에서 처리됩니다. 왜냐하면 이 파일이 요청 URL을 라이브러리에 있는 각 Story에서 생성된 슬러그로 매핑하기 때문입니다. Storyblok 콘텐츠 탭에서 Test Blog를 만들어 테스트해볼 수 있습니다. \"New Story\"로 이동하고 \"Content type\"을 \"BlogPost\"로 선택하면 됩니다. 왼쪽에는 Visual Editor라 불리는 화면이 나타나고 오른쪽에는 콘텐츠/미디어를 작성 및 관리하는 일반 편집기가 표시됩니다.\n\n\n\n\n## Storyblok의 시각 에디터에 대해 알아보기\n\nStoryblok의 시각 에디터는 작가/개발자에게 즐거운 경험을 제공해주는 게임을 바꿔놓는 기능이라고 생각해요.\n\n하지만 이를 설정하려면 데브 서버가 실행 중인 로컬호스트 및 포트 번호로 미리보기 URL을 기본값에서 변경해야 해요. 제 경우에는 https://localhost:4321/입니다.\n\n참고: 데브 서버는 기본적으로 HTTP에서 실행되지만, Storyblok은 앱을 HTTPS를 통해 제공해야 하므로 이를 우회하기 위해 basicSsl을 설치하고 앱을 HTTPS로 실행하세요. 자세한 내용은 다음 링크를 참조하세요: [링크](https://www.storyblok.com/faq/setting-up-https-on-localhost-in-astro)\n\n\n\n\n![image](/assets/img/2024-05-15-HowIsetupmyBlogSitewithAstroandStoryblok_6.png)\n\n작업이 완료되었습니다. 이제 우리는 콘텐츠 편집기 플랫폼을 갖추었고, 실시간으로 변경 사항을 시각화하고 Storyblok의 에셋 라이브러리를 사용하여 미디어를 관리하며 사용자 정의 블록을 사용하여 모든 구성 요소를 사용자 정의할 수 있습니다.\n\n## 소스 코드:\n\n## 참고 자료:\n\n\n\n\n- Astro Docs: [https://docs.astro.build/en/getting-started/](https://docs.astro.build/en/getting-started/)\n- Storyblok Integration Guide: [https://docs.astro.build/en/guides/cms/storyblok/](https://docs.astro.build/en/guides/cms/storyblok/)\n- Astro Syntax: [https://docs.astro.build/en/basics/astro-syntax/](https://docs.astro.build/en/basics/astro-syntax/)\n- Astro Community Guides: [https://docs.astro.build/en/community-resources/talks/](https://docs.astro.build/en/community-resources/talks/)\n- RichText vs Markdown: [https://www.ssp.sh/brain/markdown-vs-rich-text/](https://www.ssp.sh/brain/markdown-vs-rich-text/)","ogImage":{"url":"/assets/img/2024-05-15-HowIsetupmyBlogSitewithAstroandStoryblok_0.png"},"coverImage":"/assets/img/2024-05-15-HowIsetupmyBlogSitewithAstroandStoryblok_0.png","tag":["Tech"],"readingTime":11},{"title":"자바에서의 지도 지향 프로그래밍","description":"","date":"2024-05-15 15:16","slug":"2024-05-15-Map-OrientedProgramminginJava","content":"\n\nMOP을 사용하는 것은 때로는 편리할 수 있지만, 때로는 엉망일 수도 있습니다.\n\n![MOP image](/assets/img/2024-05-15-Map-OrientedProgramminginJava_0.png)\n\n# 바트폴로 가기!\n\nTwitter 및 LinkedIn에서 개발자들이 Bag/Multiset 유형을 사용하는지 또는 Java Map만 사용하는지에 대해 투표를 진행했습니다. 놀랍게도, java.util.Map이 양쪽 투표 모두에서 우세하게 보입니다.\n\n\n\n(1960년대 TV 버전 배트맨을 보지 못한 분들께 죄송합니다… 배트폴은 슬라이딩 서랍장 뒤에 숨겨진 두 막대이며 배트맨과 로빈은 이를 사용하여 배트케이브로 미끄러져 내려갔습니다.)\n\n이 질문은 Bag와 Map 중 어떤 것이 더 나은 유형인지를 결정하기 위한 것이 아닙니다. 두 인터페이스는 서로 다른 목적을 위해 사용되며 다른 동작을 갖습니다. Map은 키를 값에 연결합니다. Bag는 순서가 없는 중복되지 않는 컬렉션으로, 사물의 개수를 추적하기 쉽게 해주며 일반적으로 조회 속도를 높이기 위해 Map에 의해 지원됩니다. Map은 개수를 추적하는 데 사용될 수 있으며, 마찬가지로 망치를 잭해머 대신 콘크리트에 구멍을 뚫기 위해 사용할 수 있습니다. 누구도 망치가 콘크리트에 구멍을 뚫는 데 더 나은 도구라고 주장하지 않을 것입니다. 그러나 손에 잭해머가 없다면, 가지고 있는 망치로 콘크리트를 두드려 구멍을 뚫게 될 것입니다.\n\n어쨌든, 다시 설문과 궁극적인 질문으로… 이 설문에 언급된 세 개의 라이브러리는 Java에서 Bag/Multiset 유형을 제공합니다 - Google Guava, Apache Commons Collections 및 Eclipse Collections. 그리고 Java에서의 Map도 있습니다. 진짜 질문은 당신이 어플리케이션에 Bag/Multiset 유형을 얻기 위해 제3자 종속성을 받아들일 의사가 있는지이거나 Map-지향 프로그래밍(MOP)을 유지하는 것에 만족하는지입니다? 대부분의 개발자들은 요즘 다양한 이유로(바이너리 크기, 버전 충돌 해결, 잠재적 취약점 등) 제3자 종속성을 제한하려고 합니다. 이로 인해 대부분의 개발자들은 단지 JDK에서 제공되는 Map-지향 프로그래밍 대안을 활용하거나 Bag/Multiset 솔루션을 직접 만들어야 하는 입장에 자리 잡게 됩니다. 대부분 아는 개발자들은 Map-지향 프로그래밍 솔루션을 선택합니다.\n\n다음 인용구는 Map-지향 프로그래밍 (MOP)의 본질입니다.\n\n\n\nMOP의 문제는 Map이 key와 value 슬롯에 포함할 데이터에 대해 매우 유연하지만 그 동작은 동일하다는 점입니다. 말 그대로 Map이라는 것입니다. 거기에 데이터를 넣을 수도 있고, 빼낼 수도 있습니다. null이나 다른 무작위 타입을 포함하여요. 오랜 시간 동안 Java Map 인터페이스는 키가 없는 경우 기본 값을 가져오거나 요소를 병합하거나 계산할 수 있는 새로운 Map 특정 동작을 추가하여 유연성을 향상시켰습니다. 값 슬롯 중 하나에 컬렉션에 항목을 추가하거나 제거하는 등의 Map 계약의 일부가 아닌 추가 특수 동작이 코드에 노출되거나 Stream 및 Collector에 추가된 알고리즘에 끼어들게 됩니다. Map 위에 보완적인 동작을 제공하는 유형 및 구조를 가질 수 있는 능력을 상실합니다.\n\n저는 Smalltalk와 Java에서 전문적으로 일한 경험이 있어 동적 타입 시스템과 정적 타입 시스템 모두의 혜택을 즐겼습니다. 때로는 Map과 같은 데이터 구조는 동적 타입 시스템의 혜택을 느끼게 해줍니다만 정적 타입 시스템의 혜택은 제공하지 않습니다. 제게는 여러 가지 이유로 정적 타입 시스템을 좋아합니다. 혼자 개발할 때 때로는 속도를 늦춥니다만요. Map-지향 프로그래밍을 좋아하지는 않지만 새로운 유형을 추가하는 것이 번거로운 경우 편리함을 제공할 때 가끔 사용합니다. 새로운 유형이 필요하다는 것을 발견하면 주로 추가합니다. 이것은 가끔 어려운 길일 수 있지만 보통 옳은 길입니다. 저희 애플리케이션에 있는 모든 새로운 유형 추가에는 비용이 들지만, 의사 소통, 명확성, 캡슐화, 코드 중복 감소, 증가한 안전성 및 성능 향상과 같은 혜택도 함께 있습니다.\n\nJDK에는 Map으로 대체된 세 가지 누락된 유형이 있습니다. Map을 사용하면 기존 유형 유연성을 활용하여 비용을 피할 수 있습니다. 이 경우 프레임워크 개발자에게 부과된 비용은 Map을 반환 유형으로 사용하는 애플리케이션 개발자로 옮겨집니다. 다음은 이러한 Map 반환 유형을 사용하는 Collectors에서 변경할 수 없는 Map 반환 유형입니다. Java 8이 출시되었을 때 Collectors에 도입된 이 Map 반환 유형들입니다.\n\n```js\n// Map\u003cBoolean, List\u003cT\u003e\u003e -\u003e Pair\u003cT, T\u003e\nCollectors.partitioningBy()\n\n// Map\u003cT, Long\u003e          -\u003e Bag\u003cT\u003e\nCollectors.groupingBy(Collectors.counting)\n\n// Map\u003cK, Collection\u003cV\u003e\u003e -\u003e Multimap\u003cK, V\u003e \nCollectors.groupingBy() \n```\n\n\n\n페어(Pair), 가방(Bag) 및 멀티맵(Multimap)은 JDK에 빠진 몇 가지 유형 중 일부일 뿐이에요. 우리는 partitioningBy와 같은 경우에 Pair를 더 구체적으로 부르는 것이 가능하긴 하지만 여전히 같은 유형의 두 가지 항목으로 이루어진 Pair라는 것이에요.\n\n# 우리는 Pair 유형이 필요 없어요!\n\n자바에 제네릭 Pair 유형이나 제네릭 튜플 지원을 추가하지 않기로 한 결정은 신중하게 이루어 졌어요. 대신, Java Records를 통해 생성된 명명된 유형의 사용이 권장되는데, 이는 자바 16부터 릴리스된 이후부터 해당되는 사항이에요. 이 결정은 제가 완전히 지지하는 것이며, 제가 만든 오픈 소스 프레임워크(Eclipse Collections)가 Pair와 Triple 유형을 가지고 있더라도 그렇죠. 특수화된 유형을 만드는 것을 감사하게 생각하며, Java Records를 사용하여 매우 간단하게 수행할 수 있는 기술은 멋지다고 느껴요.\n\n다음에 올 내용을 기대해 주세요.\n\n\n\n## 지도를 이용해봅시다!\n\n일반적인 Pair 유형으로 Map을 사용하는 것은 일반적인 Pair 유형을 추가하는 것보다 나쁠 수 있다고 말할 수 있습니다. Map을 Pair로 사용하는 방법은 무엇인가요? JDK의 Stream 및 Collectors 코드에 있는 partitioningBy의 예제가 있습니다.\n\n다음과 같은 partitioningBy 예제를 살펴봅시다. 이 예제에서는 Integer Stream을 짝수와 홀수로 분리된 List 인스턴스로 필터링하는 과정을 한 번에 수행합니다.\n\n```js\n@Test\npublic void partitioningBy()\n{\n    Map\u003cBoolean, List\u003cInteger\u003e\u003e map =\n            IntStream.rangeClosed(1, 10)\n                    .boxed()\n                    .collect(Collectors.partitioningBy(each -\u003e each % 2 == 0));\n\n    List\u003cInteger\u003e evens = map.get(true);\n    List\u003cInteger\u003e odds = map.get(false);\n    List\u003cInteger\u003e ummm = map.get(null);\n    List\u003cInteger\u003e ohno = map.get(new Object());\n\n    Assertions.assertEquals(List.of(2, 4, 6, 8, 10), evens);\n    Assertions.assertEquals(List.of(1, 3, 5, 7, 9), odds);\n    Assertions.assertNull(ummm);\n    Assertions.assertNull(ohno);\n\n    ummm = map.getOrDefault(null, evens);\n    Assertions.assertEquals(List.of(2, 4, 6, 8, 10), ummm);\n\n    ohno = map.getOrDefault(new Object(), odds);\n    Assertions.assertEquals(List.of(1, 3, 5, 7, 9), ohno);\n}\n```\n\n\n\n이 코드는 1부터 10까지의 정수를 가진 Stream을 가져와서 partitioningBy를 사용하여 짝수 값을 하나의 List로 필터링하고 홀수 값을 다른 List로 분할합니다. 결과는 Map`Boolean, List`Integer``입니다. 맵에서 true 값은 포함하는 필터, false 값은 배타적인 필터, null 값은... 기다려봐, 왜 이 Map에 null 값이 있는 거지? 왜 Map`Boolean, List`Integer``에서 새로운 Object() 검색이 있는 거지? 여기에서 무슨 일이 벌어지고 있는 거야!?! Map은 제네릭이 Java에 추가되기 전인 Java 5 이전에 존재했음을 기억해. Map의 get 메서드는 제네릭이 아니고 모든 종류의 객체를 수용해.\n\npartitioningBy 결과를 깊게 파본 적이 없다면, 이 메서드는 Partition이라는 이름의 타입의 인스턴스를 반환하며, 이는 Collectors의 내부 클래스입니다. partitioningBy 메서드가 Map`Boolean, List`Type``을 반환한다는 것은 알고 있었지만, 실제 구현에 대해선 오늘 살펴보기 전까지 알지 못했어. Partition 타입은 변경할 수 없지만 위에서 설명한 대로 Map처럼 동작해. Map의 get 메서드는 제네릭이 아니기 때문에 모든 종류의 객체를 수용해. Partition 클래스는 get을 통한 부울이 아닌 접근 시 null을 반환하되 예외를 던지지는 않아. 잠재적으로 모든 종류로의 조회는 null을 반환해. getOrDefault 또는 다른 읽기 전용 Map 메서드는 다른 Map 유형과 일관된 방식으로 동작해. put과 같은 가변 메서드는 예외를 던집니다.\n\n## 원시 BooleanObjectMap을 사용해볼까요?\n\n부울을 키로 사용하는 원시 BooleanObjectMap의 제네릭 get 문제를 해결하기 위해 Eclipse Collections의 원시 버전을 제안할 것인지 궁금하신 분들을 위해... 나는 제안하지 않을 거야, 그리고 할 수도 없어. BooleanObjectMap 타입은 Eclipse Collections에 존재하지 않아. 우리가 원시 Map 계층 구조를 설계할 때, 우리는 부울을 키로 하는 모든 원시 맵 조합을 제거하기로 결정했어. Eclipse Collections에는 부울을 키로 하는 모든 것의 맵이 없어.\n\n\n\nBoolean 유형의 Map은 망치처럼 사용하는 것 같은 디자인 문제가 있습니다. true와 false 각각에 대한 두 가지 값이 필요하다면 값을 저장할 두 가지 변수를 사용하고 이러한 값을 특정 유형에 넣으세요. 새 유형 안의 변수는 의도를 드러내는 이름(예: 선택된(selected) 및 거부된(rejected), Eclipse Collections의 PartitionIterable)을 가질 수 있습니다. ifTrue와 ifFalse와 같이 의미 없는 이름이 아니라 Map의 Boolean 값처럼 적은 의미를 가진 이름을 사용하지 마세요. 이러한 값들을 무언가의 단일 제네릭 인스턴스로 함께 전달하려면 새로운 유형을 추가할 수 없거나 원하지 않으므로 제네릭 Pair를 사용하세요. 구매자 유의. Pair를 사용하면 내부 값에 대해 덜 의미 있는 이름을 얻을 것입니다 (one과 two 또는 left와 right).\n\n## 만약 Boolean 대신 Enum을 키 유형으로 사용하면 어떨까요?\n\n같은 유형의 쌍을 나타내기 위해 Map을 사용하는 또 다른 옵션은 키로 Enum을 사용하는 것입니다. Enum 내의 이름이 의도를 드러내는 이름(예: Filter.SELECTED, Filter.REJECTED)을 가지도록 한 후 map.get(Filter.SELECTED) 대신 map.get(true)을 쓸 수 있습니다.\n\n이 솔루션에는 키 이름을 포함할 새 Enum 유형이 만들어져야 합니다. 이미 새 유형을 추가해야 하는 경우에는 지정된 변수와 유형으로 필요한 특정 유형을 정의하는 것이 더 좋습니다(e.g., 선택된(selected) 및 거부된(rejected) 변수를 가진 Partition 유형). Enum에서 더 나은 이름도 Map의 get 메서드에 대한 일반적인 문제를 해결하지 않습니다. 사실, 여전히 map.get(true)를 작성하면 null을 반환할 수 있습니다.\n\n\n\n# Stop Hammer time!\n\n저는 JDK가 가능한 경우에는 Map 대신에 특정 유형을 반환하여 정적 유형의 이점을 활용하는 것이 더 나을 것이라고 생각합니다. partitioningBy에 대해 Partition 유형을 반환하는 것이 Map을 반환하는 것보다 더 의미가 있을 것으로 생각합니다. 이렇게 하면 새로운 공개 유형을 노출해야 합니다. Partition 유형은 비공개 정적입니다. 새로운 공개 유형이 Pair와 같이 완전히 일반적인 유형이 될 필요는 없습니다. Eclipse Collections의 partition 메서드는 RichIterable에서 PartitionIterable 유형을 반환합니다. Eclipse Collections 개발자가 처리하는 이 유형과 모든 하위 유형을 추가/유지하는 데는 비용이 듭니다. 라이브러리를 사용하는 개발자들에게 유형 계층구조의 다양한 수준에서 가장 안전하고 가장 구체적인 대안을 제공합니다.\n\n```java\n@Test\npublic void partition()\n{\n    PartitionMutableList\u003cInteger\u003e partition =\n            Interval.oneTo(10)\n                    .partition(each -\u003e each % 2 == 0);\n\n    MutableList\u003cInteger\u003e selected = partition.getSelected();\n    MutableList\u003cInteger\u003e rejected = partition.getRejected();\n\n    Assertions.assertEquals(List.of(2, 4, 6, 8, 10), selected);\n    Assertions.assertEquals(List.of(1, 3, 5, 7, 9), rejected);\n}\n```\n\nCollectors가 Map을 반환하는 두 가지 다른 위치가 더 구체적인 유형으로 반환될 것이 더 나았을 것입니다. 문제는 편의성과 비용입니다. Java 8 릴리스에서 Bag 또는 Multimap과 같은 보다 구체적인 유형을 도입할 필요가 있었기 때문에 Map을 반환하는 것이 더 편리했었습니다. 하지만 이는 Java 8 릴리스를 크게 지연시킬 수도 있었을 것입니다. 몇 년 전 Eclipse Collections에서 이러한 유형이 생성된 것을 본 바 있습니다. 이러한 유형은 구축 및 테스트하기가 모두 비용이 많이 드는 것으로 확인할 수 있습니다. 안타깝게도, 편의성을 따라가고 Collectors에서 Map 형식을 영원히 반환할 결정에 갇혀 있습니다.\n\n\n\n저는 이전에 Map vs. Bag 및 Map vs. Multimap에 대해 블로그를 작성했습니다. 더 알고 싶다면 아래 링크에서 블로그를 읽어보세요.\n\nEclipse Collections에서 partition에 대한 몇 가지 다른 예제와 세부 정보가 있습니다. 아래 블로그에 해당 내용이 있습니다. 이 블로그에서 일부 개발자들에게 가장 흥미로운 것은 partition 메서드의 공변성을 지원하기 위해 구현된 PartitionIterable 계층 구조입니다.\n\n# Map-중심 프로그래밍의 미래\n\nMap은 망치입니다. 매우 유용하고 편리한 도구이지만, 우리는 Map을 모든 용도의 도구로 자주 사용하며, 유연한 반환 유형으로 너무 자주 의지합니다. Java Records는 정적 타입의 이점과 함께 새로운 편의수준을 제공합니다. Bag 및 Multimap과 같은 추가 Collection 유형은 Map의 능력을 다양한 특수화된 동작으로 보완하여 개발자가 활용할 수 있도록 합니다.\n\n\n\n데이터 중심 프로그래밍 공간에서는 행 기반 맵 컬렉션보다 훨씬 구체적인 Dataframe 라이브러리와 같은 솔루션을 선호합니다. 이러한 라이브러리들은 기능과 목적에 대해 맵 컬렉션보다 훨씬 명확합니다. 제 생각에는 Java Record가 정적 타입 검사가 가능한 레코드 유형의 컬렉션을 생성하는 데 좋은 저회의 대안을 제공합니다. 이는 타입 안정성, 메모리 효율성 및 성능을 제공하는 데 도움이 됩니다.\n\nJDK에 더 많은 컬렉션 유형이 통합되기를 희망합니다. 편리하지만 혼란스러운 대체로 Map을 계속 사용하는 대신 Partition, Bag 및 Multimap 유형이 포함되었으면 좋겠습니다. 이미 Partition은 구현으로 존재합니다. Partition은 Map이 된 척을 그만두고 대신 더 구체적이고 제한적인 인터페이스로 공개되거나 표현되어야 합니다. 안타깝게도 partitioningBy가 이미 Map을 반환하기 때문에 이 메서드는 아마도 변경되지 않을 것이지만 더 나은 반환 유형을 가진 대안으로 대체될 수 있도록 사용 중지 또는 폐기될 수 있습니다.\n\n이 블로그를 통해 Map을 모든 용도의 반환 유형으로 사용할 때의 비용 대비 이점에 대해 생각해보시기를 바랍니다. 내 권장 사항 -- 그렇게 하지 마십시오! 메서드에 대해 사용 가능한 최상의 옵션이 이메일 인 경우에만 Map을 반환 유형으로 사용하십시오. 다른 유형이 더 나은 옵션이 될 경우에는 해당 유형을 생성하거나 이미 존재하는 경우 사용하십시오.\n\n읽어 주셔서 감사합니다!\n\n\n\n저는 Eclipse Collections OSS 프로젝트의 창시자이자 기여자입니다. 이 프로젝트는 Eclipse Foundation에서 관리됩니다. Eclipse Collections는 기여를 환영합니다.","ogImage":{"url":"/assets/img/2024-05-15-Map-OrientedProgramminginJava_0.png"},"coverImage":"/assets/img/2024-05-15-Map-OrientedProgramminginJava_0.png","tag":["Tech"],"readingTime":9},{"title":"사이버 보안과 2024년 호주 연방 예산","description":"","date":"2024-05-15 11:47","slug":"2024-05-15-CybersecurityandtheAustralianFederalBudget2024","content":"\n\n예산에서 사이버 보안 항목을 찾아봤어요. 귀찮게 하지 않고 대신 찾았죠.\n\n![이미지](/assets/img/2024-05-15-CybersecurityandtheAustralianFederalBudget2024_0.png)\n\n## 처음 생각\n\n2021년, 2022년, 2023년에 본 것과 같이, 호주 정부는 사이버 보안 관련 예산을 자체에만 사용하고 있어요.\n\n\n\n그렇다면, 적어도 보통 시민을 보호하기 위해 어떻게 돈을 집중할지에 대해 고민한 것으로 보입니다:\n\n- 가장 많은 돈을 받은 기관은 많은 주요 시민 정보를 보유한 시스템을 책임지고 있습니다.\n- 호주의 디지털 ID 능력을 확대하는 데 상당한 금액이 소요되고 있습니다.\n- 여러 산업 전반에 걸쳐 사이버 보안을 시행하는 주요 규제 기관들은 자체 사이버 저항력을 향상시키기 위해 상당한 돈을 받았습니다.\n\n## 예산 지출\n\n예산 내 사이버 관련 항목에 대한 세부 내용은 다음과 같습니다:\n\n\n\n- 서비스 오스트레일리아에 18억 달러가 지원될 예정입니다. 이는 고객 및 결제 서비스 제공을 지원하기 위한 것으로, 이에는 클레임 처리, 자연 재해 대응, 사이버 보안 환경 개선을 위한 초기지원금뿐만 아니라 프론트라인 직원과 서비스 제공 직원에 대한 자금도 포함됩니다.\n- 2년 동안 3억 1410만 달러가 투입되어 서비스 오스트레일리아 센터의 안전과 보안을 크게 강화할 예정입니다.\n- 2억 8810만 달러가 추가 투자되어 오스트레일리아의 디지털 ID 시스템의 확대 및 구축을 지원할 예정이며 이를 통해 더 많은 오스트레일리아인들이 디지털 ID의 경제, 보안 및 개인 정보 보호 혜택을 실현할 수 있습니다.\n- 2024-25년까지 연간 4년에 걸쳐 총 2억 6400만 달러(연간 720만 달러)가 투입되어 호주 은행감독청(APRA), 호주 증권거래위원회(ASIC)의 데이터 역량과 사이버 보안을 개선하고 비즈니스 등록부 안정화 및 기존 시스템의 현대화를 계속 지원할 것입니다.","ogImage":{"url":"/assets/img/2024-05-15-CybersecurityandtheAustralianFederalBudget2024_0.png"},"coverImage":"/assets/img/2024-05-15-CybersecurityandtheAustralianFederalBudget2024_0.png","tag":["Tech"],"readingTime":1},{"title":"첫 번째 RCE를 발견한 방법","description":"","date":"2024-05-15 11:46","slug":"2024-05-15-HowIFoundMyFirstRCE","content":"\n\n안녕하세요 여러분! 이 글에서는 제 첫 RCE 경험에 대해 이야기하려고 해요. 제가 Apache ActiveMQ에서 발생한 CVE-2023-46604로 발생한 사건이죠. 전문적인 버그 헌터를 위한 새로운 정보를 제공하는 것보다는 어떻게 발견했는지에 더 초점을 맞출 거에요.\n\n저의 탐색 과정에서, 매주 서브도메인 목록을 업데이트하고 3일마다(하루에 한 번 하는 것이 더 좋겠지만) 열린 포트를 스캔했어요. 서브도메인 열람을 위해 Subfinder와 Amass 같은 도구를 사용했어요.\n\n```js\nsubfinder -dL domains.txt -o subdomains.txt\n#그리고 서브도메인의 서브도메인\nsubfinder -dL subdomains.txt -o more-subdomains.txt\n\n#Amass 사용\namass enum -passive -norecursive -noalts -df domains.txt -o subs.txt\n#그리고 서브도메인의 서브도메인\namass enum -passive -norecursive -noalts -df subs.txt -o more-subs.txt\n```\n\n\n\n아래와 같이 하세요:\n\n```bash\ncat more-subdomains.txt subdomains.txt subs.txt more-subs.txt | sort -u \u003e targets.txt\n```\n\n이후에는 몇 가지 경우에는 많은 수의 서브도메인이 생기기도 하는데, 때로는 5천개 이상이 될 때도 있습니다. DNSx를 사용하여 서브도메인을 확인하는 간단한 스크립트를 만들어 15개씩 그룹으로 나누었습니다. 그런 다음, 백그라운드에서 계속 실행하기 위해 nohup을 사용하여 Naabu를 실행했습니다.\n\n사용한 스크립트\n\n\n\n```sh\n#!/bin/bash\n\nif [ $# -eq 0 ]; then\n    echo \"사용법: $0 \u003cfile\u003e\"\n    exit 1\nfi\n\ncat $1 | dnsx -o $1_ok.txt\n\nsplit -l 15 $1_ok.txt 15_file_\n\nfor file in 15_file_*; do\n    nohup naabu -list \"$file\" -p - -o \"${file}.out\"\u0026\ndone\n```\n\n그리고\n\n```sh\ncat 15*out | sort -u \u003e ports.out \n```\n\n많은 시간 동안 그 목록을 수동으로 확인했습니다. 저는 허니팟일 가능성이 있는 호스트를 필터링했고, 때로는 Naabu가 신뢰할 수 없는 결과를 제공했습니다.\n\n\n\n그리고 그 이후에, 3부터 10 사이의 열린 포트를 가진 호스트를 수동으로 확인했어요. 이상한 열린 포트를 발견했을 때, Nmap을 이용해서 어떤 서비스가 작동 중인지 확인했어요.\n\n한 사례에서 bamboo.target.com이라는 호스트가 있었고, 포트 54663이 열려 있다는 것을 알았어요.\n\n-sSCV 플래그와 함께 Nmap을 사용했을 때, Apache ActiveMQ가 실행 중이라는 것을 확인했고, 최신 버전의 CVE-2023-46604가 있었어요.\n\n그런 다음 해당 취약점을 쉽게 적용했는데, 바로 작동했어요. 상세 보고서를 작성했고, 이는 현명한 선택이었어요. 트리저와 보안팀에 필요한 모든 정보를 제공하는 것은 자신의 노력에 대한 좋은 보상을 가져다주곤 해요.\n\n\n\n아래는 제 결과에 대한 이미지입니다\n\n![이미지1](/assets/img/2024-05-15-HowIFoundMyFirstRCE_0.png)\n\n그 결과에 대한 이미지도 있습니다\n\n![이미지2](/assets/img/2024-05-15-HowIFoundMyFirstRCE_1.png)\n\n그게 다야! 시간 내어 주셔서 감사합니다. LinkedIn이나 Twitter도 부담 갖지 마시고 방문해주세요 — 거기서 친구를 찾고 있어요!\n\n\n\n# 찬양합니다. 주님, 우리에게 깨닫는 것은 주님의 가르침밖에 없습니다. 우리의 마지막 기도는 모든 찬양을 받으시는 세계의 주님 하나님께로부터 오는 것입니다.","ogImage":{"url":"/assets/img/2024-05-15-HowIFoundMyFirstRCE_0.png"},"coverImage":"/assets/img/2024-05-15-HowIFoundMyFirstRCE_0.png","tag":["Tech"],"readingTime":2},{"title":"플러터 프로젝트에 조금의 창조적 예술 추가하기","description":"","date":"2024-05-15 11:44","slug":"2024-05-15-AddingabitofGenerativeArttoaFlutterproject","content":"\n여러분 안녕하세요, 저는 최근에 pub.dev에 제 첫 번째 패키지를 게시했어요. 이 패키지는 여러분의 프로젝트를 좀 더 흥미롭게 만들어줄 수 있는 기능을 제공해요. 이 글에서는 이 패키지를 만드는 과정과 활용 방법에 대해 알려드릴게요.\n\nFlutter Animated Generative Art Backgrounds collection (gen_art_bg)은 플러터 앱에 흥미로운 애니메이션 배경을 추가하거나 로딩 화면으로 사용하는 것을 쉽게 만들어줍니다.\n\n![image](/assets/img/2024-05-15-AddingabitofGenerativeArttoaFlutterproject_0.png)\n\n모든 것은 flutter 지식과 기술을 향상시키기 위해 개발 중인 사이드 프로젝트로 시작했어요. 간단한 게임을 만들기 시작했고 정적 애플리케이션에 애니메이션을 추가하고 심지어 미니멀한 디자인을 유지하는 것에 도전했죠.\n\n저는 Flutter에서 애니메이션 그리드 배경에 대해 쓴 글을 정확히 이렇게 썼어요.\n\n한 예를 만들어서 앱에 통합시켰는데 결과물이 정말 마음에 들었어요. 더 발전시키고 몇 가지 더 예제를 추가하고 싶었어요.\n\n몇몇 작업에서 영감받아 flutter와 비슷한 것을 구현해보기로 결정했어요.\n\nflutter_spinkit에 영감을 받아요.\n\n그리고 플러터에서 화제인 생성 예술 주제의 멋진 기사 및 저장소를 소개합니다.\n\n- 플러터에서의 생성 예술\n- funvas\n- Flutter-Artbook\n- 아트 프로세싱 플레이그라운드\n- GenArtCanvas\n\n## p5.js 제작자\n\n- Patt Vira\n- mattdesl\n\n## 작성자 정보\n\n- 로니 카우프만\n\n만약 이 주제에 대한 다른 자료를 알고 계시다면 꼭 알려주세요!\n\n# 그래서 왜 막바지에 패키지를 만들게 되었을까요?\n\n위에는 두 가지 분명한 이유가 있습니다:\n\n- 진짜 작은 프로젝트 만들기\n\n네, 패키지도 작은 프로젝트예요(일부 패키지는 앱만큼 유용할 수 있어요). 프로젝트 개발 및 배포의 모든 과정을 직접 경험하고 싶었습니다.\n\n- 커뮤니티 기여\n\np5.js를 사용하면 이러한 애니메이션을 쉽게 구현할 수 있습니다. 플러터는 다른 작업이 필요합니다. 원하는 배경의 이름을 호출하는 것이 코드를 처음부터 작성하는 것보다 더 쉽다고 판단했습니다.\n\n15개의 예제가 준비되자마자 패키지 개발을 시작했습니다. 인터넷에는 프로젝트를 만드는 방법에 대한 많은 안내서가 있으므로 여기서는 몇 가지 포인트만 언급하겠습니다.\n\n위젯 속성을 조정할 수 있는 기능을 추가하여 생성자를 통해 전달하고 패키지를 쉽게 사용할 수 있도록 README.md를 형식화했습니다.\n\n# 패키지 소개\n\n설치는 pub.dev의 모든 패키지와 동일한 방식으로 진행됩니다:\n\n```yaml\ndependencies:\n  gen_art_bg: ^0.0.2\n```\n\n```js\nimport \"package:gen_art_bg/gen_art_bg.dart\";\n```\n\n또는 Flutter의 경우:\n\n```js\nflutter pub add gen_art_bg\n```\n\n그 다음으로 진행할 내용은:\n\n```js\nvoid main() {\n  runApp(const MaterialApp(\n    debugShowCheckedModeBanner: false,\n    home: Scaffold(\n      body: WaveLineGrid(\n        columns: 15, // 열의 수를 변경하려면 이 값을 변경하세요\n        rows: 25, // 행의 수를 변경하려면 이 값을 변경하세요\n        locationConstant: 100, // 위치를 변경하려면 이 값을 변경하세요\n        animationDuration: Duration(seconds: 5), // 애니메이션 지속 시간을 변경하려면 이 값을 변경하세요\n      )\n    ),\n  ));\n}\n```\n\n완성!\n\n다음으로, 우리는 각 예제를 개별적으로 살펴볼 것입니다.\n\n# 쇼케이스\n\n## WaveLineGrid\n\n![WaveLineGrid](https://miro.medium.com/v2/resize:fit:324/1*Ya_bFaYvfthWV7aCbIKAdA.gif)\n\n```js\nWaveLineGrid(\n        columns: 15, // 그리드의 열 수\n        rows: 25, // 그리드의 행 수\n        locationConstant: 100, // 그리드 위치 조정 상수\n        animationDuration:  Duration(seconds: 5), // 애니메이션의 지속 시간\n      ),\n```\n\n## PerlinNoise\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:324/1*MfXXrfKaEwLfOxmFLUQjOA.gif\" /\u003e\n\n```js\nPerlinNoise(\n        width: 40, // 폭\n        height: 40, // 높이\n        frequency: 5, // 주파수\n      ),\n```\n\n## 랜덤스퀘어\n\n![이미지](https://miro.medium.com/v2/resize:fit:312/1*eROYDX56LY7L-MO0S90-hQ.gif)\n\n```js\nRandomSquare(\n        gridSize: 10, // 그리드 크기를 변경하려면 이 값을 수정하세요\n        updateInterval: Duration(seconds: 1), // 업데이트 간격을 변경하려면 이 값을 수정하세요\n      ),\n```\n\n## 스파이럴 웨이브\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:312/1*nk6mjIB32974wRuJm5FzQA.gif\" /\u003e\n\n```js\nSpiralWave(\n        size: 10, // 각 원의 크기\n        k: 20, // 파도 효과 제어 상수\n      ),\n```\n\n## GridOfLines\n\nmattdesl에 영감을 받음\n\nmd\n![GridOfLines animation](https://miro.medium.com/v2/resize:fit:324/1*u010xIK6bJ1u3P0gbcX9SQ.gif)\n\n```js\nGridOfLines(\n        animationDuration: 5, // Animation duration in seconds\n        gridSize: 10, // Number of lines in the grid\n        strokeWidth: 0.015, // Stroke width of the lines\n        color: Colors.black, // Color of the lines\n      ),\n```\n\n## AnimatedBWSquares and AnimatedColoredSquares\n\nRoni Kaufman의 영감을 받아 만들어졌습니다.\n\n![image](https://miro.medium.com/v2/resize:fit:324/1*M8eaiZY1slAFRz_C3KU0-g.gif)\n\n```js\nAnimatedBWSquares(\n        squareCount: 40, // Number of squares\n        animationDuration: 10, // Duration of the animation\n        margin: 0, // Margin around the canvas\n        strokeWidth: 1.5, // Stroke width of the squares\n      ),\n```\n\n## AnimatedLines\n\n![image](https://miro.medium.com/v2/resize:fit:324/1*zLmbd3nXmeePU0aS4Iul0w.gif)\n\n```js\nAnimatedLines(\n        numberOfLines: 30, // 라인 수\n        lineLength: 200, // 각 라인의 길이\n        lineColor: Colors.black, // 각 라인의 색상\n        strokeWidth: 3, // 각 라인의 스트로크 너비\n        animationDuration: 10, // 애니메이션 지속 시간\n      ),\n```\n\n## AnimatedLinesGradient\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:324/1*Noj2EpPkomlHwaBhsxBnwA.gif\" /\u003e\n\n```js\nAnimatedLinesGradient(\n        animationDuration: 5, // 애니메이션 지속 시간\n      ),\n```\n\n## 랜덤노이즈\n\n![랜덤노이즈](https://miro.medium.com/v2/resize:fit:324/1*G5SU8F9du_k4jwfceK0n-w.gif)\n\n```js\nRandomNoise(\n        duration: Duration(seconds: 10), // 애니메이션 지속 시간\n        dotSize: 13, // 점의 크기\n        dotSpacing: 11, // 점 사이의 간격\n      ),\n```\n\n## 몰나르아트\n\nRoaa Khaddam의 영감을 받아서\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:324/1*CJHl7YWPQSw5zdFCxPPH4g.gif\" /\u003e\n\n```js\nMolnarArt(\n        rows: 8, // 행 수\n        cols: 8, // 열 수\n        n: 12, // 코드\n        colSeq: [\n          Color(0xFFC4951B),\n          Color(0xFF9E3C52),\n          Color(0xFF1D6383),\n          Color(0xFF19315B),\n          Color(0xFF0D1280),\n          Color(0xFFADD27D),\n          Color(0xFFBD1528),\n          Color(0xFF0D4D89),\n          Color(0xFFAC4075),\n          Color(0xFFAB933C),\n          Color(0xFF7EB741),\n          Color(0xFF1C2266),\n        ],\n      ),\n```\n\nMolnarArt 함수의 매개변수 n은 각 그리드 셀에 생성된 이진 코드의 비트 수를 맡습니다. 이 이진 코드는 각 셀의 패턴 구조를 정의하는 데 사용됩니다. 좀 더 구체적으로, 이 이진 코드의 각 비트는 특정 패턴 레이어가 매핑되어야 하는지를 나타냅니다. 예를 들어, n이 12이면 각 그리드 셀에 대해 무작위 12비트 이진 코드가 생성됩니다. 이 코드의 각 비트는 다른 패턴 레이어를 나타냅니다. 비트가 1로 설정되어 있으면 해당 패턴 레이어가 해당 셀에 표시되고, 비트가 0이면 레이어가 표시되지 않습니다.\n\n## ConicGradient\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:324/1*oy61Nehr-KMyZ5tnT6zvsw.gif\" /\u003e\n\n```js\nConicGradient(\n        durationSeconds: 10, // 애니메이션의 지속 시간(초)\n        maxDiameter: 1.2, // 그라데이션의 최대 지름\n        steps: 10, // 그라데이션의 단계 수\n      ),\n```\n\n## PulsedCircleGrid\n\nInspired by Roni Kaufman\n\n![Image](https://miro.medium.com/v2/resize:fit:324/1*I5wdqJfYMHm3mpI7oyF_Cg.gif)\n\n```js\nPulsedCircleGrid(\n        cellSize: 36, // Size of each grid cell\n        marginSize: 72, // Margin around the grid\n        circleDiameter: 27, // Diameter of circles\n        animationDuration: Duration(seconds: 5), // Animation duration\n        numberOfRowsColumns: 12, // Number of rows and columns in the grid\n      ),\n```\n\n## WaveDotGrid\n\nWaveLineGrid를 사용한 동일한 예시이지만 점 사이에 선이 없는 버전입니다.\n\n![WaveDotGrid](https://miro.medium.com/v2/resize:fit:324/1*-lIFdHQ6m3s4mzeF21mPNg.gif)\n\n```js\nWaveDotGrid(\n        columns: 15, // 열의 수\n        rows: 25, // 행의 수\n        locationConstant: 100, // 위치 상수\n      ),\n```\n\n여기서 각 예시가 모든 기기 크기에서 동일하게 동작하지는 않는다는 점을 강조해야 합니다. 만약 문제가 발생하는 경우 문제를 열어 알려주세요. 라이브러리에 기능이 누락된 것 같다면 Github에서 티켓을 올려주시면 살펴보겠습니다. PR도 환영합니다.\n\n# 다음은 무엇인가요?\n\n더 많은 예제를 추가하여 이 패키지를 개발하고 싶습니다. 이런 종류의 개발은 처음이라서 피드백을 공유해 주시면 감사하겠습니다.\n또한 패키지의 개발에 참여해 주시면 더욱 기쁠 것입니다.\n\n## 링크\n\n- 패키지\n- GitHub\n\n이 기사를 즐겨 보셨길 바랍니다. 의견을 댓글로 공유해 주세요 ❤️\n\n참, 패키지 개발 권장 사항에 대해 Eugenia님에게 많은 감사를 드립니다\n","ogImage":{"url":"/assets/img/2024-05-15-AddingabitofGenerativeArttoaFlutterproject_0.png"},"coverImage":"/assets/img/2024-05-15-AddingabitofGenerativeArttoaFlutterproject_0.png","tag":["Tech"],"readingTime":7},{"title":"대용량 언어 모델을 제공하는 도커 이미지 크기를 줄이기 파트 1","description":"","date":"2024-05-15 11:42","slug":"2024-05-15-ReducingtheSizeofDockerImagesServingLargeLanguageModelspart1","content":"\n\n\u003cimg src=\"/assets/img/2024-05-15-ReducingtheSizeofDockerImagesServingLargeLanguageModelspart1_0.png\" /\u003e\n\n# 소개\n\nBERT, RoBERTa 또는 T5와 같은 Transformer 기반 모델은 자연어 처리에서 맞춤 문제에 대한 최신 솔루션을 제공합니다. 제품에서 모델을 제공하는 보편적인 방법은 모델에 대한 API를 제공하는 Docker 이미지를 빌드하는 것입니다. 이미지는 필요한 종속성, 모델 자체 및 모델로 입력 데이터를 처리하는 코드를 캡슐화합니다. 큰 생성 모델 (GenAI)과 비교하면, 이러한 모델은 상대적으로 작아서 0.5~2GB 정도입니다. 그러나 모델을 Docker 이미지로 배포하는 간단한 방법을 따를 때, 이미지 크기가 8GB에 이를 수 있음에 놀랐을 수도 있습니다. 대상 이미지가 왜 그렇게 큰지, 그리고 이미지 크기를 줄일 수 있는 방법이 있는지 궁금했던 적이 있나요? 이 이야기에서는 Docker 이미지가 왜 그렇게 큰지 설명하고 그 크기를 줄이는 방법에 대해 논의하겠습니다.\n\n이 이야기에서 사용된 Python 스크립트 및 Docker 파일의 예시는 [1]에서도 확인할 수 있습니다:\n\n\n\n# 기본 도커 이미지\n\n언어 감지 모델을 위한 간단한 도커 이미지를 만들어 봅시다. 모델을 구축하기 위한 몇 가지 전제사항은 다음과 같습니다:\n\n- 훈련된 모델을 사용할 것입니다: papluca/xlm-roberta-base-language-detection [2].\n- 가능한 최상의 성능을 얻기 위해 GPU를 활용할 것입니다.\n- 단일 텍스트를 처리하는 간단한 엔드포인트를 제공하기 위해 FastAPI를 사용할 것입니다.\n\n다음은 이미지를 빌드하기 위한 Dockerfile입니다:\n\n\n\n모델을 로드하고 추론을 수행하는 데 사용된 코드는 다음과 같습니다:\n\n다음은 이미지를 빌드하는 데 사용된 명령어입니다:\n\n```js\ndocker build -t language_detection_cuda . -f Dockerfile_cuda\n```\n\n... 그리고 이미지를 실행하세요.\n\n\n\n```js\n도커 실행 --gpus 0 -p 8000:8000 language_detection_cuda\n```\n\n... 엔드포인트를 테스트해 보겠습니다:\n\n```js\n시간 curl -X 'POST'   'http://localhost:8000/process'   -H 'accept: application/json'   -H 'Content-Type: application/json'   -d '{\n  \"text\": \"Certo ci sono stati dei problemi - problemi che dovremo risolvere in vista, per esempio, dell'\\''ampliamento - ma a volte ne esageriamo il lato negativo.\"\n}'\n```\n\n다음 출력을 받았습니다:\n\n\n\n```js\n\"it\"\n```\n\n지금까지 특별한 것은 없어요. 엔드포인트가 할 일을 잘 수행하고 있어요.\n\n모델의 크기는 1.11GB입니다 (model.safetensors 파일), 토크나이저를 위한 추가 10MB가 있어요. 이제 도커 이미지의 크기를 보겠습니다:\n\n```js\ndocker images | grep language_detection_cuda\n```\n\n\n\n… 출력물은:\n\n```js\nlanguage_detection_cuda    최신 버전   47f4c1c0de2d   33분 전   7.05GB\n```\n\n도커 이미지의 총 용량은 7.05GB입니다. 와우, 상당히 많죠? 하지만 왜 이미지가 그렇게 큰 걸까요? 이제 컨테이너로 들어가서 내부를 확인해 보겠습니다.\n\n```js\ndocker run -it --gpus 0 -p 8000:8000 --entrypoint \"/bin/bash\"  language_detection_cuda\n```\n\n\n\n이미지 크기를 분석하기 위해 du명령어를 사용하고 가장 큰 폴더를 추적할 것입니다.\n\n```shell\ndu -h --max-depth 1 /\n```\n\n루트 디렉토리의 출력을 포함하여 가장 큰 폴더들:\n\n```shell\n5.9G    /usr\n1.1G    /workspace\n ...\n```\n\n\n\nWorkspace 폴더에는 모델과 Python 스크립트가 포함되어 있으며, 주로 model.safetensors 파일의 크기입니다. 여기서 놀라운 점은 없어요.\n\nusr 폴더에는 Python 코드를 실행하는 데 필요한 종속성이 포함되어 있어요. 폴더 안에 무엇이 있는지 살펴보겠습니다.\n\n\n- 5.3G /usr/local/lib/python3.9/dist-packages/\n- 2.9G /usr/local/lib/python3.9/dist-packages/nvidia\n- 1.6G /usr/local/lib/python3.9/dist-packages/torch\n- 439M /usr/local/lib/python3.9/dist-packages/triton\n- 77M /usr/local/lib/python3.9/dist-packages/transformers\n- 53M /usr/local/lib/python3.9/dist-packages/sympy\n- ...\n\n\n5.9G 중 5.3G는 Python 모듈을 위한 것입니다. 가장 큰 패키지는 다음과 같습니다:\n\n\n\n- 3.0 GB — nvidia (cuda, cudnn, cublas, 등)\n- 1.6 GB — torch\n- 0.4 GB — triton\n\nnvidia와 triton 모듈은 torch에 종속됩니다. GPU에서 추론을 실행하려면 nvidia 모듈이 필요합니다. 다시 말해, transformers 모듈을 실행하기 위해서 torch 모듈이 필요합니다. 아래 다이어그램은 언급된 모듈이 전체 이미지에 기여하는 방식을 보여줍니다.\n\n![Diagram](/assets/img/2024-05-15-ReducingtheSizeofDockerImagesServingLargeLanguageModelspart1_1.png)\n\nGPU에서 추론을 실행하려면 이미지 크기를 크게 줄일 수 있는 방법은 없습니다. 그러나 GPU 추론 대신 ONNX [4] 및 양자화를 사용하여 Docker 이미지 크기를 최대 10배 줄일 수 있습니다.\n\n\n\n# ONNX 모델을 포함한 Docker 이미지\n\nint8 양자화가 적용된 ONNX는 성능 손실이 거의 없는 채 모델 크기를 4배로 축소할 수 있습니다 [5]. 다른 장점은 Docker 이미지의 크기를 최대 10배 줄일 수 있다는 것입니다. 이것이 어떻게 가능한 걸까요? ONNX 모델의 Docker 이미지를 빌드하는 데 필요한 작업을 살펴보겠습니다:\n\n다음은 onnxruntime을 사용하여 추론을 실행하는 Python 코드입니다:\n\n먼저, 이미지를 빌드하고 크기를 비교해 보겠습니다. 그런 다음, 이와 이전 이미지 간의 차이를 분석하겠습니다.\n\n\n\n```js\n도커 빌드 -t language_detection_onnx . -f Dockerfile_onnx\n```\n\n… 그리고 이미지를 실행하세요:\n\n```js\n도커 실행 -p 8000:8000 language_detection_onnx\n```\n\n이미지의 크기를 비교해봅시다:\n\n\n\n```js\n도커 이미지 | grep language_detection\n```\n\n출력:\n\n```js\nlanguage_detection_cuda    latest   47f4c1c0de2d   33분 전   7.05GB\nlanguage_detection_onnx    latest   3086089bd994   9시간 전    699MB\n```\n\n7.05 GB 대 699 MB — 이것은 정말로 10배 작은 도커 이미지입니다. 이게 어떻게 가능했을까요?\n\n\n\n세 이미지 사이에는 세 가지 주요 차이점이 있습니다.\n\n## 1. 베이스 도커 이미지\n\n대신 nvidia/cuda:11.8.0-base-ubuntu22.04를 사용하는 대신에 훨씬 작은 베이스 도커 이미지 python:3.9-slim을 사용했습니다. 첫 번째 이미지에는 GPU에서 추론을 실행하는 데 필요한 모든 Nvidia 라이브러리가 포함되어 있습니다 (CUDA, cuDNN, cuBLAS). ONNX 및 양자화된 모델로 추론을 실행하기 위해서는 GPU가 필요하지 않습니다. 따라서 Nvidia 라이브러리가 필요하지 않습니다.\n\n## 2. Python 모듈\n\n\n\n토치 대신 NVIDIA와 Triton 모듈이 필요 없는 ONNX Runtime을 사용했습니다. 이렇게 하면 세 개의 큰 Python 모듈을 제거할 수 있었어요.\n\n## 3. ONNX 형식의 양자화된 모델\n\n마지막으로 중요한 차이점은 ONNX 형식으로 변환된 양자화된 모델을 사용했다는 것입니다 [3]. model_quantized.onnx 파일은 279 MB로, 원본 모델 크기의 4분의 1 크기입니다.\n\n# 결론\n\n\n\n양자화된 ONNX를 사용하면 제품 이미지의 크기를 최대 10배까지 줄일 수 있어요.\n\n어떤 경우에는 제품 모델의 크기가 과도한 모델 성능보다 중요할 수 있어요. 그런 경우에는 모델 양자화와 ONNX 형식으로 전환하는 것이 도움이 될 수 있어요. 양자화는 Docker 이미지의 크기를 줄일 뿐만 아니라 CPU를 사용하는 인스턴스보다 GPU를 사용하는 인스턴스보다 비용을 줄일 수 있어요. 그럼에도 결정은 여러 요인에 기반해야 해요 - 해결해야 하는 문제, 예상 성능, 예상 추론 시간, 양자화된 모델에 대한 성능 손실, 그리고 제품 환경의 구성 등을 고려해야 해요.\n\n# 문제 해결\n\n도커 이미지를 --gpus 매개변수와 함께 실행하는 중 문제가 발생하면 다음을 확인해보세요:\n\n\n\n- Nvidia 컨테이너 툴킷 설치\n\n```js\nsudo apt install nvidia-container-toolkit\n```\n\n2. 도커 서비스 재시작\n\n```js\nsudo systemctl restart docker\n```\n\n\n\n다음 명령은 GPU에 관한 정보를 출력해야 합니다:\n\n```js\ndocker run --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi\n```\n\n# 참조\n\n[1] https://github.com/CodeNLP/codenlp-docker-ml\n\n\n\n[2] [papluca/xlm-roberta-base-language-detection](https://huggingface.co/papluca/xlm-roberta-base-language-detection)\n\n[3] [protectai/xlm-roberta-base-language-detection-onnx](https://huggingface.co/protectai/xlm-roberta-base-language-detection-onnx)\n\n[4] [ONNX](https://onnx.ai/)\n\n[5] [Reducing Inference Time of T5 Models](https://medium.com/codenlp/reducing-inference-time-of-t5-models-76e996523fb2?sk=f02379f5a8363d2de73a332fcef55f78)","ogImage":{"url":"/assets/img/2024-05-15-ReducingtheSizeofDockerImagesServingLargeLanguageModelspart1_0.png"},"coverImage":"/assets/img/2024-05-15-ReducingtheSizeofDockerImagesServingLargeLanguageModelspart1_0.png","tag":["Tech"],"readingTime":6},{"title":"Kolmogorov-Arnold Networks KANs를 사용한 시계열 예측","description":"","date":"2024-05-15 11:39","slug":"2024-05-15-Kolmogorov-ArnoldNetworksKANsforTimeSeriesForecasting","content":"\n\n\n![링크](/assets/img/2024-05-15-Kolmogorov-ArnoldNetworksKANsforTimeSeriesForecasting_0.png)\n\n다층 퍼셉트론(MLP)은 딥러닝 모델의 기본적인 구조 중 하나입니다. 이는 N-BEATS, NHiTS 및 TSMixer와 같은 최신 예측 모델의 기본 구성 요소도 됩니다.\n\n2024년 4월 30일에 KAN: Kolmogorov-Arnold Network 논문이 발표되었으며, 많은 딥러닝 분야의 전문가들의 주목을 끌었습니다. 여기서 저자들은 MLP의 대안으로 콜모고로프-아놀드 네트워크 또는 KAN을 제안합니다.\n\n가중치와 고정 활성화 함수를 사용하는 대신, KAN은 스플라인으로 매개변수화 된 학습 가능한 함수를 사용합니다. 연구자들은 KAN이 MLP보다 더 적은 학습 가능한 매개변수로 더 정확할 수 있다고 제안합니다.\n\n\n\n\n이 글에서는 우리가 KAN의 아키텍쳐와 주요 요소를 이해하는 데 도움이 되는 스플라인에 대해 먼저 살펴보겠습니다. 그런 다음, 우리는 KAN의 내부 작동 방식을 자세히 살펴보겠습니다. 마지막으로, 우리는 KAN을 시계열 예측에 적용하고 표준 MLP 및 N-BEATS 모델과의 성능을 평가할 것입니다.\n\n더 자세한 내용은 KAN에 대한 원본 논문을 읽어보세요.\n\n시작해봅시다!\n\n# 스플라인 방문\n\n\n\n스플라인은 콜모고로프-아놀드 네트워크의 핵심이기 때문에 이를 이해하는 데 시간을 투자해봅시다.\n\n스플라인은 다항식으로 조각조각 나누어진 함수로 간단하게 정의됩니다. 이를 통해 우리는 고차 다항식을 사용하지 않고도 많은 데이터 포인트를 횡단하는 부드러운 선을 구축할 수 있습니다. 고차 다항식은 진동이 심하여 피하는 것이 좋습니다.\n\n다음 예시를 살펴보세요.\n\n![image](/assets/img/2024-05-15-Kolmogorov-ArnoldNetworksKANsforTimeSeriesForecasting_1.png)\n\n\n\n위 그림에서 볼 수 있듯이, 네 개의 데이터 포인트가 있습니다. 이들을 통해 선을 맞추고 싶다면 3차 다항식을 사용할 수 있습니다. 차수가 n인 다항식은 n+1개의 계수를 갖는다는 것을 기억해야 합니다. 따라서 좋은 적합을 위해 최소한 n+1개의 데이터 포인트가 필요합니다.\n\n우리는 이를 Excel에서 시도해볼 수 있습니다. 데이터에 트렌드 라인을 추가하고 3차 다항식을 지정해 보세요.\n\n![그림](/assets/img/2024-05-15-Kolmogorov-ArnoldNetworksKANsforTimeSeriesForecasting_2.png)\n\n보시다시피, 이 경우에 다항식을 적합시키는 것이 잘 작동합니다. 부드러운 곡선을 얻을 수 있습니다.\n\n\n\n그러나 더 많은 데이터 포인트가 있을 때 어떻게 될까요?\n\n이 경우, Excel은 6차 다항식으로 제한됩니다. 그래서 아래에 표시된 것처럼 일곱 개의 데이터 포인트를 통과하는 선을 맞추어 보겠습니다.\n\n![이미지](/assets/img/2024-05-15-Kolmogorov-ArnoldNetworksKANsforTimeSeriesForecasting_3.png)\n\n위 그림에서 처음 몇 점을 통해 맞는 것은 합리적이지만, 오른쪽 끝의 마지막 두 점에서 큰 진동이 발생합니다. 이것이 고차 다항식을 사용하는 문제입니다.\n\n\n\n현실에서 우리는 매우 큰 데이터셋을 다루기 때문에 점차적으로 커지는 다항식을 사용하는 것은 의미가 없어요. \n\n대신, 우리는 저차수 다항식을 각 부분 데이터 집합에 맞추어 데이터셋을 나눌 수 있어요.\n\n이 경우에는 7개의 데이터 포인트를 통과하는 단일 선을 맞추는 대신, 첫 네 개의 포인트에 3차 다항식을 맞추고, 마지막 네 개의 포인트에 다른 3차 다항식을 맞출 수 있어요. 각 세트가 최종적인 맞춤에 공백이 없도록 하기 위해 하나의 데이터 포인트를 공유한다는 점에 유의해주시면 좋겠어요.\n\n\u003cimg src=\"/assets/img/2024-05-15-Kolmogorov-ArnoldNetworksKANsforTimeSeriesForecasting_4.png\" /\u003e\n\n\n\n위의 그림에서, 우리는 적은 진동을 얻는 것을 볼 수 있습니다. 그러나 네 번째 데이터 포인트를 자세히 살펴보세요. 맞춘 선에 이상한 단절이 나타납니다. 이로 인해 부드러운 적합이 아닙니다.\n\n단절이 발생하는 지점을 노트라고 합니다. 곡선의 부자연스러움을 해결하기 위해 각 다항식의 도함수가 노트에서 동일해야 한다는 조건을 추가합니다.\n\n이것은 모든 데이터 포인트에서 부드러운 적합 곡선을 보장합니다. 더불어 임의의 데이터 포인트를 사용할 수 있도록 하기 위해 각 다항식의 두 번째 도함수에도 제약 조건을 설정하여 노트에서 두 번째 도함수도 동일하게 만듭니다.\n\n데이터를 하위 시퀀스로 분할하고 각 시퀀스에 낮은 차수의 다항식을 적합하며 노트에서 제약 조건이 준수되도록 하는 결과는 스플라인입니다. 만약 스플라인이 많은 3차 다항식으로 구성된다면, cubic 스플라인을 얻게 됩니다.\n\n\n\n위의 그림에서는 스플라인을 사용하여 데이터 포인트를 맞추는 결과를 볼 수 있습니다. 선이 부드럽고 이상한 진동이 없는 것을 볼 수 있으며 원하는만큼 많은 포인트를 사용할 수 있습니다.\n\nKAN의 경우, 기저 스플라인 또는 B-스플라인을 사용합니다.\n\n아이디어는 임의의 스플라인 함수가 B-스플라인의 선형 조합으로 표현될 수 있다는 것입니다. 더 중요한 것은 각 스플라인 함수가 B-스플라인의 고유한 조합을 가지고 있다는 것입니다.\n\n\n\n그 모든 것을 염두에 두고, KAN 아키텍처를 더 자세히 살펴보겠습니다.\n\n# 콜모고로프-아놀드 네트워크 탐색\n\n지금은 스플라인에 대한 보다 깊은 이해를 갖게 되었으니, 콜모고로프-아놀드 네트워크 아키텍처에 통합된 방식을 살펴보겠습니다.\n\n먼저, 말할 것도 없이 KAN은 콜모고로프-아놀드 표현 정리에 기초합니다. 이는 다변수 연속 함수를 단변수 함수와 덧셈 연산의 유한 조합으로 표현할 수 있다는 것을 확립합니다.\n\n\n\n간단히 말해, 다변수 함수는 여러 단변수 함수를 결합하는 것으로 요약됩니다.\n\n이 정리는 단변수 함수가 부드럽고 학습 가능한 경우에만 실용적인 가치를 갖습니다. 만약 그것들이 비부드러운 함수이거나 프랙탈 함수라면 학습할 수 없게 되어서 KAN이 쓸모가 없어집니다.\n\n다행히 대부분의 사용 사례는 부드러운 함수를 포함하고 있기 때문에, KAN은 MLP 대안으로 제안되고 있습니다.\n\n## KAN의 아키텍처\n\n\n\n그 후 연구자들은 다변수 함수를 표현하기 위해 단변수 함수를 학습하는 신경망을 구축했습니다.\n\n![KAN Architecture](/assets/img/2024-05-15-Kolmogorov-ArnoldNetworksKANsforTimeSeriesForecasting_6.png)\n\n위 그림에서 우리는 KAN의 구조와 MLP와 비교하는 방법을 볼 수 있습니다.\n\nKAN의 엣지(선으로 표시된)는 학습 가능한 단변수 함수로, B-스플라인으로 매개변수화됩니다. 그런 다음, 노드(점으로 표시된)에서는 합산이 수행됩니다.\n\n\n\nKolmogorov-Arnold 표현 정리가 신경망에서 작동 중이라는 것을 인식하는 데 시간을 갖는 것이 좋습니다. 여러 단변량 함수가 학습되고 결합되어 최종적으로 다른 프로세스를 표현하도록 합니다.\n\n또한, MLP 아키텍처와 대조되는 방법을 볼 수 있습니다. MLP에서 노드는 고정된 활성화 함수로 설정되어 있으며 일반적으로 ReLU와 같은 비선형 함수입니다. 그런 다음, MLP는 가중치를 학습할 수 있는 엣지를 가지고 있습니다.\n\n따라서 KAN과 MLP 간의 주요 차이점은 KAN에서 비선형 함수가 학습 가능하고 MLP에서는 고정되어 있다는 것입니다. 따라서 KAN은 입력 데이터로부터 더 적은 매개변수를 사용하여 학습할 수 있으며 함수가 입력 데이터에 따라 학습되고 조정되기 때문에 기술적으로 더 나은 결과를 얻을 수 있습니다.\n\n물론 더 크고 깊은 KAN을 사용하면 근사 및 일반화 능력이 향상되어 네트워크가 임의의 함수를 학습할 수 있습니다.\n\n\n\n이제 KAN을 더 깊게 만들면서도 매개변수를 효과적으로 유지하는 비결은 그리드 확장에 있습니다.\n\n## KAN에서의 그리드 확장\n\n그리드 확장은 KAN에서 각 B-스플라인 함수에 대해 모델의 정확도와 효율성을 높이는 방법으로 사용됩니다.\n\n![그리드 확장](/assets/img/2024-05-15-Kolmogorov-ArnoldNetworksKANsforTimeSeriesForecasting_7.png)\n\n\n\n위의 그림에서 KAN (왼쪽)에서 활성화 흐름과 각 스플라인에 적용된 그리드 확장 기술 (오른쪽)을 볼 수 있습니다.\n\n그리드 확장을 통해 스플라인 그리드의 세분화를 증가시켜 복잡한 함수의 더 나은 근사치를 얻을 수 있습니다. 이는 같은 영역 내에서 간격의 수를 증가시킴으로써 이루어집니다. 그림에서는 G1 = 5에서 G2 = 10으로 변화함으로써 이를 설명하고 있습니다.\n\n간격의 수를 증가시킴으로써 최종 스플라인 함수를 구성하는 조각의 수도 증가합니다. 이는 데이터에서 보다 세부적인 행동을 배울 수 있게 합니다.\n\n이 확장 기능은 MLP의 경우와 대조적입니다. MLP의 경우 더 복잡한 함수를 학습하기 위해 모델이 더 깊어져야 합니다. 그러나 KAN에서는 각 스플라인마다 이 작업을 수행하므로 더 복잡한 함수를 학습하기 위해서는 기술적으로 더 적은 층이 필요합니다.\n\n\n\n이제 우리는 KAN과 그 내부 작동에 대해 잘 이해했으니 파이썬을 사용하여 시계열 예측에 적용하는 방법을 살펴보겠습니다.\n\n# KAN으로 예측하기\n\n이 섹션에서는 파이썬을 사용하여 예측 작업에 KAN 아키텍처를 테스트합니다.\n\n본 문서 작성 시점에서 KAN은 매우 새로운 기술이므로, 내가 좋아하는 예측 라이브러리 neuralforecast를 이 Pytorch 기반의 KAN 구현으로 확장하였고 이를 시계열 예측에 적용했습니다.\n\n\n\n또한, KAN 모델이 neuralforecast의 안정적인 릴리스에서 사용할 수 없을 수도 있습니다. 결과를 재현하려면 다음을 수행할 수 있습니다:\n\n- neuralforecast 저장소를 복제하고 이 브랜치에서 작업\n- 또는 브랜치가 병합된 경우 다음을 실행할 수 있습니다.\n\n```js\npip install git+https://github.com/Nixtla/neuralforecast.git\n```\n\n지금 이 실험에서는 Creative Commons Attribution 4.0 라이선스를 통해 제공된 월간 M3 데이터셋에 KAN 모델을 테스트합니다.\n\n\n\n이 데이터셋은 다양한 도메인에서 나온 월별 주기를 가진 1428개의 고유한 시계열을 포함하고 있습니다.\n\nKAN의 성능은 간단한 MLP와 N-BEATS 모델과 비교될 것입니다.\n\n이러한 결과를 재현하는 모든 코드는 GitHub에서 확인할 수 있습니다.\n\n시작해봅시다!\n\n\n\n## 초기 설정\n\n우리는 이 실험에 필요한 패키지들을 import하여 시작합니다.\n\n```js\nimport pandas as pd\n\nfrom datasetsforecast.m3 import M3\n\nfrom utilsforecast.losses import mae, smape\nfrom utilsforecast.evaluation import evaluate\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import KAN, MLP, NBEATS\n```\n\n우리는 neuralforecast와 호환성 있는 형식으로 월간 M3 데이터셋을 불러오기 위해 datasetsforecast 라이브러리를 사용합니다.\n\n\n\n```js\nY_df, *_ = M3.load(\"./data\", \"Monthly\")\n```\n\n그런 다음 데이터셋 사양에 지정된 대로 18의 예측 기간을 사용합니다. 따라서 마지막 18 개의 시간 단계를 테스트 세트로 예약하고 나머지 데이터를 학습에 사용합니다.\n\n```js\nhorizon = 18\n\ntest_df = Y_df.groupby('unique_id').tail(horizon)\ntrain_df = Y_df.drop(test_df.index).reset_index(drop=True)\n```\n\n좋아요! 이 단계에서는 학습 및 테스트 세트가 준비되었으므로 모델을 적합할 준비가 되었습니다.\n\n\n\n## 모델 맞추기\n\n모델을 맞추기 위해, 우리는 훈련시키고자 하는 모든 모델들의 목록을 간단히 정의합니다. 여기서는 기본 설정을 유지합니다. 기본 KAN과 MLP는 입력 레이어, 은닉 레이어, 출력 레이어로 이루어진 세 개의 레이어만 가지고 있음을 유의해 주세요.\n\n또한 1000번의 훈련 단계로 설정하고, 인내심을 3으로 설정했습니다. 이는 검증 손실이 세 번의 확인 후에도 개선되지 않으면 모델이 훈련을 멈출 것임을 의미합니다.\n\n```js\nmodels = [\n    KAN(input_size=2*horizon,\n        h=horizon,\n        scaler_type='robust',\n        max_steps=1000,\n        early_stop_patience_steps=3),\n    MLP(input_size=2*horizon,\n        h=horizon,\n        scaler_type='robust',\n        max_steps=1000,\n        early_stop_patience_steps=3),\n    NBEATS(input_size=2*horizon,\n           h=horizon,\n           scaler_type='robust',\n           max_steps=1000,\n           early_stop_patience_steps=3)\n]\n```\n\n\n\n대박! 이제 데이터를 처리하고 모델을 맞추는 NeuralForecast의 인스턴스를 만듭니다. 그런 다음 fit 메소드를 호출하여 각 모델을 훈련시킵니다.\n\n```js\nnf = NeuralForecast(models=models, freq='M')\n\nnf.fit(train_df, val_size=horizon)\n```\n\n훈련이 완료되면 예측을 수행하고 각 모델의 성능을 평가할 수 있습니다.\n\n## 평가\n\n\n\n이제 적합된 모델을 활용하여 예측을 수행할 수 있고, 해당 값들을 테스트 세트에 저장된 실제 값과 비교할 수 있습니다.\n\n```js\npreds = nf.predict()\n\npreds = preds.reset_index()\n\ntest_df = pd.merge(test_df, preds, 'left', ['ds', 'unique_id'])\n```\n\n우리의 모델을 평가하기 위해 평균 절대 오차(MAE)와 대칭 평균 절대 백분율 오차(sMAPE)를 사용합니다.\n\n이 부분에서는 예측 모델을 평가하는 많은 메트릭과 유틸리티 함수를 편리하게 제공하는 utilsforecast 라이브러리를 사용합니다.\n\n\n\n```js\n평가 = evaluate(\n    test_df,\n    metrics=[mae, smape],\n    models=[\"KAN\", \"MLP\", \"NBEATS\"],\n    target_col=\"y\",\n)\n\n평가 = 평가.drop(['unique_id'], axis=1).groupby('metric').mean().reset_index()\n평가\n```\n\n위의 코드 블록은 아래에 표시된 결과를 출력합니다.\n\n\u003cimg src=\"/assets/img/2024-05-15-Kolmogorov-ArnoldNetworksKANsforTimeSeriesForecasting_8.png\" /\u003e\n\n위의 표에서 KAN이 아주 간단한 MLP과 비교하여 최악의 성능을 달성하는 것을 볼 수 있습니다. 예상대로, N-BEATS는 MAE가 637, sMAPE가 7.1%로 최상의 성능을 달성했습니다.\n\n\n\nKAN의 성능이 그리 눈에 띄지는 않지만, 알아두세요. KAN은 학습 가능한 매개변수가 272k로 MLP(1.1M)와 N-BEATS(2.2M)에 비해 적습니다. MLP에 비해 매개변수 수를 75% 줄인 것이죠. 그럼에도 불구하고, 이 시나리오에서 그 성능은 실망스럽습니다.\n\n## 시계열 예측을 위한 KAN의 벤치마킹\n\n위 실험은 전체 M3 데이터셋뿐만 아니라 M4 데이터셋에도 손쉽게 확장할 수 있습니다. 두 데이터셋 모두 Creative Commons Attribution 4.0 라이선스로 제공됩니다.\n\n아래에서 벤치마킹 결과가 표시됩니다. 최고의 성능은 굵게, 두 번째로 좋은 성능은 밑줄로 표시되어 있습니다.\n\n\n\n\u003cimg src=\"/assets/img/2024-05-15-Kolmogorov-ArnoldNetworksKANsforTimeSeriesForecasting_9.png\" /\u003e\n\n위 표를 보면 KAN이 종종 최악의 예측 모델이라는 것을 알 수 있습니다. 일반적으로 간단한 MLP보다 성능이 낮습니다. KAN은 주간 M4 데이터셋에서 MLP보다 우수한 성과를 보이며, 시간당 M4 데이터셋에서 가장 우수한 성과를 내고 있음을 알 수 있습니다. 또한 KAN이 벤치마크에서 가장 느린 모델임을 주목해 주세요.\n\n모든 예측 작업에 대해 KAN은 실제로 MLP 또는 N-BEATS보다 매개변수 효율적이지만 성능은 실망스럽습니다.\n\n# KAN에 대한 내 의견\n\n\n\nKAN 아키텍처는 많은 관심을 끌고 있고 해당 모델을 중심으로 큰 홍보가 진행되고 있습니다. 그러나 예측 작업에 적용할 경우 상당히 부정적인 결과가 나왔습니다.\n\nMLP도 예측 모델로는 그리 좋지 않다는 점은 예상했습니다. KAN은 MLP의 대체제로 제안되었기 때문입니다.\n\n논문의 저자들은 MLP 대비 성능이 향상된다고 주장하지만, 시계열 예측에 적용했을 때는 그러한 성과가 나타나지 않았습니다.\n\n제 생각에 진정한 잠재력은 MLP 유닛을 N-BEATS나 NHiTS와 같이 고급 시계열 예측 모델에서 KAN으로 대체하는 데 있다고 생각합니다. 결국 시계열 예측은 어려운 작업이며, KAN이나 MLP와 같은 모델은 스스로만으로는 성능이 충분하지 않습니다.\n\n\n\n그러나 KAN 기반의 N-BEATS 또는 NHiTS를 사용하면 가벼워지고 더 빠르며 더 나은 예측이 가능할 수 있습니다. 이를 곧 테스트되길 희망합니다.\n\n# 결론\n\nKolmogorov-Arnold 네트워크(KAN)는 딥러닝에서 근본적인 다층 퍼셉트론(MLP) 대체로 제시됩니다.\n\n이는 Kolmogorov-Arnold 표현 정리를 적용하여 다변수 함수가 일변수 함수의 조합으로 표현될 수 있다고 설명하고 있습니다.\n\n\n\nKAN에서는 단변량 함수들이 B-스플라인으로 학습되고 매개변수화됩니다. MLP가 고정된 비선형 활성화 함수를 사용하는 것과는 달리, 스플라인은 학습되어 훈련 데이터에 맞게 조정될 수 있는 비선형 함수입니다.\n\n이는 KAN이 MLP보다 매개변수를 효율적으로 사용할 수 있게 하며 이론적으로 더 나은 성능을 달성할 수 있다는 것을 의미합니다.\n\n그러나 KAN을 시계열 예측에 적용한 결과, 모델이 매우 간단한 MLP보다 성능이 부족한 경우가 많았습니다.\n\n그 잠재력은 아마 MLP를 N-BEATS나 NHiTS와 같은 더 정립된 예측 모델로 대체하는 데 있을 것으로 예상됩니다.\n\n\n\nKAN은 아주 새로운 기술이지만, 여전히 딥 러닝 분야에서 흥미로운 진전을 보여줍니다.\n\n읽어 주셔서 감사합니다! 즐겁게 읽으셨기를 바라며 무언가 새로운 것을 배우셨으면 좋겠어요!\n\n건배 🍻\n\n# 제게 응원을 해주세요\n\n\n\n제 일에 만족하고 계신가요? 지지를 표현해보세요. 'Buy me a coffee'는 저를 격려하는 간단한 방법입니다. 한 잔의 커피를 마실 수 있고, 여러분도 응원할 수 있어요! 응원하고 싶다면 아래 버튼을 클릭해주세요 👇\n\n![KAN: Kolmogorov–Arnold Networks by Ziming Liu1, Yixuan Wang Sachin Vaidya Fabian Ruehle, James Halverson, Marin Soljačić, Thomas Y. Hou, Max Tegmark](/assets/img/2024-05-15-Kolmogorov-ArnoldNetworksKANsforTimeSeriesForecasting_10.png)\n\n# 참고문헌\n\nKAN: Kolmogorov–Arnold Networks 저자: Ziming Liu1, Yixuan Wang Sachin Vaidya Fabian Ruehle, James Halverson, Marin Soljačić, Thomas Y. Hou, Max Tegmark\n\n\n\nGitHub에 Kolmogorov-Arnold network의 효율적인 구현이 있어요!","ogImage":{"url":"/assets/img/2024-05-15-Kolmogorov-ArnoldNetworksKANsforTimeSeriesForecasting_0.png"},"coverImage":"/assets/img/2024-05-15-Kolmogorov-ArnoldNetworksKANsforTimeSeriesForecasting_0.png","tag":["Tech"],"readingTime":11},{"title":"GPT-4 대 GPT-4 대 Gemini 15   성능 분석","description":"","date":"2024-05-15 11:37","slug":"2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis","content":"\n\n## 오픈에이아이(OpenAI)의 새로운 프래그십 모델의 영어 언어 이해 능력 측정\n\n![이미지](/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_0.png)\n\n오픈에이아이의 GPT-4o 최근 공개로 인공지능 언어 모델과 그들과의 상호작용에 새로운 시대가 열렸습니다.\n\n가장 인상적인 부분은 대화 중단과 함께 ChatGPT와의 실시간 상호작용을 지원하는 것이었습니다.\n\n\n\n실시간 데모 중 일부 키크는 사건이 있었지만, 팀이 이룬 성과에 놀랍지 않을 수가 없어요.\n\n더 좋은 소식은, 데모 직후 OpenAI가 GPT-4o API에 접속 권한을 부여했어요.\n\n본 기사에서는, 제가 만든 영어 데이터셋을 사용해 GPT-4o 대 GPT-4 대 Google의 Gemini 및 Unicorn 모델의 분류 능력을 측정한 독립적인 분석을 제시할 거에요.\n\n이 모델 중 어떤 것이 영어 이해력에서 가장 강한지 알아볼까요?\n\n\n\n![image](/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_1.png)\n\n# GPT-4o에 대한 새로운 소식\n\n제일 먼저 소개하는 것은 OmnI 모델 개념으로, 텍스트, 오디오, 비디오를 매끄럽게 이해하고 처리하도록 설계되었습니다.\n\nOpenAI의 초점은 GPT-4 수준의 지능을 대중들에게 민주화 하는 방향으로 바뀌어, GPT-4 수준의 언어 모델 지능을 무료 사용자에게도 접근 가능하게 만드는 것을 중심으로 이루어지는 것으로 보입니다.\n\n\n\nOpenAI가 GPT-4o에 향상된 품질과 속도로 50개 이상의 언어에 대해 더 포괄적이고 전 세계적으로 접근 가능한 AI 경험을 제공한다고 발표했습니다. 더 저렴한 가격으로!\n\n그들은 또한 유료 구독자들이 비유료 사용자들과 비교하여 5배 용량을 제공받게 될 것이라고 언급했습니다.\n\n게다가 대중을 위해 오디오, 비전, 텍스트 인터페이스를 통해 실시간 추론을 용이하게 하는 ChatGPT의 데스크톱 버전을 출시할 예정입니다.\n\n# GPT-4o API 사용 방법\n\n\n\n새로운 GPT-4o 모델은 OpenAI의 기존 채팅 완성 API를 따르며, 역호환성을 유지하고 사용하기 간단합니다.\n\n```js\nfrom openai import AsyncOpenAI\n\n\nOPENAI_API_KEY = \"\u003cyour-api-key\u003e\"\n\n\ndef openai_chat_resolve(response: dict, strip_tokens = None) -\u003e str:\n    if strip_tokens is None:\n        strip_tokens = []\n    if response and response.choices and len(response.choices) \u003e 0:\n        content = response.choices[0].message.content.strip()\n        if content is not None or content != '':\n            if strip_tokens:\n                for token in strip_tokens:\n                    content = content.replace(token, '')\n            return content\n    raise Exception(f'응답을 해결할 수 없습니다: {response}')\n\n\nasync def openai_chat_request(prompt: str, model_nane: str, temperature=0.0):\n    message = {'role': 'user', 'content': prompt}\n    client = AsyncOpenAI(api_key=OPENAI_API_KEY)\n    return await client.chat.completions.create(\n        model=model_nane,\n        messages=[message],\n        temperature=temperature,\n    )\n\n\nopenai_chat_request(prompt=\"안녕하세요!\", model_nane=\"gpt-4o-2024–05–13\")\n```\n\nGPT-4o는 ChatGPT 인터페이스를 통해도 이용 가능합니다:\n\n\u003cimg src=\"/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_2.png\" /\u003e\n\n\n\n# 공식 평가\n\nOpenAI의 블로그 게시물에는 MMLU 및 HumanEval과 같은 알려진 데이터셋의 평가 점수가 포함되어 있습니다.\n\n![그래프](/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_3.png)\n\n그래프에서 확인할 수 있듯이, GPT-4o의 성능은 이 분야에서 최첨단으로 분류될 수 있으며 — 새로운 모델이 더 저렴하고 빠르다는 것을 고려하면 매우 유망하게 들립니다.\n\n\n\n지난 해 동안 여러 모델들을 보았는데, State-of-the-art 언어 성능을 주장하는 모델들이 많았어요. 하지만 실제로는 이러한 모델들 중 일부가 이러한 공개 데이터셋에서 부분적으로 학습되었거나 (또는 오버핏팅)하여 리더보드에서 현실적이지 않은 점수를 보여주기도 했어요.\n\n그러므로, 이러한 모델들의 성능을 독립적으로 분석하고, 제가 만든 데이터셋과 같은 잘 알려지지 않은 데이터셋을 사용하여 성능을 평가하는 것이 중요합니다 😄\n\n# 제 평가 데이터셋 🔢\n\n이전 글에서 설명했듯이, 저는 다양한 LLMs를 통해 분류 성능을 측정할 수 있는 토픽 데이터셋을 만들었어요.\n\n\n\n데이터셋은 50가지 주제로 분류된 200개의 문장으로 구성되어 있습니다. 일부는 분류 작업을 더 어렵게 만들기 위해 밀접하게 관련되어 있습니다.\n\n전체 데이터셋은 저가 수작업으로 영어로 작성하고 레이블을 지정했습니다.\n\n그런 다음 GPT4 (gpt-4-0613)를 사용하여 데이터셋을 여러 언어로 번역했습니다.\n\n그러나 이 평가 중에는 데이터셋의 영어 버전만 평가할 것이며, 데이터셋 생성과 주제 예측에 동일한 언어 모델을 사용함으로 인해 발생할 수 있는 잠재적인 편향으로 인해 결과에 영향을 미치지 않아야 합니다.\n\n\n\n지금 당장 데이터셋을 확인해보세요: 주제 데이터셋.\n\n# 성능 결과 📊\n\n다음 모델들을 평가하기로 결정했어요:\n\n- GPT-4o: gpt-4o-2024–05–13\n- GPT-4: gpt-4–0613\n- GPT-4-Turbo: gpt-4-turbo-2024–04–09\n- Gemini 1.5 Pro: gemini-1.5-pro-preview-0409\n- Gemini 1.0: gemini-1.0-pro-002\n- Palm 2 Unicorn: text-unicorn@001\n\n\n\n언어 모델에 주어진 작업은 데이터셋의 각 문장을 올바른 주제와 일치시키는 것입니다. 이를 통해 각 언어와 각 모델의 정확도 점수 및 오류율을 계산할 수 있습니다.\n\n대부분의 모델이 올바르게 분류되기 때문에 각 모델의 오류율을 그래프로 플로팅하고 있습니다.\n\n낮은 오류율은 더 나은 모델 성능을 나타냅니다.\n\n그래프에서 볼 수 있듯이, GPT-4o는 모든 모델 중에서 가장 낮은 오류율을 보여 2개의 실수만 발생했습니다.\n\n\n\nGPT-4, Gemini 1.5, and Palm 2 Unicorn는 GPT-4o보다 한 가지 더 실수가 있었음을 알 수도 있습니다. 이들은 강력한 성능을 보여주고 있습니다. 흥미로운 점은 GPT-4 Turbo가 GPT-4-0613보다 약간 성능이 떨어진다는 것인데, 이는 OpenAI가 모델 페이지에 작성한 내용과는 다른 결과입니다.\n\n마지막으로, Gemini 1.0은 가격대를 고려하면 예상대로 다소 뒤처지고 있습니다.\n\n# 결론 💡\n\n이 독특한 영어 데이터셋을 활용한 이 분석은 이러한 고급 언어 모델의 최첨단 능력에 대한 통찰을 제공합니다.\n\n\n\nGPT-4, OpenAI의 최신 모델은 테스트된 모델 중에서 가장 낮은 오류율로 놀랍습니다. 이는 OpenAI가 성능에 관한 주장을 확증합니다.\n\n인공지능 커뮤니티와 사용자들은 서로 독립적인 평가를 계속해야 합니다. 이를 통해 표준화된 벤치마킹만으로는 실용적인 효과를 제공하는 모델에 대해 더 명확한 그림을 제시할 수 있습니다.\n\n데이터셋이 상당히 작기 때문에 결과는 데이터셋에 따라 달라질 수 있습니다. 성능은 영어 데이터셋만을 사용했으며, 다국어 비교는 다음 기회를 기다려야 할 것입니다.\n\n읽어 주셔서 감사합니다!\n\n\n\n향후 유사한 콘텐츠를 받으려면 팔로우하세요!\n\n문의 사항이 있으시면 언제든지 연락해주세요!","ogImage":{"url":"/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_0.png"},"coverImage":"/assets/img/2024-05-15-GPT-4ovsGPT-4vsGemini15PerformanceAnalysis_0.png","tag":["Tech"],"readingTime":5}],"page":"89","totalPageCount":151,"totalPageGroupCount":8,"lastPageGroup":20,"currentPageGroup":4},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"89"},"buildId":"t9N7vwmpvBMQnO2PSctoH","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>