<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>allround-coder</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://allround-coder.github.io///posts/73" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="allround-coder" data-gatsby-head="true"/><meta property="og:title" content="allround-coder" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://allround-coder.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://allround-coder.github.io///posts/73" data-gatsby-head="true"/><meta name="twitter:title" content="allround-coder" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | allround-coder" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZFDEQ947R4"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
  
            gtag('config', 'G-ZFDEQ947R4');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-ec7535a55e788b31.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/Y-fCAg8BUV7y2HNFwX9AA/_buildManifest.js" defer=""></script><script src="/_next/static/Y-fCAg8BUV7y2HNFwX9AA/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Allround Coder</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="Angular에서 간단한 코드로 SCSS를 활용해 트리 계층구조를 만드는 방법" href="/post/2024-05-17-Howtomakesimpletreehierarchyinangularusingscsswithsimplecoding"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Angular에서 간단한 코드로 SCSS를 활용해 트리 계층구조를 만드는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-Howtomakesimpletreehierarchyinangularusingscsswithsimplecoding_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Angular에서 간단한 코드로 SCSS를 활용해 트리 계층구조를 만드는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">Angular에서 간단한 코드로 SCSS를 활용해 트리 계층구조를 만드는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Reactime v25, 개발자 도구를 더욱 잘 활용하는 방법" href="/post/2024-05-17-Reactimev25Thetimetoreactisnow"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Reactime v25, 개발자 도구를 더욱 잘 활용하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-Reactimev25Thetimetoreactisnow_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Reactime v25, 개발자 도구를 더욱 잘 활용하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">Reactime v25, 개발자 도구를 더욱 잘 활용하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="VsCode에 React 앱을 설치하는 방법(2024년 최신)" href="/post/2024-05-17-HowtoInstallReactAppInVsCode2024"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="VsCode에 React 앱을 설치하는 방법(2024년 최신)" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-HowtoInstallReactAppInVsCode2024_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="VsCode에 React 앱을 설치하는 방법(2024년 최신)" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">VsCode에 React 앱을 설치하는 방법(2024년 최신)</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="React Native 페이지 최적화 방법 정리(2024년 최신)" href="/post/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="React Native 페이지 최적화 방법 정리(2024년 최신)" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="React Native 페이지 최적화 방법 정리(2024년 최신)" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">React Native 페이지 최적화 방법 정리(2024년 최신)</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">20<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Vite, Nginx 및 런타임에서 정적 웹 사이트용 환경 변수 적용하는 방법" href="/post/2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Vite, Nginx 및 런타임에서 정적 웹 사이트용 환경 변수 적용하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Vite, Nginx 및 런타임에서 정적 웹 사이트용 환경 변수 적용하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">Vite, Nginx 및 런타임에서 정적 웹 사이트용 환경 변수 적용하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="대형 언어 모델LLM을 활용한 웹 어플리케이션 만드는 방법" href="/post/2024-05-17-BuildingaWebApplicationPoweredbyLargeLanguageModelsLLMpart2"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="대형 언어 모델LLM을 활용한 웹 어플리케이션 만드는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-BuildingaWebApplicationPoweredbyLargeLanguageModelsLLMpart2_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="대형 언어 모델LLM을 활용한 웹 어플리케이션 만드는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">대형 언어 모델LLM을 활용한 웹 어플리케이션 만드는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="통계적 파워와 파워 분석 개요" href="/post/2024-05-17-APrimeronStatisticalPowerandPowerAnalysis"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="통계적 파워와 파워 분석 개요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-APrimeronStatisticalPowerandPowerAnalysis_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="통계적 파워와 파워 분석 개요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">통계적 파워와 파워 분석 개요</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="새로운 langchain_huggingface 라이브러리 만들면서 배우기" href="/post/2024-05-17-ExploringtheNewlangchain_huggingfacelibraryAHands-OnExperiment"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="새로운 langchain_huggingface 라이브러리 만들면서 배우기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-ExploringtheNewlangchain_huggingfacelibraryAHands-OnExperiment_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="새로운 langchain_huggingface 라이브러리 만들면서 배우기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">새로운 langchain_huggingface 라이브러리 만들면서 배우기</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="CodeLlama vs CodeGemma, AI 코딩 어시스턴스에 오픈 모델 활용하기" href="/post/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="CodeLlama vs CodeGemma, AI 코딩 어시스턴스에 오픈 모델 활용하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="CodeLlama vs CodeGemma, AI 코딩 어시스턴스에 오픈 모델 활용하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">CodeLlama vs CodeGemma, AI 코딩 어시스턴스에 오픈 모델 활용하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">14<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="대기 시간을 통해의 신비로운 여행" href="/post/2024-05-17-AWhimsicalJourneyThroughWaitTimes"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="대기 시간을 통해의 신비로운 여행" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="대기 시간을 통해의 신비로운 여행" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">대기 시간을 통해의 신비로운 여행</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">20<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/61">61</a><a class="link" href="/posts/62">62</a><a class="link" href="/posts/63">63</a><a class="link" href="/posts/64">64</a><a class="link" href="/posts/65">65</a><a class="link" href="/posts/66">66</a><a class="link" href="/posts/67">67</a><a class="link" href="/posts/68">68</a><a class="link" href="/posts/69">69</a><a class="link" href="/posts/70">70</a><a class="link" href="/posts/71">71</a><a class="link" href="/posts/72">72</a><a class="link posts_-active__YVJEi" href="/posts/73">73</a><a class="link" href="/posts/74">74</a><a class="link" href="/posts/75">75</a><a class="link" href="/posts/76">76</a><a class="link" href="/posts/77">77</a><a class="link" href="/posts/78">78</a><a class="link" href="/posts/79">79</a><a class="link" href="/posts/80">80</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"Angular에서 간단한 코드로 SCSS를 활용해 트리 계층구조를 만드는 방법","description":"","date":"2024-05-17 20:59","slug":"2024-05-17-Howtomakesimpletreehierarchyinangularusingscsswithsimplecoding","content":"\n\n\n![Tree Hierarchy Example](/assets/img/2024-05-17-Howtomakesimpletreehierarchyinangularusingscsswithsimplecoding_0.png)\n\n한 가지 문자열 배열이 있다고 가정해봅시다. 만약 우리가 문자열 배열을 트리 구조로 그리고 싶다면, 어떻게 할 수 있을까요? 함께 살펴보겠습니다.\n\n![Tree Hierarchy Example](/assets/img/2024-05-17-Howtomakesimpletreehierarchyinangularusingscsswithsimplecoding_1.png)\n\n# 단계 1:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n샘플 Angular 애플리케이션을 cmd를 사용하여 생성합니다.\n\n# 단계 2:\n\ntreeData 배열을 생성하고 기본값으로 초기화합니다.\n\n```js\n//app.component.ts\n\nimport { Component } from '@angular/core';\n\n@Component({\n  selector: 'my-app',\n  templateUrl: './app.component.html',\n  styleUrls: ['./app.component.scss'],\n})\nexport class AppComponent {\n\n  treeData:string[];\n\n  constructor() {\n    this.treeData = [\n      'Root',\n      'Node1',\n      'Node2',\n      'Node3'\n    ];\n  }\n\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 단계 3:\n\nSCSS 파일에 믹스인 함수를 만드세요.\n\n```scss\n//app.component.scss\n\n@mixin generate($prefix, $property, $length) {\n  $spacing: 20px;\n  @for $i from 1 through $length {\n    .#{$prefix}-#{$i} {\n      #{$property}: $spacing * $i;\n    }\n  }\n}\n \n@include generate(li, margin-left, 20);\n```\n\n믹스인을 사용하면 스타일을 정의하고 스타일 시트 전체에서 재사용할 수 있습니다. 이를 통해 .float-left와 같은 의미 없는 클래스를 사용하는 것을 피하고 스타일 모음을 라이브러리로 분배하는 것이 쉬워집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n자세히 보기: https://sass-lang.com/documentation/at-rules/mixin/\n\n`generate()` 함수는 주어진 접두사, 속성 및 길이로 여러 클래스를 생성하는 데 사용됩니다. 'li', 'margin-left', '20'을 전달하면 다음과 같은 클래스가 생성됩니다.\n\n```js\n.li-1 {\n  margin-left: 20px;\n}\n\n.li-2 {\n  margin-left: 40px;\n}\n\n.li-3 {\n  margin-left: 60px;\n}\n...\n...\n...\n.li-20 {\n  margin-left: 400px;\n}\n```\n\n이 클래스를 사용하여 각 반복에서 왼쪽 마진을 증가시킵니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 단계 4:\n\n`ul` 및 `li` 태그를 사용하여 HTML 파일에 목록을 만들고 `li` 태그에 *ngFor를 추가합니다.\n\n```js\n\u003cul\u003e\n  \u003cli *ngFor=\"let data of treeData;index as i\" [ngClass]=\"'li-'+i\"\u003e\n    {data}\n  \u003c/li\u003e\n\u003c/ul\u003e\n```\n\n여기서 `[ngClass]=”’li-’+i”`를 추가했습니다. 각 반복마다 동적으로 생성된 클래스를 사용한다는 의미입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n[ngClass]=\"'li-1'\"\n[ngClass]=\"'li-2'\"\n[ngClass]=\"'li-3'\"\n[ngClass]=\"'li-4'\"\n....\n....\n[ngClass]=\"'li-20'\"\n\n# Step 5:\n\n코드를 실행하고 즐기세요!\n\n코딩을 즐기세요!!!\n","ogImage":{"url":"/assets/img/2024-05-17-Howtomakesimpletreehierarchyinangularusingscsswithsimplecoding_0.png"},"coverImage":"/assets/img/2024-05-17-Howtomakesimpletreehierarchyinangularusingscsswithsimplecoding_0.png","tag":["Tech"],"readingTime":3},{"title":"Reactime v25, 개발자 도구를 더욱 잘 활용하는 방법","description":"","date":"2024-05-17 20:58","slug":"2024-05-17-Reactimev25Thetimetoreactisnow","content":"\n\n강력한 개발자 도구가 더욱 강력하고 직관적으로 업그레이드되었습니다.\n\n공동 저술자: Haider Ali, Mel Koppens, Jose Luis Sanchez\n\nReactime이란?\n\nReact는 여전히 최고입니다! React는 2023년에 가장 인기 있는 자바스크립트 프론트엔드 프레임워크였으며 어떤 언어의 프론트엔드 프레임워크 중 가장 많이 사용되는 프레임워크 중 하나입니다. 그러나 혁신을 위한 여지는 항상 존재합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n큰 복잡한 코드베이스를 다룰 때 문제가 생길 수 있습니다 — React는 대화식이고 확장 가능한 애플리케이션을 만들 때 보편적으로 사용되는 점을 고려할 때 매우 중요합니다. React 개발자들은 컴포넌트 아키텍처, 상태, 그리고 프로그래밍 중 불가피하게 발생하는 버그들을 고려해야 합니다. Reactime은 이러한 난관을 완화하는 데 도움이 되어서 무엇이 일어나고 있는지 빠르게 확인하고 효과적으로 빌드할 수 있도록 돕습니다.\n\n간단히 말해서, Reactime은 React 애플리케이션을 위해 설계된 오픈 소스 타임 트래블 디버깅 도구입니다. 이 도구는 컴포넌트 트리의 동적 그래픽 표현, 컴포넌트 상태(현재 및 이력), 다양한 메트릭 등을 포함하여 많은 기능을 제공합니다. 이러한 기능들은 숙련된 개발자들에게 훌륭한 도구로 만들어주며, 새로운 개발자들이 React를 배우는 데 훌륭한 도구로 만드는 새로워진 UI도 제공합니다!\n\n버전 25.0을 소개합니다!\n\n![Reactime](https://miro.medium.com/v2/resize:fit:1400/1*mWtM2Ad_D4rwpHggQv3JYQ.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프롭 드릴링 시각화\n\nReactime 앱의 컴포넌트 맵 디스플레이는 가장 눈에 띄는 기능 중 하나일 수 있습니다. 이는 사용자가 React 앱의 모든 컴포넌트가 어떻게 서로 연결되고 흐르는지를 볼 수 있게 합니다. Reactime 버전 25.0은 이 직관적인 그래픽 사용자 인터페이스를 확장하여 컴포넌트 간에 어떻게 프롭이 전달되는지를 보여줍니다. 부모와 자식 노드를 연결하는 링크의 색상으로 전달된 프롭의 존재와 양을 나타냅니다. 회색 링크 대신에 프롭을 전달하는 링크는 낮은 프롭부터 높은 프롭까지의 범위인 노랑에서 마룬까지의 색상을 가지고 있습니다. 또한 굵은 글씨는 외관을 통합하면서 요소 간에 흐르는 프롭의 양을 직관적으로 나타내어 깔끔한 모습을 유지합니다.\n\n![Reactimev25](/assets/img/2024-05-17-Reactimev25Thetimetoreactisnow_0.png)\n\n개선된 UI: 더 적은 혼잡, 더 많은 사용성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 개발자 도구에 포함된 다양한 개별 도구들은 훌륭하지만, 너무 많은 도구들은 UI를 혼란스럽게 만들고 앱을 탐색하기 어렵게 만들 수 있습니다. 이를 해결하기 위해, 우리는 최상위 컨테이너에서 비탐색 구성 요소를 제거하여 탐색 허브로 변형하고 다른 모든 탐색 버튼을 이동시켰어요. 아, 그리고 우리는 현대적인 스타일도 적용했어요. 이제 Reactime을 사용하는 방법에 대해 고민하는 시간을 줄이고 실제로 사용하는 시간을 늘릴 수 있어요. 추가로, 주 컨테이너는 React fiber tree(또는 해당 컨테이너 내에 표시되는 다른 도구들)에 더 많은 공간을 제공합니다.\n\n![이미지](/assets/img/2024-05-17-Reactimev25Thetimetoreactisnow_1.png)\n\n버그 수정: 이제 더 부드러워요\n\n이전 버전의 Reactime Chrome 확장 프로그램은 가끔 시작할 때 문제를 발생시켜 Chrome 브라우저가 오랫동안 활성화되어 있으면 작동을 중단할 수 있었습니다. 이 문제를 해결하기 위해, 저희 팀은 Chrome API의 비동기성을 처리하기 위한 개선을 구현하여, 브라우저가 오랫동안 활성화되어 있으면 더 부드럽게 작동하도록 보장했어요. 주된 문제는 활성 탭의 속성에 액세스를 시도하기 전에 어떤 탭이 활성인지 확인하지 않았다는 것이었어요. 이 문제는 Chrome API의 비동기적 특성을 부적절하게 처리하여 발생했죠. 이를 해결하기 위해, background.js 파일의 코드를 다시 구성하여 비동기 작업을 올바르게 처리했어요. 이를 위해, 내용 스크립트를 삽입하기 전에 활성 탭을 쿼리하는 로직을 추가하여, 확실한 컨텍스트에서 이동하기 전에 확장 프로그램이 올바른 컨텍스트를 갖도록 했어요. 추가로, 활성 탭이 무엇인지 계속 확인하고 확증하기 위한 구독 서비스가 구현되었어요. 이 접근 방식은 더 많은 리소스를 소비하지만, 브라우저가 오랫동안 활성화되어 있을 때 확장 프로그램이 작동 중단되지 않도록 보장합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이러한 개선으로 중요한 긍정적 결과가 나타났습니다. 시작 대기 시간이 약 10초에서 2초 미만으로 줄어 들었습니다. 이전에 8회 중 4회 발생했던 시작 실패는 수정 후 테스트된 5건에서 모두 제거되었습니다. 더불어, 확장 기능이 작동을 중지하기 전의 최대 유휴 시간이 22분에서 테스트된 최대 기간인 3일로 증가했습니다.\n\nChrome API의 비동기 처리를 해결하고 활성 탭을 추적하는 강력한 메커니즘을 구현함으로써 Reactime 확장의 신뢰성과 성능이 크게 향상되었습니다. 이러한 개선으로, 브라우저가 장기간 유휴 상태에 있더라도 개발자가 가로막힘 없이 작업을 수행할 수 있게 되었습니다.\n\n테스트\n\n오픈 소스 프로젝트를 유지하기 위해서는 미래 기여자가 계속해서 발전시킬 수 있도록 유지 가능해야 합니다. 소프트웨어 테스트는 결함을 감지하고 품질과 성능을 향상시키는 중요한 도구입니다. 이에 우리는 테스트의 타당성을 높이는 데 크게 투자했습니다. 결과는 65%의 테스트 통과율 증가입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n결론\n\n이미 강력한 디버깅 도구가 더 쉽게 사용할 수 있도록 개선되었으며, 새로운 기능, 시스템 개선 및 스타일 업데이트를 자랑합니다.\n\nReactime에 기여하거나 실험해 보고 싶다면 GitHub 페이지를 확인해보세요!\n\nChrome 웹 스토어에서 확장 프로그램을 시도해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# v25 Reactime 팀을 만나보세요:\n\n- Logan Nelsen | [GitHub](GitHub 링크) | [LinkedIn](LinkedIn 링크)\n- Haider Ali | [GitHub](GitHub 링크) | [LinkedIn](LinkedIn 링크)\n- Mel Koppens | [GitHub](GitHub 링크) | [LinkedIn](LinkedIn 링크)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nJose Luis Sanchez | GitHub | LinkedIn\n\n저희 웹사이트를 방문하시고 GitHub에서 별표를 부탁드립니다!","ogImage":{"url":"/assets/img/2024-05-17-Reactimev25Thetimetoreactisnow_0.png"},"coverImage":"/assets/img/2024-05-17-Reactimev25Thetimetoreactisnow_0.png","tag":["Tech"],"readingTime":4},{"title":"VsCode에 React 앱을 설치하는 방법(2024년 최신)","description":"","date":"2024-05-17 20:57","slug":"2024-05-17-HowtoInstallReactAppInVsCode2024","content":"\n\nReact.js은 실시간 응용 프로그램 및 사용자 인터페이스 개발에 널리 사용되는 JavaScript 라이브러리입니다. 이는 종종 프런트엔드 JavaScript 프레임워크로 언급됩니다. Visual Studio Code (VSCode)는 가벼우면서 강력한 코드 편집기로, React.js 개발에 탁월한 지원을 제공합니다. 이 글에서는 React.js를 빠르고 주관적인 빌드 도구인 Vite와 함께 VSCode에 설정하는 과정을 안내해 드리겠습니다. 그러니, 빠르게 React 앱을 VS Code에 설치해 봅시다.\n\n![이미지](/assets/img/2024-05-17-HowtoInstallReactAppInVsCode2024_0.png)\n\n# 사전 준비 사항:\n\n설치 프로세스에 진입하기 전에, 필요한 모든 사전 요구 사항이 갖추어져 있는지 확인해 보겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Node.js 및 npm:\n\n- React.js는 Node.js와 npm (Node Package Manager)에 의존합니다. 아직 설치하지 않은 경우, nodejs.org로 이동하여 최신 버전을 다운로드하고 설치해보세요.\n\n2. Visual Studio Code:\n\n- 컴퓨터에 Visual Studio Code가 설치되어 있는지 확인해주세요. 아직 설치하지 않은 경우, code.visualstudio.com에서 운영 체제와 호환되는 최신 버전을 다운로드하고 설치하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 단계 1: Visual Studio Code를 실행하세요\n\nVisual Studio Code를 열면 여정이 시작됩니다. 아직 설치하지 않았다면, 지금 설치하는 것이 바로 시기입니다.\n\n# 단계 2: React 앱 만들기\n\n## 2.1 통합 터미널 열기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n상위 메뉴로 이동하여 View - Terminal을 선택하거나 바로 가기 Ctrl +를 사용하여 Visual Studio Code 내에 통합 터미널을 열어보세요.\n\n# 2.2 새 React 앱 생성하기\n\n다음 명령을 실행하여 새 React 앱을 만들어보세요. 원하는 프로젝트 이름으로 my-react-app을 사용자 정의할 수 있습니다.\n\n```js\nnpx create-react-app my-react-app\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 단계 3: 프로젝트로 이동하기\n\n다음 명령어를 사용하여 프로젝트 디렉토리로 이동하세요:\n\n```js\ncd my-react-app\n```\n\n# 단계 4: 개발 서버 실행하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 4.1 개발 서버 시작하기\n\n다음 명령어를 사용하여 개발 서버를 시작하세요:\n\n```js\nnpm start\n```\n\n이 명령어를 실행하면 React 앱이 개발 모드로 실행되며, 브라우저를 통해 http://localhost:3000/ 에서 접근할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 4.2 원활한 개발을 위한 자동 업데이트\n\nReact 코드를 조정하고 수정하는 동안 개발 서버가 자동으로 업데이트되어 원활하고 효율적인 개발 경험을 제공합니다.\n\n# 단계 5: React 앱 구조 살펴보기\n\nVisual Studio Code를 열고 프로젝트 폴더로 이동합니다. src 폴더는 소스 코드용이고 public 폴더는 정적 자산용 등 필수 폴더를 포함한 표준 React 프로젝트 구조가 여러분을 기다리고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 단계 6: 향상된 개발을 위한 선택 도구\n\n# 6.1 React 개발자 도구 확장\n\nVisual Studio Code에서 \"React 개발자 도구\" 확장을 통합하여 개발 경험을 향상시킵니다. 이 확장은 React 애플리케이션을 디버깅하는 데 유용한 통찰력과 도구를 제공합니다.\n\n- 확장 뷰( Ctrl + Shift + X)를 열고 \"React Developer Tools\"를 검색한 후 설치를 클릭하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 6.2 ESLint과 Prettier를 통한 코드 품질 관리\n\n코드 일관성과 품질을 유지하기 위해 React 프로젝트에 ESLint와 Prettier를 통합하는 것을 고려해보세요.\n\n- ESLint를 전역으로 설치하세요:\n\n```js\nnpm install -g eslint\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Visual Studio Code에 ESLint 확장 프로그램을 설치해보세요.\n- ESLint 구성 파일을 만들어보세요:\n\n```js\nnpx eslint --init\n```\n\nPrettier를 설치해보세요:\n\n```js\nnpm install --save-dev prettier\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 프로젝트에 .prettierrc 파일을 만들어 Prettier를 구성하세요.\n\n## 단계 7: 코딩 어드벤처 시작하기\n\n축하합니다! 이제 비주얼 스튜디오 코드에서 React.js 프로젝트를 성공적으로 설정했고, 이제 창의력을 발휘할 준비가 되었습니다. 강력한 React 컴포넌트를 구축하고, React 라이브러리의 방대한 생태계를 탐험하며, 웹 개발의 무한한 가능성에 대해 탐구해보세요.\n\n## 결론:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2024년이 시작되면서 React.js는 현대 웹 개발의 선두에 있습니다. React.js를 정복하면 다양한 기회의 문을 열 수 있습니다. 이 포괄적인 안내를 따르면, Visual Studio Code에 React를 설치하고도 풍부한 코딩 여정을 경험할 수 있게 될 것입니다.","ogImage":{"url":"/assets/img/2024-05-17-HowtoInstallReactAppInVsCode2024_0.png"},"coverImage":"/assets/img/2024-05-17-HowtoInstallReactAppInVsCode2024_0.png","tag":["Tech"],"readingTime":3},{"title":"React Native 페이지 최적화 방법 정리(2024년 최신)","description":"","date":"2024-05-17 20:52","slug":"2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney","content":"\n\n리액트는 쉽게 시작할 수 있는 프레임워크이지만 규모 확장에는 어렵습니다. 어플리케이션이 커지면 잘못된 상태 업데이트, 뒤얽힌 렌더 로직, 비효율적인 이벤트 핸들러 생성, 비효율적인 라이브러리 사용, 그리고 불필요한 useEffect가 매우 쉽게 발생하고 어플리케이션의 렌더 성능에 심각한 영향을 미칠 수 있습니다. 이 느려짐은 React Native 어플리케이션에서 특히 더 눈에 띄며, 여기서 모든 렌더링이 강력한 웹 서버에 의해 수행되지 않기 때문입니다. 저는 현재 진행 중인 피트니스 어플리케이션의 프로필 페이지를 작성하면서 이 현상을 다시 한번 깨닫게 되었습니다.\n\n이 기사는 원래 2년 전에 작성한 프로필 페이지를 점진적으로 다시 작성하는 과정을 요약할 것입니다. 프로필 페이지로 네비게이션하면 Google Pixel 7에서 프레임이 20-40 FPS로 떨어지는 현상이 있었습니다. 최적화 이후, 어플리케이션은 86 FPS의 프레임율을 유지할 수 있었습니다. 최적화 이후 90 FPS에서 4 FPS가 떨어진 것은 사용 중인 React Navigation 1.0 라이브러리가 최적이 아니었기 때문에 불가피했습니다. 제 어플리케이션의 이 라이브러리 업그레이드는 진행 중이며, 라이브러리 업그레이드 후의 성능 향상에 대해 향후 기사에서 보고하겠습니다.\n\n끝까지 긴 여행이니 그에 맞게 준비하세요! 그러나 궁금해 하지 않으시면, 깊이 파고들기 전에 미리 작성해 둔 주요 내용을 읽어보실 수 있습니다. 또한, 본 기사는 React, React Native, 그리고 React Native Animations의 기본을 알고 있다고 가정합니다. 그럼, 더 이상 미루지 말고 출발해봅시다!\n\n# 주요 내용\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- React 개발자로 활동하면 React Native 앱 개발에 대한 우위를 가질 수 있어요. 하지만 효율적인 React Native 앱을 만들기 위해 따르아야 할 특정한 디자인 가이드라인이 있어요. 예를 들어,\na. 좋은 예전 map 함수 대신 컴포넌트 목록을 렌더링하기 위해 FlatLists를 사용합니다.\nb. 제스처를 처리하기 위해 제스처 핸들러를 최대한 활용합니다 — 모바일 앱 개발은 클릭보다는 제스처에 집중되어 있어요.\nc. 컴포넌트를 애니메이션화하기 위해 Reanimated 라이브러리를 효율적으로 활용합니다. 다시 말해, 웹과는 다르게, 애니메이션은 앱 UX에서 더 중요한 역할을 합니다.\nd. 긴 목록의 컴포넌트를 렌더링하기 위해 항상 FlatLists를 사용합니다. 각 컴포넌트 내부의 비즈니스 로직을 최소화해야 합니다.\n- 목록을 어떻게 렌더링하든지간에, React는 목록의 모든 컴포넌트가 렌더링된 후에만 결과를 화면에 그립니다. 따라서, FlatLists를 사용하더라도 각 컴포넌트의 렌더링 시간을 최적화해야 합니다. 과도한 렌더링 로직은 막대한 화면 드랍을 초래할 수 있습니다.\n- 각 컴포넌트 내부에 무거운 렌더링 로직을 사용하는 것이 불가피할 경우, 렌더링 로직 실행을 디바운스하여 목록의 빠른 초기 로드를 보장할 수 있습니다. 제 경우, 각 목록 컴포넌트에 부담이 되는 MapView를 렌더링해야 했기 때문에 화면 드랍이 발생했어요. 해결책은 MapView를 렌더링하기 전에 의도적으로 1초의 지연을 도입하는 것이었어요. 이로써 화면 드랍 없이 초기 렌더링 시간이 빨라지게 되었고, Map은 초기 로드 후 1초 후에 렌더링되었습니다. 디바운스 중일 때 가벼운 로더를 표시해야 합니다. 사용자는 디바운스된 논리 실행 후 레이아웃 점프를 보게 되면 안 됩니다.\n- 앱 전체에서 재사용될 이미지를 미리 가져올 수 있어요. 이는 expo-image나 react-native-fast-image와 같은 라이브러리를 사용하여 수행할 수 있습니다.\n- 특히 목록 내부에 있는 컴포넌트를 메모라이즈해야 합니다.\ninitialNumToRender 속성을 사용 중이라면, FlatList는 초기 목록 컴포넌트가 렌더링된 후에 정의된 창 크기까지 전체 목록을 다시 렌더링합니다.\n예: 만약 initialNumToRender가 3이고 창 크기가 10이라면, FlatList는 다음과 같이 동작할 것입니다:\na. 처음 3개의 목록 항목을 초기로드합니다.\nb. 완료되었을 때, 첫 10개 항목을 렌더링합니다. 이미 로드된 처음 3개 항목을 다시 렌더링합니다.\n- React 상태와 Reanimated 공유 값이 혼합되지 않도록 주의해야 합니다. React 상태는 JS 스레드에서 유지되고, Reanimated 공유 값은 UI 스레드에서 유지됩니다. 항상 기억해야 할 사항은:\na. React 상태를 수정하는 것은 비용이 많이 들지만, 공유 값의 수정은 그렇지 않습니다.\nb. 공유 값 수정은 컴포넌트를 다시 렌더링하지 않습니다. 따라서 Reanimated 값 변경 시 자동으로 업데이트되지 않는다고 하더라도, Reanimated 래퍼 내에 있지 않는 React JS 변수는 컴포넌트가 업데이트되지 않습니다.\n- 마지막으로, React 상태 업데이트는 매우 비용이 많이 들 수 있음을 인지해야 합니다. Memoization은 이러한 문제를 해결하는 데 매우 유용합니다. 예를 들어, 부모에 상태 변수가 포함된 경우, 모든 자식이 부모 상태 변경 시 다시 렌더링됩니다. 이는 단순 컴포넌트에는 해로울 수 있지만, 무거운 자식 컴포넌트의 다시 렌더링은 화면 드랍을 유발할 수 있습니다. 메모라이제이션은 종속 프로퍼티 변경 시에만 다시 렌더링되도록 보정합니다.\n\n이론적인 내용이 도움이 되었기를 바라며, 지금은 비성능 페이지 수정의 풍요로운 여정을 떠나봅시다.\n\n# 프로필 페이지에 관한 내용과 마주한 문제들\n\n## 기능성 및 초기 컴포넌트 구조\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Component Structure](/assets/img/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney_0.png)\n\n프로필 페이지의 초기 구성은 위 이미지에 요약되어 있습니다. PersonalProfile은 이 페이지의 \"화면\"인 최상위 구성 요소입니다. PersonalProfile을 통해 다음 정보가 표시됩니다.\n\n- ProfileSummary 구성 요소는 다음을 표시합니다:\n  a. 프로필 사진 (Avatar라고 불리는 구성 요소를 통해)\n  b. 사용자의 이름\n  c. 사용자의 운동 횟수, 팔로워 수 및 사용자가 팔로우하는 사람 수\n\n- ProfileTabs 구성 요소에는 사용자가 최근에 완료한 운동 및 해당 사용자가 편성한 훈련 계획을 표시하는 두 개의 탭이 포함되어 있습니다.\n\n- WorkoutSnippet 구성 요소를 통해 각 운동이 요약됩니다. WorkoutSnippet은 운동 제목 (\"Saturday Night Run\"이 화면 샷에 표시됨), 캡션 (\"A good run\"이 화면 샷에 표시됨), 운동 경로를 나타내는 MapView, 운동 통계 및 운동과 상호 작용하는 몇 가지 제어가 표시됩니다.\n\n구성 요소 구조는 다음과 같이 요약될 수 있습니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n\u003cPersonalProfile\u003e\n  \u003cProfileSummary /\u003e\n  \u003cProfileTabs\u003e\n    {...\u003cWorkoutSnippet /\u003e}\n  \u003c/ProfileTabs\u003e\n\u003c/PersonalProfile\u003e\n```\n\nInitial analysis 후 많은 개선점을 발견했지만, 페이지 성능을 저해하는 주요 원인은 운동 스니펫 목록이었다고 결론지었습니다. 각 스니펫에는 비싼 MapView가 있었고, 잘못된 위치에 상태 업데이트가 발생하여 긴 목록이 다시 처음부터 렌더링되었습니다. 사용자가 페이지를 보기 전까지 React가 가상 DOM에서 전체 목록을 렌더링할 때 크게 프레임 속도가 떨어졌습니다.\n\n## 사용자 메타데이터 가져오기\n\n- 사용자 정보는 앱의 로컬 스토리지에 캐시되어 있어 같은 세션에서는 메타데이터를 다시 가져 오지 않습니다. 사용자가 프로필 페이지를 수동으로 새로 고치지 않는 한 (Instagram처럼 아래로 끌어 다시 가져오는 것), \n- 백엔드 통신은 GraphQL을 기반으로 하며, PersonalProfile 구성 요소는 Apollo의 useQuery 훅을 사용하여 메타데이터를 가져옵니다. 성공적인 검색을 통해 저장된 사용자 데이터를 업데이트해야 하므로 가져온 데이터에 대한 useEffect가 구현됩니다. 훅 값이 변경 될 때 캐시를 업데이트 합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n// 인증 컨텍스트를 사용하여 캐시 스토리지와 상호 작용합니다.\nconst { secureUser, setUserData } =\n    useContext\u003cAuthContextEntity\u003e(AuthContext);\n\n// 팔로워 및 팔로잉 수를 가져오기 위한 쿼리\nconst {\n  data: followCount,\n  loading: followCountLoading,\n  error: followCountError,\n} = useQuery\u003c{ userById: Partial\u003cUser\u003e }\u003e(userQueries.followCount, {\n  variables: { id: secureUser._id },\n});\n\n// 운동 수를 가져오기 위한 쿼리\nconst {\n  data: workoutCount,\n  loading: workoutCountLoading,\n  error: workoutCountError,\n} = useQuery\u003c{ getActivityCount: number }\u003e(\n  recentActivityQueries.activityCount,\n  {\n    variables: { userId: secureUser._id },\n  }\n);\n\nconst updateUserInCache = () =\u003e {\n  setUserData({\n    ...secureUser,\n    followCount: followCount.followCount,\n    followerCount: followCount.followerCount,\n    workoutCount,\n  });\n};\n\n// 운동 수 검색 후 캐시에 사용자 업데이트\nuseEffect(() =\u003e {\n  updateUserInCache();\n}, [workoutCount]);\n\n// 팔로워-팔로잉 수 검색 후 캐시에 사용자 업데이트\nuseEffect(() =\u003e {\n  updateUserInCache();\n}, [followCount]);\n```\n\n문제:\n이 메타데이터 가져오기는 Apollo 클라이언트 라이브러리에서 제공하는 훅에 의해 초기 렌더링 후에 발생합니다. 이 요청은 React 컨텍스트를 업데이트하므로 컨텍스트 업데이트는 루트 컴포넌트인 PersonalProfile을 다시 렌더링하게 만듭니다. 부모 컴포넌트의 다시 렌더링은 모든 하위 컴포넌트를 다시 렌더링하게 만듭니다.\n초기 로드 중 프레임 드롭의 원인은 아니지만, 이는 후속 렌더링 시간을 늘리는 원인이 되었습니다.\n해결책:\n모든 하위 컴포넌트의 메모이제이션.\n\n## 초기 코드- 탭 렌더링\n\n초기 설계에서 탭 관리 책임을 ProfileTabs 컴포넌트에 통합했습니다.\n다음과 같은 내용을 포함했습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 상단에 두 개의 탭이 있습니다 — 운동 및 훈련 계획.\n- 프로필 Body. 이 안에 있는 내용은 탭에 의해 관리되는 상태에 따라 다릅니다.\n\n두 탭 중 하나를 클릭하면 React 상태가 업데이트되어 Body가 다시 렌더링됩니다.\n이는 UX를 떨어뜨렸을 뿐만 아니라 두 탭 사이를 스와이프할 수 없고, 그냥 하나의 탭을 클릭해야 했으며, 본문에 포함된 전체 목록이 언마운트되어 다시 처음부터 마운트되고 활성 탭이 다시 전환되면 자신도 다시 렌더링되었습니다 — 가시적인 스터터가 발생했습니다.\n\n```js\nconst [activeTab, setActiveTab] = useState(0);\nconst handleTabPress = (index: number) =\u003e {\n  setActiveTab(index);\n};\nconst renderTabs = () =\u003e {\nreturn (\n    \u003c\u003e\n      \u003cView style={styles.tabContainer}\u003e\n        {tabs.map((tab, index) =\u003e (\n          \u003cTouchable\n            {...tabProps}\n          \u003e\n            {tab.icon}\n          \u003c/Touchable\u003e\n        ))}\n      \u003c/View\u003e\n      \u003cView style={styles.tabBottomContainer}\u003e\n        \u003cTabIndicator\n          activeIndex={activeTab}\n          width={styles.tabBottom.width}\n          height={styles.tabBottom.height}\n          backgroundColor={styles.tabBottom.backgroundColor}\n          totalTabs={TAB_ARR_LENGTH}\n        /\u003e\n      \u003c/View\u003e\n      {activeTab === 0 ? renderWorkouts() : renderTrainingPlans()}\n    \u003c/\u003e\n  );\n}\n```\n\n## 초기 코드 — 운동 목록 렌더링\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프레임 드랍의 뿌리는 비효율적으로 렌더링되는 고가의 구성 요소 목록입니다.\n\n```js\n\u003cView style={styles.body}\u003e\n  {recentWorkouts.map((workout, index) =\u003e (\n    \u003cWorkoutSnippet\n      workout={workout}\n      key={workout.endTime}\n      {...props}\n    /\u003e\n  ))}\n\u003c/View\u003e\n```\n\n알 수 있듯이 FlatList를 사용하지 않았으며 각 구성 요소가 비싼 MapView를 렌더링했습니다. 최적화 없이 초기에 6개의 WorkoutSnippet 및 따라서 한꺼번에 6개의 MapView가 렌더링되어 React가 거대한 프레임 드롭이 발생했습니다.\n동시에 프로필 페이지는 다음과 같은 문제를 마주해 큰 프레임 속도가 감소하게 되었습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 운동 목록의 초기 렌더링이 느립니다.\n- 사용자 정보를 업데이트하는 후크가 전체 페이지를 다시 렌더링하므로 이후에 발생하는 지연이 증가합니다.\n- 탭을 전환하면 본문이 다시 렌더링되어 지연을 야기합니다.\n\n아래 문제를 확인할 수 있습니다:\n\n![문제1](https://miro.medium.com/v2/resize:fit:932/1*zkDh8rVTwp3JcXvIGI_3gA.gif)\n\n![문제2](https://miro.medium.com/v2/resize:fit:632/1*zkEbgEryLuesOPbJHBejRw.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 프로파일러의 단점 관찰\n\n프로파일러를 읽는 방법을 모르겠다면, 이 기사를 읽기를 권장합니다. 프로파일러 데이터를 읽고 해석하는 것이 문제를 이해하고 이를 최적화하는 데 많은 역할을 했습니다.\n플레임 그래프는 가장 부담스러운 구성 요소를 확인하는 데 사용되었습니다. 이것이 어떻게해서 MapViews가 지연의 근본 원인인지 알아낼 수 있었던 이유입니다. 플레임 그래프는 또한 모든 연이은 렌더링을 나열하고 어떤 구성 요소가 다시 렌더링되었는지 강조합니다. 이것이 부담스러운 구성 요소의 불필요한 재렌더링을 알아낼 수 있는 방법이었습니다.\n\n프로파일러의 플레임 그래프를 읽은 결과는 다음과 같습니다:\n\n- 프로파일 화면의 초기 렌더링에는  list가 135ms 소요되어 총 200ms가 걸렸습니다.\n- 사용자 메타데이터를 가져오면 앞서 설명한대로 콘텍스트 개체가 업데이트되어 전체 화면이 다시 렌더링됩니다. 이 재렌더링은 122ms가 걸렸습니다.\n- 탭을 탐색하면 상태가 업데이트되어 탭 및 본문 전체가 다시 렌더링되며 렌더링 시간은 190ms였습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n안녕하세요!\n\n# 최적화\n\n## ScrollView를 FlatList로 대체하기\n\nFlatList는 React Native에서 제공하는 가상 리스트로, 대규모 리스트의 성능을 향상시키고 메모리 소비를 줄입니다. 이는 활성 항목들의 유한한 렌더 창을 유지함으로써 달성됩니다. 이 렌더 창 밖에 있는 항목들은 공백 뷰로 대체되어 전체 리스트의 성능을 향상시킵니다. 렌더 성능을 최적화하기 위해 여러 프롭스가 제공되며, 개발자는 렌더 창을 미세 조정할 수 있습니다. 리스트의 초기 렌더링에 문제가 있었기 때문에 initialNumToRender 프롭이 관련이 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n따라서 ScrollView 안에있던 맵을 FlatList로 전환하여 운동 목록을 렌더링했습니다:\n\n```js\nconst renderItem: ListRenderItem\u003cWorkout\u003e = useCallback(\n  (workout: ListRenderItemInfo\u003cWorkout\u003e) =\u003e {\n    return (\n      \u003cWorkoutSnippet\n        workout={workout.item}\n        {...otherProps}\n      /\u003e\n    );\n  },\n  []\n);\nreturn (\n  \u003cFlatList\n    data={workouts}\n    renderItem={renderItem}\n    keyExtractor={(item) =\u003e item._id}\n    initialNumToRender={3}\n    {...otherProps}\n  /\u003e\n);\n```\n\n아래에 몇 가지 주요 관찰 사항이 나와 있어요. 주의 깊게 읽어 주세요:\n\n- initialNumToRender 속성을 3으로 설정하여 가상 목록이 초기 렌더링 시 처음 3개 요소만 렌더링되도록 했어요.\n그러나 초기 렌더링이 완료되면, 가상 목록이 창 크기 내의 모든 항목을 렌더링합니다 (기본적으로 10 뷰포트 단위에 해당하는).\n재랜더링 시 초기에 렌더링된 구성 요소를 무시하지 않아요. 창 크기 내 목록의 모든 항목이 다시 렌더링됩니다.\n예: 창 크기 내에 10개 항목이 있고, 초기 렌더링할 항목 수가 3개이면 목록은 다음과 같이 되겠죠:\ni. 초기 렌더링 시 3개 항목을 렌더링합니다.\nii. 다음 렌더링 시 (이미 렌더링된 초기 항목 포함) 모든 10개 항목을 렌더링합니다.\n따라서, 가상 목록에서 재랜더링을 방지하기 위해 렌더링되는 구성 요소를 메모이즈하는 것이 중요합니다.\n목록에서 렌더링되는 구성 요소를 메모이즈하면 초기 항목이 다시 불필요하게 렌더링되는 것을 방지할 수 있어요.\n- renderItem 속성에 전달된 함수는 FlatList의 렌더링 로직을 정의합니다.\n이것을 참조로 전달하고, useCallback 훅 내부에 래핑되었는지 확인하는 것이 중요합니다.\n이를 하지 않으면 FlatList 부모의 재랜더링마다 함수가 재정의되어 목록의 중복 재랜더링을 일으킬 수 있어요. 그것은 매우 비용이 많이들 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 최적화를 고려한 후에 성능을 확인해봅시다:\n\n![GIF](https://miro.medium.com/v2/resize:fit:1224/1*eMhn-98QVNHKvJh4T-ILnQ.gif)\n\n관찰할 수 있듯이, 여전히 일시적인 끊김이 있습니다! 3개의 컴포넌트를 동시에 렌더링해도, MapView는 여전히 핸드폰이 작은 시간프레임 내에서 렌더링하기에 너무 많은 부하를 줍니다.\n\n## MapViews의 지연 로딩\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해결책은 MapViews를 Lazy Load하는 것이었습니다. 이 방법은 다음과 같이 작동했습니다:\n\n- 각 목록 항목에 고정 높이 MapView가 있습니다.\n- MapView의 로딩을 일부러 1초 지연합니다.\n- 해당 시간까지 MapView 자리에 스켈레톤 로더를 표시합니다.\n\n마운트 시에 useEffect 내에서 timeout을 놓는 것으로 구현하였습니다.\n리스트 컴포넌트 내에 상태를 배치합니다:\n\n```js\nconst [mapLoaded, setMapLoaded] = useState(false);\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n리스트 컴포넌트 내에 useEffect를 정의하세요:\n\n```js\nuseEffect(() =\u003e {\n  setTimeout(() =\u003e {\n    setMapLoaded(true);\n  }, 1000);\n}, []);\n```\n\nMapView 렌더링 로직:\n\n```js\nif (!mapLoaded) {\n  return (\n    \u003cActivityIndicator /\u003e\n  );\n}\nreturn (\n  \u003cMapView {...props} /\u003e\n);\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n최종 최적화:\n\n지도를 이렇게 로드하는 것은 mapLoaded = false에서 mapLoaded = true로 상태가 업데이트되는 동안 UI를 차단합니다. 예를 들어, 이 상태가 업데이트되는 동안 탭을 전환하려고 하면 지연이 발생할 수 있습니다. 여기서 React의 새로운 비동기 아키텍처가 문제를 해결해 줍니다 - useTransition 훅을 사용하여 비동기 상태 업데이트를 실행함으로써 차단된 UI 요소는 더 이상 문제가 되지 않습니다. 더 자세한 내용은 여기를 참조하세요.\n따라서 우리는 이 상태 업데이트를 전환 내부로 감싸줍니다:\n\n```js\nuseEffect(() =\u003e {\n  setTimeout(() =\u003e {\n    startTransition(() =\u003e {\n      setMapLoaded(true);\n    });\n  }, 1000);\n}, []);\n```\n\n마지막으로, 여기가 결과입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](https://miro.medium.com/v2/resize:fit:808/1*lXJIEkRu_pn9vl7VH5loag.gif)\n\nThe drop during mount is now down to 82 FPS from a previously unreliable 20–40 FPS! There is an inevitable drop when the MapViews load in eventually after 1 second, but the UI remains responsive throughout!\n\nAs for the profiler results, the render time of the screen dropped to 120ms, with the list itself taking 90ms.\nThat’s an improvement by a third of the original render time!\n\n## Fixing Tab Switching Logic — Making the Tabs Swipe-able\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이전에는 탭을 클릭할 수만 있고 스와이프할 수는 없었습니다. 탭을 전환할 때마다 본문이 다시 렌더링되어 부드럽지 않은 화면 전환이 발생했죠. 이 문제를 해결하기 위해 본문을 수평으로 렌더링하는 FlatList로 변경할 것입니다. 이렇게하면 재렌더링으로 인한 문제 해결뿐 아니라 (FlatList는 상태에 관계없이 두 번째 탭을 게으르게 렌더링합니다), 사용자 경험을 더 좋게 만들어 프로필 페이지를 더 쉽게 탐색할 수 있습니다.\n\n참고: 이 하위 섹션은 최적화보다는 UI 디자인 구현에 가깝습니다. 이 섹션은 읽지 않고 결과만 보셔도 됩니다.\n\n다음은 새로운 레이아웃입니다:\n\n![이미지](/assets/img/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n최종 결과물:\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:504/1*Drzw-Y4UMkDy09OwlS2v2Q.gif\" /\u003e\n\n정말 부드러운 모션인데요!\n\n사용자가 수평으로 스와이프할 때 무슨 일이 벌어지는지 자세히 살펴봅시다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 사용자가 탭의 너비의 약 50%로 스크롤 할 때 활성 탭 아이콘이 \"점등\"합니다.\n- 활성 탭을 나타내는 하얀색 하단 테두리가 사용자의 수평 스크롤에 따라 이동합니다.\n\n![이미지](https://miro.medium.com/v2/resize:fit:712/1*bfGvqGl9Z1vbTZ9QQgHUHw.gif)\n\n3. 탭을 클릭하면 본문이 100% 스크롤되어 다음 요소로 이동합니다. 탭 표시기도 함께 이동합니다.\n\n![이미지](https://miro.medium.com/v2/resize:fit:956/1*kXqvHtGO3Avsa_jBwGsgjA.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 고정 탭 구현하기\n\n이것은 매우 간단합니다. React Native의 FlatList 컴포넌트가 제공하는 stickyHeaderIndices 속성은 수직 목록에서 작동하며 지정된 인덱스의 구성요소를 스크롤할 때 상단에 고정시킵니다. 다음은 프로필 화면 내에 정의된 최상위 FlatList의 코드입니다:\n\n```js\nconst flatListData = useMemo(\n  () =\u003e [renderProfileSummary, renderTabs, renderBody],\n  [renderProfileSummary, renderTabs, renderBody]\n);\nconst renderItem: ListRenderItem\u003c() =\u003e JSX.Element\u003e = useCallback(\n  (item) =\u003e item.item(),\n  []\n);\nconst stickyIndices = useMemo(() =\u003e [1], []);\n\n\u003cFlatList\n  data={flatListData}\n  renderItem={renderItem}\n  stickyHeaderIndices={stickyIndices}\n  {...otherProps}\n/\u003e\n```\n\nFlatList로 전달된 모든 데이터가 메모화된 것에 주목하세요. 이는 프로필 화면의 재렌더링 시 props의 재정의를 방지해야 하기 때문입니다 (React는 객체에 대한 참조 무결성을 확인합니다. 객체를 메모화하면 렌더링 간 참조 무결성을 유지하는 데 도움이 됩니다). 기억하세요 - props의 변경은 전체 목록을 다시 렌더링하게 만들며, 우리는 그것을 방지하려고 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- ProfileSummary(프로필 요약 렌더링), Tabs(탭 렌더링), 및 body(본문 렌더링) 함수들은 데이터로 FlatList에 전달됩니다. renderItem 함수는 이러한 함수들을 간단히 실행합니다.\n- stickyHeaderIndices가 [1]로 정의되어 있습니다. 이는 우리가 탭들(데이터 배열의 첫 번째 위치에 정의된)을 스크롤하여 지나갈 때에 고정시킵니다.\n\n## 동적으로 하단 테두리 효과 구현하기\n\n이 부분은 다소 까다로운 부분입니다. 이 효과를 달성하기 위해 Reanimated 라이브러리의 공유 값(shared values)을 활용했습니다. 만약 이 라이브러리에 익숙하지 않다면, 그 뛰어난 문서를 읽어보는 것을 권합니다.\n\n한 발 물러서서, 가로 스크롤 뷰에 대해 다음을 관찰합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 각 탭은 화면 너비와 같은 너비를 갖습니다 (100vw).\n- 따라서, 수평 스크롤 뷰의 총 너비는 nTabs * 100vw 입니다. 이것은 우리의 공유 값의 범위가 됩니다:\n[스크롤 없음, 모든 탭 스크롤됨] = [0, nTabs * 100vw]\n다시 말해, 애니메이션 값은 사용자가 수평으로 스크롤한 픽셀량을 단순히 추적할 것입니다.\n\n수평 FlatList가 스크롤되면, 이 애니메이션의 값을 조정하여 단순히 사용자가 스크롤한 현재 오프셋 (픽셀 수)이어야 합니다. FlatList의 onScroll 프로퍼티를 사용하면 아주 쉽게 이를 달성할 수 있습니다:\n\n```js\nconst onBodyScroll = useCallback(\n  (event: NativeSyntheticEvent\u003cNativeScrollEvent\u003e) =\u003e {\n    const { nativeEvent } = event;\n    const { contentOffset } = nativeEvent;\n    const { x } = contentOffset;\n    swipeAnimationValue.value = x;\n  },\n  [swipeAnimationValue]\n);\n``` \n\n마지막으로, 탭 인디케이터의 스타일을 다음과 같이 설정하겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nconst indicatorStyle = useAnimatedStyle(() =\u003e ({\n  position: \"absolute\",\n  bottom: 0,\n  left: 0,\n  width: vw(100 / nTabs),\n  transform: [\n    {\n      translateX: interpolate(animatedValue.value, [0, nTabs * vw(100)], [\n        0,\n        nTabs * vw(100 / nTabs),\n      ]),\n    },\n  ],\n}));\n```\n\ninterpolare 함수는 애니메이션 값과 스타일 속성 값의 매핑을 담당합니다.\n\n- 인디케이터의 너비는 100 % / nTabs (우리 예에서 50vw)와 같아야 합니다.\n- 인디케이터는 왼쪽 하단에 절대 위치로 배치됩니다.\n- 스크롤이 없는 경우에는 어떤 이동도 필요하지 않습니다. 목록이 완전히 스크롤되었을 때 (마지막 요소조차 완전히 스크롤된 경우), 인디케이터는 nTabs * vw(100 / nTabs)만큼 이동해야 합니다.\nReanimated 라이브러리가 이들 극단값 사이의 중간 값들을 처리해줄 것입니다.\n\n아래에 시각화가 제공되었습니다: \n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney_2.png)\n\nThis wraps up our translation effect!\n\n## Achieving Dynamic Tab Icon Color\n\nObserve carefully when the color of the tab icon changes:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](https://miro.medium.com/v2/resize:fit:1100/1*S9kq4JSTm65UgmYbbv_Cpg.gif)\n\n사용자가 탭 본문의 50% 이상으로 스크롤했을 때 탭 색상이 변경됩니다. 새로운 색상으로 유지되는 기간은 얼마인가요? 사용자가 탭 본문의 50% 이상 스크롤하지 않는 한 계속해서 색상이 유지됩니다.\n우리의 animatedValue가 저장하고 있는 것을 기억하세요: 그렇습니다, 수평 FlatList의 스크롤 오프셋을 저장하고 있습니다!\n우리는 Reanimated 라이브러리에서 제공되는 interpolateColor 함수를 사용하여 탭의 색상을 보간할 수 있습니다!\n스크롤 오프셋을 탭 아이콘의 색상으로 매핑하는 보간 함수를 구성해야 합니다.\n\n각 탭에는 인덱스가 있습니다. 여기서 두 탭의 인덱스는 각각 0과 1입니다.\n\n여기 우리의 수평 탭 본문 목록이 펼쳐진 모습입니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\u003cimg src=\"/assets/img/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney_3.png\" /\u003e\n\n그러므로, animatedValue의 최대 가능한 값은 얼마라고 생각하시나요?\n200vw를 추측했다면, 정답입니다. 이는 사용자가 두 번째 탭 (Tab 1)을 넘어간 경우, 즉 뷰포트에 탭이 전혀 표시되지 않는 경우입니다.\n여기에 마지막으로, 각 탭이 시작하는 오프셋을 기록합니다:\n\n- Tab 0는 오프셋 0에서 시작합니다.\n- Tab 1은 Tab 0 이후 100vw에서 시작합니다.\n\n여기 사용자가 초기에 화면에서 볼 수 있는 것입니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney_4.png\" /\u003e\n\n여기서,\n\n- 스크롤 오프셋은 0입니다 (스크롤이 발생하지 않았으므로, animatedValue는 0입니다.)\n- 탭 0은 활성화된 색 (흰색)을 가지고 있고, 탭 1은 비활성화된 색 (회색)을 가지고 있습니다.\n\n자, 이제 활성 탭이 변경될 때 스크롤의 정확한 상태를 확인해 봅시다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney_5.png\" /\u003e\n\n여기서,\n\n- 스크롤 오프셋은 50vw입니다(탭의 반쪽이 사용자에 의해 스크롤되어 지나갔기 때문에), 그래서 우리의 애니메이션 값은 50vw입니다.\n- 탭 0은 비활성화되었고(회색), 탭 1은 활성화되었습니다(흰색).\n\n이전에 언급한 것처럼, 탭 0의 스크롤 오프셋은 0에서 시작하고, 탭 1의 스크롤 오프셋은 100vw에서 시작합니다. 추론하면, 삽입된 탭 2는 200vw에서 시작할 것이며, 이와 같은 식으로 계속됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n애니메이션을 완성하려면 이 최종 질문에 답해야 합니다:\n\n답변:\n사용자가 (i — 0.5) * x로 스크롤할 때(시작 오프셋 — 탭 너비의 50%라면) 탭을 활성화합니다.\n사용자가 (i + 0.5) * x로 스크롤할 때(시작 오프셋 + 탭 너비의 50%라면) 탭을 비활성화합니다.\n우리 예시에서 이를 설명하면,\n- 탭 0은 현재 스크롤 오프셋이 (0–0.5) * 100vw와 (0+0.5) * 100vw, 즉 -50vw와 50vw 사이일 때 활성화됩니다.\n- 탭 1은 현재 스크롤 오프셋이 (1 - 0.5) * 100vw와 (1 + 0.5) * 100vw, 즉 50vw와 150vw 사이일 때 활성화됩니다.\n\n마침내 보간된 아이콘 스타일이 준비되었습니다:\n\n```js\nconst iconStyle = useAnimatedStyle(() =\u003e ({\n  color: interpolateColor(\n    animatedValue.value,\n    [\n      (idx - 0.5) * animOffset - 1,\n      (idx - 0.5) * animOffset,\n      (idx + 0.5) * animOffset,\n      (idx + 0.5) * animOffset + 1,\n    ],\n    [inactiveTabColor, activeTabColor, activeTabColor, inactiveTabColor],\n  ),\n}));\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만개의 프롭 객체가 전부 useMemo를 사용해 메모이제이션했고, 화면의 모든 자식 컴포넌트를 React.memo를 사용해 메모이즈드 컴포넌트로 만들었어요.\n\n## 최적의 라이브러리 사용과 아이콘 폰트 미리 불러오기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이미지 및 글꼴을 렌더링할 때 추가 밀리초를 저장하기 위한 마지막 단계였습니다. React Native 문서 자체에서는 기본 `Image /` 컴포넌트 대신 전용 이미지 라이브러리를 사용하는 것을 제안합니다. expo-image 라이브러리는 잘 유지되며 이미지를 캐시하는 옵션을 제공합니다.\n\n정적 데이터를 가져오는 최적화를 위해 앱을 로드할 때 모든 아이콘 및 텍스트 글꼴을 미리 가져오기 위해 expo-font 패키지를 사용했습니다:\n\n```js\nconst [fontsLoaded] = useFonts({\n  // 텍스트 글꼴\n  Oswald: require(\"fitnet/assets/textFonts/Oswald.ttf\"),\n  Raleway: require(\"./src/assets/textFonts/Raleway.ttf\"),\n  \"Raleway-Bold\": require(\"./src/assets/textFonts/Raleway-Bold.ttf\"),\n  // 아이콘 글꼴\n  NavBarIcons: require(\"fitnet/assets/iconFonts/NavBarIcons.ttf\"),\n  HomeIcons: require(\"fitnet/assets/iconFonts/HomeIcons.ttf\"),\n  ...AntDesign.font,\n  ...createIconSetFromIcoMoon.font,\n  ...EvilIcons.font,\n  ...FontAwesome.font,\n  ...FontAwesome5.font,\n  ...MaterialCommunityIcons.font,\n  ...MaterialIcons.font,\n});\n```\n\nexpo-image 라이브러리를 사용하여 사용자의 프로필 사진을 로그인할 때 캐시하고 앱 전체에 걸쳐 프로필 사진을 반복 다운로드하는 것을 방지했습니다. 이는 로그아웃 시에 지워졌습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n```js\nconst signIn = (user) =\u003e {\n  if (user.displayPicture) {\n    Image.prefetch(user.displayPicture, \"memory\");\n  }\n  setUserData(user);\n};\n...\nconst signOut = async () =\u003e {\n  await unsetUserData();\n  await clearAsyncStorage();\n  await Image.clearMemoryCache();\n  await Image.clearDiskCache();\n}\n```\n\n# 결론\n\n긴 여정이었습니다! React Native 애플리케이션을 최적으로 설계하는 데 어떤 통찰력을 얻었으면 좋겠어요. 메모이제이션, 적절한 네이티브 컴포넌트 사용, 캐싱 그리고 값 비싼 로직을 신중하게 배치하는 것은 앱을 최적화하는 데 큰 역할을 합니다. 이러한 전략을 사용하여 렌더링 시간을 200ms에서 110ms로 줄일 수 있었어요. 탭을 재설계하고 reanimated 라이브러리를 활용하며 값 비싼 상태 업데이트를 피함으로써 추후의 느림 현상을 완전히 제거할 수 있었어요! 프로파일러는 앱 성능의 병목 지점을 관찰하는 데 훌륭한 도구에요. 다음 번엔 또 뵙겠습니다!\n\n# 관련 기사\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 테이블 태그를 Markdown 형식으로 변경해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n리액트 네이티브에서 대량의 UI 항목을 최적으로 로드하는 방법에 대한 제안 목록입니다.","ogImage":{"url":"/assets/img/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney_0.png"},"coverImage":"/assets/img/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney_0.png","tag":["Tech"],"readingTime":20},{"title":"Vite, Nginx 및 런타임에서 정적 웹 사이트용 환경 변수 적용하는 방법","description":"","date":"2024-05-17 20:51","slug":"2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime","content":"\n\u003cimg src=\"/assets/img/2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime_0.png\" /\u003e\n\n안녕하세요 여러분! 저는 Quadcode의 프런트엔드 개발자 Dmitry Pashkevich입니다. 오늘은 Vite 빌드 도구와 Nginx 웹 서버를 이용하여 정적 웹사이트에 런타임 환경 변수를 전달하는 방법을 공유하려고 합니다.\n\n프런트엔드 개발에서 흔한 작업은 애플리케이션에 환경 변수를 전달하는 것입니다. 애플리케이션이 실행되는 환경에 따라 다르게 동작하도록 환경 변수를 설정하는 작업이죠. 간단한 작업으로 보이지만 이를 문서에 설명된 대로 처리하려면 .env 파일을 옆에 두고 빌드를 실행해야 합니다... 각 환경에서 말이죠.\n\n솔루션을 찾은 것 같습니다. 그러나 이로 인해 각 환경마다 다른 빌드 프로세스와 이에 따른 다른 결과로 이어집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n실무에서 빌드 단계의 기능에 문제가 발생하는 경우가 종종 있습니다. 예를 들어 변경 사항을 적용할 때 한 환경을 위해 설정, 스크립트 등을 업데이트하는 것을 잊을 때가 있습니다. 결과적으로, 아티팩트도 다르기 때문에 애플리케이션 자체에 문제가 발생합니다.\n\n그러므로 모든 환경에 대해 하나의 빌드 아티팩트를 얻고 환경 변수 값을 전달할 수 있는 것이 더 나을 것으로 보입니다. 따라서 변수 값이 정확한 한 가지 문제를 해결하는 것이 빌드 단계를 조사하는 것보다 더 쉽습니다.\n\n그럼 이를 Vite와 Nginx 도구를 사용한 예제로 어떻게 수행할 수 있는지 살펴봅시다.\n\n# 저장소 준비\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저 React + Typescript용 Vite 빌더에서 제공하는 템플릿을 사용하여 프로젝트를 생성해보겠습니다.\n\n```js\nnpm create vite@latest vite-nginx-dynamic-env-variables-example --\n--template react-ts \u0026\u0026 cd vite-nginx-dynamic-env-variables-example \u0026\u0026 npm\ninstal\n```\n\n# 프로젝트 구성 준비\n\n위 명령어를 성공적으로 실행한 후, 새로 생성된 프로젝트를 좋아하는 IDE에서 열고 목표 솔루션을 만들기 시작해봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파일 src/vite-env.d.ts를 수정해보세요. IDE 힌팅을 활성화하기 위해 사용 가능한 환경 변수 유형에 대한 설명을 추가할 거에요.\n\n```js\n/// \u003creference types=\"vite/client\" /\u003e\n\ninterface ImportMetaEnv {\n    readonly VITE_VERSION: string\n}\n\ninterface ImportMeta {\n    readonly env: ImportMetaEnv\n}\n```\n\n이제 IDE가 사용 가능한 환경 변수에 대한 힌트를 제공할 거예요.\n\n다음으로, 환경 변수 템플릿이 들어 있는 파일을 생성해볼게요: src/shared/projectEnvVariables.ts. 그리고 아래 내용을 추가해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ntype ProjectEnvVariablesType = Pick\u003cImportMetaEnv, \"VITE_VERSION\"\u003e;\n\n// 환경 변수 템플릿 런타임에 대체되도록\nconst projectEnvVariables: ProjectEnvVariablesType = {\n  VITE_VERSION: \"${VITE_VERSION}\",\n};\n\n// 런타임에서 변수 값을 반환하거나 빌드 결과로 얻음\nexport const getProjectEnvVariables = (): {\n  envVariables: ProjectEnvVariablesType,\n} =\u003e {\n  return {\n    envVariables: {\n      VITE_VERSION: !projectEnvVariables.VITE_VERSION.includes(\"VITE_\")\n        ? projectEnvVariables.VITE_VERSION\n        : import.meta.env.VITE_VERSION,\n    },\n  };\n};\n```\n\n그 다음, 위의 파일이 빌드 단계 후 예측 가능한 이름을 갖도록 빌드 구성을 vite.config.ts에 변경해야 합니다. 이를 위해 구성에 rollup을 위한 섹션을 추가해주세요.\n\n```js\nimport { defineConfig } from 'vite'\nimport react from '@vitejs/plugin-react'\n\n// https://vitejs.dev/config/\nexport default defineConfig({\n   plugins: [react()],\n   build: {\n       rollupOptions: {\n           output: {\n               format: 'es',\n               globals: {\n                   react: 'React',\n                   'react-dom': 'ReactDOM',\n               },\n               manualChunks(id) {\n                   if (/projectEnvVariables.ts/.test(id)) {\n                       return 'projectEnvVariables'\n                   }\n               },\n           },\n       }\n   }\n}\n```\n\nmanualChunks 섹션에서 사용자 정의 청크를 생성하고, 파일을 빌드한 후 이 파일을 환경 변수로 대체할 수 있도록 일부 이름을 저장합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nsrc/App.tsx 파일을 수정하여 환경 변수의 값들을 확인해봅시다.\n\n```js\nimport { getProjectEnvVariables } from \"./shared/projectEnvVariables.ts\";\n\nconst { envVariables } = getProjectEnvVariables();\n\nfunction App() {\n  return (\n    \u003c\u003e\n      \u003ch1\u003eVITE_VERSION\u003c/h1\u003e\n      \u003cdiv\u003e{envVariables.VITE_VERSION}\u003c/div\u003e\n\n      \u003chr /\u003e\n\n      \u003ch2\u003eimport.meta.env.VITE_VERSION\u003c/h2\u003e\n      \u003cdiv\u003e{import.meta.env.VITE_VERSION}\u003c/div\u003e\n    \u003c/\u003e\n  );\n}\n\nexport default App;\n```\n\n다음으로, 빌드를 실행하여 빌드 단계 이후에 변수를 대체하는 데 필요한 청크를 얻었는지 확인해봅시다.\n\n```js\nnpm run build\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n빌드가 완료되면 dist/assets 디렉토리로 이동하세요. 이전에 구성한 projectEnvVariables\\*이라는 청크가 존재하는 것을 확인할 수 있을 겁니다.\n\n![이미지](/assets/img/2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime_1.png)\n\n이제 연이어 실험을 진행해보겠습니다.\n\n원하는 빌드 결과를 얻는 데 쉽게 이해할 수 있도록, 각 빌드는 지정된 환경 변수로 수행될 것입니다. 이를 통해 getProjectEnvVariables 함수에서 환경 변수의 값을 반환하는 조건을 시각적으로 확인할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n첫 번째 실험을 위해 프로젝트 루트에 다음 내용을 포함한 .env 파일을 생성해주세요.\n\n```js\nVITE_VERSION = dev;\n```\n\n프로젝트 빌드를 시작하고 빌드 결과를 확인하는 모드로 전환해봅시다.\n\n```js\nnpm run build \u0026\u0026 npm run preview\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nhttp://localhost:4173/로 이동하면 구성에서 직접 환경 변수로부터 읽은 변수의 두 개의 동일한 값이 표시됩니다.\n\n![image](/assets/img/2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime_2.png)\n\n두 번째 실험에서는 애플리케이션을 빌드한 후 생성된 dist/assets/projectEnvVariables-wa84hTgi.js 파일에서 변수를 변경해보겠습니다. 이 파일에서 $'VITE_VERSION' 값이 들어있는 줄을 dev_from_env로 바꿔주세요. 브라우저에서 페이지를 새로고침하면 구성 getProjectEnvVariables에서 읽은 화면의 변수가 업데이트된 버전으로 표시됩니다.\n\n![image](/assets/img/2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모든 것이 예상대로 작동합니다! 이제 변수 대체를 자동화할 차례입니다.\n\n# 도커 + Nginx 환경 설정 준비\n\nDocker 컨테이너를 사용하여 Nginx 웹 서버를 실행하기 전에 초기화 스크립트를 실행하고 envsubst를 사용하여 환경 변수를 대체하는 변수 대체의 자동화를 보여 드리겠습니다.\n\n프로젝트 루트에 .docker 디렉토리를 만들어 Nginx 웹 서버를 위한 구성 내용을 넣어주시면 됩니다. Nginx 구성의 완전한 예시는 저장소에 있으며, 아래는 .docker/app/nginx/init-scripts/100-init-project-env-variables.sh 파일의 bash 코드입니다. 이 코드는 환경 변수를 대체합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```sh\n#!/usr/bin/env sh\n\nset -ex\n\n#환경 변수를 치환해야 하는 파일을 찾습니다.\nprojectEnvVariables=$(ls -t /usr/share/nginx/html/assets/projectEnvVariables*.js | head -n1)\n\n#환경 변수를 치환합니다.\nenvsubst \u003c \"$projectEnvVariables\" \u003e ./projectEnvVariables_temp\ncp ./projectEnvVariables_temp \"$projectEnvVariables\"\nrm ./projectEnvVariables_temp\n```\n\n이후에, 프로젝트 루트에서 다음 내용을 가진 Dockerfile을 생성하세요. 이 Dockerfile은 애플리케이션을 빌드하고 정적 파일을 제공하기 위해 Nginx 웹 서버를 실행하는 내용을 설명합니다.\n\n```js\nFROM node:20-alpine as builder\n\nWORKDIR /app\n\nCOPY package.json package-lock.json ./\n\nRUN npm ci\n\nCOPY . .\n\nARG NODE_ENV=production\nENV NODE_ENV=${NODE_ENV}\n\nRUN npm run build\n\nFROM nginx:alpine\n\nARG VITE_VERSION=dev\nENV VITE_VERSION=${VITE_VERSION}\n\nARG PORT=80\nENV NGINX_PORT=${PORT}\nENV NGINX_HOST=localhost\n\nEXPOSE ${PORT}\n\nCOPY .docker/app/nginx/nginx.conf /etc/nginx/nginx.conf\nCOPY .docker/app/nginx/conf.d/ /etc/nginx/conf.d/\nCOPY .docker/app/entrypoint.sh /entrypoint.sh\nCOPY .docker/app/nginx/init-scripts/ /docker-entrypoint.d/\n\nWORKDIR /usr/share/nginx/html\n\nCOPY --from=builder /app/dist ./\n```\n\n이제 컨테이너를 빌드해봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndocker build -t\nvite-nginx-dynamic-env-variables-example .\n```\n\n다음으로, 응용 프로그램에서 사용할 환경 변수에 대한 새로운 값을 가진 작성된 컨테이너를 실행해 봅시다.\n\n```js\ndocker run -p 81:80 -e VITE_VERSION=FROM_NGINX\nvite-nginx-dynamic-env-variables-example\n```\n\nhttp://127.0.0.1:81 으로 이동하여, 환경 변수가 현재 값으로 초기화되었음을 확인할 수 있습니다. 직접 읽은 환경 변수는 여전히 이전 값으로 남아 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime_4.png\" /\u003e\n\n# 결론\n\n이렇게 하면 실행 중에 환경 변수를 정적으로 빌드된 애플리케이션에 대체하여 모든 환경에서 통합 빌드가 가능합니다.\n\n코드는 저장소에서 찾을 수 있습니다.\n","ogImage":{"url":"/assets/img/2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime_0.png"},"coverImage":"/assets/img/2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime_0.png","tag":["Tech"],"readingTime":7},{"title":"대형 언어 모델LLM을 활용한 웹 어플리케이션 만드는 방법","description":"","date":"2024-05-17 20:49","slug":"2024-05-17-BuildingaWebApplicationPoweredbyLargeLanguageModelsLLMpart2","content":"\n\n\u003cimg src=\"/assets/img/2024-05-17-BuildingaWebApplicationPoweredbyLargeLanguageModelsLLMpart2_0.png\" /\u003e\n\n이전 글인 Building a Web Application Powered by Large Language Models (LLM): part 1에서는 ASP.NET Core API를 사용하여 CV 리뷰어 애플리케이션을 위한 견고한 백엔드를 개발했습니다. 웹 스크래핑을 위해 Azure Function을 활용하고 GPT 모델을 통합하여 이력서를 채용 공고와 관련하여 분석했습니다. 이번 글에서는 React 템플릿과 TypeScript를 사용하여 애플리케이션의 프론트엔드를 구축하는 데 초점을 맞출 것입니다. Bootstrap을 사용하여 애플리케이션을 스타일링하여 반응형이며 사용자 친화적인 인터페이스를 제공할 것입니다.\n\n# 요구 사항\n\n- Node.js와 npm이 컴퓨터에 설치되어 있어야 합니다.\n- React 및 TypeScript의 기본적인 이해가 필요합니다.\n- Bootstrap 스타일링에 대한 이해가 있으면 도움이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# React 프로젝트 설정하기\n\nVite를 사용하여 React 프로젝트 초기화: Vite는 React 애플리케이션을 위한 빠르고 최적화된 설정을 제공합니다. TypeScript 템플릿을 이용하여 Vite로 새로운 React 프로젝트를 생성하세요.\n\n```js\nnpm create vite@latest cv.reviewer.frontend -- --template react-ts\ncd cv.reviewer.frontend\n```\n\nBootstrap 설치하기: 프로젝트에 스타일링을 위해 Bootstrap을 추가하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nnpm install bootstrap@5.3.0\nnpm install @types/bootstrap\n```\n\n프로젝트 구조: 프로젝트를 컴포넌트, 서비스 및 스타일 폴더로 구성하여 관리를 더욱 편리하게 합니다.\n\n# 부트스트랩 및 전역 스타일 설정\n\nmain.tsx에 부트스트랩을 가져오세요: 메인 엔트리 파일에 부트스트랩 CSS를 추가하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport React from 'react';\nimport ReactDOM from 'react-dom/client';\nimport App from './App';\nimport 'bootstrap/dist/css/bootstrap.min.css';\nimport './styles/global.css';\n\nReactDOM.createRoot(document.getElementById('root') as HTMLElement).render(\n  \u003cReact.StrictMode\u003e\n    \u003cApp /\u003e\n  \u003c/React.StrictMode\u003e\n);\n```\n\n글로벌 스타일: styles 폴더에 global.css 파일을 만들어 추가적인 글로벌 스타일을 적용하세요.\n\n```js\nbody {\n  background-color: #f8f9fa;\n}\n```\n\n# 주요 컴포넌트 구축하기\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nFormComponent.tsx를 만들어보세요: 이 컴포넌트는 파일 업로드와 작업 URL 입력을 처리할 겁니다.\n\n```js\nimport React, { useState } from \"react\";\nimport apiClient from \"../services/apiClient\";\n\nconst FormComponent: React.FC = () =\u003e {\n  const [jobUrl, setJobUrl] = useState(\"\");\n  const [cvFile, setCvFile] = useState\u003cFile | null\u003e(null);\n  const [review, setReview] = useState\u003cstring | null\u003e(null);\n  const [adSource, setAdSource] = useState\u003cstring | null\u003e(null);\n  const [title, setJobTitle] = useState\u003cstring | null\u003e(null);\n  const [description, setJobDescription] = useState\u003cstring | null\u003e(null);\n  const [loading, setLoading] = useState(false);\n\n  const handleUrlChange = (e: React.ChangeEvent\u003cHTMLInputElement\u003e) =\u003e {\n    setJobUrl(e.target.value);\n  };\n\n  const handleFileChange = (e: React.ChangeEvent\u003cHTMLInputElement\u003e) =\u003e {\n    if (e.target.files) {\n      setCvFile(e.target.files[0]);\n    }\n  };\n\n  const handleSubmit = async (e: React.FormEvent) =\u003e {\n    e.preventDefault();\n    if (!jobUrl || !cvFile) {\n      alert(\"작업 URL과 이력서 파일을 모두 제공해주세요.\");\n      return;\n    }\n\n    const formData = new FormData();\n    formData.append(\"JobUrl\", jobUrl);\n    formData.append(\"CvFile\", cvFile);\n\n    setLoading(true);\n    try {\n      const response = await apiClient.post(\"/reviewcv\", formData, {\n        headers: {\n          \"Content-Type\": \"multipart/form-data\",\n        },\n      });\n\n      if (response.data.isSuccess) {\n        setReview(response.data.review);\n        setJobTitle(response.data.jobDetail.title);\n        setJobDescription(response.data.jobDetail.raw);\n        setAdSource(response.data.jobDetail.domain);\n      }\n    } catch (error) {\n      console.error(\"양식 제출 중 오류 발생:\", error);\n      alert(\"양식 제출 중 오류가 발생했습니다. 다시 시도해주세요.\");\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  return (\n    \u003cdiv className=\"container mt-5\"\u003e\n      \u003ch1 className=\"text-center mb-4\"\u003e이력서 리뷰어\u003c/h1\u003e\n      \u003cform onSubmit={handleSubmit}\u003e\n        \u003cdiv className=\"mb-3\"\u003e\n          \u003clabel htmlFor=\"jobUrl\" className=\"form-label\"\u003e\n            작업 광고 URL\n          \u003c/label\u003e\n          \u003cinput\n            type=\"url\"\n            className=\"form-control\"\n            id=\"jobUrl\"\n            value={jobUrl}\n            onChange={handleUrlChange}\n            required\n          /\u003e\n        \u003c/div\u003e\n        \u003cdiv className=\"mb-3\"\u003e\n          \u003clabel htmlFor=\"cvFile\" className=\"form-label\"\u003e\n            이력서 업로드\n          \u003c/label\u003e\n          \u003cinput\n            type=\"file\"\n            className=\"form-control\"\n            id=\"cvFile\"\n            accept=\".pdf,.doc,.docx\"\n            onChange={handleFileChange}\n            required\n          /\u003e\n        \u003c/div\u003e\n        \u003cbutton type=\"submit\" className=\"btn btn-primary\" disabled={loading}\u003e\n          {loading ? \"처리 중...\" : \"제출\"}\n        \u003c/button\u003e\n      \u003c/form\u003e\n      {review \u0026\u0026 (\n        \u003cdiv className=\"row mt-4\"\u003e\n          \u003cdiv className=\"col-md-6 pt-3 border\"\u003e\n            \u003ch2\u003e작업 세부 정보\u003c/h2\u003e\n            \u003cp\u003e\n              \u003cstrong\u003e작업 제목:\u003c/strong\u003e {title}\n            \u003c/p\u003e\n            \u003cp\u003e\n              \u003cstrong\u003e광고 출처:\u003c/strong\u003e {adSource}\n            \u003c/p\u003e\n            \u003cdiv\n              dangerouslySetInnerHTML={{ __html: description || \"\" }}\n              className=\"border\"\n            /\u003e\n          \u003c/div\u003e\n          \u003cdiv className=\"col-md-6 pt-3 border\"\u003e\n            \u003cdiv dangerouslySetInnerHTML={{ __html: review || \"\" }} /\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n      )}\n    \u003c/div\u003e\n  );\n};\n\nexport default FormComponent;\n```\n\n주 애플리케이션 컴포넌트 (App.tsx): 주 애플리케이션에 폼 컴포넌트를 통합해보세요\n\n```js\nimport React from 'react';\nimport FormComponent from './components/FormComponent';\n\nconst App: React.FC = () =\u003e {\n  return (\n    \u003cdiv className=\"App\"\u003e\n      \u003cFormComponent /\u003e\n    \u003c/div\u003e\n  );\n};\n\nexport default App;\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n액시오스 서비스를 만들어보세요: 코드 구조화와 재사용성을 위해 apiClient.tsx와 같은 서비스 파일에 API 호출을 중앙 집중화하세요.\n\n```js\nimport axios from 'axios';\n\nconst apiClient = axios.create({\n  baseURL: 'http://localhost:5000/api',\n  headers: {\n    'Content-Type': 'application/json'\n  }\n});\n\nexport default apiClient;\n```\n\n# 애플리케이션 테스트 및 실행\n\n개발 서버 실행: 프로젝트 루트 디렉토리 내에서 터미널에서 아래 명령어를 실행하여 리액트 개발 서버를 시작하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nnpm run dev\n```\n\n애플리케이션 테스트: 브라우저를 열고 http://localhost:5173 또는 터미널에서 제공된 엔드포인트로 이동합니다.\n\n![이미지](/assets/img/2024-05-17-BuildingaWebApplicationPoweredbyLargeLanguageModelsLLMpart2_1.png)\n\n작업 URL을 입력하고 이력서 파일을 업로드한 후 제출 버튼을 클릭하여 테스트해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-17-BuildingaWebApplicationPoweredbyLargeLanguageModelsLLMpart2_2.png\" /\u003e\n\n애플리케이션은 백엔드 서비스에 요청을 보내 작업 세부 정보와 이력서 검토를 가져옵니다.\n\n\u003cimg src=\"/assets/img/2024-05-17-BuildingaWebApplicationPoweredbyLargeLanguageModelsLLMpart2_3.png\" /\u003e\n\n# 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사에서는 React, TypeScript 및 Bootstrap을 사용하여 CV Reviewer 애플리케이션의 프론트엔드를 성공적으로 구축했습니다. 이 애플리케이션은 현대 웹 기술의 통합뿐만 아니라 백엔드 서비스 및 API를 활용하여 원활한 사용자 경험을 만드는 방법을 보여줍니다. 애플리케이션은 사용자 인증, 오류 처리 개선, 여러 이력서 검토용 대시보드 추가 또는 구직 지원서용 커버 레터 생성 기능과 같은 기능을 추가하여 향상 및 확장될 수 있습니다.","ogImage":{"url":"/assets/img/2024-05-17-BuildingaWebApplicationPoweredbyLargeLanguageModelsLLMpart2_0.png"},"coverImage":"/assets/img/2024-05-17-BuildingaWebApplicationPoweredbyLargeLanguageModelsLLMpart2_0.png","tag":["Tech"],"readingTime":7},{"title":"통계적 파워와 파워 분석 개요","description":"","date":"2024-05-17 20:47","slug":"2024-05-17-APrimeronStatisticalPowerandPowerAnalysis","content":"\n\n만약 내 경험이 너의 것과 비슷하다면, 너도 일할 때 '통계적 파워'에 대해 다양한 사람들이 이야기하는 것을 들어본 적이 있을 거야. 대부분의 경우, 이들 사람들은 더 큰 표본 크기를 주장하면서 보통 더 많은 n이 항상 좋다는 모호한 개념을 기반으로 이야기하는 것 같아.\n\n하지만 이들 중 얼마나 많은 사람이 실제로 '통계적 파워'가 무엇인지 정의할 수 있는지 알고 있을까? 이 기사에서는 통계적 파워의 개념과 정의를 살펴보고 이것이 측정 수단으로 어디에 유용한지 확인해보려고 해.\n\n## 가설 검정\n\n‘통계적 파워’라는 용어는 가설 검정을 할 때만 의미가 있어. 아마도 네가 기억할 수 있듯이, 가설 검정은 데이터 샘플의 통계적 특성을 사용해 그 샘플이 추출된 전체 모집단에 대한 진술의 확신 수준을 결정하는 것을 포함해. 예를 들어보자. 사람들 분석 데이터 R 패키지의 세일즈인 사원들의 데이터 셋은 기술 회사의 샘플 세일즈인들의 데이터를 포함하고 있어, 이들의 연간 매출액(천 달러)과 최근에 증가하는 순서 척도의 평가 등급을 포함하고 있어. 처음 몇 행을 살펴보자.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```R\nlibrary(peopleanalyticsdata)\nsalespeople \u003c- salespeople[complete.cases(salespeople), ]\nhead(salespeople)\n\n##          promoted sales customer_rate performance\n## 1        0        594   3.94          2\n## 2        0        446   4.06          3\n## 3        1        674   3.83          4\n## 4        0        525   3.62          2\n## 5        1        657   4.40          3\n## 6        1        918   4.54          2\n```\n\n이제 이 문장을 살펴봅시다. 최상위 성과 영업 사원의 평균 매출액은 전체 인구의 최하위 성과 영업 사원들과 다를 수 있다는 것입니다. 이 문장을 검증하기 위해, 우리는 최상위 성과자와 최하위 성과자의 평균 매출액이 동일하다고 가정하고, 이를 귀무 가설이라고합니다. 그런 다음 귀무 가설이 전체 인구에서 사실일 때 샘플이 보이는 방식의 최대 확률을 설정하기 위해 테스트를 수행하고, 이를 테스트의 p값이라고합니다. 이 경우, 균등한 분산을 가진 두 샘플을 비교하기 위해 Welch의 t-테스트를 수행합니다.\n\n```R\n# 최상위 성과자의 매출\nsales4 \u003c- salespeople$sales[salespeople$performance == 4]\n\n# 최하위 성과자의 매출\nsales1 \u003c- salespeople$sales[salespeople$performance == 1]\n\n# 두 평균이 동일하다는 귀무 가설의 p값\nt.test(sales4, sales1)$p.value\n\n## 1.093244e-05\n```\n\n위 결과는 만일 우리의 귀무 가설이 전체 인구에서 사실이라면, 우리의 샘플이 보이는 방식은 매우 잘 나타나지 않을 가능성이 있다는 것을 의미합니다. 우리는 귀무 가설을 기각하기로 합의하는 확률 수준을 정의하고, 이를 알파로 알려집니다. 종종 알파 값은 0.05이지만, 때로는 더 낮을 수도 있습니다. 여기서 알파 값을 0.05로 설정하면, 귀무 가설을 편안하게 기각하고 대립 가설을 결론 내리게 됩니다 — 즉, 인구에서 낮은 성과자와 높은 성과자 간 평균 매출액에 차이가 있다는 것입니다. 알파 값을 0.05로 선택함으로써, 평균적으로 20번 중 1회 틀린 결론을 내리게 될 것이라는 것을 유의하십시오. 가설 검정은 확률에 관한 것이며, 확신에 관한 것이 아닙니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 통계적 유의성 정의\n\n우리는 가설 검정이 우리가 존재하는 모집단의 차이를 결론 내릴만큼 충분히 확신하는 수준에 대한 것임을 알 수 있습니다. 이는 우리가 그 모집단의 샘플만을 관측할 수 있다는 것을 인정하는 것입니다. 본질적으로 미 관측 모집단에 대해 100% 확실한 것은 없으며, 따라서 네 가지 경우가 발생할 수 있습니다:\n\n- 귀무 가설이 모집단에 대해 사실이고, 그것이 샘플을 기반으로 기각되지 않음\n- 귀무 가설이 모집단에 대해 사실이고, 그것이 샘플을 기반으로 기각됨 (1종 오류)\n- 귀무 가설이 모집단에 대해 부정하고, 그것이 샘플을 기반으로 기각되지 않음 (2종 오류)\n- 귀무 가설이 모집단에 대해 부정하고, 그것이 샘플을 기반으로 기각됨\n\n통계적 유의성은 4번과 관련이 있습니다 — 이는 모집단에 대해 거짓이라는 것이 주어졌을 때 샘플을 기반으로 귀무 가설이 기각될 확률입니다. 직관적으로, 이는 샘플의 크기, 실제(미관측) 모집단의 차이(적절히 정규화된), 그리고 귀무 가설을 기각하는 확신의 수준(알파)에 따라 달라집니다. 예를 들어 실제 모집단의 차이가 더 클 경우, 더 작은 샘플에서 확인할 수 있습니다. 알파가 작을 경우, 더 큰 모집단 차이나 더 높은 'n'이 필요할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 방에 있는 코끼리는 물론 우리는 인구 차이를 결코 알 수 없을 것입니다. 우리는 우리 샘플의 차이만을 알고 있습니다. 따라서 보통 우리는 우리 샘플에서 관측된 통계적인 파워를 만족시키고 자신을 다스립니다. 여기서 우리의 영업사원 예시를 들어 보면, 이것이 t-검정이기 때문에 우리는 Cohen의 효과 크기 d를 정규화된 관측된 차이로 사용합니다. 이를 샘플 크기와 알파 0.05와 결합하여 우리의 가설 검정을 위한 통계적인 파워를 0.996로 계산할 수 있습니다. 우리는 귀무가설이 정확하게 기각될 것이라고 매우 확신할 수 있습니다.\n\n```js\nlibrary(effectsize)\nlibrary(WebPower)\n\n# sample sizes\nn4 \u003c- length(sales4)\nn1 \u003c- length(sales1)\n\n# cohen's effect size d\nd \u003c- cohens_d(sales4, sales1)$Cohens_d\n\n# statistical power\nwp.t(n4, n1, d = d, type = \"two.sample.2n\")\n\n\n## Unbalanced two-sample t-test\n##\n## n1 n2         d alpha    power\n## 55 60 0.8741483 0.05     0.996347\n```\n\n## 통계적인 파워를 사용하는 경우\n\n솔직히 말해서 그렇게 자주 사용되지는 않습니다. 당신이 샘플들과 데이터들을 가지고 이미 가설 테스트를 진행한 상황에서, 통계적인 파워는 실제로 단지 얼마나 잘 알파 바를 넘어섰는지를 나타내는 지표일 뿐입니다. 알파가 덜 엄격할수록 파워가 높아집니다. 한번 확인해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```r\nlibrary(ggplot2)\n\n# 통계적 파워\ntest \u003c- WebPower::wp.t(n4, n1, d = d, type = \"two.sample.2n\", \n                       alpha = seq(0.05, 0.0001, by = -0.0001))\n\ntest_df \u003c- data.frame(\n  Alpha = test$alpha,\n  Power = test$power\n)\n\n\n# 알파에 대한 파워 플롯\nggplot(test_df, aes(x = Alpha, y = Power)) +\n  geom_point(color = \"pink\") +\n  theme_minimal()\n```\n\n\u003cimg src=\"/assets/img/2024-05-17-APrimeronStatisticalPowerandPowerAnalysis_0.png\" /\u003e\n\n샘플 데이터를 가져오지 않았거나 가설 검정을 수행하지 않았다면, 실험이나 연구를 계획 중이고 많은 작업이 필요한 경우 통계적 파워는 도움이 될 수 있습니다. 샘플 크기가 역할을 하기 때문에 이론적으로 특정 알파 기준을 달성하기 위한 최소 샘플 크기를 계산할 수 있습니다.\n\n하지만 실제로는 관측된 효과 크기를 알아야 하는데, 물론 아직 실험을 실행하지 않았기 때문에 알 수가 없습니다. 따라서 통계적 파워 계산에서 나오는 대부분의 샘플 크기 추정은 민감도 범위의 형태를 취하는 경향이 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n실험은 조직하고 자원을 조달하기 어려울 수 있으며, 통계적 파워는 필요한 규모를 결정하는 데 도움이 될 수 있습니다. 또한 샘플 크기를 테스트할 때 중요한 부분에서 추가적인 n이 파워에 큰 영향을 미치지 않는 지점이 있는지 보여줄 수도 있습니다. 예를 들어, 중간 효과 크기와 알파 0.05를 가진 쌍체 t-테스트에서 여러 샘플 크기 범위를 시험하면, 추가적인 n이 파워에 큰 차이를 만들지 않는 시점을 볼 수 있습니다.\n\n```js\n# 여러 샘플 크기를 테스트\nsample_sizes \u003c- 20:100\npower \u003c- wp.t(n1 = sample_sizes, d = 0.5, type = \"paired\")\n\npower_df \u003c- data.frame(\n  n = power$n,\n  Power = power$power\n)\n\n# 샘플 크기에 따른 파워 플롯\nggplot(power_df, aes(x = n, y = Power)) +\n  geom_point(color = \"lightblue\") +\n  theme_minimal()\n```\n\n\u003cimg src=\"/assets/img/2024-05-17-APrimeronStatisticalPowerandPowerAnalysis_1.png\" /\u003e\n\n전반적으로, 통계적 파워는 총명치인 도구입니다. 이것은 주로 실험 디자인과 관련된 특정 상황에서만 유용한 가설 검정의 '볼트온'으로 생각할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 통계적 역량 및 검정 및 회귀 모델에서 사용되는 다양한 통계에 대해 더 자세히 탐구하고 싶다면, People Analytics의 Handbook of Regression Modeling의 11장을 확인해보세요.\n\n![이미지](/assets/img/2024-05-17-APrimeronStatisticalPowerandPowerAnalysis_2.png)","ogImage":{"url":"/assets/img/2024-05-17-APrimeronStatisticalPowerandPowerAnalysis_0.png"},"coverImage":"/assets/img/2024-05-17-APrimeronStatisticalPowerandPowerAnalysis_0.png","tag":["Tech"],"readingTime":6},{"title":"새로운 langchain_huggingface 라이브러리 만들면서 배우기","description":"","date":"2024-05-17 20:46","slug":"2024-05-17-ExploringtheNewlangchain_huggingfacelibraryAHands-OnExperiment","content":"\n\n\u003cimg src=\"/assets/img/2024-05-17-ExploringtheNewlangchain_huggingfacelibraryAHands-OnExperiment_0.png\" /\u003e\n\n# 배경\n\n최근에 Langchain과 HuggingFace가 함께 새로운 파트너 패키지를 발표했습니다. Langchain은 이미 커뮤니티에서 유지보수되는 HuggingFace 패키지를 보유하고 있었지만, 이 새로운 버전은 HuggingFace가 Langchain의 파트너로 공식 지원하는 것입니다! Langchain은 다양한 LLM과 상호 작용하기 위한 공통 인터페이스를 제공하며, HuggingFace는 오픈 소스 모델을 포함한 호스팅된 LLM에 대한 추론 엔드포인트를 제공합니다.\n\n이 블로그에서는 HuggingFace의 오픈 소스 모델의 추론을 이 새로운 Langchain 라이브러리로 사용하는 내 경험을 공유하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# TL;DR\n\n직접 시도해 보고 싶다면, 아래 저장소를 클론해보세요:\n\n# 실험\n\n## HuggingFace를 통한 추론 옵션\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nHuggingFace에서 추론을 수행하는 세 가지 방법이 제공됩니다:\n\n- UI를 통해 직접: 각 모델에 대한 채팅 위젯이 제공됩니다. Meta의 LLAMA 모델과 같은 목록에서 모델을 선택할 수 있습니다.\n- (무료) 추론 API (서버리스): 이 옵션은 최소한의 테스트에 적합합니다. HuggingFace의 공유 인프라를 사용하므로 요율 제한이 적용됩니다. API 키로 계정 설정에서 액세스 토큰을 사용합니다. 이 옵션을 사용하여 Langchain 라이브러리를 시도해 볼 것입니다.\n- (유료) 추론 엔드포인트 (전용 API): 제품 사용에 적합하지만, 이번 실험에서는 배포하고 이 옵션을 사용하지 않을 것입니다.\n\n## Langchain_HuggingFace 라이브러리\n\n이 라이브러리는 HuggingFace LLMs와 상호 작용하기 위해 두 가지 클래스를 노출합니다: HuggingFacePipeline 및 HuggingFaceEndpoint.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 원격 추론을 가능하게 하는 HuggingFaceEndpoint를 사용하는 것에 관심이 있습니다. 이 클래스의 내부에서는 InferenceClient를 사용합니다. 특정 모델의 경우, 해당 모델의 HuggingFace 페이지(예: Meta의 LLAMA)에서 해당 모델의 약관에 동의해야 사용할 수 있습니다. HuggingFacePipeline은 모델을 로컬로 다운로드해야 하기 때문에 특정 이유가 없는 이상 이상적이지 않습니다.\n\nHuggingFaceEndpoint 클래스를 인스턴스화한 후, 몇 가지 langchain.schema 메시지를 정의합니다. 이 라이브러리에서 또 한 가지 중요한 클래스는 ChatHuggingFace 클래스인데, 이는 특정 모델에 따라 특별 토큰으로 프롬프트를 향상시킵니다. 또한 사용된 토큰과 같은 모델 메타데이터를 응답에 추가하여 Langchain이 약속한 응답의 일관성을 보장합니다.\n\n이 실험을 위해 작성한 코드를 확인해보세요!\n\n## 전반적인 인상\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n라이브러리는 작업 중인 것 같아서 전반적인 경험은 원활하지 않았어요. 여기 몇 가지 구체적인 문제가 있었어요:\n\n- 오래된 독스트링: IDE의 클래스 독스트링이 최신으로 업데이트되지 않았어요.\n\n![2024-05-17-ExploringtheNewlangchain_huggingfacelibraryAHands-OnExperiment_1.png](/assets/img/2024-05-17-ExploringtheNewlangchain_huggingfacelibraryAHands-OnExperiment_1.png)\n\n2. 불완전한 문서화: Langchain의 문서가 최신으로 업데이트되지 않아서 아마도 Langchain v0.2에서 업데이트 예정일 것 같아요. 그들의 공지를 따라서 사용하면 분명히 작동하지 않을 거에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3. 비기능적 매개변수: 몇 가지 매개변수는 모델 응답에 영향을 미치지 않거나 오류를 발생시킵니다.\n\n```js\nllm = HuggingFaceEndpoint(\n    repo_id=LLAMA_INSTRUCT,  # endpoint_url을 사용하는 경우 model_id도 제공해야 함. ChatHuggingFace에서 model_id는 repo_id만큼 영향을 미침\n    task=\"text-generation\",\n    streaming=True,\n    max_new_tokens=1024,  # 출력 길이에 영향을 주는 것 같지 않음\n    model=\"\",  # 이 필드는 필수이지만 출력에는 영향을 미치지 않음, repo_id만 영향 있음\n    client=None,\n    async_client=None,\n    return_full_text=True,\n    repetition_penalty=1.1,\n    cache=False,\n    do_sample=False,\n)\n```\n\n# 결론 및 가능한 향후 작업\n\n그들의 발표는 다음과 같이 마무리되었습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 실험이 가치 있는 피드백으로 작용하기를 희망하며, Langchain 저장소에 이슈를 만들 계획입니다. 이 실험을 통해 HuggingFace의 무료 OSS LLM 추론 및 그 Langchain 통합 라이브러리 상태에 대해 더 나은 이해를 얻을 수 있었습니다.\n\n향후 실험에서는 이 예시를 따라 에이전트를 만들고자 합니다. 제 다음 블로그 포스트를 기대해 주세요!","ogImage":{"url":"/assets/img/2024-05-17-ExploringtheNewlangchain_huggingfacelibraryAHands-OnExperiment_0.png"},"coverImage":"/assets/img/2024-05-17-ExploringtheNewlangchain_huggingfacelibraryAHands-OnExperiment_0.png","tag":["Tech"],"readingTime":3},{"title":"CodeLlama vs CodeGemma, AI 코딩 어시스턴스에 오픈 모델 활용하기","description":"","date":"2024-05-17 20:44","slug":"2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance","content":"\n\n\u003cimg src=\"/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_0.png\" /\u003e\n\nAI 코딩 도구 시장은 수십억 달러의 산업입니다. 2030년까지 172억 달러에 이를 것으로 예상되며, 현재에도 VS Code 또는 JetBrains IDE용 AI 플러그인은 수백만 번 다운로드되었습니다. 하지만 무료 코딩 도우미로 로컬 모델을 실행할 수 있을까요? 그리고 그 성능은 어떨까요? 이 기사에서는 두 개의 오픈 모델, Code Gemma와 Code Llama를 테스트해 보겠습니다. 제 PC에 설치하고, 그들이 어떻게 작동하는지 확인할 것입니다.\n\n더 이상의 말이 필요 없으니, 시작해 봅시다!\n\n## 1. 모델들\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n본문 작성 시점에서 코딩 목적으로 두 가지 주요 오픈 모델이 무료로 다운로드할 수 있으며 사용할 수 있습니다:\n\n- CodeLlama. 이 모델은 2023년 Meta에서 출시되었으며, 7B, 13B, 34B, 70B 크기로 제공됩니다. \"Base\", \"Instruct\", \"Python\" 모델을 사용할 수 있습니다. 4가지 크기이지만, 로컬에서 실제로 사용할 수 있는 것은 7B 및 13B 모델뿐입니다; 다른 크기는 너무 \"무겁습니다.\"\n- CodeGemma. 이 모델은 2024년 Google에서 출시되었으며, 2B 및 7B 크기로 제공됩니다. 2B 모델은 코드 완성을 위해 훈련되었으며, 7B 모델은 코드 채움 및 자연어 프롬프트를 위해 훈련되었습니다.\n\n본문에서는 HuggingFace에서 제공되며 GGUF 형식으로 다운로드할 수 있는 7B 및 13B 모델을 테스트할 것이며, 이를 사용하여 다양한 앱에서 이 모델들을 사용할 수 있도록 OpenAI 호환 로컬 서버를 실행할 것입니다. 그러나 이를 수행하기 전에 단순히 모델을 Python으로 실행하여 무엇을 할 수 있는지 살펴보겠습니다. 실제 사용으로 넘어가고 싶은 독자분들은 이 부분을 건너뛸 수 있습니다.\n\n두 모델을 테스트하기 위해 Google Colab 인스턴스를 무료로 사용할 것입니다. 먼저, 모델과 토크나이저를 로드해보겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nimport transformers\nimport torch\n\n\nmodel_id = \"...\"\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=False,\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    quantization_config=bnb_config,\n    device_map=\"cuda\",\n    torch_dtype=torch.bfloat16,\n)\n```\n\nHuggingFace의 Transformers 라이브러리는 모델 파일을 자동으로 다운로드해줍니다. 7B 모델은 약 16.2 GB의 GPU RAM을 필요로 하지만, bits and bytes 라이브러리를 활용하여 4비트 해상도로 모델을 실행하면 필요한 메모리 용량은 약 5GB 정도로 줄어듭니다.\n\n이제 모델을 테스트하기 위한 코드 조각을 만들어 봅시다. 예를 들어, 문자열 목록을 파일에 작성하는 Python 메서드를 작성해보겠습니다:\n\n```python\npython_code = \"\"\"\nclass Writer:\n   def write_file(self, filename: str, data: List[str]):\n        \\\"\\\"\\\" Write list of strings to a text file \\\"\\\"\\\"\n        with open(filename, 'w') as f_out:\n            for line in data:\n                f_out.write(f\"{line}\\n\")\n\"\"\"\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델의 코딩 능력을 테스트하기 위해, 두 모델에게 \"pytest\"를 만들도록 요청해보겠습니다:\n\n```js\nchat = [{\n    \"role\": \"user\",\n    \"content\": f\"이 파이썬 메소드에 대한 pytest를 작성해주세요:\\n{python_code}. \"\\\n               f\"테스트가 끝나면 생성된 파일을 삭제하세요.\"\n    }]\n\n\nprompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\ninputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\noutputs = model.generate(input_ids=inputs.to(model.device), max_new_tokens=1024)\nresult = tokenizer.decode(outputs[0])\n```\n\n결과적으로, CodeLlama 7B가 이 코드를 생성했고, 이 과정은 19초가 걸렸습니다:\n\n```js\nimport pytest\n\n\nclass TestWriter:\n    def test_write_file(self):\n        writer = Writer()\n        filename = 'test.txt'\n        data = ['line1', 'line2', 'line3']\n        writer.write_file(filename, data)\n        with open(filename, 'r') as f:\n            lines = f.readlines()\n            assert lines == data\n        os.remove(filename)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nCodeGemma이 이 코드를 생성했고, 프로세스에는 16초가 걸렸어요:\n\n```js\nimport pytest\n\n\ndef test_write_file():\n    \"\"\" write_file 메소드를 테스트함 \"\"\"\n    filename = \"test.txt\"\n    data = [\"This is a test\", \"line 2\", \"line 3\"]\n    Writer().write_file(filename, data)\n\n    with open(filename, \"r\") as f:\n        assert f.read() == \"This is a test\\nline 2\\nline 3\\n\"\n\n    import os\n    os.remove(filename)\n```\n\n개인적으로, 저는 두 번째 버전을 선호해요. 첫째, CodeGemma가 메소드의 설명을 나타내는 docstring을 제공했고, 이는 현대적인 \"linter\" 도구의 요구 사항이에요. 둘째, Writer().write_file(...) 코드는 writer 변수를 선언하고 나중에 사용하는 것보다 더 간결하고 가독성이 좋아 보여요. 셋째, CodeGemma는 \"os\" 파이썬 모듈을 가져왔는데, CodeLlama는 이를 \"잊어버렸어요\".\n\n첫눈에는 두 코드 조각이 모두 올바르게 보여요. pytest -v file.py 명령을 실행하여 코드를 실행해 보겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\u003cimg src=\"/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_1.png\" /\u003e\n\n실제로 두 테스트의 정확성에 대해 잘못 이야기 했었고, 첫 번째 테스트에 버그가 있습니다. 재미있게도, 두 번째 테스트는 뿐만 아니라 더 나은 모습을 하고 있으며, 작동하기도 합니다. 그 반면 첫 번째는 작동하지 않습니다. 스크린샷에서 오류는 명백합니다. 독자들은 자신의 힘으로 어떻게 수정할지 찾아보세요.\n\n처음에는 CodeGemma 2B \"코드 완성\" 모델을 테스트할 계획이 없었지만, 독자들을 위한 추가 혜택으로 해보자구요! 모델을 로드하는 방법은 동일합니다. 오직 모델 ID만 바꾸면 됩니다:\n\n```js\nmodel_id = \"google/codegemma-2b\"\nmodel = AutoModelForCausalLM.from_pretrained(model_id, ...)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 코드 완성을 위해 훈련된 모델입니다. 영어 설명이 없어도 되며, 소스 코드만 제공하면 됩니다:\n\n```js\n# Prompt\npython_code = \"\"\"\nclass Writer:\n   def write_file(self, filename: str, data: List[str]):\n      ...\n\nimport pytest\n\ndef test_write_file():\n    \\\"\\\"\\\"\\ Test the write_file method \\\"\\\"\\\"\n\"\"\"\n\nprompt = f\"\"\"\n\u003c|fim_prefix|\u003e{python_code}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리가 볼 수 있듯이 해당 코드는 \"그대로 사용\"되지 않을 것입니다. 하지만 논리는 올바른 것으로 보입니다. 필요한 수정은 assert 라인을 올바르게 포맷하는 것입니다:\n\n```js\nassert lines == [\"Hello\\n\", \"World\\n\"]\n```\n\n이후에 \"pytest\"가 통과되었습니다. 모델은 테스트 이후 파일을 제거하지 않았지만, 나는 프롬프트에서 그것을 요청하지 않았습니다. 마지막으로, 소형 모델의 실행 시간은 단지 3.3초로, 더 큰 모델과 비교했을 때 약 5배 빠릅니다.\n\n## 2. 람마 서버 실행\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 파이썬에서 모델을 테스트했고, 이제 로컬 OpenAI 호환 서버를 실행해볼 차례입니다. 이를 위해 Llama-cpp-python을 사용할 거예요. 이 프로젝트는 멋지고 가벼워요. 한 줄의 명령어로 우리가 원하는 어떤 모델이든 실행할 수 있어요:\n\n```js\n# 코드 Gemma\npython3 -m llama_cpp.server --model codegemma-7b-it-Q4_K_M.gguf --n_ctx 8192 --n_gpu_layers -1 --host 0.0.0.0 --port 8000\n\n# 코드 Llama 7B\npython3 -m llama_cpp.server --model codellama-7b-instruct.Q4_K_M.gguf --n_ctx 8192 --n_gpu_layers -1 --host 0.0.0.0 --port 8000\n\n# 코드 Llama 13B\npython3 -m llama_cpp.server --model codellama-13b-instruct.Q4_K_M.gguf --n_ctx 8192 --n_gpu_layers -1 --host 0.0.0.0 --port 8000\n```\n\n모델을 로드할 GPU RAM이 충분하지 않으면, n_gpu_layers 매개변수를 변경하여 GPU에 일부 레이어만 로드할 수 있어요. 또한 Apple Silicon이나 심지어 CPU에서 모델을 실행할 수도 있지만 물론 느릴 거예요.\n\n## 3. 앱들\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금은 로컬 OpenAI 호환 서버가 있으며 몇 가지 앱을 테스트할 준비가 되어 있습니다!\n\n### 3.1 AI Shell\n\nAI Shell은 자연어 프롬프트를 콘솔 명령어로 변환할 수 있는 오픈 소스 앱입니다. 이 앱은 꽤 인기가 있으며 작성 당시 프로젝트는 GitHub에서 3.6K개의 스타를 받았습니다. AI Shell은 TypeScript로 작성되었으며 npm 패키지 관리자를 통해 이 앱을 설치할 수 있습니다 (저는 여기서 Node JS 20.13.0도 설치했습니다):\n\n```js\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\nnvm install v20.13.0\nnpm install -g @builder.io/ai-shell\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n앱을 실행하기 전에 API 엔드포인트를 구성해야 합니다:\n\n```js\nai config set OPENAI_KEY=12345678\nai config set OPENAI_API_ENDPOINT=http://127.0.0.1:8000/v1\n```\n\n이제 콘솔에서 \"ai chat\" 명령을 입력하여 언제든지 모델과 대화를 시작할 수 있습니다:\n\n![대화 모델](https://miro.medium.com/v2/resize:fit:1400/1*9zJpuyFx_-HW4AZ4b9ZH8A.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프로그램을 사용하는 또 다른 방법은 실행하려는 명령어를 입력하는 것입니다. 예를 들어, \"현재 폴더에 있는 파일 표시\"와 같은 내용을 입력할 수 있어요:\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*4PElpWscaef11mHRzCdZ5Q.gif)\n\n안타깝게도 무료 7B 모델로는 작동하지 않았고, 모델이 올바른 쉘 명령어를 생성하지 못했어요. 또한 프롬프트 안에 있는 \"스크립트\"라는 단어가 모델을 혼란스럽게 만들었고, 영화 대본과 관련된 텍스트를 생성했어요.\n\n이 문제는 아마도 프롬프트를 조정하여 해결할 수 있겠죠. 그러나 이 텍스트를 작성할 때에는 프롬프트가 TypeScript 소스에 하드코딩되어 있어 쉽게 구성할 수 없었어요. 아직까지 GitHub에서 제 기능 제안에 응답한 사람이 없지만, 향후 개선될 것을 희망해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3.2 ShellGPT\n\nShellGPT는 이 텍스트를 작성하는 시점에서 GitHub에서 8.3K개의 스타를 가진 또 다른 흥미로운 오픈소스 프로젝트입니다. 우리는 다음과 같이 pip를 사용하여 쉽게 응용 프로그램을 설치할 수 있습니다:\n\n```js\npip3 install shell-gpt\n```\n\n로컬 모델과 함께 ShellGPT를 사용하려면 ~/.config/shell_gpt/.sgptrc 파일에서 API 엔드포인트를 변경해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nAPI_BASE_URL=http://127.0.0.1:8000/v1\nOPENAI_API_KEY=12345678\n```\n\n그럼 이제 우리는 이전 앱과 거의 같은 방식으로 터미널 쉘에 직접 요청을 입력할 수 있어요:\n\n```js\nsgpt \"로컬 파일을 표시하는 명령어를 작성해주세요\"\n```\n\n안타깝게도, CodeGemma 모델은 ShellGPT에서 작동하지 않았고, LlamaCpp 서버는 Server 500 오류를 반환했어요: '시스템 역할이 지원되지 않음'. 처음에는 LlamaCpp 문제인 줄 알았지만 로그를 확인한 후에는 모델 메타데이터에 이런 라인이 있는 것을 보았어요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n{ if messages[0]['role'] == 'system' }\n  { raise_exception('시스템 역할은 지원되지 않습니다')\n```\n\n코드젬마가 \"시스템\" 역할을 지원하지 않는 것은 안타깝습니다. 왜냐하면 OpenAI API에서 널리 사용되기 때문입니다. 따라서 OpenAI 호환 앱은 코드젬마를 사용할 수 없습니다. 이전에 보았던 것처럼, 코드젬마가 생성한 코드는 꽤 좋았기 때문에 아쉽습니다.\n\n코드람마에 대한 셸GPT는 잘 작동합니다:\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*N6gwsFM7ZNt7OW2sZcaNZg.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n터미널 셸에서 '—shell' 접두어를 지정하여 명령을 직접 실행하는 기능이 편리합니다.\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*xTTNTI0Ykh8NGuqkIpwLVg.gif)\n\n더 개선할 공간이 있습니다. 예를 들어, \"문서 폴더의 크기 표시하기\" 프롬프트에 대한 du -sh ~/Documents 응답이 반환됩니다. 이것은 올바른 bash 명령어입니다. 그러나 ShellGPT는  문자열에서 해당 명령을 가져오지 못했고 \"명령을 찾을 수 없음\" 오류만 받았습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nbash 명령어를 사용하는 것도 유용하지만, 실제 코딩 지원은 어떨까요? 오픈소스 CodeGPT 플러그인을 통해 이를 할 수 있어요. 먼저, PyCharm IDE에 플러그인을 설치하고 LlamaCpp와 함께 사용할 수 있도록 설정했어요:\n\n![CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance](/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_2.png)\n\n예를 들어, 다음과 같은 Python 클래스를 고려해봅시다:\n\n```js\nclass ServerConnection:\n    \"\"\" Server connection handling \"\"\"\n\n    def __init__(self):\n        self.is_connected = False\n        self.connection_time = -1\n        self.uploads_total = 0\n        self.reconnects_total = 0\n        self.reconnect_threshold_sec = 64\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 모델에게 변수를 따로 Python 데이터 클래스로 리팩터링하도록 요청할 것입니다.\n\n결과적으로 CodeGemma는 이를 수행하지 못했으며 \"시스템 역할을 지원하지 않음\"이라는 오류가 발생했습니다. CodeLlama 7B는 작업을 완료할 수 없었고 대신에 데이터 클래스 대신 표준 클래스를 생성했습니다. 반면에 CodeLlama 13B는 잘 수행했습니다:\n\n![이미지](/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_3.png)\n\n다음 단계로, 더 복잡한 내용을 요청하고 텍스트 필드와 버튼 프롬프트가 있는 UI Python 애플리케이션을 만들어보았습니다. Llama 13B 모델이 이 코드를 생성했습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nimport tkinter as tk\n\n# 메인 창 생성\nroot = tk.Tk()\nroot.title(\"Hello World\")\nroot.geometry(\"320x200\")\n\n# 텍스트 필드 생성\ntext_field = tk.Entry(root)\ntext_field.pack()\n\n# 버튼 생성\nbutton = tk.Button(root, text=\"Click Me!\", command=lambda: print(\"You clicked the button!\"))\nbutton.pack()\n\n# 메인 루프 시작\nroot.mainloop()\n``` \n\n코드는 올바르지만, 애플리케이션 창이 보이지 않았습니다. 크기가 지정되지 않았습니다. 나는 모델에게 제목을 \"Hello World\"로 변경하고 창 크기를 320x200으로 설정하도록 요청했습니다: \n\n\u003cimg src=\"/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_4.png\" /\u003e\n\n결과가 적절하게 나와 요청한 애플리케이션이 예상대로 작동했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_5](/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_5.png)\n\n저는 13B 모델이 완벽하지 않다는 것을 인정해야합니다. 이론적으로는 큰 컨텍스트 창과 이전 채팅 결과를 사용해야 하지만, 제가 모델에게 생성된 코드를 클래스로 이동하도록 요청했을 때 창 크기나 제목을 설정하지 않은 새로운 코드를 생성했습니다:\n\n```js\nimport tkinter as tk\n\nclass HelloWorld(tk.Frame):\n    def __init__(self, master=None):\n        super().__init__(master)\n        self.pack()\n\n        # 텍스트 필드 생성\n        self.text_field = tk.Entry(self)\n        self.text_field.pack()\n\n        # 버튼 생성\n        self.button = tk.Button(self, text=\"Click Me!\", command=lambda: print(\"Button clicked!\"))\n        self.button.pack()\n\n\nif __name__ == \"__main__\":\n    root = tk.Tk()\n    app = HelloWorld(root)\n    root.mainloop()\n```\n\n하지만 일반적으로 말하자면, 모델이 정확한 클래스를 생성했으며 조금의 복사 붙여넣기로 작업을 완료하는 것이 쉬웠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 4. 단점\n\n지금까지 모든 예시를 통해 모델이 작동하는 것을 확인할 수 있습니다; 코드와 bash 명령을 모두 생성할 수 있습니다. 그러나 몇 가지 단점과 문제점도 있습니다:\n\n- 로컬 LLM 인스턴스를 사용하려면 좋은 그래픽 카드가 필요합니다. 저는 2.5년 전에 구매한 8GB GPU RAM을 갖춘 GeForce RTX 3060 카드를 사용하고 있습니다. Colab 테스트에서는 8 GB가 7B 모델을 실행하는 데 충분하다는 것을 확인했지만, 실제 데스크탑에서는 그 용량이 부족했습니다. OS 자체도 일부 GPU를 필요로 하기 때문입니다. 실제로 13B 모델을 실행하려면 적어도 16 GB의 GPU RAM이 필요하며, 미래 개선을 위한 여유 공간으로 24 GB가 필요합니다. 현실적으로 고려할만 한가요? 현재 GPU 가격을 고려할 때, 1000-1500달러에는 AI 구독을 여러 년간 할 수 있습니다.\n- 오픈 소스 앱은 완벽하지 않습니다. 제 테스트에서 LlamaCpp 서버는 때로 \"segmentation fault\"와 함께 충돌하고, CodeGPT 앱은 때로는 모델에 요청을 전송하지 않았고, PyCharm을 재시작해야 했고 등등 발생했습니다. 이것은 오픈 소스이며 어떤 종류의 보장도 없으므로 불평할 것이 아니지만, 이러한 AI 도구들에 대해서는 아직 \"초기 채택\" 단계에 있다는 것을 인정해야 합니다.\n- 또한 대형 로컬 언어 모델 실행은 에너지를 많이 소비하는 작업입니다. 마지막 테스트로 내 데스크톱 PC에 전력계를 연결했습니다. 평상시에는 약 80 와트를 소비하는 것으로 나타났습니다. 하지만 LLM 요청이 실행될 때는 에너지 소비량이 거의 3배 증가합니다: \n\n![이미지](/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_6.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 결론\n\n본 기사에서는 오픈 언어 모델이 코딩 어시스턴트로서 작동하는 능력을 테스트하였고, 결과는 흥미로웠습니다:\n\n- 작은 7B 및 13B 모델조차도 리팩토링, 단위 테스트 생성 또는 작은 코드 템플릿 작성과 같은 일부 코딩 작업을 수행할 수 있습니다. 물론, 이러한 모델들은 175B ChatGPT 3.5와 같이 큰 모델에 비해 능력이 떨어지지만, 로컬 모델을 사용하는 것은 구독 비용이 필요하지 않을 뿐만 아니라, 개인 정보 관점에서 빠르고 효율적일 수도 있습니다.\n- 반면에 로컬 모델을 실행하려면 고사양의 하드웨어가 필요하며, 이는 비용 부담뿐만 아니라 에너지 소모도 초래할 수 있습니다. 본 기사 작성 시, 고사양 GPU는 최대 $1500에 이를 수 있으며, 이는 로컬 LLMs만 실행하기에는 현실적이지 않습니다 — 해당 비용으로 클라우드 서비스 구독을 매우 오랜 기간 동안 이용할 수 있습니다.\n- AI 도구를 사용하는 도전 과제는 하드웨어뿐만 아니라 소프트웨어에도 있습니다. 최소한 본 게시물 작성 시점에는 AI 소프트웨어의 오픈 소스 생태계가 아직 미성숙한 것으로 나타났습니다. HuggingFace에서 39,769개의 오픈 7B 모델을 발견했으나 GitHub에서의 오픈 소스 AI 앱 수는 미미합니다. 이 기사에서 설명한 3가지가 거의 제가 찾아낸 전부였습니다 (만약 놓친 것이 있다면, 아래 댓글에 쓰거나, 추가 리뷰를 진행할지도 모릅니다).\n\n일반적으로 일상적인 코딩 작업에 로컬 LLM을 사용하는 것은 가능하지만, 소프트웨어와 하드웨어 모두에서 여전히 많은 도전 과제가 있음을 알 수 있습니다. 더 나은 AI 칩 및 효율적인 모델을 위해 노력하고 있는 다른 기업들이 있음도 알고 있습니다. Microsoft의 Phi-3와 같은 새로운 모델은 이제 모바일 하드웨어에서도 작동할 수 있습니다. 그것이 AI 산업을 어떻게 바꿀지 어떻게 알 수 있을까요? 다음 세대의 통합 그래픽 카드는 저렴하고 조용하며 CUDA 호환될 것인가요? 아직 모릅니다. 분명히 새로운 AI 관련 하드웨어가 발표될 것이며 (M4가 이미 첫 번째였습니다), 적어도 오픈 사용을 위한 드라이버 없이 독점적인 새 하드웨어가 되지 않기를 희망합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n읽어 주셔서 감사합니다. 이야기가 마음에 드셨다면 Medium에 구독해보세요. 그러면 새 기사가 발행될 때 알림을 받을 수 있을 뿐만 아니라 수천 편의 다른 작가들의 이야기에도 완전한 접속 권한을 얻을 수 있습니다. 또한 LinkedIn을 통해 연락하실 수도 있습니다. 거기에서는 전체 기사로 충분치 않은 작은 포스트를 주기적으로 발행하고 있습니다. 이번 포스트와 다른 포스트의 전체 소스 코드를 원하신다면 Patreon 페이지를 방문해보세요.\n\n자연어 처리와 언어 모델을 사용하는 것에 관심이 있는 분들은 다른 논문들도 읽어보세요:\n\n- GPT 모델: 어떻게 작동합니까?\n- 16, 8 및 4비트 부동 소수점 형식 - 어떻게 작동합니까?\n- 대규모 언어 모델로 판다 데이터프레임 처리하기\n- 주말 AI 프로젝트 (제1부): 라즈베리 파이에서 음성 인식 및 LLaMA-2 GPT 실행\n- 주말 AI 프로젝트 (제2부): 음성 인식, PTT 및 라지 액션 모델을 라즈베리 파이에서 사용하기\n- 주말 AI 프로젝트 (제3부): 시각 장애인을 위한 시각 보조 도구 만들기","ogImage":{"url":"/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_0.png"},"coverImage":"/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_0.png","tag":["Tech"],"readingTime":14},{"title":"대기 시간을 통해의 신비로운 여행","description":"","date":"2024-05-17 20:39","slug":"2024-05-17-AWhimsicalJourneyThroughWaitTimes","content":"\n\n## 파이썬을 사용하여 전자레인지 카운트다운부터 끝나지 않는 전화 대기 시간까지\n\n![image](/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_0.png)\n\n전자레인지 오븐의 카운트다운이 빠르게 0으로 수렴하는 것을 본 적이 있나요? 반면 전화 대기시간은 영원처럼 늘어날까요?\n\n한가지 생각해 보세요. 포플콘을 전자레인지에 넣어 가열한 지 겨우 1분 지난 때에는 그릇을 준비하고 서빙할 준비를 합니다. 하지만 전화 대기 중에 1분이 지난다면? 다시 사람과 대화를 나눌 수 있을지 의문이 들 정도입니다. 10분 후, 포플콘을 즐기는 중이겠죠. 하지만 전화는? 대기 음악이 끝도 없는 연옥의 배경음악이 되고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그리고 팝콘을 기다리는 사이와 전화 대기를 이어가는 서사 속을 맴도는 … 주간 복권. 승리를 기다립니다. 매주 새로운 티켓은 이전 주의 실망과는 거리가 먼 신선한 약속을 간직하고 있습니다.\n\n요약하자면, 세 가지 다른 종류의 대기가 나타납니다:\n\n- “대기 전화”형 — 기다린 시간이 오래 될수록 더 오랫동안 기다릴 것으로 기대합니다.\n- “팝콘”형 — 기다린 시간이 길어질수록 더 짧게 기다릴 것으로 기대합니다.\n- “복권 당첨”형 — 지금까지 기다린 것과 관계없이 예상 대기 시간은 변하지 않습니다.\n\n이 대기 시간의 차이는 실제로 존재하는 것일까요, 아니면 마음의 장난일까요? 이 질문에 대한 대답은 두 부분으로 나누어 알아보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 부분 1 — 데이터 분석\n- 부분 2 — 데이터 모델링\n\n각 부분에서 대기 시간 유형을 각각 살펴보겠습니다. 자세한 Python 코드와 설명이 번갈아 나옵니다. Python에 관심이 있다면 코드 부분을 읽어보세요. 대기 시간에 대해 배우고 싶다면 코드를 건너뛰어도 됩니다.\n\n# \"대기 중\" 유형 대기 시간 — 기다린 시간이 길수록 더 오래 기다리게 됩니다.\n\n데이터로 시작하고 싶지만 \"대기 중\" 시간에 대한 데이터가 없습니다. 대신 컴퓨터 파일의 편집 사이의 시간에 대해서 어떠세요? 그런 편집 시간을 보는 곳 한 곳이 바로 위키피디아입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위키피디아 페이지에서 마지막 편집 이후의 시간을 보고 다음 편집까지 얼마나 남았는지 예측할 수 있을까요?\n\n위키피디아 페이지 편집에 대한 다음 편집까지의 시간을 어떻게 예측할 수 있을까요? 다음 편집이 언제 발생할지 정확히 예측해 보세요: \"저는 이 페이지가 정확히 5일 3시간 20분 후에 편집될 것으로 예측합니다.\" 하지만 그렇게 구체적으로 예측하는 것은 너무 정확성이 떨어질 것입니다.\n\n시간 범위를 예측할 수도 있습니다: \"저는 이 페이지가 다음 100년 이내에 언제든지 편집될 것으로 예측합니다.\" 이렇게 하면 거의 항상 맞을 수 있겠지만, 너무 모호하고 흥미롭지 않습니다.\n\n더 실용적인 예측은 \"중위 다음 편집 시간\"의 형태입니다. 이렇게 말할 수 있습니다: \"저는 이 페이지가 다음 5일 3시간 20분 이내에 50% 확률로 편집될 것으로 예측합니다.\" 저, 당신의 적,는 \"이전\" 또는 \"이후\"를 선택할 것입니다. 만약 실제 중위 다음 편집 시간이 3일이라고 가정하면, \"이전\"을 선택할 것입니다. 그럼 우리는 최대 5일 3시간 20분까지 기다립니다. 그 동안 누군가(다시 말해서, 우리 둘을 제외한 누군가) 페이지를 편집하면 상대방이 점수를 획들하고, 그렇지 않으면 당신이 점수를 획득합니다. 이러한 점수 체계를 통해, 만약 제가 당신보다 더 좋은 예측자라면 더 많은 점수를 획득해야 할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이썬에 대해 알아보고 이러한 예측을 어떻게 할 수 있는지 살펴봅시다:\n\n## “대기 중” 유형의 대기 시간 — Python\n\n아티스트 Marie Cochran에 관한 위키피디아 문서를 살펴보겠습니다. 문서의 개정 내역을 살펴볼 수 있습니다:\n\n![image](/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다양한 위키피디아 문서에서 데이터를 수집하기 위해 작은 파이썬 스크립트를 작성했어요. 다음과 같은 작업을 합니다:\n\n- https://en.wikipedia.org/wiki/Special:Random을 통해 랜덤한 영어 위키백과 페이지를 선택합니다.\n- 해당 페이지의 편집 이력으로 이동합니다. 예를 들어, https://en.wikipedia.org/w/index.php?title=Marie_Cochran\u0026action=history.\n- (최대) 최근 50회 편집의 날짜와 시간을 추출합니다. 시간은 분 단위로 표시됩니다.\n- 문서 제목, 수정 시간, 스크립트 실행 시간으로 구성된 줄을 생성합니다. 모든 시간은 UTC 시간대를 사용합니다. 탭으로 열을 구분합니다.\n- 줄을 파일에 추가합니다.\n\n편집 시간 데이터 일부를 보여드리겠습니다:\n\n```js\nMarie_Cochran 01:20, 8 January 2024 01:16, 08 February 2024\nMarie_Cochran 01:10, 27 September 2023 01:16, 08 February 2024\nMarie_Cochran 00:59, 12 September 2023 01:16, 08 February 2024\nMarie_Cochran 11:43, 2 November 2022 01:16, 08 February 2024\n...\nMarie_Cochran 19:20, 10 March 2018 01:16, 08 February 2024\nPeter_Tennant 15:03, 29 July 2023 01:16, 08 February 2024\nPeter_Tennant 21:39, 15 April 2022 01:16, 08 February 2024\n...\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nimport pandas as pd\n\n# 데이터 읽기\nwiki_df = pd.read_csv(\"edit_history.txt\", sep='\\t', header=None, names=[\"Title\", \"Edit DateTime\", \"Probe DateTime\"], usecols=[\"Title\", \"Edit DateTime\"])\nwiki_df['Edit DateTime'] = pd.to_datetime(wiki_df['Edit DateTime']) # 텍스트를 날짜 및 시간으로 변환\n\n# 'Title' 및 'Edit DateTime'을 기준으로 DataFrame 정렬하여 시간 간격이 올바르게 계산되도록 함\nwiki_df.sort_values(by=['Title', 'Edit DateTime'], inplace=True)\n\n# 동일한 제목 내에서 연속해서 편집한 경우의 시간 간격 계산\nwiki_df['Time Delta'] = wiki_df.groupby('Title')['Edit DateTime'].diff()\nwiki_df.head()\n```\n\n결과로 나온 Pandas 데이터프레임은 샘플된 기사 중 알파벳상으로 가장 빠른 기사(제목 기준)로 시작합니다. 이 기사는 몽골 출신인 매우 키가 큰 사람 인 Öndör Gongor에 대해 독자들에게 알려줍니다:\n\n![image](/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_2.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해당 기사의 마지막 50개의 편집 중 첫 번째 편집은 2008년 1월 27일 오후 3시 13분 (UTC)에 이루어졌습니다. 다음 편집은 16분 후에 이루어졌습니다. 그 다음 편집은 데이터의 해상도 한계로 인해 1분 내로 발생하여 0일 00:00:00으로 표시됩니다.\n\n계속 처리하면, 각 기사 맨 처음에 나타나는 NaT (not-a-time) 행을 제거해 보겠습니다. 또한 대기 시간에 따라 정렬하고 판다의 인덱스를 재설정할 것입니다:\n\n```js\n# 'Time Delta' 열에서 NaT(시간이 아님) 값이 포함된 행 제거\nwiki_df.dropna(subset=['Time Delta'], inplace=True)\n# 시간 간격으로 정렬 및 인덱스 재설정\nwiki_df.sort_values(by='Time Delta', inplace=True)\nwiki_df.reset_index(drop=True, inplace=True)\ndisplay(wiki_df)\nwiki_df['Time Delta'].describe()\n```\n\n이를 통해 다음과 같이 시작하고 끝나는 데이터프레임이 생성됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 통계 요약입니다.\n\n```js\ncount                          36320\nmean      92 days 13:46:11.116189427\nstd      195 days 11:36:52.016155110\nmin                  0 days 00:00:00\n25%                  0 days 00:27:00\n50%                 15 days 05:41:00\n75%                100 days 21:45:45\nmax               4810 days 17:39:00\n```\n\n조사 결과, 샘플링된 대기 시간은 0일 00:00:00(즉, 1분 미만)부터 13년 이상까지 다양합니다. (13년 편집 대기는 버지니아 대학교의 건물에 관한 기사였습니다.) 편집의 1/4은 이전 편집 후 27분 이내에 발생합니다. 편집 간 중위값은 약 15일을 조금 넘습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n조금 더 발전하기 전에, 웨이팅 시간을 향상시키고 싶은데요. 다음과 같이 작은 함수를 사용해서 웨이팅 시간을 표시할 수 있습니다:\n\n```js\ndef seconds_to_text(seconds):\n    seconds = round(seconds)\n    result = []\n    for unit_name, unit_seconds in [('y', 86400 * 365.25),('d', 86400),('h', 3600),('m', 60),('s', 1)]:\n        if seconds \u003e= unit_seconds:\n            unit_value, seconds = divmod(seconds, unit_seconds)\n            result.append(f\"{int(unit_value)}{unit_name}\")\n    return ' '.join(result) if result else \"\u003c1s\"\n\nseconds_to_text(100)\n```\n\n위의 `seconds_to_text` 함수는 100초를 `1m 40s`로 표시합니다.\n\n이제 위키피디아 데이터를 위한 \"웨이팅 테이블\"을 만들 수 있습니다. 기존에 기사의 다음 편집을 기다린 시간을 주면, 이 테이블은 중간 추가로 기다려야 할 시간을 알려줍니다. (\"중간값\"은 이 시간보다 덜 기다릴 확률이 50%이고, 시간이 더 걸리는 확률이 50%라는 것을 의미합니다.)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport numpy as np\n\ndef wait_wait_table(df, wait_ticks):\n    sorted_time_deltas_seconds = df['Time Delta'].dt.total_seconds()\n    results = []\n    for wait_tick in wait_ticks:\n        greater_or_equal_values = sorted_time_deltas_seconds[sorted_time_deltas_seconds \u003e= wait_tick]\n        median_wait = np.median(greater_or_equal_values)\n        additional_wait = median_wait - wait_tick\n        results.append({\"Wait So Far\": seconds_to_text(wait_tick), \"Median Additional Wait\": seconds_to_text(additional_wait)})\n    return pd.DataFrame(results)\n\nwiki_wait_ticks = [0, 60, 60*5, 60*15, 3600, 3600*4, 86400, 86400 * 7,86400 * 30, 86400 * 100, 86400 * 365.25, 86400 * 365.25 * 5, 86400 * 365.25 * 10]\nwiki_wait_tick_labels = [seconds_to_text(wait_tick) for wait_tick in wiki_wait_ticks]\nwait_wait_table(wiki_df, wiki_wait_ticks).style.hide(axis=\"index\")\n```\n\n이제 이 표의 출력에 대해 알아보겠습니다.\n\n## \"대기 중\" 유형의 대기 - 토론\n\n앞의 파이썬 코드는 이 표를 생성합니다. 이것을 \"대기-대기\" 표라고 부르죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_4.png)\n\n만약 아무도 기다리지 않았다면(다시 말해, 누군가가 페이지를 편집했다) 다음 편집은 15일이 넘게 기다릴 것으로 예상됩니다. 그러나 1분 후에도 누군가 기사를 편집하지 않았다면, 19일을 기다려야 할 것으로 예상됩니다. 따라서 1분 기다리면 예상 추가 대기 시간이 거의 4일 더 늘어납니다. 한 시간 후에도 누구도 기사를 편집하지 않았다면, 예상 추가 대기 시간은 47일로 두 배 넘게 늘어납니다.\n\n이 현상을 생각하는 한 가지 방법은 다음 편집을 기다리기 시작할 때 우리가 어떤 종류의 페이지에 있는지 모르는 것입니다. 이것이 테일러 스위프트와 같은 핫 팝컬쳐 주제의 기사인가요? 아니면 5000명 대학의 건물인 '로턴다(The Rotunda)'와 같은 니치하고 느린 주제인가요? 수정이 일어나지 않는 매 분이 지날수록, 확률은 이것이 테일러 스위프트와 같은 기사에서 '로턴다(The Rotunda)'와 같은 기사로 이동합니다.\n\n마찬가지로, 고객 서비스에 전화하고 대기시간이 발생할 때 - 처음에는 어떤 종류의 고객 서비스를 기다리고 있는지 모릅니다. 그러나 매 분이 지날 때마다, 우리는 서서히 나쁜, 느린 고객 서비스를 기다리고 있다는 것을 알게 됩니다. 따라서 예상 추가 대기 시간은 늘어납니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금까지는 데이터를 직접 사용했습니다. 데이터를 확률 분포로 모델링해 볼 수도 있습니다. 그러나 모델링으로 넘어가기 전에 다른 두 예제인 마이크로파 팝콘 요리와 복권 당첨을 살펴보겠습니다.\n\n# \"팝콘\"형 기다림 - 기다릴수록 덜 기다리는 것을 기대합니다.\n\n위키피디아 편집을 기다리는 기법을 마이크로파 팝콘 조리를 기다리는 것에 적용해 봅시다. (매력적일지도 모르는) 실제 데이터를 수집하는 대신 모의 데이터를 시뮬레이션하는 것으로 만족합니다. 난수 생성기를 사용할 것입니다. 요리 시간은 센서를 기반으로 하는 것이라 가정하며, 5분에서 15초 차이가 날 수 있다고 가정합니다.\n\n## \"팝콘\"형 기다림 - 파이썬\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이썬에서 특히:\n\n```python\nseed = 0\nrng = np.random.default_rng(seed)\nsorted_popcorn_time_deltas = np.sort(rng.normal(5*60, 15, 30_000))\npopcorn_df = pd.DataFrame(pd.to_timedelta(sorted_popcorn_time_deltas, unit=\"s\"), columns=[\"Time Delta\"])\nprint(popcorn_df.describe())\n```\n\n이 코드는 다음과 같은 통계 요약이 포함된 판다 데이터프레임을 생성합니다:\n\n\n                      Time Delta\ncount                      30000\nmean   0 days 00:05:00.060355606\nstd    0 days 00:00:14.956424467\nmin    0 days 00:03:52.588244397\n25%    0 days 00:04:50.011437922\n50%    0 days 00:04:59.971380399\n75%    0 days 00:05:10.239357827\nmax    0 days 00:05:59.183245298\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예상대로, 이 정규 분포에서 데이터를 생성할 때 평균은 5분이고 표준 편차는 약 15초입니다. 우리가 시뮬레이션한 대기 시간은 3분 52초에서 6분까지 범위에 있습니다.\n\n이제 \"대기-대기\" 테이블을 생성할 수 있습니다:\n\n```js\nwait_wait_table(popcorn_df, [0, 10, 30, 60, 2*60, 3*60, 4*60, 5*60]).style.hide(axis=\"index\")\n```\n\n## \"팝콘\" 형태의 대기 시간 — 토론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리의 \"기다려-기다려\" 소프트웨어는 팝콘 테이블을 아래와 같이 보여줍니다:\n\n![팝콘 대기 시간](/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_5.png)\n\n우리의 테이블에 따르면, 처음에는 5분 기다림을 예상합니다. 그리고 10초를 기다린 후에는 추가로 기대되는 대기 시간이 정확히 10초 줄어듭니다 (4분 50초로). 1분을 기다린 후에는 추가 대기 시간이 4분으로 줄어들고, 그러한 식으로 이어집니다. 5분에 이르러서도 추가 대기 시간은 계속해서 줄어들지만 0으로는 안 줄어듭니다.\n\n나중에 데이터 모델링 하는 방법을 보게 될 것입니다. 지금은 복권 당첨을 기다리는 것에 대해 다음으로 살펴봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# “로또 당첨” 스타일 대기 시간 — 지금까지 기다린 시간과는 무관하게, 예상 대기 시간은 동일합니다.\n\n로또 데이터에 대해서는 다시 시뮬레이션된 데이터를 생성하는 것이 편합니다. 워싱턴 주의 로또는 당첨 확률을 1 대 27.1로 제공합니다. (가장 흔한 당첨은 $1 베팅에 $3를 지불합니다.) 100만 주 (약 1만 9천 년) 동안 로또를 플레이하고 당첨 사이의 대기 시간에 대한 데이터를 수집해 봅시다.\n\n## “로또 당첨” 스타일 대기 시간 — 파이썬\n\n우리는 100만 주 동안의 로또 플레이를 시뮬레이션합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n시드 = 0\nrng = np.random.default_rng(시드)\n지난주_당첨 = None\n로또_대기 = []\nfor 주차 in range(1_000_000):\n    if rng.uniform(high=27.1) \u003c 1.0:\n        if 지난주_당첨 is not None:\n            로또_대기.append(주차 - 지난주_당첨)\n        지난주_당첨 = 주차\n정렬된_로또_시간_간격 = np.sort(np.array(로또_대기) * 7 * 24 * 60 * 60)\nlotto_df = pd.DataFrame(pd.to_timedelta(정렬된_로또_시간_간격, unit=\"s\"), columns=[\"시간 간격\"])\nprint(lotto_df.describe())\n```\n\n```js\n                        시간 간격\ncount                        36773\nmean   190 days 08:21:00.141951976\nstd    185 days 22:42:41.462765808\nmin                7 days 00:00:00\n25%               56 days 00:00:00\n50%              133 days 00:00:00\n75%              259 days 00:00:00\nmax             2429 days 00:00:00\n```\n\n우리의 최단 가능한 당첨 간격은 7일입니다. 가장 긴 시뮬레이션된 건조 기간은 6년 이상입니다. 중앙값 대기 시간은 133일입니다.\n\n우리는 \"대기-대기\" 테이블을 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nlotto_days = [0, 7, 7.00001,  2*7, 4*7, 183, 365.25, 2*365.25, 5*365.25]\nlotto_waits = [day * 24 * 60 * 60 for day in lotto_days]\nwait_wait_table(lotto_df, lotto_waits).style.hide(axis=\"index\")\n```\n\n## \"로또 당첨\" 스타일 대기 시간 — 토론\n\n여기 \"대기-대기\" 테이블이 있습니다:\n\n\u003cimg src=\"/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_6.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음은 Markdown 형식으로 작성된 텍스트입니다.\n\n테이블에 따르면 복권은 우리가 이기기까지 얼마나 기다렸는지에 신경을 쓰지 않습니다. 우리가 방금 이겼던지 (지금까지 기다린 시간 ` 1초) 아니면 1년 동안 이기지 못했던지, 우리가 다음 승리까지 기다려야 하는 예상 추가 기다림은 대부분 항상 126일부터 133일 사이입니다.\n\n표의 세 항목은 이상할 수 있습니다. 7일과 7일 1초에서 무슨 일이 일어나는지 생각해보세요. 추가 기다림이 126일에서 거의 즉시 133일 정도로 급격히 증가하는 이유는 무엇일까요? 답은 매주 추첨하는 시점에서 승리까지의 최소 기다림이 0일에서 7일로 변경되기 때문입니다. 그리고 5년은 어떻게 되는 걸까요? 5년을 기다린다면 보통 133일이 걸리는 대신 단지 50일만에 승리를 기대할 수 있는 것일까요? 안타깝게도 아닙니다. 오히려 이는 우리 데이터의 한계를 보여줍니다. 데이터에서는 5년을 기다리는 경우를 세 번만 볼 수 있습니다:\n\n```js\nlotto_df[lotto_df[\"Time Delta\"] \u003e pd.to_timedelta(24*60*60 * 365.25 * 5, unit=\"s\")]\n```\n\n\u003cimg src=\"/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_7.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n삼 가지 값은 중위수의 노이즈 추정치로 이어집니다.\n\n지금까지 실제 및 모의 데이터에서 본 것을 요약해보면:\n\n- 위키피디아 편집 — 기다릴수록 기대하는 대기 시간이 길어집니다.\n- 팝콘 — 기다릴수록 기대하는 대기 시간이 줄어듭니다.\n- 복권 당첨 — 지금까지의 대기 시간과 관계없이 기대 대기 시간은 동일합니다.\n\n다음 섹션에서는 모델링의 방법과 그 이유에 대해 살펴보겠습니다. 미국 로또 데이터부터 시작하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 부분에서는 대기 시간 예측을 위한 간단한 표현을 찾아보겠습니다. 예측에는 이러한 간소화가 필요하지 않습니다. 우리가 지금까지 만든 것은 경험적 분포라고 불리며 잘 작동합니다. 그러나 더 간단한 표현은 더 편리할 수 있습니다. 또한 다른 종류의 대기를 이해하기 쉽게 비교할 수 있게 해줄 수도 있습니다.\n\n우리는 세 가지 예제를 살펴보면서 진행할 것입니다. 가장 간단한 것부터 시작하여 (복권 당첨) 가장 복잡한 것(Wikipedia 편집)으로 넘어갈 것입니다. 이전과 마찬가지로 Python 코드(건너뛸 수 있는)와 토론 사이를 오가겠습니다.\n\n먼저 대기 시간 데이터프레임에 누적 분포 열을 추가하는 것부터 시작하겠습니다. 이전에 데이터프레임을 시간 딜타로 정렬했음을 기억해주세요.\n\n```python\nwiki_df['CDF'] = wiki_df['Time Delta'].rank(pct=True)\npopcorn_df['CDF'] = popcorn_df['Time Delta'].rank(pct=True)\nlotto_df['CDF'] = lotto_df['Time Delta'].rank(pct=True)\nwiki_df\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nCDF 컬럼은 누적 분포 함수(Cumulative Distribution Function)를 나타내며, 가장 짧은 대기 시간에는 0.0에 가까운 값이 있고, 가장 긴 대기 시간에는 1.0이 있습니다. 다시 말해, 각 행의 순위가 분수로 나타난 것입니다. 위키피디아 데이터프레임은 이제 다음과 같습니다:\n\n\n| Time Delta  |  CDF  |\n|-------------|-------|\n| 0 days 00:00:10 | 0.1 |\n| 0 days 00:00:30 | 0.3 |\n| 0 days 00:01:00 | 0.5 |\n| 0 days 00:02:00 | 0.7 |\n| 0 days 00:05:00 | 0.9 |\n| 0 days 00:10:00 | 1.0 |\n\n\n이제 CDF(누적 분포 함수)를 대기 시간 Time Delta(x-축)에 대해 그릴 수 있습니다. 파이썬에서 다음과 같은 플로팅 코드를 사용할 수 있습니다:\n\n```python\nimport matplotlib.pyplot as plt\n\ndef wait_cdf(title, sorted_df, wait_ticks, dist=None, dist_label=None, left=None, right=None, xscale='linear'):\n    wait_seconds = sorted_df['Time Delta'].dt.total_seconds() # x values\n    cdf = sorted_df['CDF'] # y values\n\n    left = left or wait_seconds.min()\n    right = right or wait_seconds.max()\n\n    plt.figure(figsize=(10, 6))\n    plt.title(title + ' 누적 분포 함수(CDF)')\n    plt.plot(wait_seconds, cdf, marker='.', linestyle=\" \", label='경험적인 CDF')\n\n    if dist is not None:\n        dist_x = np.logspace(np.log10(left), np.log10(right), 100) if xscale == 'log' else np.linspace(left, right, 100)\n        dist_y = dist.cdf(dist_x)\n        plt.plot(dist_x, dist_y, label = dist_label)\n\n    plt.xlabel('대기 시간')\n    plt.ylabel('CDF')\n    plt.xscale(xscale)\n    plt.xticks(wait_ticks, [seconds_to_text(wait_tick) for wait_tick in wait_ticks], rotation=45)\n    plt.xlim(left=left, right=right)\n    plt.grid(True, which=\"both\", ls=\"--\")\n    plt.legend(loc='upper left')\n    plt.show()\n\nwait_cdf(\"로또 당첨\", lotto_df, wiki_wait_ticks, xscale='log')\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n로또 당첨과 대기 시간의 CDF 플롯을 로그 스케일로 표시하였습니다:\n\n![Lottery Wins CDF Plot](/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_9.png)\n\n곡선이 간단해 보이니 이에 간단한 곡선을 적합해보려고 합니다. 가장 적합한 곡선은 지수 분포입니다. 이는 대기 시간과 관련된 가장 간단한 일반 함수입니다.\n\nPython의 scipy.stats 패키지를 사용하면 데이터에 지수 곡선을 맞추고 해당 결과 곡선을 Python 객체로 표현하는 것이 쉽습니다. 여기서는 lotto_expon_dist라는 이름으로 이를 표현했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nfrom scipy.stats import expon\n\n_, lotto_e_scale = expon.fit(lotto_df['Time Delta'].dt.total_seconds(), floc=0)\nlotto_expon_dist = expon(scale=lotto_e_scale)\nprint(f\"복권 당첨 지수 중앙값은 {seconds_to_text(lotto_expon_dist.median())} 입니다. 스케일 매개변수는 {seconds_to_text(lotto_e_scale)} 입니다.\")\n```\n\n이 코드는 출력합니다:\n\n복권 당첨 지수 중앙값은 131일 22시간 32분 20초 입니다. 스케일 매개변수는 190일 8시간 21분 입니다.\n\n적합된 곡선의 중앙값은 약 132일로, 경험적인 중앙값인 133일과 근접합니다. 지수곡선을 관행적으로 스케일이라는 단일 숫자로 매개변수화하는데, 이것은 분포의 평균에 해당하지만 평균에서 중앙값을 쉽게 계산하거나 그 반대로 할 수 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n로또 당첨금에 대한 경험적 누적 분포(EMCDF) 및 적합 누적 분포(FCDF) 플롯입니다:\n\n```js\nlotto_expon_label = f'ExponentialDistribution(scale={seconds_to_text(lotto_e_scale)})'\nwait_cdf(\"당첨금\", lotto_df, wiki_wait_ticks, dist=lotto_expon_dist, dist_label=lotto_expon_label, xscale='log')\n```\n\n\u003cimg src=\"/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_10.png\" /\u003e\n\n둘이 꽤 근접합니다. 왼쪽의 약간의 불일치는 복권 추첨시 모멘트의 즉시 7일 점프에 의해 발생합니다. 이 글에서는 이 작은 불일치를 무시하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리 (모의) 복권 당첨 데이터에 지수 함수가 잘 작동합니다. Popcorn과 Wikipedia 데이터에도 어떻게 작동하는지 살펴봅시다. 다음은 이러한 데이터프레임에 지수 분포를 맞추는 코드입니다.\n\n```js\n_, popcorn_e_scale = expon.fit(popcorn_df['Time Delta'].dt.total_seconds(), floc=0)\npopcorn_expon_dist = expon(scale=popcorn_e_scale)\nprint(f\"Popcorn exponential median is {seconds_to_text(popcorn_expon_dist.median())}\")\npopcorn_expon_label = f'ExponentialDistribution(scale={seconds_to_text(popcorn_e_scale)})'\nwait_cdf(\"Popcorn\", popcorn_df, popcorn_ticks, dist=popcorn_expon_dist, dist_label=popcorn_expon_label, left=10, right=6*60, xscale='linear' )\n\n_, wiki_e_scale = expon.fit(wiki_df['Time Delta'].dt.total_seconds(), floc=0)\nwiki_expon_dist = expon(scale=wiki_e_scale)\nprint(f\"Wiki exponential median is {seconds_to_text(wiki_expon_dist.median())}\")\nwiki_expon_label = f'ExponentialDistribution(scale={seconds_to_text(wiki_e_scale)})'\nwait_cdf(\"Wiki Edits\", wiki_df, wiki_wait_ticks, dist=wiki_expon_dist, dist_label=wiki_expon_label, xscale='log', left=60)\n```\n\n그리고 여기가 그림들입니다:\n\n\u003cimg src=\"/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_11.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_12.png)\n\n이런, 이 곡선 맞추기 결과는 정말 최악이네요! 문제는 지수 분포가 \"복권 당첨\"과 유사한 데이터만 모델링한다는 것입니다. 구체적으로 말하면, 대기 시간이 이전 대기 시간에 관계없이 기대 대기 시간이 동일한 경우에 해당합니다. 이전 대기 시간을 무시하는 대기 시간에 대해 좌우되는 경우, 이것이 메모리리스(exponential)이라고 불립니다. 또한 연속 분포 중에서 지수 분포는 유일한 메모리리스 분포입니다.\n\n그렇다면 분포에 메모리가 필요하다면 어떨까요? 다음으로 시도할 수 있는 가장 간단한 분포는 와이블(Weibull) 분포입니다.\n\n와이블 분포는 형태(shape)와 척도(scale) 두 매개변수로 매개화됩니다. 복권 데이터로 시작해 보죠:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\nfrom scipy.stats import weibull_min\n\nlotto_shape, _, lotto_w_scale = weibull_min.fit(lotto_df['Time Delta'].dt.total_seconds(), floc=0)\nlotto_weibull_dist = weibull_min(c=lotto_shape,scale=lotto_w_scale)\n\nprint(f\"복권 당첨 위블 중앙값은 {seconds_to_text(lotto_weibull_dist.median())}\")\nlotto_weibull_label = f'WeibullDistribution(shape={lotto_shape:.3},scale={seconds_to_text(lotto_w_scale)})'\nwait_cdf(\"복권 당첨\", lotto_df, wiki_wait_ticks, dist=lotto_weibull_dist, dist_label=lotto_weibull_label, xscale='log')\n\n\n이는 지수함수와 유사한 장착 곡선을 생성합니다. 실제로 형태가 1일때 위블 분포는 지수 분포입니다. 여기서 형태는 1.06입니다.\n\n\u003cimg src=\"/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_13.png\" /\u003e\n\n팝콘 데이터에 위블을 적합하려고 하면 무엇이 발생하나요?\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\npopcorn_shape, _, popcorn_w_scale = weibull_min.fit(popcorn_df['Time Delta'].dt.total_seconds(), floc=0)\npopcorn_weibull_dist = weibull_min(c=popcorn_shape, scale=popcorn_w_scale)\nprint(f\"Popcorn Weibull median is {seconds_to_text(popcorn_weibull_dist.median())}\")\npopcorn_df_weibull_label = f'Weibull(shape={popcorn_shape:.3}, scale={seconds_to_text(popcorn_w_scale)})'\nwait_cdf(\"Popcorn\", popcorn_df, popcorn_ticks, dist=popcorn_weibull_dist, dist_label=popcorn_df_weibull_label, left=3*60, right=7*60, xscale='linear')\n```\n\n![Image](/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_14.png)\n\n안전하진 않지만, 이 적합은 지수 함수의 적합보다 훨씬 낫습니다. 모양 모수의 값이 20임을 주목하세요. Weibull의 모양 모수가 1보다 큰 경우 \"대기 시간이 길수록 대기 시간을 기대하는 것이 줄어든다\"를 나타냅니다.\n\n마지막으로, 위키피디아 데이터에 Weibull을 시도해보겠습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nwiki_shape, _, wiki_w_scale = weibull_min.fit(wiki_df['Time Delta'].dt.total_seconds(), floc=0)\nwiki_weibull_dist = weibull_min(c=wiki_shape, scale=wiki_w_scale)\nprint(f\"위키 위불 중앙값은 {seconds_to_text(wiki_weibull_dist.median())}\")\nwiki_df_weibull_label = f'위불(모양={wiki_shape:.3},스케일={seconds_to_text(wiki_w_scale)})'\nwait_cdf(\"위키 편집\", wiki_df, wiki_wait_ticks, dist=wiki_weibull_dist, dist_label=wiki_df_weibull_label, xscale='log', left=60)\n```\n\n\u003cimg src=\"/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_15.png\" /\u003e\n\n이 곡선 맞춤은 완벽하지 않지만, 지수함수의 맞춤보다 훨씬 좋습니다. 모양 모수값인 0.292에 주목해보세요. 위불의 모양 모수가 1보다 작을 때는 \"기다린 시간이 길수록 더 기다려야 한다\"는 것을 나타냅니다. 그러나 위불만이 이 특성을 갖고 있는 것은 아닙니다. 이 특성을 갖는 무수히 많은 분포들도 있습니다. 실제로 위키피디아 분포는 이 특성을 갖지만 위불 분포가 아닙니다.\n\n# 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n결론적으로, 당신과 나는 미친 것이 아닙니다(필요에 따라).\n\n우리는 정말 기다린 시간이 길수록 더 기다려야 할 상황이 있는 것을 보았습니다. 위키피디아 편집 사이의 시간 간격에서 경험적으로 확인할 수 있습니다. 또한 Weibull 분포에서 형태 매개변수가 1보다 작은 경우에도 확인할 수 있습니다.\n\n똑같이, 다른 몇 가지 대기 시간에는 \"기다린 시간이 길수록 더 적게 기다리게 된다\"는 규칙이 적용됩니다. 팝콘에서 이 현상을 확인할 수도 있습니다. 또한 Weibull 분포에서 형태 매개변수가 1보다 큰 경우에도 이를 확인할 수 있습니다.\n\n마지막으로, 세 번째 종류의 대기 시간인 \"메모리리스\"도 존재합니다. 이 경우, 지금까지 기다린 시간에 상관없이 기대 대기 시간은 동일합니다. 복권 당첨 간의 시간에서 이를 확인했습니다. 이는 형태 매개변수가 1인 Weibull 분포(지수 분포와 동일)와 관련이 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터를 분석할 때 기다릴 데이터가 있는 경우, Weibull 분포를 시도하는 것을 권장합니다. Python을 사용하면 이러한 곡선을 fitting하는 것이 쉽습니다. 그러나 데이터가 Weibull 분포와 잘 맞지 않는 경우에는 Weibull을 사용하지 않는 것이 좋습니다. 대신, 자료 분포를 직접 사용하여 데이터가 스스로 말하도록하십시오.\n\n기다림 시간에 대한 이 여정에 참여해 주셔서 감사합니다. 이제 기다림 시간과 그 분석에 대해 더 잘 이해하게 되었으면 좋겠습니다.\n\n칼을 Medium에서 팔로우해 주세요. 저는 Rust 및 Python에서의 과학적 프로그래밍, 머신러닝 및 통계에 대해 씁니다. 월 한 번 정도 기사를 씁니다.","ogImage":{"url":"/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_0.png"},"coverImage":"/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_0.png","tag":["Tech"],"readingTime":20}],"page":"73","totalPageCount":154,"totalPageGroupCount":8,"lastPageGroup":20,"currentPageGroup":3},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"73"},"buildId":"Y-fCAg8BUV7y2HNFwX9AA","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>