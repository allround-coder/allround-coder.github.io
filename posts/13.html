<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>allround-coder</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://allround-coder.github.io///posts/13" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="allround-coder" data-gatsby-head="true"/><meta property="og:title" content="allround-coder" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://allround-coder.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://allround-coder.github.io///posts/13" data-gatsby-head="true"/><meta name="twitter:title" content="allround-coder" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | allround-coder" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZFDEQ947R4"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
  
            gtag('config', 'G-ZFDEQ947R4');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/baeec1f16d6ea8b8.css" as="style"/><link rel="stylesheet" href="/_next/static/css/baeec1f16d6ea8b8.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-af801b1eee26eff3.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-498da29379dd58dc.js" defer=""></script><script src="/_next/static/7rKODeu6chWTLgXf6auoL/_buildManifest.js" defer=""></script><script src="/_next/static/7rKODeu6chWTLgXf6auoL/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Allround Coder</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="VsCode에 React 앱을 설치하는 방법(2024년 최신)" href="/post/2024-05-17-HowtoInstallReactAppInVsCode2024"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="VsCode에 React 앱을 설치하는 방법(2024년 최신)" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-HowtoInstallReactAppInVsCode2024_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="VsCode에 React 앱을 설치하는 방법(2024년 최신)" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">VsCode에 React 앱을 설치하는 방법(2024년 최신)</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="React Native 페이지 최적화 방법 정리(2024년 최신)" href="/post/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="React Native 페이지 최적화 방법 정리(2024년 최신)" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="React Native 페이지 최적화 방법 정리(2024년 최신)" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">React Native 페이지 최적화 방법 정리(2024년 최신)</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">20<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Vite, Nginx 및 런타임에서 정적 웹 사이트용 환경 변수 적용하는 방법" href="/post/2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Vite, Nginx 및 런타임에서 정적 웹 사이트용 환경 변수 적용하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Vite, Nginx 및 런타임에서 정적 웹 사이트용 환경 변수 적용하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">Vite, Nginx 및 런타임에서 정적 웹 사이트용 환경 변수 적용하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="대형 언어 모델LLM을 활용한 웹 어플리케이션 만드는 방법" href="/post/2024-05-17-BuildingaWebApplicationPoweredbyLargeLanguageModelsLLMpart2"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="대형 언어 모델LLM을 활용한 웹 어플리케이션 만드는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-BuildingaWebApplicationPoweredbyLargeLanguageModelsLLMpart2_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="대형 언어 모델LLM을 활용한 웹 어플리케이션 만드는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">대형 언어 모델LLM을 활용한 웹 어플리케이션 만드는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="통계적 파워와 파워 분석 개요" href="/post/2024-05-17-APrimeronStatisticalPowerandPowerAnalysis"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="통계적 파워와 파워 분석 개요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-APrimeronStatisticalPowerandPowerAnalysis_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="통계적 파워와 파워 분석 개요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">통계적 파워와 파워 분석 개요</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="새로운 langchain_huggingface 라이브러리 만들면서 배우기" href="/post/2024-05-17-ExploringtheNewlangchain_huggingfacelibraryAHands-OnExperiment"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="새로운 langchain_huggingface 라이브러리 만들면서 배우기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-ExploringtheNewlangchain_huggingfacelibraryAHands-OnExperiment_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="새로운 langchain_huggingface 라이브러리 만들면서 배우기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">새로운 langchain_huggingface 라이브러리 만들면서 배우기</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="CodeLlama vs CodeGemma, AI 코딩 어시스턴스에 오픈 모델 활용하기" href="/post/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="CodeLlama vs CodeGemma, AI 코딩 어시스턴스에 오픈 모델 활용하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="CodeLlama vs CodeGemma, AI 코딩 어시스턴스에 오픈 모델 활용하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">CodeLlama vs CodeGemma, AI 코딩 어시스턴스에 오픈 모델 활용하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">14<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="대기 시간을 통해의 신비로운 여행" href="/post/2024-05-17-AWhimsicalJourneyThroughWaitTimes"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="대기 시간을 통해의 신비로운 여행" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="대기 시간을 통해의 신비로운 여행" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">대기 시간을 통해의 신비로운 여행</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">20<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AWS Glue로 다수의 CSV 파일을 처리하는 ETL 단계별 팁" href="/post/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AWS Glue로 다수의 CSV 파일을 처리하는 ETL 단계별 팁" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AWS Glue로 다수의 CSV 파일을 처리하는 ETL 단계별 팁" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">AWS Glue로 다수의 CSV 파일을 처리하는 ETL 단계별 팁</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Node에서 안정적인 분산 시스템 구축하는 방법" href="/post/2024-05-17-BuildingReliableDistributedSystemsinNode"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Node에서 안정적인 분산 시스템 구축하는 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-BuildingReliableDistributedSystemsinNode_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Node에서 안정적인 분산 시스템 구축하는 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">Node에서 안정적인 분산 시스템 구축하는 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 17, 2024</span><span class="PostList_reading_time__6CBMQ">12<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><a class="link" href="/posts/1">1</a><a class="link" href="/posts/2">2</a><a class="link" href="/posts/3">3</a><a class="link" href="/posts/4">4</a><a class="link" href="/posts/5">5</a><a class="link" href="/posts/6">6</a><a class="link" href="/posts/7">7</a><a class="link" href="/posts/8">8</a><a class="link" href="/posts/9">9</a><a class="link" href="/posts/10">10</a><a class="link" href="/posts/11">11</a><a class="link" href="/posts/12">12</a><a class="link posts_-active__YVJEi" href="/posts/13">13</a><a class="link" href="/posts/14">14</a><a class="link" href="/posts/15">15</a><a class="link" href="/posts/16">16</a><a class="link" href="/posts/17">17</a><a class="link" href="/posts/18">18</a><a class="link" href="/posts/19">19</a><a class="link" href="/posts/20">20</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"VsCode에 React 앱을 설치하는 방법(2024년 최신)","description":"","date":"2024-05-17 20:57","slug":"2024-05-17-HowtoInstallReactAppInVsCode2024","content":"\n\nReact.js은 실시간 응용 프로그램 및 사용자 인터페이스 개발에 널리 사용되는 JavaScript 라이브러리입니다. 이는 종종 프런트엔드 JavaScript 프레임워크로 언급됩니다. Visual Studio Code (VSCode)는 가벼우면서 강력한 코드 편집기로, React.js 개발에 탁월한 지원을 제공합니다. 이 글에서는 React.js를 빠르고 주관적인 빌드 도구인 Vite와 함께 VSCode에 설정하는 과정을 안내해 드리겠습니다. 그러니, 빠르게 React 앱을 VS Code에 설치해 봅시다.\n\n![이미지](/assets/img/2024-05-17-HowtoInstallReactAppInVsCode2024_0.png)\n\n# 사전 준비 사항:\n\n설치 프로세스에 진입하기 전에, 필요한 모든 사전 요구 사항이 갖추어져 있는지 확인해 보겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Node.js 및 npm:\n\n- React.js는 Node.js와 npm (Node Package Manager)에 의존합니다. 아직 설치하지 않은 경우, nodejs.org로 이동하여 최신 버전을 다운로드하고 설치해보세요.\n\n2. Visual Studio Code:\n\n- 컴퓨터에 Visual Studio Code가 설치되어 있는지 확인해주세요. 아직 설치하지 않은 경우, code.visualstudio.com에서 운영 체제와 호환되는 최신 버전을 다운로드하고 설치하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 단계 1: Visual Studio Code를 실행하세요\n\nVisual Studio Code를 열면 여정이 시작됩니다. 아직 설치하지 않았다면, 지금 설치하는 것이 바로 시기입니다.\n\n# 단계 2: React 앱 만들기\n\n## 2.1 통합 터미널 열기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n상위 메뉴로 이동하여 View - Terminal을 선택하거나 바로 가기 Ctrl +를 사용하여 Visual Studio Code 내에 통합 터미널을 열어보세요.\n\n# 2.2 새 React 앱 생성하기\n\n다음 명령을 실행하여 새 React 앱을 만들어보세요. 원하는 프로젝트 이름으로 my-react-app을 사용자 정의할 수 있습니다.\n\n```js\nnpx create-react-app my-react-app\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 단계 3: 프로젝트로 이동하기\n\n다음 명령어를 사용하여 프로젝트 디렉토리로 이동하세요:\n\n```js\ncd my-react-app\n```\n\n# 단계 4: 개발 서버 실행하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 4.1 개발 서버 시작하기\n\n다음 명령어를 사용하여 개발 서버를 시작하세요:\n\n```js\nnpm start\n```\n\n이 명령어를 실행하면 React 앱이 개발 모드로 실행되며, 브라우저를 통해 http://localhost:3000/ 에서 접근할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 4.2 원활한 개발을 위한 자동 업데이트\n\nReact 코드를 조정하고 수정하는 동안 개발 서버가 자동으로 업데이트되어 원활하고 효율적인 개발 경험을 제공합니다.\n\n# 단계 5: React 앱 구조 살펴보기\n\nVisual Studio Code를 열고 프로젝트 폴더로 이동합니다. src 폴더는 소스 코드용이고 public 폴더는 정적 자산용 등 필수 폴더를 포함한 표준 React 프로젝트 구조가 여러분을 기다리고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 단계 6: 향상된 개발을 위한 선택 도구\n\n# 6.1 React 개발자 도구 확장\n\nVisual Studio Code에서 \"React 개발자 도구\" 확장을 통합하여 개발 경험을 향상시킵니다. 이 확장은 React 애플리케이션을 디버깅하는 데 유용한 통찰력과 도구를 제공합니다.\n\n- 확장 뷰( Ctrl + Shift + X)를 열고 \"React Developer Tools\"를 검색한 후 설치를 클릭하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 6.2 ESLint과 Prettier를 통한 코드 품질 관리\n\n코드 일관성과 품질을 유지하기 위해 React 프로젝트에 ESLint와 Prettier를 통합하는 것을 고려해보세요.\n\n- ESLint를 전역으로 설치하세요:\n\n```js\nnpm install -g eslint\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- Visual Studio Code에 ESLint 확장 프로그램을 설치해보세요.\n- ESLint 구성 파일을 만들어보세요:\n\n```js\nnpx eslint --init\n```\n\nPrettier를 설치해보세요:\n\n```js\nnpm install --save-dev prettier\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 프로젝트에 .prettierrc 파일을 만들어 Prettier를 구성하세요.\n\n## 단계 7: 코딩 어드벤처 시작하기\n\n축하합니다! 이제 비주얼 스튜디오 코드에서 React.js 프로젝트를 성공적으로 설정했고, 이제 창의력을 발휘할 준비가 되었습니다. 강력한 React 컴포넌트를 구축하고, React 라이브러리의 방대한 생태계를 탐험하며, 웹 개발의 무한한 가능성에 대해 탐구해보세요.\n\n## 결론:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2024년이 시작되면서 React.js는 현대 웹 개발의 선두에 있습니다. React.js를 정복하면 다양한 기회의 문을 열 수 있습니다. 이 포괄적인 안내를 따르면, Visual Studio Code에 React를 설치하고도 풍부한 코딩 여정을 경험할 수 있게 될 것입니다.","ogImage":{"url":"/assets/img/2024-05-17-HowtoInstallReactAppInVsCode2024_0.png"},"coverImage":"/assets/img/2024-05-17-HowtoInstallReactAppInVsCode2024_0.png","tag":["Tech"],"readingTime":3},{"title":"React Native 페이지 최적화 방법 정리(2024년 최신)","description":"","date":"2024-05-17 20:52","slug":"2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney","content":"\n\n리액트는 쉽게 시작할 수 있는 프레임워크이지만 규모 확장에는 어렵습니다. 어플리케이션이 커지면 잘못된 상태 업데이트, 뒤얽힌 렌더 로직, 비효율적인 이벤트 핸들러 생성, 비효율적인 라이브러리 사용, 그리고 불필요한 useEffect가 매우 쉽게 발생하고 어플리케이션의 렌더 성능에 심각한 영향을 미칠 수 있습니다. 이 느려짐은 React Native 어플리케이션에서 특히 더 눈에 띄며, 여기서 모든 렌더링이 강력한 웹 서버에 의해 수행되지 않기 때문입니다. 저는 현재 진행 중인 피트니스 어플리케이션의 프로필 페이지를 작성하면서 이 현상을 다시 한번 깨닫게 되었습니다.\n\n이 기사는 원래 2년 전에 작성한 프로필 페이지를 점진적으로 다시 작성하는 과정을 요약할 것입니다. 프로필 페이지로 네비게이션하면 Google Pixel 7에서 프레임이 20-40 FPS로 떨어지는 현상이 있었습니다. 최적화 이후, 어플리케이션은 86 FPS의 프레임율을 유지할 수 있었습니다. 최적화 이후 90 FPS에서 4 FPS가 떨어진 것은 사용 중인 React Navigation 1.0 라이브러리가 최적이 아니었기 때문에 불가피했습니다. 제 어플리케이션의 이 라이브러리 업그레이드는 진행 중이며, 라이브러리 업그레이드 후의 성능 향상에 대해 향후 기사에서 보고하겠습니다.\n\n끝까지 긴 여행이니 그에 맞게 준비하세요! 그러나 궁금해 하지 않으시면, 깊이 파고들기 전에 미리 작성해 둔 주요 내용을 읽어보실 수 있습니다. 또한, 본 기사는 React, React Native, 그리고 React Native Animations의 기본을 알고 있다고 가정합니다. 그럼, 더 이상 미루지 말고 출발해봅시다!\n\n# 주요 내용\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- React 개발자로 활동하면 React Native 앱 개발에 대한 우위를 가질 수 있어요. 하지만 효율적인 React Native 앱을 만들기 위해 따르아야 할 특정한 디자인 가이드라인이 있어요. 예를 들어,\na. 좋은 예전 map 함수 대신 컴포넌트 목록을 렌더링하기 위해 FlatLists를 사용합니다.\nb. 제스처를 처리하기 위해 제스처 핸들러를 최대한 활용합니다 — 모바일 앱 개발은 클릭보다는 제스처에 집중되어 있어요.\nc. 컴포넌트를 애니메이션화하기 위해 Reanimated 라이브러리를 효율적으로 활용합니다. 다시 말해, 웹과는 다르게, 애니메이션은 앱 UX에서 더 중요한 역할을 합니다.\nd. 긴 목록의 컴포넌트를 렌더링하기 위해 항상 FlatLists를 사용합니다. 각 컴포넌트 내부의 비즈니스 로직을 최소화해야 합니다.\n- 목록을 어떻게 렌더링하든지간에, React는 목록의 모든 컴포넌트가 렌더링된 후에만 결과를 화면에 그립니다. 따라서, FlatLists를 사용하더라도 각 컴포넌트의 렌더링 시간을 최적화해야 합니다. 과도한 렌더링 로직은 막대한 화면 드랍을 초래할 수 있습니다.\n- 각 컴포넌트 내부에 무거운 렌더링 로직을 사용하는 것이 불가피할 경우, 렌더링 로직 실행을 디바운스하여 목록의 빠른 초기 로드를 보장할 수 있습니다. 제 경우, 각 목록 컴포넌트에 부담이 되는 MapView를 렌더링해야 했기 때문에 화면 드랍이 발생했어요. 해결책은 MapView를 렌더링하기 전에 의도적으로 1초의 지연을 도입하는 것이었어요. 이로써 화면 드랍 없이 초기 렌더링 시간이 빨라지게 되었고, Map은 초기 로드 후 1초 후에 렌더링되었습니다. 디바운스 중일 때 가벼운 로더를 표시해야 합니다. 사용자는 디바운스된 논리 실행 후 레이아웃 점프를 보게 되면 안 됩니다.\n- 앱 전체에서 재사용될 이미지를 미리 가져올 수 있어요. 이는 expo-image나 react-native-fast-image와 같은 라이브러리를 사용하여 수행할 수 있습니다.\n- 특히 목록 내부에 있는 컴포넌트를 메모라이즈해야 합니다.\ninitialNumToRender 속성을 사용 중이라면, FlatList는 초기 목록 컴포넌트가 렌더링된 후에 정의된 창 크기까지 전체 목록을 다시 렌더링합니다.\n예: 만약 initialNumToRender가 3이고 창 크기가 10이라면, FlatList는 다음과 같이 동작할 것입니다:\na. 처음 3개의 목록 항목을 초기로드합니다.\nb. 완료되었을 때, 첫 10개 항목을 렌더링합니다. 이미 로드된 처음 3개 항목을 다시 렌더링합니다.\n- React 상태와 Reanimated 공유 값이 혼합되지 않도록 주의해야 합니다. React 상태는 JS 스레드에서 유지되고, Reanimated 공유 값은 UI 스레드에서 유지됩니다. 항상 기억해야 할 사항은:\na. React 상태를 수정하는 것은 비용이 많이 들지만, 공유 값의 수정은 그렇지 않습니다.\nb. 공유 값 수정은 컴포넌트를 다시 렌더링하지 않습니다. 따라서 Reanimated 값 변경 시 자동으로 업데이트되지 않는다고 하더라도, Reanimated 래퍼 내에 있지 않는 React JS 변수는 컴포넌트가 업데이트되지 않습니다.\n- 마지막으로, React 상태 업데이트는 매우 비용이 많이 들 수 있음을 인지해야 합니다. Memoization은 이러한 문제를 해결하는 데 매우 유용합니다. 예를 들어, 부모에 상태 변수가 포함된 경우, 모든 자식이 부모 상태 변경 시 다시 렌더링됩니다. 이는 단순 컴포넌트에는 해로울 수 있지만, 무거운 자식 컴포넌트의 다시 렌더링은 화면 드랍을 유발할 수 있습니다. 메모라이제이션은 종속 프로퍼티 변경 시에만 다시 렌더링되도록 보정합니다.\n\n이론적인 내용이 도움이 되었기를 바라며, 지금은 비성능 페이지 수정의 풍요로운 여정을 떠나봅시다.\n\n# 프로필 페이지에 관한 내용과 마주한 문제들\n\n## 기능성 및 초기 컴포넌트 구조\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Component Structure](/assets/img/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney_0.png)\n\n프로필 페이지의 초기 구성은 위 이미지에 요약되어 있습니다. PersonalProfile은 이 페이지의 \"화면\"인 최상위 구성 요소입니다. PersonalProfile을 통해 다음 정보가 표시됩니다.\n\n- ProfileSummary 구성 요소는 다음을 표시합니다:\n  a. 프로필 사진 (Avatar라고 불리는 구성 요소를 통해)\n  b. 사용자의 이름\n  c. 사용자의 운동 횟수, 팔로워 수 및 사용자가 팔로우하는 사람 수\n\n- ProfileTabs 구성 요소에는 사용자가 최근에 완료한 운동 및 해당 사용자가 편성한 훈련 계획을 표시하는 두 개의 탭이 포함되어 있습니다.\n\n- WorkoutSnippet 구성 요소를 통해 각 운동이 요약됩니다. WorkoutSnippet은 운동 제목 (\"Saturday Night Run\"이 화면 샷에 표시됨), 캡션 (\"A good run\"이 화면 샷에 표시됨), 운동 경로를 나타내는 MapView, 운동 통계 및 운동과 상호 작용하는 몇 가지 제어가 표시됩니다.\n\n구성 요소 구조는 다음과 같이 요약될 수 있습니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n\u003cPersonalProfile\u003e\n  \u003cProfileSummary /\u003e\n  \u003cProfileTabs\u003e\n    {...\u003cWorkoutSnippet /\u003e}\n  \u003c/ProfileTabs\u003e\n\u003c/PersonalProfile\u003e\n```\n\nInitial analysis 후 많은 개선점을 발견했지만, 페이지 성능을 저해하는 주요 원인은 운동 스니펫 목록이었다고 결론지었습니다. 각 스니펫에는 비싼 MapView가 있었고, 잘못된 위치에 상태 업데이트가 발생하여 긴 목록이 다시 처음부터 렌더링되었습니다. 사용자가 페이지를 보기 전까지 React가 가상 DOM에서 전체 목록을 렌더링할 때 크게 프레임 속도가 떨어졌습니다.\n\n## 사용자 메타데이터 가져오기\n\n- 사용자 정보는 앱의 로컬 스토리지에 캐시되어 있어 같은 세션에서는 메타데이터를 다시 가져 오지 않습니다. 사용자가 프로필 페이지를 수동으로 새로 고치지 않는 한 (Instagram처럼 아래로 끌어 다시 가져오는 것), \n- 백엔드 통신은 GraphQL을 기반으로 하며, PersonalProfile 구성 요소는 Apollo의 useQuery 훅을 사용하여 메타데이터를 가져옵니다. 성공적인 검색을 통해 저장된 사용자 데이터를 업데이트해야 하므로 가져온 데이터에 대한 useEffect가 구현됩니다. 훅 값이 변경 될 때 캐시를 업데이트 합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n// 인증 컨텍스트를 사용하여 캐시 스토리지와 상호 작용합니다.\nconst { secureUser, setUserData } =\n    useContext\u003cAuthContextEntity\u003e(AuthContext);\n\n// 팔로워 및 팔로잉 수를 가져오기 위한 쿼리\nconst {\n  data: followCount,\n  loading: followCountLoading,\n  error: followCountError,\n} = useQuery\u003c{ userById: Partial\u003cUser\u003e }\u003e(userQueries.followCount, {\n  variables: { id: secureUser._id },\n});\n\n// 운동 수를 가져오기 위한 쿼리\nconst {\n  data: workoutCount,\n  loading: workoutCountLoading,\n  error: workoutCountError,\n} = useQuery\u003c{ getActivityCount: number }\u003e(\n  recentActivityQueries.activityCount,\n  {\n    variables: { userId: secureUser._id },\n  }\n);\n\nconst updateUserInCache = () =\u003e {\n  setUserData({\n    ...secureUser,\n    followCount: followCount.followCount,\n    followerCount: followCount.followerCount,\n    workoutCount,\n  });\n};\n\n// 운동 수 검색 후 캐시에 사용자 업데이트\nuseEffect(() =\u003e {\n  updateUserInCache();\n}, [workoutCount]);\n\n// 팔로워-팔로잉 수 검색 후 캐시에 사용자 업데이트\nuseEffect(() =\u003e {\n  updateUserInCache();\n}, [followCount]);\n```\n\n문제:\n이 메타데이터 가져오기는 Apollo 클라이언트 라이브러리에서 제공하는 훅에 의해 초기 렌더링 후에 발생합니다. 이 요청은 React 컨텍스트를 업데이트하므로 컨텍스트 업데이트는 루트 컴포넌트인 PersonalProfile을 다시 렌더링하게 만듭니다. 부모 컴포넌트의 다시 렌더링은 모든 하위 컴포넌트를 다시 렌더링하게 만듭니다.\n초기 로드 중 프레임 드롭의 원인은 아니지만, 이는 후속 렌더링 시간을 늘리는 원인이 되었습니다.\n해결책:\n모든 하위 컴포넌트의 메모이제이션.\n\n## 초기 코드- 탭 렌더링\n\n초기 설계에서 탭 관리 책임을 ProfileTabs 컴포넌트에 통합했습니다.\n다음과 같은 내용을 포함했습니다:```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 상단에 두 개의 탭이 있습니다 — 운동 및 훈련 계획.\n- 프로필 Body. 이 안에 있는 내용은 탭에 의해 관리되는 상태에 따라 다릅니다.\n\n두 탭 중 하나를 클릭하면 React 상태가 업데이트되어 Body가 다시 렌더링됩니다.\n이는 UX를 떨어뜨렸을 뿐만 아니라 두 탭 사이를 스와이프할 수 없고, 그냥 하나의 탭을 클릭해야 했으며, 본문에 포함된 전체 목록이 언마운트되어 다시 처음부터 마운트되고 활성 탭이 다시 전환되면 자신도 다시 렌더링되었습니다 — 가시적인 스터터가 발생했습니다.\n\n```js\nconst [activeTab, setActiveTab] = useState(0);\nconst handleTabPress = (index: number) =\u003e {\n  setActiveTab(index);\n};\nconst renderTabs = () =\u003e {\nreturn (\n    \u003c\u003e\n      \u003cView style={styles.tabContainer}\u003e\n        {tabs.map((tab, index) =\u003e (\n          \u003cTouchable\n            {...tabProps}\n          \u003e\n            {tab.icon}\n          \u003c/Touchable\u003e\n        ))}\n      \u003c/View\u003e\n      \u003cView style={styles.tabBottomContainer}\u003e\n        \u003cTabIndicator\n          activeIndex={activeTab}\n          width={styles.tabBottom.width}\n          height={styles.tabBottom.height}\n          backgroundColor={styles.tabBottom.backgroundColor}\n          totalTabs={TAB_ARR_LENGTH}\n        /\u003e\n      \u003c/View\u003e\n      {activeTab === 0 ? renderWorkouts() : renderTrainingPlans()}\n    \u003c/\u003e\n  );\n}\n```\n\n## 초기 코드 — 운동 목록 렌더링\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프레임 드랍의 뿌리는 비효율적으로 렌더링되는 고가의 구성 요소 목록입니다.\n\n```js\n\u003cView style={styles.body}\u003e\n  {recentWorkouts.map((workout, index) =\u003e (\n    \u003cWorkoutSnippet\n      workout={workout}\n      key={workout.endTime}\n      {...props}\n    /\u003e\n  ))}\n\u003c/View\u003e\n```\n\n알 수 있듯이 FlatList를 사용하지 않았으며 각 구성 요소가 비싼 MapView를 렌더링했습니다. 최적화 없이 초기에 6개의 WorkoutSnippet 및 따라서 한꺼번에 6개의 MapView가 렌더링되어 React가 거대한 프레임 드롭이 발생했습니다.\n동시에 프로필 페이지는 다음과 같은 문제를 마주해 큰 프레임 속도가 감소하게 되었습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 운동 목록의 초기 렌더링이 느립니다.\n- 사용자 정보를 업데이트하는 후크가 전체 페이지를 다시 렌더링하므로 이후에 발생하는 지연이 증가합니다.\n- 탭을 전환하면 본문이 다시 렌더링되어 지연을 야기합니다.\n\n아래 문제를 확인할 수 있습니다:\n\n![문제1](https://miro.medium.com/v2/resize:fit:932/1*zkDh8rVTwp3JcXvIGI_3gA.gif)\n\n![문제2](https://miro.medium.com/v2/resize:fit:632/1*zkEbgEryLuesOPbJHBejRw.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 프로파일러의 단점 관찰\n\n프로파일러를 읽는 방법을 모르겠다면, 이 기사를 읽기를 권장합니다. 프로파일러 데이터를 읽고 해석하는 것이 문제를 이해하고 이를 최적화하는 데 많은 역할을 했습니다.\n플레임 그래프는 가장 부담스러운 구성 요소를 확인하는 데 사용되었습니다. 이것이 어떻게해서 MapViews가 지연의 근본 원인인지 알아낼 수 있었던 이유입니다. 플레임 그래프는 또한 모든 연이은 렌더링을 나열하고 어떤 구성 요소가 다시 렌더링되었는지 강조합니다. 이것이 부담스러운 구성 요소의 불필요한 재렌더링을 알아낼 수 있는 방법이었습니다.\n\n프로파일러의 플레임 그래프를 읽은 결과는 다음과 같습니다:\n\n- 프로파일 화면의 초기 렌더링에는  list가 135ms 소요되어 총 200ms가 걸렸습니다.\n- 사용자 메타데이터를 가져오면 앞서 설명한대로 콘텍스트 개체가 업데이트되어 전체 화면이 다시 렌더링됩니다. 이 재렌더링은 122ms가 걸렸습니다.\n- 탭을 탐색하면 상태가 업데이트되어 탭 및 본문 전체가 다시 렌더링되며 렌더링 시간은 190ms였습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n안녕하세요!\n\n# 최적화\n\n## ScrollView를 FlatList로 대체하기\n\nFlatList는 React Native에서 제공하는 가상 리스트로, 대규모 리스트의 성능을 향상시키고 메모리 소비를 줄입니다. 이는 활성 항목들의 유한한 렌더 창을 유지함으로써 달성됩니다. 이 렌더 창 밖에 있는 항목들은 공백 뷰로 대체되어 전체 리스트의 성능을 향상시킵니다. 렌더 성능을 최적화하기 위해 여러 프롭스가 제공되며, 개발자는 렌더 창을 미세 조정할 수 있습니다. 리스트의 초기 렌더링에 문제가 있었기 때문에 initialNumToRender 프롭이 관련이 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n따라서 ScrollView 안에있던 맵을 FlatList로 전환하여 운동 목록을 렌더링했습니다:\n\n```js\nconst renderItem: ListRenderItem\u003cWorkout\u003e = useCallback(\n  (workout: ListRenderItemInfo\u003cWorkout\u003e) =\u003e {\n    return (\n      \u003cWorkoutSnippet\n        workout={workout.item}\n        {...otherProps}\n      /\u003e\n    );\n  },\n  []\n);\nreturn (\n  \u003cFlatList\n    data={workouts}\n    renderItem={renderItem}\n    keyExtractor={(item) =\u003e item._id}\n    initialNumToRender={3}\n    {...otherProps}\n  /\u003e\n);\n```\n\n아래에 몇 가지 주요 관찰 사항이 나와 있어요. 주의 깊게 읽어 주세요:\n\n- initialNumToRender 속성을 3으로 설정하여 가상 목록이 초기 렌더링 시 처음 3개 요소만 렌더링되도록 했어요.\n그러나 초기 렌더링이 완료되면, 가상 목록이 창 크기 내의 모든 항목을 렌더링합니다 (기본적으로 10 뷰포트 단위에 해당하는).\n재랜더링 시 초기에 렌더링된 구성 요소를 무시하지 않아요. 창 크기 내 목록의 모든 항목이 다시 렌더링됩니다.\n예: 창 크기 내에 10개 항목이 있고, 초기 렌더링할 항목 수가 3개이면 목록은 다음과 같이 되겠죠:\ni. 초기 렌더링 시 3개 항목을 렌더링합니다.\nii. 다음 렌더링 시 (이미 렌더링된 초기 항목 포함) 모든 10개 항목을 렌더링합니다.\n따라서, 가상 목록에서 재랜더링을 방지하기 위해 렌더링되는 구성 요소를 메모이즈하는 것이 중요합니다.\n목록에서 렌더링되는 구성 요소를 메모이즈하면 초기 항목이 다시 불필요하게 렌더링되는 것을 방지할 수 있어요.\n- renderItem 속성에 전달된 함수는 FlatList의 렌더링 로직을 정의합니다.\n이것을 참조로 전달하고, useCallback 훅 내부에 래핑되었는지 확인하는 것이 중요합니다.\n이를 하지 않으면 FlatList 부모의 재랜더링마다 함수가 재정의되어 목록의 중복 재랜더링을 일으킬 수 있어요. 그것은 매우 비용이 많이들 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 최적화를 고려한 후에 성능을 확인해봅시다:\n\n![GIF](https://miro.medium.com/v2/resize:fit:1224/1*eMhn-98QVNHKvJh4T-ILnQ.gif)\n\n관찰할 수 있듯이, 여전히 일시적인 끊김이 있습니다! 3개의 컴포넌트를 동시에 렌더링해도, MapView는 여전히 핸드폰이 작은 시간프레임 내에서 렌더링하기에 너무 많은 부하를 줍니다.\n\n## MapViews의 지연 로딩\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해결책은 MapViews를 Lazy Load하는 것이었습니다. 이 방법은 다음과 같이 작동했습니다:\n\n- 각 목록 항목에 고정 높이 MapView가 있습니다.\n- MapView의 로딩을 일부러 1초 지연합니다.\n- 해당 시간까지 MapView 자리에 스켈레톤 로더를 표시합니다.\n\n마운트 시에 useEffect 내에서 timeout을 놓는 것으로 구현하였습니다.\n리스트 컴포넌트 내에 상태를 배치합니다:\n\n```js\nconst [mapLoaded, setMapLoaded] = useState(false);\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n리스트 컴포넌트 내에 useEffect를 정의하세요:\n\n```js\nuseEffect(() =\u003e {\n  setTimeout(() =\u003e {\n    setMapLoaded(true);\n  }, 1000);\n}, []);\n```\n\nMapView 렌더링 로직:\n\n```js\nif (!mapLoaded) {\n  return (\n    \u003cActivityIndicator /\u003e\n  );\n}\nreturn (\n  \u003cMapView {...props} /\u003e\n);\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n최종 최적화:\n\n지도를 이렇게 로드하는 것은 mapLoaded = false에서 mapLoaded = true로 상태가 업데이트되는 동안 UI를 차단합니다. 예를 들어, 이 상태가 업데이트되는 동안 탭을 전환하려고 하면 지연이 발생할 수 있습니다. 여기서 React의 새로운 비동기 아키텍처가 문제를 해결해 줍니다 - useTransition 훅을 사용하여 비동기 상태 업데이트를 실행함으로써 차단된 UI 요소는 더 이상 문제가 되지 않습니다. 더 자세한 내용은 여기를 참조하세요.\n따라서 우리는 이 상태 업데이트를 전환 내부로 감싸줍니다:\n\n```js\nuseEffect(() =\u003e {\n  setTimeout(() =\u003e {\n    startTransition(() =\u003e {\n      setMapLoaded(true);\n    });\n  }, 1000);\n}, []);\n```\n\n마지막으로, 여기가 결과입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](https://miro.medium.com/v2/resize:fit:808/1*lXJIEkRu_pn9vl7VH5loag.gif)\n\nThe drop during mount is now down to 82 FPS from a previously unreliable 20–40 FPS! There is an inevitable drop when the MapViews load in eventually after 1 second, but the UI remains responsive throughout!\n\nAs for the profiler results, the render time of the screen dropped to 120ms, with the list itself taking 90ms.\nThat’s an improvement by a third of the original render time!\n\n## Fixing Tab Switching Logic — Making the Tabs Swipe-able\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이전에는 탭을 클릭할 수만 있고 스와이프할 수는 없었습니다. 탭을 전환할 때마다 본문이 다시 렌더링되어 부드럽지 않은 화면 전환이 발생했죠. 이 문제를 해결하기 위해 본문을 수평으로 렌더링하는 FlatList로 변경할 것입니다. 이렇게하면 재렌더링으로 인한 문제 해결뿐 아니라 (FlatList는 상태에 관계없이 두 번째 탭을 게으르게 렌더링합니다), 사용자 경험을 더 좋게 만들어 프로필 페이지를 더 쉽게 탐색할 수 있습니다.\n\n참고: 이 하위 섹션은 최적화보다는 UI 디자인 구현에 가깝습니다. 이 섹션은 읽지 않고 결과만 보셔도 됩니다.\n\n다음은 새로운 레이아웃입니다:\n\n![이미지](/assets/img/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n최종 결과물:\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:504/1*Drzw-Y4UMkDy09OwlS2v2Q.gif\" /\u003e\n\n정말 부드러운 모션인데요!\n\n사용자가 수평으로 스와이프할 때 무슨 일이 벌어지는지 자세히 살펴봅시다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 사용자가 탭의 너비의 약 50%로 스크롤 할 때 활성 탭 아이콘이 \"점등\"합니다.\n- 활성 탭을 나타내는 하얀색 하단 테두리가 사용자의 수평 스크롤에 따라 이동합니다.\n\n![이미지](https://miro.medium.com/v2/resize:fit:712/1*bfGvqGl9Z1vbTZ9QQgHUHw.gif)\n\n3. 탭을 클릭하면 본문이 100% 스크롤되어 다음 요소로 이동합니다. 탭 표시기도 함께 이동합니다.\n\n![이미지](https://miro.medium.com/v2/resize:fit:956/1*kXqvHtGO3Avsa_jBwGsgjA.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 고정 탭 구현하기\n\n이것은 매우 간단합니다. React Native의 FlatList 컴포넌트가 제공하는 stickyHeaderIndices 속성은 수직 목록에서 작동하며 지정된 인덱스의 구성요소를 스크롤할 때 상단에 고정시킵니다. 다음은 프로필 화면 내에 정의된 최상위 FlatList의 코드입니다:\n\n```js\nconst flatListData = useMemo(\n  () =\u003e [renderProfileSummary, renderTabs, renderBody],\n  [renderProfileSummary, renderTabs, renderBody]\n);\nconst renderItem: ListRenderItem\u003c() =\u003e JSX.Element\u003e = useCallback(\n  (item) =\u003e item.item(),\n  []\n);\nconst stickyIndices = useMemo(() =\u003e [1], []);\n\n\u003cFlatList\n  data={flatListData}\n  renderItem={renderItem}\n  stickyHeaderIndices={stickyIndices}\n  {...otherProps}\n/\u003e\n```\n\nFlatList로 전달된 모든 데이터가 메모화된 것에 주목하세요. 이는 프로필 화면의 재렌더링 시 props의 재정의를 방지해야 하기 때문입니다 (React는 객체에 대한 참조 무결성을 확인합니다. 객체를 메모화하면 렌더링 간 참조 무결성을 유지하는 데 도움이 됩니다). 기억하세요 - props의 변경은 전체 목록을 다시 렌더링하게 만들며, 우리는 그것을 방지하려고 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- ProfileSummary(프로필 요약 렌더링), Tabs(탭 렌더링), 및 body(본문 렌더링) 함수들은 데이터로 FlatList에 전달됩니다. renderItem 함수는 이러한 함수들을 간단히 실행합니다.\n- stickyHeaderIndices가 [1]로 정의되어 있습니다. 이는 우리가 탭들(데이터 배열의 첫 번째 위치에 정의된)을 스크롤하여 지나갈 때에 고정시킵니다.\n\n## 동적으로 하단 테두리 효과 구현하기\n\n이 부분은 다소 까다로운 부분입니다. 이 효과를 달성하기 위해 Reanimated 라이브러리의 공유 값(shared values)을 활용했습니다. 만약 이 라이브러리에 익숙하지 않다면, 그 뛰어난 문서를 읽어보는 것을 권합니다.\n\n한 발 물러서서, 가로 스크롤 뷰에 대해 다음을 관찰합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 각 탭은 화면 너비와 같은 너비를 갖습니다 (100vw).\n- 따라서, 수평 스크롤 뷰의 총 너비는 nTabs * 100vw 입니다. 이것은 우리의 공유 값의 범위가 됩니다:\n[스크롤 없음, 모든 탭 스크롤됨] = [0, nTabs * 100vw]\n다시 말해, 애니메이션 값은 사용자가 수평으로 스크롤한 픽셀량을 단순히 추적할 것입니다.\n\n수평 FlatList가 스크롤되면, 이 애니메이션의 값을 조정하여 단순히 사용자가 스크롤한 현재 오프셋 (픽셀 수)이어야 합니다. FlatList의 onScroll 프로퍼티를 사용하면 아주 쉽게 이를 달성할 수 있습니다:\n\n```js\nconst onBodyScroll = useCallback(\n  (event: NativeSyntheticEvent\u003cNativeScrollEvent\u003e) =\u003e {\n    const { nativeEvent } = event;\n    const { contentOffset } = nativeEvent;\n    const { x } = contentOffset;\n    swipeAnimationValue.value = x;\n  },\n  [swipeAnimationValue]\n);\n``` \n\n마지막으로, 탭 인디케이터의 스타일을 다음과 같이 설정하겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nconst indicatorStyle = useAnimatedStyle(() =\u003e ({\n  position: \"absolute\",\n  bottom: 0,\n  left: 0,\n  width: vw(100 / nTabs),\n  transform: [\n    {\n      translateX: interpolate(animatedValue.value, [0, nTabs * vw(100)], [\n        0,\n        nTabs * vw(100 / nTabs),\n      ]),\n    },\n  ],\n}));\n```\n\ninterpolare 함수는 애니메이션 값과 스타일 속성 값의 매핑을 담당합니다.\n\n- 인디케이터의 너비는 100 % / nTabs (우리 예에서 50vw)와 같아야 합니다.\n- 인디케이터는 왼쪽 하단에 절대 위치로 배치됩니다.\n- 스크롤이 없는 경우에는 어떤 이동도 필요하지 않습니다. 목록이 완전히 스크롤되었을 때 (마지막 요소조차 완전히 스크롤된 경우), 인디케이터는 nTabs * vw(100 / nTabs)만큼 이동해야 합니다.\nReanimated 라이브러리가 이들 극단값 사이의 중간 값들을 처리해줄 것입니다.\n\n아래에 시각화가 제공되었습니다: \n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney_2.png)\n\nThis wraps up our translation effect!\n\n## Achieving Dynamic Tab Icon Color\n\nObserve carefully when the color of the tab icon changes:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](https://miro.medium.com/v2/resize:fit:1100/1*S9kq4JSTm65UgmYbbv_Cpg.gif)\n\n사용자가 탭 본문의 50% 이상으로 스크롤했을 때 탭 색상이 변경됩니다. 새로운 색상으로 유지되는 기간은 얼마인가요? 사용자가 탭 본문의 50% 이상 스크롤하지 않는 한 계속해서 색상이 유지됩니다.\n우리의 animatedValue가 저장하고 있는 것을 기억하세요: 그렇습니다, 수평 FlatList의 스크롤 오프셋을 저장하고 있습니다!\n우리는 Reanimated 라이브러리에서 제공되는 interpolateColor 함수를 사용하여 탭의 색상을 보간할 수 있습니다!\n스크롤 오프셋을 탭 아이콘의 색상으로 매핑하는 보간 함수를 구성해야 합니다.\n\n각 탭에는 인덱스가 있습니다. 여기서 두 탭의 인덱스는 각각 0과 1입니다.\n\n여기 우리의 수평 탭 본문 목록이 펼쳐진 모습입니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\u003cimg src=\"/assets/img/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney_3.png\" /\u003e\n\n그러므로, animatedValue의 최대 가능한 값은 얼마라고 생각하시나요?\n200vw를 추측했다면, 정답입니다. 이는 사용자가 두 번째 탭 (Tab 1)을 넘어간 경우, 즉 뷰포트에 탭이 전혀 표시되지 않는 경우입니다.\n여기에 마지막으로, 각 탭이 시작하는 오프셋을 기록합니다:\n\n- Tab 0는 오프셋 0에서 시작합니다.\n- Tab 1은 Tab 0 이후 100vw에서 시작합니다.\n\n여기 사용자가 초기에 화면에서 볼 수 있는 것입니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney_4.png\" /\u003e\n\n여기서,\n\n- 스크롤 오프셋은 0입니다 (스크롤이 발생하지 않았으므로, animatedValue는 0입니다.)\n- 탭 0은 활성화된 색 (흰색)을 가지고 있고, 탭 1은 비활성화된 색 (회색)을 가지고 있습니다.\n\n자, 이제 활성 탭이 변경될 때 스크롤의 정확한 상태를 확인해 봅시다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney_5.png\" /\u003e\n\n여기서,\n\n- 스크롤 오프셋은 50vw입니다(탭의 반쪽이 사용자에 의해 스크롤되어 지나갔기 때문에), 그래서 우리의 애니메이션 값은 50vw입니다.\n- 탭 0은 비활성화되었고(회색), 탭 1은 활성화되었습니다(흰색).\n\n이전에 언급한 것처럼, 탭 0의 스크롤 오프셋은 0에서 시작하고, 탭 1의 스크롤 오프셋은 100vw에서 시작합니다. 추론하면, 삽입된 탭 2는 200vw에서 시작할 것이며, 이와 같은 식으로 계속됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n애니메이션을 완성하려면 이 최종 질문에 답해야 합니다:\n\n답변:\n사용자가 (i — 0.5) * x로 스크롤할 때(시작 오프셋 — 탭 너비의 50%라면) 탭을 활성화합니다.\n사용자가 (i + 0.5) * x로 스크롤할 때(시작 오프셋 + 탭 너비의 50%라면) 탭을 비활성화합니다.\n우리 예시에서 이를 설명하면,\n- 탭 0은 현재 스크롤 오프셋이 (0–0.5) * 100vw와 (0+0.5) * 100vw, 즉 -50vw와 50vw 사이일 때 활성화됩니다.\n- 탭 1은 현재 스크롤 오프셋이 (1 - 0.5) * 100vw와 (1 + 0.5) * 100vw, 즉 50vw와 150vw 사이일 때 활성화됩니다.\n\n마침내 보간된 아이콘 스타일이 준비되었습니다:\n\n```js\nconst iconStyle = useAnimatedStyle(() =\u003e ({\n  color: interpolateColor(\n    animatedValue.value,\n    [\n      (idx - 0.5) * animOffset - 1,\n      (idx - 0.5) * animOffset,\n      (idx + 0.5) * animOffset,\n      (idx + 0.5) * animOffset + 1,\n    ],\n    [inactiveTabColor, activeTabColor, activeTabColor, inactiveTabColor],\n  ),\n}));\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만개의 프롭 객체가 전부 useMemo를 사용해 메모이제이션했고, 화면의 모든 자식 컴포넌트를 React.memo를 사용해 메모이즈드 컴포넌트로 만들었어요.\n\n## 최적의 라이브러리 사용과 아이콘 폰트 미리 불러오기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이미지 및 글꼴을 렌더링할 때 추가 밀리초를 저장하기 위한 마지막 단계였습니다. React Native 문서 자체에서는 기본 `Image /` 컴포넌트 대신 전용 이미지 라이브러리를 사용하는 것을 제안합니다. expo-image 라이브러리는 잘 유지되며 이미지를 캐시하는 옵션을 제공합니다.\n\n정적 데이터를 가져오는 최적화를 위해 앱을 로드할 때 모든 아이콘 및 텍스트 글꼴을 미리 가져오기 위해 expo-font 패키지를 사용했습니다:\n\n```js\nconst [fontsLoaded] = useFonts({\n  // 텍스트 글꼴\n  Oswald: require(\"fitnet/assets/textFonts/Oswald.ttf\"),\n  Raleway: require(\"./src/assets/textFonts/Raleway.ttf\"),\n  \"Raleway-Bold\": require(\"./src/assets/textFonts/Raleway-Bold.ttf\"),\n  // 아이콘 글꼴\n  NavBarIcons: require(\"fitnet/assets/iconFonts/NavBarIcons.ttf\"),\n  HomeIcons: require(\"fitnet/assets/iconFonts/HomeIcons.ttf\"),\n  ...AntDesign.font,\n  ...createIconSetFromIcoMoon.font,\n  ...EvilIcons.font,\n  ...FontAwesome.font,\n  ...FontAwesome5.font,\n  ...MaterialCommunityIcons.font,\n  ...MaterialIcons.font,\n});\n```\n\nexpo-image 라이브러리를 사용하여 사용자의 프로필 사진을 로그인할 때 캐시하고 앱 전체에 걸쳐 프로필 사진을 반복 다운로드하는 것을 방지했습니다. 이는 로그아웃 시에 지워졌습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n```js\nconst signIn = (user) =\u003e {\n  if (user.displayPicture) {\n    Image.prefetch(user.displayPicture, \"memory\");\n  }\n  setUserData(user);\n};\n...\nconst signOut = async () =\u003e {\n  await unsetUserData();\n  await clearAsyncStorage();\n  await Image.clearMemoryCache();\n  await Image.clearDiskCache();\n}\n```\n\n# 결론\n\n긴 여정이었습니다! React Native 애플리케이션을 최적으로 설계하는 데 어떤 통찰력을 얻었으면 좋겠어요. 메모이제이션, 적절한 네이티브 컴포넌트 사용, 캐싱 그리고 값 비싼 로직을 신중하게 배치하는 것은 앱을 최적화하는 데 큰 역할을 합니다. 이러한 전략을 사용하여 렌더링 시간을 200ms에서 110ms로 줄일 수 있었어요. 탭을 재설계하고 reanimated 라이브러리를 활용하며 값 비싼 상태 업데이트를 피함으로써 추후의 느림 현상을 완전히 제거할 수 있었어요! 프로파일러는 앱 성능의 병목 지점을 관찰하는 데 훌륭한 도구에요. 다음 번엔 또 뵙겠습니다!\n\n# 관련 기사\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 테이블 태그를 Markdown 형식으로 변경해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n리액트 네이티브에서 대량의 UI 항목을 최적으로 로드하는 방법에 대한 제안 목록입니다.","ogImage":{"url":"/assets/img/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney_0.png"},"coverImage":"/assets/img/2024-05-17-OptimizingaHeavyReactNativePageAGradualRewriteJourney_0.png","tag":["Tech"],"readingTime":20},{"title":"Vite, Nginx 및 런타임에서 정적 웹 사이트용 환경 변수 적용하는 방법","description":"","date":"2024-05-17 20:51","slug":"2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime","content":"\n\n\u003cimg src=\"/assets/img/2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime_0.png\" /\u003e\n\n안녕하세요 여러분! 저는 Quadcode의 프런트엔드 개발자 Dmitry Pashkevich입니다. 오늘은 Vite 빌드 도구와 Nginx 웹 서버를 이용하여 정적 웹사이트에 런타임 환경 변수를 전달하는 방법을 공유하려고 합니다.\n\n프런트엔드 개발에서 흔한 작업은 애플리케이션에 환경 변수를 전달하는 것입니다. 애플리케이션이 실행되는 환경에 따라 다르게 동작하도록 환경 변수를 설정하는 작업이죠. 간단한 작업으로 보이지만 이를 문서에 설명된 대로 처리하려면 .env 파일을 옆에 두고 빌드를 실행해야 합니다... 각 환경에서 말이죠.\n\n솔루션을 찾은 것 같습니다. 그러나 이로 인해 각 환경마다 다른 빌드 프로세스와 이에 따른 다른 결과로 이어집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n실무에서 빌드 단계의 기능에 문제가 발생하는 경우가 종종 있습니다. 예를 들어 변경 사항을 적용할 때 한 환경을 위해 설정, 스크립트 등을 업데이트하는 것을 잊을 때가 있습니다. 결과적으로, 아티팩트도 다르기 때문에 애플리케이션 자체에 문제가 발생합니다.\n\n그러므로 모든 환경에 대해 하나의 빌드 아티팩트를 얻고 환경 변수 값을 전달할 수 있는 것이 더 나을 것으로 보입니다. 따라서 변수 값이 정확한 한 가지 문제를 해결하는 것이 빌드 단계를 조사하는 것보다 더 쉽습니다.\n\n그럼 이를 Vite와 Nginx 도구를 사용한 예제로 어떻게 수행할 수 있는지 살펴봅시다.\n\n# 저장소 준비\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저 React + Typescript용 Vite 빌더에서 제공하는 템플릿을 사용하여 프로젝트를 생성해보겠습니다.\n\n```js\nnpm create vite@latest vite-nginx-dynamic-env-variables-example -- \n--template react-ts \u0026\u0026 cd vite-nginx-dynamic-env-variables-example \u0026\u0026 npm \ninstal\n```\n\n# 프로젝트 구성 준비\n\n위 명령어를 성공적으로 실행한 후, 새로 생성된 프로젝트를 좋아하는 IDE에서 열고 목표 솔루션을 만들기 시작해봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파일 src/vite-env.d.ts를 수정해보세요. IDE 힌팅을 활성화하기 위해 사용 가능한 환경 변수 유형에 대한 설명을 추가할 거에요.\n\n```js\n/// \u003creference types=\"vite/client\" /\u003e\n\ninterface ImportMetaEnv {\n    readonly VITE_VERSION: string\n}\n\ninterface ImportMeta {\n    readonly env: ImportMetaEnv\n}\n```\n\n이제 IDE가 사용 가능한 환경 변수에 대한 힌트를 제공할 거예요.\n\n다음으로, 환경 변수 템플릿이 들어 있는 파일을 생성해볼게요: src/shared/projectEnvVariables.ts. 그리고 아래 내용을 추가해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ntype ProjectEnvVariablesType = Pick\u003cImportMetaEnv, 'VITE_VERSION'\u003e\n\n\n// 환경 변수 템플릿 런타임에 대체되도록\nconst projectEnvVariables: ProjectEnvVariablesType = {\n   VITE_VERSION: '${VITE_VERSION}',\n}\n\n\n// 런타임에서 변수 값을 반환하거나 빌드 결과로 얻음\nexport const getProjectEnvVariables = (): {\n   envVariables: ProjectEnvVariablesType\n} =\u003e {\n   return {\n       envVariables: {\n           VITE_VERSION: !projectEnvVariables.VITE_VERSION.includes('VITE_') ? projectEnvVariables.VITE_VERSION : import.meta.env.VITE_VERSION,\n       }\n   }\n}\n```\n\n그 다음, 위의 파일이 빌드 단계 후 예측 가능한 이름을 갖도록 빌드 구성을 vite.config.ts에 변경해야 합니다. 이를 위해 구성에 rollup을 위한 섹션을 추가해주세요.\n\n```js\nimport { defineConfig } from 'vite'\nimport react from '@vitejs/plugin-react'\n\n// https://vitejs.dev/config/\nexport default defineConfig({\n   plugins: [react()],\n   build: {\n       rollupOptions: {\n           output: {\n               format: 'es',\n               globals: {\n                   react: 'React',\n                   'react-dom': 'ReactDOM',\n               },\n               manualChunks(id) {\n                   if (/projectEnvVariables.ts/.test(id)) {\n                       return 'projectEnvVariables'\n                   }\n               },\n           },\n       }\n   }\n}\n```\n\nmanualChunks 섹션에서 사용자 정의 청크를 생성하고, 파일을 빌드한 후 이 파일을 환경 변수로 대체할 수 있도록 일부 이름을 저장합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nsrc/App.tsx 파일을 수정하여 환경 변수의 값들을 확인해봅시다.\n\n```js\nimport { getProjectEnvVariables } from \"./shared/projectEnvVariables.ts\";\n\nconst { envVariables } = getProjectEnvVariables()\n\nfunction App() {\n return (\n     \u003c\u003e\n         \u003ch1\u003eVITE_VERSION\u003c/h1\u003e\n         \u003cdiv\u003e{envVariables.VITE_VERSION}\u003c/div\u003e\n\n         \u003chr /\u003e\n\n         \u003ch2\u003eimport.meta.env.VITE_VERSION\u003c/h2\u003e\n         \u003cdiv\u003e{import.meta.env.VITE_VERSION}\u003c/div\u003e\n     \u003c/\u003e\n )\n}\n\nexport default App\n```\n\n다음으로, 빌드를 실행하여 빌드 단계 이후에 변수를 대체하는 데 필요한 청크를 얻었는지 확인해봅시다.\n\n```js\nnpm run build\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n빌드가 완료되면 dist/assets 디렉토리로 이동하세요. 이전에 구성한 projectEnvVariables*이라는 청크가 존재하는 것을 확인할 수 있을 겁니다.\n\n![이미지](/assets/img/2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime_1.png)\n\n이제 연이어 실험을 진행해보겠습니다.\n\n원하는 빌드 결과를 얻는 데 쉽게 이해할 수 있도록, 각 빌드는 지정된 환경 변수로 수행될 것입니다. 이를 통해 getProjectEnvVariables 함수에서 환경 변수의 값을 반환하는 조건을 시각적으로 확인할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n첫 번째 실험을 위해 프로젝트 루트에 다음 내용을 포함한 .env 파일을 생성해주세요.\n\n```js\nVITE_VERSION=dev\n```\n\n프로젝트 빌드를 시작하고 빌드 결과를 확인하는 모드로 전환해봅시다.\n\n```js\nnpm run build \u0026\u0026 npm run preview\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nhttp://localhost:4173/로 이동하면 구성에서 직접 환경 변수로부터 읽은 변수의 두 개의 동일한 값이 표시됩니다.\n\n![image](/assets/img/2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime_2.png)\n\n두 번째 실험에서는 애플리케이션을 빌드한 후 생성된 dist/assets/projectEnvVariables-wa84hTgi.js 파일에서 변수를 변경해보겠습니다. 이 파일에서 $'VITE_VERSION' 값이 들어있는 줄을 dev_from_env로 바꿔주세요. 브라우저에서 페이지를 새로고침하면 구성 getProjectEnvVariables에서 읽은 화면의 변수가 업데이트된 버전으로 표시됩니다.\n\n![image](/assets/img/2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모든 것이 예상대로 작동합니다! 이제 변수 대체를 자동화할 차례입니다.\n\n# 도커 + Nginx 환경 설정 준비\n\nDocker 컨테이너를 사용하여 Nginx 웹 서버를 실행하기 전에 초기화 스크립트를 실행하고 envsubst를 사용하여 환경 변수를 대체하는 변수 대체의 자동화를 보여 드리겠습니다.\n\n프로젝트 루트에 .docker 디렉토리를 만들어 Nginx 웹 서버를 위한 구성 내용을 넣어주시면 됩니다. Nginx 구성의 완전한 예시는 저장소에 있으며, 아래는 .docker/app/nginx/init-scripts/100-init-project-env-variables.sh 파일의 bash 코드입니다. 이 코드는 환경 변수를 대체합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```sh\n#!/usr/bin/env sh\n\nset -ex\n\n#환경 변수를 치환해야 하는 파일을 찾습니다.\nprojectEnvVariables=$(ls -t /usr/share/nginx/html/assets/projectEnvVariables*.js | head -n1)\n\n#환경 변수를 치환합니다.\nenvsubst \u003c \"$projectEnvVariables\" \u003e ./projectEnvVariables_temp\ncp ./projectEnvVariables_temp \"$projectEnvVariables\"\nrm ./projectEnvVariables_temp\n```\n\n이후에, 프로젝트 루트에서 다음 내용을 가진 Dockerfile을 생성하세요. 이 Dockerfile은 애플리케이션을 빌드하고 정적 파일을 제공하기 위해 Nginx 웹 서버를 실행하는 내용을 설명합니다.\n\n```dockerfile\nFROM node:20-alpine as builder\n\nWORKDIR /app\n\nCOPY package.json package-lock.json ./\n\nRUN npm ci\n\nCOPY . .\n\nARG NODE_ENV=production\nENV NODE_ENV=${NODE_ENV}\n\nRUN npm run build\n\nFROM nginx:alpine\n\nARG VITE_VERSION=dev\nENV VITE_VERSION=${VITE_VERSION}\n\nARG PORT=80\nENV NGINX_PORT=${PORT}\nENV NGINX_HOST=localhost\n\nEXPOSE ${PORT}\n\nCOPY .docker/app/nginx/nginx.conf /etc/nginx/nginx.conf\nCOPY .docker/app/nginx/conf.d/ /etc/nginx/conf.d/\nCOPY .docker/app/entrypoint.sh /entrypoint.sh\nCOPY .docker/app/nginx/init-scripts/ /docker-entrypoint.d/\n\nWORKDIR /usr/share/nginx/html\n\nCOPY --from=builder /app/dist ./\n```\n\n이제 컨테이너를 빌드해봅시다.\n  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndocker build -t\nvite-nginx-dynamic-env-variables-example .\n```\n\n다음으로, 응용 프로그램에서 사용할 환경 변수에 대한 새로운 값을 가진 작성된 컨테이너를 실행해 봅시다.\n\n```js\ndocker run -p 81:80 -e VITE_VERSION=FROM_NGINX\nvite-nginx-dynamic-env-variables-example\n```\nhttp://127.0.0.1:81 으로 이동하여, 환경 변수가 현재 값으로 초기화되었음을 확인할 수 있습니다. 직접 읽은 환경 변수는 여전히 이전 값으로 남아 있습니다.```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime_4.png\" /\u003e\n\n# 결론\n\n이렇게 하면 실행 중에 환경 변수를 정적으로 빌드된 애플리케이션에 대체하여 모든 환경에서 통합 빌드가 가능합니다.\n\n코드는 저장소에서 찾을 수 있습니다.","ogImage":{"url":"/assets/img/2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime_0.png"},"coverImage":"/assets/img/2024-05-17-ViteNginxandenvironmentvariablesforastaticwebsiteatruntime_0.png","tag":["Tech"],"readingTime":7},{"title":"대형 언어 모델LLM을 활용한 웹 어플리케이션 만드는 방법","description":"","date":"2024-05-17 20:49","slug":"2024-05-17-BuildingaWebApplicationPoweredbyLargeLanguageModelsLLMpart2","content":"\n\n\u003cimg src=\"/assets/img/2024-05-17-BuildingaWebApplicationPoweredbyLargeLanguageModelsLLMpart2_0.png\" /\u003e\n\n이전 글인 Building a Web Application Powered by Large Language Models (LLM): part 1에서는 ASP.NET Core API를 사용하여 CV 리뷰어 애플리케이션을 위한 견고한 백엔드를 개발했습니다. 웹 스크래핑을 위해 Azure Function을 활용하고 GPT 모델을 통합하여 이력서를 채용 공고와 관련하여 분석했습니다. 이번 글에서는 React 템플릿과 TypeScript를 사용하여 애플리케이션의 프론트엔드를 구축하는 데 초점을 맞출 것입니다. Bootstrap을 사용하여 애플리케이션을 스타일링하여 반응형이며 사용자 친화적인 인터페이스를 제공할 것입니다.\n\n# 요구 사항\n\n- Node.js와 npm이 컴퓨터에 설치되어 있어야 합니다.\n- React 및 TypeScript의 기본적인 이해가 필요합니다.\n- Bootstrap 스타일링에 대한 이해가 있으면 도움이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# React 프로젝트 설정하기\n\nVite를 사용하여 React 프로젝트 초기화: Vite는 React 애플리케이션을 위한 빠르고 최적화된 설정을 제공합니다. TypeScript 템플릿을 이용하여 Vite로 새로운 React 프로젝트를 생성하세요.\n\n```js\nnpm create vite@latest cv.reviewer.frontend -- --template react-ts\ncd cv.reviewer.frontend\n```\n\nBootstrap 설치하기: 프로젝트에 스타일링을 위해 Bootstrap을 추가하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nnpm install bootstrap@5.3.0\nnpm install @types/bootstrap\n```\n\n프로젝트 구조: 프로젝트를 컴포넌트, 서비스 및 스타일 폴더로 구성하여 관리를 더욱 편리하게 합니다.\n\n# 부트스트랩 및 전역 스타일 설정\n\nmain.tsx에 부트스트랩을 가져오세요: 메인 엔트리 파일에 부트스트랩 CSS를 추가하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport React from 'react';\nimport ReactDOM from 'react-dom/client';\nimport App from './App';\nimport 'bootstrap/dist/css/bootstrap.min.css';\nimport './styles/global.css';\n\nReactDOM.createRoot(document.getElementById('root') as HTMLElement).render(\n  \u003cReact.StrictMode\u003e\n    \u003cApp /\u003e\n  \u003c/React.StrictMode\u003e\n);\n```\n\n글로벌 스타일: styles 폴더에 global.css 파일을 만들어 추가적인 글로벌 스타일을 적용하세요.\n\n```js\nbody {\n  background-color: #f8f9fa;\n}\n```\n\n# 주요 컴포넌트 구축하기\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nFormComponent.tsx를 만들어보세요: 이 컴포넌트는 파일 업로드와 작업 URL 입력을 처리할 겁니다.\n\n```js\nimport React, { useState } from \"react\";\nimport apiClient from \"../services/apiClient\";\n\nconst FormComponent: React.FC = () =\u003e {\n  const [jobUrl, setJobUrl] = useState(\"\");\n  const [cvFile, setCvFile] = useState\u003cFile | null\u003e(null);\n  const [review, setReview] = useState\u003cstring | null\u003e(null);\n  const [adSource, setAdSource] = useState\u003cstring | null\u003e(null);\n  const [title, setJobTitle] = useState\u003cstring | null\u003e(null);\n  const [description, setJobDescription] = useState\u003cstring | null\u003e(null);\n  const [loading, setLoading] = useState(false);\n\n  const handleUrlChange = (e: React.ChangeEvent\u003cHTMLInputElement\u003e) =\u003e {\n    setJobUrl(e.target.value);\n  };\n\n  const handleFileChange = (e: React.ChangeEvent\u003cHTMLInputElement\u003e) =\u003e {\n    if (e.target.files) {\n      setCvFile(e.target.files[0]);\n    }\n  };\n\n  const handleSubmit = async (e: React.FormEvent) =\u003e {\n    e.preventDefault();\n    if (!jobUrl || !cvFile) {\n      alert(\"작업 URL과 이력서 파일을 모두 제공해주세요.\");\n      return;\n    }\n\n    const formData = new FormData();\n    formData.append(\"JobUrl\", jobUrl);\n    formData.append(\"CvFile\", cvFile);\n\n    setLoading(true);\n    try {\n      const response = await apiClient.post(\"/reviewcv\", formData, {\n        headers: {\n          \"Content-Type\": \"multipart/form-data\",\n        },\n      });\n\n      if (response.data.isSuccess) {\n        setReview(response.data.review);\n        setJobTitle(response.data.jobDetail.title);\n        setJobDescription(response.data.jobDetail.raw);\n        setAdSource(response.data.jobDetail.domain);\n      }\n    } catch (error) {\n      console.error(\"양식 제출 중 오류 발생:\", error);\n      alert(\"양식 제출 중 오류가 발생했습니다. 다시 시도해주세요.\");\n    } finally {\n      setLoading(false);\n    }\n  };\n\n  return (\n    \u003cdiv className=\"container mt-5\"\u003e\n      \u003ch1 className=\"text-center mb-4\"\u003e이력서 리뷰어\u003c/h1\u003e\n      \u003cform onSubmit={handleSubmit}\u003e\n        \u003cdiv className=\"mb-3\"\u003e\n          \u003clabel htmlFor=\"jobUrl\" className=\"form-label\"\u003e\n            작업 광고 URL\n          \u003c/label\u003e\n          \u003cinput\n            type=\"url\"\n            className=\"form-control\"\n            id=\"jobUrl\"\n            value={jobUrl}\n            onChange={handleUrlChange}\n            required\n          /\u003e\n        \u003c/div\u003e\n        \u003cdiv className=\"mb-3\"\u003e\n          \u003clabel htmlFor=\"cvFile\" className=\"form-label\"\u003e\n            이력서 업로드\n          \u003c/label\u003e\n          \u003cinput\n            type=\"file\"\n            className=\"form-control\"\n            id=\"cvFile\"\n            accept=\".pdf,.doc,.docx\"\n            onChange={handleFileChange}\n            required\n          /\u003e\n        \u003c/div\u003e\n        \u003cbutton type=\"submit\" className=\"btn btn-primary\" disabled={loading}\u003e\n          {loading ? \"처리 중...\" : \"제출\"}\n        \u003c/button\u003e\n      \u003c/form\u003e\n      {review \u0026\u0026 (\n        \u003cdiv className=\"row mt-4\"\u003e\n          \u003cdiv className=\"col-md-6 pt-3 border\"\u003e\n            \u003ch2\u003e작업 세부 정보\u003c/h2\u003e\n            \u003cp\u003e\n              \u003cstrong\u003e작업 제목:\u003c/strong\u003e {title}\n            \u003c/p\u003e\n            \u003cp\u003e\n              \u003cstrong\u003e광고 출처:\u003c/strong\u003e {adSource}\n            \u003c/p\u003e\n            \u003cdiv\n              dangerouslySetInnerHTML={{ __html: description || \"\" }}\n              className=\"border\"\n            /\u003e\n          \u003c/div\u003e\n          \u003cdiv className=\"col-md-6 pt-3 border\"\u003e\n            \u003cdiv dangerouslySetInnerHTML={{ __html: review || \"\" }} /\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n      )}\n    \u003c/div\u003e\n  );\n};\n\nexport default FormComponent;\n```\n\n주 애플리케이션 컴포넌트 (App.tsx): 주 애플리케이션에 폼 컴포넌트를 통합해보세요\n\n```js\nimport React from 'react';\nimport FormComponent from './components/FormComponent';\n\nconst App: React.FC = () =\u003e {\n  return (\n    \u003cdiv className=\"App\"\u003e\n      \u003cFormComponent /\u003e\n    \u003c/div\u003e\n  );\n};\n\nexport default App;\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n액시오스 서비스를 만들어보세요: 코드 구조화와 재사용성을 위해 apiClient.tsx와 같은 서비스 파일에 API 호출을 중앙 집중화하세요.\n\n```js\nimport axios from 'axios';\n\nconst apiClient = axios.create({\n  baseURL: 'http://localhost:5000/api',\n  headers: {\n    'Content-Type': 'application/json'\n  }\n});\n\nexport default apiClient;\n```\n\n# 애플리케이션 테스트 및 실행\n\n개발 서버 실행: 프로젝트 루트 디렉토리 내에서 터미널에서 아래 명령어를 실행하여 리액트 개발 서버를 시작하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nnpm run dev\n```\n\n애플리케이션 테스트: 브라우저를 열고 http://localhost:5173 또는 터미널에서 제공된 엔드포인트로 이동합니다.\n\n![이미지](/assets/img/2024-05-17-BuildingaWebApplicationPoweredbyLargeLanguageModelsLLMpart2_1.png)\n\n작업 URL을 입력하고 이력서 파일을 업로드한 후 제출 버튼을 클릭하여 테스트해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-17-BuildingaWebApplicationPoweredbyLargeLanguageModelsLLMpart2_2.png\" /\u003e\n\n애플리케이션은 백엔드 서비스에 요청을 보내 작업 세부 정보와 이력서 검토를 가져옵니다.\n\n\u003cimg src=\"/assets/img/2024-05-17-BuildingaWebApplicationPoweredbyLargeLanguageModelsLLMpart2_3.png\" /\u003e\n\n# 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 기사에서는 React, TypeScript 및 Bootstrap을 사용하여 CV Reviewer 애플리케이션의 프론트엔드를 성공적으로 구축했습니다. 이 애플리케이션은 현대 웹 기술의 통합뿐만 아니라 백엔드 서비스 및 API를 활용하여 원활한 사용자 경험을 만드는 방법을 보여줍니다. 애플리케이션은 사용자 인증, 오류 처리 개선, 여러 이력서 검토용 대시보드 추가 또는 구직 지원서용 커버 레터 생성 기능과 같은 기능을 추가하여 향상 및 확장될 수 있습니다.","ogImage":{"url":"/assets/img/2024-05-17-BuildingaWebApplicationPoweredbyLargeLanguageModelsLLMpart2_0.png"},"coverImage":"/assets/img/2024-05-17-BuildingaWebApplicationPoweredbyLargeLanguageModelsLLMpart2_0.png","tag":["Tech"],"readingTime":7},{"title":"통계적 파워와 파워 분석 개요","description":"","date":"2024-05-17 20:47","slug":"2024-05-17-APrimeronStatisticalPowerandPowerAnalysis","content":"\n\n만약 내 경험이 너의 것과 비슷하다면, 너도 일할 때 '통계적 파워'에 대해 다양한 사람들이 이야기하는 것을 들어본 적이 있을 거야. 대부분의 경우, 이들 사람들은 더 큰 표본 크기를 주장하면서 보통 더 많은 n이 항상 좋다는 모호한 개념을 기반으로 이야기하는 것 같아.\n\n하지만 이들 중 얼마나 많은 사람이 실제로 '통계적 파워'가 무엇인지 정의할 수 있는지 알고 있을까? 이 기사에서는 통계적 파워의 개념과 정의를 살펴보고 이것이 측정 수단으로 어디에 유용한지 확인해보려고 해.\n\n## 가설 검정\n\n‘통계적 파워’라는 용어는 가설 검정을 할 때만 의미가 있어. 아마도 네가 기억할 수 있듯이, 가설 검정은 데이터 샘플의 통계적 특성을 사용해 그 샘플이 추출된 전체 모집단에 대한 진술의 확신 수준을 결정하는 것을 포함해. 예를 들어보자. 사람들 분석 데이터 R 패키지의 세일즈인 사원들의 데이터 셋은 기술 회사의 샘플 세일즈인들의 데이터를 포함하고 있어, 이들의 연간 매출액(천 달러)과 최근에 증가하는 순서 척도의 평가 등급을 포함하고 있어. 처음 몇 행을 살펴보자.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```R\nlibrary(peopleanalyticsdata)\nsalespeople \u003c- salespeople[complete.cases(salespeople), ]\nhead(salespeople)\n\n##          promoted sales customer_rate performance\n## 1        0        594   3.94          2\n## 2        0        446   4.06          3\n## 3        1        674   3.83          4\n## 4        0        525   3.62          2\n## 5        1        657   4.40          3\n## 6        1        918   4.54          2\n```\n\n이제 이 문장을 살펴봅시다. 최상위 성과 영업 사원의 평균 매출액은 전체 인구의 최하위 성과 영업 사원들과 다를 수 있다는 것입니다. 이 문장을 검증하기 위해, 우리는 최상위 성과자와 최하위 성과자의 평균 매출액이 동일하다고 가정하고, 이를 귀무 가설이라고합니다. 그런 다음 귀무 가설이 전체 인구에서 사실일 때 샘플이 보이는 방식의 최대 확률을 설정하기 위해 테스트를 수행하고, 이를 테스트의 p값이라고합니다. 이 경우, 균등한 분산을 가진 두 샘플을 비교하기 위해 Welch의 t-테스트를 수행합니다.\n\n```R\n# 최상위 성과자의 매출\nsales4 \u003c- salespeople$sales[salespeople$performance == 4]\n\n# 최하위 성과자의 매출\nsales1 \u003c- salespeople$sales[salespeople$performance == 1]\n\n# 두 평균이 동일하다는 귀무 가설의 p값\nt.test(sales4, sales1)$p.value\n\n## 1.093244e-05\n```\n\n위 결과는 만일 우리의 귀무 가설이 전체 인구에서 사실이라면, 우리의 샘플이 보이는 방식은 매우 잘 나타나지 않을 가능성이 있다는 것을 의미합니다. 우리는 귀무 가설을 기각하기로 합의하는 확률 수준을 정의하고, 이를 알파로 알려집니다. 종종 알파 값은 0.05이지만, 때로는 더 낮을 수도 있습니다. 여기서 알파 값을 0.05로 설정하면, 귀무 가설을 편안하게 기각하고 대립 가설을 결론 내리게 됩니다 — 즉, 인구에서 낮은 성과자와 높은 성과자 간 평균 매출액에 차이가 있다는 것입니다. 알파 값을 0.05로 선택함으로써, 평균적으로 20번 중 1회 틀린 결론을 내리게 될 것이라는 것을 유의하십시오. 가설 검정은 확률에 관한 것이며, 확신에 관한 것이 아닙니다.```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 통계적 유의성 정의\n\n우리는 가설 검정이 우리가 존재하는 모집단의 차이를 결론 내릴만큼 충분히 확신하는 수준에 대한 것임을 알 수 있습니다. 이는 우리가 그 모집단의 샘플만을 관측할 수 있다는 것을 인정하는 것입니다. 본질적으로 미 관측 모집단에 대해 100% 확실한 것은 없으며, 따라서 네 가지 경우가 발생할 수 있습니다:\n\n- 귀무 가설이 모집단에 대해 사실이고, 그것이 샘플을 기반으로 기각되지 않음\n- 귀무 가설이 모집단에 대해 사실이고, 그것이 샘플을 기반으로 기각됨 (1종 오류)\n- 귀무 가설이 모집단에 대해 부정하고, 그것이 샘플을 기반으로 기각되지 않음 (2종 오류)\n- 귀무 가설이 모집단에 대해 부정하고, 그것이 샘플을 기반으로 기각됨\n\n통계적 유의성은 4번과 관련이 있습니다 — 이는 모집단에 대해 거짓이라는 것이 주어졌을 때 샘플을 기반으로 귀무 가설이 기각될 확률입니다. 직관적으로, 이는 샘플의 크기, 실제(미관측) 모집단의 차이(적절히 정규화된), 그리고 귀무 가설을 기각하는 확신의 수준(알파)에 따라 달라집니다. 예를 들어 실제 모집단의 차이가 더 클 경우, 더 작은 샘플에서 확인할 수 있습니다. 알파가 작을 경우, 더 큰 모집단 차이나 더 높은 'n'이 필요할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 방에 있는 코끼리는 물론 우리는 인구 차이를 결코 알 수 없을 것입니다. 우리는 우리 샘플의 차이만을 알고 있습니다. 따라서 보통 우리는 우리 샘플에서 관측된 통계적인 파워를 만족시키고 자신을 다스립니다. 여기서 우리의 영업사원 예시를 들어 보면, 이것이 t-검정이기 때문에 우리는 Cohen의 효과 크기 d를 정규화된 관측된 차이로 사용합니다. 이를 샘플 크기와 알파 0.05와 결합하여 우리의 가설 검정을 위한 통계적인 파워를 0.996로 계산할 수 있습니다. 우리는 귀무가설이 정확하게 기각될 것이라고 매우 확신할 수 있습니다.\n\n```js\nlibrary(effectsize)\nlibrary(WebPower)\n\n# sample sizes\nn4 \u003c- length(sales4)\nn1 \u003c- length(sales1)\n\n# cohen's effect size d\nd \u003c- cohens_d(sales4, sales1)$Cohens_d\n\n# statistical power\nwp.t(n4, n1, d = d, type = \"two.sample.2n\")\n\n\n## Unbalanced two-sample t-test\n##\n## n1 n2         d alpha    power\n## 55 60 0.8741483 0.05     0.996347\n```\n\n## 통계적인 파워를 사용하는 경우\n\n솔직히 말해서 그렇게 자주 사용되지는 않습니다. 당신이 샘플들과 데이터들을 가지고 이미 가설 테스트를 진행한 상황에서, 통계적인 파워는 실제로 단지 얼마나 잘 알파 바를 넘어섰는지를 나타내는 지표일 뿐입니다. 알파가 덜 엄격할수록 파워가 높아집니다. 한번 확인해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```r\nlibrary(ggplot2)\n\n# 통계적 파워\ntest \u003c- WebPower::wp.t(n4, n1, d = d, type = \"two.sample.2n\", \n                       alpha = seq(0.05, 0.0001, by = -0.0001))\n\ntest_df \u003c- data.frame(\n  Alpha = test$alpha,\n  Power = test$power\n)\n\n\n# 알파에 대한 파워 플롯\nggplot(test_df, aes(x = Alpha, y = Power)) +\n  geom_point(color = \"pink\") +\n  theme_minimal()\n```\n\n\u003cimg src=\"/assets/img/2024-05-17-APrimeronStatisticalPowerandPowerAnalysis_0.png\" /\u003e\n\n샘플 데이터를 가져오지 않았거나 가설 검정을 수행하지 않았다면, 실험이나 연구를 계획 중이고 많은 작업이 필요한 경우 통계적 파워는 도움이 될 수 있습니다. 샘플 크기가 역할을 하기 때문에 이론적으로 특정 알파 기준을 달성하기 위한 최소 샘플 크기를 계산할 수 있습니다.\n\n하지만 실제로는 관측된 효과 크기를 알아야 하는데, 물론 아직 실험을 실행하지 않았기 때문에 알 수가 없습니다. 따라서 통계적 파워 계산에서 나오는 대부분의 샘플 크기 추정은 민감도 범위의 형태를 취하는 경향이 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n실험은 조직하고 자원을 조달하기 어려울 수 있으며, 통계적 파워는 필요한 규모를 결정하는 데 도움이 될 수 있습니다. 또한 샘플 크기를 테스트할 때 중요한 부분에서 추가적인 n이 파워에 큰 영향을 미치지 않는 지점이 있는지 보여줄 수도 있습니다. 예를 들어, 중간 효과 크기와 알파 0.05를 가진 쌍체 t-테스트에서 여러 샘플 크기 범위를 시험하면, 추가적인 n이 파워에 큰 차이를 만들지 않는 시점을 볼 수 있습니다.\n\n```js\n# 여러 샘플 크기를 테스트\nsample_sizes \u003c- 20:100\npower \u003c- wp.t(n1 = sample_sizes, d = 0.5, type = \"paired\")\n\npower_df \u003c- data.frame(\n  n = power$n,\n  Power = power$power\n)\n\n# 샘플 크기에 따른 파워 플롯\nggplot(power_df, aes(x = n, y = Power)) +\n  geom_point(color = \"lightblue\") +\n  theme_minimal()\n```\n\n\u003cimg src=\"/assets/img/2024-05-17-APrimeronStatisticalPowerandPowerAnalysis_1.png\" /\u003e\n\n전반적으로, 통계적 파워는 총명치인 도구입니다. 이것은 주로 실험 디자인과 관련된 특정 상황에서만 유용한 가설 검정의 '볼트온'으로 생각할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 통계적 역량 및 검정 및 회귀 모델에서 사용되는 다양한 통계에 대해 더 자세히 탐구하고 싶다면, People Analytics의 Handbook of Regression Modeling의 11장을 확인해보세요.\n\n![이미지](/assets/img/2024-05-17-APrimeronStatisticalPowerandPowerAnalysis_2.png)","ogImage":{"url":"/assets/img/2024-05-17-APrimeronStatisticalPowerandPowerAnalysis_0.png"},"coverImage":"/assets/img/2024-05-17-APrimeronStatisticalPowerandPowerAnalysis_0.png","tag":["Tech"],"readingTime":6},{"title":"새로운 langchain_huggingface 라이브러리 만들면서 배우기","description":"","date":"2024-05-17 20:46","slug":"2024-05-17-ExploringtheNewlangchain_huggingfacelibraryAHands-OnExperiment","content":"\n\n\u003cimg src=\"/assets/img/2024-05-17-ExploringtheNewlangchain_huggingfacelibraryAHands-OnExperiment_0.png\" /\u003e\n\n# 배경\n\n최근에 Langchain과 HuggingFace가 함께 새로운 파트너 패키지를 발표했습니다. Langchain은 이미 커뮤니티에서 유지보수되는 HuggingFace 패키지를 보유하고 있었지만, 이 새로운 버전은 HuggingFace가 Langchain의 파트너로 공식 지원하는 것입니다! Langchain은 다양한 LLM과 상호 작용하기 위한 공통 인터페이스를 제공하며, HuggingFace는 오픈 소스 모델을 포함한 호스팅된 LLM에 대한 추론 엔드포인트를 제공합니다.\n\n이 블로그에서는 HuggingFace의 오픈 소스 모델의 추론을 이 새로운 Langchain 라이브러리로 사용하는 내 경험을 공유하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# TL;DR\n\n직접 시도해 보고 싶다면, 아래 저장소를 클론해보세요:\n\n# 실험\n\n## HuggingFace를 통한 추론 옵션\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nHuggingFace에서 추론을 수행하는 세 가지 방법이 제공됩니다:\n\n- UI를 통해 직접: 각 모델에 대한 채팅 위젯이 제공됩니다. Meta의 LLAMA 모델과 같은 목록에서 모델을 선택할 수 있습니다.\n- (무료) 추론 API (서버리스): 이 옵션은 최소한의 테스트에 적합합니다. HuggingFace의 공유 인프라를 사용하므로 요율 제한이 적용됩니다. API 키로 계정 설정에서 액세스 토큰을 사용합니다. 이 옵션을 사용하여 Langchain 라이브러리를 시도해 볼 것입니다.\n- (유료) 추론 엔드포인트 (전용 API): 제품 사용에 적합하지만, 이번 실험에서는 배포하고 이 옵션을 사용하지 않을 것입니다.\n\n## Langchain_HuggingFace 라이브러리\n\n이 라이브러리는 HuggingFace LLMs와 상호 작용하기 위해 두 가지 클래스를 노출합니다: HuggingFacePipeline 및 HuggingFaceEndpoint.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 원격 추론을 가능하게 하는 HuggingFaceEndpoint를 사용하는 것에 관심이 있습니다. 이 클래스의 내부에서는 InferenceClient를 사용합니다. 특정 모델의 경우, 해당 모델의 HuggingFace 페이지(예: Meta의 LLAMA)에서 해당 모델의 약관에 동의해야 사용할 수 있습니다. HuggingFacePipeline은 모델을 로컬로 다운로드해야 하기 때문에 특정 이유가 없는 이상 이상적이지 않습니다.\n\nHuggingFaceEndpoint 클래스를 인스턴스화한 후, 몇 가지 langchain.schema 메시지를 정의합니다. 이 라이브러리에서 또 한 가지 중요한 클래스는 ChatHuggingFace 클래스인데, 이는 특정 모델에 따라 특별 토큰으로 프롬프트를 향상시킵니다. 또한 사용된 토큰과 같은 모델 메타데이터를 응답에 추가하여 Langchain이 약속한 응답의 일관성을 보장합니다.\n\n이 실험을 위해 작성한 코드를 확인해보세요!\n\n## 전반적인 인상\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n라이브러리는 작업 중인 것 같아서 전반적인 경험은 원활하지 않았어요. 여기 몇 가지 구체적인 문제가 있었어요:\n\n- 오래된 독스트링: IDE의 클래스 독스트링이 최신으로 업데이트되지 않았어요.\n\n![2024-05-17-ExploringtheNewlangchain_huggingfacelibraryAHands-OnExperiment_1.png](/assets/img/2024-05-17-ExploringtheNewlangchain_huggingfacelibraryAHands-OnExperiment_1.png)\n\n2. 불완전한 문서화: Langchain의 문서가 최신으로 업데이트되지 않아서 아마도 Langchain v0.2에서 업데이트 예정일 것 같아요. 그들의 공지를 따라서 사용하면 분명히 작동하지 않을 거에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3. 비기능적 매개변수: 몇 가지 매개변수는 모델 응답에 영향을 미치지 않거나 오류를 발생시킵니다.\n\n```js\nllm = HuggingFaceEndpoint(\n    repo_id=LLAMA_INSTRUCT,  # endpoint_url을 사용하는 경우 model_id도 제공해야 함. ChatHuggingFace에서 model_id는 repo_id만큼 영향을 미침\n    task=\"text-generation\",\n    streaming=True,\n    max_new_tokens=1024,  # 출력 길이에 영향을 주는 것 같지 않음\n    model=\"\",  # 이 필드는 필수이지만 출력에는 영향을 미치지 않음, repo_id만 영향 있음\n    client=None,\n    async_client=None,\n    return_full_text=True,\n    repetition_penalty=1.1,\n    cache=False,\n    do_sample=False,\n)\n```\n\n# 결론 및 가능한 향후 작업\n\n그들의 발표는 다음과 같이 마무리되었습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 실험이 가치 있는 피드백으로 작용하기를 희망하며, Langchain 저장소에 이슈를 만들 계획입니다. 이 실험을 통해 HuggingFace의 무료 OSS LLM 추론 및 그 Langchain 통합 라이브러리 상태에 대해 더 나은 이해를 얻을 수 있었습니다.\n\n향후 실험에서는 이 예시를 따라 에이전트를 만들고자 합니다. 제 다음 블로그 포스트를 기대해 주세요!","ogImage":{"url":"/assets/img/2024-05-17-ExploringtheNewlangchain_huggingfacelibraryAHands-OnExperiment_0.png"},"coverImage":"/assets/img/2024-05-17-ExploringtheNewlangchain_huggingfacelibraryAHands-OnExperiment_0.png","tag":["Tech"],"readingTime":3},{"title":"CodeLlama vs CodeGemma, AI 코딩 어시스턴스에 오픈 모델 활용하기","description":"","date":"2024-05-17 20:44","slug":"2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance","content":"\n\n\u003cimg src=\"/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_0.png\" /\u003e\n\nAI 코딩 도구 시장은 수십억 달러의 산업입니다. 2030년까지 172억 달러에 이를 것으로 예상되며, 현재에도 VS Code 또는 JetBrains IDE용 AI 플러그인은 수백만 번 다운로드되었습니다. 하지만 무료 코딩 도우미로 로컬 모델을 실행할 수 있을까요? 그리고 그 성능은 어떨까요? 이 기사에서는 두 개의 오픈 모델, Code Gemma와 Code Llama를 테스트해 보겠습니다. 제 PC에 설치하고, 그들이 어떻게 작동하는지 확인할 것입니다.\n\n더 이상의 말이 필요 없으니, 시작해 봅시다!\n\n## 1. 모델들\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n본문 작성 시점에서 코딩 목적으로 두 가지 주요 오픈 모델이 무료로 다운로드할 수 있으며 사용할 수 있습니다:\n\n- CodeLlama. 이 모델은 2023년 Meta에서 출시되었으며, 7B, 13B, 34B, 70B 크기로 제공됩니다. \"Base\", \"Instruct\", \"Python\" 모델을 사용할 수 있습니다. 4가지 크기이지만, 로컬에서 실제로 사용할 수 있는 것은 7B 및 13B 모델뿐입니다; 다른 크기는 너무 \"무겁습니다.\"\n- CodeGemma. 이 모델은 2024년 Google에서 출시되었으며, 2B 및 7B 크기로 제공됩니다. 2B 모델은 코드 완성을 위해 훈련되었으며, 7B 모델은 코드 채움 및 자연어 프롬프트를 위해 훈련되었습니다.\n\n본문에서는 HuggingFace에서 제공되며 GGUF 형식으로 다운로드할 수 있는 7B 및 13B 모델을 테스트할 것이며, 이를 사용하여 다양한 앱에서 이 모델들을 사용할 수 있도록 OpenAI 호환 로컬 서버를 실행할 것입니다. 그러나 이를 수행하기 전에 단순히 모델을 Python으로 실행하여 무엇을 할 수 있는지 살펴보겠습니다. 실제 사용으로 넘어가고 싶은 독자분들은 이 부분을 건너뛸 수 있습니다.\n\n두 모델을 테스트하기 위해 Google Colab 인스턴스를 무료로 사용할 것입니다. 먼저, 모델과 토크나이저를 로드해보겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\nimport transformers\nimport torch\n\n\nmodel_id = \"...\"\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=False,\n)\n\ntokenizer = AutoTokenizer.from_pretrained(model_id)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_id,\n    quantization_config=bnb_config,\n    device_map=\"cuda\",\n    torch_dtype=torch.bfloat16,\n)\n```\n\nHuggingFace의 Transformers 라이브러리는 모델 파일을 자동으로 다운로드해줍니다. 7B 모델은 약 16.2 GB의 GPU RAM을 필요로 하지만, bits and bytes 라이브러리를 활용하여 4비트 해상도로 모델을 실행하면 필요한 메모리 용량은 약 5GB 정도로 줄어듭니다.\n\n이제 모델을 테스트하기 위한 코드 조각을 만들어 봅시다. 예를 들어, 문자열 목록을 파일에 작성하는 Python 메서드를 작성해보겠습니다:\n\n```python\npython_code = \"\"\"\nclass Writer:\n   def write_file(self, filename: str, data: List[str]):\n        \\\"\\\"\\\" Write list of strings to a text file \\\"\\\"\\\"\n        with open(filename, 'w') as f_out:\n            for line in data:\n                f_out.write(f\"{line}\\n\")\n\"\"\"\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델의 코딩 능력을 테스트하기 위해, 두 모델에게 \"pytest\"를 만들도록 요청해보겠습니다:\n\n```js\nchat = [{\n    \"role\": \"user\",\n    \"content\": f\"이 파이썬 메소드에 대한 pytest를 작성해주세요:\\n{python_code}. \"\\\n               f\"테스트가 끝나면 생성된 파일을 삭제하세요.\"\n    }]\n\n\nprompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\ninputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")\noutputs = model.generate(input_ids=inputs.to(model.device), max_new_tokens=1024)\nresult = tokenizer.decode(outputs[0])\n```\n\n결과적으로, CodeLlama 7B가 이 코드를 생성했고, 이 과정은 19초가 걸렸습니다:\n\n```js\nimport pytest\n\n\nclass TestWriter:\n    def test_write_file(self):\n        writer = Writer()\n        filename = 'test.txt'\n        data = ['line1', 'line2', 'line3']\n        writer.write_file(filename, data)\n        with open(filename, 'r') as f:\n            lines = f.readlines()\n            assert lines == data\n        os.remove(filename)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nCodeGemma이 이 코드를 생성했고, 프로세스에는 16초가 걸렸어요:\n\n```js\nimport pytest\n\n\ndef test_write_file():\n    \"\"\" write_file 메소드를 테스트함 \"\"\"\n    filename = \"test.txt\"\n    data = [\"This is a test\", \"line 2\", \"line 3\"]\n    Writer().write_file(filename, data)\n\n    with open(filename, \"r\") as f:\n        assert f.read() == \"This is a test\\nline 2\\nline 3\\n\"\n\n    import os\n    os.remove(filename)\n```\n\n개인적으로, 저는 두 번째 버전을 선호해요. 첫째, CodeGemma가 메소드의 설명을 나타내는 docstring을 제공했고, 이는 현대적인 \"linter\" 도구의 요구 사항이에요. 둘째, Writer().write_file(...) 코드는 writer 변수를 선언하고 나중에 사용하는 것보다 더 간결하고 가독성이 좋아 보여요. 셋째, CodeGemma는 \"os\" 파이썬 모듈을 가져왔는데, CodeLlama는 이를 \"잊어버렸어요\".\n\n첫눈에는 두 코드 조각이 모두 올바르게 보여요. pytest -v file.py 명령을 실행하여 코드를 실행해 보겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\u003cimg src=\"/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_1.png\" /\u003e\n\n실제로 두 테스트의 정확성에 대해 잘못 이야기 했었고, 첫 번째 테스트에 버그가 있습니다. 재미있게도, 두 번째 테스트는 뿐만 아니라 더 나은 모습을 하고 있으며, 작동하기도 합니다. 그 반면 첫 번째는 작동하지 않습니다. 스크린샷에서 오류는 명백합니다. 독자들은 자신의 힘으로 어떻게 수정할지 찾아보세요.\n\n처음에는 CodeGemma 2B \"코드 완성\" 모델을 테스트할 계획이 없었지만, 독자들을 위한 추가 혜택으로 해보자구요! 모델을 로드하는 방법은 동일합니다. 오직 모델 ID만 바꾸면 됩니다:\n\n```js\nmodel_id = \"google/codegemma-2b\"\nmodel = AutoModelForCausalLM.from_pretrained(model_id, ...)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 코드 완성을 위해 훈련된 모델입니다. 영어 설명이 없어도 되며, 소스 코드만 제공하면 됩니다:\n\n```js\n# Prompt\npython_code = \"\"\"\nclass Writer:\n   def write_file(self, filename: str, data: List[str]):\n      ...\n\nimport pytest\n\ndef test_write_file():\n    \\\"\\\"\\\"\\ Test the write_file method \\\"\\\"\\\"\n\"\"\"\n\nprompt = f\"\"\"\n\u003c|fim_prefix|\u003e{python_code}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리가 볼 수 있듯이 해당 코드는 \"그대로 사용\"되지 않을 것입니다. 하지만 논리는 올바른 것으로 보입니다. 필요한 수정은 assert 라인을 올바르게 포맷하는 것입니다:\n\n```js\nassert lines == [\"Hello\\n\", \"World\\n\"]\n```\n\n이후에 \"pytest\"가 통과되었습니다. 모델은 테스트 이후 파일을 제거하지 않았지만, 나는 프롬프트에서 그것을 요청하지 않았습니다. 마지막으로, 소형 모델의 실행 시간은 단지 3.3초로, 더 큰 모델과 비교했을 때 약 5배 빠릅니다.\n\n## 2. 람마 서버 실행\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 파이썬에서 모델을 테스트했고, 이제 로컬 OpenAI 호환 서버를 실행해볼 차례입니다. 이를 위해 Llama-cpp-python을 사용할 거예요. 이 프로젝트는 멋지고 가벼워요. 한 줄의 명령어로 우리가 원하는 어떤 모델이든 실행할 수 있어요:\n\n```js\n# 코드 Gemma\npython3 -m llama_cpp.server --model codegemma-7b-it-Q4_K_M.gguf --n_ctx 8192 --n_gpu_layers -1 --host 0.0.0.0 --port 8000\n\n# 코드 Llama 7B\npython3 -m llama_cpp.server --model codellama-7b-instruct.Q4_K_M.gguf --n_ctx 8192 --n_gpu_layers -1 --host 0.0.0.0 --port 8000\n\n# 코드 Llama 13B\npython3 -m llama_cpp.server --model codellama-13b-instruct.Q4_K_M.gguf --n_ctx 8192 --n_gpu_layers -1 --host 0.0.0.0 --port 8000\n```\n\n모델을 로드할 GPU RAM이 충분하지 않으면, n_gpu_layers 매개변수를 변경하여 GPU에 일부 레이어만 로드할 수 있어요. 또한 Apple Silicon이나 심지어 CPU에서 모델을 실행할 수도 있지만 물론 느릴 거예요.\n\n## 3. 앱들\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금은 로컬 OpenAI 호환 서버가 있으며 몇 가지 앱을 테스트할 준비가 되어 있습니다!\n\n### 3.1 AI Shell\n\nAI Shell은 자연어 프롬프트를 콘솔 명령어로 변환할 수 있는 오픈 소스 앱입니다. 이 앱은 꽤 인기가 있으며 작성 당시 프로젝트는 GitHub에서 3.6K개의 스타를 받았습니다. AI Shell은 TypeScript로 작성되었으며 npm 패키지 관리자를 통해 이 앱을 설치할 수 있습니다 (저는 여기서 Node JS 20.13.0도 설치했습니다):\n\n```js\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.7/install.sh | bash\nnvm install v20.13.0\nnpm install -g @builder.io/ai-shell\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n앱을 실행하기 전에 API 엔드포인트를 구성해야 합니다:\n\n```js\nai config set OPENAI_KEY=12345678\nai config set OPENAI_API_ENDPOINT=http://127.0.0.1:8000/v1\n```\n\n이제 콘솔에서 \"ai chat\" 명령을 입력하여 언제든지 모델과 대화를 시작할 수 있습니다:\n\n![대화 모델](https://miro.medium.com/v2/resize:fit:1400/1*9zJpuyFx_-HW4AZ4b9ZH8A.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프로그램을 사용하는 또 다른 방법은 실행하려는 명령어를 입력하는 것입니다. 예를 들어, \"현재 폴더에 있는 파일 표시\"와 같은 내용을 입력할 수 있어요:\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*4PElpWscaef11mHRzCdZ5Q.gif)\n\n안타깝게도 무료 7B 모델로는 작동하지 않았고, 모델이 올바른 쉘 명령어를 생성하지 못했어요. 또한 프롬프트 안에 있는 \"스크립트\"라는 단어가 모델을 혼란스럽게 만들었고, 영화 대본과 관련된 텍스트를 생성했어요.\n\n이 문제는 아마도 프롬프트를 조정하여 해결할 수 있겠죠. 그러나 이 텍스트를 작성할 때에는 프롬프트가 TypeScript 소스에 하드코딩되어 있어 쉽게 구성할 수 없었어요. 아직까지 GitHub에서 제 기능 제안에 응답한 사람이 없지만, 향후 개선될 것을 희망해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3.2 ShellGPT\n\nShellGPT는 이 텍스트를 작성하는 시점에서 GitHub에서 8.3K개의 스타를 가진 또 다른 흥미로운 오픈소스 프로젝트입니다. 우리는 다음과 같이 pip를 사용하여 쉽게 응용 프로그램을 설치할 수 있습니다:\n\n```js\npip3 install shell-gpt\n```\n\n로컬 모델과 함께 ShellGPT를 사용하려면 ~/.config/shell_gpt/.sgptrc 파일에서 API 엔드포인트를 변경해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nAPI_BASE_URL=http://127.0.0.1:8000/v1\nOPENAI_API_KEY=12345678\n```\n\n그럼 이제 우리는 이전 앱과 거의 같은 방식으로 터미널 쉘에 직접 요청을 입력할 수 있어요:\n\n```js\nsgpt \"로컬 파일을 표시하는 명령어를 작성해주세요\"\n```\n\n안타깝게도, CodeGemma 모델은 ShellGPT에서 작동하지 않았고, LlamaCpp 서버는 Server 500 오류를 반환했어요: '시스템 역할이 지원되지 않음'. 처음에는 LlamaCpp 문제인 줄 알았지만 로그를 확인한 후에는 모델 메타데이터에 이런 라인이 있는 것을 보았어요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n{ if messages[0]['role'] == 'system' }\n  { raise_exception('시스템 역할은 지원되지 않습니다')\n```\n\n코드젬마가 \"시스템\" 역할을 지원하지 않는 것은 안타깝습니다. 왜냐하면 OpenAI API에서 널리 사용되기 때문입니다. 따라서 OpenAI 호환 앱은 코드젬마를 사용할 수 없습니다. 이전에 보았던 것처럼, 코드젬마가 생성한 코드는 꽤 좋았기 때문에 아쉽습니다.\n\n코드람마에 대한 셸GPT는 잘 작동합니다:\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*N6gwsFM7ZNt7OW2sZcaNZg.gif)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n터미널 셸에서 '—shell' 접두어를 지정하여 명령을 직접 실행하는 기능이 편리합니다.\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*xTTNTI0Ykh8NGuqkIpwLVg.gif)\n\n더 개선할 공간이 있습니다. 예를 들어, \"문서 폴더의 크기 표시하기\" 프롬프트에 대한 ```du -sh ~/Documents``` 응답이 반환됩니다. 이것은 올바른 bash 명령어입니다. 그러나 ShellGPT는 ``` 문자열에서 해당 명령을 가져오지 못했고 \"명령을 찾을 수 없음\" 오류만 받았습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nbash 명령어를 사용하는 것도 유용하지만, 실제 코딩 지원은 어떨까요? 오픈소스 CodeGPT 플러그인을 통해 이를 할 수 있어요. 먼저, PyCharm IDE에 플러그인을 설치하고 LlamaCpp와 함께 사용할 수 있도록 설정했어요:\n\n![CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance](/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_2.png)\n\n예를 들어, 다음과 같은 Python 클래스를 고려해봅시다:\n\n```js\nclass ServerConnection:\n    \"\"\" Server connection handling \"\"\"\n\n    def __init__(self):\n        self.is_connected = False\n        self.connection_time = -1\n        self.uploads_total = 0\n        self.reconnects_total = 0\n        self.reconnect_threshold_sec = 64\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 모델에게 변수를 따로 Python 데이터 클래스로 리팩터링하도록 요청할 것입니다.\n\n결과적으로 CodeGemma는 이를 수행하지 못했으며 \"시스템 역할을 지원하지 않음\"이라는 오류가 발생했습니다. CodeLlama 7B는 작업을 완료할 수 없었고 대신에 데이터 클래스 대신 표준 클래스를 생성했습니다. 반면에 CodeLlama 13B는 잘 수행했습니다:\n\n![이미지](/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_3.png)\n\n다음 단계로, 더 복잡한 내용을 요청하고 텍스트 필드와 버튼 프롬프트가 있는 UI Python 애플리케이션을 만들어보았습니다. Llama 13B 모델이 이 코드를 생성했습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nimport tkinter as tk\n\n# 메인 창 생성\nroot = tk.Tk()\nroot.title(\"Hello World\")\nroot.geometry(\"320x200\")\n\n# 텍스트 필드 생성\ntext_field = tk.Entry(root)\ntext_field.pack()\n\n# 버튼 생성\nbutton = tk.Button(root, text=\"Click Me!\", command=lambda: print(\"You clicked the button!\"))\nbutton.pack()\n\n# 메인 루프 시작\nroot.mainloop()\n``` \n\n코드는 올바르지만, 애플리케이션 창이 보이지 않았습니다. 크기가 지정되지 않았습니다. 나는 모델에게 제목을 \"Hello World\"로 변경하고 창 크기를 320x200으로 설정하도록 요청했습니다: \n\n\u003cimg src=\"/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_4.png\" /\u003e\n\n결과가 적절하게 나와 요청한 애플리케이션이 예상대로 작동했습니다.```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_5](/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_5.png)\n\n저는 13B 모델이 완벽하지 않다는 것을 인정해야합니다. 이론적으로는 큰 컨텍스트 창과 이전 채팅 결과를 사용해야 하지만, 제가 모델에게 생성된 코드를 클래스로 이동하도록 요청했을 때 창 크기나 제목을 설정하지 않은 새로운 코드를 생성했습니다:\n\n```js\nimport tkinter as tk\n\nclass HelloWorld(tk.Frame):\n    def __init__(self, master=None):\n        super().__init__(master)\n        self.pack()\n\n        # 텍스트 필드 생성\n        self.text_field = tk.Entry(self)\n        self.text_field.pack()\n\n        # 버튼 생성\n        self.button = tk.Button(self, text=\"Click Me!\", command=lambda: print(\"Button clicked!\"))\n        self.button.pack()\n\n\nif __name__ == \"__main__\":\n    root = tk.Tk()\n    app = HelloWorld(root)\n    root.mainloop()\n```\n\n하지만 일반적으로 말하자면, 모델이 정확한 클래스를 생성했으며 조금의 복사 붙여넣기로 작업을 완료하는 것이 쉬웠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 4. 단점\n\n지금까지 모든 예시를 통해 모델이 작동하는 것을 확인할 수 있습니다; 코드와 bash 명령을 모두 생성할 수 있습니다. 그러나 몇 가지 단점과 문제점도 있습니다:\n\n- 로컬 LLM 인스턴스를 사용하려면 좋은 그래픽 카드가 필요합니다. 저는 2.5년 전에 구매한 8GB GPU RAM을 갖춘 GeForce RTX 3060 카드를 사용하고 있습니다. Colab 테스트에서는 8 GB가 7B 모델을 실행하는 데 충분하다는 것을 확인했지만, 실제 데스크탑에서는 그 용량이 부족했습니다. OS 자체도 일부 GPU를 필요로 하기 때문입니다. 실제로 13B 모델을 실행하려면 적어도 16 GB의 GPU RAM이 필요하며, 미래 개선을 위한 여유 공간으로 24 GB가 필요합니다. 현실적으로 고려할만 한가요? 현재 GPU 가격을 고려할 때, 1000-1500달러에는 AI 구독을 여러 년간 할 수 있습니다.\n- 오픈 소스 앱은 완벽하지 않습니다. 제 테스트에서 LlamaCpp 서버는 때로 \"segmentation fault\"와 함께 충돌하고, CodeGPT 앱은 때로는 모델에 요청을 전송하지 않았고, PyCharm을 재시작해야 했고 등등 발생했습니다. 이것은 오픈 소스이며 어떤 종류의 보장도 없으므로 불평할 것이 아니지만, 이러한 AI 도구들에 대해서는 아직 \"초기 채택\" 단계에 있다는 것을 인정해야 합니다.\n- 또한 대형 로컬 언어 모델 실행은 에너지를 많이 소비하는 작업입니다. 마지막 테스트로 내 데스크톱 PC에 전력계를 연결했습니다. 평상시에는 약 80 와트를 소비하는 것으로 나타났습니다. 하지만 LLM 요청이 실행될 때는 에너지 소비량이 거의 3배 증가합니다: \n\n![이미지](/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_6.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 결론\n\n본 기사에서는 오픈 언어 모델이 코딩 어시스턴트로서 작동하는 능력을 테스트하였고, 결과는 흥미로웠습니다:\n\n- 작은 7B 및 13B 모델조차도 리팩토링, 단위 테스트 생성 또는 작은 코드 템플릿 작성과 같은 일부 코딩 작업을 수행할 수 있습니다. 물론, 이러한 모델들은 175B ChatGPT 3.5와 같이 큰 모델에 비해 능력이 떨어지지만, 로컬 모델을 사용하는 것은 구독 비용이 필요하지 않을 뿐만 아니라, 개인 정보 관점에서 빠르고 효율적일 수도 있습니다.\n- 반면에 로컬 모델을 실행하려면 고사양의 하드웨어가 필요하며, 이는 비용 부담뿐만 아니라 에너지 소모도 초래할 수 있습니다. 본 기사 작성 시, 고사양 GPU는 최대 $1500에 이를 수 있으며, 이는 로컬 LLMs만 실행하기에는 현실적이지 않습니다 — 해당 비용으로 클라우드 서비스 구독을 매우 오랜 기간 동안 이용할 수 있습니다.\n- AI 도구를 사용하는 도전 과제는 하드웨어뿐만 아니라 소프트웨어에도 있습니다. 최소한 본 게시물 작성 시점에는 AI 소프트웨어의 오픈 소스 생태계가 아직 미성숙한 것으로 나타났습니다. HuggingFace에서 39,769개의 오픈 7B 모델을 발견했으나 GitHub에서의 오픈 소스 AI 앱 수는 미미합니다. 이 기사에서 설명한 3가지가 거의 제가 찾아낸 전부였습니다 (만약 놓친 것이 있다면, 아래 댓글에 쓰거나, 추가 리뷰를 진행할지도 모릅니다).\n\n일반적으로 일상적인 코딩 작업에 로컬 LLM을 사용하는 것은 가능하지만, 소프트웨어와 하드웨어 모두에서 여전히 많은 도전 과제가 있음을 알 수 있습니다. 더 나은 AI 칩 및 효율적인 모델을 위해 노력하고 있는 다른 기업들이 있음도 알고 있습니다. Microsoft의 Phi-3와 같은 새로운 모델은 이제 모바일 하드웨어에서도 작동할 수 있습니다. 그것이 AI 산업을 어떻게 바꿀지 어떻게 알 수 있을까요? 다음 세대의 통합 그래픽 카드는 저렴하고 조용하며 CUDA 호환될 것인가요? 아직 모릅니다. 분명히 새로운 AI 관련 하드웨어가 발표될 것이며 (M4가 이미 첫 번째였습니다), 적어도 오픈 사용을 위한 드라이버 없이 독점적인 새 하드웨어가 되지 않기를 희망합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n읽어 주셔서 감사합니다. 이야기가 마음에 드셨다면 Medium에 구독해보세요. 그러면 새 기사가 발행될 때 알림을 받을 수 있을 뿐만 아니라 수천 편의 다른 작가들의 이야기에도 완전한 접속 권한을 얻을 수 있습니다. 또한 LinkedIn을 통해 연락하실 수도 있습니다. 거기에서는 전체 기사로 충분치 않은 작은 포스트를 주기적으로 발행하고 있습니다. 이번 포스트와 다른 포스트의 전체 소스 코드를 원하신다면 Patreon 페이지를 방문해보세요.\n\n자연어 처리와 언어 모델을 사용하는 것에 관심이 있는 분들은 다른 논문들도 읽어보세요:\n\n- GPT 모델: 어떻게 작동합니까?\n- 16, 8 및 4비트 부동 소수점 형식 - 어떻게 작동합니까?\n- 대규모 언어 모델로 판다 데이터프레임 처리하기\n- 주말 AI 프로젝트 (제1부): 라즈베리 파이에서 음성 인식 및 LLaMA-2 GPT 실행\n- 주말 AI 프로젝트 (제2부): 음성 인식, PTT 및 라지 액션 모델을 라즈베리 파이에서 사용하기\n- 주말 AI 프로젝트 (제3부): 시각 장애인을 위한 시각 보조 도구 만들기","ogImage":{"url":"/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_0.png"},"coverImage":"/assets/img/2024-05-17-CodeLlamavsCodeGemmaUsingOpenModelsforAICodingAssistance_0.png","tag":["Tech"],"readingTime":14},{"title":"대기 시간을 통해의 신비로운 여행","description":"","date":"2024-05-17 20:39","slug":"2024-05-17-AWhimsicalJourneyThroughWaitTimes","content":"\n\n## 파이썬을 사용하여 전자레인지 카운트다운부터 끝나지 않는 전화 대기 시간까지\n\n![image](/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_0.png)\n\n전자레인지 오븐의 카운트다운이 빠르게 0으로 수렴하는 것을 본 적이 있나요? 반면 전화 대기시간은 영원처럼 늘어날까요?\n\n한가지 생각해 보세요. 포플콘을 전자레인지에 넣어 가열한 지 겨우 1분 지난 때에는 그릇을 준비하고 서빙할 준비를 합니다. 하지만 전화 대기 중에 1분이 지난다면? 다시 사람과 대화를 나눌 수 있을지 의문이 들 정도입니다. 10분 후, 포플콘을 즐기는 중이겠죠. 하지만 전화는? 대기 음악이 끝도 없는 연옥의 배경음악이 되고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그리고 팝콘을 기다리는 사이와 전화 대기를 이어가는 서사 속을 맴도는 … 주간 복권. 승리를 기다립니다. 매주 새로운 티켓은 이전 주의 실망과는 거리가 먼 신선한 약속을 간직하고 있습니다.\n\n요약하자면, 세 가지 다른 종류의 대기가 나타납니다:\n\n- “대기 전화”형 — 기다린 시간이 오래 될수록 더 오랫동안 기다릴 것으로 기대합니다.\n- “팝콘”형 — 기다린 시간이 길어질수록 더 짧게 기다릴 것으로 기대합니다.\n- “복권 당첨”형 — 지금까지 기다린 것과 관계없이 예상 대기 시간은 변하지 않습니다.\n\n이 대기 시간의 차이는 실제로 존재하는 것일까요, 아니면 마음의 장난일까요? 이 질문에 대한 대답은 두 부분으로 나누어 알아보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 부분 1 — 데이터 분석\n- 부분 2 — 데이터 모델링\n\n각 부분에서 대기 시간 유형을 각각 살펴보겠습니다. 자세한 Python 코드와 설명이 번갈아 나옵니다. Python에 관심이 있다면 코드 부분을 읽어보세요. 대기 시간에 대해 배우고 싶다면 코드를 건너뛰어도 됩니다.\n\n# \"대기 중\" 유형 대기 시간 — 기다린 시간이 길수록 더 오래 기다리게 됩니다.\n\n데이터로 시작하고 싶지만 \"대기 중\" 시간에 대한 데이터가 없습니다. 대신 컴퓨터 파일의 편집 사이의 시간에 대해서 어떠세요? 그런 편집 시간을 보는 곳 한 곳이 바로 위키피디아입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위키피디아 페이지에서 마지막 편집 이후의 시간을 보고 다음 편집까지 얼마나 남았는지 예측할 수 있을까요?\n\n위키피디아 페이지 편집에 대한 다음 편집까지의 시간을 어떻게 예측할 수 있을까요? 다음 편집이 언제 발생할지 정확히 예측해 보세요: \"저는 이 페이지가 정확히 5일 3시간 20분 후에 편집될 것으로 예측합니다.\" 하지만 그렇게 구체적으로 예측하는 것은 너무 정확성이 떨어질 것입니다.\n\n시간 범위를 예측할 수도 있습니다: \"저는 이 페이지가 다음 100년 이내에 언제든지 편집될 것으로 예측합니다.\" 이렇게 하면 거의 항상 맞을 수 있겠지만, 너무 모호하고 흥미롭지 않습니다.\n\n더 실용적인 예측은 \"중위 다음 편집 시간\"의 형태입니다. 이렇게 말할 수 있습니다: \"저는 이 페이지가 다음 5일 3시간 20분 이내에 50% 확률로 편집될 것으로 예측합니다.\" 저, 당신의 적,는 \"이전\" 또는 \"이후\"를 선택할 것입니다. 만약 실제 중위 다음 편집 시간이 3일이라고 가정하면, \"이전\"을 선택할 것입니다. 그럼 우리는 최대 5일 3시간 20분까지 기다립니다. 그 동안 누군가(다시 말해서, 우리 둘을 제외한 누군가) 페이지를 편집하면 상대방이 점수를 획들하고, 그렇지 않으면 당신이 점수를 획득합니다. 이러한 점수 체계를 통해, 만약 제가 당신보다 더 좋은 예측자라면 더 많은 점수를 획득해야 할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이썬에 대해 알아보고 이러한 예측을 어떻게 할 수 있는지 살펴봅시다:\n\n## “대기 중” 유형의 대기 시간 — Python\n\n아티스트 Marie Cochran에 관한 위키피디아 문서를 살펴보겠습니다. 문서의 개정 내역을 살펴볼 수 있습니다:\n\n![image](/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다양한 위키피디아 문서에서 데이터를 수집하기 위해 작은 파이썬 스크립트를 작성했어요. 다음과 같은 작업을 합니다:\n\n- https://en.wikipedia.org/wiki/Special:Random을 통해 랜덤한 영어 위키백과 페이지를 선택합니다.\n- 해당 페이지의 편집 이력으로 이동합니다. 예를 들어, https://en.wikipedia.org/w/index.php?title=Marie_Cochran\u0026action=history.\n- (최대) 최근 50회 편집의 날짜와 시간을 추출합니다. 시간은 분 단위로 표시됩니다.\n- 문서 제목, 수정 시간, 스크립트 실행 시간으로 구성된 줄을 생성합니다. 모든 시간은 UTC 시간대를 사용합니다. 탭으로 열을 구분합니다.\n- 줄을 파일에 추가합니다.\n\n편집 시간 데이터 일부를 보여드리겠습니다:\n\n```js\nMarie_Cochran 01:20, 8 January 2024 01:16, 08 February 2024\nMarie_Cochran 01:10, 27 September 2023 01:16, 08 February 2024\nMarie_Cochran 00:59, 12 September 2023 01:16, 08 February 2024\nMarie_Cochran 11:43, 2 November 2022 01:16, 08 February 2024\n...\nMarie_Cochran 19:20, 10 March 2018 01:16, 08 February 2024\nPeter_Tennant 15:03, 29 July 2023 01:16, 08 February 2024\nPeter_Tennant 21:39, 15 April 2022 01:16, 08 February 2024\n...\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nimport pandas as pd\n\n# 데이터 읽기\nwiki_df = pd.read_csv(\"edit_history.txt\", sep='\\t', header=None, names=[\"Title\", \"Edit DateTime\", \"Probe DateTime\"], usecols=[\"Title\", \"Edit DateTime\"])\nwiki_df['Edit DateTime'] = pd.to_datetime(wiki_df['Edit DateTime']) # 텍스트를 날짜 및 시간으로 변환\n\n# 'Title' 및 'Edit DateTime'을 기준으로 DataFrame 정렬하여 시간 간격이 올바르게 계산되도록 함\nwiki_df.sort_values(by=['Title', 'Edit DateTime'], inplace=True)\n\n# 동일한 제목 내에서 연속해서 편집한 경우의 시간 간격 계산\nwiki_df['Time Delta'] = wiki_df.groupby('Title')['Edit DateTime'].diff()\nwiki_df.head()\n```\n\n결과로 나온 Pandas 데이터프레임은 샘플된 기사 중 알파벳상으로 가장 빠른 기사(제목 기준)로 시작합니다. 이 기사는 몽골 출신인 매우 키가 큰 사람 인 Öndör Gongor에 대해 독자들에게 알려줍니다:\n\n![image](/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_2.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해당 기사의 마지막 50개의 편집 중 첫 번째 편집은 2008년 1월 27일 오후 3시 13분 (UTC)에 이루어졌습니다. 다음 편집은 16분 후에 이루어졌습니다. 그 다음 편집은 데이터의 해상도 한계로 인해 1분 내로 발생하여 0일 00:00:00으로 표시됩니다.\n\n계속 처리하면, 각 기사 맨 처음에 나타나는 NaT (not-a-time) 행을 제거해 보겠습니다. 또한 대기 시간에 따라 정렬하고 판다의 인덱스를 재설정할 것입니다:\n\n```js\n# 'Time Delta' 열에서 NaT(시간이 아님) 값이 포함된 행 제거\nwiki_df.dropna(subset=['Time Delta'], inplace=True)\n# 시간 간격으로 정렬 및 인덱스 재설정\nwiki_df.sort_values(by='Time Delta', inplace=True)\nwiki_df.reset_index(drop=True, inplace=True)\ndisplay(wiki_df)\nwiki_df['Time Delta'].describe()\n```\n\n이를 통해 다음과 같이 시작하고 끝나는 데이터프레임이 생성됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 통계 요약입니다.\n\n```js\ncount                          36320\nmean      92 days 13:46:11.116189427\nstd      195 days 11:36:52.016155110\nmin                  0 days 00:00:00\n25%                  0 days 00:27:00\n50%                 15 days 05:41:00\n75%                100 days 21:45:45\nmax               4810 days 17:39:00\n```\n\n조사 결과, 샘플링된 대기 시간은 0일 00:00:00(즉, 1분 미만)부터 13년 이상까지 다양합니다. (13년 편집 대기는 버지니아 대학교의 건물에 관한 기사였습니다.) 편집의 1/4은 이전 편집 후 27분 이내에 발생합니다. 편집 간 중위값은 약 15일을 조금 넘습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n조금 더 발전하기 전에, 웨이팅 시간을 향상시키고 싶은데요. 다음과 같이 작은 함수를 사용해서 웨이팅 시간을 표시할 수 있습니다:\n\n```js\ndef seconds_to_text(seconds):\n    seconds = round(seconds)\n    result = []\n    for unit_name, unit_seconds in [('y', 86400 * 365.25),('d', 86400),('h', 3600),('m', 60),('s', 1)]:\n        if seconds \u003e= unit_seconds:\n            unit_value, seconds = divmod(seconds, unit_seconds)\n            result.append(f\"{int(unit_value)}{unit_name}\")\n    return ' '.join(result) if result else \"\u003c1s\"\n\nseconds_to_text(100)\n```\n\n위의 `seconds_to_text` 함수는 100초를 `1m 40s`로 표시합니다.\n\n이제 위키피디아 데이터를 위한 \"웨이팅 테이블\"을 만들 수 있습니다. 기존에 기사의 다음 편집을 기다린 시간을 주면, 이 테이블은 중간 추가로 기다려야 할 시간을 알려줍니다. (\"중간값\"은 이 시간보다 덜 기다릴 확률이 50%이고, 시간이 더 걸리는 확률이 50%라는 것을 의미합니다.)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport numpy as np\n\ndef wait_wait_table(df, wait_ticks):\n    sorted_time_deltas_seconds = df['Time Delta'].dt.total_seconds()\n    results = []\n    for wait_tick in wait_ticks:\n        greater_or_equal_values = sorted_time_deltas_seconds[sorted_time_deltas_seconds \u003e= wait_tick]\n        median_wait = np.median(greater_or_equal_values)\n        additional_wait = median_wait - wait_tick\n        results.append({\"Wait So Far\": seconds_to_text(wait_tick), \"Median Additional Wait\": seconds_to_text(additional_wait)})\n    return pd.DataFrame(results)\n\nwiki_wait_ticks = [0, 60, 60*5, 60*15, 3600, 3600*4, 86400, 86400 * 7,86400 * 30, 86400 * 100, 86400 * 365.25, 86400 * 365.25 * 5, 86400 * 365.25 * 10]\nwiki_wait_tick_labels = [seconds_to_text(wait_tick) for wait_tick in wiki_wait_ticks]\nwait_wait_table(wiki_df, wiki_wait_ticks).style.hide(axis=\"index\")\n```\n\n이제 이 표의 출력에 대해 알아보겠습니다.\n\n## \"대기 중\" 유형의 대기 - 토론\n\n앞의 파이썬 코드는 이 표를 생성합니다. 이것을 \"대기-대기\" 표라고 부르죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_4.png)\n\n만약 아무도 기다리지 않았다면(다시 말해, 누군가가 페이지를 편집했다) 다음 편집은 15일이 넘게 기다릴 것으로 예상됩니다. 그러나 1분 후에도 누군가 기사를 편집하지 않았다면, 19일을 기다려야 할 것으로 예상됩니다. 따라서 1분 기다리면 예상 추가 대기 시간이 거의 4일 더 늘어납니다. 한 시간 후에도 누구도 기사를 편집하지 않았다면, 예상 추가 대기 시간은 47일로 두 배 넘게 늘어납니다.\n\n이 현상을 생각하는 한 가지 방법은 다음 편집을 기다리기 시작할 때 우리가 어떤 종류의 페이지에 있는지 모르는 것입니다. 이것이 테일러 스위프트와 같은 핫 팝컬쳐 주제의 기사인가요? 아니면 5000명 대학의 건물인 '로턴다(The Rotunda)'와 같은 니치하고 느린 주제인가요? 수정이 일어나지 않는 매 분이 지날수록, 확률은 이것이 테일러 스위프트와 같은 기사에서 '로턴다(The Rotunda)'와 같은 기사로 이동합니다.\n\n마찬가지로, 고객 서비스에 전화하고 대기시간이 발생할 때 - 처음에는 어떤 종류의 고객 서비스를 기다리고 있는지 모릅니다. 그러나 매 분이 지날 때마다, 우리는 서서히 나쁜, 느린 고객 서비스를 기다리고 있다는 것을 알게 됩니다. 따라서 예상 추가 대기 시간은 늘어납니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금까지는 데이터를 직접 사용했습니다. 데이터를 확률 분포로 모델링해 볼 수도 있습니다. 그러나 모델링으로 넘어가기 전에 다른 두 예제인 마이크로파 팝콘 요리와 복권 당첨을 살펴보겠습니다.\n\n# \"팝콘\"형 기다림 - 기다릴수록 덜 기다리는 것을 기대합니다.\n\n위키피디아 편집을 기다리는 기법을 마이크로파 팝콘 조리를 기다리는 것에 적용해 봅시다. (매력적일지도 모르는) 실제 데이터를 수집하는 대신 모의 데이터를 시뮬레이션하는 것으로 만족합니다. 난수 생성기를 사용할 것입니다. 요리 시간은 센서를 기반으로 하는 것이라 가정하며, 5분에서 15초 차이가 날 수 있다고 가정합니다.\n\n## \"팝콘\"형 기다림 - 파이썬\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이썬에서 특히:\n\n```python\nseed = 0\nrng = np.random.default_rng(seed)\nsorted_popcorn_time_deltas = np.sort(rng.normal(5*60, 15, 30_000))\npopcorn_df = pd.DataFrame(pd.to_timedelta(sorted_popcorn_time_deltas, unit=\"s\"), columns=[\"Time Delta\"])\nprint(popcorn_df.describe())\n```\n\n이 코드는 다음과 같은 통계 요약이 포함된 판다 데이터프레임을 생성합니다:\n\n\n                      Time Delta\ncount                      30000\nmean   0 days 00:05:00.060355606\nstd    0 days 00:00:14.956424467\nmin    0 days 00:03:52.588244397\n25%    0 days 00:04:50.011437922\n50%    0 days 00:04:59.971380399\n75%    0 days 00:05:10.239357827\nmax    0 days 00:05:59.183245298\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예상대로, 이 정규 분포에서 데이터를 생성할 때 평균은 5분이고 표준 편차는 약 15초입니다. 우리가 시뮬레이션한 대기 시간은 3분 52초에서 6분까지 범위에 있습니다.\n\n이제 \"대기-대기\" 테이블을 생성할 수 있습니다:\n\n```js\nwait_wait_table(popcorn_df, [0, 10, 30, 60, 2*60, 3*60, 4*60, 5*60]).style.hide(axis=\"index\")\n```\n\n## \"팝콘\" 형태의 대기 시간 — 토론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리의 \"기다려-기다려\" 소프트웨어는 팝콘 테이블을 아래와 같이 보여줍니다:\n\n![팝콘 대기 시간](/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_5.png)\n\n우리의 테이블에 따르면, 처음에는 5분 기다림을 예상합니다. 그리고 10초를 기다린 후에는 추가로 기대되는 대기 시간이 정확히 10초 줄어듭니다 (4분 50초로). 1분을 기다린 후에는 추가 대기 시간이 4분으로 줄어들고, 그러한 식으로 이어집니다. 5분에 이르러서도 추가 대기 시간은 계속해서 줄어들지만 0으로는 안 줄어듭니다.\n\n나중에 데이터 모델링 하는 방법을 보게 될 것입니다. 지금은 복권 당첨을 기다리는 것에 대해 다음으로 살펴봅시다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# “로또 당첨” 스타일 대기 시간 — 지금까지 기다린 시간과는 무관하게, 예상 대기 시간은 동일합니다.\n\n로또 데이터에 대해서는 다시 시뮬레이션된 데이터를 생성하는 것이 편합니다. 워싱턴 주의 로또는 당첨 확률을 1 대 27.1로 제공합니다. (가장 흔한 당첨은 $1 베팅에 $3를 지불합니다.) 100만 주 (약 1만 9천 년) 동안 로또를 플레이하고 당첨 사이의 대기 시간에 대한 데이터를 수집해 봅시다.\n\n## “로또 당첨” 스타일 대기 시간 — 파이썬\n\n우리는 100만 주 동안의 로또 플레이를 시뮬레이션합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n시드 = 0\nrng = np.random.default_rng(시드)\n지난주_당첨 = None\n로또_대기 = []\nfor 주차 in range(1_000_000):\n    if rng.uniform(high=27.1) \u003c 1.0:\n        if 지난주_당첨 is not None:\n            로또_대기.append(주차 - 지난주_당첨)\n        지난주_당첨 = 주차\n정렬된_로또_시간_간격 = np.sort(np.array(로또_대기) * 7 * 24 * 60 * 60)\nlotto_df = pd.DataFrame(pd.to_timedelta(정렬된_로또_시간_간격, unit=\"s\"), columns=[\"시간 간격\"])\nprint(lotto_df.describe())\n```\n\n```js\n                        시간 간격\ncount                        36773\nmean   190 days 08:21:00.141951976\nstd    185 days 22:42:41.462765808\nmin                7 days 00:00:00\n25%               56 days 00:00:00\n50%              133 days 00:00:00\n75%              259 days 00:00:00\nmax             2429 days 00:00:00\n```\n\n우리의 최단 가능한 당첨 간격은 7일입니다. 가장 긴 시뮬레이션된 건조 기간은 6년 이상입니다. 중앙값 대기 시간은 133일입니다.\n\n우리는 \"대기-대기\" 테이블을 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nlotto_days = [0, 7, 7.00001,  2*7, 4*7, 183, 365.25, 2*365.25, 5*365.25]\nlotto_waits = [day * 24 * 60 * 60 for day in lotto_days]\nwait_wait_table(lotto_df, lotto_waits).style.hide(axis=\"index\")\n```\n\n## \"로또 당첨\" 스타일 대기 시간 — 토론\n\n여기 \"대기-대기\" 테이블이 있습니다:\n\n\u003cimg src=\"/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_6.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음은 Markdown 형식으로 작성된 텍스트입니다.\n\n테이블에 따르면 복권은 우리가 이기기까지 얼마나 기다렸는지에 신경을 쓰지 않습니다. 우리가 방금 이겼던지 (지금까지 기다린 시간 ` 1초) 아니면 1년 동안 이기지 못했던지, 우리가 다음 승리까지 기다려야 하는 예상 추가 기다림은 대부분 항상 126일부터 133일 사이입니다.\n\n표의 세 항목은 이상할 수 있습니다. 7일과 7일 1초에서 무슨 일이 일어나는지 생각해보세요. 추가 기다림이 126일에서 거의 즉시 133일 정도로 급격히 증가하는 이유는 무엇일까요? 답은 매주 추첨하는 시점에서 승리까지의 최소 기다림이 0일에서 7일로 변경되기 때문입니다. 그리고 5년은 어떻게 되는 걸까요? 5년을 기다린다면 보통 133일이 걸리는 대신 단지 50일만에 승리를 기대할 수 있는 것일까요? 안타깝게도 아닙니다. 오히려 이는 우리 데이터의 한계를 보여줍니다. 데이터에서는 5년을 기다리는 경우를 세 번만 볼 수 있습니다:\n\n```js\nlotto_df[lotto_df[\"Time Delta\"] \u003e pd.to_timedelta(24*60*60 * 365.25 * 5, unit=\"s\")]\n```\n\n\u003cimg src=\"/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_7.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n삼 가지 값은 중위수의 노이즈 추정치로 이어집니다.\n\n지금까지 실제 및 모의 데이터에서 본 것을 요약해보면:\n\n- 위키피디아 편집 — 기다릴수록 기대하는 대기 시간이 길어집니다.\n- 팝콘 — 기다릴수록 기대하는 대기 시간이 줄어듭니다.\n- 복권 당첨 — 지금까지의 대기 시간과 관계없이 기대 대기 시간은 동일합니다.\n\n다음 섹션에서는 모델링의 방법과 그 이유에 대해 살펴보겠습니다. 미국 로또 데이터부터 시작하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 부분에서는 대기 시간 예측을 위한 간단한 표현을 찾아보겠습니다. 예측에는 이러한 간소화가 필요하지 않습니다. 우리가 지금까지 만든 것은 경험적 분포라고 불리며 잘 작동합니다. 그러나 더 간단한 표현은 더 편리할 수 있습니다. 또한 다른 종류의 대기를 이해하기 쉽게 비교할 수 있게 해줄 수도 있습니다.\n\n우리는 세 가지 예제를 살펴보면서 진행할 것입니다. 가장 간단한 것부터 시작하여 (복권 당첨) 가장 복잡한 것(Wikipedia 편집)으로 넘어갈 것입니다. 이전과 마찬가지로 Python 코드(건너뛸 수 있는)와 토론 사이를 오가겠습니다.\n\n먼저 대기 시간 데이터프레임에 누적 분포 열을 추가하는 것부터 시작하겠습니다. 이전에 데이터프레임을 시간 딜타로 정렬했음을 기억해주세요.\n\n```python\nwiki_df['CDF'] = wiki_df['Time Delta'].rank(pct=True)\npopcorn_df['CDF'] = popcorn_df['Time Delta'].rank(pct=True)\nlotto_df['CDF'] = lotto_df['Time Delta'].rank(pct=True)\nwiki_df\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nCDF 컬럼은 누적 분포 함수(Cumulative Distribution Function)를 나타내며, 가장 짧은 대기 시간에는 0.0에 가까운 값이 있고, 가장 긴 대기 시간에는 1.0이 있습니다. 다시 말해, 각 행의 순위가 분수로 나타난 것입니다. 위키피디아 데이터프레임은 이제 다음과 같습니다:\n\n\n| Time Delta  |  CDF  |\n|-------------|-------|\n| 0 days 00:00:10 | 0.1 |\n| 0 days 00:00:30 | 0.3 |\n| 0 days 00:01:00 | 0.5 |\n| 0 days 00:02:00 | 0.7 |\n| 0 days 00:05:00 | 0.9 |\n| 0 days 00:10:00 | 1.0 |\n\n\n이제 CDF(누적 분포 함수)를 대기 시간 Time Delta(x-축)에 대해 그릴 수 있습니다. 파이썬에서 다음과 같은 플로팅 코드를 사용할 수 있습니다:\n\n```python\nimport matplotlib.pyplot as plt\n\ndef wait_cdf(title, sorted_df, wait_ticks, dist=None, dist_label=None, left=None, right=None, xscale='linear'):\n    wait_seconds = sorted_df['Time Delta'].dt.total_seconds() # x values\n    cdf = sorted_df['CDF'] # y values\n\n    left = left or wait_seconds.min()\n    right = right or wait_seconds.max()\n\n    plt.figure(figsize=(10, 6))\n    plt.title(title + ' 누적 분포 함수(CDF)')\n    plt.plot(wait_seconds, cdf, marker='.', linestyle=\" \", label='경험적인 CDF')\n\n    if dist is not None:\n        dist_x = np.logspace(np.log10(left), np.log10(right), 100) if xscale == 'log' else np.linspace(left, right, 100)\n        dist_y = dist.cdf(dist_x)\n        plt.plot(dist_x, dist_y, label = dist_label)\n\n    plt.xlabel('대기 시간')\n    plt.ylabel('CDF')\n    plt.xscale(xscale)\n    plt.xticks(wait_ticks, [seconds_to_text(wait_tick) for wait_tick in wait_ticks], rotation=45)\n    plt.xlim(left=left, right=right)\n    plt.grid(True, which=\"both\", ls=\"--\")\n    plt.legend(loc='upper left')\n    plt.show()\n\nwait_cdf(\"로또 당첨\", lotto_df, wiki_wait_ticks, xscale='log')\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n로또 당첨과 대기 시간의 CDF 플롯을 로그 스케일로 표시하였습니다:\n\n![Lottery Wins CDF Plot](/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_9.png)\n\n곡선이 간단해 보이니 이에 간단한 곡선을 적합해보려고 합니다. 가장 적합한 곡선은 지수 분포입니다. 이는 대기 시간과 관련된 가장 간단한 일반 함수입니다.\n\nPython의 scipy.stats 패키지를 사용하면 데이터에 지수 곡선을 맞추고 해당 결과 곡선을 Python 객체로 표현하는 것이 쉽습니다. 여기서는 lotto_expon_dist라는 이름으로 이를 표현했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nfrom scipy.stats import expon\n\n_, lotto_e_scale = expon.fit(lotto_df['Time Delta'].dt.total_seconds(), floc=0)\nlotto_expon_dist = expon(scale=lotto_e_scale)\nprint(f\"복권 당첨 지수 중앙값은 {seconds_to_text(lotto_expon_dist.median())} 입니다. 스케일 매개변수는 {seconds_to_text(lotto_e_scale)} 입니다.\")\n```\n\n이 코드는 출력합니다:\n\n복권 당첨 지수 중앙값은 131일 22시간 32분 20초 입니다. 스케일 매개변수는 190일 8시간 21분 입니다.\n\n적합된 곡선의 중앙값은 약 132일로, 경험적인 중앙값인 133일과 근접합니다. 지수곡선을 관행적으로 스케일이라는 단일 숫자로 매개변수화하는데, 이것은 분포의 평균에 해당하지만 평균에서 중앙값을 쉽게 계산하거나 그 반대로 할 수 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n로또 당첨금에 대한 경험적 누적 분포(EMCDF) 및 적합 누적 분포(FCDF) 플롯입니다:\n\n```js\nlotto_expon_label = f'ExponentialDistribution(scale={seconds_to_text(lotto_e_scale)})'\nwait_cdf(\"당첨금\", lotto_df, wiki_wait_ticks, dist=lotto_expon_dist, dist_label=lotto_expon_label, xscale='log')\n```\n\n\u003cimg src=\"/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_10.png\" /\u003e\n\n둘이 꽤 근접합니다. 왼쪽의 약간의 불일치는 복권 추첨시 모멘트의 즉시 7일 점프에 의해 발생합니다. 이 글에서는 이 작은 불일치를 무시하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리 (모의) 복권 당첨 데이터에 지수 함수가 잘 작동합니다. Popcorn과 Wikipedia 데이터에도 어떻게 작동하는지 살펴봅시다. 다음은 이러한 데이터프레임에 지수 분포를 맞추는 코드입니다.\n\n```js\n_, popcorn_e_scale = expon.fit(popcorn_df['Time Delta'].dt.total_seconds(), floc=0)\npopcorn_expon_dist = expon(scale=popcorn_e_scale)\nprint(f\"Popcorn exponential median is {seconds_to_text(popcorn_expon_dist.median())}\")\npopcorn_expon_label = f'ExponentialDistribution(scale={seconds_to_text(popcorn_e_scale)})'\nwait_cdf(\"Popcorn\", popcorn_df, popcorn_ticks, dist=popcorn_expon_dist, dist_label=popcorn_expon_label, left=10, right=6*60, xscale='linear' )\n\n_, wiki_e_scale = expon.fit(wiki_df['Time Delta'].dt.total_seconds(), floc=0)\nwiki_expon_dist = expon(scale=wiki_e_scale)\nprint(f\"Wiki exponential median is {seconds_to_text(wiki_expon_dist.median())}\")\nwiki_expon_label = f'ExponentialDistribution(scale={seconds_to_text(wiki_e_scale)})'\nwait_cdf(\"Wiki Edits\", wiki_df, wiki_wait_ticks, dist=wiki_expon_dist, dist_label=wiki_expon_label, xscale='log', left=60)\n```\n\n그리고 여기가 그림들입니다:\n\n\u003cimg src=\"/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_11.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_12.png)\n\n이런, 이 곡선 맞추기 결과는 정말 최악이네요! 문제는 지수 분포가 \"복권 당첨\"과 유사한 데이터만 모델링한다는 것입니다. 구체적으로 말하면, 대기 시간이 이전 대기 시간에 관계없이 기대 대기 시간이 동일한 경우에 해당합니다. 이전 대기 시간을 무시하는 대기 시간에 대해 좌우되는 경우, 이것이 메모리리스(exponential)이라고 불립니다. 또한 연속 분포 중에서 지수 분포는 유일한 메모리리스 분포입니다.\n\n그렇다면 분포에 메모리가 필요하다면 어떨까요? 다음으로 시도할 수 있는 가장 간단한 분포는 와이블(Weibull) 분포입니다.\n\n와이블 분포는 형태(shape)와 척도(scale) 두 매개변수로 매개화됩니다. 복권 데이터로 시작해 보죠:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```md\nfrom scipy.stats import weibull_min\n\nlotto_shape, _, lotto_w_scale = weibull_min.fit(lotto_df['Time Delta'].dt.total_seconds(), floc=0)\nlotto_weibull_dist = weibull_min(c=lotto_shape,scale=lotto_w_scale)\n\nprint(f\"복권 당첨 위블 중앙값은 {seconds_to_text(lotto_weibull_dist.median())}\")\nlotto_weibull_label = f'WeibullDistribution(shape={lotto_shape:.3},scale={seconds_to_text(lotto_w_scale)})'\nwait_cdf(\"복권 당첨\", lotto_df, wiki_wait_ticks, dist=lotto_weibull_dist, dist_label=lotto_weibull_label, xscale='log')\n```\n\n이는 지수함수와 유사한 장착 곡선을 생성합니다. 실제로 형태가 1일때 위블 분포는 지수 분포입니다. 여기서 형태는 1.06입니다.\n\n\u003cimg src=\"/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_13.png\" /\u003e\n\n팝콘 데이터에 위블을 적합하려고 하면 무엇이 발생하나요?\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\npopcorn_shape, _, popcorn_w_scale = weibull_min.fit(popcorn_df['Time Delta'].dt.total_seconds(), floc=0)\npopcorn_weibull_dist = weibull_min(c=popcorn_shape, scale=popcorn_w_scale)\nprint(f\"Popcorn Weibull median is {seconds_to_text(popcorn_weibull_dist.median())}\")\npopcorn_df_weibull_label = f'Weibull(shape={popcorn_shape:.3}, scale={seconds_to_text(popcorn_w_scale)})'\nwait_cdf(\"Popcorn\", popcorn_df, popcorn_ticks, dist=popcorn_weibull_dist, dist_label=popcorn_df_weibull_label, left=3*60, right=7*60, xscale='linear')\n```\n\n![Image](/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_14.png)\n\n안전하진 않지만, 이 적합은 지수 함수의 적합보다 훨씬 낫습니다. 모양 모수의 값이 20임을 주목하세요. Weibull의 모양 모수가 1보다 큰 경우 \"대기 시간이 길수록 대기 시간을 기대하는 것이 줄어든다\"를 나타냅니다.\n\n마지막으로, 위키피디아 데이터에 Weibull을 시도해보겠습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nwiki_shape, _, wiki_w_scale = weibull_min.fit(wiki_df['Time Delta'].dt.total_seconds(), floc=0)\nwiki_weibull_dist = weibull_min(c=wiki_shape, scale=wiki_w_scale)\nprint(f\"위키 위불 중앙값은 {seconds_to_text(wiki_weibull_dist.median())}\")\nwiki_df_weibull_label = f'위불(모양={wiki_shape:.3},스케일={seconds_to_text(wiki_w_scale)})'\nwait_cdf(\"위키 편집\", wiki_df, wiki_wait_ticks, dist=wiki_weibull_dist, dist_label=wiki_df_weibull_label, xscale='log', left=60)\n```\n\n\u003cimg src=\"/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_15.png\" /\u003e\n\n이 곡선 맞춤은 완벽하지 않지만, 지수함수의 맞춤보다 훨씬 좋습니다. 모양 모수값인 0.292에 주목해보세요. 위불의 모양 모수가 1보다 작을 때는 \"기다린 시간이 길수록 더 기다려야 한다\"는 것을 나타냅니다. 그러나 위불만이 이 특성을 갖고 있는 것은 아닙니다. 이 특성을 갖는 무수히 많은 분포들도 있습니다. 실제로 위키피디아 분포는 이 특성을 갖지만 위불 분포가 아닙니다.\n\n# 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n결론적으로, 당신과 나는 미친 것이 아닙니다(필요에 따라).\n\n우리는 정말 기다린 시간이 길수록 더 기다려야 할 상황이 있는 것을 보았습니다. 위키피디아 편집 사이의 시간 간격에서 경험적으로 확인할 수 있습니다. 또한 Weibull 분포에서 형태 매개변수가 1보다 작은 경우에도 확인할 수 있습니다.\n\n똑같이, 다른 몇 가지 대기 시간에는 \"기다린 시간이 길수록 더 적게 기다리게 된다\"는 규칙이 적용됩니다. 팝콘에서 이 현상을 확인할 수도 있습니다. 또한 Weibull 분포에서 형태 매개변수가 1보다 큰 경우에도 이를 확인할 수 있습니다.\n\n마지막으로, 세 번째 종류의 대기 시간인 \"메모리리스\"도 존재합니다. 이 경우, 지금까지 기다린 시간에 상관없이 기대 대기 시간은 동일합니다. 복권 당첨 간의 시간에서 이를 확인했습니다. 이는 형태 매개변수가 1인 Weibull 분포(지수 분포와 동일)와 관련이 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터를 분석할 때 기다릴 데이터가 있는 경우, Weibull 분포를 시도하는 것을 권장합니다. Python을 사용하면 이러한 곡선을 fitting하는 것이 쉽습니다. 그러나 데이터가 Weibull 분포와 잘 맞지 않는 경우에는 Weibull을 사용하지 않는 것이 좋습니다. 대신, 자료 분포를 직접 사용하여 데이터가 스스로 말하도록하십시오.\n\n기다림 시간에 대한 이 여정에 참여해 주셔서 감사합니다. 이제 기다림 시간과 그 분석에 대해 더 잘 이해하게 되었으면 좋겠습니다.\n\n칼을 Medium에서 팔로우해 주세요. 저는 Rust 및 Python에서의 과학적 프로그래밍, 머신러닝 및 통계에 대해 씁니다. 월 한 번 정도 기사를 씁니다.","ogImage":{"url":"/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_0.png"},"coverImage":"/assets/img/2024-05-17-AWhimsicalJourneyThroughWaitTimes_0.png","tag":["Tech"],"readingTime":20},{"title":"AWS Glue로 다수의 CSV 파일을 처리하는 ETL 단계별 팁","description":"","date":"2024-05-17 20:37","slug":"2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3","content":"\n\n이건 훌륭한 이미지입니다! 이 디지털 시대에 데이터는 기업에게 귀중한 자산이 되었습니다. 데이터를 효과적으로 처리하고 분석하는 것이 유용한 통찰력을 얻고 스마트한 의사결정을 하는 데 중요합니다. AWS Glue는 데이터를 쉽고 효율적으로 관리하고 분석하는 데 도움이 되는 포괄적인 솔루션이 됩니다.\n\n이 세션에서는 AWS Glue, 데이터 카탈로그, 및 크롤러가 하나의 버킷에 있는 여러 CSV 파일을 단일 데이터 세트로 읽는 방법에 대해 논의할 것입니다. 아래는 아키텍처 요약입니다:\n\n![아키텍처 이미지](/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# S3 버킷 준비하기\n\n처리하려는 모든 CSV 파일이 아마존 S3의 단일 버킷에 저장되어 있는지 확인하세요.\n\n![이미지](/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_2.png)\n\n# AWS Glue 데이터 카탈로그에서 데이터베이스 생성하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAWS Management Console에서 AWS Glue를 열고, \"데이터베이스\" 섹션으로 이동하여 메타데이터를 저장할 새 데이터베이스를 생성하세요.\n\n![이미지](/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_3.png)\n\n# 크롤러 생성\n\n이전에 생성한 데이터베이스를 선택하여 크롤러에 의해 생성된 테이블을 저장하세요. 크롤러를 사용하여 테이블 추가를 선택하세요. 크롤러에 이름을 지정하고 CSV 파일을 포함하는 S3 버킷 위치를 선택하여 데이터 원본을 지정하세요. S3의 데이터 원본에 액세스할 수 있는 IAM 역할을 지정하고 Glue 데이터 카탈로그에 항목을 생성할 수 있는 권한이 있는 IAM 역할을 지정하세요. 필요에 따라 크롤러 옵션을 구성하세요. 크롤러를 주기적으로 실행하려면 빈도를 설정하세요. 구성을 완료한 후 크롤러를 실행하세요. 크롤러는 지정된 버킷의 모든 CSV 파일을 읽고 Glue 데이터 카탈로그에 하나 이상의 테이블을 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Step-by-Step ETL Tips with AWS Glue: Handling Multiple CSV Files from S3](/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_4.png)\n\n![Step-by-Step ETL Tips with AWS Glue: Handling Multiple CSV Files from S3](/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_5.png)\n\nOnce the crawler status is complete you can preview the table data that has been created using Athena\n\n![Step-by-Step ETL Tips with AWS Glue: Handling Multiple CSV Files from S3](/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_6.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# AWS Glue에서 ETL 작업 만들기\n\n![ETL image](/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_7.png)\n\nAWS Glue은 데이터 변환의 핵심 프로세스인 ETL(추출, 변환, 로드)을 수행하는 다양한 방법을 제공합니다. 시각적 ETL, 주피터, 또는 스크립팅을 통해 가장 적합한 방법을 선택할 수 있습니다.\n\n## 시각적 ETL\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_8.png\" /\u003e\n\n기술적 배경이 없는 분들에게 시각적 ETL은 이상적인 선택지입니다. 직관적인 드래그 앤 드롭 인터페이스를 통해 코드 작성 없이도 ETL 워크플로를 구축할 수 있습니다. 다양한 데이터 원본을 쉽게 연결하고 데이터 변환을 적용하며 처리된 데이터를 원하는 대상에로 로드할 수 있습니다.\n\n여기 AWS Glue로 Data Catalog에서 S3로 시각적 ETL을 구축하는 단계별 안내서가 있습니다.\n\n- AWS Glue Studio에 액세스\n- 새 워크플로 생성\n- 데이터 원본 선택\n- 변환 추가\n- 데이터 대상 선택\n- 작업 구성\n- 작업 검토 및 실행\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## Jupyter Notebook\n\n![Image](/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_9.png)\n\n보다 경험 많은 데이터 전문가들에게 Jupyter는 더 많은 유연성과 파워를 제공합니다. Jupyter 노트북을 사용하면 Python 코드와 텍스트, 시각화를 결합하여 복잡한 데이터 분석을 수행할 수 있습니다.\n\n다음은 AWS Glue를 사용하여 Jupyter Notebook을 사용하는 단계입니다. Data Catalog에서 S3로 콘솔에서 사용하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- AWS Glue Studio를 열어주세요.\n- 새로운 주피터 노트북을 생성해주세요.\n- 주피터 노트북에 파이썬 코드를 작성해주세요.\n- 작성한 파이썬 코드를 실행해주세요.\n- 주피터 노트북을 저장하고 공유해주세요.\n\n## 스크립팅\n\nETL 프로세스를 완전히 제어하고 싶은 경우, AWS Glue를 사용하여 Python 및 Scala와 같은 다양한 프로그래밍 언어로 스크립트를 작성할 수 있습니다. 이러한 스크립트는 귀하의 특정 요구에 맞게 설계된 복잡한 데이터 변환을 수행하는 데 사용될 수 있습니다.\n\n아래는 데이터 카탈로그부터 S3까지 콘솔에서 AWS Glue를 스크립팅과 함께 사용하는 단계입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- AWS Glue 콘솔을 열어주세요.\n- 좌측 탐색 패널에서 Glue를 선택합니다.\n- 메인 패널 상단에서 Jobs를 선택합니다.\n- 'Create job'을 클릭합니다.\n- 작업의 이름을 입력해주세요. 예를 들어 \"TransferDataFromCatalogToS3\"와 같이 지정합니다.\n- Script location 섹션에서 Glue 스크립트를 선택합니다.\n- Glue 스크립트 상자에 다음과 같은 Python 스크립트를 입력하세요. 이는 예시입니다.\n\n```js\nimport sys\nfrom awsglue.transforms import *\nfrom awsglue.utils import getResolvedOptions\nfrom pyspark.context import SparkContext\nfrom awsglue.context import GlueContext\nfrom awsglue.job import Job\n  \nsc = SparkContext.getOrCreate()\nglueContext = GlueContext(sc)\nspark = glueContext.spark_session\njob = Job(glueContext)\n\n# Read\ndyf = glueContext.create_dynamic_frame.from_catalog(database='db-s3-glue ', \n                                                    table_name='1_source'\n                                                   )\n\n# Store\noutput_dyf = glueContext.write_dynamic_frame.from_options(frame=dyf, \n                                                          connection_type=\"s3\", \n                                                          format=\"glueparquet\", \n                                                          connection_options={\"path\": \"s3://s3-glue/2-target/\", \"partitionKeys\": []}, \n                                                          format_options={\"compression\": \"uncompressed\"}\n                                                         )\n\njob.commit()\n```\n\n# 다음은 무엇이 있을까요?\n\n- MySQL, SQL Server, Aurora와 같은 RDBMS 소스 탐색하기.\n- Redshift와 같은 데이터 웨어하우스로의 대상 데이터 탐색하기.\n- Workflows(오케스트레이션)를 사용하여 작업 자동화하기.\n- 스트림 처리.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 최선의 인사\n\n린탕 길랑","ogImage":{"url":"/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_0.png"},"coverImage":"/assets/img/2024-05-17-Step-by-StepETLTipswithAWSGlueHandlingMultipleCSVFilesfromS3_0.png","tag":["Tech"],"readingTime":5},{"title":"Node에서 안정적인 분산 시스템 구축하는 방법","description":"","date":"2024-05-17 20:34","slug":"2024-05-17-BuildingReliableDistributedSystemsinNode","content":"\n\n이 게시물은 Stripe, Netflix, Coinbase, Snap 및 기타 많은 회사들이 분산 시스템에서 다양한 문제를 해결하기 위해 사용하는 durable execution 개념을 소개합니다. 그리고 Temporal의 TypeScript/JavaScript SDK를 사용하여 durable 코드를 작성하는 것이 얼마나 간단한지 보여줍니다.\n\n# 분산 시스템\n\n트랜잭션을 지원하는 단일 데이터베이스로 뒷받침된 요청-응답 단일체를 구축할 때, 우리는 분산 시스템에 대한 많은 고려 사항이 없습니다. 단순한 실패 모드를 가질 수 있으며 쉽게 정확한 상태를 유지할 수 있습니다:\n\n- 클라이언트가 서버에 도달할 수 없는 경우 클라이언트가 다시 시도합니다.\n- 클라이언트가 서버에 도달하지만 서버가 데이터베이스에 도달하지 못하는 경우 서버는 오류로 응답하고 클라이언트가 다시 시도합니다.\n- 서버가 데이터베이스에 도달하지만 트랜잭션이 실패하는 경우 서버는 오류로 응답하고 클라이언트가 다시 시도합니다.\n- 트랜잭션이 성공하지만 서버가 클라이언트에 응답하기 전에 종료된 경우 클라이언트가 서버가 다시 켜질 때까지 다시 시도하고, 트랜잭션은 두 번째로 실패합니다(트랜잭션이 이미 적용되었는지를 알려주는 idempotency token과 같은 확인이 있음을 가정), 그리고 서버는 클라이언트에게 작업이 이미 수행되었음을 보고합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한 번에 두 번째 위치를 추가하면 데이터베이스를 사용하는 서비스나 외부 API와 같은 일은 장애를 처리하고 일관성을 유지하는 것(모든 데이터 저장소 간의 정확성)이 훨씬 더 복잡해집니다. 예를 들어, 서버가 신용 카드를 청구하고 데이터베이스를 업데이트해야 하는 경우처럼, 단순한 코드를 더 이상 작성할 수 없게 됩니다.\n\n```js\nfunction handleRequest() {\n  paymentAPI.chargeCard()\n  database.insertOrder()\n  return 200\n}\n```\n\n카드 청구(첫 번째 단계)는 성공했지만 데이터베이스에 주문 추가(두 번째 단계)가 실패할 경우 시스템은 일관성 없는 상태에 놓일 수 있습니다. 이 일관성을 유지하기 위해 두 번째 단계를 데이터베이스에 도달할 때까지 다시 시도하도록 할 수 있습니다. 그러나 코드를 실행하는 프로세스가 실패할 수도 있으며, 이 경우 우리는 첫 번째 단계가 발생한 사실을 전혀 알 수 없게 됩니다. 이 문제를 해결하려면 세 가지를 수행해야 합니다:\n\n- 주문 세부 정보를 유지\n- 완료한 프로그램 단계를 유지\n- 데이터베이스에서 미완료 주문을 확인하고 다음 단계로 계속 진행하는 워커 프로세스 실행\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그, 그리고 재시도 상태를 유지하고 각 단계에 시간 제한을 추가하는 것만으로도 많은 코드를 작성해야 하고, 특정 가장자리 경우나 실패 모드를 놓칠 수 있습니다. 만약 전체적이고 확장 가능한 아키텍처를 보려면 클릭하세요. 우리가 모든 그 코드를 작성하고 디버그할 필요 없이 좀 더 빠르고 신뢰할 수 있는 것들을 구축할 수 있었으면 좋겠다. 그걸 할 필요 없다는 건 우리가 내구성 실행을 사용할 수 있기 때문입니다.\n\n# 내구성 실행\n\n내구성 실행 시스템은 우리의 코드를 각 단계를 지속시키는 방식으로 실행합니다. 코드를 실행하는 프로세스나 컨테이너가 종료되어도 코드는 호출 스택과 로컬 변수를 포함한 모든 상태를 유지한 채 다른 프로세스에서 자동으로 계속 실행됩니다.\n\n내구성 실행은 하드웨어가 얼마나 신뢰할지나 하류 서비스가 얼마나 오랫동안 오프라인인지에 상관없이 코드가 완료되도록 보장합니다. 재시도와 타임아웃은 자동으로 수행되며, 코드가 아무것도 하지 않을 때(예를 들어 sleep('1 month') 문을 기다리는 동안) 자원이 해제됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n내구성 있는 실행은 이벤트 주도 아키텍처, 작업 대기열, 사가, 회로 차단기 및 트랜잭션 아웃박스와 같은 분산 시스템 패턴을 구현하는 것이 중요하지 않거나 불필요하게 만듭니다. 이것은 더 높은 추상화 수준에서 프로그래밍하는 것으로, 서버 충돌이나 네트워크 문제와 같은 일시적인 실패에 대해 걱정할 필요가 없는 곳입니다. 이것은 다음과 같은 새로운 가능성을 엽니다:\n\n- 로컬 변수에 상태를 저장하는 것이 데이터베이스보다 낫습니다. 로컬 변수는 자동으로 저장되기 때문입니다.\n- 한 달 동안 잠자는 코드를 작성할 수 있습니다. 다음 달에도 잠자던 프로세스가 여전히 존재할 필요가 없고, 리소스가 지속되는 동안 사용되지 않아도 됩니다.\n- 영원히 실행할 수 있는 함수, 그리고 이러한 함수와 상호작용할 수 있는 (명령을 보내거나 데이터를 쿼리하는) 기능들.\n\n내구성 있는 실행 시스템의 몇 가지 예는 Azure 내구성 함수, Amazon SWF, Uber Cadence, Infinitic, 그리고 Temporal(내가 일하는 곳)입니다. 완벽히 객관적이지 못할 리스크를 감수하더라도, 나는 Temporal이 이러한 옵션 중에서 최고라고 생각합니다 😊.\n\n# 내구성 있는 JavaScript\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 분산 시스템에서의 일관성과 내구 실행이 무엇인지 살펴보았으니, 실제 예시를 살펴보겠습니다. 내가 만든 이 음식 주문 앱은 내구성 있는 코드가 어떻게 생겼고 어떤 문제를 해결하는지 보여줍니다:\n\ntemporal.menu\n\n![Building Reliable Distributed Systems in Node](/assets/img/2024-05-17-BuildingReliableDistributedSystemsinNode_0.png)\n\n이 앱은 네 가지 주요 기능을 갖고 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 주문 생성 및 고객에게 청구\n- 주문 상태 가져오기\n- 주문 수령 처리\n- 주문 배달 처리\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*5Ivi74IEaDxDo182J91nSA.gif)\n\n메뉴에서 품목을 주문하면 배송 기사 사이트(drive.temporal.menu)에 나타나며, 운전자는 주문을 수령 처리하고 배달된 것으로 표시할 수 있습니다.\n\n모든 이 기능은 내구성이 있는 JavaScript 또는 TypeScript의 단일 기능에서 구현할 수 있습니다. 저희는 TypeScript를 사용하고 있습니다 - TypeScript를 권장하며 라이브러리의 이름은 TypeScript SDK입니다. 그러나 npm에는 JavaScript 형식으로 게시되어 있으며 모든 Node.js 프로젝트에서 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 주문 생성하기\n\n이 앱의 코드를 살펴봅시다. 몇 가지 API 경로를 살펴보겠지만 대부분은 order라는 단일 내구성 함수의 각 부분을 검토할 겁니다. 앱을 실행하거나 코드를 보려면 프로젝트를 다운로드하고 설정하려면 다음을 실행하세요:\n\n```js\nnpx @temporalio/create@latest --sample food-delivery\n```\n\n사용자가 주문 버튼을 클릭하면 React 프론트엔드가 tRPC 백엔드에서 정의된 createOrder 뮤테이션을 호출합니다. createOrder API 경로 핸들러는 내구성 주문 함수를 시작하여 주문을 생성합니다. 내구성 함수인 Workflows은 @temporalio/client의 Client 인스턴스를 사용하여 시작된다. 이는 tRPC 컨텍스트에 ctx.temporal로 추가되었으며, 경로 핸들러는 유효성이 검증된 입력(제품 ID 번호 및 주문 ID 문자열을 포함한 객체)을 받아들이며, ctx.temporal.workflow.start를 호출하여 주문 Workflows을 시작합니다. 입력.productId를 인수로 제공합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```typescript\napps/menu/pages/api/[trpc].ts\n\nimport { initTRPC } from '@trpc/server'\nimport { z } from 'zod'\nimport { taskQueue } from 'common'\nimport { Context } from 'common/trpc-context'\nimport { order } from 'workflows'\n\nconst t = initTRPC.context\u003cContext\u003e().create()\n\nexport const appRouter = t.router({\n  createOrder: t.procedure\n    .input(z.object({ productId: z.number(), orderId: z.string() }))\n    .mutation(async ({ input, ctx }) =\u003e {\n      await ctx.temporal.workflow.start(order, {\n        workflowId: input.orderId,\n        args: [input.productId],\n        taskQueue,\n      })\n      return 'Order received and persisted!'\n    }),\n```\n\nThe order function starts out validating the input, setting up the initial state, and charging the customer:\n\npackages/workflows/order.ts\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ntype OrderState = 'Charging card' | 'Paid' | 'Picked up' | 'Delivered' | 'Refunding'\n\nexport async function order(productId: number): Promise\u003cvoid\u003e {\n  const product = getProductById(productId)\n  if (!product) {\n    throw ApplicationFailure.create({ message: `Product ${productId} not found` })\n  }\n  let state: OrderState = 'Charging card'\n  let deliveredAt: Date\n  try {\n    await chargeCustomer(product)\n  } catch (err) {\n    const message = `Failed to charge customer for ${product.name}. Error: ${errorMessage(err)}`\n    await sendPushNotification(message)\n    throw ApplicationFailure.create({ message })\n  }\n  state = 'Paid'\n```\n\n어떤 기능이 실패할 수있는 함수는 자동으로 재시도됩니다. 이 경우 chargeCustomer 및 sendPushNotification은 두 서비스에 액세스하며, 현재 가동 중이거나 \"일시적으로 사용할 수 없음\"과 같은 일시적 오류 메시지를 반환할 수 있습니다. Temporal은 이러한 함수를 실행하는 것을 자동으로 재시도합니다 (기본적으로 제곱 백오프 방식으로 무제한으로, 그러나 이것은 구성 가능합니다). 함수는 \"카드 거절\"과 같은 재시도할 수 없는 오류도 throw할 수 있습니다. 이 경우에는 재시도되지 않습니다. 대신, 에러가 chargeCustomer(product)에서 throw되고 catch 블록에서 캐치됩니다. 고객은 결제 방법이 실패했다는 알림을 받으며, 우리는 주문 Workflow를 실패시키기 위해 ApplicationFailure를 throw합니다.\n\n# 주문 상태 확인\n\n다음 코드 부분은 약간의 백그라운드 지식이 필요합니다. 일반 함수는 오래 실행할 수 없으므로, 일이 발생할 때까지 대기하는 동안 리소스를 차지하고, 언젠가는 새 코드를 배포하고 이전 컨테이너가 종료되면 종료될 것입니다. 내구성 함수는 두 가지 이유로 임의의 길이로 실행할 수 있습니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 어떤 것을 기다리고 있을 때에는 리소스를 차지하지 않습니다.\n- 그들을 실행하는 프로세스가 종료되어도 문제가 되지 않습니다. 다른 프로세스가 실행을 계속할 것이기 때문입니다.\n\n따라서 일부 영구 함수는 돈을 이체하는 함수처럼 짧은 시간 운영되지만, 어떤 것은 주문이 완료될 때 끝나는 주문 함수와 고객의 평생을 지속하는 고객 함수와 같이 길게 운영됩니다.\n\n긴 시간 동안 실행되는 함수와 상호 작용할 수 있는 것은 유용합니다. Temporal은 함수로 데이터를 보내는 신호(Signals)와 함수에서 데이터를 가져오는 쿼리(Queries)를 제공합니다. 드라이버 사이트는 이 API 경로를 통해 주문 함수에 쿼리를 보내어 각 주문의 상태를 보여줍니다:\n\napps/menu/pages/api/[trpc].ts\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ngetOrderStatus: t.procedure\n  .input(z.string())\n  .query(({ input: orderId, ctx }) =\u003e ctx.temporal.workflow.getHandle(orderId).query(getStatusQuery)),\n```\n\n특정 주문 함수(Workflow Execution이라고도 함)의 핸들을 가져와 getStatusQuery를 보내고 결과를 반환합니다. getStatusQuery는 주문 파일에 정의되어 있으며 주문 함수에서 처리됩니다:\n\npackages/workflows/order.ts\n\n```js\nimport { defineQuery, setHandler } from '@temporalio/workflow'\n\nexport const getStatusQuery = defineQuery\u003cOrderStatus\u003e('getStatus')\n\nexport async function order(productId: number): Promise\u003cvoid\u003e {\n  let state: OrderState = 'Charging card'\n  let deliveredAt: Date\n  //…\n  setHandler(getStatusQuery, () =\u003e {\n    return { state, deliveredAt, productId }\n  })\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\ngetStatusQuery를 전달하는 order 함수가 호출되면, setHandler에 전달된 함수가 호출되어 로컬 변수의 값을 반환합니다. chargeCustomer 호출이 성공하면 상태가 '지불 완료'로 변경되고, getStatusQuery를 계속 폴링하던 드라이버 사이트가 업데이트된 상태를 받습니다. 그리고 'Pick up' 버튼을 표시합니다.\n\n# 주문 픽업하기\n\n드라이버가 주문을 픽업으로 표시하기 위해 버튼을 탭하면, 사이트는 API 서버에 pickUp 변경을 보내고, 이는 order 함수에 pickedUpSignal을 보냅니다:\n\napps/driver/pages/api/[trpc].ts\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\npickUp: t.procedure\n  .input(z.string())\n  .mutation(async ({ input: orderId, ctx }) =\u003e \n    ctx.temporal.workflow.getHandle(orderId).signal(pickedUpSignal)\n  ),\n```\n\n신청 함수는 상태를 업데이트하여 시그널을 처리합니다:\n\npackages/workflows/order.ts\n\n```js\nexport const pickedUpSignal = defineSignal('pickedUp')\n\nexport async function order(productId: number): Promise\u003cvoid\u003e {\n  // …\n  setHandler(pickedUpSignal, () =\u003e {\n    if (state === 'Paid') {\n      state = 'Picked up'\n    }\n  })\n```  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n함수의 하단에서는 고객에 청구된 후에 픽업이 발생할 때까지 기다려왔다:\n\npackages/workflows/order.ts\n\n```js\nimport { condition } from '@temporalio/workflow'\n\nexport async function order(productId: number): Promise\u003cvoid\u003e {\n  // ...\n  try {\n    await chargeCustomer(product)\n  } catch (err) {\n    // ...\n  }\n  state = 'Paid'\n  const notPickedUpInTime = !(await condition(() =\u003e state === 'Picked up', '1 min'))\n  if (notPickedUpInTime) {\n    state = 'Refunding'\n    await refundAndNotify(\n      product,\n      '⚠️ No drivers were available to pick up your order. Your payment has been refunded.'\n    )\n    throw ApplicationFailure.create({ message: 'Not picked up in time' })\n  }\n```\n\n`await condition(() =\u003e state === 'Picked up', '1 min')` 함수는 상태 변화를 'Picked up'으로 변경할 때까지 1분 동안 대기합니다. 1분이 지나도 상태가 변경되지 않으면 false를 반환하고 고객에게 환불을 합니다. (우리는 요리사와 배송 기사의 속도에 엄격한 기준을 가지고 있거나, 데모 앱의 사용자가 모든 실패 모드를 볼 수 있기를 원하는 것 같아요 😄.)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 배송\n\n마찬가지로 \"배송\" 버튼으로 전송된 deliveredSignal이 있습니다. 픽업 후 1분 이내에 운전자가 배송을 완료하지 않으면 고객에게 환불이 이뤄집니다.\n\npackages/workflows/order.ts\n\n```js\nexport const deliveredSignal = defineSignal('delivered')\n\nexport async function order(productId: number): Promise\u003cvoid\u003e {\n  setHandler(deliveredSignal, () =\u003e {\n    if (state === 'Picked up') {\n      state = 'Delivered'\n      deliveredAt = new Date()\n    }\n  })\n  // …\n  await sendPushNotification('🚗 주문 픽업됨')\n  const notDeliveredInTime = !(await condition(() =\u003e state === 'Delivered', '1 min'))\n  if (notDeliveredInTime) {\n    state = 'Refunding'\n    await refundAndNotify(product, '⚠️ 운전자가 주문을 배달하지 못했습니다. 결제가 환불되었습니다.')\n    throw ApplicationFailure.create({ message: '제시간 배송되지 않음' })\n  }\n  await sendPushNotification('✅ 주문이 배달되었습니다!')\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n배송이 성공적으로 완료되면 고객이 식사를 하는 데 한 분을 기다리고, 그들에게 경험을 평가하도록 요청합니다.\n\n```js\n  await sleep('1 min') // 이것은 몇 시간 또는 심지어 몇 달이 될 수도 있습니다\n  await sendPushNotification(`✍️ 식사를 평가해주세요. ${product.name.toLowerCase()}는 어떠셨나요?`)\n}\n```\n\n최종 푸시 알림 이후, 주문 함수 실행이 종료되고 Workflow Execution이 성공적으로 완료됩니다. 함수가 완료되었더라도 Temporal이 함수의 최종 상태를 저장하고 있기 때문에 여전히 쿼리를 보낼 수 있습니다. 주문이 배달된 후 1분 뒤 페이지를 새로 고치면 여전히 getStatusQuery가 작동하고 \"배송됨\"이 상태로 표시됩니다:\n\n![이미지](/assets/img/2024-05-17-BuildingReliableDistributedSystemsinNode_1.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 요약\n\n단일 내구성 함수를 사용하여 다단계 주문 흐름을 구현할 수 있는 방법을 살펴보았습니다. 이 함수는 네트워크, 데이터 저장소 또는 하위 서비스와 관련된 일시적 문제뿐만 아니라 다음과 같은 문제가 발생할 경우에도 완료가 보장됩니다:\n\n- 네트워크, 데이터 저장소 또는 하위 서비스와 관련된 일시적 문제\n- 함수 실행 중 문제 발생\n- 기반이 되는 Temporal 서비스 또는 데이터베이스 다운\n\n이를 통해 분산 시스템에 대한 여러 문제점을 해결할 수 있었으며:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 로컬 변수를 사용하여 상태를 데이터베이스에 저장하는 대신에 활용할 수 있습니다.\n- 주문이 너무 오래 걸려 주문을 취소하거나 chargeCustomer와 같은 일시적 함수를 재시도하고 시간 초과하는 내장 기능을 위해 데이터베이스에 타이머를 설정할 필요가 없었습니다.\n- 다음 단계로 진행하기 위해 워커가 조사하는 작업 대기열을 설정할 필요가 없었으며, 실패한 프로세스에 의해 중단된 미완료 작업을 진행하거나 선택하기 위해서도 필요하지 않았습니다.\n\n다음 글에서는 배송 앱의 코드를 더 살펴보고 Temporal이 우리에게 내구성 실행을 제공하는 방법을 배우게 될 것입니다. 새로운 글이 올라오면 알림을 받으려면 Twitter 또는 LinkedIn에서 팔로우해주세요.\n\n질문이 있으면 언제든지 도와드릴게요! Temporal의 미션이 개발자를 돕는 데에 있고, 개인적으로 그것에서 기쁨을 느낍니다 🤗. 트위터에서는 @lorendsr로, temporal-typescript 태그가 달린 StackOverflow 질문에는 답변(그리고 좋아요 😄)을 달며, 커뮤니티 Slack에는 @Loren으로 활동하고 있습니다 💃.\n\n# 더 배우기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n더 알아보려면 다음 자료를 추천합니다:\n\n- 영상: Temporal 소개 및 TypeScript SDK 사용하기\n- 몇 가지 일반적인 사용 사례\n- TypeScript SDK 문서: t.mp/ts\n- TypeScript API 참조: t.mp/ts-api\n- TypeScript 튜토리얼\n\n더 많은 TypeScript SDK에 관한 블로그 포스트:\n\n- Node.js 작업 큐로서 Temporal 사용하기\n- 장기 워크플로를 통해 API 요청 캐싱하기\n- 워크플로에 대한 REST API를 생성하는 Express 미들웨어\n- TS SDK 1.0.0 릴리스\n- Workflow 결정론을 강제하기 위해 V8 독립체 사용하는 방법\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n💬 하커 뉴스, 레딧, 트위터, 또는 링크드인에서 토론해보세요. \n\n이 게시물 초안을 읽어준 제시카 웨스트, 브라이언 호건, 애밀리아 망고, 그리고 짐 워커에게 감사드립니다.","ogImage":{"url":"/assets/img/2024-05-17-BuildingReliableDistributedSystemsinNode_0.png"},"coverImage":"/assets/img/2024-05-17-BuildingReliableDistributedSystemsinNode_0.png","tag":["Tech"],"readingTime":12}],"page":"13","totalPageCount":94,"totalPageGroupCount":5,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"13"},"buildId":"7rKODeu6chWTLgXf6auoL","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>