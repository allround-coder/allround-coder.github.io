<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>allround-coder</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://allround-coder.github.io///posts/1" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="allround-coder" data-gatsby-head="true"/><meta property="og:title" content="allround-coder" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://allround-coder.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://allround-coder.github.io///posts/1" data-gatsby-head="true"/><meta name="twitter:title" content="allround-coder" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | allround-coder" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZFDEQ947R4"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
  
            gtag('config', 'G-ZFDEQ947R4');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/baeec1f16d6ea8b8.css" as="style"/><link rel="stylesheet" href="/_next/static/css/baeec1f16d6ea8b8.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/873-af801b1eee26eff3.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-498da29379dd58dc.js" defer=""></script><script src="/_next/static/R94iUTCf1NWeBC_VXjTJG/_buildManifest.js" defer=""></script><script src="/_next/static/R94iUTCf1NWeBC_VXjTJG/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Allround Coder</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="아니요, 제가 줌에서 당신을 보고 싶지 않아요" href="/post/2024-05-17-NoIDontWanttoLookAtYouonZoom"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="아니요, 제가 줌에서 당신을 보고 싶지 않아요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-NoIDontWanttoLookAtYouonZoom_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="아니요, 제가 줌에서 당신을 보고 싶지 않아요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">아니요, 제가 줌에서 당신을 보고 싶지 않아요</strong><div class="PostList_meta__VCFLX"><span class="date">13 hours ago</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="오픈CTI 61의 텔레메트리" href="/post/2024-05-17-TelemetryinOpenCTI61"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="오픈CTI 61의 텔레메트리" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-TelemetryinOpenCTI61_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="오픈CTI 61의 텔레메트리" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">오픈CTI 61의 텔레메트리</strong><div class="PostList_meta__VCFLX"><span class="date">13 hours ago</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="중간여정의 SREF 랜덤 ID 코드 해석하기" href="/post/2024-05-17-CrackingtheCodeofMidjourneysSREFRandomIDs"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="중간여정의 SREF 랜덤 ID 코드 해석하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-CrackingtheCodeofMidjourneysSREFRandomIDs_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="중간여정의 SREF 랜덤 ID 코드 해석하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">중간여정의 SREF 랜덤 ID 코드 해석하기</strong><div class="PostList_meta__VCFLX"><span class="date">13 hours ago</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="암 치료에 대한 대응" href="/post/2024-05-17-ResponsetoCancerTreatment"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="암 치료에 대한 대응" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-ResponsetoCancerTreatment_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="암 치료에 대한 대응" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">암 치료에 대한 대응</strong><div class="PostList_meta__VCFLX"><span class="date">13 hours ago</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="오픈 소스 모델, 온도 조정, 재순위 매기기 등 최신 LLM 반드시 읽어야 할 글들을 놓치지 마세요" href="/post/2024-05-17-Open-SourceModelsTemperatureScalingRe-RankingandMoreDontMissOurRecentLLMMust-Reads"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="오픈 소스 모델, 온도 조정, 재순위 매기기 등 최신 LLM 반드시 읽어야 할 글들을 놓치지 마세요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-Open-SourceModelsTemperatureScalingRe-RankingandMoreDontMissOurRecentLLMMust-Reads_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="오픈 소스 모델, 온도 조정, 재순위 매기기 등 최신 LLM 반드시 읽어야 할 글들을 놓치지 마세요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">오픈 소스 모델, 온도 조정, 재순위 매기기 등 최신 LLM 반드시 읽어야 할 글들을 놓치지 마세요</strong><div class="PostList_meta__VCFLX"><span class="date">13 hours ago</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AWS 기반 클라우드 기반 생성 AI" href="/post/2024-05-17-AWSBedrockCloud-basedGenerativeAI"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AWS 기반 클라우드 기반 생성 AI" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-AWSBedrockCloud-basedGenerativeAI_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AWS 기반 클라우드 기반 생성 AI" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">AWS 기반 클라우드 기반 생성 AI</strong><div class="PostList_meta__VCFLX"><span class="date">13 hours ago</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="여러분의 RAG 어플리케이션 개선을 위한 5가지 해킹 팁" href="/post/2024-05-17-5HacksToImproveYourRAGApplication"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="여러분의 RAG 어플리케이션 개선을 위한 5가지 해킹 팁" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-5HacksToImproveYourRAGApplication_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="여러분의 RAG 어플리케이션 개선을 위한 5가지 해킹 팁" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">여러분의 RAG 어플리케이션 개선을 위한 5가지 해킹 팁</strong><div class="PostList_meta__VCFLX"><span class="date">13 hours ago</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AI 콘텍스트 뉴로심볼릭 RAG 및 지식 그래프의 힘" href="/post/2024-05-17-ContextualAINeurosymbolicRAGandthePowerofKnowledgeGraphs"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AI 콘텍스트 뉴로심볼릭 RAG 및 지식 그래프의 힘" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-ContextualAINeurosymbolicRAGandthePowerofKnowledgeGraphs_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AI 콘텍스트 뉴로심볼릭 RAG 및 지식 그래프의 힘" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">AI 콘텍스트 뉴로심볼릭 RAG 및 지식 그래프의 힘</strong><div class="PostList_meta__VCFLX"><span class="date">13 hours ago</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="글로벌 자동화론" href="/post/2024-05-17-TheGlobalAutomatonFallacy"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="글로벌 자동화론" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-TheGlobalAutomatonFallacy_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="글로벌 자동화론" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">글로벌 자동화론</strong><div class="PostList_meta__VCFLX"><span class="date">13 hours ago</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="홈 랩 DNS 업데이트 테크니티움, 파이홀" href="/post/2024-05-17-HomeLabDNSUpdateTechnitiumPi-Hole"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="홈 랩 DNS 업데이트 테크니티움, 파이홀" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-17-HomeLabDNSUpdateTechnitiumPi-Hole_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="홈 랩 DNS 업데이트 테크니티움, 파이홀" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">홈 랩 DNS 업데이트 테크니티움, 파이홀</strong><div class="PostList_meta__VCFLX"><span class="date">13 hours ago</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><a class="link posts_-active__YVJEi" href="/posts/1">1</a><a class="link" href="/posts/2">2</a><a class="link" href="/posts/3">3</a><a class="link" href="/posts/4">4</a><a class="link" href="/posts/5">5</a><a class="link" href="/posts/6">6</a><a class="link" href="/posts/7">7</a><a class="link" href="/posts/8">8</a><a class="link" href="/posts/9">9</a><a class="link" href="/posts/10">10</a><a class="link" href="/posts/11">11</a><a class="link" href="/posts/12">12</a><a class="link" href="/posts/13">13</a><a class="link" href="/posts/14">14</a><a class="link" href="/posts/15">15</a><a class="link" href="/posts/16">16</a><a class="link" href="/posts/17">17</a><a class="link" href="/posts/18">18</a><a class="link" href="/posts/19">19</a><a class="link" href="/posts/20">20</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"아니요, 제가 줌에서 당신을 보고 싶지 않아요","description":"","date":"2024-05-17 04:29","slug":"2024-05-17-NoIDontWanttoLookAtYouonZoom","content":"\n\n![NoIDontWanttoLookAtYouonZoom](/assets/img/2024-05-17-NoIDontWanttoLookAtYouonZoom_0.png)\n\nZoom를 항상 싫어했던 유일한 사람인가요?\n\n잘못 이해하지 마세요. 필요한 때에 나타났고, COVID가 거리를 패달아 다녔을 때 나타났죠. 모든 건물이 닫혀 있었고, 마스크를 쓰지 않은 사람은 보지도 못했어요.\n\n저는 대학 시절 COVID를 겪은 사람으로서 이 모든 것을 잘 알고 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n수업에 가지 않아도 되는 아이디어를 좋아했는데, Zoom 덕분에 교수님들과 매니저들이 완전히 긴장된 상태가 되었어요.\n\n지금은 Zoom 콜을 위해 사람들이 만든 모든 규칙들을 싫어해요:\n\n- 카메라를 꼭 켜야 합니다\n- 좋은 소리를 꼭 설정해야 합니다\n- 채팅에 댓글/질문을 하나 꼭 써야 합니다\n- 프로필 사진이 있어야 합니다\n- 멋진 배경을 가져야 합니다\n\n정말 말도 안 되게 되고 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 내가 어떻게 생겼는지 이미 아는데 내 얼굴을 왜 보려고 하나요?\n\n뻔한 농담을 할 때마다 가짜 미소를 보려고 하는 거예요? 내가 뭘 입었는지 보려고?\n\n진지해져요.\n\n대부분의 경우, 줌 콜이 예정되어 있을 때, 저는 잠옷을 입고 있어요. 화장도 안 하고 머리는 엉망이 되어 있을 거예요. 마치 방금 일어난 것처럼 보일 거예요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그건 내가 너나 누구에게도 보고 싶어하는 것이 아닌 걸.\n\n집에서는 칙칙한 모습을 보여주고 싶지 않아. 그건 직장에서 해야 할 일이지.\n\nZoom은 거의 개인 정보 침해로 변모했어.\n\n왜 내 배경이 어떤지 볼 필요가 있어? 내가 어디에 있는지 알고 싶어?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n내 위치는 당신의 사업이 아닙니다.\n\n그리고 온라인에서 사용할 수 있는 멋진 배경에 대해 전혀 신경 쓰지 않습니다. 내 카메라는 꺼져 있어야 하기 때문에 배경을 찾아야 할 이유가 없습니다!\n\n이것은 오디오 통화여야만 합니다.\n\n## 그 큰 불평을 한 이유는 다시 일반 전화 통화를 정상화해야 한다는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 서로 얼굴을 본 적이 없고 자신을 소개하거나 화면 공유를 통해 중요한 내용을 논의하고 싶다면 Zoom 콜의 필요성을 이해합니다. 완전히 이해할 수 있어요.\n\n하지만 월간 또는 주간 상호작용에는 Zoom 콜이 필요하지 않아요.\n\n그 순간에, 당신은 누군가를 감시하거나 신뢰하지 않는 사람을 조사하기 위해 Zoom 콜을 진행하고 있어요. 이제 이런 일에 시간을 할애할 여유가 없어요.\n\n오디오 콜이 돌아오기를 바래요 (이전에는 그것이 불편했던 사람으로서).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 빛을 보았어요.\n\n당신의 얼굴을 보고 싶지 않고, 제 얼굴도 보고 싶지 않아요, 알겠죠?\n\n화가 풀렸어요.\n\n90일 안에 글쓰기 습관을 시작하고 싶나요? 여기서 무료 글쓰기 습관 안내서를 받아보세요.","ogImage":{"url":"/assets/img/2024-05-17-NoIDontWanttoLookAtYouonZoom_0.png"},"coverImage":"/assets/img/2024-05-17-NoIDontWanttoLookAtYouonZoom_0.png","tag":["Tech"],"readingTime":2},{"title":"오픈CTI 61의 텔레메트리","description":"","date":"2024-05-17 04:28","slug":"2024-05-17-TelemetryinOpenCTI61","content":"\n\n\u003cimg src=\"/assets/img/2024-05-17-TelemetryinOpenCTI61_0.png\" /\u003e\n\n6.1부터 OpenCTI는 플랫폼과 관련된 일부 측정 값을 수집합니다. 현재 사용량은 이전보다 매우 많은 데이터 양을 의미하기 때문에 플랫폼 성능을 개선하기 위해 이러한 메트릭 수집은 이제 필수적입니다. 또한 우리에게는 워크플로우를 향상시키고 커뮤니티 사용 패턴에 맞게 적응시키는 것이 중요합니다. 데이터는 익명화되어 통계적으로 처리됩니다. 사용자 개인 정보와 기밀 데이터는 수집되지 않습니다.\n\n함께 이 과정을 알아보도록 합시다! 🙂\n\n# 기밀성과 익명화\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n수집된 모든 데이터는 익명화되어 있으며 IP 주소, 이메일 주소 또는 사용자 이름과 같은 개별 사용자를 식별할 수 있는 데이터는 수집하지 않습니다. 따라서 사용자의 개인 정보는 개인정보 규정을 준수하여 보호받고 있습니다.\n\n또한 위협 인식 지식과 관련된 정보를 수집하지 않습니다: 플랫폼에서 소비된 데이터 및 분석 데이터는 엄격히 기밀을 유지합니다.\n\n# 텔레메트리의 목적\n\n수집된 데이터는 다음을 위해 사용됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 플랫폼 사용을 더 잘 이해하여 응용 프로그램의 기능과 성능을 향상시킵니다.\n- 사용자 행동을 분석하여 사용자 경험을 향상시킵니다.\n- 내부 측정항목 및 KPI를 위해 집계 및 익명화된 통계를 생성합니다.\n\n미래에는 외부 보고를 위해 이 통계 데이터도 사용할 계획이며, OpenCTI 사용에 대한 직접적인 통찰을 사용자 및 고객 커뮤니티에 제공할 것입니다.\n\n# 텔레메트리 데이터 계산\n\n텔레메트리 데이터를 수집, 관리 및 내보내기하기 위해 OpenTelemetry 라이브러리를 사용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n메트릭은 텔레메트리 관리자에 의해 매 시간 수집됩니다. 플랫폼 수명 중 변하지 않는 버전과 같은 일부 메트릭은 텔레메트리 관리자 시작 시에 한 번만 수집됩니다.\n\n## 텔레메트리 데이터 내보내기\n\n데이터는 두 가지 방법으로 매 6시간마다 내보냅니다:\n\n- 파일 내보내기 — 메트릭은 파일 내보내기자를 통해 특정 로그 파일에 기록됩니다. 이 파일은 로컬 OpenCTI 폴더(경로: opencti/opencti-platform/opencti-graphql/telemetry/)에서 찾을 수 있으므로 내보낸 데이터에 액세스할 수 있습니다. 이 파일들은 지원 패키지에 포함되어 있습니다. 이 파일들은 항상 생성되며 비활성화할 수 없습니다.\n- OTPL 내보내기 — 연결된 플랫폼의 경우 메트릭은 OTLP 프로토콜을 통해 HTTPS를 통해 telemetry.filigran.io 호스트에 전송됩니다. 이 내보내기는 OpenCTI가 텔레메트리 관리자 시작 시에 호스트명에 연결할 수없는 경우 비활성화됩니다(연결 끊긴 플랫폼).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n내보낸 데이터는 OpenTelemetry JSON 형식으로 작성됩니다.\n\n![그림](/assets/img/2024-05-17-TelemetryinOpenCTI61_1.png)\n\n## 수집된 데이터\n\n다음은 OpenCTI 6.1에서 수집된 플랫폼 사용에 관련된 메트릭 목록입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 현재 플랫폼 버전,\n- 플랫폼 고유 식별자,\n- 플랫폼 생성 날짜,\n- 노드(인스턴스) 수,\n- 총 사용자 수,\n- 활성 사용자 수 (즉, 텔레미트리 매니저에 의해 마지막 데이터 수집 이후 세션을 활성화한 사용자 수),\n- 엔터프라이즈 에디션 상태 (EE가 활성화되었는지 여부),\n- 활성 커넥터 수.\n\n# 다음 단계\n\n향후 플랫폼 사용 상황을 더 잘 이해하기 위해 다른 데이터가 수집될 수 있습니다:\n\n- 엔터프라이즈 에디션 활성화 원점 (EE 팝업이 열린 페이지) 등, 어떤 기능이 사용자가 EE를 가장 많이 채택하게 하는지 알아내기.\n- 시간 경과에 따른 평균 세션 기간, 시간이 지남에 따른 사용자 플랫폼 사용 변화 평가.\n- 기능 채택률을 평가하기 위한 몇 가지 메트릭, 시간이 지남에 따른 특정 기능 사용량 파악하는 데 도움이 됩니다. 예를 들어 세션당 특정 기능의 API 호출 수를 통해 계산될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\nFiligran을 위한 텔레메트리 데이터 수집은 사용자의 개인 정보와 데이터 기밀성을 고려하며, 플랫폼 이용 방식을 더 잘 이해할 수 있게 해줍니다. 이를 통해 사용자들의 행동에 적합한 솔루션과 기능을 제안하고, 우리 커뮤니티를 위해 OpenCTI 경험과 기능을 가장 잘 개선할 수 있습니다.\n\nSlack 커뮤니티 채널에서 언제든지 관련 질문을 자유롭게 해 주세요! 📢","ogImage":{"url":"/assets/img/2024-05-17-TelemetryinOpenCTI61_0.png"},"coverImage":"/assets/img/2024-05-17-TelemetryinOpenCTI61_0.png","tag":["Tech"],"readingTime":3},{"title":"중간여정의 SREF 랜덤 ID 코드 해석하기","description":"","date":"2024-05-17 04:27","slug":"2024-05-17-CrackingtheCodeofMidjourneysSREFRandomIDs","content":"\n\n## MIDJOURNEY \u0026 SREF 코드 숙달하기\n\nMidjourney의 새로운 스타일 참조 ID를 통해 프로젝트를 혁신하고, 여러 프롬프트에서 일관된 예술 스타일을 보장하세요.\n\n2월에 Midjourney는 새로운 스타일 참조 이미지 기능을 도입했습니다. 여기서 혁신적인 점은 사용자가 적절한 이미지 URL을 사용하여 --sref [URL] 또는 --sref [URL] [URL] [URL]을 프롬프트에 사용할 수 있으며, 이를 통해 프롬프트에 스타일을 적용할 수 있다는 것입니다. 이것은 여러 이미지 프롬프트 전반에 걸쳐 일관된 모습을 유지할 수 있는 방법을 마침내 제공했기 때문에 게임 체인저였습니다. 그래픽 소설이나 어린이 도서를 제작하는 창작자들은 프로젝트 전체에서 동일한 예술 스타일을 원할 수 있습니다. 텍스트 프롬프트로 특정 스타일을 유지하는 것은 때로는 어려울 수 있었지만, 새로운 SREF를 사용하면 쉽게 가능합니다.\n\n하지만 Midjourney는 여기서 멈추지 않았습니다! --sref random이라는 것을 소개했는데, 이를 사용하면 1부터 4294967295 사이의 숫자를 얻을 수 있습니다. 네, 맞았습니다. 40억 가량의 숫자가 가능합니다. 각 ID 번호에는 다른 스타일이 적용되어 있으며 일부는 유사한 영향을 받을 수도 있습니다. --sref random을 사용하거나 범위 내에서 숫자를 선택하고 프롬프트 끝에 --sref ID#를 사용하여 해당 번호를 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n새로 생성된 --sref random으로 만든 새 SREF ID에 대한 기본 이미지를 보는 것은 불가능합니다. 그러나 다른 프롬프트 없이도 해당 ID의 직접적인 영향을 볼 수 있는 방법이 있습니다. 이를 통해 주어진 ID의 내부 영향을 훨씬 명확하게 파악할 수 있습니다.\n\n이를 실행하는 방법은 빈 프롬프트와 스타일 가중치 1000 --sw 1000으로 나타내는 상자 아래에 표시된 대로 하면 됩니다. 스타일 가중치는 1부터 1000 사이의 값을 가질 수 있습니다.\n\n```js\n\"\" --ar 2:3 --sw 1000 --sref random\n```\n\n아무것도 넣지 않고 빈 이중 인용부호만 사용함으로써 Midjourney에 프롬프트를 만들도록 강제하는 것입니다. 스타일 가중치를 1000으로 설정하면 이 비-프롬프트에 스타일의 전체 가중치를 강제로 부여합니다. 반환되는 이미지는 해당 ID가 무엇을 하는지 명확히 보여줍니다. 몇 가지 예를 들어 설명해 드리겠습니다. 동일한 SREF ID로부터 만들어진 네 개의 이미지 쿼드를 실행했습니다. 다양한 변형이 있지만 전부 영향을 받은 것이 매우 유사함을 보여줍니다. 강한 여성적이고 핑크색 및 네온 요소를 가진 이 ID를 선택한 이유는 이를 빠르게 식별하고 영향을 파악할 수 있기 때문입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n\"\" --ar 2:3 --sref 1583246159 --sw 1000\n```\n\n여자와 소녀의 이미지를 만들었어요. 이 스타일에 너무 잘 어울린다고 생각했어요. 소년은 조금 흔해빠진 이미지일지도 모르겠어요 (죄송해요). 하지만 SREF가 없는 보통 이미지에는 이미지에 분필이 많이 들어 있지 않았을 거에요.\n\n```js\na beautiful young woman posing for a portrait --ar 2:3 --sref 1583246159\nA little girl having a tea party with her favourite dolls. --ar 2:3 --sref 1583246159\nA little boy playing war games with his action figures. --ar 2:3 --sref 1583246159\n```\n\n다음 이미지들로 넓은 지역에 갔어요. 사진에 나오는 오두막은 자연 실외 색상이 핑크 톤을 압도했어요. 일반적으로 더 많은 초록색이 아닐까 생각했지만, #1의 연한 핑크징을 힌트로 남겨뒀어요, #2와 #3의 핑크징으로 이루어진 집, 그리고 #4에서 미세하게 핑크 빛을 받아빛나는 민들레까지도요. 물에 비치는 핑크색의 반사와 모래색이 따뜻하고 황금빛을 내는 걸 특히 좋아했어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n빈 프롬프트 이미지를 확인하는 것이 도움이 되는 이유 중 하나는 동일한 ID를 사용하여 만든 이미지에서 불일치가 발견되면, 프롬프트에 충돌하는 요소가 ID의 기저 영향과 일치하지 않을 가능성이 있다는 것을 나타낼 수 있습니다.\n\n```js\n일몰이 진 해변, 따뜻한 황금 모래가 촉촉하게 반짝입니다. 푸른 파도가 천천히 해변으로 밀려옵니다. 갈매기들이 하늘을 가볍게 날아다닙니다. --ar 2:3 --sref 1583246159\n자정에 도심 거리를 희주로 달리는 스포츠 카 --ar 2:3 --sref 1583246159\n숲 속 작은 오두막, 왼쪽에는 상록수로 둘러싸여 있고 오른쪽의 개방된 초원은 민들레로 가득합니다. --ar 2:3 --sref 1583246159\n```\n\n위의 세 개의 쿼드는 기본 스타일 가중치인 100으로 실행됩니다. --sw #이 지정되지 않으면 자동으로 100을 사용합니다. ID가 프롬프트에 미치는 영향을 가볍게 만들기 위해 숫자를 줄일 수 있습니다. 아래에는 스타일 가중치가 200, 500 및 1000인 동일한 프롬프트를 실행한 예시가 있습니다. 이 ID의 분홍색 스타일은 강력하기 때문에 차이를 보기 어렵지만, 200에서 이미 사람들을 포함하지 않는 프롬프트에 여성이 나타나기 시작합니다.\n\n아래 상자에 서로 다른 스타일 가중치를 순열로 설정했습니다. 순열은 하나의 프롬프트로 여러 프롬프트를 실행할 수 있게 하는 꼼수입니다. 중괄호 안에 쉼표로 구분된 목록을 추가함으로써, 미드저니에게 200으로 먼저 프롬프트를 실행하고, 그 다음에는 500으로, 그리고 1000으로 실행하라고 알려주는 것입니다. 이는 무엇이 무엇을 하는지 탐색하는 경우에 유용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n해변, 일몰, 따뜻한 황금빛 모래가 촉촉하게 빛난다. 파란 파도가 천천히 밀려나 올라온다. 갈매기가 하늘을 가르며 날아다닌다. --ar 2:3 --sref 1583246159 --sw {200,500,1000}\n자정에 도시 길을 광장히 달리는 스포츠카 --ar 2:3 --sref 1583246159 --sw {200,500,1000}\n나무로 된 작은 오두막, 왼쪽으로 이어진 상록수와 오른편의 물푸레나무로 가득한 넓은 목초지. --ar 2:3 --sref 1583246159 --sw {200,500,1000}\n```\n\n## 더 알아보기\n\n## 30개의 SREF ID가 당신의 프롬프트를 기다립니다!\n\n## 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n중간 여행의 혁신적인 스타일 참조 이미지 기능과 무작위 ID 생성 기능은 창작자들이 작품에서 일관성을 유지할 수 있는 방식을 변화시켰습니다. 그래픽 소설, 어린이 책 또는 일관된 스타일을 필요로 하는 어떤 창의적 프로젝트를 작업 중이든, 이러한 도구들은 탁월한 제어와 창의성을 제공합니다. 서로 다른 스타일 가중치와 순열을 실험함으로써 여러 예술적 가능성을 개방하고 이미지에서의 영향을 세밀하게 조절할 수 있습니다. 이러한 기능들을 포용하여 매번 일관된, 시각적으로 놀라운 결과물을 달성하고 예술을 높이세요.\n\n여러분의 참여와 피드백은 저에게 귀중합니다. 제가 작성하는 콘텐츠를 안내해주어 그것이 공감되고 풍요로워지도록 합니다. 만약 이 중간 여행 탐험에서 영감을 받았다면 언제든지 생각을 공유하고 그 박수를 클릭해주기를 망설이지 마세요—총 50개까지 가능합니다! 다음 예술적 모험까지, 계속해서 창작하고 영감을 주세요!\n\n![Cracking the Code of Midjourney's SREF Random IDs](/assets/img/2024-05-17-CrackingtheCodeofMidjourneysSREFRandomIDs_0.png)\n\n```js\n\"\" --ar 4:3 --sref 509968410 --sw 1000\n```","ogImage":{"url":"/assets/img/2024-05-17-CrackingtheCodeofMidjourneysSREFRandomIDs_0.png"},"coverImage":"/assets/img/2024-05-17-CrackingtheCodeofMidjourneysSREFRandomIDs_0.png","tag":["Tech"],"readingTime":5},{"title":"암 치료에 대한 대응","description":"","date":"2024-05-17 04:24","slug":"2024-05-17-ResponsetoCancerTreatment","content":"\n\n## 암 치료 반응 지표의 정확한 추출\n\n![이미지](/assets/img/2024-05-17-ResponsetoCancerTreatment_0.png)\n\n저자: Gursev Pirge, Samed Kocer\n\n암 치료에 대한 환자 반응을 정확하게 평가하는 것은 임상 의사 결정에 유용하며 치료 결과를 최적화하는 데 중요합니다. 대형 언어 모델(Large Language Models, LLMs)은 다양한 자연어 처리(Natural Language Processing, NLP) 작업에서 인상적인 성능을 발휘해 왔지만, 의료 언어의 복잡성과 임상 내러티브 해석의 세심한 뉘앙스로 인해 이 도메인에서의 성능이 제한되어 왔습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n임상 보고서에 기록된 복잡한 세부 내용을 정확하게 이해하는 능력은 후속 치료 결정을 인도하고 치료 전략을 조정하며 궁극적으로 환자 결과를 향상시키는 데 중요합니다. John Snow Labs은 비정형 텍스트에서 환자 응답을 추출하고 분류하는 데 뛰어난 정확성으로 알려진 모델을 제공하여 NLP를 암 치료에 적용하는 중요한 발전을 이루었습니다.\n\n본 게시물에서는 John Snow Labs의 Healthcare NLP 라이브러리의 사전 훈련된 모델을 사용하여 환자의 암 치료에 대한 응답을 평가하는 내용을 다룹니다. 환자의 암 치료 경과/변화를 이해하는 데 중요한 텍스트 데이터의 키워드나 구절 NER을 식별하고, 더불어 텍스트 분류 모델을 사용하여 적용된 치료에 대한 응답을 평가할 것입니다.\n\n우선 짧은 Spark NLP 소개부터 시작한 다음, 암 치료에 대한 응답의 세부 내용과 실질적인 결과에 대해 논의해보겠습니다.\n\n## Spark NLP 및 LLM\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n헬스케어 라이브러리는 존 스노 랩의 Spark NLP 플랫폼의 강력한 구성 요소로, 의료 분야 내에서 NLP 작업을 용이하게 하는 데 설계되었습니다. 이 라이브러리는 의료 데이터에 맞춘 2,200개 이상의 사전 훈련된 모델과 파이프라인을 제공하여 정확한 정보 추출, 임상 및 의료 개념을 위한 NER, 텍스트 분석 기능을 제공합니다. 정기적으로 업데이트되며 최첨단 알고리즘으로 구축된 헬스케어 라이브러리는 정보 처리를 최적화하고 전자 의료 기록, 임상 노트, 생물 의학 문헌과 같은 비정형 의료 데이터 소스로부터 의료 전문가들에게 더 깊은 통찰력을 제공하기 위해 노력하고 있습니다.\n\n존 스노 랩의 GitHub 저장소는 사용자가 오픈 소스 리소스에 액세스할 수 있는 협업 플랫폼으로, 코드 샘플, 튜토리얼 및 프로젝트 등을 포함합니다. 이를 통해 사용자들은 Spark NLP 및 관련 도구의 이해와 활용을 더욱 향상시킬 수 있습니다.\n\n존 스노 랩은 또한 헬스케어 라이브러리 및 NLP 플랫폼의 다른 구성 요소를 이용하는 데 전문 지식을 습득하는 데 도움이 되는 주기적인 인증 교육을 제공합니다.\n\n존 스노 랩의 데모 페이지는 라이브러리의 기능을 탐색하기 위한 사용자 친화적 인터페이스를 제공하여 사용자가 상호 작용적으로 테스트하고 다양한 기능과 모델을 시각화할 수 있도록 하며, 이러한 도구가 의료 및 다른 분야에서 실제 시나리오에 적용될 수 있는 방법에 대한 더 깊은 이해를 돕습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nJohn Snow Labs의 Healthcare Library가 핵심 역할을 할 수 있는 중요한 응용 분야 중 하나는 환자가 암 치료에 대한 반응을 평가하는 것입니다. 개인이 치료에 어떻게 반응하는지 정확하게 평가하는 것은 임상 의사 결정을 안내하고 치료 결과를 최적화하는 데 중요합니다. 그러나 의료 언어의 복잡성과 그러한 텍스트를 해석하는 데 관련된 세세한 점들 때문에 비구조적 임상 문서에서 이 정보를 추출하는 것은 어려울 수 있습니다.\n\nNLP를 사용하여 환자의 암 치료에 대한 반응을 평가하는 데 여러 접근 방법이 있습니다. 첫 번째 접근 방식은 NER 모델을 사용하여 비구조적 임상 텍스트에서 관련 있는 종양학적 개념 및 엔티티를 추출하는 것입니다. 이를 통해 시스템은 환자의 상태, 치료 방법 및 결과에 관련된 주요 정보를 정확하게 파악할 수 있습니다.\n\n두 번째 접근 방식은 텍스트 분류 모델을 사용하여 임상 내러티브의 전반적인 내용과 문맥을 분석하는 것입니다. 이러한 모델을 레이블이 지정된 데이터셋으로 훈련시킴으로써, 이 모델은 환자의 진행 상황, 증상 및 기타 관련 요소를 묘사하는 데 사용된 언어를 기반으로 처방된 암 치료의 효과성과 효율성을 평가할 수 있습니다.\n\n이 블로그 포스트에서 우리는 John Snow Labs의 NER 및 텍스트 분류 모델이 이 중요한 문제를 해결하기 위해 정확한 솔루션으로서의 잠재력을 탐구할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 임상 노트에서 종양학 관련 엔티티 추출\n\n이 파트에서는 John Snow Labs Healthcare NLP 라이브러리가 임상 노트에서 종양학 관련 엔티티(NERs)를 추출하는 방법에 대해 살펴볼 것입니다.\n\n200개 이상의 종양학 모델의 힘을 활용하여 의료 전문가들은 복잡한 임상 내러티브에서 암 진단, 치료 및 환자 결과에 관련된 중요한 정보를 효율적으로 식별하고 추출할 수 있습니다.\n\nSpark NLP는 파이프라인을 사용하여 가치 있는 정보를 추출하며, 이를 위해 6단계만 필요합니다. 나는 ner_oncology 모델을 활용하여 종양과 관련된 엔티티를 추출했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# 단계 1: 원시 텍스트를 `document`로 변환합니다.\ndocument = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\n# 단계 2: 문장 감지/분할\nsentencer = SentenceDetectorDLModel.pretrained(\"sentence_detector_dl_healthcare\",\"en\",\"clinical/models\")\\\n    .setInputCols([\"document\"])\\\n    .setOutputCol(\"sentence\")\n\n# 단계 3: 토큰화\ntokenizer = Tokenizer()\\\n    .setInputCols([\"sentence\"])\\\n    .setOutputCol(\"token\")\\\n    .setSplitChars([\"-\", \"\\/\"])\n\n# 단계 4: 임상 임베딩\nembeddings = WordEmbeddingsModel.pretrained(\"embeddings_clinical\",\"en\",\"clinical/models\")\\\n    .setInputCols([\"sentence\",\"token\"])\\\n    .setOutputCol(\"embeddings\")\n\n# 종양학 모델\nmodel = MedicalNerModel.pretrained(\"ner_oncology\",\"en\",\"clinical/models\")\\\n    .setInputCols([\"sentence\",\"token\",\"embeddings\"])\\\n    .setOutputCol(\"ner_oncology\")\\\n\nconverter = NerConverterInternal()\\\n    .setInputCols([\"sentence\",\"token\",\"ner_oncology\"])\\\n    .setOutputCol(\"ner_oncology_chunk\")\n\n# 파이프라인 정의\npipeline = Pipeline(stages=[document, tokenizer, embeddings, model, converter])\n\n# 빈 데이터프레임 생성\nempty_df = spark.createDataFrame([['']]).toDF(\"text\")\n\n# 데이터프레임을 파이프라인에 맞추어 모델을 가져옵니다.\npipelineModel = pipeline.fit(empty_df)\n```\n\n모델의 효과적인 분석을 위해 이 임상 텍스트 샘플을 활용해 보겠습니다.\n\n```js\nsample_text = \"\"\"65세 여성이 복부 및 골반의 컴퓨터 단층 촬영(CT)을 받았고, 복난소에 복잡한 난소 종양이 보였습니다. 한 달 후에 실시된 Pap 스며는 비정상적인 선세포를 보여 주며 점액선암을 의심케 합니다. 병리 검사에 따르면 종양은 난관, 충수, 위막 및 5개의 비정상적으로 커진 림프절 전방에 걸쳐 있었습니다. 종양의 최종 병리학적 진단은 ⅡIC 형태의 유두낭 형성 난소 선암이었습니다. 그리고 2개월 후 환자는 폐 전이 병변이 발견되었습니다.\n\"\"\"\n```\n\n여기서 LightPipeline을 사용하여 엔티티를 추출해 보겠습니다. LightPipeline은 Spark NLP 특정 파이프라인 클래스로, Spark ML 파이프라인과 동등한 기능을 제공합니다. 다만, Spark 원칙을 준수하지 않고 모든 계산을 로컬(그러나 병렬)로 수행하여 데이터 양이 적을 때 빠른 결과를 얻을 수 있습니다.```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nlight_model = LightPipeline(pipelineModel)\n\nlight_result_onc = light_model.fullAnnotate(sample_text)\n\n\nchunks = []\nentities = []\nsentence= []\nbegin = []\nend = []\nconfidence = []\n\nfor n in light_result_onc[0]['ner_oncology_chunk']:\n\n    begin.append(n.begin)\n    end.append(n.end)\n    chunks.append(n.result)\n    entities.append(n.metadata['entity'])\n    sentence.append(n.metadata['sentence'])\n    confidence.append(n.metadata[\"confidence\"])\n\ndf_oncology = pd.DataFrame({'chunks':chunks, 'begin': begin, 'end':end,\n                   'sentence_id':sentence, 'entities':entities, 'confidence':confidence})\n\ndf_oncology.head()\n```\n\nner_oncology 모델을 적용한 후, 샘플 임상 노트에서 다음과 같은 관련 의학적 개념이 자동으로 식별되고 추출되었습니다:\n\n![의학 개념](/assets/img/2024-05-17-ResponsetoCancerTreatment_1.png)\n\nSpark NLP를 사용하여 생성된 엔티티를 빠르게 시각화할 수 있는 기능은 개발 프로세스를 가속화하고 얻은 결과를 이해하는 데 매우 유용합니다. Spark NLP Display는 Spark NLP에서 생성된 추출된 및 레이블이 지정된 엔티티를 시각화하기 위한 오픈 소스 파이썬 라이브러리입니다. NerVisualizer 어노테이터는 추출된 명명된 엔티티를 강조하고 분석된 텍스트 위에 레이블을 표시하여 보여줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nfrom sparknlp_display import NerVisualizer\n\nvisualiser = NerVisualizer()\n\nvisualiser.display(light_result_onc[0], label_col='ner_oncology_chunk', document_col='document')\n```\n\n이러한 엔티티를 강조함으로써 환자의 상태, 치료 계획 및 전반적인 예후에 대한 깊은 통찰력을 얻게 되어 의료 전문가들이 맞춤형 치료를 안내하고 종양학 실무에서 치료 결과를 최적화할 수 있는 가치 있는 정보를 얻을 수 있습니다.\n\n## 임상 보고서로부터 암 치료에 대한 환자 반응 평가하기\n\nNER 모델은 임상 노트에서 종양학적 개념을 추출할 수 있지만, 치료 반응을 이해하려면 주로 내러티브의 전체 맥락을 분석해야 합니다. 텍스트 분류 모델은 환자 파일의 전반적인 내용이 긍정적인 반응을 나타내는지, 또는 질병 진행을 시사하는지를 판단할 수 있습니다. 임상 전문가가 치료 결과에 따라 파일을 레이블링한 주석이 달린 데이터셋으로 모델을 훈련하면, 이러한 모델은 상태, 증상, 영상 소견 및 기타 중요한 요소를 기술하는 언어에서 예측적인 패턴을 학습합니다. 새로운 미레이블 파일에 적용하면, 모델은 높은 정확도로 분류할 수 있습니다. 이 자동 분류는 추가 검토를 위해 사례를 필터링하고 연구를 위한 코호트 식별을 간소화하는 데 도움이 될 수 있습니다. 그러나 높은 정확도를 달성하려면 고품질의 훈련 데이터와 이 도메인에서의 실제 언어 뉘앙스를 주의 깊게 다루어야 합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 중요한 임무에 대한 텍스트 분류 모델의 성능을 평가하기 위해 John Snow Labs의 데이터 과학자들은 5,000개 이상의 환자 파일로 구성된 정제된 데이터셋에서 여러 모델을 훈련하고 테스트했습니다. 각 파일은 의료 전문의들에 의해 수동으로 레이블이 지정되었으며 치료 반응에 따라 '환자가 치료에 응답함' 또는 '환자가 치료에 반응하지 않음' 중 하나로 분류되었습니다. 가장 우수한 성능을 보인 모델은 이 특수 데이터셋으로 미세 조정된 BERT 기반 아키텍처였습니다.\n\n아래에 표시된 임상 텍스트 조각들에 대한 정확한 레이블 할당을 얻기 위해 종양 치료 반응 분류기를 사용해봅시다:\n\n```python\nsample_texts = [\n    [\"뇌의 콘트라스트 증강 MRI는 테모졸로마이드 요법 이후 안정된 질병을 시사하여 글리오블라스토마 크기의 변화가 없음을 보여줌.\"],\n    [\"신생 대상화 요법 이후의 유방 초음파는 3cm에서 1cm로 원발 병변 크기 감소를 보여줌으로써 치료에 대한 유리한 반응을 시사합니다. 피부 감염 역시 다중 항생제 치료로 잘 통제됨.\"],\n    [\"골반의 MRI는 복강경 총 제거 및 6개월 호르몬 억제 요법 후, 자궁내막증의 추가 진전이 없음을 나타냄.\"],\n    [\"재방문 내시경 검사는 치료되고 있는 위궤양 및  H. pylori 감염의 신증상을 보여줍니다. PPI 계속 논의할 예정입니다.\"],\n    [\"간의 다이내믹 콘트라스트 증강 MRI는 소라페닙을 이용한 6개월간의 전향요법 이후 간 전이의 크기와 개수에 상당한 감소가 없음을 나타냈습니다.\"],\n    [\"뇌혈관의 디지털 적출 혈관 조영술은 뇌동맥류 코일 재관류 후, 뇌동맥류의 진전 확장과 새로운 혈관 이상을 나타내어 시도가 실패한 것으로 나타냅니다.\"],\n    [\"환자의 반복 폐기능 검사는 FEV1과 FVC 모두에 심각한 향상이 없음을 나타냄으로써 최대한 최적화된 흡입요법으로도 천식 증상을 효과적으로 통제하는 데 실패했음을 시사합니다. 계속해서 논의할 것입니다.\"]\n]\n```\n\n이 모델의 치료에 대한 반응을 예측하는 정확성은 제공된 벤치마킹 결과에서 명확하게 확인됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n\u003cimg src=\"/assets/img/2024-05-17-ResponsetoCancerTreatment_2.png\" /\u003e\n\nSpark NLP 어노테이터 MedicalBertForSequenceClassification을 사용한 텍스트 분류를 위한 파이프라인이 더욱 짧아졌어요:\n\n```js\n# 단계 1: 원시 텍스트를 `document`로 변환\ndocument_assembler = DocumentAssembler()\\\n    .setInputCol(\"text\")\\\n    .setOutputCol(\"document\")\n\n# 단계 2: 토큰화\ntokenizer = Tokenizer()\\\n    .setInputCols([\"document\"])\\\n    .setOutputCol(\"token\")\n\n# 단계 3: 텍스트 분류\nsequenceClassifier = MedicalBertForSequenceClassification.pretrained(\"bert_sequence_classifier_response_to_treatment\", \"en\", \"clinical/models\")\\\n    .setInputCols([\"document\",\"token\"])\\\n    .setOutputCol(\"prediction\")\n\npipeline = Pipeline(\n        stages=[\n            document_assembler,\n            tokenizer,\n            sequenceClassifier\n])\n\n# 샘플 텍스트에서 Spark 데이터프레임 생성\nsample_data = spark.createDataFrame(sample_texts).toDF(\"text\")\n\n# 데이터프레임을 파이프라인에 맞추고 예측값 가져오기\nresult = pipeline.fit(sample_data).transform(sample_data)\n\nresult.select(\"text\", \"prediction.result\", 'prediction.metadata').show(truncate = 100)\n```\n\n텍스트 분류 모델을 적용한 후, 샘플 임상 텍스트는 치료에 대한 응답 또는 응답이 없음을 나타내는 신뢰도 값과 함께 분류되었습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모델은 임상 노트를 기반으로 반응 및 비반응 사례를 구별하는 뛰어난 능력을 보였습니다. 이러한 결과는 더 포괄적인 인간 리뷰 전 단계로서 맞춤형 텍스트 분류 모델을 사용할 수 있는 가능성을 보여줍니다. 정확도가 93% 이상이어서, 모델은 교종류팀이 우선적으로 평가할 고위험 비반응 사례를 자동으로 도출할 수 있었습니다. 더 많은 레이블이 적용 가능한 경우 계속해서 반복적인 훈련을 거침으로써 성능을 더욱 향상시킬 수 있을 것입니다.\n\n## 결론\n\n암 치료와 같이 중요한 분야에서, 치료에 대한 응답을 정확하게 평가할 수 있는 것이 치료 전략과 결과에 영향을 줄 수 있는데, John Snow Labs NER 및 텍스트 분류 모델은 복잡한 임상 보고서에서 정보 추출 및 환자 응답을 분류하는 데 높은 정확도를 달성했습니다.\n\nLLMs를 사용하여 환자의 암 치료에 대한 응답을 평가하는 것은 정확도를 향상시키고 맥락을 이해하는 데 도움이 될 수 있습니다. 일반적으로, 더 많은 매개변수를 가진 큰 모델은 많은 NLP 과제에서 더 나은 성능을 이룰 수 있지만 계산 비용이 더 많이 드는 경향이 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n결론적으로, 이 두 가지 접근 방식은 암 치료에 대한 환자의 반응을 평가하는 데 유용한 통찰력을 제공합니다. NER 및 텍스트 분류 모델을 활용하면 임상 텍스트를 분석하는 효율적이고 정확한 방법을 제공하며 치료 결과에 대한 통찰력을 제공합니다. 한편, 수십억 개의 매개변수로 이루어진 LLM을 활용하면 맥락과 의미에 대한 보다 깊은 이해력으로 인해 향상된 정확도가 약속됩니다. 그러나 이에는 계산 자원 및 인프라 요구 사항을 포함한 비용 증가가 따릅니다. 궁극적으로, 이러한 접근 방식들 사이의 선택은 헬스케어 환경의 구체적인 요구 사항에 의존하며 정확도와 비용 효율성 사이의 절충을 균형있게 고려해야 합니다.","ogImage":{"url":"/assets/img/2024-05-17-ResponsetoCancerTreatment_0.png"},"coverImage":"/assets/img/2024-05-17-ResponsetoCancerTreatment_0.png","tag":["Tech"],"readingTime":10},{"title":"오픈 소스 모델, 온도 조정, 재순위 매기기 등 최신 LLM 반드시 읽어야 할 글들을 놓치지 마세요","description":"","date":"2024-05-17 04:22","slug":"2024-05-17-Open-SourceModelsTemperatureScalingRe-RankingandMoreDontMissOurRecentLLMMust-Reads","content":"\n\n새로운 LLM들이 거의 매일 등장하고, 그들이 가능케 하는 도구와 워크플로우도 더 빨리 확산됩니다. 우리는 이 영원히 변화하는 지형에서 최근 대화들을 되짚는 좋은 순간이라고 생각했고, 그것을 하는 더 나은 방법을 생각해내지 못했습니다. 과거 몇 주간의 강력한 기사 중 몇 가지를 강조함으로써 그것을 할 수 있다고 판단했습니다.\n\n우리가 모아둔 글의 라인업은 고수준의 질문과 미시적인 문제들을 다루고 있습니다. 그래서 AI 윤리에 관심이 있다든지, 오픈 소스 기술의 발전에 흥미가 있다든지, 혁신적인 RAG 접근법이 궁금하다든지 하더라도, 여기에서 여러분의 관심을 끄는 것이 있을 거라고 확신합니다. 함께 살펴보죠.\n\n- 변화하는 흐름: 오픈 소스 LLM이 닫힌 소스 LLM에 비해 경쟁 우위에 있는 이유\n생산적인 AI 도구의 초기 물결은 OpenAI가 출시한 프로프레타리 모델들에 의해 주도되었습니다. \n레오니 몬티아티(LTM’s)의 새로운 기사는 떠오르는 트렌드에 초점을 맞추고 있습니다: 데이터 보안, 맞춤화, 비용 등의 요소로 주목받는 작은 오픈 소스 재단 모델들이 등장하면서 점차 더 많은 시장을 지배하고 있다는 점.\n- 챗봇의 윤리?\nLLM들이 사실 정보를 요청했을 때 환각을 유발할 수 있다는 것은 알고 있습니다. 사용자들이 윤리에 초점을 맞춘 조언을 요청하기 시작했을 때 어떻게 될까요?\n에얼 아하로니와 에디 나미아스는 이 tricky한 질문과 \"특정한, 통제된 상황에서 인간의 윤리적 대화를 모방하거나 합성할 수 있는\" 챗봇들의 도덕성 지각에 내재된 위험에 대한 최신 연구를 제시합니다.\n- LLM의 추천이 제품 가시성 향상을 위해 조작될 수 있을까요?\n전자상거래는 이미 조작과 의문 스러운 비즈니스 관행에 민감한 분야입니다.\n파룰 판데이는 최근 논문 분석에서 보듯이, 텍스트와 다른 미디어를 빠르게 대량으로 생산할 수 있는 LLM은 이미이 생태계에서 여러 갭과 맹점을 악용할 수 있도록 준비되어 있습니다.\n\n![Open-SourceModelsTemperatureScalingRe-RankingandMoreDontMissOurRecentLLMMust-Reads_0](/assets/img/2024-05-17-Open-SourceModelsTemperatureScalingRe-RankingandMoreDontMissOurRecentLLMMust-Reads_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- LLM에서 온도 스케일링 및 빔 서치 텍스트 생성, ML-인접\n포괄적이고 예시 가득한 가이드에서,\n마이크 체트가\n생성적 AI 워크플로우 문맥에서 온도 개념을 해체합니다: 이는 모델의 출력 순서의 예측 가능성을 수정하는 매개변수이며, 그 세세한 점을 숙달함으로써 실무자들이 AI 도구를 보다 효과적으로 활용할 수 있습니다.\n- 더 나은 LLM RAG 검색을 위한 Re-Ranking 사용 방법\n검색 확장 생성에 대한 초기 흥분 이후, 많은 실무자들에게 RAG 시스템이 더 고급 정제 방법에서 효과를 볼 수 있는 것으로 명확해졌습니다.\nLeon Eversberg 박사\n의 최근 자습서에서, 우리를 더 나은 결과를 위해 (오픈 소스 바이-인코더와 크로스-인코더를 사용하는) 두 단계 검색을 활용하는 워크플로우를 안내합니다.\n\n우리의 저자들은 항상 그랬던 것처럼, 최근 몇 주간 다양한 주제로 뻗어나가며 우수한 기사들을 제공했고, 여기 대표적인 샘플이 있습니다:\n\n- 고객 평생 가치 시리즈를 여기저기에 끝낸 후,\n캐서린 군이\n가용한 예측 방법의 상세 개요와 각각에 대한 마케터와 데이터 과학자들이 기대할 수 있는 것을 제공합니다.\n- 모든\n사친 데이트가\n몰입 분석은 축하할 가치가 있으며, 최신 버전도 이외의 것이 아닙니다. 19세기 난파 사건을 통해 설득력 있는 통계 수렴의 철저한 탐구입니다.\n- 최신 초보자 친화적 가이드에서,\nSrijanie Dey 박사\n는 Llama 3로 이동하고, 그 변환기 구조의 세세한 점을 해체합니다.\n- 분자 생물학, 생물 정보학 및 AI의 교차로에서 글쓰는,\n무르토 힐라리가\n단백질 상호 작용의 변이에 대한 효과를 예측하는 다중 분류 모델을 구축하는 방법을 보여줍니다.\n- 물리학 (및 관련 분야)에서 데이터 과학으로의 직업 전환을 고려 중이라면,\n사라 노브레가\n스스로의 여정과 그동안 모은 경험을 바탕으로 한 실용적인 가이드를 놓치지 마십시오.\n- 딥 러닝을 시작하는 사람들에게는,\n쉬레야 라오가\n컨볼루션 신경망에 대한 새로운 초보자 친화적이고 전문적으로 그림으로 설명된 입문서를 가져왔습니다.\n- 콜모고로프-아놀드 네트워크 (KANs)를 공개한 논문은 겨우 2주 된 것이지만 이미 분야에서 큰 파장을 일으키고 있습니다.\n테오 울프가\nKANs가 어떻게 작동하며 그에 대한 소문이 무엇인지 이해하는 데 도움이 되는 TDS 초간단 기사를 첫 번째로 소개했습니다.\n\n우리의 저자들을 지원해 주셔서 감사합니다! 우리는 새로운 저자들로부터의 기사를 출판하는 것을 사랑하므로, 최근에 재미있는 프로젝트 설명서, 자습서 또는 핵심 주제 중 하나에 대한 이론적 반성을 작성한 경우 우리와 공유하시기 바랍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 변수까지,\n\nTDS 팀","ogImage":{"url":"/assets/img/2024-05-17-Open-SourceModelsTemperatureScalingRe-RankingandMoreDontMissOurRecentLLMMust-Reads_0.png"},"coverImage":"/assets/img/2024-05-17-Open-SourceModelsTemperatureScalingRe-RankingandMoreDontMissOurRecentLLMMust-Reads_0.png","tag":["Tech"],"readingTime":3},{"title":"AWS 기반 클라우드 기반 생성 AI","description":"","date":"2024-05-17 04:21","slug":"2024-05-17-AWSBedrockCloud-basedGenerativeAI","content":"\n\n\n![AWS Bedrock](/assets/img/2024-05-17-AWSBedrockCloud-basedGenerativeAI_0.png)\n\nAmazon Bedrock은 클라우드에서 대형 언어 모델을 활용하는 견고한 솔루션입니다! 경험 많은 개발자, 데이터 과학자 또는 Generative AI의 시작부터 Amazon Bedrock은 끝까지 Generative AI 애플리케이션을 테스트하고 구현하는 이상적인 장소가 될 수 있습니다.\n이 튜토리얼을 통해 AWS Bedrock 설정 및 시작하는 프로세스를 간단하게 만드는 데 목표를 두었습니다. 이 튜토리얼에서는 Meta의 Llama-3-70B-Instruct 모델을 가져와 사용할 것입니다. 튜토리얼을 따라가기 전에 다음 사전 요구 사항을 충족해야 합니다:\n1. AWS 계정\n2. Visual Studio Code 또는 IDE\n3. Amazon Web Services의 기본 지식\n\n- IAM에서 새 사용자를 생성하고 \"AmazonBedrockFullAccess\" 정책을 연결합니다. 나중에 사용할 자격 증명이 AWS Bedrock 서비스에 액세스할 수 있도록 합니다. 자격 증명을 다운로드하고 안전하게 보관해야 합니다. 나중에 사용해야 합니다.\n\n2. AWS 콘솔에서 AWS Bedrock을 검색하고 지역을 신중하게 선택합니다. 현재 일부 대형 언어 모델은 특정 지역에서만 사용할 수 있습니다. 이 튜토리얼에서는 \"us-west-2\"를 선택하고 Meta의 \"Llama-3-70B-Instruct\" 모델에 액세스할 것입니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 선택한 IDE(제 경우 VS Code)로 이동하여 CLI에서 IAM 자격 증명을 구성하세요. 이미 구성해 두었지만, 자격 증명을 요청받을 때 신중히 입력해주세요.\n\n2. 자격 증명을 설정한 후, Boto3를 사용하여 AWS Bedrock 서비스에서 모델을 호출하는 기본 코드를 작성하세요. 아래는 이 튜토리얼용 코드 스니펫이며, 필요에 따라 수정할 수 있습니다. 사용 사례에 맞게 모델 매개변수를 조정할 수도 있습니다.\n\n```js\nimport boto3\nimport json\n\nprompt_template=\"\"\"\nGenerative AI 엔지니어로 활동하여 Generative AI에 관한 멋진 사실 10가지를 말해주세요.\n\"\"\"\n\nbedrock=boto3.client(service_name=\"bedrock-runtime\", region_name=\"us-west-2\")\n\npayload={\n    \"prompt\":\"[INST]\" + prompt_template +\"[/INST]\",\n    \"max_gen_len\":2048,\n    \"temperature\":0.5,\n    \"top_p\":0.9\n}\n\nbody=json.dumps(payload)\nmodel_id = \"meta.llama3-70b-instruct-v1:0\"\nresponse = bedrock.invoke_model(\n    body=body,\n    modelId=model_id,\n    accept= \"application/json\",\n    contentType=\"application/json\"\n)\n\nresponse_body = json.loads(response.get(\"body\").read())\nresponse_text=response_body['generation']\nprint(response_text)\n```\n\n3. 코드를 실행하고 결과를 테스트하세요!\n예시 프롬프트: \"리오넬 메시가 시대 최고의 선수인 이유를 5가지 말해주세요. 답변을 100~150 단어로 요약해주세요.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![AWSBedrockCloud-basedGenerativeAI](/assets/img/2024-05-17-AWSBedrockCloud-basedGenerativeAI_1.png)\n\n클라우드 기반 생성적 AI를 시작하는 기본적인 튜토리얼입니다. 사용 사례는 무한합니다. 저도 복잡한 사용 사례와 그 가능한 해결책을 탐구하고 싶습니다. 궁금한 점이나 질문이 있으면 언제든 댓글에 남겨주세요!\n\n읽어 주셔서 감사합니다. 궁금한 점이 있거나 단순히 즐겁게 이야기 나누고 싶다면 망설임 없이 Linkedin에서 저에게 연락해주세요.","ogImage":{"url":"/assets/img/2024-05-17-AWSBedrockCloud-basedGenerativeAI_0.png"},"coverImage":"/assets/img/2024-05-17-AWSBedrockCloud-basedGenerativeAI_0.png","tag":["Tech"],"readingTime":3},{"title":"여러분의 RAG 어플리케이션 개선을 위한 5가지 해킹 팁","description":"","date":"2024-05-17 04:20","slug":"2024-05-17-5HacksToImproveYourRAGApplication","content":"\n\nRAG는 기업 및 비즈니스에서 Gen AI 기능을 사용자 지정 데이터와 통합하는 데 중요한 도구가 되었습니다.\n\n![image](/assets/img/2024-05-17-5HacksToImproveYourRAGApplication_0.png)\n\n다음은 RAG 애플리케이션을 개선하는 몇 가지 팁입니다.\n\n- 쿼리 보강\n- 문서 청킹\n- 결과 재랭킹\n- 임베딩 어댑터\n- 가상 문서 임베딩\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n쿼리 확장:\n\n관련 데이터를 검색하고 정확한 응답을 얻기 위해 프롬프트와 함께 보강하는 것이 중요합니다.\n\n단계:\n\n- 코사인 유사도나 유클리드 거리를 사용하여 벡터 임베딩 데이터베이스를 사용하여 사용자 쿼리를 기반으로 문서를 검색합니다.\n- 검색된 데이터/문서와 프롬프트를 결합합니다.\n- LLM(언어 모델)을 사용하여 하이브리드 데이터로부터 데이터를 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nimport chromadb\nimport openai\n\ndef augmented_query_creator(user_query, retrieved_documents):\n    information = \"\\n\\n\".join(retrieved_documents)\n    prompt = (f'You are a movie critic.\\n'\n    f'Your users are asking questions about movie review.\\n'\n    f'You will be shown the user\\'s question, and the relevant information from the movie.\\n'\n    f'Answer the user\\'s question using only this information.\\n\\n'\n    f'Question: {query}. \\n Information: {information}')\n    return prompt\n\ndef generate_answer(prompt):\n    openai.api_key = \"YOUR_OPENAI_API_KEY\"  \n    response = openai.Completion.create(\n        engine=\"text-davinci-003\",  \n        prompt=prompt,\n        max_tokens=1024, \n        n=1,\n        stop=None,\n        temperature=0.7\n    )\n    return response.choices[0].text.strip()\n\nif __name__ == \"__main__\":\n    query = \"What is the review of the movie?\"\n    \n    # 1 Retrive relevant documents\n    results = chroma_collection.query(query_texts=[query], n_results=5)\n    retrieved_documents = results['documents'][0]\n    \n    # 2 Augmented query generation\n    augmented_query = augmented_query_creator(query,retrieved_documents)\n\n    # 3 Response for augmented query\n    result = generate_answer(augmented_query)\r\n```\n\n문서 청크 데이터 중복 :\n\n다양한 문서에 대한 벡터 데이터베이스를 구축할 때, 토큰 제한으로 인해 데이터 손실이 발생할 수 있습니다. 이 문제를 해결하기 위해 데이터를 작은 세그먼트로 분할하는 것이 해결책입니다.\n\n하지만 이러한 청크를 사용하더라도 한 문서와 다른 문서 사이의 의미와 연속성 손실이 발생할 수 있습니다. 이 문제를 완화하기 위해 데이터의 일관성과 흐름을 유지하기 위해 청크 사이에 중첩을 도입하는 것이 중요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nfrom langchain.vectorstores import Chroma\nfrom langchain.embeddings import OpenAIEmbeddings  # 귀하의 선택한 임베딩 모델로 대체하십시오\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.document_loaders import TextLoader\n\n# 문서 경로와 임베딩 모델 정의 (귀하의 것으로 대체하십시오)\ndocument_path = \"your_document.txt\"\nembedding_model = OpenAIEmbeddings\n\n# 청크 크기 및 선택적인 오버랩 설정\nchunk_size = 500\nchunk_overlap = 100\n\n# 문서를 로드하고 RecursiveCharacterTextSplitter로 분할합니다.\ntext_loader = TextLoader(document_path)\ndocuments = text_loader.load()\nsplitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\ntexts = splitter.split_documents(documents)\n\n# 임베딩을 사용하여 ChromaDB 생성\npersist_directory = \"chroma_db\"\nchroma_collection = Chroma.from_documents(\n    documents=texts, embedding=embedding_model(), persist_directory=persist_directory\n)\n```\n\n재랭킹\n\n결과를 재랭킹하는 것은 검색된 문서를 검색기에 의해 검색된 후 특정 기준에 따라 다시 정렬하는 것을 의미합니다. 응답을 생성하기 전에 검색된 문서의 관련성을 더욱 정제하는 데 유용할 수 있습니다.\n\n우리는 문서의 관련성 순서를 변경하기 위해 코사인 유사성 대신 크로스 인코더 모델을 사용합니다.```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nStep 1: 크로스-인코더 모델을 로드합니다.\n\nStep 2: 관련성 점수를 변경하는 재랭크 함수입니다.\n\nStep 3: 문서를 정렬하고 반환합니다.\n\n```python\nfrom sentence_transformers import SentenceTransformer\n\n# ChromaDB와 크로스-인코더 모델을 로드합니다.\nchromadb = Chroma.load(\"chroma_db\")  \ncross_encoder = SentenceTransformer(\"all-mpnet-base-v2\")  \n\ndef re_rank_results(query, retrieved_chunks, k=3):\n  \n  scored_chunks = []\n  for chunk in retrieved_chunks:\n    score = cross_encoder.compute_similarity([query], [chunk])[0][0]\n    scored_chunks.append({\"chunk\": chunk, \"score\": score})\n\n  # 점수를 기준으로 (내림차순으로) 정렬하고 상위 k개 결과를 반환합니다.\n  sorted_chunks = sorted(scored_chunks, key=lambda x: x[\"score\"], reverse=True)\n  return sorted_chunks[:k]\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n임베딩 어댑터:\n\n임베딩 어댑터는 초기 임베딩 프로세스와 검색 단계 간의 세세한 조정 단계로 작용하는 소규모 신경망 모듈입니다. 그 목적은 쿼리의 임베딩과 지식베이스에 저장된 문서 표현의 정렬을 개선하는 것입니다.\n\n단계 1: 임베딩 생성\n\n단계 2: 임베딩 어댑터로 섬세하게 조정하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n3단계: 개선된 검색\n\n```js\nfrom langchain.vectorstores import Chroma\nfrom langchain.text_embeddings import SentenceTransformerEmbeddings\nfrom langchain.text_encoders import IdentityEncoder  # 원본 텍스트 보존\nfrom langchain.document_loaders import TextLoader\n\n# 문서 경로 및 임베딩 모델 정의\ndocument_path = \"your_document.txt\"\nembedding_model = SentenceTransformerEmbeddings(\"all-mpnet-base-v2\")\n\n# 문서 로드\ntext_loader = TextLoader(document_path)\ndocuments = text_loader.load()\n\n# 텍스트 인코더를 사용하여 ChromaDB 생성 (선택 사항)\npersist_directory = \"chroma_db\"  \ntext_encoder = IdentityEncoder()  \n\nvectordb = Chroma.from_documents(\n    documents=documents,\n    embedding=embedding_model(),\n    text_encoder=text_encoder,\n    persist_directory=persist_directory\n)\n\n# 선택적 지속성\nvectordb.persist()\n\n# 텍스트 검색 예시\nquery = \"북극 해는 어디에 있나요?\"\n\n# 인코딩된 텍스트를 기반으로 검색 (임베딩 아님)\nresults = vectordb.search(query, k=5)  # 상위 5개 결과 가져오기\n\n# 검색된 문서 출력\nfor doc in results:\n    print(doc)\n\nprint(\"ChromaDB 검색 완료!\")\n```\n\n가상 문서 임베딩:\n\nHyDE는 대형 언어 모델(Large Language Models, LLMs)을 활용하여 문서로부터 정보 검색을 개선하는 기술입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nStep 1: Query 이해하기: 모든 것은 사용자 쿼리로 시작됩니다. HyDE는 이 쿼리를 입력으로 받습니다.\n\nStep 2: 가상 문서 생성: HyDE는 GPT-3과 같은 LLM을 사용하여 사용자 쿼리에 완벽한 답변이 될 것으로 믿는 가상 문서를 생성합니다. 이 문서에는 사실적인 정보 뿐만 아니라 창의적인 요소나 사용자 의도에 부합하는 설명이 포함될 수 있습니다.\n\nStep 3: 가설 인코딩: 가상 문서가 생성된 후, HyDE는 문서 자체를 사용하지 않습니다. 대신, 문서의 의미를 수학적 벡터 표현으로 인코딩합니다. 이 벡터는 가상 답변 내의 핵심 개념과 정보를 포착합니다.\n\nStep 4: 유사 문서 찾기: 이제 검색 과정이 시작됩니다. HyDE는 가상 문서를 나타내는 벡터를 사용하여 방대한 문서 컬렉션(보통 미리 인코딩된)을 검색합니다. 이것은 가상 문서의 벡터와 유사한 실제 문서를 탐색합니다. 유사성은 이 실제 문서들이 가상 답변과 유사한 방법으로 사용자 쿼리에 대응한다는 것을 나타냅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n5단계: 검색된 문서를 활용하기: HyDE 프로세스를 기반으로 가장 관련성 높은 것으로 간주된 이러한 검색된 문서는 이후 RAG 시스템에 공급됩니다. RAG 내의 LLM은 이 문서들을 사용하여 사용자의 초기 쿼리에 대한 더 포괄적이고 유익한 응답을 생성할 수 있습니다.\n\n참고 자료:\n\n- https://platform.openai.com/docs/assistants/overview\n- LinkedIn GitHub","ogImage":{"url":"/assets/img/2024-05-17-5HacksToImproveYourRAGApplication_0.png"},"coverImage":"/assets/img/2024-05-17-5HacksToImproveYourRAGApplication_0.png","tag":["Tech"],"readingTime":6},{"title":"AI 콘텍스트 뉴로심볼릭 RAG 및 지식 그래프의 힘","description":"","date":"2024-05-17 04:17","slug":"2024-05-17-ContextualAINeurosymbolicRAGandthePowerofKnowledgeGraphs","content":"\n\n지식 그래프를 활용한 검색 기반 생성 (RAG)은 실세계 LLM 응용 프로그램에 대한 중요한 AI 스택입니다.\n\nRAG는 언어 모델이 생성 과정 중 외부 지식을 검색하고 통합할 수 있게 하는 기술로, 엄청난 잠재력을 가지고 있습니다. 그러나 이 잠재력을 완전히 발휘하기 위해서는 협동 필터링 기술을 적용하여 심볼적 사전 추론으로 증강 프로세스를 제한해야 합니다.\n\n이를 달성하는 가장 유연하고 확장 가능한 접근 방식은 지식 그래프를 활용하는 것입니다. 이는 현실 세계 개체 및 관계의 구조화된 표현으로, 어떤 도메인에서 세계 이해를 지배하는 지식, 제약 및 논리적 규칙의 풍부한 연결을 포착합니다.\n\n지식 그래프의 심볼적 지지체 안에 RAG를 고정시킴으로써, 순수히 신경적인 접근 방식에 오랫동안 부족했던 견고한 추론, 컨텍스트 인식 생성, 향상된 설명 및 해석 가능성을 AI 시스템에 주입할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n또한, 이 신경-기호론 RAG 패러다임은 선량한 데이터 플라이휠 효과를 제시합니다.\n\nAI 시스템이 물리적 증강을 위해 지식 그래프를 활용하는 동안 생성하는 통찰과 결과물은 다시 지식 그래프로 피드백되어 지식 그래프를 계속 풍부하게 하고 정제하는 구조화된 지식 베이스로 이어질 수 있습니다.\n\n이 반복적인 과정은 연속적인 학습과 개선을 촉진할 뿐만 아니라, 최종 추론 접근법에서 큰 언어 모델(LLMs)을 정교조정하기 위한 길을 열어 그들의 맥락에 민감한 능력을 더욱 향상시킵니다.\n\n또한, LLMs가 생성 프로세스 중에 다양한 관련 예시를 제공받는 많은 예시 내 문맥 학습의 파워를 활용함으로써, 우리는 신경-기호론 RAG의 이점을 확대시키고 AI 시스템이 풍부한 맥락화 된 지식과 추론 패턴으로부터 학습하도록 할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# I. 순수한 신경망 접근 방식의 제한\n\n신경망은 다양한 작업에서 놀라운 성공을 거두었지만, 종종 인간 수준의 지능에 필요한 견고한 추론 능력과 기본적인 지식이 부족합니다. 순수한 신경망 접근 방식의 주요 제한 사항 중 일부는 다음과 같습니다:\n\n## A. 견고한 추론 및 기본적인 지식의 부족:\n\n특히 대형 언어 모델(LLM)은 데이터의 통계적 패턴을 캡처하는 데 뛰어나지만, 사람들이 가진 합성성, 인과관계, 시간성 및 상식 추론을 통합하는 데 어려움을 겪습니다. 이는 복잡한 시나리오에서 일관성이 없거나 비논리적인 결과물로 이어질 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## B. 규범화, 시간 이해 및 상식 추론에서의 과제:\n\n신경망은 익숙한 개념을 새로운 방식으로 결합해야 하는 합성적 규범화에 어려움을 겪기도 합니다. 또한 동역학을 해체하고 상급적 시뮬레이션을 실행하는 것도 어렵습니다. 이는 시간 이해와 상식적 추론에 중요합니다.\n\n## C. 구조화된 지식 통합의 필요성:\n\n기업이 심층적인 AI 발전을 추구하는 가운데, 인간의 지식을 구조화된 지타구로 인코딩하는 것이 필수적입니다. 비구조화된 데이터에서의 순수한 통계적 학습은 현실 세계를 조절하는 풍부한 관계, 제약 및 규칙을 포착하지 못합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이러한 한계를 해결하기 위해 연구자들은 신경 기호 접근법을 채택해왔습니다. 이 방법은 신경망의 유연성과 학습 능력을 기호적 시스템의 구조화된 지식과 추론 능력과 결합합니다.\n\n## II. 지식 그래프: 세계의 구조화된 표현\n\n지식 그래프는 현실 세계의 사실과 관계를 구조화된 기계 가독성 형식으로 표현하는 강력한 방법입니다. 비구조화된 데이터 소스와 달리, 지식 그래프는 정보를 연결된 개체 및 관계의 네트워크로 구성하여 인간의 이해를 기반으로 하는 복잡한 의미론과 논리를 포착합니다.\n\n### A. 지식 그래프의 정의:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지식 그래프는 지식의 그래프 기반 표현으로, 노드는 엔티티(예: 사람, 장소, 개념)를 나타내고 엣지는 이러한 엔티티 간의 관계(예: 출생지, 근무처, 친구)를 나타냅니다.\n\n## B. 지식 그래프의 비구조화된 데이터에 대한 장점:\n\n지식 그래프는 텍스트 말뭉치와 같은 비구조화된 데이터 소스보다 몇 가지 장점을 제공합니다:\n\n- 관계 및 제약 조건의 명시적 표현\n- 다양한 소스에서 지식 통합\n- 논리적 추론과 추론 용이성 제공\n- 지식의 쿼리 및 탐색 용이성을 제공\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## C. 다양한 도메인에서의 지식 그래프의 다양한 응용:\n\n지식 그래프는 다음과 같은 다양한 도메인에서 응용되어 왔습니다:\n\n- 생명 과학 및 생물 의학 (예: 약물-타겟 상호작용, 질병 온톨로지 표현)\n- 기업 지식 관리 (예: 조직 구조, 업무 흐름, 정책 수립 캡처)\n- 학술 및 과학 연구 (예: 게재물, 저자, 학회, 연구 주제 연결)\n- 추천 시스템 및 맞춤형 어시스턴스 (예: 사용자 선호도, 제품 카탈로그, 콘텐츠 메타데이터 표현)\n\n지식 그래프의 구조화된 특성을 활용함으로써, AI 시스템은 다양한 지식의 풍부한 직물에 접근하여 보다 견고한 추론 및 세간적인 이해를 가능케 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# III. 검색 보강 생성 (RAG): 언어 모델 강화\n\n검색 보강 생성 (RAG)은 대형 언어 모델 (LLM)의 능력을 향상시키는 데 중요한 방법으로 등장한 기술입니다. RAG 시스템은 LLM의 생성 능력과 생성 과정 중 외부 소스에서 관련 정보를 검색하고 통합하는 능력을 결합합니다.\n\n## A. RAG 및 해당 변형에 대한 개요:\n\nRAG 시스템은 다양한 방법을 통해 LLM을 보강할 수 있습니다. 이 방법에는 이와 같은 것들이 포함됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 쿼리 기반: 검색된 콘텐츠가 LLM 프롬프트로 직접 공급됩니다.\n- 잠재: LLM이 검색된 개체의 잠재 임베딩과 상호 작용합니다.\n- 로짓: 검색 출력물이 생성 로짓으로 결합됩니다.\n- 추론적: 일부 생성 계산이 검색 출력물로 대체됩니다.\n\n## B. 비구조화 데이터 소스를 사용하는 RAG의 한계:\n\n대부분의 기존 RAG 시스템은 검색 소스로 비구조화된 텍스트 말뭉치를 사용합니다. 이는 유용한 문맥 정보를 제공할 수 있지만, 견고한 추론과 이해에 필요한 풍부하고 구조화된 지식이 부족한 경우가 많습니다.\n\n## C. 지식 그래프 증강 RAG (논리 RAG)의 잠재력:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n외부 지식 원천으로 지식 그래프를 통합함으로써, RAG 시스템은 실세계 엔티티, 관계 및 제약 조건의 구조화된 표현을 활용할 수 있습니다. 이 접근 방식은 종종 \"논리 RAG\"라고 불리며, 복잡한 추론 및 컨텍스트 인식 생성을 용이하게 하는 더 고급 검색 패러다임을 가능하게 합니다.\n\n# IV. 신호신경 기호 RAG: 신경적 유연성과 심볼 지식의 결합\n\n신호신경 AI는 신경망과 심볼적 추론 시스템의 강점을 결합하려는 신흥 분야입니다.\n\nRAG의 맥락에서 신호신경적 접근법은 신경망의 유연성과 학습 능력을 구조화된 지식 및 논리 추론 능력과 통합하는 것을 목표로 합니다. 종종 지식 그래프 형태로 이루어집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## A. 뉴로 심볼릭 접근:\n\n신경망과 상징적 추론을 통합: 뉴로심볼릭 AI는 상징적 추론과 신경망을 결합하는 다양한 방법을 탐구하여, 서로 보완적인 강점을 활용합니다.\n\nRAG의 경우, 이는 신경망을 사용하여 언어 생성 및 지식 검색을 수행하고, 지식 그래프 상에서 상징적 추론을 활용하여 구조화되고 맥락을 갖춘 지식을 제공하는 것을 의미합니다.\n\n## B. 지식 그래프와 논리 검색 패러다임:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n논리적인 지식 그래프를 통한 검색에 대해 여러 패러다임이 제안되었습니다. 문맥을 고려하고 추론을 기반으로 한 지식 검색을 가능케 합니다:\n\n- 그래프 알고리즘: 구조적 쿼리와 제약 조건을 일치시키기 위해 원시 지식 그래프 알고리즘을 직접 활용합니다(예: 약물과 상호 작용하는 개체를 찾아 약물 조합을 권장하는 경우).\n- Entity embeddings: 관계와 제약 조건을 포함하는 개체 표현을 학습함으로써(예: 상호작용, 대상 및 효과에 따라 약물을 임베딩), 임베딩 공간 일치를 통한 검색을 가능하게 합니다.\n\n![image](/assets/img/2024-05-17-ContextualAINeurosymbolicRAGandthePowerofKnowledgeGraphs_0.png)\n\n3. Hybrid methods: 학습된 표현을 사용하여 상징적 알고리즘을 결합합니다(예: 중요한 제약 조건에 따라 검색된 개체를 필터링하는 경우).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## C. Contextual and grounded AI benefits of neurosymbolic RAG:\n\nThrough the integration of knowledge graphs into the RAG process, neurosymbolic approaches offer numerous advantages:\n\n1. **Robust reasoning and grounded understanding:** Knowledge graphs offer a structured foundation for capturing real-world limitations, rules, and connections. This capability enhances robust and grounded reasoning.\n\n2. **Context-aware generation:** By retrieving relevant entities and relationships from knowledge graphs, rich contextual information is provided for language generation tasks. This results in more coherent and meaningful outputs.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n가독성 및 해석력: 지식 그래프의 상징적 특성과 관계의 명시적 표현은 신호기호 RAG 시스템의 해석력과 가독성을 향상시킬 수 있습니다.\n\n도메인 전문지식을 활용: 도메인별 지식 그래프는 전문지식을 활용하고 확립된 온톨로지를 통합하여 RAG 시스템에 통합할 수 있게 해줍니다.\n\n연구자와 개발자는 신경망의 강점과 상징적 추론을 결합하여 더욱 유연하고 맥락에 민감하며 기반을 둔 생성이 가능한 AI 시스템을 만들 수 있습니다, 이는 네이로신호 기호 RAG를 통해 더욱 인간과 유사한 지능을 달성할 수 있는 발판을 마련합니다.\n\n![ContextualAINeurosymbolicRAGandthePowerofKnowledgeGraphs_1.png](/assets/img/2024-05-17-ContextualAINeurosymbolicRAGandthePowerofKnowledgeGraphs_1.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# V. 지식 그래프 내에서 협력 필터링을 결합한 예시와 문맥 학습에서의 검색\n\n신경 기호론 RAG의 유망한 응용 사례 중 하나는 지능적인 협력 필터링을 위해 지식 그래프를 활용하는 것이며, 이는 채용 및 인재 매칭을 위한 후보자-요구 사항 점수화의 한 예입니다.\n\n## A. 후보자-요구 사항 점수화에 협력 필터링 적용하기:\n\n추천 시스템에서의 협력 필터링 기술은 후보자를 직무 요구 사항에 대해 점수화하는 데 적용될 수 있으며, 후보자와 요구 사항의 유사성을 고려합니다. 이 접근 방식은 후보자 정보, 공석 정보, 기술, 요구 사항 및 점수를 지식 그래프 내에 저장하는 것을 포함합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## B. 지식 그래프를 활용한 지능적인 유사성 계산:\n\n이 방법의 핵심은 후보자와 요구 사항 간의 유사성을 지능적으로 계산하는 것으로, 지식 그래프 내의 구조화된 지식을 활용합니다:\n\n- 기술 온톨로지 및 계층 구조: 기술 계층 구조와 근접성을 기반으로 유사성을 계산하기 위한 기술 온톨로지를 개발하며, 기술의 중요성과 맥락을 고려하여 직무 요구 사항에 대한 계산을 고려합니다.\n- 맥락적 일치와 개인화: 기술이 언급된 맥락을 고려하고, 고객이 고유한 요구에 기반해 후보자 속성에 대한 개인화된 가중치와 선호도를 설정할 수 있도록 합니다.\n- 경험, 교육, 그리고 도메인 전문 지식 활용: 후보자의 경험 수준, 고위권, 교육, 자격증, 산업, 그리고 도메인 전문 지식을 유사성 계산에 통합하여 보다 포괄적인 평가를 제공합니다.\n\n## C. 사용자 피드백을 통한 지속적인 개선과 설명력:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시스템은 사용자 피드백을 기반으로 유사성 계산을 지속적으로 개선하는 피드백 루프를 구현할 수 있습니다.\n\n또한, 유사한 후보-요구사항 쌍을 활용한 집중된 대조 분석은 후보자의 점수에 영향을 미친 주요 요소를 강조함으로써 설명 가능성을 제공할 수 있습니다.\n\n협력 필터링 기술과 지식 그래프 기반의 유사성 계산을 결합하여, 이 접근법은 체계적인 지식 표현과 추론의 힘을 활용하여 보다 정보화되고 문맥에 맞게 해석 가능한 후보-요구사항 점수를 제공하고자 합니다.\n\n# VI. 응용 및 현실 세계 사용 사례\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nNeurosymbolic RAG with Knowledge Graphs has the potential to unlock a wide range of applications and real-world use cases, spanning various domains and industries. Here are some examples:\n\n## A. 질문 응답 및 자연어 이해:\n\n지식 그래프를 RAG 시스템에 통합함으로써 이러한 시스템은 자연어 질문에 더 정확하고 맥락적인 응답을 제공할 수 있습니다. 이는 고객 서비스, 가상 어시스턴트 및 교육 애플리케이션과 같은 도메인에서 특히 유용할 수 있습니다.\n\n## B. 추천 시스템 및 개인화 어시스턴트:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지식 그래프를 증강한 RAG는 권장 시스템과 개인화된 어시스턴트를 개선하여 사용자 선호도, 제품 속성 및 맥락 제약의 더 섬세한 이해를 가능케 합니다. 이는 더 관련성 높고 맞춤형 권장 사항을 제공하여 사용자 만족도와 참여도를 향상시킬 수 있습니다.\n\n### C. 생명과학 및 과학 연구:\n\n생명과학 및 과학 지식 그래프는 RAG 시스템에 통합되어 연구자들이 문헌 탐색, 가설 생성 및 약물 발견과 같은 다양한 작업을 지원할 수 있습니다. 생물학적 프로세스, 분자 상호작용 및 과학 문헌의 구조화된 지식을 활용함으로써, 이러한 시스템은 더 통찰력 있고 실질적인 권장 사항과 분석을 제공할 수 있습니다.\n\n### D. 기업 의사결정 지원 및 업무 자동화:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지식 그래프는 기업 내의 조직 구조, 정책, 워크플로 및 도메인 특정 지식을 포착할 수 있습니다. 이러한 지식 그래프를 RAG 시스템에 통합하면 더 지능적인 의사 결정 지원, 자동 추론 및 워크플로 최적화를 가능하게 하여 효율성을 증가시키고 더 나은 결정을 내릴 수 있게 도와줄 수 있습니다.\n\n# VII. 과제 및 미래 방향\n\n뇌 심볼릭 RAG와 지식 그래프를 결합하는 것은 상당한 잠재력을 지니고 있지만, 더 탐구해야 할 여러 가지 도전과 미래 방향이 있습니다:\n\n## A. 지식 그래프 구축 및 유지 관리:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n높은 품질의 지식 그래프를 구축하고 유지하는 것은 복잡하고 자원 소모적인 작업입니다. 종종 상당한 도메인 전문 지식과 수동으로 관리하는 작업이 필요합니다. 자동화된 지식 그래프 구축 및 정제 기술은 이러한 시스템의 널리 통용되는 채택을 위해 중요할 것입니다.\n\n## B. 확장성과 계산 복잡성:\n\n대규모 지식 그래프를 통합하고 이를 토대로 논리적 추론을 수행하는 것은 계산적으로 비용이 많이 들 수 있습니다. 특히 실시간 응용프로그램에서 그렇습니다. 효율적인 알고리즘 개발과 하드웨어 가속기를 활용하는 것이 중요할 것입니다. 이것이 신경 기호 주의적 RAG 시스템의 확장성을 보장하기 위해 필요합니다.\n\n## C. 신경 기호 주의 모델의 해석 가능성과 투명성:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n심볼릭 구성 요소가 뇌 심볼릭 RAG 시스템의 해석 가능성을 향상시킬 수 있지만, 신경 구성 요소는 여전히 불투명성과 투명성의 부족을 도입할 수 있습니다. 이러한 혼합 모델이 내린 결정을 해석하고 설명하는 기술은 신뢰를 구축하고 인간-인공지능 협업을 원활하게 하는 데 중요할 것입니다.\n\n## D. 다중 모달 데이터 및 상식적 추론 통합:\n\n지식 그래프는 구조화된 지식을 포착할 수 있지만, 다중 모달 데이터(예: 이미지, 비디오, 오디오) 및 상식적 추론 능력이 뇌 심볼릭 RAG 시스템에 통합되는 것은 여전히 도전입니다. 다중 모달 지식 표현 및 추론의 발전은 정말로 지능적이고 맥락에 민감한 인공지능 시스템을 만드는 데 중요할 것입니다.\n\n이러한 도전에도 불구하고, 뇌 심볼릭 RAG 및 지식 그래프 통합 분야는 맥락적이고 뿌리있는 AI의 미래를 형성하는 데 엄청난 잠재력을 가지고 있습니다. 이 분야에서 계속되는 연구, 협업 및 혁신은 인공지능의 전체 잠재력을 발휘하고, 인간과 유사한 지능으로 세계를 인지하고 조작할 수 있는 시스템을 가능하게 하는 데 중요할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\n지능적이고 맥락에 따라 인공 지능 시스템을 탐색하는 과정에서 신경 기호론적 접근, 추출 증강 생성 (RAG), 그리고 지식 그래프 통합이 미래의 유망한 방향으로 떠오르고 있습니다. 신경망의 유연성과 학습 능력을 기호적 시스템의 구조화된 지식과 추론 능력과 결합함으로써 신경 기호론적 RAG는 세계를 더욱 흔들리지 않고 인간과 비슷한 방식으로 이해하고 추론할 수 있는 AI 시스템을 구축하기 위한 강력한 프레임워크를 제공합니다.\n\n지식 그래프는 현실 세계 개체와 관계의 구조화된 표현을 제공하여 RAG 시스템에 의해 공유될 수 있는 풍부한 지식 천연물을 제공합니다. 그래프 알고리즘, 엔티티 임베딩, 그리고 혼합 방법과 같은 논리적 검색 패러다임을 통해 신경 기호론적 RAG는 견고한 추론, 맥락에 의한 생성, 그리고 향상된 설명과 해석 가능성을 활성화할 수 있습니다.\n\n지식 그래프와 함께하는 신경 기호론적 RAG의 응용은 질의 응답, 추천 시스템, 생명과학 연구, 그리고 기업 의사 결정 지원을 포함한 다양한 분야에 걸쳐 있습니다. 구조화된 지식과 논리적 추론을 활용함으로써 이러한 시스템은 더 정확하고 맥락적이며 통찰력 있는 결과물을 제공하여 실제로 지적이고 터무니없는 AI 솔루션으로 향하게 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그러나 신경 기호 RAG의 완전한 잠재력을 실현하려면 지식 그래프 구축 및 유지, 확장성 및 계산 복잡성, 해석 가능성 및 투명성, 다중 모달 데이터 및 상식 추론과 같은 도전을 극복해야 합니다. 이러한 영역에서 계속된 연구, 협업 및 혁신이 문맥적이고 기초가 있는 AI의 미래를 결정하는 데 중요할 것입니다.","ogImage":{"url":"/assets/img/2024-05-17-ContextualAINeurosymbolicRAGandthePowerofKnowledgeGraphs_0.png"},"coverImage":"/assets/img/2024-05-17-ContextualAINeurosymbolicRAGandthePowerofKnowledgeGraphs_0.png","tag":["Tech"],"readingTime":10},{"title":"글로벌 자동화론","description":"","date":"2024-05-17 04:15","slug":"2024-05-17-TheGlobalAutomatonFallacy","content":"\n\n## 기술 세계가 어리석어지고 있는가요?\n\n![이미지](/assets/img/2024-05-17-TheGlobalAutomatonFallacy_0.png)\n\n자동화는 인간 제어 없이 작동하는 작업이나 프로세스입니다.\n\n자동화는 자동기구, 프로세스 또는 기계/로봇을 가리킵니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n글로벌 자동화 기계란 i) 사람이 할 수 있는 일을 할 수 있는 로봇이고, ii) 다른 로봇을 제어하는 프로세스를 만들 수 있으며, iii) 다른 로봇을 만들 수 있는 로봇을 가리킵니다.\n\n글로벌 자동화 기계론은 창조자에게 긍정적인 경제적 결과를 가져다줄 수 있는 글로벌 자동화 기계가 조만간 존재할 것이라는 신념입니다.\n\n# 수요는 무엇인가요?\n\n건축 학생에게 전문 지도를 제공할 수 있는 글로벌 자동화 기계가 존재한다고 가정해봅시다. 더불어, 건물 크기, 선호도, 위치 등에 대한 일부 입력을 사용하여 건축가, 디자이너 또는 취미로 건축도면을 작성할 수 있습니다. 또한 건축 자재를 재료로 사용하여 작업을 완료하는 데 측정된 건설 자재만 필요한 대형 3D 프린터에 연결할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 자동화 도구를 만든 사람은 다음과 같이 스스로에게 물어봐야합니다: 그가 하는 일은 무엇일까요? 건축에 관한 모든 것을 '알아서' 가르치는 것인가요? 그림을 그리는 것인가요? 아니면 건축을 하는 것인가요?\n\n첫 번째 문제(수요의 문제)는 건축의 '전체 자동화 도구'를 만들려고 한다는 것은 각각의 '작업'이 잠재적인 고객들이 신뢰하기 전에 많은 '훈련', '시험', '평가' 및 '증명'이 필요한 만큼 복잡하다는 것입니다.\n\n두 번째 문제(수요의 문제)는 가격 책정이 반드시 복잡해져야 한다는 점입니다. 왜냐하면 '만능 인재' 자동화 도구는 단일 작업의 전문가가 아니라 시장 가격과 비교할 수 있는 작업 하나만에 뛰어난 전문가가 아니기 때문입니다.\n\n세 번째 문제(수요의 문제)는 창조자가 잠재적 투자자와 고객 양측에게 '전체 자동화 도구'의 가치나 유틸리티를 마케팅하거나 합리화해야 한다는 어려운 과제를 직면하게 될 것입니다. 투자자들에게 창조자가 해결해야 할 필요성이나 문제를 어떻게 정당화할 것인가요? 고객들에게는 창조자가 제품/서비스의 혜택이나 인간 대체품 사용에 따른 전환 비용을 어떻게 정당화할 것인가요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 공급은 무엇인가요?\n\n어떤 '글로벌 자동화' 가능한 창조자가 직면해야 할 현실은 동기부여, 비용, 의도, 합리화 및 기회 비용입니다.\n\n첫 번째 문제(공급의 문제)는 동기부여의 문제입니다. 동기부여는 전염병과 매우 유사합니다. 그것의 부재나 보유는 회사 전체에 빠르게 퍼질 수 있습니다. 특히 충분한 자금이 없어 사람들에게 직장이나 직업을 교체하도록 \"동기부여\"할 여력이 없는 스타트업에게는 그렇습니다. 그러나 '건축 학생들을 위한 최고의 과왕 자동화', 건축가들을 위한 '최고의 디자이너 자동화' 또는 건축가들을 위한 '최고의 건설 자동화'를 구축하는 목표가 명확하지 않으면, 동기부여를 얻기가 어려울 것입니다. 드물게 그런 동기부여를 찾았다 하더라도, 손에 쥔 과제는 평균 이상이어야 하며, 세 가지 매우 복잡한 작업에서 (실제 필요나 원하는 것을 충족시키지 않을 수도 있는) 더 좋은 것을 만드는 작업에 관여하게 될 것입니다.\n\n두 번째 문제(공급의 문제)는 비용 문제입니다. 양산 비용은 지역 자동화에 초점을 맞추거나 인간 대체품을 고용하는 것과 대조적으로 매우 방해가 될 가능성이 높습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n공급의 세 번째 문제는 의도나 비전입니다. 만약 창업 창조자가 더 빠르고 저렴하며 더 나은 그리고 우아한 사무실 건물에 대해 실제로 중요하게 생각하는 것이라고 깨달았다면 어떨까요? 그런 경우에는 첫 번째 두 로컬 자동화 장치가 무의미할 뿐만 아니라 동일한 목표를 달성하기 위해 자동화 장치를 만들지 않고도 가능성이 있습니다.\n\n공급의 네 번째 문제는 (내부) 합리화입니다. 후자가 인간 대체품보다 실제로 빠르고 저렴하며 더 나은지 아니면 우아한지 의문을 제기해볼 수 있습니다. (건축) 교육, 설계 및 건설 과제를 수행하는 대신에 (가능한) 프랑켄슈타인을 '창조'하는 시간을 왜 소비해야 할까요? 이 시간, 돈 및 재능을 효과적으로 사용하는 것인가요?\n\n다른 관련된 합리화 문제는 전문성 또는 (내가 싫어하는 단어인) 특수화입니다. 사람이 자동화 장치를 만드는 전문가일까요, 아니면 건축 및 건설에 관련된 모든 것에 대해 전문가일까요? '잘 했어요' 작업을 어떻게 평가하고, 그것이 '평균 이상'일지 여부를 누가 평가할까요? 이들은 모두 집중과 최적화를 요구하는 복잡하고 가치 있는 요소이므로 지속적인 기간 동안 집중과 최적화가 필요합니다. 또한 제품을 개선하거나 고객에게 유혹적인 혜택을 제공하여 고객이 전환하거나 행동을 변경하도록 유도하려면 두 가지 몬스터 작업을 동시에 수행하는 것이 경제적(또는 심리적)으로 최적일까요?\n\n공급의 다섯 번째 문제는 기회 비용입니다. (건축) 자동화장치와 더 빠르고 저렴하며 더 나은 그리고 우아한 건물/건축을 위한 시장이 있다고 가정했을 때, 더 크고 비용 효율적인 시장을 평가해볼 수 없을까요? 두 가지 옵션 간의 시장 진입 시간은 어떻게 되는가요? 자동화 장치를 만든 후 몇 년이 지나면 시장 요인, 취향, 법률 및 경쟁사가 어떻게 변하는가요? 이러한 자동화 장치가 예기치 않은 블랙 스완 사건에 대한 사용자 정의 또는 안티프래질윤을 갖추고 있는가요? 한편, 자동화장치를 구축하는 데 들어가는 비용과 복잡성은 예상된 이점을 가져다줄 정당한 노력을 정당화하기에도 충분하지 않을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n모든 그 자원들, 모든 그 시간들, 모든 그 돈들, 그리고 모든 그 재능들은 더 유익하고 더 효과적이며 더 혁신적이며 더 유익하며 더 흥미로운 일들에 사용될 수 있었을 텐데요.\n\n![이미지](/assets/img/2024-05-17-TheGlobalAutomatonFallacy_1.png)","ogImage":{"url":"/assets/img/2024-05-17-TheGlobalAutomatonFallacy_0.png"},"coverImage":"/assets/img/2024-05-17-TheGlobalAutomatonFallacy_0.png","tag":["Tech"],"readingTime":4},{"title":"홈 랩 DNS 업데이트 테크니티움, 파이홀","description":"","date":"2024-05-17 04:14","slug":"2024-05-17-HomeLabDNSUpdateTechnitiumPi-Hole","content":"\n\n이번 아침에는 Pi Hole DNS 서버를 다른 Technitium 설치로 대체하기로 결정했어요. 그래서 이제 HA를 위해 두 개의 Technitium DNS 서버를 사용하고 있어요.\n\n우분투 23.10 서버 이미지를 설치한 후, Technitium의 웹사이트에서 이 편리한 한 줄 명령어를 제공하네요:\n\n```js\ncurl -sSL https://download.technitium.com/dns/install.sh | sudo bash\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n거기서 고정 IP, 관리자 비밀번호를 설정하고 원래의 Technitium DNS 서버에서 설정을 가져왔습니다. 최근 블로그 게시물에서 이에 대한 내용을 다뤘어요.\n\nTechnitium 웹 인터페이스로 돌아와서 설정 페이지의 가져오기/내보내기 기능을 사용하여 주 서버의 설정을 백업하고 보조 서버에 복원했어요:\n\n![image](/assets/img/2024-05-17-HomeLabDNSUpdateTechnitiumPi-Hole_1.png)\n\n백업 인터페이스를 통해 캡처할 항목을 선택할 수 있어요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마찬가지로 복원 페이지에서 가져오길 원하는 것을 묻습니다:\n\n![capture](/assets/img/2024-05-17-HomeLabDNSUpdateTechnitiumPi-Hole_3.png)\n\n그 후에 정적 IP를 적용하고 모든 것이 예상대로 작동하는지 확인하기 위해 다시 부팅했습니다. 이제 두 개의 다른 라즈베리 파이 장치에서 두 개의 Technitium DNS 서버가 실행 중입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n내 원래 계획은 라즈베리 파이 서버에 어떤 종류의 microk8s 설치를 사용하고 Kubernetes가 컨테이너를 실행하도록 하는 것이었습니다. 그러나 외부에서 k8s가 포트 53에서 듣도록 하는 데 어려움이 있었기 때문에, 일단 그 계획을 포기하기로 결정했습니다. 다시 시도하지 않을 것 같고, 대신 내장형 (잘, 쉽게 설치 가능한) core-dns 기능을 사용할 것입니다. 그 목적으로는 K8s가 과도한 것이었을 것입니다.\n\n업데이트된 홈 랩 인벤토리 다이어그램이 도착했습니다. 곧 발행될 예정이니 기대해주세요!","ogImage":{"url":"/assets/img/2024-05-17-HomeLabDNSUpdateTechnitiumPi-Hole_0.png"},"coverImage":"/assets/img/2024-05-17-HomeLabDNSUpdateTechnitiumPi-Hole_0.png","tag":["Tech"],"readingTime":2}],"page":"1","totalPageCount":80,"totalPageGroupCount":4,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"1"},"buildId":"R94iUTCf1NWeBC_VXjTJG","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>