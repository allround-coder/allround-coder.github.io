<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>allround-coder</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://allround-coder.github.io///posts/85" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="allround-coder" data-gatsby-head="true"/><meta property="og:title" content="allround-coder" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://allround-coder.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://allround-coder.github.io///posts/85" data-gatsby-head="true"/><meta name="twitter:title" content="allround-coder" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | allround-coder" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZFDEQ947R4"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
  
            gtag('config', 'G-ZFDEQ947R4');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-ec7535a55e788b31.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/Rv-NbbtWUaja2joH5WkO_/_buildManifest.js" defer=""></script><script src="/_next/static/Rv-NbbtWUaja2joH5WkO_/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Allround Coder</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="2024년 두보이 도전 R 프로그래밍 활용 방법" href="/post/2024-05-16-2024DuBoisChallengeusingRProgramming"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="2024년 두보이 도전 R 프로그래밍 활용 방법" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-2024DuBoisChallengeusingRProgramming_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="2024년 두보이 도전 R 프로그래밍 활용 방법" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">2024년 두보이 도전 R 프로그래밍 활용 방법</strong><div class="PostList_meta__VCFLX"><span class="date">May 16, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="윈도우 보안 여정 - Windows Defender Antivirus" href="/post/2024-05-16-TheWindowsSecurityJourneyWindowsDefenderAntivirus"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="윈도우 보안 여정 - Windows Defender Antivirus" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-TheWindowsSecurityJourneyWindowsDefenderAntivirus_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="윈도우 보안 여정 - Windows Defender Antivirus" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">윈도우 보안 여정 - Windows Defender Antivirus</strong><div class="PostList_meta__VCFLX"><span class="date">May 16, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="맥OS에서 Expo로 빌드하는 동안 권한 문제 해결하기 개인 경험 공유" href="/post/2024-05-16-SolvingPermissionIssuesinmacOSWhileBuildingwithExpoAPersonalExperience"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="맥OS에서 Expo로 빌드하는 동안 권한 문제 해결하기 개인 경험 공유" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-SolvingPermissionIssuesinmacOSWhileBuildingwithExpoAPersonalExperience_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="맥OS에서 Expo로 빌드하는 동안 권한 문제 해결하기 개인 경험 공유" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">맥OS에서 Expo로 빌드하는 동안 권한 문제 해결하기 개인 경험 공유</strong><div class="PostList_meta__VCFLX"><span class="date">May 16, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="리눅스에서 DNS 서버 설정하기" href="/post/2024-05-16-SettingupaDNSserveronLinux"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="리눅스에서 DNS 서버 설정하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-SettingupaDNSserveronLinux_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="리눅스에서 DNS 서버 설정하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">리눅스에서 DNS 서버 설정하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 16, 2024</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="리액트 네이티브 인앱 구매 iOS - 2부" href="/post/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="리액트 네이티브 인앱 구매 iOS - 2부" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="리액트 네이티브 인앱 구매 iOS - 2부" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">리액트 네이티브 인앱 구매 iOS - 2부</strong><div class="PostList_meta__VCFLX"><span class="date">May 16, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="테라폼을 사용하여 다양한 쿠버네티스 리소스 생성하기" href="/post/2024-05-16-CreatevariousKubernetesresourcesusingTerraform"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="테라폼을 사용하여 다양한 쿠버네티스 리소스 생성하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-CreatevariousKubernetesresourcesusingTerraform_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="테라폼을 사용하여 다양한 쿠버네티스 리소스 생성하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">테라폼을 사용하여 다양한 쿠버네티스 리소스 생성하기</strong><div class="PostList_meta__VCFLX"><span class="date">May 16, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="테크오라마 2024 하이라이트" href="/post/2024-05-16-Techorama2024Highlights"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="테크오라마 2024 하이라이트" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-Techorama2024Highlights_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="테크오라마 2024 하이라이트" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">테크오라마 2024 하이라이트</strong><div class="PostList_meta__VCFLX"><span class="date">May 16, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="백엔드 기본 사항" href="/post/2024-05-16-BACK-ENDBASICS"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="백엔드 기본 사항" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-BACK-ENDBASICS_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="백엔드 기본 사항" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">백엔드 기본 사항</strong><div class="PostList_meta__VCFLX"><span class="date">May 16, 2024</span><span class="PostList_reading_time__6CBMQ">12<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="타임 시리즈에 대해 PySpark와 Databricks를 사용한 피처 엔지니어링" href="/post/2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="타임 시리즈에 대해 PySpark와 Databricks를 사용한 피처 엔지니어링" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="타임 시리즈에 대해 PySpark와 Databricks를 사용한 피처 엔지니어링" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">타임 시리즈에 대해 PySpark와 Databricks를 사용한 피처 엔지니어링</strong><div class="PostList_meta__VCFLX"><span class="date">May 16, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="EKS에서 자체 호스팅 LLM을 배포하는 방법 및 그 이유" href="/post/2024-05-16-HowtoDeployaSelf-HostedLLMonEKSandWhyYouShould"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="EKS에서 자체 호스팅 LLM을 배포하는 방법 및 그 이유" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-HowtoDeployaSelf-HostedLLMonEKSandWhyYouShould_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="EKS에서 자체 호스팅 LLM을 배포하는 방법 및 그 이유" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">EKS에서 자체 호스팅 LLM을 배포하는 방법 및 그 이유</strong><div class="PostList_meta__VCFLX"><span class="date">May 16, 2024</span><span class="PostList_reading_time__6CBMQ">9<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/81">81</a><a class="link" href="/posts/82">82</a><a class="link" href="/posts/83">83</a><a class="link" href="/posts/84">84</a><a class="link posts_-active__YVJEi" href="/posts/85">85</a><a class="link" href="/posts/86">86</a><a class="link" href="/posts/87">87</a><a class="link" href="/posts/88">88</a><a class="link" href="/posts/89">89</a><a class="link" href="/posts/90">90</a><a class="link" href="/posts/91">91</a><a class="link" href="/posts/92">92</a><a class="link" href="/posts/93">93</a><a class="link" href="/posts/94">94</a><a class="link" href="/posts/95">95</a><a class="link" href="/posts/96">96</a><a class="link" href="/posts/97">97</a><a class="link" href="/posts/98">98</a><a class="link" href="/posts/99">99</a><a class="link" href="/posts/100">100</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"2024년 두보이 도전 R 프로그래밍 활용 방법","description":"","date":"2024-05-16 03:58","slug":"2024-05-16-2024DuBoisChallengeusingRProgramming","content":"\n\n![2024 Du Bois Challenge](/assets/img/2024-05-16-2024DuBoisChallengeusingRProgramming_0.png)\n\n## #2024DuBoisChallenge을 되돌아보며\n\n올해는 2월 5일부터 4월 8일까지 진행된 2024 Du Bois Challenge에 참여하고 싶었습니다. 처음에는 10주 동안 꾸준히 기여할 것을 예상하지 않았습니다. 다행히도 이번 챌린지는 매주 한 번의 게시물만 요구했기 때문에 매주 한 개의 플롯을 작업할 시간을 주었습니다. 챌린지 관련 리포지토리는 여기에서 확인할 수 있습니다. 총 10개 중 7개의 차트를 완성했습니다. 주차별로 실력이 향상되고 있다는 것을 깨달았습니다. R만을 사용하여 챌린지를 성공적으로 완료할 수 있을 거라고는 생각하지 않았습니다. 그러나 tidyverse와 ggplot 패키지는 모든 플롯에 사용되었습니다.\n\n![2024 Du Bois Challenge Result](/assets/img/2024-05-16-2024DuBoisChallengeusingRProgramming_1.png)\n\n\n\n도전 과제의 주제는 팬 아프리카 국기의 색상을 중심으로 구성되었습니다:\n도전 1-3: 빨강,\n도전 4-6: 검정,\n도전 7-9: 녹색,\n도전 10: 혼합.\n안소니 스타크의 글에 따르면, 디 부아 도전의 아이디어는 앨런 힐러리와 세쿠 타일러리가 나왔습니다. 2021년 2월 초에 앨런과 세쿠는 안소니 스타크에게 선택된 디 부아 시각화를 재현하고 작품을 온라인으로 공유하는 온라인 도전의 아이디어를 제안했습니다. 이 도전의 목표는 W.E.B 디 부아의 데이터 시각화 유산을 축하하는 것이었는데, 그는 흑인 미국 인권 운동가, 사회학자 및 작가로, 1900년 파리 박람회에서의 시각화를 현대 도구를 사용해 재현했습니다. 그는 또한 NAACP를 설립하는 데 도움을 주었습니다.\n\n모든 시각화(원본 및 내 재현본)과 해당 데이터는 이미 안소니 스타크의 GitHub 저장소에서 수집되어 있어, 나는 도전을 위한 특별한 디렉터리를 만들었습니다.\n\n올해 도전은 Data Visualisation Society slack 채널에 자신의 작품을 게시한 일관적인 기여자들을 위한 상을 제공했습니다. 10주 동안 일관적으로 제출한 기여자들은 1년간의 DVS 회원 자격(99달러 가치) 또는 Nightingale 잡지(40달러 가치)를 획득했습니다.\n\n이 글에 포함된 모든 재현 이미지는 저자가 작성했습니다.\n\n\n\n## 도전 01 _주 01, 2월 5일— 조지아 주의 흑인 인구, 1870년, 1880년 (플레이트 06)\n\n도전 01에서는 1870년과 1880년 데이터셋을 사용하여 조지아의 두 지도를 작성하기 시작했습니다. 지도 패키지를 사용하여 조지아 주의 군을 가져오기 위해, 1880년과 1870년 데이터셋의 군 이름은 지도 패키지의 조지아 지역 이름과 소문자로 변경하여 병합해야 했습니다. 또한 인구 값은 표준화되고, 인구 수에 따라 색으로 부호화되었습니다.\n\n두 범례는 10 x 12 플롯을 사용하여 텍스트 주석을 통해 만들었습니다. 그런 다음 cowplot 패키지를 사용하여 plot_grid() 함수를 사용하여 플롯을 결합했습니다. 배경 색상은 \"papayawhip\"로 설정되었습니다.\n\n\u003cimg src=\"/assets/img/2024-05-16-2024DuBoisChallengeusingRProgramming_2.png\" /\u003e\n\n\n\n## 도전과제 02_week02, 2월 12일 — 노예와 해방된 흑인 (plate 12)\n\n도전의 다음 주에는 텍스트 글꼴을 \"mono\"로 변경해야 한다는 것을 깨달았어요. 이것은 원본 플레이트와 더 비슷하게 보였어요. 나는 이 글꼴을 나머지 플롯에 사용했어요.\n\n도전 02 데이터셋을 사용하여 geom_line() 함수를 사용하여 그림을 통해 선을 그렸어요. 검정색과 빨간색 영역을 음영 처리하기 위해 geom_ribbon() 함수를 사용하여 데이터 포인트의 범위나 범위를 표시했어요. 아래 코드 블록에 표시된 것처럼 geom_ribbon 함수 내에서 ymin은 리본의 하한을 나타내고 ymax는 상한을 나타냅니다. Free와 Inf는 변수입니다. 데이터는 NULL로 설정되었습니다. 왜냐하면 데이터가 이미 ggplot의 도전 02 데이터셋으로 설정되었기 때문이에요. 채우는 색상은 검정색과 빨간색으로 설정되었고, 알파는 채우는 색상의 투명도를 지정합니다. 불행히도, 플롯에서 흰색 선을 표시하지 않았고, 외부 텍스트가 플롯에 표시되었어요.\n\n```js\n#geom_ribbon은 플롯에서 검정색과 빨간색 영역을 설정\ngeom_ribbon(data = NULL, aes(ymin = Free, ymax = Inf), fill = \"black\", alpha = 0.5) +\ngeom_ribbon(data = NULL, aes(ymin = -Inf, ymax = Free), fill = \"red\", alpha = 0.5)\n```\n\n\n\n![image](/assets/img/2024-05-16-2024DuBoisChallengeusingRProgramming_3.png)\n\n## Challenge 05_week 05, March 4 — 조지아의 인종 융합 (plate 13)\n\n챌린지 05는 모든 주 중 코드 라인이 가장 짧았습니다. 챌린지 05 데이터셋은 세 가지 값이 있어 플롯이 간단합니다.\n\ngeom_bar() 함수에서 위치를 \"stack\"으로 설정하고 카테고리별로 막대를 채웠습니다. 세 개의 텍스트 주석은 각각의 카테고리 오른쪽에 추가되었습니다.\n\n\n\n\u003cimg src=\"/assets/img/2024-05-16-2024DuBoisChallengeusingRProgramming_4.png\" /\u003e\n\n## Challenge 07_week 07, March 18 - 다른 국가들과 비교한 미국 흑인의 무문맹률(판 47)\n\nChallenge 07에서 사용된 데이터셋은 다른 국가들의 인구 값으로 막대 그래프를 만들기 쉽게했습니다. 그러나 coord_flip() 함수를 사용해 수평 막대 그래프로 완성하였습니다.\n\n\u003cimg src=\"/assets/img/2024-05-16-2024DuBoisChallengeusingRProgramming_5.png\" /\u003e\n\n\n\n## Challenge 08주 8일, 3월 25일 — 1세대에서 노예에서 자유로움으로 네그로들의 부상 (plate 50)\n\nChallenge 08 차트를 만들기 위해, 1890년과 1860년 데이터가 사용되었고 이를 새로운 데이터프레임으로 만들어 두 개의 쌓인 막대 플롯으로 시작했습니다. Challenge 05와 달리 이 쌓인 막대 차트에서는 coord_flip() 함수를 사용하지 않았습니다. 막대 차트 위에 굵은 글자로 년도가 주석 달린 상태입니다. 두 플롯 사이의 텍스트는 4 x 4 플롯을 사용하여 생성되었습니다.\n\nplot_grid() 함수를 사용하여 세 플롯을 모두 결합했습니다. 1890년 플롯의 높이를 1860년 플롯보다 높게 조정하여 재현을 완료했습니다. 플롯을 최종화한 후 1860년과 1890년 플롯 사이의 점선을 삽입하지 않았다는 것을 발견했습니다. 솔직히 말해서, 난 지긋지긋해서 그 점선을 추가할 엄두가 나지 않았어요..ㅋㅋ.\n\n\n\n## 도전 09_week 09, 4월 1일 — 자유인과 노예의 비율 (plate 51)\n\n제 도전 09 차트 재현에서는 geom_area() 함수를 사용하여 두 가지 카테고리, 즉 자유인과 노예의 상태를 채웠습니다. 도전 09 데이터셋은 넓은 형식에서 긴 형식으로 변환해야 했습니다. 특히 범주형 변수를 다룰 때나 한 그래프에 여러 변수를 플로팅하는 등 특정 유형의 분석과 시각화에는 데이터를 긴 형식으로 작업하는 것이 더 쉽다고 생각했습니다. 또한, 자유인과 노예 카테고리의 각 점에 숫자 주석을 추가했습니다.\n\n![도전 09 차트](/assets/img/2024-05-16-2024DuBoisChallengeusingRProgramming_7.png)\n\n## 도전 10_week 10, 4월 8일 — 미국 거주 플로리다 흑인의 자손들의 상황을 보여주는 통계 차트 일련화 (plate 37)\n\n\n\n도전의 마지막 주에는, 너무 복잡해 보여서 마지막 차트를 만들 수 있을 것이라고 생각하지 않았어요. 플롯을 만드는 내 단계는 다음과 같아요.  \n\n**단계 1** — 이전 플롯들과 동일하게, 내 도전 10은 각 디자인을 만들기 위해 여러 플롯을 사용했어요. 전부터 사용해온 지도 패키지를 사용하여 모든 주(State)에 색을 입혀 네 개의 주위 텍스트 어노테이션을 만들었어요.\n\n**단계 2** — 파이 차트 데이터 세트는 원하는 레이아웃을 얻기 위해 정렬이 필요했지만, 어떻게든 원래의 플레이트와 정확히 일치하지는 않았어요. 두 개의 10x12 플롯을 사용하여 파이 차트 양쪽에 있는 색이 칠해진 원형 범례를 만들었어요. 밑에 있는 텍스트 어노테이션에는 5x12 플롯을 사용하여 텍스트를 추가했어요.\n\n**단계 3** — 플롯을 결합할 때, 제목과 부제목을 하나의 플롯으로 시작했어요. 그리고 지도 플롯을 주위 텍스트 어노테이션과 함께 결합하여 다른 플롯을 만들었어요. 파이 차트에 두 개의 범례 및 아래 텍스트 어노테이션을 추가하여 세 번째 플롯을 만들었어요. 이 세 가지 플롯을 모두 합칠 때, 페파야 휩(연한 주황색)을 배경색으로 사용하여 모든 플롯을 통일시키고 차트 아래에 캡션을 추가했어요.\n\n\n\n\u003cimg src=\"/assets/img/2024-05-16-2024DuBoisChallengeusingRProgramming_8.png\" /\u003e\n\n도전에 참여해서 R을 사용하여 만들 수 있는 가능성을 배울 수 있었어요. 일부 차트를 재현하지 못했지만 업무에 바쁜 나날이었기 때문에, 나는 내가 한 일을 Slack 채널에 공유하고 다른 참여자들로부터 좋은 피드백을 받아서 기뻤어요. 또한 cowplot 패키지가 patchwork보다 더 강력한 결합 도구라는 것을 배웠어요. 내 의견으로는 이것을 사용하면 그림을 맞추기 위해 폭과 높이를 많이 조정해야 해요. 다음 해에는 도전을 완수할 수 있기를 희망하며, 그 재현물이 원본 플레이트에 더 가깝게 보일 수 있기를 기대합니다.","ogImage":{"url":"/assets/img/2024-05-16-2024DuBoisChallengeusingRProgramming_0.png"},"coverImage":"/assets/img/2024-05-16-2024DuBoisChallengeusingRProgramming_0.png","tag":["Tech"],"readingTime":5},{"title":"윈도우 보안 여정 - Windows Defender Antivirus","description":"","date":"2024-05-16 03:57","slug":"2024-05-16-TheWindowsSecurityJourneyWindowsDefenderAntivirus","content":"\n\n\"Windows Defender Antivirus\"은 Windows 10/11/Server용으로 제공됩니다. 알려진/알 수 없는 악성 소프트웨어로부터 보호하기 위해 고급 기술을 사용합니다. 이를 위해 의심스러운 활동을 모니터링하고 행동에 기반한 위협을 차단합니다. 이는 기계 학습/이상 탐지(2015년까지는 정적으로만 신호만 사용)를 통해 이루어지며, 클라우드 기반 인텔리전스와 실시간 업데이트도 제공합니다. \"Windows Defender Antivirus\"는 온라인 및 오프라인 모두에서 작동합니다(https://learn.microsoft.com/en-us/microsoft-365/security/defender-endpoint/microsoft-defender-antivirus-windows?view=o365-worldwide) — 아래 스크린샷에서 확인할 수 있습니다.\n\n전반적으로, \"Windows Defender Antivirus\"는 Windows와 함께 제공되는 차세대 보안 솔루션으로 생각할 수 있습니다. Microsoft Defender Antivirus는 실시간으로 항상 켜져 있는 백신 프로그램입니다(https://www.microsoft.com/en-us/windows/comprehensive-security). 그리고 Android용 \"Microsoft Defender: Antivirus\" 버전도 있습니다(https://play.google.com/store/apps/details?id=com.microsoft.scmx\u0026hl=en\u0026gl=US), 하지만 이는 현재 글의 범위를 벗어납니다.\n\n마지막으로, 2021년부터 \"Windows Defender Antivirus\"는 더 큰 Microsoft Defender 브랜드의 일부로 속합니다. 그 브랜드에는 \"Microsoft Defender 취약점 관리\", \"Microsoft Defender for Cloud Apps\", \"Microsoft Defender for Identity\", \"Microsoft Defender Endpoint\" 등이 포함됩니다(https://en.wikipedia.org/wiki/Microsoft_Defender_Antivirus) — 앞으로의 글에서 이에 대해 더 자세히 살펴볼 예정입니다.\n\n다음 글에서 만나요 ;-) 트위터에서 저를 팔로우할 수 있습니다 — @boutnaru (https://twitter.com/boutnaru). 또한, 제 다른 글은 미디엄에서 읽을 수 있습니다 — https://medium.com/@boutnaru. 무료 eBook은 https://TheLearningJourneyEbooks.com에서 찾을 수 있습니다.\n\n\n\n![2024-05-16-TheWindowsSecurityJourneyWindowsDefenderAntivirus_0.png](/assets/img/2024-05-16-TheWindowsSecurityJourneyWindowsDefenderAntivirus_0.png)","ogImage":{"url":"/assets/img/2024-05-16-TheWindowsSecurityJourneyWindowsDefenderAntivirus_0.png"},"coverImage":"/assets/img/2024-05-16-TheWindowsSecurityJourneyWindowsDefenderAntivirus_0.png","tag":["Tech"],"readingTime":2},{"title":"맥OS에서 Expo로 빌드하는 동안 권한 문제 해결하기 개인 경험 공유","description":"","date":"2024-05-16 03:56","slug":"2024-05-16-SolvingPermissionIssuesinmacOSWhileBuildingwithExpoAPersonalExperience","content":"\n\n# 소개\n\nReact Native 프로젝트에서 작업하는 개발자로서, macOS에서 네이티브 모듈 및 종속성을 다룰 때 허가 관련 문제에 직면할 수 있습니다. 최근에는 Expo 프로젝트를 위한 네이티브 iOS 폴더를 생성하는 동안 이 문제에 직면했습니다. 제 경험의 단계별 설명과 문제를 해결한 방법을 소개하겠습니다. 여러분에게도 도움이 되기를 바랍니다.\n\n# 문제\n\nmacOS에서 Expo 프로젝트의 네이티브 환경을 설정하는 동안 여러 문제를 겪게 되었습니다.\n\n\n\n- 초기 설정: 내 맥에 Node.js, Expo 또는 EAS CLI가 설치되지 않았습니다 (새 맥북).\n- sudo로 설치: Expo 및 EAS를 설치하기 위해 sudo를 사용했더니 소유권 관련 문제가 발생했습니다.\n- 권한 오류: 이 문제로 인해 CocoaPods 및 기타 종속성이 성공적으로 설치되는 것을 방해하는 권한 오류가 발생했습니다.\n\n# 문제 해결 단계\n\n## 단계 1: 문제 파악\n\nnpm 패키지를 설치할 때 sudo를 사용하면 파일이 루트 사용자에 의해 소유된 상태가 될 수 있습니다. 이 소유권 불일치로 인해 이후에 해당 패키지를 실행하거나 수정할 때 권한 오류가 발생할 수 있습니다. 문제를 식별하고 해결한 방법은 다음과 같습니다.\n\n\n\n## 단계 2: 전역으로 설치된 패키지 제거하기\n\n먼저, sudo를 사용하여 설치된 전역 패키지를 제거해야 했어요.\n\n```js\nsudo npm uninstall -g expo-cli eas-cli\n```\n\n## 단계 3: 디렉토리 소유권 변경하기\n\n\n\n저는 권한 문제를 피하기 위해 프로젝트 디렉토리를 내 사용자 계정의 소유로 설정했어요.\n\n터미널을 열어주세요: 프로젝트가 있는 디렉토리로 이동해주세요.\n\n소유권 변경:\n\n```bash\nsudo chown -R 당신의사용자이름:당신의그룹 /Users/ociuz/Documents/nss-kuwait\n```\n\n\n\n## 단계 4: Expo와 EAS CLI를 sudo 없이 설치하기\n\n다음으로, sudo를 사용하지 않고 Expo와 EAS CLI를 다시 설치했습니다.\n\n```js\nnpm install -g expo-cli eas-cli\nrm -rf /Users/{username}/.npm/_cacache/content-v2/sha512/5b/e8\n```\n\n\n\n두 번째 명령어는 sudo를 사용하여 생성된 캐시와 파일을 제거하는 것입니다. 이를 본인의 경로로 교체해야 합니다.\n\n## 단계 5: 엑스포 미리 빌드\n\n그런 다음 미리 빌드를 실행하세요.\n\n```js\nnpx expo prebuild\n```\n\n\n\n맨 처음에는 CocoaPods 설치가 실패했지만 재시도에서 성공했습니다.\n\n이제 android와 ios 폴더가 생겼을 것입니다.\n\n# 결론\n\n위 단계를 따라서 Expo를 사용하면서 macOS에서 권한 문제를 성공적으로 해결했습니다. 올바른 소유권을 보장하고 개발 도구 설치 시 sudo를 피하는 것이 원활한 설정 과정의 핵심이었습니다. 유사한 문제를 겪으면 이 단계를 시도하고 환경이 올바르게 구성되었는지 확인하세요.\n\n\n\n# 추가 팁\n\n- npm 사용 시 sudo 사용 피하기: 전역으로 npm 패키지를 설치할 때는 sudo 사용을 피하는 것이 일반적으로 좋은 관행입니다. 대신, npm을 홈 디렉터리에 패키지를 설치하도록 구성하세요.\n- 권한 정기적으로 확인하기: 프로젝트 디렉토리의 권한을 주기적으로 확인하여 예상치 못한 문제를 방지하세요.\n- 버전 관리 사용하기: Git과 같은 버전 관리 시스템을 사용하여 데이터 손실을 방지하고 변경 사항을 추적하세요.\n\n이 가이드가 당신의 개발 작업에서 권한 문제를 탐색하고 해결하는 데 도움이 되기를 바라며, 질문이나 추가 팁이 있다면 아래 댓글에서 자유롭게 공유해 주세요!","ogImage":{"url":"/assets/img/2024-05-16-SolvingPermissionIssuesinmacOSWhileBuildingwithExpoAPersonalExperience_0.png"},"coverImage":"/assets/img/2024-05-16-SolvingPermissionIssuesinmacOSWhileBuildingwithExpoAPersonalExperience_0.png","tag":["Tech"],"readingTime":2},{"title":"리눅스에서 DNS 서버 설정하기","description":"","date":"2024-05-16 03:55","slug":"2024-05-16-SettingupaDNSserveronLinux","content":"\n\n오늘날, 우리가 인터넷을 브라우징하고 웹 페이지를 요청할 때마다, 브라우저에 입력한 웹 페이지 이름을 해당 IP 주소로 변환하기 위해 도메인 이름 시스템(DNS)에 의존하게 됩니다. 이를 통해 우리는 원하는 웹 페이지에 액세스할 수 있게 됩니다. DNS가 없으면 여러 웹 서버와 연결된 다양한 IP 주소를 인간의 두뇌가 기억하기가 어려워 인터넷 사용이 매우 어려울 것입니다. 이 글에서는 CentOS 8을 이용하여 DNS 서버를 설정하고 이름 해결 과정을 탐험하는 방법을 배우겠습니다. 시작해봅시다.\n\n## 시나리오\n\n우리는 현재 회사 EOS 소유의 사설 네트워크에 연결되어 있습니다. 이 네트워크 내에는 웹 서버를 호스팅하는 Metasploitable 이라는 서버가 있습니다. 그러나 현재 이 웹 서버에 접속하기 위해서는 Metasploitable 서버의 IP 주소에 의존하고 있습니다. 따라서 우리의 목표는 이 웹 서버에 도메인 이름을 사용하여 액세스할 수 있는 것입니다. 이 시나리오는 아래 그림으로 더 자세히 설명됩니다:\n\n![DNS 서버 설정하기](/assets/img/2024-05-16-SettingupaDNSserveronLinux_0.png)\n\n\n\n# DNS 설정하기\n\n첫 번째 단계는 DNS 리졸버로 사용할 서버에 BIND와 필수 유틸리티를 설치하는 것입니다.\n\n```js\n# yum install bind bind-utils -y\n```\n\n설치가 완료되면 다음 명령어를 사용하여 설치된 BIND 버전을 확인할 수 있습니다.\n\n\n\n```js\n# 이름 -v\n```\n\n이제 BIND의 주 구성 파일을 편집할 수 있습니다. 그러나 그 전에 예방 차원으로 파일의 백업을 만드는 것이 좋습니다. 구성에서는 우리 네트워크(192.168.3.0/24)에서의 쿼리만 허용하고 재귀 모드를 활성화하여 서버가 캐싱을 수행할 수 있도록 할 것입니다.\n\n```js\n# cp /etc/named.conf /etc/named/conf.bak\n# vi named.conf\n\n// 아래와 같이 편집 :\n//listen-on port 53 { 127.0.0.1; };\n//listen-on-v6 port 53 { ::1; };\n\nallow-query { localhost; 192.168.3.0/24; }; \nrecursion yes;\n```\n\n## 포워드 및 리버스 존 생성하기\n\n\n\n전방존은 호스트 이름을 IP 주소로 해석하고, 역방존은 IP 주소를 호스트 이름으로 해석할 수 있게 합니다. 이를 구성하려면 다음 라인을 named.conf 파일 끝에 추가해야 합니다.\n\n```js\n// 전방존\nzone \"eos.net\" IN {\n     type master;\n     file \"eos.net.db\";\n     allow-update { none; };\n     allow-query { any; };\n};\n\n// 역방존\nzone \"3.168.192.in-addr.arpa\" IN {\n     type master;\n     file \"eos.net.rev\";\n     allow-update { none; };\n     allow-query { any; };\n};\n```\n\n- type: 존에 대한 서버 역할을 지정합니다.\n- file: 두 존에 사용되는 파일을 지정합니다.\n- allow-update: 동적 DNS 업데이트를 수행할 수 있는 호스트 시스템을 지정합니다. 이 경우 특정 호스트를 지정하지 않았습니다.\n\n## 존 파일 만들기\n\n\n\n우리는 이미 위에서 전방 존(eos.net.db)과 역방 존(eos.net.rev)을 모두 지정했습니다. 이제 /var/named 디렉토리 안에 이러한 파일들을 만들어야 합니다. 전방 존부터 시작해봅시다. 아래와 같이 정보를 입력하여 파일을 만들어 주세요:\n\n```js\n# nano /var/named/eos.net.db\n$ORIGIN eos.net.\n$TTL 86400\n@ IN SOA server.eos.net. admin.eos.net. (\n    2024051300 ;시리얼\n    3600 ;새로고침\n    1800 ;재시도\n    604800 ;만료\n    86400 ;최소\n)\n\n; 네임 서버 정보\n@ IN NS server.eos.net.\n\n; 네임 서버용 IP 주소\nserver IN A 192.168.3.210\n\n; 다음 호스트 이름을 위한 A 레코드\nmetasploitable IN A 192.168.3.195\ndns IN A 192.168.3.210\n\n; CNAME 레코드\ndns-primary IN CNAME server.eos.net.\n```\n\n이제, 역방 존은 다음과 같이 나타나야 합니다:\n\n```js\n# nano /var/named/eos.net.rev\n$ORIGIN 3.168.192.in-addr.arpa.\n$TTL 86400\n@ IN SOA server.eos.net. admin.eos.net. (\n                                            2024051300 ;시리얼\n                                            3600 ;새로고침\n                                            1800 ;재시도\n                                            604800 ;만료\n                                            86400 ;최소 TTL\n)\n; 네임 서버 정보\n@ IN NS server.eos.net.\nserver     IN      A       192.168.3.210\n\n; 네임 서버에 대한 역방 조회\n210 IN PTR server.eos.net.\n\n; IP 주소에 대한 호스트 이름에 대한 PTR 레코드\n195      IN      PTR     metasploitable.eos.net.\n```\n\n\n\n양방향 및 역방향 존이 모두 순서대로 되어 있습니다. 이제 파일에 적절한 권한을 설정해야 합니다:\n\n```js\n# chown named:named /var/named/eos.net.db\n# chown named:named /var/named/eos.net.rev\n```\n\n이제 우리의 설정이 올바른지 확인해야 합니다. 이를 위해 named-checkconf 및 named-checkzone 명령어를 사용할 수 있습니다.\n\n```js\n# named-checkconf\n# named-checkzone eos.net eos.net.db\n# named-checkzone 3.168.192.in-addr.arpa eos.net.rev\n```\n\n\n\n\n![DNS server setup](/assets/img/2024-05-16-SettingupaDNSserveronLinux_1.png)\n\n이제 named 데몬을 다시 시작해야 합니다:\n\n```shell\n# systemctl start named.service\n# chkconfig named on\n```\n\n## DNS 서비스 테스트\n\n\n\n\nWindows 호스트에서는 nslookup 명령을 사용하여 호스트인 Metasploitable의 전방 및 후방 존을 테스트할 수 있습니다. 우리는 호스트 Metasploitable의 DNS 정보를 검색할 수 있는 것을 확인할 것입니다.\n\n![이미지](/assets/img/2024-05-16-SettingupaDNSserveronLinux_2.png)\n\n## 결론\n\n이 게시물에서는 BIND 소프트웨어를 사용하여 Linux 환경에 DNS 서비스를 설정하는 과정을 탐구했습니다. DNS는 인터넷의 기본 구성 요소이며, 그 중요성을 과장할 수 없습니다. 시스템 관리자로서 Linux 환경에서 서비스를 배포할 수 있는 능력을 갖추고 DNS를 이해하는 것이 특히 중요합니다. 이 게시물이 도움이 되었다면 박수를 치거나 댓글을 남기고 더 많은 콘텐츠를 위해 팔로우해 주세요. 감사합니다!","ogImage":{"url":"/assets/img/2024-05-16-SettingupaDNSserveronLinux_0.png"},"coverImage":"/assets/img/2024-05-16-SettingupaDNSserveronLinux_0.png","tag":["Tech"],"readingTime":4},{"title":"리액트 네이티브 인앱 구매 iOS - 2부","description":"","date":"2024-05-16 03:53","slug":"2024-05-16-ReactNativeIn-AppPurchasesiOSPart2","content":"\n\n## iOS에서 인앱 구매 구성\n\n![image](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_0.png)\n\nPart 1에서는 인앱 구매, 그 유형 및 그 이점에 대해 배웠습니다.\n\n이 블로그에서는 인앱 구매의 유형을 구독과 인앱 구매로 분류합니다.\n\n\n\n구독에는 자동 갱신 및 비갱신 타입 두 가지가 있습니다.\n\n![Auto-Renewable Subscriptions](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_1.png)\n\n## 자동 갱신 구독\n\n\n\n다시 마켓에서 구독 그룹을 설정해야 합니다.\n\n![이미지](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_2.png)\n\n\n\n2. 구독 만들기\n\n그룹을 형성한 후 제품을 만듭니다. 그룹으로 이동하여 \"생성\" 버튼이나 이미 구독이 있는 경우 플러스 (+) 아이콘을 클릭합니다.\n\n![image](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_3.png)\n\n구독을 성공적으로 생성한 후에는 필요한 정보를 제공하세요. 이 정보에는 다음이 포함됩니다:\n\n\n\n구독 기간: 구독 만료 전에 기간을 지정합니다.\n\n가족 공유: 이를 활성화하면 다른 가족 구성원이 구독을 다시 구매하지 않고 사용할 수 있습니다. 한 번 활성화되면 비활성화할 수 없음을 유념하세요.\n\n![이미지](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_4.png)\n\n3. 가능 여부\n\n\n\nApp Store에서 지원하는 175개 국가나 지역에서 구독을 이용할 수 있습니다.\n\n![image](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_5.png)\n\n4. 구독 가격\n\n국가별로 가격을 구성하세요. 국가를 선택한 다음 목록에서 가격을 선택합니다. 가격은 수동으로 추가할 수 없습니다.\n\n\n\n\u003cimg src=\"/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_6.png\" /\u003e\n\n\"다음\"을 클릭한 후에는 필요에 따라 각 국가의 비용을 확인하고 조정할 수 있습니다.\n\n5. 세금 카테고리 설정\n\n앱의 카테고리에 해당하는 세금 카테고리를 선택하여 구독 가격에 영향을 미칩니다.\n\n\n\n마크다운 형식으로 표 태그를 변경해주세요.\n\n\n\u003cimg src=\"/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_7.png\" /\u003e\n\n6. App Store Localization\n\n다른 지역이나 국가의 사용자를 위해 로컬화된 제품 정보를 제공하세요. 디스플레이 이름과 설명을 포함합니다.\n\n\u003cimg src=\"/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_8.png\" /\u003e\n\n\n\n\n7. 앱 스토어 프로모션 및 리뷰 정보\n\n프로모션을 위해, 고객이 제공 코드를 교환할 때 앱 제품 페이지에 나타날 이미지(1024 x 1024 픽셀 이하)를 업로드하십시오.\n\n리뷰 섹션의 스크린샷은 애플 리뷰 전용이며 앱 스토어에 표시되지 않습니다.\n\n\u003cimg src=\"/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_9.png\" /\u003e\n\n\n\n위 단계를 완료한 후 \"저장\"을 눌러 제품을 추가하세요.\n\n## 비갱신 구독\n\n비갱신 구독은 기간이 끝나면 만료됩니다. 계속 사용하려면 다시 구매해야 합니다. 예시로는 Weather Underground, Pocket Casts, Nova Launcher 등이 있습니다.\n\n비갱신 구독을 추가하려면:\n\n\n\n1. 구독 관리\n\"관리\"를 클릭하여 대시보드에 액세스하면 비갱신 구독을 추가할 수 있습니다.\n\n![이미지](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_10.png)\n\n2. 비갱신 구독 생성\n플러스 (+) 아이콘을 선택하여 새 구독을 위한 참조 이름 및 제품 ID를 추가하십시오. 제품을 만든 후에는 해당 정보를 볼 수 있고 수정할 수 있습니다.\n\n![이미지](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_11.png)\n\n\n\n제품을 생성한 후에는 해당 정보를 확인하고 수정할 수 있습니다.\n\n![product_image](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_12.png)\n\n3. 가용성\n\nApp Store에서 지원하는 175개 국가나 지역에서 구독을 이용할 수 있습니다.\n\n\n\n이미지 태그를 Markdown 형식으로 변경해주세요.\n\nmd\n![이미지](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_13.png)\n\n\n4. 가격 일정\n\n가격을 구독과 국가 요율에 기반하여 설정하세요.\n\n![이미지](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_14.png)\n\n\n\n5. 세금 카테고리 설정\n\n구독 가격에 영향을 미치는 앱에 적합한 세금 카테고리를 선택하세요.\n\n![이미지](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_15.png)\n\n6. 앱스토어 지역화\n\n\n\n구독을 위한 표시 이름과 설명을 제공해주세요. 구독 구매 팝업 상자에 표시됩니다.\n\n![이미지](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_16.png)\n\n7. 앱 스토어 프로모션 및 리뷰 정보\n\n앱 스토어 프로 motion을 위한 이미지를 업로드하고, Apple 리뷰를 위한 스샷을 제공해주세요.\n\n\n\n\n![Image](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_17.png)\n\n# 앱 내 구매\n\n앱 내 구매에는 소비 가능 및 비소비 가능 두 가지 유형이 있습니다.\n\n- 소비 가능은 사용 후 사라지고 다시 구매해야하는 항목을 구매하고 사용할 수 있는 것을 의미합니다.\n- 비소비 가능은 사용자가 한 번 구매하면 영구적으로 사용할 수 있는 것을 의미합니다.\n\n\n\n\n앱 스토어 커넥트 계정으로 이동해서 앱을 선택하고 MONETIZATION 아래의 In-App Purchases 섹션으로 이동해주세요.\n\n![이미지](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_18.png)\n\n1. 인앱 구매 생성하기\n\n제품을 추가하려면 플러스(+) 아이콘을 클릭하고, 소비형 또는 비소비형 중에서 선택해주세요. 참조 이름과 제품 ID를 입력해주세요.\n\n\n\n\n![이미지](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_19.png)\n\n2. Family Sharing and Availability\n\nFor non-consumable items, you can enable Family Sharing, allowing users to share the purchase across family members’ accounts. Once enabled, this cannot be disabled.\n\nYou can also choose to make your in-app purchases available in any supported country or region.\n\n\n\n\n\u003cimg src=\"/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_20.png\" /\u003e\n\n3. 인앱 구매 가격 설정\n\n가격을 설정하려면 먼저 나라를 선택하세요. 가격은 수동으로 설정할 수 없고 드롭다운 목록에서 선택해야 합니다. 필요에 따라 다른 국가에 대한 가격을 조정하세요.\n\n\u003cimg src=\"/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_21.png\" /\u003e\n\n\n\n4. 세금 카테고리 설정\n\n앱의 세금 카테고리를 선택하여 인앱 구매 가격에 영향을 줍니다.\n\n![이미지](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_22.png)\n\n5. 앱 스토어 로컬라이제이션\n\n\n\n만약 당신의 앱이 다른 지역이나 국가의 사용자를 대상으로 한다면, 디스플레이 이름과 설명을 포함한 현지화된 제품 정보를 제공해주세요.\n\n![이미지](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_23.png)\n\n6. 앱 스토어 홍보 및 리뷰 정보\n\n프로모션을 위해, 고객이 할인 코드를 교환할 때 당신의 앱 제품 페이지에 나타날 이미지(1024 x 1024 픽셀 이하)를 업로드해주세요.\n\n\n\n리뷰 섹션에 표시되는 스크린샷은 Apple 리뷰 전용이며 앱 스토어에는 표시되지 않습니다.\n\n![Image](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_24.png)\n\n인앱 구매를 성공적으로 정의한 후, 빌링 라이브러리가 포함된 빌드를 업로드하여 이를 활성화하세요.\n\n# 빌링 용서 기간\n\n\n\n결제 유예 기간은 구독자가 선택한 기간 동안 요금 청구 문제로 구독이 만료되더라도 당신의 앱의 유료 콘텐츠에 액세스할 수 있도록 합니다.\n\n![이미지](/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_25.png)\n\n# 결론\n\n이 섹션에서는 구독 및 인앱 구매 제품을 만드는 단계와 결제 실패에 대한 유예 기간 설정에 대해 개요를 제시했습니다.\n\n\n\n제 3부에서는 안드로이드 앱 내 구매 및 구독을 통합하는 단계를 다룰 것입니다.","ogImage":{"url":"/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_0.png"},"coverImage":"/assets/img/2024-05-16-ReactNativeIn-AppPurchasesiOSPart2_0.png","tag":["Tech"],"readingTime":5},{"title":"테라폼을 사용하여 다양한 쿠버네티스 리소스 생성하기","description":"","date":"2024-05-16 03:50","slug":"2024-05-16-CreatevariousKubernetesresourcesusingTerraform","content":"\n\n\u003cimg src=\"/assets/img/2024-05-16-CreatevariousKubernetesresourcesusingTerraform_0.png\" /\u003e\n\n테라폼을 사용하여 쿠버네티스(Kubernetes) 리소스를 생성하는 것은 인프라를 코드로 정의하는 것을 의미합니다. 이를 통해 배포하는 과정에서 자동화, 버전 관리 및 재현성이 가능해집니다.\n\n여기서는 테라폼을 사용하여 일반적인 쿠버네티스 리소스인 네임스페이스, 디플로이먼트 및 서비스를 생성하는 방법에 대해 안내하겠습니다.\n\n## 테라폼이 쿠버네티스 클러스터 프로비저닝에 좋은 도구인 이유:\n\n\n\n- Terraform은 사용자가 Kubernetes 클러스터 정의를 코드로 유지할 수 있게 해줍니다.\n- 하부 인프라 구성을 위해 동일한 선언적 구문을 사용합니다.\n- Terraform을 사용하면 변수를 통해 Kubernetes 클러스터를 수정할 수 있습니다.\n- 변경 사항이 적용되기 전에 Kubernetes 클러스터에 대한 수정 사항을 먼저 미리 확인할 수 있는 dry-run 기능이 있습니다.\n- Terraform의 중요한 이점 중 하나는 Kubernetes 프로비저닝 및 그에 따른 응용 프로그램 배포에 동일한 구성 언어를 사용할 수 있는 능력입니다.\n- Terraform을 사용하면 API를 확인할 필요 없이 pod 및 리소스를 생성, 업데이트 및 삭제하는 데 하나의 명령어만 필요합니다.\n- Terraform은 리소스 간의 관계를 인식하고 코드에서 인프라를 모듈화합니다.\n- Terraform은 제품 출시 시간을 단축시키며 재해 복구 시간과 릴리스 문제에 도움을 줍니다.\n\n## 준비 사항:\n\n- 가동 중인 Kubernetes 클러스터\n- Terraform 및 kubectl 설치 및 구성\n\n이제 자원을 생성해 봅시다.\n\n\n\n## 단계 1: Terraform 구성 설정하기\n\n- Terraform 프로젝트 디렉토리를 만듭니다.\n\n```js\nmkdir terraform-k8s \u0026\u0026 cd terraform-k8s\n```\n\n- Kubernetes 공급자를 정의하는 provider.tf 파일을 만듭니다.\n\n\n\n```js\nterraform {\n  required_providers {\n    kubernetes = {\n      source = \"hashicorp/kubernetes\"\n    }\n  }\n}\n\nprovider \"kubernetes\" {\n  config_path = \"~/.kube/config\"\n}\n```\n\n## Step 2: Define Kubernetes Resources\n\n- Create a `namespace.tf` file to define a Kubernetes namespace.\n\n```js\nresource \"kubernetes_namespace\" \"demo\" {\n  metadata {\n    name = \"demo-namespace\"\n  }\n}\n```\n\n\n\n- 애플리케이션을 배포하기 위한 deployment.tf 파일을 생성하세요.\n\n```js\nresource \"kubernetes_deployment\" \"demo\" {\n  metadata {\n    name = \"demo-deployment\"\n    namespace = kubernetes_namespace.example.metadata[0].name\n  }\n\n  spec {\n    replicas = 3\n    selector {\n      match_labels = {\n        app = \"demo\"\n      }\n    }\n\n    template {\n      metadata {\n        labels = {\n          app = \"demo\"\n        }\n      }\n\n      spec {\n        container {\n          image = \"nginx:latest\"\n          name  = \"demo-deployment\"\n        }\n      }\n    }\n  }\n}\n```\n\n- 배포를 노출하기 위한 service.tf 파일을 생성하세요.\n\n```js\nresource \"kubernetes_service\" \"demo\" {\n  metadata {\n    name = \"demo-service\"\n    namespace = kubernetes_namespace.example.metadata[0].name\n  }\n\n  spec {\n    selector = {\n      app = \"example\"\n    }\n\n    port {\n      port        = 80\n      target_port = 80\n    }\n\n    type = \"LoadBalancer\"\n  }\n}\n```\n\n\n\n- 구성 맵을 정의하는 configmap.tf 파일을 작성하세요.\n\n```js\nresource \"kubernetes_config_map\" \"demo\" {\n  metadata {\n    name = \"demo-config\"\n    namespace = kubernetes_namespace.example.metadata[0].name\n  }\n\n  data = {\n    \"config.json\" = jsonencode({\n      \"key\" = \"value\"\n    })\n  }\n}\n```\n\n- Kubernetes 시크릿을 정의하는 secret.tf 파일을 작성하세요.\n\n```js\nresource \"kubernetes_secret\" \"demo\" {\n  metadata {\n    name = \"demo-secret\"\n    namespace = kubernetes_namespace.example.metadata[0].name\n  }\n\n  data = {\n    \"password\" = base64encode(\"supersecret\")\n  }\n}\n```\n\n\n\n- PersistentVolumeClaim을 정의하는 pvc.tf 파일을 만들어보세요.\n\n```javascript\nresource \"kubernetes_persistent_volume_claim\" \"demo\" {\n  metadata {\n    name = \"demo-pvc\"\n    namespace = kubernetes_namespace.example.metadata[0].name\n  }\n\n  spec {\n    access_modes = [\"ReadWriteOnce\"]\n    resources {\n      requests = {\n        storage = \"10Gi\"\n      }\n    }\n  }\n}\n```\n\n- 이제, 배포 파일을 수정하여 ConfigMap과 Secret을 마운트하도록 해봅시다.\n\n```javascript\nresource \"kubernetes_deployment\" \"demo\" {\n  metadata {\n    name = \"demo-deployment\"\n    namespace = kubernetes_namespace.example.metadata[0].name\n  }\n\n  spec {\n    replicas = 3\n    selector {\n      match_labels = {\n        app = \"demo\"\n      }\n    }\n\n    template {\n      metadata {\n        labels = {\n          app = \"demo\"\n        }\n      }\n\n      spec {\n        container {\n          image = \"nginx:latest\"\n          name  = \"demo\"\n\n          volume_mount {\n            mount_path = \"/etc/config\"\n            name       = \"config\"\n          }\n\n          volume_mount {\n            mount_path = \"/etc/secret\"\n            name       = \"secret\"\n            read_only  = true\n          }\n        }\n\n        volume {\n          name = \"config\"\n          config_map {\n            name = kubernetes_config_map.example.metadata[0].name\n          }\n        }\n\n        volume {\n          name = \"secret\"\n          secret {\n            secret_name = kubernetes_secret.example.metadata[0].name\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n\n\n## 단계 3: 작업 디렉터리 초기화\n\n- 작업 디렉터리에서 terraform init 명령을 실행하십시오. 이 명령은 필요한 모든 공급자를 다운로드하고 모든 모듈을 초기화하며 백엔드도 초기화합니다.\n\n## 단계 4: Terraform 실행 계획 생성\n\n- 작업 디렉터리에서 terraform plan 명령을 실행하십시오. 이 명령은 실행 계획을 제공합니다.\n\n\n\n## 단계 5: Terraform apply 실행\n\n- 작업 디렉토리에서 terraform apply 명령을 실행하면 AWS에 필요한 모든 리소스가 생성됩니다.\n\n## 단계 6: 리소스 확인\n\n- Terraform이 변경 사항을 적용한 후, 리소스가 올바르게 배포되었는지 확인하세요.\n\n\n\n```js\nkubectl get all --namespace=demo-namespace\n```\n\n여기까지만 하면, 이제 Terraform을 사용하여 다양한 K8s 리소스를 생성하는 방법을 배웠습니다. 이제 이를 사용하여 필요에 따라 수정하고 실험할 수 있습니다.\n\n이 안내서가 도움이 되었다면 👏 버튼을 클릭해 주시고 댓글을 자유롭게 남겨주세요.\n\n이와 같은 이야기를 더 보시려면 팔로우 해주세요 😊\n\n\n\n\n# 스택데믹 🎓\n\n끝까지 읽어 주셔서 감사합니다. 떠나시기 전에:\n\n- 작가를 클랩하고 팔로우해 주시면 감사하겠습니다! 👏\n- 팔로우하기: X | LinkedIn | YouTube | Discord\n- 다른 플랫폼 방문하기: In Plain English | CoFeed | Venture | Cubed\n- 알고리즘 콘텐츠를 다루도록 강요하는 블로그 플랫폼에 지쳤나요? Differ를 시도해보세요\n- 더 많은 콘텐츠는 Stackademic.com에서 확인하세요","ogImage":{"url":"/assets/img/2024-05-16-CreatevariousKubernetesresourcesusingTerraform_0.png"},"coverImage":"/assets/img/2024-05-16-CreatevariousKubernetesresourcesusingTerraform_0.png","tag":["Tech"],"readingTime":6},{"title":"테크오라마 2024 하이라이트","description":"","date":"2024-05-16 03:49","slug":"2024-05-16-Techorama2024Highlights","content":"\n\n지난 주에 Kapuani를 대표하여 동료 Jan과 함께 Antwerp의 Kinepolis에서 개최된 Techorama 2024에 참석한 경험은 대단했어요. 이곳에서 내가 가장 좋아하는 발표 몇 가지를 소개하려고 해요 (특정한 순서는 없어요).\n\n## Azure 아키텍처: 현명하게 선택하기\n\n— Rik Hepworth\n\n하루를 멋지게 시작했어요. Rik의 무기는 화이트보드이었어요. 이 매우 인터랙티브한 세션에서 우리는 데이터부터 호스팅, 보안 등 모든 측면을 다뤘어요. 저는 상상 속 애플리케이션을 Azure Container Apps에 호스팅하는 건의를 했는데, Rik도 매우 좋아했던 아이디어였어요.\n\n\n\n대부분의 내용을 알고 있었지만, 다시 확인하고 커뮤니티 동료들과 확인하여 올바른 방향으로 나아가고 있는지 확인하는 것은 좋은 일이에요. Rik이 우리에게 제안해 준 새로운 시각 중 하나는 API 관리를 사용하여 외부 서비스로의 요청을 프록시하는 것인데, 우리는 이를 곧 구현할 예정입니다.\n\n## 안녕하세요 Azure Kubernetes Service! 어서오세요 Azure Container Apps!\n\n— Johnny Hooyberghs 작성\n\n처음부터 Azure Container Apps 플랫폼을 지원하고 채택해 왔습니다. Johnny도 마찬가지로 이를 수용하고 훌륭한 서비스에 대해 깊이 파고들어 이야기했어요. 그는 매우 중요한 질문을 던졌습니다:\n\n\n\n팀의 소형부터 중간 규모까지 다양한 팀이 쿠버네티스를 채택하지만 그 결정의 결과를 충분히 고려하지 않고 있습니다. 쿠버네티스 플랫폼을 사랑하고 많은 전문 지식을 쌓아왔지만, 우리는 고객들에게 먼저 대안을 고려할 것을 권장합니다.\n\nJohnny가 제안한 것처럼, Azure Container Apps는 쿠버네티스에 좋은 대안입니다. 이 서비스는 쿠버네티스 플랫폼 위에 구축된 추상화 계층이며, KEDA, Dapr, Envoy 등의 기타 오픈 소스 도구들과 통합되어 있습니다. 비교적 간단하며 팀의 속도를 가속화시키며 기본 인프라의 유지보수가 필요하지 않습니다.\n\n심지어 .Net Aspire에 대해 자세히 살펴보았는데, 로컬 개발에 적합한 훌륭한 도구이며, Azure 개발자 CLI(azd)를 사용하여 Azure Container Apps로 배포할 수 있습니다(비 프로덕션 환경에서). 데모/콘셉트 증명 시나리오에서 매우 편리합니다.\n\nMarkdown 포맷의 표는 아래와 같습니다:\n\n| 기존 방식 | Kubernetes | Azure Container Apps |\n|--------------|--------------|---------------------|\n| 특징 | 복잡함, 전문 지식 필요 | 간단함, 유지보수 필요 X |\n| 통합된 도구 | KEDA, Dapr, Envoy 등 | - |\n\n\n\n## 남은 부분 이론 소개\n\n— Barry O'Reilly\n\n남은 부분 이론은 우리에게 소프트웨어 시스템을 과학적 방법으로 설계하고 복잡성 과학을 활용하여 불확실성을 관리하는 것을 디자인 프로세스의 기본 요소로 만드는 새로운 관점을 제공했습니다.\n\n결국 이 설계자들도 그것을 몰랐지만, Barry가 조사한 결과, 그들을 다른 사람들과 구분 짓는 요소를 발견했습니다. 바로 그들이 복잡성과 불확실성에 접근하는 방식이었습니다.\n\n\n\n이론적 배경 이후에, 그는 전기 자동차 충전소 형태의 훌륭한 예시를 제시했습니다. 이 예시에서 그는 몇 가지 간단한 질문이 시스템에 영향을 미칠 수 있는 특정 `스트레서스(stressors)`를 밝힐 수 있다는 것을 보여주었습니다. 더 많은 스트레서스에 대처할수록 시스템이 더 강건해지고, 미래에 문제가 발생해도 이미 해결책이 있을 수 있다는 점을 깨달을 겁니다.\n\n## Microsoft Azure API Management을 활용한 견고한 API Landscape 구축\n\n— Tom Kerkhove 작성\n\n우리는 Tom Kerkhove를 오랫동안 큰 팬으로 지내 왔습니다. 그는 Kubernetes 이벤트 중심 자동 확장(KEDA) 오픈 소스 프로젝트를 유저들이 일상적으로 사용합니다. 따라서, Techorama에서 그를 발표하고 있는 걸 보게 되어 기쁩니다.\n\n\n\n이번 실습에서 Tom은 Azure Api Management가 제공하는 복원력 기능에 대해 깊이 파고들었습니다. 그는 여러 지역을 지원하는 APIM 인스턴스를 설정하는 방법과, 여러 지역에 걸쳐 Azure가 제공하는 로드 밸런싱을 사용하거나 트래픽 관리자 인스턴스와 각 배포된 게이트웨이 인스턴스의 지역 엔드포인트를 결합하여 사용자 정의 규칙 또는 가중치를 생성할 수 있다는 것을 보여 주었습니다.\n\nTom은 Api Management 정책 내의 속도 제한 및 회로 차단 기능을 보여 주었으며, Azure Load Testing 도구를 사용하여 수백만 건의 요청을 몇 분 동안 시뮬레이션하는 데모를 제공했습니다.","ogImage":{"url":"/assets/img/2024-05-16-Techorama2024Highlights_0.png"},"coverImage":"/assets/img/2024-05-16-Techorama2024Highlights_0.png","tag":["Tech"],"readingTime":3},{"title":"백엔드 기본 사항","description":"","date":"2024-05-16 03:46","slug":"2024-05-16-BACK-ENDBASICS","content":"\n\n## Node.js와 PostgreSQL 데이터베이스를 활용한 RESTful API 및 AWS EC2 인스턴스 배포 기본\n\n![Image](/assets/img/2024-05-16-BACK-ENDBASICS_0.png)\n\n이 튜토리얼은 백엔드 개발의 특정 측면에 초점을 맞춥니다: Node.js를 사용하여 PostgreSQL 데이터베이스를 Docker에 호스팅하고 AWS EC2 인스턴스에 배포하는 RESTful API 생성.\n\n이 튜토리얼은 백엔드 개발의 모든 측면을 다루지는 않지만 이러한 구체적인 구성 요소 내에서 범위를 유지할 것입니다.\n\n\n\n# 백엔드\n\n과도하게 단순화해서 말하면, 모든 애플리케이션의 백엔드는 일반적으로 어떤 종류의 데이터 저장 시스템과 상호 작용하는 데이터 처리 작업을 포함합니다.\n\n백엔드는 여러 시스템으로 구성될 수 있습니다. 예를 들어, 마이크로 서비스 아키텍처에서는 수십 개의 API가 있는데, 각각이 특정 프로세스를 처리하여 프론트엔드 애플리케이션에서의 요청을 이행합니다.\n\n# API\n\n\n\nAPI(Application Programming Interface)은 사용자(프로그래머, 소비자 등)와 프로세스, 시스템 또는 도구 사이의 인터페이스를 만들기 위해 설계되었습니다.\n\n예를 들어, 운영 체제(OS, Operating System)의 많은 기능 중 하나는 프로그래머와 하드웨어에서 제공되는 리소스 사이의 인터페이스 역할을 하는 것입니다. OS는 각 CPU에서의 프로세스 실행 할당 작업을 추상화하여 프로그래머가 프로그램을 실행할 때마다 각각 구현할 필요가 없도록 합니다.\n\n따라서, API는 입력 값을 받아 이러한 값들을 처리하고 결과를 반환합니다. 이 결과는 API의 인터페이스에서 지정된 성공적인 실행을 나타내는 확인 메시지 또는 다른 출력일 수 있습니다.\n\n\n\n# HTTP/HTTPS\n\nHTTP (Hypertext Transfer Protocol)은 월드 와이드 웹(WWW)에서 클라이언트와 서버 간 메시지 교환을 위한 인터페이스로 작동합니다.\n\n시간이 지나면서 이 프로토콜은 적용 범위를 확대하며 인터넷 상의 클라이언트-서버 응용 프로그램 중 가장 널리 사용되는 프로토콜 중 하나가 되었습니다.\n\nHTTP는 세 가지 주요 구성 요소인 메서드, 헤더 및 상태 코드의 구조를 기반으로 합니다.\n\n\n\n메소드는 요청에서 실행할 수 있는 작은 일련의 작업입니다. 주로 사용되는 메소드에는 GET, POST, PUT 및 DELETE가 포함됩니다.\n\n![이미지](/assets/img/2024-05-16-BACK-ENDBASICS_2.png)\n\n이전에 설명한대로 HTTP는 어떤 종류의 애플리케이션에도 적용 가능하다는 특성을 갖고 있어 웹 페이지에 대한 작업이 추상화되고, 앞에서 언급한 메소드는 일반적으로 유사한 작업을 수행하기 위해 사용됩니다. 자세한 정보는 아래 표를 참조해주세요.\n\n헤더는 HTTP 요청에 추가 정보를 제공합니다. 표준 헤더에는 Content-Type: application/json과 같이 요청 본문에 보내는 객체가 JSON임을 지정하는 예와, 일반적으로 애플리케이션 수준에서 인증에 사용되는 Authorization Header와 같은 예가 있습니다.\n\n\n\n마침내 HTTP 통신에서 응답을 표준화하는 데 사용되는 상태 코드입니다.\n\n![이미지](/assets/img/2024-05-16-BACK-ENDBASICS_3.png)\n\n이들은 응답의 성격을 나타내는 카테고리로 그룹화됩니다. 예를 들어, 403 상태 코드는 'Forbidden(금지됨)'을 의미하며, 일반적으로 클라이언트가 제공한 권한이 서버에서 유효하지 않다고 판단될 때 사용됩니다. 상태 코드의 각 카테고리는 요청 처리에 대한 통찰력을 제공하며, 일반적으로 서버 측에서 디버깅과 응용프로그램 관리에 도움이 됩니다.\n\n# RESTful\n\n\n\nRESTful (Representational State Transfer)은 인터넷을 위한 아키텍처 스타일입니다. 이 스타일은 HTTP 프로토콜을 사용하고, 균일한 인터페이스, 클라이언트-서버, 상태를 저장하지 않음, 캐시 가능, 계층화된 시스템 다섯 가지 원칙을 따릅니다.\n\n- 명확히 정의된 인터페이스가 필수입니다.\n- 서버와 클라이언트는 독립적입니다.\n- 통신에 필요한 모든 정보는 요청 안에 포함되어 있습니다.\n- 캐싱이 필요한 경우 명시적으로 명시되어야 합니다.\n- 통신에 관여하는 구성 요소는 전체 시스템을 인식할 필요가 없습니다.\n\n자세한 설명은 제공된 참고 자료와 아래 비디오를 참조하십시오.\n\n# 구현\n\n\n\n친절한 톤으로 번역해드리겠습니다.\n\n보다 실용적인 관점을 제공하기 위해 RESTful API를 구현하고 사용 및 배포하는 방법을 보여드리겠습니다.\n\n이 구현에는 PostgreSQL 데이터베이스를 Docker에서 실행하고 Node.js를 사용하여 해당 데이터베이스에서 CRUD(Create, Retrieve, Update, Delete) 작업을 수행하는 것이 포함됩니다.\n\n튜토리얼을 더 잘 따를 수 있도록, 이미 구현된 예제 애플리케이션을 사용할 것이며 해당 예제는 GitHub 리포지토리에서 사용 가능합니다.\n\n먼저, 다음 애플리케이션을 다운로드해야 합니다:\n\n\n\n- 서버용으로 Node.js\n- HTTP 요청을 만들기 위해 Postman\n- PostgreSQL 데이터베이스를 실행하기 위해 Docker\n- 데이터베이스에서 SQL 쿼리를 실행하기 위해 DBeaver\n\n# DOCKER\n\n우선, PostgreSQL 데이터베이스를 만들어야 합니다. 이를 위해 아래 명령을 실행하는 Docker를 사용할 것입니다.\n\n```js\nsudo docker run --name postgresdb -p 5432:5432 -e POSTGRES_PASSWORD=postgres -e POSTGRES_USER=postgres -e POSTGRES_DB=postgres -d postgres\n```\n\n\n\n이 작업이 어떤 역할을 하는지 더 잘 이해하려면 Docker Hub의 이 문서를 읽어보세요.\n\n# 데이터베이스 테이블\n\n이제 DBeaver를 열고 Docker run 명령어에 사용한 자격 증명을 입력하여 생성한 PostgreSQL 데이터베이스에 액세스하세요.\n\n연결에 필요한 데이터에 주의를 기울이세요. 암호를 포함한 필수 정보는 Docker run 명령어에 명시되어 있습니다.\n\n\n\n마지막으로, GitHub 저장소에서 찾을 수 있는 SQL 스크립트를 실행해주세요. 이 스크립트는 애플리케이션에서 사용자를 기본 저장하는 데 사용됩니다.\n\n이제 테이블과 데이터베이스가 설정되었으니, 다음 단계는 데이터베이스를 서버에 연결하고 해당 데이터베이스에 쿼리를 시작하는 것입니다.\n\n# 서버\n\n시작하기 전에 이 API가 무엇을 추상화할지 명확하게 알아봅시다.\n\n\n\n데이터베이스 관련 작업에서는 SQL 문을 사용하여 행을 생성, 검색, 업데이트 및 삭제합니다.\n\n이를 기억하면, 이 서버에서 할 일은 이 SQL 명령어의 입력 부분을 채울 값들을 간단히 수락하는 것입니다. \n\n예를 들어 사용자를 생성할 때, 이름, 이메일 및 비밀번호를 문자열로 삽입 문에 채워야 새로운 행을 만들 수 있습니다. 이제 API를 통해 사용자 입력을 받고 이러한 문자열을 채울 수 있습니다.\n\n우리가 추상화하는 내용을 이해했으니, 계속하기 위해 저장소를 복제해야 합니다.\n\n\n\n저장소를 복제한 후, 필요한 Node.js 패키지를 설치하고 다음 명령을 실행하여 서버를 시작하세요.\n\n```js\nnpm i\nnpm start\n```\n\n이제 서버가 http://localhost:3000/ 에서 실행 중입니다. 그러나 서버를 사용하기 전에 이 문서의 DOCUMENTATION 섹션을 완료하는 것을 제안합니다.\n\n이제 한 걸음 물러나서 RESTful API를 생성하는 데 필요한 것들을 다시 살펴보겠습니다.\n\n\n\n인터페이스를 각 메소드마다 정의해야 하며, 사용할 메소드를 지정하고 각 메소드가 무엇을 추상화할지 결정해야 합니다. 이를 위해 이 구조를 반영하도록 설계된 디렉터리 트리를 생성했습니다.\n\n```js\nbackend-basics/\n├── dml.sql\n├── package.json\n├── package-lock.json\n├── README.md\n├── server.js\n└── src\n    ├── controllers\n    │   └── users.js\n    ├── helpers\n    │   └── pg.js\n    ├── queries\n    │   └── users.js\n    └── routes\n        └── routes.js\n```\n\nsrc 폴더 아래에는 API를 RESTful하게 만드는 데 필요한 모든 요소가 포함되어 있습니다.\n\n다음 섹션에 나오는 코드는 GitHub 저장소에서 추출된 것으로 모두를 포함하고 있지 않습니다. 설명을 위해 일부 조각으로 제공됩니다.\n\n\n\n## 매개변수\n\nRESTful API의 가장 중요한 측면은 사용자가 서버 쪽으로 보내는 정보입니다. 일반적으로 세 가지 유형의 매개변수 전달 방법이 적용됩니다: 경로, 쿼리 및 본문.\n\n- **경로**: 매개변수가 URL에 직접 포함됩니다. 예: http://localhost:3000/api/users/Guilherme Huther.\n- **쿼리**: 매개변수는 URL에서 매개변수 이름을 사용하여 지정됩니다. 예: http://localhost:3000/api/users?id_users=d290f1ee-65c54-4b01-90e6-d701748f0851.\n- **본문**: 본문은 요청에서 페이로드 부분에 전송됩니다. 이는 JSON부터 HTML까지 다양한 유형의 콘텐츠일 수 있으며, 일반적으로 클라이언트가 보내는 Content-Type 헤더와 관련하여 데이터 유형을 명시합니다.\n\n## 컨트롤러\n\n\n\n컨트롤러에는 HTTP 프로토콜의 인터페이스, 상태 코드 및 *헤더가 포함되어 있습니다.\n\n필요한 작업을 효과적으로 실행하기 위해 쿼리 및 도우미가 필요합니다.\n\n```js\n// backend-basics/src/controllers/users.js\n\nconst pool = require(\"../helpers/pg\");\n\nconst {\n  sql_get_all_users,\n  sql_get_users,\n} = require(\"../queries/users\");\n\nconst get_users = async (req, res) =\u003e {\n  const id_users = req.query.id_users;\n\n  if (id_users) {\n    pool.query(sql_get_users, [id_users], (err, response) =\u003e {\n      if (err) {\n        res.status(500).send(\"사용자 가져오는 중 오류 발생: \" + err.message);\n\n        return;\n      }\n      res.status(200).send(response.rows);\n\n      return;\n    });\n\n    return;\n  } else {\n    pool.query(sql_get_all_users, (err, response) =\u003e {\n      if (err) {\n        res.status(500).send(\"사용자 가져오는 중 오류 발생: \" + err.message);\n\n        return;\n      }\n      res.status(200).send(response.rows);\n\n      return;\n    });\n    return;\n  }\n};\n```\n\n이 코드에서는 사용자 입력 매개변수를 처리하고 이러한 매개변수를 사용하여 데이터베이스에서 쿼리를 실행한 후 클라이언트에 응답을 제공합니다. 작업이 실패하면 오류가 발생하고 성공하면 쿼리된 데이터가 반환됩니다.\n\n\n\n*헤더: 컨트롤러에서 헤더를 관리할 수 있지만, 이 상황에서는 주로 Express Node.js 패키지를 통해 그들의 사용이 용이해집니다.\n\n## 쿼리 및 헬퍼\n\n이 두 구성 요소에는 API를 통해 중재될 프로세스가 포함되어 있습니다. 이 경우에는 PostgreSQL 데이터베이스에서 CRUD 작업이 포함됩니다.\n\n쿼리는 저장 시스템에서 실행될 SQL 문입니다. 마지막으로, 헬퍼는 Node.js에서 PostgreSQL과 함께 SQL을 실행하는 데 필요한 연결을 관리합니다.\n\n\n\n```js\n// backend-basics/src/helpers/pg.js\n\nconst Pool = require(\"pg\").Pool;\n\nconst pool = new Pool({\n  user: \"postgres\",\n  host: \"localhost\",\n  database: \"postgres\",\n  password: \"postgres\",\n  port: 5432,\n});\n\nmodule.exports = pool;\n```\n\n쿼리를 실행하는 데 필요한 PostgreSQL 데이터베이스 연결입니다.\n\n```js\n// backend-basics/src/queries/users.js\n\nconst sql_get_all_users = `\nSELECT \n    * \nFROM \n    users;\n`;\n\nconst sql_get_users = `\nSELECT \n    * \nFROM \n    users \nWHERE\n    id_users = $1;\n`;\n```\n\n컨트롤러에서 사용되는 쿼리는 사용자의 입력에 따라 달라집니다.\n\n\n\n## 경로\n\n여기서 각 컨트롤러에 대한 HTTP 메소드가 설정되어 있습니다. GET, POST, PUT, DELETE 메소드는 수행 중인 작업의 유형을 나타냅니다.\n\n예를 들어, 이 API에서 POST 엔드포인트는 CRUD에서 \"만들기\" 작업에 해당하며, 데이터베이스에서 새 인스턴스를 만듭니다.\n\n```js\n// backend-basics/src/routes/routes.js\n\nconst express = require(\"express\");\nconst router = express.Router();\n\nconst {\n    get_users,\n    create_users,\n    update_users,\n    delete_users,\n} = require(\"../controllers/users.js\");\n\nrouter.get(\"/users\", get_users);\nrouter.post(\"/users\", create_users);\nrouter.put(\"/users\", update_users);\nrouter.delete(\"/users\", delete_users);\n\nmodule.exports = router;\n```\n\n\n\n라우트는 컨트롤러 프로세스를 활용하여 각 메소드가 무엇을 수행할지와 사용 가능한 메소드를 지정합니다.\n\n## 서버의 다음 단계\n\n보안, 확장성 및 효율성을 강화하기 위해 미들웨어, 웹 소켓 및 기타 기능을 추가할 수도 있습니다.\n\n# 사용법\n\n\n\n이제 API를 테스트하고 상호 작용하기 위해 Postman을 사용할 것입니다.\n\n이 도구를 사용하면 사용자가 HTTP 요청을 만들고 요청의 모든 구성 요소를 사용자 정의할 수 있습니다. 요청에 헤더를 설정하거나 메서드를 변경하거나 요청을위한 URL을 지정하고 본문에 데이터를 보낼 수 있습니다.\n\n기본 사용법을 보여주는 이미지와 API를 테스트하는 방법에 대한 설명서가 여기 있습니다.\n\n# 문서화\n\n\n\n문서 작성은 개발의 중요한 부분입니다. 당신이 무엇을 하는지 이해하는 데 도움이 되며, 무엇보다도 프로젝트의 다른 사람들이 당신의 작업을 이해할 수 있게 해줍니다.\n\n이것은 매우 중요한데, 종종 다른 팀원들이 당신의 기여에 대해 명확한 이해를 가지고 있지 않을 수 있기 때문입니다. 그러므로 철저한 문서 작성이 당신이 성취한 것을 설명하는 가장 좋은 방법입니다.\n\n이 API에는 문서가 포함되어 있으며 다음 URL을 통해 액세스할 수 있습니다:\n\n```js\nhttp://localhost:3000/docs\n```\n\n\n\n# AWS 배포\n\n이 섹션에서는 AWS EC2 인스턴스에 애플리케이션을 배포하는 방법을 안내하겠습니다.\n\n먼저, AWS에서 계정을 생성하고 제공되는 서비스를 사용하기 위해 신용카드 정보를 입력해야 합니다. 비록 무료 티어에 속해있더라도 서비스를 이용하려면 이 작업을 해주셔야 합니다.\n\n다음은 수행해야 할 단계들입니다:\n\n\n\n- EC2 인스턴스 생성;\n- GitHub 저장소 복제;\n- 데이터베이스 설정;\n- 서버 설정.\n\n## EC2 인스턴스 생성\n\n![이미지](\"/assets/img/2024-05-16-BACK-ENDBASICS_4.png\")\n\n![이미지](\"/assets/img/2024-05-16-BACK-ENDBASICS_5.png\")\n\n\n\n\n![Image 6](/assets/img/2024-05-16-BACK-ENDBASICS_6.png)\n![Image 7](/assets/img/2024-05-16-BACK-ENDBASICS_7.png)\n![Image 8](/assets/img/2024-05-16-BACK-ENDBASICS_8.png)\n![Image 9](/assets/img/2024-05-16-BACK-ENDBASICS_9.png)\n  \n\n\n\n\u003cimg src=\"/assets/img/2024-05-16-BACK-ENDBASICS_10.png\" /\u003e\n\n## 깃허브 저장소 복제하기\n\n이제 EC2 인스턴스 내에서 GitHub 계정에 새 SSH 키를 등록하여 머신에 저장소를 복제할 수 있습니다.\n\nWindows - PowerShell(관리자 권한으로 실행해야 함)\n\n\n\n```js\nssh-keygen -t ed25519 -C \"\u003cYOUR_GITHUB_EMAIL\u003e\"\n\ncat \u003cPUBLIC_KEY_PATH\u003e\n# 출력을 복사하고 다음 링크에서 새 SSH 키를 만드세요:\n# https://github.com/settings/keys\n\nGet-Service -Name ssh-agent | Set-Service -Startup Manual\nStart-Service ssh-agent\nssh-add \u003cPRIVATE_KEY_PATH\u003e\ngit clone \u003cSSH_GITHUB_CLONE_CODE\u003e\n```\n\nLinux - Bash\n\n```js\nssh-keygen -t ed25519 -C \"\u003cYOUR_GITHUB_EMAIL\u003e\"\n\ncat \u003cPUBLIC_KEY_PATH\u003e\n# 출력을 복사하고 다음 링크에서 새 SSH 키를 만드세요:\n# https://github.com/settings/keys\n```\n\n일반적으로 키는 .ssh 디렉토리에 위치합니다. 설정이 완료되면 `git clone REPOSITORY_SSH_URL` 명령어를 사용하여 리포지토리를 복제할 수 있습니다. \n\n\n\n\n## 데이터베이스 설정\n\n이제 다음 명령을 실행하여 데이터베이스용 Docker를 다운로드해야 합니다.\n\n```js\nsudo apt update\nsudo apt upgrade\n\nsudo apt-get install ca-certificates curl\nsudo install -m 0755 -d /etc/apt/keyrings\nsudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\nsudo chmod a+r /etc/apt/keyrings/docker.asc\n\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\n  $(. /etc/os-release \u0026\u0026 echo \"$VERSION_CODENAME\") stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list \u003e /dev/null\n\nsudo apt-get update\n\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n```\n\n다음으로 다음 Docker 명령을 실행하여 PostgreSQL 데이터베이스를 생성하세요:\n\n\n\n```js\nsudo docker run --name postgresdb -p 5432:5432 -e POSTGRES_PASSWORD=postgres -e POSTGRES_USER=postgres -e POSTGRES_DB=postgres -d postgres\n```\n\n마지막으로 데이터베이스 테이블을 만들려면 설정한 도커 컨테이너 안에서 dml.sql 스크립트를 실행하세요:\n\n```js\ncat /home/ubuntu/backend-basics/dml.sql | sudo docker exec -i postgresdb psql -U postgres -d postgres\n```\n\n이제 새로 만든 테이블이 포함된 데이터베이스가 작동 중입니다.\n\n\n\n## 서버 설정\n\n마침내, 서버를 실행할 수 있도록 Node.js와 npm을 다운로드해야 합니다.\n\n```js\nsudo apt update\n\nsudo apt install npm\nsudo apt-get install nodejs\n```\n\n다운로드를 완료한 후, 해당 디렉토리에 액세스하여 서버를 시작하고 필요한 패키지를 다운로드한 다음, 서버를 인스턴스화하는 명령을 실행해야 합니다.\n\n\n\n```js\ncd /home/ubuntu/backend-basics\n\nnpm i\n\nnpm i pm2\n\npm2 start server.js --watch  # 서버를 문제없이 실행하기 위해 시작합니다 \n#\n# 혹은 npm start\n#\n# pm2 stop server.js         # 서버를 중지하는 명령어\n# pm2 logs                   # 서버 로그를 확인하는 명령어\n```\n\nAWS EC2 인스턴스에서 실행 중인 서버에 액세스하려면 인스턴스의 공용 IPv4 주소를 사용하세요. API 요청에서 로컬 주소를 인스턴스의 공용 IPv4로 교체하세요.\n\n사용 방법 섹션에 있는 http://localhost:3000을 http://`EC2_PUBLIC_IPV4`:3000으로 변경하세요.\n\n## AWS 배포의 다음 단계\n\n\n\n\n이제 서버가 배포되었으니, HTTPS 연결 설정, 로드 밸런서 구현, 복제 구성 등 잠재적인 문제에 대해 대응해야 합니다. 이러한 도전에 대해 사전에 대비하고 시스템의 보안 및 성능을 계속 향상시키세요.\n\n링크드인과 깃허브에서 저를 팔로우하세요.\n\n# 참고 자료\n\n- Tanenbaum, A.S. and Wetherall, D.J. (2011) Computer Networks. 5th Edition, Prentice Hall, Inc., 미국.\n- Andrew S. Tanenbaum and Herbert Bos. 2014. Modern Operating Systems (4th. ed.). Prentice Hall Press, 미국.\n- https://github.com/guilhermehuther/backend-basics\n- https://developer.mozilla.org/en-US/docs/Web/HTTP/Status\n- https://developer.mozilla.org/en-US/docs/Web/HTTP\n- https://www.ibm.com/topics/rest-apis\n- https://aws.amazon.com/what-is/restful-api/\n- https://restfulapi.net\n- https://www.postgresql.org/docs/current/\n- https://nodejs.org/docs/latest/api\n- https://docs.docker.com","ogImage":{"url":"/assets/img/2024-05-16-BACK-ENDBASICS_0.png"},"coverImage":"/assets/img/2024-05-16-BACK-ENDBASICS_0.png","tag":["Tech"],"readingTime":12},{"title":"타임 시리즈에 대해 PySpark와 Databricks를 사용한 피처 엔지니어링","description":"","date":"2024-05-16 03:43","slug":"2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks","content":"\n\n대규모 데이터 세트에서 고속 쿼리 및 분석에 대한 수요가 증가함에 따라 Apache Spark는 최근 몇 년간 가장 인기 있는 분석 엔진 중 하나로 돌아서고 있습니다. 그것은 분산 데이터 처리에서 강력한데, 마스터-워커 아키텍처 때문에 그렇습니다. 이에는 클러스터 매니저(마스터)와 협력하고 작은 작업을 워커 노드로 분배하는 실행을 제어하는 드라이버 프로그램이 포함되어 있습니다. 게다가, 내부 메모리 데이터 처리 엔진으로 설계된 Spark는 데이터를 저장하고 조작할 때 주로 RAM을 사용하여 디스크 저장소에 의존하는 것 대신 데이터를 더 빨리 처리할 수 있게 도와줍니다.\n\n![이미지](/assets/img/2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks_0.png)\n\n## Apache Spark: 낮은 수준에서 높은 수준까지\n\n낮은 수준에서는 그 아키텍처가 두 가지 주요 추상화를 기반으로 설계되어 있습니다.\n\n\n\n- Resilient Distributed Dataset (RDD) - 각 데이터 세트를 논리적 부분으로 분할하고 클러스터 작업자 노드에서 실행하여 병렬 프로그래밍을 지원하는 저수준 데이터 추상화입니다.\n- Directed Acyclic Graph (DAG) - 작업의 종속성과 순서를 최적화하고 예약하는 표현을 의미합니다.\n\n더 높은 수준에서는 Scala, Python 또는 R과 같은 언어를 사용하여 다양한 고수준 도구를 활용할 수 있습니다. 도구 예시로는 SQL 및 데이터프레임 용 Spark SQL, Pandas 작업을 위한 Spark Pandas API, 스트림 처리를 위한 구조적 스트리밍 등이 있습니다.\n\n하지만 이러한 기능을 즐기기 전에는 인프라 설정 및 다양한 복잡한 도구들을 통해 Spark 클러스터를 자체 관리해야 할 수 있으며, 이는 머리를 아프게 만들 수 있습니다.\n\n## Databricks에서 PySpark\n\n\n\n이러한 도전에 대응하기 위해 Databricks에서 PySpark를 최근 산업의 고수준 솔루션 중 하나로 소개하고 있습니다. PySpark는 Spark용 Python API이며, Databricks는 Spark를 기반으로 한 완전한 소프트웨어 플랫폼입니다. 노트북, 인프라 오케스트레이션(자동 프로비저닝 및 스케일링), 프로세스 오케스트레이션(작업 제출 및 예약), 관리 클러스터 및 소스 제어까지 모두 포함하고 있습니다.\n\nDatabricks에서 PySpark API를 사용하여 시계열 데이터에 대한 특성 엔지니어링 프로젝트를 시연하고 수행할 것입니다. 이 실습 여정에서는 Pandas 라이브러리가 일반적으로 데이터 처리에 사용되는 방식을 시뮬레이션하되, 확장성과 병렬성의 추가 혜택을 누릴 수 있습니다.\n\n아래와 같은 시나리오를 고려해 보세요. 2006년 12월부터 2010년 11월까지 1분 간격으로 샘플링된 가정용 전기 사용 데이터가 있습니다. 저희의 목표는 데이터를 수집하고 조작하며 특성을 추출하고 시각화를 생성하는 것입니다.\n\n![Link text](/assets/img/2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks_1.png)\n\n\n\n데이터셋 [라이센스: 데이터베이스 오픈 데이터베이스, 콘텐츠: 데이터베이스 콘텐츠]은 Kaggle에서 얻은 것으로서 날짜, 시간, 글로벌 전력 (유효 및 무효), 전압, 글로벌 강도 및 서브미터링 (1, 2 및 3)과 같은 다양한 필드가 포함되어 있습니다. 이제 분석을 시작할 수 있습니다.\n\n## 초기 설정\n\n시작하려면 Databricks Community Edition을 위한 사용자 계정을 만들어야 합니다. 이것은 우리의 개념 증명을 위한 적합한 Databricks 환경을 제공합니다. 그 다음으로 입력 데이터 파일을 FileStore로 업로드해야 합니다. FileStore는 Databricks 전용 경로입니다. \"노트북에 테이블 생성\"을 클릭하면 데이터 수집을 시작하는 코드 템플릿이 제공됩니다.\n\n![이미지](/assets/img/2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks_2.png)\n\n\n\n\n![이미지](/assets/img/2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks_3.png)\n\n## 피처 엔지니어링 프로젝트 생성\n\n### 1. 데이터 가져오기\n\n- 정적 데이터\n\n\n\n\n우리는 데이터 소스를 읽고 DataFrame, 즉 관계형 테이블을 반환하는 spark.read() 메서드를 사용합니다. CSV, JSON, Parquet 등 다양한 데이터 소스를 지원합니다. 이 경우에는 첫 번째 행이 헤더 역할을 하고 \";\"를 구분자로 사용하는 정의된 스키마로 CSV 형식의 전력 소비 데이터를 읽습니다.\n\n```js\n# 파일 위치 및 유형\nfile_location = \"/FileStore/tables/household_power_consumption.csv\"\nfile_type = \"csv\"\n\n# CSV 옵션\nschema = \"Date STRING, Time STRING, Global_active_power DOUBLE, Global_reactive_power DOUBLE, Voltage DOUBLE, Global_intensity DOUBLE, Sub_metering_1 DOUBLE, Sub_metering_2 DOUBLE, Sub_metering_3 DOUBLE\"\nfirst_row_as_header = \"true\"\ndelimiter = \";\"\n\n# CSV 파일 읽기\norg_df = spark.read.format(file_type) \\\n.schema(schema) \\\n.option(\"header\", first_row_as_header) \\\n.option(\"delimiter\", delimiter) \\\n.load(file_location)\n\ndisplay(org_df)\n```\n\nDataFrame의 몇 가지 첫 행 출력:\n\n\u003cimg src=\"/assets/img/2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks_4.png\" /\u003e\n\n\n\n- 데이터 스트리밍\n\n데이터가 지속적으로 생성되는 시나리오에서는 스트림 처리 기술을 사용하여 데이터를 점진적으로 읽습니다. Spark의 동작을 보여주기 위해 원본 데이터 세트를 10개의 하위 집합으로 분할하고 미리 \"/FileStore/tables/stream/\" 경로에 저장했습니다. 그리고 나서 다른 메서드인 spark.readStream()을 사용하여 데이터를 스트리밍합니다.\n\n```js\nsourceStream=spark.readStream.format(\"csv\") \\\n.option(\"header\",True) \\\n.schema(schema) \\\n.option(\"mode\",\"dropMalformed\") \\\n.option(\"maxFilesPerTrigger\",1) \\\n.option(\"ignoreLeadingWhiteSpace\",True) \\\n.load(\"dbfs:/FileStore/tables/stream\") \\\n```\n\n\"dropMalformed\"로 설정된 모드 설정은 손상된 레코드를 방지하기 때문에 구조적 불일치로 인한 손상이든 다른 사용할 수 없는 요소로 인한 손상이든 상관없이 해당 레코드를 폐기합니다. 또한 트리거 이벤트 당 하나의 파일만 처리하도록 선택했습니다.\n\n\n\n데이터를 수신하고 10초마다 레코드 수를 확인하여 스트리밍 데이터가 계속 도착하는 것을 관찰할 수 있습니다.\n\n```js\nimport time\n\n# DataFrame 내용을 스트리밍\nquery = sourceStream.writeStream \\\n.queryName(\"count\") \\\n.format(\"memory\") \\\n.outputMode(\"append\") \\\n.start()\n\n# 행 수를 표시\nfor _ in range(10):\n  spark.sql(\"SELECT COUNT(*) AS no_of_rows FROM count\").show()\n  time.sleep(10)\n```\n\n#2 데이터 조작 및 탐색\n\n- 데이터 변환\n\n\n\n결측값이 포함된 행의 수가 상대적으로 미비하기 때문에 해당 행을 삭제하는 것으로 결정했습니다. 게다가 시간 관련 특성을 추출하여 나중에 더 높은 차원에서 패턴을 관찰할 수 있을 것으로 기대됩니다.\n\n```python\nfrom pyspark.sql.functions import col, concat_ws, to_date\n\n# 결측값이 포함된 행 삭제\ndf = org_df.na.drop()\n\n# \"Date\"와 \"Time\" 열을 새로운 \"DateTime\" 열로 변환\ndf = df.withColumn(\"Date\", to_date(col(\"Date\"),\"d/M/y\"))\ndf = df.withColumn(\"Date\", df[\"Date\"].cast(\"date\"))\ndf = df.select(concat_ws(\" \", to_date(col(\"Date\"),\"d/M/y\"), col(\"Time\")).alias(\"DateTime\"), \"*\")\ndf = df.withColumn(\"DateTime\", df[\"DateTime\"].cast(\"timestamp\"))\n\n# 시간 관련 특성 추가\ndf = df.withColumn(\"year\", year(\"DateTime\"))\ndf = df.withColumn(\"month\", month(\"DateTime\"))\ndf = df.withColumn(\"week_num\", weekofyear(\"DateTime\"))\ndf = df.withColumn(\"hour\", hour(\"DateTime\"))\n```\n\n- 데이터 탐색\n\n다양한 PySpark 기본 메서드로 데이터를 탐색할 수 있습니다.\n\n\n\n(1) 선택하기\n\n\"select\" 메소드를 사용하면 데이터 프레임에서 열 단위로 하위 집합을 만들 수 있습니다. 이 예시에서는 글로벌 액티브 전력의 내림차순으로 열을 선택합니다.\n\n```js\ndf.select(\"DateTime\", \"Global_active_power\", \"Global_intensity\").sort(\"Global_active_power\", ascending=False).show(5)\n```\n\n\u003cimg src=\"/assets/img/2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks_5.png\" /\u003e\n\n\n\n(2) 필터\n\n이 필터는 열 값에 따라 데이터 포인트를 필터링합니다. 이 예에서는 \"year\"와 \"Global_intensity\" 열 두 개에 대해 필터링합니다.\n\n```js\ndf.filter(\n    (col(\"year\") == 2009) \u0026\n    (col(\"Global_intensity\") \u003e 40)\n).count()\n\n# 출력: 10\n```\n\n(3) 그룹화\n\n\n\n우리는 집계 작업도 수행할 수 있어요. 데이터셋에서 다양한 월에 대한 전역 활성 전력 및 서브 미터링의 평균을 계산해 봅시다.\n\n```js\ndf.groupby(\"month\").agg(\n     round(mean(\"Global_active_power\"), 2).alias(\"평균_전역_활성_전력\"),\n     round(mean(\"Sub_metering_1\"), 2).alias(\"평균_서브_미터링_1\"),\n     round(mean(\"Sub_metering_2\"), 2).alias(\"평균_서브_미터링_2\"),\n     round(mean(\"Sub_metering_3\"), 2).alias(\"평균_서브_미터링_3\"),\n).sort([\"month\"]).show(5)\n```\n\n![그림](/assets/img/2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks_6.png)\n\n#3 창 함수를 사용하여 특성 추출\n\n\n\n위의 기본 PySpark 메소드와 함수에 추가로 Window 함수를 활용하여 시고열 데이터에서 시간적 종속성과 관계를 캡처할 추가적인 피처를 생성할 수 있습니다. 하루 단위로 집계된 전체 글로벌 활성 전력이 변환된 데이터 세트(\"df2\")를 가정해 봅시다. 이러한 피처들을 어떻게 얻을 수 있는지 알아보겠습니다.\n\n(1) Lag features\n\n이는 이전 날짜의 지표 값들을 나타내며, 모델이 과거 데이터로부터 학습하고 추세를 식별하는 데 도움이 됩니다.\n\n```python\nfrom pyspark.sql.window import Window\nfrom pyspark.sql.functions import lag, round\n\n# 'Date' 열을 기반으로 Window 명세 생성\nwindowSpec = Window.orderBy(\"Date\")\n\n# 'Total_global_active_power'의 이전 값 계산\ndf2 = df2.withColumn(\"power_lag1\", round(lag(col(\"Total_global_active_power\"), 1).over(windowSpec), 2))\n\ndisplay(df2)\n```\n\n\n\n\u003cimg src=\"/assets/img/2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks_7.png\" /\u003e\n\n(2) Delta features\n\n이는 원 데이터 필드와 랙 데이터 간의 차이를 계산하여 짧은 기간 내의 변화나 변동을 캡처하기 위한 차후 단계를 거치는 것입니다.\n\n```js\n# 열 간의 차이를 계산합니다\ndf2 = df2.withColumn(\"power_lag1_delta\", round(col(\"power_lag1\") - col(\"Total_global_active_power\"), 2))\n\ndisplay(df2)\n```\n\n\n\n\u003cimg src=\"/assets/img/2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks_8.png\" /\u003e\n\n(3) 창 평균 피처\n\n이러한 기능은 슬라이딩 윈도우 내에서 대상 데이터 필드의 평균 값을 계산하여 매끄러운 패턴과 상대적으로 장기적인 추세를 포착할 수 있도록 합니다. 여기서 창 크기를 14 (2 주)와 30 (대략 1 개월)로 선택했습니다.\n\n```js\n# 지정된 창 크기에 대한 데이터프레임에 창 평균 필드 추가\ndef add_window_avg_features(df, window_sizes):\n    for window_size in window_sizes:\n        window_col_name = f\"avg_power_l{window_size}\"\n        windowSpec = Window.orderBy(\"Date\").rowsBetween(-window_size, 0)\n        df = df.withColumn(window_col_name, round(avg(col(\"Total_global_active_power\")).over(windowSpec), 2))\n    return df\n\nwindow_sizes = [14, 30]\ndf2 = add_window_avg_features(df2, window_sizes)\n\ndf2.select(\"Date\", \"Total_global_active_power\", \"avg_power_l14\", \"avg_power_l30\").sort(\"Date\", ascending=False).show(5)\n```\n\n\n\n\u003cimg src=\"/assets/img/2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks_9.png\" /\u003e\n\n(4) 지수 가중 이동 평균 (EWMA) 피처\n\nEWMA 피처는 최근 데이터에 더 많은 가중치를 할당하여 과거 데이터에 덜 주의를 기울이는 창 평균 피처의 보정 버전입니다. 더 높은 가중치(알파) 값은 EWMA 피처가 원래 시계열에 더 밀접하게 추적하는 것을 의미합니다. 여기서는 0.2와 0.8이라는 두 가지 별도의 가중치를 선택했습니다.\n\n```python\nimport pyspark.pandas as ps\n\n# 데이터프레임에 지정된 알파 값의 EWMA 피처를 추가합니다\ndef add_ewma_features(df, alphas):\n    for alpha in alphas:\n        ewma_col_name = f\"ewma_power_w{str(alpha).replace('.', '')}\"\n        windowSpec = Window.orderBy(\"Date\")\n        df[ewma_col_name] = df.Total_global_active_power.ewm(alpha=alpha).mean().round(2)\n    return df\n\nalphas = [0.2, 0.8]\n# EWM 함수를 사용하기 위해 pandas-on-Spark 데이터프레임으로 변환합니다\ndf2_pd = df2.pandas_api()\ndf2_pd = add_ewma_features(df2_pd, alphas)\n# 다시 Spark 데이터프레임으로 변환합니다\ndf2 = df2_pd.to_spark()\n\ndf2.select(\"Date\", \"Total_global_active_power\", \"ewma_power_w02\", \"ewma_power_w08\").sort(\"Date\", ascending=False).show(5)\n```\n\n\n\n\u003cimg src=\"/assets/img/2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks_10.png\" /\u003e\n\n#4 Notebook에서 시각화 생성하기\n\n다양한 PySpark 함수와 메소드를 사용하여 시간 관련 데이터와 특성을 추출한 후, Databricks의 내장 지원을 활용하여 효율적으로 시각화를 생성할 수 있습니다. 이는 시각화 편집기에서 데이터 필드를 끌어다 놓고 시각적 설정을 구성함으로써 작동합니다. 아래는 몇 가지 예시입니다.\n\n- 산점도: 글로벌 활성 전력과 글로벌 강도 간의 관계\n\n\n\n해석: 두 분야 사이에는 매우 강한 양의 상관 관계가 있습니다.\n\n![그림](/assets/img/2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks_11.png)\n\n- 상자 그림: 시간대별 글로벌 활성 전력 분포\n\n해석: 7:00부터 21:00까지 글로벌 활성 전력에 상대적으로 큰 변동이 있습니다.\n\n\n\n\n![Line Chart](/assets/img/2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks_12.png)\n\n- Line chart: The changes in total global active power, EWMA with alpha 0.2, and EWMA with alpha 0.8 from Jan 2008 to Mar 2008\n\nInterpretation: EWMA with alpha 0.8 sticks more closely to the original time series than EWMA with alpha 0.2.\n\n![Line Chart](/assets/img/2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks_13.png)\n\n\n\n\n또한, 기본 데이터 프로필을 생성하여 요약 통계량(개수, 누락된 값의 %, 데이터 분포 등)을 표시할 수 있습니다. 이를 통해 특성 엔지니어링 프로세스 전반에 걸쳐 데이터 품질을 보장할 수 있습니다. 위 시각화는 Databricks SQL을 사용하여 쿼리 출력으로 대체적으로 생성할 수도 있습니다.\n\n## 마무리\n\n저희는 Databricks 플랫폼을 활용하여 시계열 데이터의 피처 엔지니어링을 위해 PySpark를 사용한 실습을 진행했습니다:\n\n- 정적 및 스트리밍 데이터 수집은 각각 spark.read() 및 spark.readStream() 메서드를 사용합니다.\n- 기본 PySpark 함수(pyspark.sql.functions) 및 DataFrame 메서드를 활용하여 데이터 조작 및 탐색이 이루어집니다.\n- trend 관련 피처 추출은 pyspark.sql.Window를 사용하여 데이터 그룹 내의 관계를 계산합니다.\n- 내장된 Databricks Notebook 기능을 활용하여 시각화를 수행합니다.\n\n\n\n대규모 데이터셋을 다룰 때는 PySpark가 Pandas보다 확장성과 성능 능력으로 인해 자주 선호됩니다. PySpark의 지연 평가 지원 덕분에 계산은 필요할 때만 수행되어 오버헤드가 줄어듭니다. 그러나 때로는 Scala가 더 나은 선택일 수도 있습니다. 왜냐하면 Spark 자체가 Scala로 작성되었기 때문에 최신 기능을 적극적으로 활용할 수 있기 때문입니다. 또한 변경할 수 없는 객체를 사용하여 오류가 덜 발생하는 시스템을 설계할 수 있습니다. 각각의 언어나 라이브러리는 그들만의 장점을 갖고 있습니다. 궁극적으로 선택은 기업 요구 사항, 개발자들의 학습 곡선 및 다른 시스템과의 통합에 달려 있습니다.\n\n## 계속 진행하기 전에\n\n이 글을 즐겨 보셨다면, 제 Medium 페이지와 LinkedIn 페이지를 팔로우해 주시기를 초대합니다. 이렇게 하면 데이터 과학 사이드 프로젝트 관련 흥미로운 콘텐츠 및 머신 러닝 운영(MLOps) 방법론에 관한 데모를 최신 상태로 유지할 수 있습니다.","ogImage":{"url":"/assets/img/2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks_0.png"},"coverImage":"/assets/img/2024-05-16-FeatureEngineeringforTime-SeriesUsingPySparkonDatabricks_0.png","tag":["Tech"],"readingTime":11},{"title":"EKS에서 자체 호스팅 LLM을 배포하는 방법 및 그 이유","description":"","date":"2024-05-16 03:39","slug":"2024-05-16-HowtoDeployaSelf-HostedLLMonEKSandWhyYouShould","content":"\n\n생산 환경에서 가격이 폭등하는 토큰에 대해 계속 걱정하고 있나요? 외부 업체가 민감한 데이터를 어떻게 처리하는지 걱정되나요? 이 게시물은 자체 호스팅 LLM을 EKS(Elastic Kubernetes Service)에 배포하는 방법을 안내해 드립니다. 이를 통해 제어권과 비용 효율성을 높일 수 있습니다. 우리는 자체 호스팅을 원하는 이유부터 설정에 필수적인 도구 및 지표에 이르기까지 모든 것을 탐구할 것입니다. 게다가 모델과 상호 작용할 수 있는 간단한 채팅 애플리케이션을 설정하는 방법을 따라해 보겠습니다.\n\n![이미지](/assets/img/2024-05-16-HowtoDeployaSelf-HostedLLMonEKSandWhyYouShould_0.png)\n\n# 자체 호스팅이란?\n\nOpenAI나 Anthropic과 같은 공급업체의 고급 언어 모델은 매우 인상적이지만 항상 지갑 친화적이라고 할 수 없습니다. 실험 및 개발은 금융 오퍼레이션팀의 주의를 끌지 않을 수 있지만, 프로덕션으로 전환하면 토큰당 요금 체계와 관련된 비용이 빠르게 누적될 수 있습니다.\n\n\n\n크고 비싼 모델들이 있긴 하지만, 언제나 당신의 요구 사항을 평가하고 단순히 큰 모델만을 공략하는 것이 아니라는 점을 염두에 두어야 합니다. 하지만 규모에 따라, 작은 모델도 결국에는 비실 것입니다.\n\n하지만, 돈만을 생각할 필요는 없어요. 자체 호스팅은 다음과 같은 중요한 이점들을 제공합니다:\n\n- 데이터 보안 — 모든 민감한 정보, 특히 개인 식별 정보(PII)는 우리 네트워크 내에서 안전하게 보관됩니다. 이 설정은 데이터를 외부로 보내거나 외부 공급 업체가 데이터를 어떻게 사용할지 걱정할 필요가 없게 합니다.\n- 개발자 자유 — 자체 호스팅은 개발자들이 치솟는 비용과 외부 데이터 개인 정보 보호 우려 없이 탐구하고 혁신할 수 있는 자유를 제공합니다. 이 자유는 기술적 실험을 장려하는 창의적인 환경을 지원하여 더 혁신적인 솔루션을 도출하게 됩니다.\n\nGPT-4와 맞먹는 오픈 소스 모델은 많이 찾기 어려울지 몰라도, 보통 GPT-3.5에서 다루는 작업에 적합한 수많은 대안이 있습니다. 이러한 모델 중 일부는 심지어 더 나은 성능을 발휘하면서 더 저렴한 비용으로 제공되고 있습니다. 이를 네트워크에 배포하여 데이터를 제어할 수 있습니다. 무엇보다 중요한 것은 사용량 당 비용을 지불하는 대신 고정 컴퓨팅 가격을 지불하므로 비용을 더 예측 가능하고 관리하기 쉽게 만들 수 있습니다.\n\n\n\n# 필요한 도구는 무엇인가요? (그리고 몇 가지 다른 고려 사항)\n\nAWS 및 EKS에 익숙하다고 가정하고, LLM 모델을 제공하는 데 필요한 다른 구성 요소에 초점을 맞추겠습니다. 고려해야 할 주요 영역은 Compute, 추론 및 모델입니다.\n\n## Compute\n\nLLM 추론을 설정할 때 고려해야 할 주요 자원은 GPU입니다. 특히 GPU의 종류와 수량을 고려해야 합니다. 이는 전체 모델이 GPU의 메모리 (VRAM)에 로드되며, 모든 LLM 계산이 GPU에서 수행되기 때문입니다.\n\n\n\n VRAM 양을 추정하려면 이 안내서를 확인하거나 다음과 같은 간단한 생각의 척도를 따르세요: 모델의 매개변수 수(10억 개 단위)를 두 배하여 기본 요구 사항을 얻은 다음, 캐싱과 오버헤드를 커버하기 위해 20%를 추가하세요. 예를 들어, 70억 개의 매개변수를 가진 모델을 이용하려면 VRAM 약 17GB(7 x 2 x 1.2 = 약 16.8 GB)가 한 개 또는 여러 개의 GPU에서 필요합니다.\n\n## 추론\n\n서빙 프레임워크로는 vLLM을 사용할 것입니다. 이는 LLM 모델을 OpenAI 호환 API 서버로 제공하는 데 설계된 오픈 소스 프레임워크입니다. vLLM은 연속 배치를 지원하며, 다중 동시 요청 및 높은 부하를 처리하기에 이상적입니다. 게다가, vLLM은 분산 서빙을 지원하며, 모델을 여러 GPU 또는 노드에서 실행해야하는 경우를 대비합니다. 분산 서빙을 위해 백엔드로 Ray를 사용하며, 이는 대규모 ML 애플리케이션을 실행하기 위한 또 다른 오픈 소스 프레임워크입니다.\n\n## 모델\n\n\n\n수백 개의 모델이 Hugging Face에 있습니다. Foundation 모델부터 더 구체적이고 특정 문제를 해결하기 위해 디자인된 Feat-Tuned 버전까지 말이죠. Hugging Face를 인공지능(AI) 및 기계학습(ML) 애플리케이션의 \"GitHub\"이라고 생각해보세요. 필요한 어떤 모델이나 데이터셋이든 찾을 수 있는 중요한 장소입니다.\n\n모델을 선택할 때 라이선스를 꼭 확인해주세요. Mistral과 같은 일부 모델은 Apache 라이선스 하에 완전히 오픈 소스입니다. 그러나 많은 모델은 상용 라이선스가 적용됩니다. 이 조항을 검토하는 것은 귀하의 법적 및 운영 계획에 부합하는지 확인하는 데 중요합니다.\n\n# 모두 함께 하기 (데모 시간)\n\n이 데모에서 Mistral 7b instruct 0.2 모델을 사용할 것이며, 이는 Apache 라이선스에 따라 완전히 오픈 소스입니다. 이 모델을 처리하기 위해 주로 15센트 미만의 비용이 드는 AWS g6.xlarge 인스턴스에서 실행할 것입니다. 이 인스턴스는 우리가 상의한 VRAM 견적 규칙에 따라 처리하기에 완벽하게 적합한 24GB VRAM을 갖춘 Nvidia L4 GPU가 장착되어 있습니다.\n\n\n\n데모 중에는 미국 서부-2 지역에 VPC를 배포하고, Fargate에서 Karpenter가 있는 EKS 클러스터, GPU를 위한 Karpenter 프로바이더 하나 및 표준 노드를 위한 또 다른 하나, Kubernetes에서 GPU를 사용할 수 있도록 Nvidia Driver 플러그인, 그리고 모니터링을 위한 Prometheus와 Grafana가 설정될 것입니다. 이 모든 리소스는 Terraform을 사용하여 설정될 것입니다.\n\n비용에 관해서는, 이 데모 실행에 예상되는 비용은 시간당 약 30~40센트입니다. NAT 게이트웨이, EKS 제어 평면 및 GPU가 장착된 노드를 포함한 모든 노드에 대한 요금이 포함됩니다.\n\n## 0. 전제 조건\n\n데모에 들어가기 전에, 다음을 준비해 두세요:\n\n\n\n- AWS 계정 — 데모에서 설치해야 할 VPC, EKS 클러스터 등을 구성할 충분한 권한이 있는 AWS 계정이 필요합니다.\n- AWS 자격 증명 — 로컬 환경에서 자격 증명이 올바르게 구성되어 있는지 확인하세요.\n- Terraform — 여러분의 컴퓨터에 Terraform이 설치되어 있어야 합니다. 데모에 필요한 AWS 리소스를 프로비저닝하고 관리하는 데 사용될 것입니다.\n- Kubectl — Kubernetes 리소스를 관리하기 때문에 Kubectl이 설치되어 있는지 확인하세요.\n- HuggingFace 액세스 토큰 — 이 가이드를 따라 Hugging Face에서 모델을 가져오기 위한 API 액세스 토큰을 생성하세요.\n\n## 1. 기본 인프라\n\n- 터미널을 열고 다음을 실행하여 저장소를 클론합니다:\n\n```js\ngit clone https://github.com/eliran89c/self-hosted-llm-on-eks\n```\n\n\n\n2. 디렉토리를 변경하세요:\n\n```js\ncd self-hosted-llm-on-eks\n```\n\n3. (선택사항) 필요에 따라 Terraform 코드를 조정하여 설정을 사용자 정의하세요.\n\n4. Terraform을 초기화하고 인프라를 배포하기 위해 Terraform 구성을 적용하세요 (EKS 클러스터를 배포하는 데 최대 30분 소요될 수 있습니다).\n\n\n\n```js\nterraform init\nterraform apply\n```\n\n5. 새로 생성된 EKS 클러스터와 상호 작용하기 위해 Kubectl을 설정하세요.\n\n```js\naws eks update-kubeconfig --region us-west-2 \\\n    --name self-hosted-llm \\\n    --alias self-hosted-llm\n```\n\n6. Karpenter와 CoreDNS가 실행 중인지 확인하세요.\n\n\n\n```js\nkubectl get pods --all-namespaces\n```\n\n기대되는 출력은 다음과 같아야 합니다:\n\n![image](/assets/img/2024-05-16-HowtoDeployaSelf-HostedLLMonEKSandWhyYouShould_1.png)\n\n7. Karpenter 제공자가 올바르게 설치되었는지 확인하세요:\n\n\n\n```js\nkubectl get ec2nodeclasses.karpenter.k8s.aws\n```\n\n원하는 결과는 사용 가능한 노드 클래스를 표시해야 합니다:\n\n![Available Node Classes](/assets/img/2024-05-16-HowtoDeployaSelf-HostedLLMonEKSandWhyYouShould_2.png)\n\n## 2. vLLM 배포 및 모델 제공\n\n\n\n- HuggingFace 모델 페이지로 이동하셔서 모델 약관에 동의해주세요\n\n![이미지](/assets/img/2024-05-16-HowtoDeployaSelf-HostedLLMonEKSandWhyYouShould_3.png)\n\n2. HuggingFace API 액세스 토큰을 사용하여 비밀을 생성하세요:\n\n```js\nkubectl create secret generic huggingface-token \\\n    --from-literal=token=\u003cyour_hugging_face_token\u003e\n```\n\n\n\n- 'your_hugging_face_token'을 실제 Hugging Face API 액세스 토큰으로 대체해주세요.\n\n3. (선택 사항) 배포 파일을 검토하고, 특히 배포 인수 섹션을 확인하세요. 필요에 따라 엔진 인수를 수정하여 특정 요구 사항에 더 잘 맞도록 설정할 수 있습니다. 모든 사용 가능한 엔진 인수 목록을 확인하려면 여기를 참조하세요.\n\n4. vLLM 배포하기:\n\n```js\nkubectl apply -f vllm.yaml\n```\n\n\n\n5. 프로메테우스가 vLLM에서 메트릭을 수집하도록 하려면 ServiceMonitor을 배포하십시오.\n\n```js\nkubectl apply -f serviceMonitor.yaml\n```\n\n6. vLLM을 배포한 후에는 일반적으로 GPU로 모델을 다운로드하고 로드하는 데 2-3분 정도가 소요됩니다. 이 초기화 단계 중에 무엇이 발생하는지 모니터링하려면 로그를 직접 확인할 수 있습니다.\n먼저, 파드가 실행 중인지 확인하십시오:\n\n```js\nkubectl get pods\n```\n\n\n\n아래와 같이 로그를 확인하세요:\n\n```js\nkubectl logs -f -l app=vllm\n```\n\n모델이 로딩되고 준비되면, 로그에 다음 메시지가 표시될 것을 기대할 수 있습니다:\n\n![이미지](/assets/img/2024-05-16-HowtoDeployaSelf-HostedLLMonEKSandWhyYouShould_4.png)\n\n\n\n7. 새 터미널을 열고 포트 포워딩을 설정하여 포트 8000에서 OpenAI 호환 API 엔드포인트와 상호 작용할 수 있습니다:\n\n```js\nkubectl port-forward svc/vllm 8000:8000\n```\n\n8. 모든 준비가 되었으므로, LLM을 테스트하기 위해 표준 OpenAI curl 명령을 사용하여 쿼리를 보내보세요. 아래는 예시입니다:\n\n```js\ncurl -X POST http://localhost:8000/v1/chat/completions \\\n-H \"Content-Type: application/json\" \\\n-d '{\n      \"model\": \"mistralai/Mistral-7B-Instruct-v0.2\",\n      \"messages\": [{\"role\": \"user\", \"content\": \"프랑스의 수도는 무엇인가요?\"}]\n    }'\n```\n\n\n\n정보를 성공적으로 검색했는지 확인하기 위해 예상 결과는 다음과 같습니다:\n\n\u003cimg src=\"/assets/img/2024-05-16-HowtoDeployaSelf-HostedLLMonEKSandWhyYouShould_5.png\" /\u003e\n\n## 3. 모델과 상호작용하는 간단한 채팅 애플리케이션 설정\n\n- 다음을 실행하여 새 Python 가상 환경을 만듭니다:\n\n\n\n```js\npython3 -m venv .venv\n```\n\n2. 가상 환경을 활성화합니다:\n\n```js\nsource .venv/bin/activate   # 리눅스 또는 맥OS\n.venv\\Scripts\\activate      # 윈도우\n```\n\n3. 필요한 파이썬 패키지를 설치하려면 다음을 실행하세요:\n\n\n\n\n```bash\npip install -r requirements.txt\n```\n\n이 패키지에는 API 요청을 위한 OpenAI Python 클라이언트와 웹 인터페이스를 만들기 위한 Gradio가 포함되어 있습니다.\n\n4. 아래 명령어를 실행하여 애플리케이션을 시작하세요:\n\n```bash\npython chat.py\n```\n\n\n\n5. 어플리케이션이 실행되면 웹 브라우저를 열고 http://localhost:7860/ 으로 이동하세요.\n\n![이미지](/assets/img/2024-05-16-HowtoDeployaSelf-HostedLLMonEKSandWhyYouShould_6.png)\n\n# 모델 모니터링\n\nLLM에서는 모델의 대기 시간(Latency) 및 처리량(Throughput)을 모니터링하고 측정하는 여러 중요한 지표가 있습니다. 이러한 지표들은 성능을 최적화하고 모델이 효율적으로 작동하는 것을 보장하기 위해 중요합니다. 아래는 고려해야 할 주요 지표입니다:\n\n\n\n첫 번째 토큰 생성 시간(TFFT) - 이 지표는 요청을 제출한 후 모델이 응답의 첫 번째 토큰을 생성하는 데 걸리는 시간을 측정합니다. 이는 모델의 초기 반응성을 나타내는 중요한 지표로, 사용자 상호 작용 애플리케이션에서 응답 시간이 사용자 경험에 영향을 미치는 경우에 특히 중요합니다.\n\n출력 토큰 시간(TFOT) - 위와 유사하게, 이 지표는 처음 토큰 생성 후 각 후속 토큰을 생성하는 데 걸리는 시간을 추적합니다. 이는 모델이 시작된 후 계속해서 내용을 처리하고 생성하는 데 효율성을 이해하는 데 도움이 됩니다. 이로써 실행량 성능에 대한 통찰을 얻을 수 있습니다.\n\n프롬프트/생성 토큰 초당 - 이 지표는 모델이 초당 처리하거나 생성하는 토큰 수를 측정합니다. 이는 모델의 처리량 용량을 평가하는 데 필수적인 지표이며, 높은 비율은 더 효율적인 모델을 나타내며 더 많은 입력을 처리하거나 시간이 적게 소요되면서 더 많은 컨텐츠를 생성할 수 있는 것을 의미합니다.\n\nvLLM은 이러한 지표(및 기타 지표)를 /metrics/endpoint를 통해 내보냅니다. 이미 Prometheus에 스크래퍼를 구성했으며, 이제 Grafana에서 대시보드를 설정하여 이러한 지표를 시각화하고 모델의 성능을 실시간으로 더 잘 이해할 수 있도록 합시다.\n\n\n\n## LLM 메트릭을 모니터링하기 위한 Grafana 대시보드 설정\n\n- 브라우저를 통해 Grafana 대시보드에 액세스하려면 먼저 Grafana 팟을 포트 포워딩해야 합니다. 터미널에서 다음 명령을 입력하세요:\n\n```js\nkubectl port-forward -n kube-prometheus-stack \\\n  service/kube-prometheus-stack-grafana 8080:80\n```\n\n2. 웹 브라우저를 열고 http://localhost:8080으로 이동하세요. 로그인 페이지가 나타날 것입니다. 사용자 이름은 \"admin\"이고 기본 비밀번호는 \"prom-operator\"입니다.\n\n\n\n3. 한 번 로그인한 후, 오른쪽 상단 막대의 “+\" 아이콘을 클릭하고 “대시보드 가져오기\"를 선택합니다.\n\n![image](/assets/img/2024-05-16-HowtoDeployaSelf-HostedLLMonEKSandWhyYouShould_7.png)\n\n4. GitHub 저장소의 루트 폴더에 있는 grafana-dashboard.json이라는 JSON 파일을 업로드하고 “가져오기\"를 클릭합니다.\n\n![image](/assets/img/2024-05-16-HowtoDeployaSelf-HostedLLMonEKSandWhyYouShould_8.png)\n\n\n\n5. 대시보드 상단 좌측에 있는 드롭다운 필터를 사용하여 원하는 모델을 선택해 모니터링할 수 있습니다:\n\n![이미지](/assets/img/2024-05-16-HowtoDeployaSelf-HostedLLMonEKSandWhyYouShould_9.png)\n\n## 환경 철거\n\n셋업을 제거하고 리소스를 해제하려면 다음 단계를 따르세요:\n\n\n\n- vLLM 배포를 제거하세요\n\n```js\nkubectl delete -f vllm.yaml\n```\n\n2. 이제, Terraform을 사용하여 생성된 모든 인프라 리소스를 삭제하세요. 아래 명령어를 실행하세요:\n\n```js\nterraform destroy\n```\n\n\n\n# 결론\n\n이 게시물에서는 중요한 혜택을 제공하는 자체 호스팅 LLM 설정을 살펴보았습니다. 특히 비용 절감과 데이터 제어 측면에서 큰 이점을 제공합니다. 이 설정은 GPT-4와 같이 가장 고급 모델이 필요하지 않거나, 작고 자원 소모가 적은 모델로도 충분한 경우에 특히 유용합니다.\n\n제품 사용을 위한 데모가 아님을 참고해주시기 바랍니다. 제품 환경에서 이 설정을 구현하기 위해 클러스터 건강 상태의 지속적인 모니터링이 매우 중요합니다. 또한 로드를 관리하고 서비스 가용성을 효과적으로 유지하기 위해 인그레스 및 스케일링 정책을 실행하는 것이 중요합니다.\n\n여러 노드에서 실행해야 하는 대규모 모델이 필요한 사용 사례의 경우, Ray operator인 KubeRay를 사용하는 것을 강력히 추천합니다. KubeRay는 복잡한 분산 시스템의 스케일링과 관리를 크게 용이하게 합니다. 큰 규모의 배포에서 KubeRay를 활용하는 방법에 대해 더 깊게 알고 싶으시면, 미래 게시물에서 KubeRay를 활용하는 것에 대해 자세히 다루도록 하겠습니다. 그게 궁금하신 경우 댓글에서 알려주시면 감사하겠습니다!","ogImage":{"url":"/assets/img/2024-05-16-HowtoDeployaSelf-HostedLLMonEKSandWhyYouShould_0.png"},"coverImage":"/assets/img/2024-05-16-HowtoDeployaSelf-HostedLLMonEKSandWhyYouShould_0.png","tag":["Tech"],"readingTime":9}],"page":"85","totalPageCount":154,"totalPageGroupCount":8,"lastPageGroup":20,"currentPageGroup":4},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"85"},"buildId":"Rv-NbbtWUaja2joH5WkO_","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>