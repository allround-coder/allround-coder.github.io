<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>allround-coder</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://allround-coder.github.io///posts/7" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="allround-coder" data-gatsby-head="true"/><meta property="og:title" content="allround-coder" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://allround-coder.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://allround-coder.github.io///posts/7" data-gatsby-head="true"/><meta name="twitter:title" content="allround-coder" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | allround-coder" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZFDEQ947R4"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
  
            gtag('config', 'G-ZFDEQ947R4');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/baeec1f16d6ea8b8.css" as="style"/><link rel="stylesheet" href="/_next/static/css/baeec1f16d6ea8b8.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-4a646156c659a948.js" defer=""></script><script src="/_next/static/chunks/348-d11c34b645b13f5b.js" defer=""></script><script src="/_next/static/chunks/324-8452a6176b22a926.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-082571b43b6fd145.js" defer=""></script><script src="/_next/static/z1a6VTi5qHH9JJH7jaxL3/_buildManifest.js" defer=""></script><script src="/_next/static/z1a6VTi5qHH9JJH7jaxL3/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Allround Coder</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="Microsoft Fabric를 위한 확장 가능한 데이터 수집 프레임워크 구축하기" href="/post/2024-05-16-BuildingascalabledataingestionframeworkforMicrosoftFabric"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Microsoft Fabric를 위한 확장 가능한 데이터 수집 프레임워크 구축하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-BuildingascalabledataingestionframeworkforMicrosoftFabric_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Microsoft Fabric를 위한 확장 가능한 데이터 수집 프레임워크 구축하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">Microsoft Fabric를 위한 확장 가능한 데이터 수집 프레임워크 구축하기</strong><div class="PostList_meta__VCFLX"><span class="date">21 hours ago</span><span class="PostList_reading_time__6CBMQ">15<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Tidymodels를 사용하여 고객 이탈 분류 모델 구축과 평가하기" href="/post/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Tidymodels를 사용하여 고객 이탈 분류 모델 구축과 평가하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Tidymodels를 사용하여 고객 이탈 분류 모델 구축과 평가하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">Tidymodels를 사용하여 고객 이탈 분류 모델 구축과 평가하기</strong><div class="PostList_meta__VCFLX"><span class="date">21 hours ago</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="암스테르담에 관한 최고의 재미있는 사실 " href="/post/2024-05-16-IusedWindowsforaYearButImSwitchingBacktoMac"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="암스테르담에 관한 최고의 재미있는 사실 " loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-IusedWindowsforaYearButImSwitchingBacktoMac_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="암스테르담에 관한 최고의 재미있는 사실 " loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">암스테르담에 관한 최고의 재미있는 사실 </strong><div class="PostList_meta__VCFLX"><span class="date">21 hours ago</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="맥용 NVM을 2분 안에 설정하기" href="/post/2024-05-16-NVMformacOSin2minutes"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="맥용 NVM을 2분 안에 설정하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-NVMformacOSin2minutes_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="맥용 NVM을 2분 안에 설정하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">맥용 NVM을 2분 안에 설정하기</strong><div class="PostList_meta__VCFLX"><span class="date">21 hours ago</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="리눅스 시스템 관리자가 되는 법 사용자와 그룹 제 1부" href="/post/2024-05-16-BecomingLinuxSystemAdministratorusersandgroupspartI"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="리눅스 시스템 관리자가 되는 법 사용자와 그룹 제 1부" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-BecomingLinuxSystemAdministratorusersandgroupspartI_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="리눅스 시스템 관리자가 되는 법 사용자와 그룹 제 1부" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">리눅스 시스템 관리자가 되는 법 사용자와 그룹 제 1부</strong><div class="PostList_meta__VCFLX"><span class="date">21 hours ago</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="m3u 및 m3u8 재생목록 재생을 위한 온라인 비디오 플레이어 만들기" href="/post/2024-05-16-CreatinganOnlineVideoPlayerform3uandm3u8PlaylistPlayback"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="m3u 및 m3u8 재생목록 재생을 위한 온라인 비디오 플레이어 만들기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-CreatinganOnlineVideoPlayerform3uandm3u8PlaylistPlayback_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="m3u 및 m3u8 재생목록 재생을 위한 온라인 비디오 플레이어 만들기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">m3u 및 m3u8 재생목록 재생을 위한 온라인 비디오 플레이어 만들기</strong><div class="PostList_meta__VCFLX"><span class="date">21 hours ago</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Google I O 2024에서 Jetpack Compose의 새로운 소식" href="/post/2024-05-16-WhatsNewinJetpackComposeatGoogleIO2024"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Google I O 2024에서 Jetpack Compose의 새로운 소식" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-WhatsNewinJetpackComposeatGoogleIO2024_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Google I O 2024에서 Jetpack Compose의 새로운 소식" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">Google I O 2024에서 Jetpack Compose의 새로운 소식</strong><div class="PostList_meta__VCFLX"><span class="date">21 hours ago</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Pulumi 대 비교 IaC 도구 선택을 위한 확실한 안내" href="/post/2024-05-16-PulumiVSTerraformTheDefinitiveGuidetoChoosingYourIaCTool"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Pulumi 대 비교 IaC 도구 선택을 위한 확실한 안내" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-PulumiVSTerraformTheDefinitiveGuidetoChoosingYourIaCTool_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Pulumi 대 비교 IaC 도구 선택을 위한 확실한 안내" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">Pulumi 대 비교 IaC 도구 선택을 위한 확실한 안내</strong><div class="PostList_meta__VCFLX"><span class="date">21 hours ago</span><span class="PostList_reading_time__6CBMQ">17<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="올라마와 오픈 웹 UI를 쿠버네티스에 배포하기" href="/post/2024-05-16-DeployingOllamaandOpenWebUIonKubernetes"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="올라마와 오픈 웹 UI를 쿠버네티스에 배포하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-DeployingOllamaandOpenWebUIonKubernetes_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="올라마와 오픈 웹 UI를 쿠버네티스에 배포하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">올라마와 오픈 웹 UI를 쿠버네티스에 배포하기</strong><div class="PostList_meta__VCFLX"><span class="date">21 hours ago</span><span class="PostList_reading_time__6CBMQ">4<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="도커에서 extra_hosts를 사용하여 DNS 해결 단순화하기" href="/post/2024-05-16-SimplifyingDNSResolutioninDockerwithextra_hosts"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="도커에서 extra_hosts를 사용하여 DNS 해결 단순화하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-05-16-SimplifyingDNSResolutioninDockerwithextra_hosts_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="도커에서 extra_hosts를 사용하여 DNS 해결 단순화하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">도커에서 extra_hosts를 사용하여 DNS 해결 단순화하기</strong><div class="PostList_meta__VCFLX"><span class="date">21 hours ago</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><a class="link" href="/posts/1">1</a><a class="link" href="/posts/2">2</a><a class="link" href="/posts/3">3</a><a class="link" href="/posts/4">4</a><a class="link" href="/posts/5">5</a><a class="link" href="/posts/6">6</a><a class="link posts_-active__YVJEi" href="/posts/7">7</a><a class="link" href="/posts/8">8</a><a class="link" href="/posts/9">9</a><a class="link" href="/posts/10">10</a><a class="link" href="/posts/11">11</a><a class="link" href="/posts/12">12</a><a class="link" href="/posts/13">13</a><a class="link" href="/posts/14">14</a><a class="link" href="/posts/15">15</a><a class="link" href="/posts/16">16</a><a class="link" href="/posts/17">17</a><a class="link" href="/posts/18">18</a><a class="link" href="/posts/19">19</a><a class="link" href="/posts/20">20</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"Microsoft Fabric를 위한 확장 가능한 데이터 수집 프레임워크 구축하기","description":"","date":"2024-05-16 17:14","slug":"2024-05-16-BuildingascalabledataingestionframeworkforMicrosoftFabric","content":"\n\n이 기사는 고객 교류 중 자주 논의되는 주제인 데이터 엔지니어링 확장에 대해 다룹니다. 데이터 수집 및 유효성 검사 프로세스를 간소화하기 위한 방법을 어떻게 향상시킬 수 있을까요? 이 질문은 복잡하며, 원하는 대상 아키텍처, 데이터 품질 및 모델링 요구 사항, 메타데이터 관리 등과 같은 다양한 측면과 얽힌 문제입니다.\n\n데이터 엔지니어링 확장의 주요 도전 과제 중 하나는 코드 작성, 매개변수 설정, 파이프라인 테스트 및 성능 모니터링과 같은 반복적이고 종종 지루한 작업을 처리하는 out-of-the-box 솔루션이 부재한 점입니다. 이 문제는 서로 다른 조직들 사이에 요구 사항의 크고 다양한 변화 때문에 주로 발생합니다. 어떤 회사들은 원본 시스템에 대해 기술 표준을 매우 다양화시키지만, 다른 회사들은 공급업체가 적고 복잡한 원본 시스템을 유지합니다. 어떤 회사들은 데이터를 광범위하게 층으로 나누는 것을 선호하지만, 다른 회사들은 권장하는 3단계 Medallion Architecture로 충분히 만족합니다. 어떤 회사들은 다른 팀 간에 데이터 큐레이션을 민주화하는 것보다 중앙 통제를 선호합니다.\n\n복잡성과 다양성과 무관하게, 대부분의 기업의 목표는 데이터 엔지니어링을 간소화하기 위한 확장 가능한 수집 프레임워크를 구축하는 것입니다. Microsoft Fabric을 위한 최소한의 실용 제품을 만들면서 이 작업이 어떻게 이루어지는지 알아봅시다.\n\n주의! 이 글은 깊이 있는 포괄적인 블로그 글입니다. Microsoft Fabric를 직접 다뤄보고 데이터 파이프라인을 시작하고, 메타데이터 중심의 수집 프레임워크를 구현하고, 모든 것을 매력적이고 유익하게 통합해 보겠습니다. 서로 다른 섹션 간에 추가적인 고려 사항을 제공할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 모든 공학 작업을 표준화할 수는 없습니다\n\n확장성의 핵심은 메타데이터 중심의 수집 프레임워크를 구축하는 데 있습니다. 이를 통해 대부분의 작업을 자동화할 수 있습니다. 그러나 데이터 수집 또는 추출의 모든 단계를 쉽게 표준화하거나 동일한 수준의 자동화를 달성할 수 있다고 이해하는 것이 중요합니다. 이러한 과정을 자세히 살펴보고 왜 복잡성이 다양한지 이해해보겠습니다.\n\n여러 단계와 우리가 구현할 수 있는 자동화와 표준화의 정도를 설명하는 시각화를 만들었습니다. 왼쪽에는 추출 및 수집 과정이 있습니다. 데이터 엔지니어링의 첫 번째 단계는 기술과 공급업체 솔루션의 다양성 때문에 복잡합니다.\n\n예를 들어, 일부 공급업체는 고유한 API (Application Programming Interfaces) 또는 고유의 데이터 형식을 사용하여 데이터 추출을 수행합니다. 공급업체가 CSV 내보내기 형식 만 지원하는 경우, 여러분은 이에 맞게 프로세스를 조정해야 합니다. 한 번 이 장벽을 극복하고 데이터가 표준화 (Delta) 형식으로 제공되면, 더 많은 표준화와 자동화를 진행할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리 다이어그램으로 돌아와서, 브론즈(원시 데이터)에서 실버(정제 및 히스토라이즈된 데이터)로의 전환은 상당히 더 직관적으로 보입니다. 이 단계에서의 변환은 일반적으로 예측 가능하고 비교적 간단하여, 컬럼 이름 변경, 필터 적용, 데이터 기본값 설정 등의 작업을 포함합니다. 보다 예측 가능한 성격 때문에, 데이터 엔지니어링의 이 단계는 매개변수화하기가 더 쉽고 효율적이며 관리하기 용이합니다.\n\n데이터 엔지니어링 프로세스의 마지막 단계는 정제된 데이터를 소비자에게 전달하는 것을 포함합니다. 이 단계는 통합에 필요한 까다로운 비즈니스 로직 때문에 주로 매개변수화하기가 어렵습니다. 이 로직은 메타데이터만을 사용하여 쉽게 설명하기 어렵습니다. 그러나 우리는 워크플로우에 표준화 수준을 도입할 수 있습니다. 템플릿과 서비스를 활용하여 프로세스를 최적화하여 효율성을 높이고 더 효율적이고 관리하기 쉽도록 만들 수 있습니다.\n\n따라서 데이터 엔지니어링의 다른 단계들의 변화를 이해하고 관리하는 것은 확장 가능한 데이터 수집 프레임워크를 구축하는 데 중요합니다. 이제 손을 댄 예제를 사용하여 구체적인 내용으로 살펴봅시다.\n\n## MVP의 사전 요구 사항\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 제안하는 해결책이 Microsoft Fabric을 사용한다고 합니다. Microsoft Fabric에 익숙하지 않다면, 최신 데이터 솔루션을 구축하기 위해 설계된 클라우드 네이티브 플랫폼으로 Lakehouse 아키텍처를 활용하는 강력한 하이브리드 솔루션입니다. 이는 데이터 웨어하우스와 데이터 레이크의 기능을 결합한 것입니다.\n\n이 블로그 포스트에서는 Azure SQL에 호스팅된 AdventureWorks 샘플 데이터베이스를 활용하고, 모든 메타데이터를 저장하기 위해 또 다른 Azure SQL 데이터베이스를 활용할 것입니다. 따라서 이 글에서 안내하는 작업을 복제하려면 먼저 이러한 서비스를 배포해야 합니다.\n\nMicrosoft Fabric을 구성하려면 적어도 하나의 워크스페이스, Bronze, Silver 및 Gold라는 세 개의 Lakehouse, 그리고 비어 있는 데이터 파이프라인을 생성해야 합니다. 이 기본 설정은 데이터 엔지니어링 프로세스를 더 발전시키고 정제하는 데 필요한 토대를 마련할 것입니다.\n\n## 구성 — Copy Data 도구를 사용하여 파이프라인 생성하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n데이터 파이프라인 설계의 초기 단계는 데이터를 플랫폼으로 가져오는 것입니다. 이를 위해 우리는 Out-of-the-Box 커넥터를 활용할 것입니다. 저희 프로젝트에서는 다양한 데이터베이스 및 시스템을 지원하는 Data Factory를 사용할 것입니다. 우리의 데이터 소스는 AdventureWorks 샘플 데이터베이스를 호스팅하는 Azure SQL 서비스입니다.\n\n모든 데이터를 복사하는 대신, 관련 기능 테이블만 선택하기로 결정했습니다. Microsoft Fabric에서 새 데이터 파이프라인 항목을 정의하면, 첫 번째 단계는 Lookup 활동을 끌어다 놓는 것입니다. 설정으로 이동하여 외부를 선택하고 새로 만들어서 데이터 소스에 연결을 설정하기 위한 모든 필요한 정보를 입력하십시오. 원하는 테이블을 검색하기 위해 쿼리를 사용하십시오. 저는 그 목적으로 다음 문을 사용하고 있습니다:\n\n```js\nSELECT * FROM INFORMATION_SCHEMA.TABLES WHERE TABLE_TYPE = 'BASE TABLE' AND TABLE_SCHEMA = 'SalesLT'\n```\n\n또한, '첫 번째 행만'을 선택 해제해 주세요. 이러한 단계를 따르면 나머지 파이프라인을 설계할 준비가 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n각 데이터 원본이 다르게 작동한다는 점을 염두에 두는 것이 중요합니다. 따라서 작업 중인 원본에 따라 파이프라인의 초기 부분이 달라질 수 있습니다. 이것을 기억하며 파이프라인 디자인을 진행해 주세요.\n\n## Parquet 파일과 폴더를 사용한 스냅샷의 히스토라이징\n\n수집할 데이터를 결정한 후, 다음 단계는 이를 데이터 플랫폼으로 전송하는 것인데, 여기서는 Microsoft Fabric을 사용합니다. Medallion 아키텍처의 맥락에서, 이 데이터를 Bronze이라는 첫 번째 레이어에 저장할 것입니다. 이를 위해 두 가지를 달성하고자 합니다: 먼저, 파일 섹션에서 Parquet을 사용하여 모든 스냅샷의 히스토리를 만들 것이고, 두 번째로, 가장 최근 데이터를 Delta 테이블로 승격시킬 것입니다.\n\n이 두 가지 작업을 왜 수행하는 걸까요? 첫째, 히스토리컬 아카이브를 생성하면 어떤 손상된 레이어든 복구할 수 있습니다. 가장 최근 복사본만 유지했다면 오류 발생 시 데이터를 복구할 수 없었을 것입니다. 그래서, 시간을 되돌아가 데이터셋을 다시 처리할 수 있습니다. 둘째, 가장 최근 데이터를 Delta 파일로 승격시킴으로써 기계 학습이나 리포팅과 같은 서비스를 사용한 아훕적인 발견이 쉬워집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n두 가지 목표를 달성하기 위해 모든 필수 단계를 포함하는 ForEach 활동을 만들 것입니다. 이미 최종 결과를 보여줬지만, 이 작업을 복제하려면 ForEach 작업 내 첫 번째 활동은 Copy Data Activity가 될 것입니다.\n\n소스 파일을 선택하려면 소스 섹션으로 이동하세요. 이미 설정한 기존 연결을 재사용하세요. 테이블에 대해 두 가지 인수를 사용하겠습니다:\n\n```js\n@item().table_schema\n@item().table_name\n```\n\n대상으로는 Bronze Lakehouse를 사용할 것입니다. 워크스페이스에 아직 Bronze Lakehouse 항목을 만들지 않았다면 먼저 생성해야 합니다. 위치로는 Root Folder를 Files로 선택하세요. 그런 다음 파일 경로에 다음 식을 사용하세요. 저는 간단한 yyyyMMdd 분할 방식을 사용하고 있지만, 더 많은 데이터를 저장하려면 타임스탬프 또는 다른 방식을 사용해도 괜찮습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n@formatDateTime(utcnow(), 'yyyyMMdd')\n@concat(item().table_schema,'.',item().table_name,'.parquet')\n```\n\n위 단계를 완료하신 후에는 파이프라인을 실행하고 브론즈 레이어를 확인하여 결과를 유효성 검사하세요. 제 경우에는 결과가 다음과 같이 나타납니다. 즉시 다양한 폴더가 많이 보입니다. 각 폴더는 전달 날짜별로 구성되어 해당 일의 모든 기능 데이터를 포함합니다. 이 접근 방식은 데이터를 깔끔하고 연대적으로 배치하여 특정 정보를 찾기 쉽게 만듭니다.\n\n한 번 더 강조하자면, 채택된 방법론은 다루고 있는 소스 시스템의 종류에 크게 의존합니다. 이 시나리오에서는 Parquet 파일을 사용하여 데이터를 일괄 적재합니다. 그러나 형식은 CSV, XML, JSON 등 다양할 수 있습니다. 또한 적재 방법도 달라질 수 있습니다. 완전한 로드를 사용하는 대신 델타를 로드하거나 실시간 적재를 선택할 수도 있습니다.\n\n## 최신 Parquet 파일을 Delta 테이블로 승격하기\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 단계는 가장 최근 파일들을 Delta 테이블로 프로모션하는 것입니다. 이렇게 하면 이전에 처리된 데이터셋이 그대로 유지됩니다. 노트북을 사용하여 모든 것을 Bronze으로 프로모션할 것입니다. 따라서 파이프라인으로 돌아가서 ForEach 활동을 열고 노트북 활동을 드래그하여 Copy 활동에 연결하세요. \"새로 만들기\" 버튼을 클릭하여 하나를 생성해주세요.\n\n그 다음, 아래 제공된 내용을 새롭게 생성된 노트북에 복사하여 붙여넣으세요. 첫 번째 셀은 인수 셀이어야 하므로 해당 설정을 조정해야 할 수 있습니다. 또한 출력 위치를 변경하는 것을 기억하세요. 아래 코드에서 OneLake 위치를 하드코딩했지만, 실제 제품 환경에서는 해당 인수를 전달하려고 할 것입니다. 동일한 메타스토어 구성을 사용하고 소스 시스템을 대상 워크스페이스 및 레이크하우스 위치에 링크하는 방법을 고려할 수 있습니다.\n\n작업을 완료하면 노트북 옵션으로 돌아가세요. cw_table 및 cw_location 매개변수를 설정하고 준비가 되면 파이프라인을 실행하세요.\n\n```js\n@item().table_name\n@formatDateTime(utcnow(), 'yyyyMMdd')\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 모든 것이 원활하게 진행된다면, 브론즈 레이어 내에 새로 생성된 델타 테이블이 표시될 것입니다. 모든 테이블을 삭제하고 다시 구축하고 있음을 알려드립니다. 델타의 테이블 히스토리 기능을 활용할 필요가 없으니, 모든 데이터의 이전 복사본을 테이블 섹션에서 유지하고 있기 때문입니다.\n\n지금까지 추출 및 적재 접근 방식은 작업 중인 소스 시스템에 따라 달라질 수 있음을 염두에 두는 것이 중요합니다. 우리의 경우, 프로세스는 비교적 간단했습니다. 그러나 다른 상황에서는 데이터가 임시 위치나 랜딩 존에 착륙하거나 다른 형식으로 제공될 수 있습니다. 확장성을 보장하기 위해, 기술적 파일 형식 변환, 복잡한 구조의 해제, 추가 작업 등을 위한 반복 가능한 스크립트를 개발하는 것을 제안합니다. 또한 가능한 경우 최선의 방법을 채택하세요.\n\n## 메타데이터 저장소 구현\n\n이 글의 두 번째 부분에 도달했습니다. 이제 표준 파일 형식을 사용하여 브론즈 레이어에 데이터를 성공적으로 착륙시킨 상태에서 우리는 실버 레이어로 모든 것을 유효성 검사하고 히스토라이징하여 확장성을 더욱 강화하기 ready합니다. 이 부분은 더 간단하고 예측 가능합니다. 필터링, 열 이름 바꾸기, 데이터 비교와 같은 변환 작업은 비교적 간단하기 때문에 이러한 단계를 더 쉽게 자동화할 수 있습니다. 이를 위해 모든 중요한 구성을 보유하는 메타데이터 저장소를 사용할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n두 번째 Azure SQL 데이터베이스에는 모든 메타데이터를 보유하는 테이블을 생성하는 스크립트를 사용할 것입니다. 따라서 Azure SQL 데이터베이스로 이동하여 아래 제공된 스크립트를 실행하십시오. 제 목표는 철저한 접근 방식을 제공하는 것이 아니라 일반적인 개념을 설명하는 것이므로 참고해 주세요.\n\n```js\nCREATE TABLE SchemaMetadata  \n(  \n    Id INT IDENTITY(1,1) PRIMARY KEY,  \n    TableName NVARCHAR(128),  \n    ColumnName NVARCHAR(128),  \n    DataType NVARCHAR(128),  \n    CharacterMaximumLength INT,  \n    NumericPrecision INT,  \n    NumericScale INT,  \n    IsNullable NVARCHAR(3),  \n    DateTimePrecision INT,  \n    IsPrimaryKey BIT DEFAULT 0  \n)  \nGO \n```\n\n다음으로는 AdventureWorks 예제 데이터베이스에서 스키마 메타데이터를 검색해야 합니다. 이를 위해 정보 스키마에서 모든 메타데이터를 읽는 간단한 스크립트를 개발했습니다. 이 스크립트는 메타데이터 저장소에 대한 INSERT 문을 생성하는 데 사용될 수 있습니다. 이 예에서는 하나의 테이블로 설명하고 있음을 참고해 주세요.\n\n```js\nSELECT   \n    TABLE_NAME as 'TableName',  \n    COLUMN_NAME as 'ColumnName',  \n    DATA_TYPE as 'DataType',  \n    CHARACTER_MAXIMUM_LENGTH as 'CharacterMaximumLength',  \n    NUMERIC_PRECISION as 'NumericPrecision',  \n    NUMERIC_SCALE as 'NumericScale',  \n    IS_NULLABLE as 'IsNullable',  \n    DATETIME_PRECISION as 'DateTimePrecision',  \n    COLUMNPROPERTY(OBJECT_ID(TABLE_NAME), COLUMN_NAME, 'IsIdentity') as 'IsPrimaryKey'  \nFROM   \n    INFORMATION_SCHEMA.COLUMNS  \nWHERE   \n    TABLE_NAME = 'Address'\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n수집한 스키마 메타데이터를 활용하여 저희 메타데이터 저장소의 Azure SQL 데이터베이스로 돌아가서 모든 레코드를 삽입해주세요. 아래는 참고용 예시입니다.\n\n```js\nINSERT INTO SchemaMetadata  \n(TableName, ColumnName, DataType, CharacterMaximumLength, NumericPrecision, NumericScale, IsNullable, DateTimePrecision, IsPrimaryKey)  \nVALUES  \n('Address', 'AddressID', 'int', NULL, 10, 0, 'NO', NULL, 1),  \n('Address', 'AddressLine1', 'nvarchar', 60, NULL, NULL, 'NO', NULL, 0),  \n('Address', 'AddressLine2', 'nvarchar', 60, NULL, NULL, 'YES', NULL, 0),  \n('Address', 'City', 'nvarchar', 30, NULL, NULL, 'NO', NULL, 0),  \n('Address', 'StateProvince', 'int', NULL, 10, 0, 'NO', NULL, 0),  \n('Address', 'PostalCode', 'nvarchar', 15, NULL, NULL, 'NO', NULL, 0),  \n('Address', 'CountryRegion', 'geography', NULL, NULL, NULL, 'YES', NULL, 0),  \n('Address', 'rowguid', 'uniqueidentifier', NULL, NULL, NULL, 'NO', NULL, 0),  \n('Address', 'ModifiedDate', 'datetime', NULL, NULL, NULL, 'NO', 3, 0);  \nGO\n```\n\n아래에 최종 결과가 표시됩니다.\n\n지금까지 수집한 메타데이터는 테이블 이름, 열, 데이터 형식, 널 가능 속성, 기본 키 등을 포함한 기본적인 내용뿐입니다. 계속해서 특정 도메인 정보, 여러 소스에 대한 메타데이터, 민감도 레이블과 같은 보안 메타데이터, 행 필터링을 위한 메타데이터 등으로 확장할 수 있습니다. 또한 소스 열을 대상 열로 이름 바꾸기, 간단한 조인 또는 연합 실행, 관련 없는 데이터 필터링 등과 같은 더 복잡한 처리 로직에 대한 메타데이터도 통합할 수 있습니다. 최종적으로 메타데이터의 범위는 특정 요구 사항 및 미래 사용 사례에 따라 다를 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저희 실습 예제로 돌아가 봅시다. 준비가 되셨다면 ForEach 활동으로 돌아가세요. 여기에 새 Lookup 활동을 추가해 보세요. 이 작업은 워크플로에 끌어다 놓으면 새 연결을 설정하여 메타데이터 저장소에서 읽어옵니다. 호출을 만들기 위해 테이블 이름을 입력으로 사용할 것이기 때문에 다음 표현식을 사용하세요:\n\n```js\n@concat('SELECT * FROM [dbo].[SchemaMetadata] WHERE TableName=''',item().table_name,'''')\n```\n\n이 설정에서는 table_name 인수만 전달하고 있음을 유의해 주세요. 보다 상세한 설정에서는 데이터베이스 이름과 버전 등 추가 인수를 사용할 것으로 예상합니다.\n\n## Great Expectations을 활용한 데이터 품질 검증하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음으로 데이터 처리 및 처리에 자동화 기능을 도입해 보겠습니다. 브론즈 단계의 데이터를 메타스토어의 메타데이터를 사용하여 유효성을 검사하는 것이 첫 번째 단계입니다. 이를 위해 새 'If Condition' 활동을 끌어다 놓으세요.\n\n조건을 설정하기 위해 LookupMetadata 활동의 수를 검증하는 식을 사용할 것입니다. 수가 0을 초과하면 처리할 메타데이터가 있는 것을 나타냅니다.\n\n```js\n@greater(activity('LookupMetadata').output.count, 0)\n```\n\n이제 앞으로 나아가서 워크스페이스 내에서 Fabric 환경을 설정해야 합니다. 이 환경에는 데이터 유효성을 검사하는 데 필요한 패키지가 포함될 것입니다. 이번 데모에서는 데이터 품질 검증을 위한 인기 있는 오픈 소스 도구인 'Great Expectations'를 사용할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시작하려면 작업 공간으로 이동한 후 상단의 '새로 만들기'를 클릭하십시오. 드롭다운에서 '새 환경'을 선택하십시오. 이 작업으로 대화 상자가 나타납니다. 여기서 공개 라이브러리 아래에 'great-expectations'를 추가해야 합니다. 이 작업을 완료한 후 '게시'를 클릭하십시오. 새 환경을 사용할 준비가 될 때까지 시간이 걸릴 수 있다는 점을 참고해 주세요.\n\n이후에는 데이터로 돌아가 'If Condition' 내부에 새로운 'Notebook' 활동을 추가하십시오. '설정 및 매개변수' 섹션에 'metadata'라는 새 매개변수를 추가해야 합니다. 해당 표현식을 사용하여 다음과 같이 입력하십시오.\n\n```js\n@string(activity('LookupMetadata').output.value)\n```\n\n이제 Python 스크립트 아래에서 제공된 내용을 사용하여 새로운 Notebook을 작성할 시간입니다. 이 스크립트에서는 우선 'metadata' 매개변수를 확인하고 JSON 형식으로 변환합니다. 그런 다음, 메타데이터를 반복하면서 데이터 품질 규칙을 작성합니다. 게다가, 데이터가 잘못된 경우 프로세스를 중지할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n노트북 자체에 대해: 새로 생성한 환경을 노트북 환경 내에서 선택해야 합니다.\n\n모든 단계를 완료한 후에 데이터 파이프라인을 시작하세요. 모든 것이 원활하게 진행되면, 메타데이터가 사용되어 데이터 품질을 동적으로 검증합니다. 이 유효성 검사는 기본적이며 현재는 열 이름만을 확인합니다. 그러나 이 스크립트는 기본 키 확인, 널 값 허용 여부, 고유성 등을 포함하여 얼마든지 확장할 수 있습니다.\n\n## Silver에 처리된 데이터의 히스토라이징\n\n데이터 파이프라인 생성의 이 부분에서는 Slowly Changing Dimensions(Type 2)를 사용하여 데이터를 히스토라이징할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n형태를, 친절한 톤으로 번역하겠습니다.\n\nSCDs(Slowly Changing Dimensions)는 현재 및 과거 데이터를 시간이 지남에 따라 단일 테이블에 통합합니다. 이 접근 방식은 여러 가지 이유로 중요합니다. 먼저, SCD는 데이터 진화의 전체적인 관점을 제공하여 트렌드 분석을 수행하고 머신러닝 모델을 구축하는 데 중요합니다. 이 과정은 데이터 진행을 시간에 따라 이해하는 데 도움이 됩니다. 둘째, SCD는 데이터 무결성과 일관성을 유지하는 데 도움이 됩니다. 마지막으로, SCD를 사용하면 효율성이 향상됩니다. 특정 시간대의 필요한 데이터만 추출하여 수백 개의 파일을 다시 처리할 필요가 없어집니다. 아래는 SCD 테이블이 어떻게 보이는지의 결과를 보실 수 있습니다.\n\n데이터 품질 유효성 검사와 마찬가지로, 이 파이프라인의 이 부분도 자동화할 수 있습니다. 데이터를 비교하고 히스토리를 저장하기 위한 또 다른 노트북 활동을 추가해 봅시다.\n\n이 작업을 위해 조금의 메타데이터를 사용할 것입니다. 'LookupMetadata' 활동으로부터 테이블 이름과 메타데이터를 제공하겠으며, 다른 노트북에 전달하여 아래와 같이 공유될 것입니다.\n\n```js\n@item().table_name\n@string(activity('LookupMetadata').output.value)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 스크립트에 대해 이야기해 봐요. 메타데이터 내에 기본 키가 제공된 경우, 해당 키는 비교를 위한 기능 키로 사용됩니다. 그렇지 않은 경우, 행 내의 모든 값들을 입력으로 사용하여 고유 해시 값을 생성합니다. 저는 MERGE SQL 문을 사용하지 않기로 결정했는데요, 이전 데이터셋에서 같은 데이터를 다시 제출하거나 이전 데이터를 삭제해도 레코드를 완전히 제어하고 닫고 다시 열기를 원하기 때문입니다.\n\n실버 레이어에서는 Delta Lake의 시간 여행 기능을 활용합니다. 따라서 테이블 자체에 기능적인 히스토리 데이터를 저장하는 것 외에도 트랜잭션 로그에서 변경 사항을 기록합니다. 이 접근 방식은 잘못 처리된 데이터셋을 지우는 유연성을 제공합니다. 예를 들어, 같은 이름을 공유하는 모든 고객을 포함하는 고객 파일이 제공되었다고 가정해 보세요. 기술적 데이터 품질 유효성 검사는이 문제를 감지하지 못할 수도 있으며, 결과적으로 이 데이터가 실버 레이어로 침투할 가능성이 높아집니다. 그러면 이전 레코드가 모두 업데이트되고 닫힐 것입니다. 이 문제를 해결하기 위해 시간 여행을 사용하여 이전 상태로 되돌릴 수 있습니다. 그런 다음 원본 시스템에 보정된 전달을 요청하고, 유효성을 검사하고 검토하여 보정된 데이터를 실버 레이어에 다시 통합시킬 수 있습니다.\n\n## 실버 레이어를 위한 몇 가지 고려 사항\n\n위에서 언급한 전략을 구현하면, 실버 레이어까지 데이터는 여전히 소스 중심입니다. 이러한 모범 사례를 따르는 것이 좋습니다. 실버 레이어에서 소스 중심 데이터를 유지하면 데이터 소유권을 결정하는 데 도움이 됩니다. 소스와 일치하는 데이터 제품을 관리하고 구축하는 것이 목표라면 엔지니어들에게 다른 도메인 애플리케이션 간에 데이터를 교차 조인하지 않도록 안내하는 것이 중요합니다. 더 엄격한 설계 접근 방식은 각 소스 시스템을 자체 Lakehouse 엔터티와 일치시키는 것입니다. 이렇게 하면 더 깨끗하고 효율적인 데이터 관리 전략을 보장하며, 데이터 중심 프로젝트를 감독하고 실행하기가 더 쉬워집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n실버 레이어를 계산 또는 비즈니스 로직과 같은 요소로 강화하는 계획을 세울 때 고려해야 할 사항이 몇 가지 있어요. 이러한 변환은 쉽게 매개변수화할 수 없어요. 그 결과, 이전 자동화된 단계를 기반으로하는 추가적인 실버 레이어를 만들어야 할지 고민해보실 필요가 있을지도 모르겠네요. 이 전략은 느슨한 결합과 유연성을 촉진하여 효율적인 데이터 관리를 위한 필수 구성 요소를 제공해요. 이 추가 레이어를 설정하는 데 더 많은 노력이 필요할 수 있지만, 제공하는 유연성은 투자의 가치가 있답니다. 이 접근 방식은 데이터 시스템의 기능을 향상시킬 뿐만 아니라 (원본에 맞게 정렬된) 데이터 제품을 비즈니스 요구 사항에 추가로 적응시킬 수 있는 것을 보장해요.\n\n## 실버에서 골드로 처리하기\n\n메달리온 아키텍처에서 골드 레이어는 \"프로젝트별\" 또는 \"사용 사례별\" 데이터로 구성되어 있어서 즉시 사용할 수 있는 데이터를 보관하고 있어요. 이 통합 단계는 복잡하며 특정 요구 사항에 매우 의존하고 있기 때문에 이전에 언급한 대로 복잡한 비즈니스 규칙을 포함할 가능성이 있어요. 변환에는 후속 처리 단계, 계산, 보강, 사용 사례별 최적화 등이 포함될 수 있어요.\n\n골드 레이어는 아키텍처의 범위에 크게 의존하기 때문에 가장 복잡한 부분을 제공할 가능성이 높아요. 가장 간단한 설정에서는 골드 레이어가 통합과 사용 사례 레이어로 모두 작동할 수 있어요. 즉, 데이터를 먼저 통합한 다음 조직의 고유한 사용 사례에 따라 특정 하위 집합을 선택하여 맞춤화하여 구조화할 수 있어요. 이 맞춤화된 접근 방식은 데이터 아키텍처가 견고하며 조직의 특정 요구 사항과 목표에 최적으로 정렬되어 있는 것을 보장해줘요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여러 도메인을 포함하는 아키텍처를 사용한다면, 골드 계층은 여러 하위 계층으로 나눌 수 있습니다. 예를 들어, 하나의 계층은 다양한 소스 시스템에서 초기 데이터 통합에 특화될 수 있습니다. 이어지는 계층은 특정 사용 사례를 위해 설계되며, 따라서 특정 요구 사항을 충족하기 위해 하위 집합을 맞춤화할 수 있습니다. 또 다른 계층은 새로운 데이터 제품을 개발하기 위해 할당될 수 있습니다. 이러한 계층들은 집계로 통칭되는 것을 형성하게 됩니다. 이에 대해 더 알고 싶다면, 메달리온 아키텍처의 층화에 관한 다른 블로그 포스트를 참조해 주세요.\n\n다음 블로그 포스트에서는 Microsoft Fabric 내에서 DBT를 사용하여 실버와 골드 간의 데이터 변환과 통합을 표준화하는 방법을 시연할 예정입니다. DBT는 템플릿과 명령줄 인터페이스를 활용하는 데이터 변환 도구로, 프로세스를 간단하게 만들어 줍니다.\n\n## 결론\n\n메타데이터 기반의 수집 프레임워크 없이 수십 개 또는 수백 개의 소스 시스템을 도입하는 것은 어려운 작업일 수 있습니다. 복잡성은 각 소스 시스템을 모든 스크립트, 파이프라인, 활동 등을 수동으로 관리해야 한다는 점에서 발생합니다. 이는 시간이 많이 소요되며 오류가 발생하기 쉽고 표준화가 부족합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n메타데이터 주도 방식은 이 프로세스를 간소화합니다. 전통적인 코드 기반 전략에 비해 여러 가지 장점을 제공합니다:\n\n- 메타데이터 주도 방식을 채택함으로써 파이프라인의 다양성과 적응성을 향상시킬 수 있습니다. 이를 통해 다양한 데이터 원본과 목적지를 지원할 수 있으며, 서로 다른 형식, 스키마 및 빈도에 맞도록 할 수 있습니다. 또한, 처리 기술을 조정함으로써 전체 로드, 증분 로드 또는 전체 덮어쓰기와 같은 여러 흡수 패턴을 수용할 수 있습니다.\n- 메타데이터 주도 프레임워크는 작성하고 유지해야 하는 코드 양을 크게 줄일 수 있습니다. 여러 노트북을 작성하는 대신, 메타데이터를 기반으로 다양한 데이터 원본 및 목적지를 처리할 수 있는 통합 파이프라인을 생성하면 됩니다.\n- 이 방식을 통해 개발 및 배포 프로세스가 크게 단순화되고 표준화됩니다. 메타데이터를 사용하여 손쉽게 검증 및 수정을 추가할 수 있어 코드를 변경하거나 파이프라인을 재배포할 필요가 없습니다.\n- 파이프라인 설계에 따라 병렬 처리와 동시성을 달성하여 여러 복사 또는 노트북 활동을 동시에 실행할 수 있습니다. 이렇게 하면 파이프라인의 성능과 효율성을 최적화할 수 있습니다.\n\n이 글이 도움이 되었기를 바랍니다. 데이터 품질, Microsoft Fabric, Microsoft Purview 등에 관한 기사를 더 많이 게시했음을 유의해 주세요! 또한, 이 블로그 게시물의 일부 내용은 \"대규모 데이터 관리\"이라는 책에서 인용되었음을 참고해 주세요.","ogImage":{"url":"/assets/img/2024-05-16-BuildingascalabledataingestionframeworkforMicrosoftFabric_0.png"},"coverImage":"/assets/img/2024-05-16-BuildingascalabledataingestionframeworkforMicrosoftFabric_0.png","tag":["Tech"],"readingTime":15},{"title":"Tidymodels를 사용하여 고객 이탈 분류 모델 구축과 평가하기","description":"","date":"2024-05-16 17:11","slug":"2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels","content":"\n\n![표](/assets/img/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels_0.png)\n\n모델을 처음 배울 때, 아주 오래 전에는 서로 다른 패키지에서 서로 다른 매개변수 이름으로 다양한 방법으로 모델을 구축하는데 여러 가지 방법이 있었습니다. 그런 다음 tidymodels를 사용하기 시작하면서 모델 빌딩을 일관된 방식으로 다양한 상황과 엔진에서 쉽게 작성할 수 있는 방법에 대해 기쁘게 놀랐습니다. 이는 서로 다른 모델에 대해 백 가지 형식과 매개변수를 기억할 필요가 없어지며 결과를 비교하기가 훨씬 쉬워졌다는 것을 의미했습니다.\n\n이 글에서는 매우 일반적인 고객 이탈 예측 시나리오를 예로 들어, tidy한 방법으로 모델을 구축하고 결과를 비교하는 방법에 대해 안내하겠습니다.\n\n# 코드\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 글의 모든 코드는 내 GitHub Repo에서 찾을 수 있어요.\n\n# 모델링을 시작해봅시다\n\n## 단계 0: 환경 설정\n\n필요한 패키지를 설치하려면 install.packages(\"package_name\")과 같은 개별 명령을 실행하거나 아래 명령을 실행하여 모든 패키지를 로드하세요. 해당 명령은 이미 존재하지 않는 경우에만 패키지를 설치한 후 로드합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```r\n# 패키지 불러오기\n\npackages \u003c- c(\"tidyverse\", \"tidymodels\", \"skimr\", \"GGally\")\n\npackage.check \u003c- lapply(packages, FUN = function(x) {\n  if (!require(x, character.only = TRUE)) {\n    install.packages(x, dependencies = TRUE)\n    library(x, character.only = TRUE)\n  }\n})\n```\n\n## 단계 1: 데이터셋\n\n이 연습에서는 Simarpreet Singh의 Kaggle에서 Creative Commons Attribution 4.0 International 라이선스(CC BY 4.0)로 사용 가능한 Binary Classification of Bank Churn Synthetic Data를 사용합니다.\n\n데이터셋은 \"Exited\" 열을 포함하고 있으며 이는 고객이 떠났는지 여부를 나타냅니다. 이를 예측할 것입니다. 먼저 데이터셋을 로드하고 데이터셋의 모습을 살펴볼 것입니다:```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```R\nbankchurn_df \u003c- read.csv(\"./data/bank_churn.csv\")\n\nbankchurn_df |\u003e \n  glimpse()\n```\n\n\u003cimg src=\"/assets/img/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels_1.png\" /\u003e\n\n## Step 2: 데이터 정제\n\n저는 모델의 특성으로 사용되지 않을 ‘Surname’이라는 용어를 포함하는 열을 제거할 것입니다. 또한 이진 분류를 위해 출력 변수인 Exited를 팩터 변수로 변환할 것입니다.\n  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```R\nbankchurn_df_upd \u003c- bankchurn_df |\u003e \n  select(Exited, everything()) |\u003e \n  mutate(Exited = as.factor(Exited)) |\u003e \n  select(-contains(\"Surname\")) \n```\n\n## 단계 3: 탐색적 데이터 분석\n\n특정 열에 대해 파고들기 전에 데이터를 초기 이해하기 위해 skim() 명령을 사용할 것입니다. 이 명령은 각 열의 분포를 제공하여 모든 변수가 동일한 척도에 있지 않다는 점을 알 수 있도록 도와줍니다.\n\n```R\nbankchurn_df_upd |\u003e \n  skim()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nmd\n![이미지](/assets/img/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels_2.png)\n\n이제 ggpairs()를 사용하여 몇 가지 예측 변수를 조사하여 출력 변수와의 관계를 이해해 보겠습니다.\n\n```js\nbankchurn_df_upd |\u003e \n  select(Exited, CreditScore, Age, Tenure, Balance) |\u003e \n  ggpairs(mapping = aes(colour = Exited, alpha = 0.3)) +\n  scale_fill_manual(values=c('darkgreen', 'red')) +\n  scale_colour_manual(values=c('darkgreen', 'red'))\n```\n\n![이미지](/assets/img/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels_3.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 패키지는 변수간의 관계를 빠르게 이해하는 데 도움이 됩니다. 이제 성별, 위치 및 출력 변수 간의 관계를 확인하겠습니다.\n\n![image](/assets/img/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels_4.png)\n\n상관 매개변수는 예측 변수 간에 강한 관계가 있는지 확인합니다.\n\n이제 모델링 단계로 넘어가겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 단계 4: 훈련/테스트 분리\n\n모든 모델링 과정에서처럼, 첫 번째 단계는 학습된 모델 정확도를 예측할 무작위 테스트 세트를 보류하는 것입니다. 이를 위해 initial_split() 명령을 사용할 것입니다. 재현성을 위해 시드를 설정하고 training() 및 testing() 함수를 사용하여 분할에 액세스할 것입니다.\n\n```js\nset.seed(123)\nbc_split \u003c- initial_split(bankchurn_df_upd, prop = 3/4, strata = \"Exited\")\n\ntrain_data \u003c- training(bc_split)\ntest_data \u003c- testing(bc_split)\n```\n\n## 단계 5: 피처 엔지니어링\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이전에 수행한 탐색적 데이터 분석을 바탕으로, 몇 가지 기본 기능 엔지니어링을 수행할 것입니다. 이를 위해 recipe()를 사용하면 매우 쉽게 반복 가능한 단계 세트를 생성할 수 있습니다. 이를 통해 일반적인 기능 엔지니어링 작업에 대해 자세한 코드를 작성할 필요가 없습니다. 이 시나리오에서 다음을 수행하려고 합니다:\n\n- 명목 변수를 더미 변수로 변환하되 결과 변수는 따로 두기.\n- 단일 값만 포함하거나 분산이 0인 변수를 제거.\n- 숫자 예측 변수를 정규화하기. 이는 일부 변수가 서로 다른 척도에 있기 때문에 필요합니다.\n\n```r\nbc_recipe \u003c- recipe(Exited ~ ., data = bankchurn_df_upd) %\u003e%\n  step_dummy(all_nominal(), -all_outcomes()) %\u003e%\n  step_zv(all_numeric()) %\u003e%\n  step_normalize(all_numeric()) %\u003e%\n  prep()\n\nbc_recipe %\u003e%\n  bake(new_data = NULL) \n```\n\n\u003cimg src=\"/assets/img/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels_5.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 단계 5: 모델 명세 및 워크플로우 작성\n\n저는 파스니프(parsnip)를 사용하여 두 가지 모델 명세와 워크플로우를 작성할 것입니다. 이를 통해 다양한 모델에서 이를 표준화된 접근으로 생성할 수 있는 방법을 보여줄 것입니다.\n\n```js\nlr_mod \u003c- logistic_reg() |\u003e \n  set_mode(\"classification\") |\u003e \n  set_engine(\"glm\")\n\nlr_mod\n```\n\n![이미지](/assets/img/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels_6.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 레시피를 모델 학습과 결합하는 워크플로를 만들겠습니다.\n\n```js\nlr_workflow \u003c- \n  workflow() |\u003e \n  add_model(lr_mod) |\u003e \n  add_recipe(bc_recipe)\n\nlr_workflow\n```\n\n![Image](/assets/img/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels_7.png/)\n\n이제 랜덤 포레스트 모델에 대해서도 위 단계를 반복할 것입니다. 모델 사양과 워크플로 생성의 유사한 구조에 주목하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```R\nrand_forest_ranger_model \u003c- rand_forest(\n  mode = \"classification\", mtry = 10, trees = 500, min_n = 20) |\u003e\n  set_engine(\"ranger\", importance = \"impurity\") \n\nrand_forest_ranger_model\n\nrf_workflow \u003c- workflow() |\u003e \n  add_model(rand_forest_ranger_model) |\u003e \n  add_recipe(bc_recipe)\n\nrf_workflow\n```\n\n\u003cimg src=\"/assets/img/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels_8.png\" /\u003e\n\n\u003cimg src=\"/assets/img/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels_9.png\" /\u003e\n\n## Step 6: 데이터 적합하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nfit() 함수를 사용하여 생성한 워크플로우를 활용하여 데이터를 학습 데이터 세트에 맞추겠습니다.\n\n```js\nlr_fit \u003c- \n  lr_workflow |\u003e\n  fit(data = train_data)\n\nrf_fit \u003c- \n  rf_workflow |\u003e\n  fit(data = train_data)\n```\n\n## 단계 7: 피처 중요도\n\n선형 모델의 경우 tidy()라는 명령을 사용할 수 있어 이전에 맞춘 모델의 구성 요소에 쉽게 액세스할 수 있습니다. 이를 액세스한 후, 예측 변수들을 특정 지표(이 경우 p-값)에 따라 정렬할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nlr_fit |\u003e \n  extract_fit_parsnip() |\u003e \n  tidy() |\u003e \n  arrange(p.value)\n```\n\n![Image](/assets/img/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels_10.png)\n\nRandom forest를 위해, extract_fit_parsnip() 함수를 사용하여 fit를 추출할 거예요. 그런 다음 importance() 명령어를 사용하여 특성과 그들의 지표를 추출할 거예요.\n\n```js\nextract_fit_parsnip(rf_fit)$fit |\u003e \n  ranger::importance() |\u003e \n  enframe() |\u003e \n  arrange(desc(value))\n``` \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels_11.png\" /\u003e\n\n## Step 8: 테스트 데이터셋에서 예측하기\n\n두 모델 모두, 이전에 맞춘 모델에 predict() 함수를 사용하여 테스트 데이터셋에서 예측을 추출할 것입니다. 이진 분류의 경우, 기본적으로 이는 예측값으로 0 또는 1의 클래스 유형을 반환합니다. 확률 값을 얻기 위해, type 매개변수를 \"prob\"로 업데이트할 것입니다.\n\n```js\n# 로지스틱 회귀\nclass_pred_lr \u003c- predict(lr_fit, test_data)\nprob_pred_lr \u003c- predict(lr_fit, test_data, type = \"prob\")\n\n# 랜덤 포레스트\nclass_pred_rf \u003c- predict(rf_fit, test_data)\nprob_pred_rf \u003c- predict(rf_fit, test_data, type = \"prob\")\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 클래스와 확률 출력 예시입니다:\n\n![Class and Probability Outputs](/assets/img/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels_12.png)\n\n동일한 테이블 내에서 두 출력을 모두 접근하기 위해 이 두 종류의 예측을 단일 데이터프레임으로 결합할 것입니다. 나는 비즈니스 시나리오에 따라 두 출력 클래스가 중요하다고 생각하기 때문에 이를 결합하려 합니다. 그 후 이 출력을 원래의 테스트 데이터셋과 병합하여 결과를 비교할 수 있도록 클래스, 확률 및 원래 \"Exited\" 값이 동일한 테이블 안에 있는 것을 확인할 것입니다. 아래는 최종 병합된 테이블이 어떻게 생겼는지에 대한 내용입니다.\n\n```r\n# 로지스틱 회귀\nlr_preds_combined \u003c- \n  data.frame(class_pred_lr, prob_pred_lr) |\u003e \n  select(class = .pred_class, prob_no = .pred_0, prob_yes = .pred_1) |\u003e \n  bind_cols(test_data)\n\n# 랜덤 포레스트\nrf_preds_combined \u003c- \n  data.frame(class_pred_rf, prob_pred_rf) |\u003e \n  select(class = .pred_class, prob_no = .pred_0, prob_yes = .pred_1) |\u003e \n  bind_cols(test_data)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels_13.png)\n\n이제 예측값을 가지고 있으니, 이 모델들의 정확도를 측정해 봅시다.\n\n## 단계 9: 성능 지표 이해\n\nROC 곡선은 서로 다른 임계값에서 이진 분류 방법의 성능을 보여줍니다. 이는 실제 양성 비율(TPR)을 거짓 양성 비율(FPR)에 대해 그립니다. roc_curve() 함수를 사용하여 roc 곡선의 값을 얻을 것입니다.\n  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# 로지스틱 회귀\nlr_roc \u003c- lr_preds_combined |\u003e \n  roc_curve(truth = Exited, prob_no) |\u003e \n  mutate(model = \"로지스틱 회귀\")\n\n# 랜덤 포레스트\nrf_roc \u003c- rf_preds_combined |\u003e \n  roc_curve(truth = Exited, prob_no) |\u003e \n  mutate(model = \"랜덤 포레스트\")\n\n# ROC curve 값 결합\nlr_roc |\u003e \n  bind_rows(rf_roc) |\u003e \n  glimpse()\n```\n\n\u003cimg src=\"/assets/img/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels_14.png\" /\u003e\n\nautoplot() 함수를 사용하여 ROC 커브를 시각화할 수 있지만, 이 경우에는 두 모델의 ROC 커브를 동시에 보기 위해 ggplot2를 사용하여 처음부터 플로팅하겠습니다.\n\n```js\nlr_roc |\u003e \n  bind_rows(rf_roc) |\u003e \n  ggplot(aes(x = 1 - specificity, y = sensitivity, color = model)) +\n  geom_line() +\n  geom_abline(lty = 2) +\n  labs(y = \"True Positive Rate\", \n       x = \"False Positive Rate\",\n       title = \"ROC 커브\") +\n  theme_bw()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n헷갈리는 행렬(Confusion matrix)은 분류 모델의 성능을 요약하는 표입니다. Tidymodels 내 caret 패키지는 confusionMatrix()라는 함수를 제공하여 많은 유용한 정보를 제공합니다. 이를 사용하여 최종 모델을 선택하기 전에 두 모델의 지표를 비교할 것입니다.\n\n```R\n# 로지스틱 회귀\ncaret::confusionMatrix(lr_preds_combined$Exited,\n                       lr_preds_combined$class,\n                       positive = \"1\")\n\n# 랜덤 포레스트\ncaret::confusionMatrix(rf_preds_combined$Exited,\n                       rf_preds_combined$class,\n                       positive = \"1\")\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n랜덤 포레스트 모델은 로지스틱 회귀 모델과 비교하여 정확도, 민감도 및 특이도를 포함한 대부분의 메트릭에서 성능이 더 좋습니다. 그러나 랜덤 포레스트의 계산 요구량은 높을 수 있습니다. 그래서 특정 비즈니스 시나리오에서 정확도 향상의 중요성에 따라, 어떤 모델이 강조되어야 할지 선택할 수 있습니다.\n\n# 다음 단계\n\n이 기사가 tidymodels 프레임워크 내의 패키지 시리즈가 제공하는 강력하고 일관된 접근 방법을 이해하는 데 도움이 되었기를 바랍니다. 가치를 보여주기 위해 두 모델만 다루었지만, 유사한 구문을 사용하여 구축할 수 있는 다른 모델들이 많이 있습니다.\n\n이러한 모델을 더욱 신뢰할 수 있게 만드는 또 다른 방법은 tidymodels에서 제공하는 도구를 사용하여 교차 검증하는 것입니다. 이에 대해 다른 기사에서 다룰 예정입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 글의 모든 코드는 제 GitHub Repo에서 찾을 수 있어요. LinkedIn에서 제를 만나고 싶다면 연락해주세요.\n\n이 글의 모든 이미지는 다른 경우가 아닌 한 저자가 찍었어요.","ogImage":{"url":"/assets/img/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels_0.png"},"coverImage":"/assets/img/2024-05-16-BuildingandEvaluatingCustomerChurnClassificationModelswithTidymodels_0.png","tag":["Tech"],"readingTime":10},{"title":"암스테르담에 관한 최고의 재미있는 사실 ","description":"","date":"2024-05-16 17:09","slug":"2024-05-16-IusedWindowsforaYearButImSwitchingBacktoMac","content":"\n\n그리고 여기에 그 이유가 있어요\n\n![image](/assets/img/2024-05-16-IusedWindowsforaYearButImSwitchingBacktoMac_0.png)\n\n저는 평생 MacOS 사용자입니다. 윈도우 컴퓨터는 한 번도 소유한 적이 없었는데요 — 작년쯤, 갑자기 강한 욕구와 필요성으로 윈도우 PC를 구매하게 되었습니다.\n\n제 맥북에 문제가 있거나 만족스럽지 않았기 때문은 아니에요. 다음과 같은 이유 때문이었죠:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 최근에는 거의 사용하지 않았던 Windows를 시도해보고 싶었고, 내 친구들이 다 사용하고 있어서 그랬어요.\n- Windows를 더 익숙해지는 것이 대학 수업을 위해 도움이 될 것 같았어요 (우리 수업에서는 주로 Windows를 사용하거든요)\n- Minecraft가 아닌 다른 비디오 게임을 해보고 싶었어요.\n\n몇 일간의 조사 끝에, 중간 정도 성능의 프리빌트 PC를 구입했어요. 모든 부품을 따로 사는 것도 고려했지만, PC 조립 부분은 경험이 없어서 손대기 싫었어요.\n\n게다가, 이 프리빌트 PC를 사는 게 부품을 따로 사는 것보다 더 싸다는 것을 알게 되었어요. 부품들이 할인 중이었고, 개별 구매보다 더 좋은 거래였죠.\n\n어쨌든, 윈도우 11이 장착된 PC를 거의 1년 사용한 후의 생각과, 왜 다시 맥으로 돌아가기로 결정했는지 알려드릴게요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저, Windows에 대해 가장 감사했던 점에 대해 이야기하고 싶습니다.\n\n## 소프트웨어 이용 가능성\n\nWindows 생태계에 대해 말할 때 가장 좋은 점은 Windows에서 작동하는 소프트웨어의 양이 매우 많다는 것입니다. 필요한 모든 응용프로그램, 프로그램 또는 도구가 거의 확실히 Windows에서 작동합니다. 이는 Windows가 세계에서 가장 많이 사용되는 데스크톱 운영 체제임을 감안하면 놀라울 것이 없습니다.\n\nMacOS 사용자로서, 이것은 매우 편리하게 느꼈습니다. 필요한 모든 소프트웨어를 쉽게 찾을 수 있었고, 내 장치에서 작동할지 걱정할 필요가 없었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n몰래 말하자면, PC를 구입한 몇 달 후 우리는 대학 과정의 일환으로 C# 프로그래밍 언어와 .NET Windows Forms 프레임워크에 작업을 시작했어요. 이 기술은 Windows에서만 작동하기 때문에 나만의 Windows 기기를 갖게 되어 정말 편리했어요. 수업 외에서도 문제없이 프로젝트를 연습하고 작업할 수 있었거든.\n\n## 게임 지배\n\n두 번째로, 내가 원하는 거의 모든 게임을 할 수 있는 능력은 정말 놀랍게 느껴졌어요. 사탕가게에서 어떤 사탕을 살지 결정하는 것 같은 기분이었어요.\n\n\u003cimg src=\"/assets/img/2024-05-16-IusedWindowsforaYearButImSwitchingBacktoMac_1.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 측면에서는 확실히 Mac 환경에서 제약을 받았어요. 그렇다고 나쁠 수록, 이것이 저가 PC를 구매하고 싶었던 주요 이유 중 하나였어요. 말하고 싶지 않은데, 실망하지 않았습니다. 1440p 해상도에서 중상위 설정에서 100프레임 이상으로 거의 모든 게임을 할 수 있었어요.\n\n게임을 하는 대부분의 시간은 2019년 Call of Duty Modern Warfare와 더 최근 Modern Warfare II를 플레이하는 데 보냈어요. 꽤 많이 플레이하고 집중한 시간도 있었어요.\n\n하지만 그만큼 많이 플레이해서 다소 죄책감을 느꼈기 때문에 그걸 줄이고 더 생산적인 활동으로 대체해야 했어요.\n\n## 훌륭한 구성 가능성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n맥에서의 맞춤 설정은 주로 표면적으로만 집중되어 있는 것 같아요 — 멋진 벽지를 선택하고, 밝거나 어두운 테마를 선택하는 정도가 전부에요. 이것이 나쁜 것은 아니지만, 그에 비해 윈도우는 깊게 파고들 수 있는 옵션들을 제공해줘요.\n\n그리고 UI 설정에 대해 이야기하는 게 아닙니다. 윈도우는 다음과 같은 것들을 커스터마이즈할 수 있게 해줘요:\n\n- 하드웨어 제어: CPU, GPU, 메모리의 오버클럭 설정 및 성능 최적화를 위한 팬 커브 조정이 가능해요.\n- 시스템 설정: 네트워크 구성에 대한 더 깊은 접근, 전원 관리 옵션, 배터리 프로필 등\n- 주변기기 커스터마이즈: 고급 키보드 및 마우스 설정 및 구성 옵션\n- 써드파티 도구: 다양한 것들에 대한 추가 맞춤 설정을 허용하는 기타 유틸리티들\n\n# macOS가 더 잘하는 것들\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기술적인 장점이 있더라도 맥보다는 윈도우가 더 나은 부분이 많았습니다.\n\n## 간결한 디자인 \u0026 사용자 경험\n\n윈도우는 11 버전에서 UI와 디자인을 많이 개선했지만, 여전히 맥과 비교할 만하지 않습니다.\n\n맥OS 인터페이스는 분명히 우아하며, 미니멀리즘과 직관적인 디자인에 중점을 둔 것이 눈에 띕니다. 독부터 창 제어까지 모두 신중하게 고려되고 광택이 돌아, 시각적 조화를 만들어 냅니다. 이것이 윈도우에서 그리운 점입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아름다움 이상으로 Mac은 항상 더 부드러운 사용자 경험을 제공합니다. 폴더 탐색, 파일 관리, 그리고 멀티태스킹과 같은 간단한 작업도 편안하고 순조로운 느낌이 들어요. 이것은 운영 체제와 싸우는 대신 작업에 더 집중할 수 있게 해줘요.\n\n## Apple 통합\n\n이 부분은 정말 중요해요!\n\nMacOS 생태계의 진정한 매력은 저에게 넓은 Apple 생태계와의 원활한 연결에 있어요. 여러 Apple 기기를 가지고 있음으로써 저는 상당한 시간과 노력을 절약하고, 생산성을 높이고 짜증나는 중단을 줄일 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기서 가장 많이 활용하는 두 가지 기능은 Universal Clipboard과 AirDrop입니다. Universal Clipboard을 사용하면 한 장치에서 텍스트, 이미지 또는 다른 미디어를 복사하여 다른 장치에 붙여넣기할 수 있습니다. 처음에는 쓸모 없어 보일 수 있지만, 실제로 매우 편리합니다.\n\nAirDrop도 마찬가지로 애플 장치 간 빠른 파일 전송을 가능케 합니다. 이 기능 없이는 살 수 없어요.\n\nWindows를 사용할 때 이렇게 하려고 했는데, 할 수 없다는 것을 깨닫고 파일을 이메일이나 WhatsApp을 통해 자신에게 보내야 했어요.\n\n이것이 내가 메인 장치로 다시 macOS로 전환하기로 결정한 주요 이유 중 하나였습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 더 나은 개발 생태계\n\n개발자로서 저는 종종 터미널을 사용합니다. 그리고 윈도우에서는 똑같이 작동하지 않는다는 사실을 깨달을 때 정말 답답했었어요. 저는 맥에서의 유닉스 기반 도구 및 원활한 터미널 통합에 너무 익숙해져서 윈도우는 끊임없는 고통으로 느껴졌어요. 제 프로젝트를 탐색하기 위해 기본 명령을 다시 배워야 하거나 서툰 해결책을 찾아야 하는 것은 제 생산성을 크게 저해했어요.\n\n터미널 외에도 많은 오픈소스 개발 도구 및 프레임워크는 유닉스와 유사한 시스템을 기반으로 설계된 것처럼 보이죠. 이러한 도구들을 윈도우에서 설치하고 설정하는 것은 종종 추가 단계나 호환성 문제를 유발했어요.\n\n윈도우에는 많은 강력한 개발 도구들이 있고 생산적인 환경을 구성하는 것이 분명히 가능하지만, 저에게는 맥이 더 잘 작동하고 문제를 훨씬 덜 겪게 되는 편이에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 결론\n\nWindows를 1년 동안 사용하면서 즐거운 시간을 보냈습니다. Mac에서는 할 수 없는 일들을 할 수 있게 해주었죠. 거의 모든 소프트웨어를 사용하고 게임 가능성을 열어줬어요. 그 이상으로 새로운 것을 배우게 해주었고, 다른 시스템과 함께 작업하는 소중한 경험을 만들어 주었습니다.\n\n하지만 문제가 없었던 것은 아니에요.\n\n최종적으로 Mac의 우아함, 직관적인 인터페이스, 그리고 다른 Apple 기기들과의 원활한 통합이 제게 다시 돌아오게 만들었어요. 제 업무와 아이디어가 가장 자연스럽게 흐르는 곳이고, 어릴 때부터 익숙한 OS였죠. 그래서 계속해서 Mac을 주 사용 장치로 사용하기로 결정했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위 내용이 어떻게 생각하시는지 댓글로 알려주세요. 어떤 OS를 선호하시나요?\n\n이 Medium에서 제 첫 이야기 중 하나에요. 읽어주셔서 감사합니다. 즐겁게 읽으셨길 바라요!","ogImage":{"url":"/assets/img/2024-05-16-IusedWindowsforaYearButImSwitchingBacktoMac_0.png"},"coverImage":"/assets/img/2024-05-16-IusedWindowsforaYearButImSwitchingBacktoMac_0.png","tag":["Tech"],"readingTime":5},{"title":"맥용 NVM을 2분 안에 설정하기","description":"","date":"2024-05-16 17:08","slug":"2024-05-16-NVMformacOSin2minutes","content":"\n\n![NVM for MacOS](/assets/img/2024-05-16-NVMformacOSin2minutes_0.png)  \n  \n애플리케이션이 Node.js 아키텍처를 기반으로 한 경우, 서로 다른 버전 간을 전환할 수 있는 능력은 기존 프로젝트와 최신 플랫폼 기능을 활용하기 위해 필수적입니다. 그러나 MacOS와 같은 운영 체제에서는 네이티브로 통합되지 않아 버전 관리가 복잡해질 수 있습니다.\n\n# NVM이란?\n\nNVM은 하나의 시스템에서 여러 버전의 Node.js를 쉽게 설치하고 관리할 수 있게 해주는 명령줄 도구입니다. 그러나 MacOS에서의 구현은 환경 및 의존성 관리에 대한 차이로 인해 다른 운영 체제와 비교했을 때 특별한 도전을 안겨줍니다. 왜냐하면 MacOS에는 내장되어 있지 않기 때문에 대신 Homebrew를 설치해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 어떻게 설치하나요?\n\n터미널을 열고 다음 명령어로 Homebrew를 설치하세요:\n\n```js\n/bin/bash -c \"$(curl -fsSL \u003chttps://raw.githubusercontent.com/Homebrew/install/master/install.sh\u003e)\"\n```\n\nHomebrew가 설치되면 NVM을 설치할 차례입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nbrew install nvm\n```\n\nNVM을 사용하려면 항상 ~/.bash_profile 또는 ~/.zshrc 파일에 포함해야 합니다:\n\n```js\nsource $(brew --prefix nvm)/nvm.sh\n```\n\n이 파일들을 찾을 수 없는 경우 sudo su 명령어를 사용하여 수퍼유저로 접근하여 찾을 수 있습니다. 만약 해당 파일이 없다면, 직접 생성할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nNVM을 설치한 후에는 NodeJS의 최신 버전을 설치할 차례입니다:\n\n```js\nnvm install node\n```\n\n설치가 완료되면 우리가 원하는 NodeJS 버전들을 설치할 수 있습니다. 이를 위해 컴퓨터에 설치된 모든 버전을 확인하려면 다음 명령을 사용하십시오:\n\n```js\nnvm ls-remote\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 우리가 설치하고 싶은 버전을 모른다면 공식 NodeJS 웹사이트를 참고할 수 있어요. 설치하고 싶은 버전을 알고 있다면 다음 명령어를 입력하면 돼요:\n\n```js\nnvm install [설치할 버전]\n\n## 예시:\nnvm install 18.10.0\n```\n\n설치되면 아래와 같이 사용할 수 있어요:\n\n```js\nnvm use [사용할 버전]\n\n## 예시:\nnvm use 18.10.0\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 우리가 다른 버전으로 변경하길 원한다면 먼저 nvm list로 설치된 모든 버전을 나열해야 합니다. 원하는 버전을 찾으면 nvm use [원하는 버전 번호]를 사용하여 해당 버전을 사용할 수 있습니다.\n\n# 결론\n\nHomebrew를 통해 MacOS에 NVM을 설치하면 Node.js 버전 관리가 크게 간소화됩니다. NVM을 사용하면 시스템에서 여러 버전의 Node.js를 쉽게 설치, 전환 및 관리할 수 있어서 다양한 프로젝트에 적응하고 최신 플랫폼 기능을 활용할 수 있습니다. 몇 가지 터미널 명령만으로 새로운 버전을 설치하고 이를 전환하며 개발 환경이 항상 호환되고 최신 상태임을 보장할 수 있습니다. 확실히 NVM을 통해 macOS에서 Node.js 개발 환경을 완전히 제어할 수 있어서 호환성 문제나 오래된 버전에 대해 걱정하지 않고 놀라운 애플리케이션을 만드는 데 집중할 수 있습니다.","ogImage":{"url":"/assets/img/2024-05-16-NVMformacOSin2minutes_0.png"},"coverImage":"/assets/img/2024-05-16-NVMformacOSin2minutes_0.png","tag":["Tech"],"readingTime":2},{"title":"리눅스 시스템 관리자가 되는 법 사용자와 그룹 제 1부","description":"","date":"2024-05-16 17:06","slug":"2024-05-16-BecomingLinuxSystemAdministratorusersandgroupspartI","content":"\n\n“리눅스는 여러 사용자 계정을 동시에 사용할 수 있는 다중 사용자 운영 체제로, 서버로 사용하기에 이상적입니다.\n\n어머니의 날 특별 할인 이벤트, 아마존 기기 최대 50% 할인 (쇼핑)\n\n![이미지](/assets/img/2024-05-16-BecomingLinuxSystemAdministratorusersandgroupspartI_0.png)\n\n- 컴퓨터 및 액세서리 베스트셀러 (쇼핑용 뷰)\n- 노트북 컴퓨터 베스트셀러 (쇼핑용 뷰)\n- 컴퓨터 네트워킹 베스트셀러 (쇼핑용 뷰)\n- 리눅스 운영 체제 베스트셀러 (쇼핑용 뷰)\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n리눅스에서는 각 계정을 사용자 이름과 UID(즉, 고유 번호로 할당된 사용자 ID)로 정의할 수 있습니다. 또한, 각 계정은 기본 그룹에 속하며 실행할 셸과 홈 디렉터리도 가지고 있습니다. 관련 정보는 /etc/passwd 파일에 저장되어 있으며 cat 명령어를 사용하여 확인할 수 있습니다. 터미널에서 단순히 \"cat /etc/passwd\" 명령어를 실행해봅시다:\n\n```js\ndavid@debian:~$ cat /etc/passwd\nroot:x:0:0:root:/root:/bin/bash\n--중략--\ndavid:x:1000:1000:David Beckham:/home/david:/bin/bash\n--중략--\n\n사용자이름:비밀번호:UID:GID:설명:홈_디렉터리:셸\n```\n\n/etc/passwd 파일의 첫 번째 항목인 \"root:x:0:0:root:/root:/bin/bash\"은 루트 계정에 대한 정보를 보여줍니다. 위의 마지막 줄에 표시된 형식에 따라 /etc/passwd 파일의 다른 항목에도 동일한 적용됩니다. 이 형식의 각 필드는 콜론(:)으로 구분됩니다. 따라서 루트 계정과 일반 사용자 david의 형식과 출력을 쉽게 매치할 수 있습니다 (위의 \"cat /etc/passwd\" 출력 참조).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n패스워드 필드의 x는 암호화된 비밀번호가 별도의 파일 /etc/shadow(아래 설명)에 저장되어 있음을 나타냅니다. 이 파일은 슈퍼유저만 읽을 수 있습니다. 이것은 누구나 시스템에서 /etc/passwd 파일을 읽을 수 있지만(암호화되어 있긴 하지만) 보안 위험이 초래될 수 있기 때문에 필요합니다.\n\n다음은 UID를 살펴봅시다. 루트 계정의 경우, UID는 항상 0으로 표시됩니다. 터미널에서 \"cat /etc/passwd\"를 실행하면, 루트나 일반 사용자 외에도 UID가 1000 미만인 계정이 많이 나올 것입니다. 이들은 시스템에서 사용되는 계정들로, 파일 /etc/login.defs를 업데이트하여 구성할 수 있습니다. 이 파일을 직접 확인해보세요:\n\n```js\ndavid@debian:~$ cat /etc/login.defs\n#\n# /etc/login.defs - Configuration control definitions for the login package.\n#\n# 세 가지 항목은 반드시 정의되어야 합니다: MAIL_DIR, ENV_SUPATH, ENV_PATH.\n# 정의되지 않은 경우, 임의의 (가능성 있는) 값으로 간주됩니다. 다른 모든 항목은 선택 사항입니다.\n# 주석 문장(문장이 \"#\"으로 시작하는 문장)과 공백 문장은 무시됩니다.\n#\n# 리눅스용으로 수정되었습니다.  --marekm\n\n# useradd/userdel/usermod에 필수\n#   메일함이 위치하는 디렉토리, _또는_ 파일의 이름, 홈 디렉토리를 상대로한 파일의 이름. 만일\n#   MAIL_DIR 및 MAIL_FILE을 정의할 경우, MAIL_DIR가 우선됩니다.\n#\n#   기본적으로:\n#      - MAIL_DIR는 사용자 메일 스불 파일의 위치를 정의하며, 아래에 정의된 것처럼\n#        MAIL_DIR에 사용자 이름을 추가함으로써(mbox 사용시) 정의됩니다.\n#      - MAIL_FILE은 사용자 메일 스불 파일의 위치를 정의하며, 사용자 홈 디렉토리를\n#        $MAIL_FILE 앞에 붙여 편리하게 얻은 완전한 경로 파일 이름으로 정의됩니다 \n#      \n# 알림: 이는 더 이상 사용자 메일 환경 변수 설정에 사용되지 않습니다\n#       이는 Debian에서 쉐도우 4.0.12-1부터 완전히 pam_mail PAM 모듈의 업무가 되었으며\n#       login, su 등에 대한 기본 PAM 구성 파일을 참고하세요.\n#\n--snip--\n```\n\n다시 /etc/passwd 파일로 돌아와서, GID는 해당 계정의 기본 그룹을 나타냅니다. 사용자가 파일을 새로 만들면, 해당 파일은 자동으로 사용자의 기본 그룹에 속하게 됩니다. 그러나 사용자가 다른 그룹을 사용하려면 newgrp 명령을 사용할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n“username:password:UID:GID:comments:home_dir:shell” 형식으로 우리가 논의 중인 바에 따르면, 5번째 필드 (comments)는 계정에 대한 설명이나 원할 경우 비워둘 수 있습니다. 이 필드를 가끔 GECOS 필드라고도 부르는데, 이는 초기 Unix 시절의 관행을 따른 것입니다. 그리고 짐작할 수 있겠지만, 시스템에 로그인하면 일반적으로 홈 디렉터리(home_dir)에 배치됩니다. 루트의 경우는 /root이며, 예시로는 David의 경우 /home/david입니다. 그러나 사용자의 홈 디렉터리가 존재하지 않는 경우에는 루트 디렉터리가 대신 사용됩니다.\n\n마지막으로, shell 필드는 사용자가 계정으로 로그인할 때 실행될 쉘을 나타냅니다. 시스템에 설치된 쉘을 확인하려면 /etc/shells 파일을 확인할 수 있습니다:\n\n```js\ndavid@debian:~$ cat /etc/shells \n# /etc/shells: valid login shells\n/bin/sh\n/bin/dash\n/bin/bash\n/bin/rbash\n/usr/bin/tmux\n```\n\n여기서 주목할 점은 /etc/passwd 파일의 shell 필드에 나열된 내용이 실제 쉘이 아닌 경우에도 로그인 시 실행된다는 것입니다. 이러한 이유로 /usr/sbin/nologin 또는 /bin/false과 같이 shell 필드에 여러 계정에 대해 다양한 항목이 채워진 것을 터미널에서 볼 수 있을 것입니다. 이러한 계정은 누구에게도 상호 작용적으로 사용될 수 없습니다. 더불어 필요에 따라 사용자가 로그인할 때 특정 프로그램을 실행할 수 있도록 shell 필드를 사용할 수 있습니다. 예를 들어, 필요한 경우 사용자를 특정 응용프로그램에 강제 접근시킬 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 '/etc/shadow' 파일 내용을 확인해보겠습니다.\n\n```js\ndavid@debian:~$ sudo cat /etc/shadow\nroot:$6$9g1IC8AYzqPorEZSHjWeZP8o21:16502:0:99999:7:::\n--중략--\n```\n\n여기서 각 필드(총 9개의 필드)가 콜론(:)으로 구분되어 있고 아래와 같이 나타납니다.\n\n- 사용자 이름\n- 암호화된 비밀번호\n- 1970년 1월 1일부터 현재까지의 일 수(여기서는 16502)로 비밀번호가 변경된 날짜\n- 비밀번호를 변경할 수 있는 일 수(여기서는 0)\n- 비밀번호를 변경해야 하는 일 수. 여기서 99999는 사용자가 비밀번호를 변경할 필요가 없음을 나타냅니다.\n- 사용자에게 비밀번호가 만료될 것임을 알리는 일 수\n- 비밀번호가 만료된 후 계정이 비활성화되는 일 수(미할당)\n- 계정이 비활성화된 날로부터 현재까지의 일 수(미할당)\n- 미래 사용을 위한 예약된 필드\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위를 읽으면 특정 날짜 01/01/1970이 사용된 이유에 궁금증을 느낄 수 있습니다. 컴퓨팅 에포크와 유닉스 시간을 읽어보시기를 권해 드립니다.\n\n이 강의는 책을 기반으로 합니다. 즉, Linux Administration: The Linux Operating System and Command Line Guide for Linux Administrators (킨들, 페이지)\n\n![이미지](/assets/img/2024-05-16-BecomingLinuxSystemAdministratorusersandgroupspartI_1.png)\n\n- Linux 운영 체제 베스트셀러 (쇼핑 보기)\n- Linux 네트워킹 및 시스템 관리 베스트셀러 (보기)","ogImage":{"url":"/assets/img/2024-05-16-BecomingLinuxSystemAdministratorusersandgroupspartI_0.png"},"coverImage":"/assets/img/2024-05-16-BecomingLinuxSystemAdministratorusersandgroupspartI_0.png","tag":["Tech"],"readingTime":5},{"title":"m3u 및 m3u8 재생목록 재생을 위한 온라인 비디오 플레이어 만들기","description":"","date":"2024-05-16 17:04","slug":"2024-05-16-CreatinganOnlineVideoPlayerform3uandm3u8PlaylistPlayback","content":"\n\n저는 m3u 및 m3u8 형식의 재생 목록을 재생할 수 있는 플레이어를 만든 경험을 공유하고 싶어요.\n\n아이디어의 기원\n\n몇 년 전, 축구 중계 시청이 비싼 구독료나 많은 광고로 제한되어 있을 때, 작은 비용으로 다양한 채널을 제공하는 서비스를 사용하기 시작했어요. 해당 서비스는 m3u8 형식의 파일을 제공했죠. iOS에서는 이 형식의 재생 목록을 재생하는 옵션이 제한되어 있었어요: 사용 가능한 앱은 유료이거나 세션 당 여러 차례 보이는 광고로 가득 찼었어요. 또한, 서비스에서 제공한 파일을 파싱할 수 없는 VLC 플레이어 문제도 있었고 OttPlayer는 일시적으로 앱 스토어에서 사라져 있었는데 (지금은 다시 이용 가능해요), 이러한 상황으로 인해 나만의 플레이어를 만들게 되었어요.\n\n첫 번째 버전의 개발\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n세 개월 동안 플레이어의 첫 번째 버전을 개발했어요. 디자인과 네비게이션은 인기 앱에서 영감을 받았어요. 애플리케이션의 아이콘은 스톡 자원에서 구매하고, 앱 아이콘은 온라인 편집기를 사용하여 만들었어요. iOS의 내장 AVPlayerViewController를 비디오 재생의 기초로 선택했어요. 처음 몇 달 동안 앱은 다운로드 숫자가 적었지만, 아시아 블로거가 자신의 텔레그램 채널에서 언급한 후 상황이 바뀌었어요.\n\n![이미지](/assets/img/2024-05-16-CreatinganOnlineVideoPlayerform3uandm3u8PlaylistPlayback_0.png)\n\n개선사항과 새로운 기능\n\n이후에 플레이리스트 작업을 위한 많은 기능이 추가되었어요. 검색, 편집, 링크 기반로딩을 포함해서 말이에요. 하지만 이는 다운로드의 큰 증가로 이어지지 않았어요. 그래서 사용자 정의와 비디오 로딩/버퍼링 추적에 관한 문제점을 해결하여 플레이어를 개선하기로 결정했어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기존 AVPlayer를 기반으로 한 향상된 플레이어가 만들어졌으며 전체 화면 모드, AirPlay 기능 및 화면 내 화면 모드를 지원합니다. 새 버전은 앱의 안정성을 향상시키고 비디오 로딩 상태를 추적하거나 플레이어에 새 기능을 추가하는 문제를 해결했습니다. 이 라이브러리는 MIT 라이선스 하에 링크를 통해 사용할 수 있습니다.\n\n사용자 정의 플레이어 버전으로 전환한 후, 안정성 비율(크래시 없음)이 95%로 감소했습니다. 스택 추적을 분석해도 명확한 해결책을 제시하지 않았고, 에러를 내 기기에서 재현할 수 없었습니다. 로딩 프로세스를 추적하기 위해 KVO를 사용한 부분에 의심이 생겼습니다. KVO 구독의 존재를 기록하는 변수를 추가함으로써 문제를 해결했습니다. 이는 구독해지 프로세스를 적절히 관리할 수 있도록 했습니다. 이 핫픽스를 구현하면 크래시가 완전히 없어졌습니다.\n\n형식 지원 확장\n\nAVPlayer는 다양한 비디오 형식을 지원하지 않습니다. 이로 인해 일부 채널에서는 재생되지 않거나 다른 채널은 오디오는 있지만 비디오가 없는 경우가 있습니다. 이 문제에 대한 해결책을 찾는 과정에서 LGPLv2.1 라이선스 하에 배포되는 오픈 소스 VLC 플레이어를 찾았습니다. 이 라이선스로 인해 소프트웨어 상에서 라이브러리를 사용할 수 있지만 해당 변경 사항이 있을 경우 라이브러리를 오픈해야 하는 제약이 있음을 이해하는 데 시간이 걸렸습니다. 이에 반해 GPLv2는 모든 코드를 동일한 라이선스 하에 공개해야 하지만 해당 변경 사항을 공개해야 하는 요구는 없습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nVLCKit 통합에 관한 이슈입니다. VLCKit은 Cocoapods와 Carthage를 통해 설치가 가능하지만, 제 프로젝트는 Swift Package Manager (SPM)를 사용하고 있습니다. GitHub에서 VLCKit을 SPM용으로 패키징한 저장소를 발견했지만, 최신 버전의 라이브러리를 포함하고 있지 않았습니다. 그래서 포크를 생성하고 VLCKit을 최신 버전으로 업데이트했습니다.\n\n이제는 라이브러리를 프로젝트에 통합하는 일만 남았습니다. 구독을 통해 별도의 향상된 플레이어를 개발 및 판매하려는 아이디어가 있었지만, VLCKit은 PIP(화면 내 화면) 기능을 지원하지 않았고, AirPlay 기능도 오디오만 전송했습니다. 결과적으로 AVPlayer를 기반으로 한 플레이어를 사용하여 링크를 열기로 결정했습니다. 재생이 실패하거나 비디오 스트림이 누락된 경우에는 VLCKit이 도움을 줍니다. 만약 VLCKit도 실패한다면 사용자에게 채널을 이용할 수 없다는 안내가 제공됩니다. VLC 지원을 한 라이브러리는 여기에서 이용 가능합니다.\n\n일부 수치\n\n앱의 대부분 사용자는 중국과 러시아에 있지만, 지난 달 미국의 다운로드가 크게 증가했습니다. 트래픽 유입에 투자하지 않았습니다. 지역화 전략과 사용자가 리뷰를 남길 수 있는 새로운 기능 도입이 특히 효과적이었습니다. 피드백 수집을 위해 앱 내평가 시스템을 사용하고 있지만, 대부분의 사용자가 텍스트 리뷰 대신 앱에 평가를 내리고 있습니다. 앞으로 사용자들이 적극적으로 리뷰를 작성하도록 유도하는 매커니즘을 개발해야 하며, 이는 앱 스토어에서 앱의 가시성 향상에 도움이 될 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image1](/assets/img/2024-05-16-CreatinganOnlineVideoPlayerform3uandm3u8PlaylistPlayback_1.png)\n\n![image2](/assets/img/2024-05-16-CreatinganOnlineVideoPlayerform3uandm3u8PlaylistPlayback_2.png)\n\n![image3](/assets/img/2024-05-16-CreatinganOnlineVideoPlayerform3uandm3u8PlaylistPlayback_3.png)\n\n![image4](/assets/img/2024-05-16-CreatinganOnlineVideoPlayerform3uandm3u8PlaylistPlayback_4.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nMonetization\n\n저는 AdMob에서 세 가지 유형의 광고를 실험해 보았습니다: 피드에 통합된 네이티브 광고, 인터스티셜 광고 및 앱 오픈 광고입니다. 처음에는 네이티브 광고를 사용했지만 수익은 미미했습니다. 그런 다음 앱 오픈 광고로 전환했는데, 지표가 약간 향상되었지만 여전히 기대에 못 미쳤습니다. 마지막으로 사용한 것은 인터스티셜 광고였습니다. 앱 오픈 광고가 앱 시작 시 표시되는 용도라는 것을 고려하면 이상적이지는 않지만, 그들의 eCPM은 상당히 높았습니다. 현재 앱을 열 때 3시간마다 한 번 광고가 표시됩니다.\n\n![이미지](/assets/img/2024-05-16-CreatinganOnlineVideoPlayerform3uandm3u8PlaylistPlayback_5.png)\n\n프로젝트 개발을 위한 계획은 무엇입니까?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저, 플랜은 온보딩을 추가하는 것입니다. 이를 통해 인터넷에서 재생 목록을 검색하는 방법을 설명하고, 가능하다면 비디오를 통해 시연할 것입니다. 애플의 가이드라인에 따라 비디오가 거절될 수 있지만 시도해 볼 가치가 있습니다. 추가로 비디오 재생을 멈추는 타이머가 도입되고, 화면 방향 잠금 기능도 추가될 예정입니다.\n\n여기까지 입니다. 주목해 주셔서 감사합니다!\n\nPS: 앱 링크입니다.","ogImage":{"url":"/assets/img/2024-05-16-CreatinganOnlineVideoPlayerform3uandm3u8PlaylistPlayback_0.png"},"coverImage":"/assets/img/2024-05-16-CreatinganOnlineVideoPlayerform3uandm3u8PlaylistPlayback_0.png","tag":["Tech"],"readingTime":4},{"title":"Google I O 2024에서 Jetpack Compose의 새로운 소식","description":"","date":"2024-05-16 17:03","slug":"2024-05-16-WhatsNewinJetpackComposeatGoogleIO2024","content":"\n\nGoogle I/O 2024에서는 특히 Jetpack Compose를 활용한 UI 개발 영역에서 개발자들을 위한 중요한 진전 사항이 소개되었습니다. 최신 업데이트를 자세히 살펴보고, 개발 경험을 향상시키는 방법을 탐색해 보겠습니다.\n\n![](/assets/img/2024-05-16-WhatsNewinJetpackComposeatGoogleIO2024_0.png)\n\n## Compose Multiplatform: 하나의 코드베이스, 다중 플랫폼\n\nJetpack Compose는 macOS 및 웹 플랫폼을 지원하는 능력을 확장했습니다. 이 발전을 통해 개발자들은 공유 코드베이스를 유지하고, 개발 프로세스를 간소화하며, 다양한 장치에서 일관된 경험을 보장할 수 있습니다. 한 번 작성하고 여러 플랫폼에 배포하는 능력은 개발 시간과 노력을 줄이면서 높은 품질의 사용자 경험을 유지할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n안녕하세요! 안드로이드, macOS 및 웹에서 작동하는 Jetpack Compose UI의 간단한 예제입니다:\n\n```js\nimport androidx.compose.desktop.ui.tooling.preview.Preview\nimport androidx.compose.runtime.Composable\nimport androidx.compose.ui.window.singleWindowApplication\n\n@Composable\nfun Greeting(name: String) {\n    Text(text = \"Hello, $name!\")\n}\n\n@Preview\n@Composable\nfun GreetingPreview() {\n    Greeting(\"Compose\")\n}\n\nfun main() = singleWindowApplication {\n    Greeting(\"World\")\n}\n```\n\n## Compose Material 3: 디자인 현대화\n\n최신 Material Design 가이드라인과 일치하는 Compose Material 3는 UI 구성 요소에 현대화된 접근 방식을 소개합니다. 이 업데이트는 시각적 매력을 강화하고 새로운 디자인 요소를 통합하여 앱이 디자인 트렌드와 함께 유지되도록 보장합니다. Material 3는 보다 유연성이 향상되고 새로운 테마 옵션을 제공하여 더 다이나믹하고 표현력 있는 UI를 구현할 수 있도록 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```kotlin\nimport androidx.compose.material3.*\n\n@Composable\nfun Material3ThemeExample() {\n    MaterialTheme {\n        Surface(color = MaterialTheme.colorScheme.background) {\n            Text(text = \"Hello Material 3!\", style = MaterialTheme.typography.h4)\n        }\n    }\n}\n```\n\n## Compose 컴파일러를 통한 향상된 성능\n\nJetpack Compose 컴파일러는 상당한 성능 향상을 이룩했습니다. 더 효율적인 코드 작성을 가능하게 하는 새로운 API가 도입되었고, 오버헤드를 줄이고 개발 과정을 최적화합니다. 이는 더 부드러운 애니메이션과 빠른 UI 렌더링으로 이어지며, 궁극적으로 더 나은 사용자 경험을 제공합니다.\n\n효율적인 목록 렌더링을 위해 LazyColumn 사용하기: \n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```kotlin\nimport androidx.compose.foundation.lazy.LazyColumn\nimport androidx.compose.foundation.lazy.items\nimport androidx.compose.runtime.Composable\n\n@Composable\nfun NamesList(names: List\u003cString\u003e) {\n    LazyColumn {\n        items(names) { name -\u003e\n            Text(text = name)\n        }\n    }\n}\n```\n\n## 접근성 향상: 포용적 디자인\n\n접근성은 앱 개발의 중요한 측면이었고, Jetpack Compose는 이를 더욱 발전시키고 있습니다. 새로 도입된 도구와 기능은 개발자들이 더 접근성이 뛰어난 앱을 만들 수 있도록 설계되었습니다. 이에는 더 나은 스크린 리더 지원, 향상된 포커스 관리 및 모든 사용자에게 앱을 사용할 수 있게 하는 기타 기능이 포함되어 있습니다.\n\n접근성을 위해 Modifier.semantics 사용하기:\n```      \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```kotlin\nimport androidx.compose.foundation.clickable\nimport androidx.compose.foundation.layout.fillMaxSize\nimport androidx.compose.foundation.layout.padding\nimport androidx.compose.material3.Text\nimport androidx.compose.runtime.Composable\nimport androidx.compose.ui.Modifier\nimport androidx.compose.ui.semantics.Role\nimport androidx.compose.ui.unit.dp\n\n@Composable\nfun AccessibleButton(onClick: () -\u003e Unit) {\n    Text(\n        text = \"Click Me\",\n        modifier = Modifier\n            .padding(16.dp)\n            .clickable(onClick = onClick, role = Role.Button)\n            .semantics { contentDescription = \"Click Me Button\" }\n    )\n}\n```\n\n# 결론\n\n젯팩 콤포즈는 플랫폼 지원을 확대하고 최신 디자인 원칙과 일치시키며 성능을 향상시키고 접근성을 우선시하여 UI 개발을 혁신하고 있습니다. 이러한 업데이트는 개발 프로세스를 간소화할 뿐만 아니라 응용 프로그램이 모든 기기에서 아름답고 기능적인 모습을 유지하도록 보장합니다.\n\n이러한 새로운 기능을 활용함으로써, 개발자들은 사용자를 기쁘게 하는 혁신적인 응용 프로그램을 만들어 경쟁적인 시장에서 두드러지게 할 수 있습니다. 더 많은 업데이트를 기대하고 이러한 새로운 능력을 실험하여 앱 개발 게임을 한 단계 높여보세요.\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n더 자세한 정보는 공식 Google Developers 블로그를 방문해보세요.","ogImage":{"url":"/assets/img/2024-05-16-WhatsNewinJetpackComposeatGoogleIO2024_0.png"},"coverImage":"/assets/img/2024-05-16-WhatsNewinJetpackComposeatGoogleIO2024_0.png","tag":["Tech"],"readingTime":4},{"title":"Pulumi 대 비교 IaC 도구 선택을 위한 확실한 안내","description":"","date":"2024-05-16 16:58","slug":"2024-05-16-PulumiVSTerraformTheDefinitiveGuidetoChoosingYourIaCTool","content":"\n\n\u003cimg src=\"/assets/img/2024-05-16-PulumiVSTerraformTheDefinitiveGuidetoChoosingYourIaCTool_0.png\" /\u003e\n\n클라우드 네이티브 시대에는 인프라스트럭처를 코드로 관리하는 것이 클라우드 인프라 관리의 표준으로 자리 잡았습니다.\n\n테라폼은 거의 10년째 사용되어오던 클라우드에 중립적인 옵션으로 서비스되어 왔으며 경쟁사들이 등장하기 전까지 독보적인 위치에 있었습니다. 지금은 AWS CDK, Terraform용 CDK 그리고 상대적으로 새로운 Pulumi와 같은 다양한 옵션이 존재합니다.\n\n다만 다양한 선택지가 있다는 것은 결정하는 과정이 어렵다는 것을 의미하지는 않습니다. 오히려 이로 인해 결정 과정이 복잡해 질 수도 있습니다. 모든 옵션을 탐색하고 정보를 수집하여 결정을 내리기 위해서는 몇 일, 아니면 몇 주가 걸릴 수도 있습니다. 그러나 빠른 클라우드 네이티브/데브옵스 시대에는 모두가 그러한 여유가 없다는 점을 잊지 말아야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n걱정하지 마세요: 이 블로그에서는 Pulumi 대 Terraform에 대해 심층적으로 살펴보겠습니다 (그리고 AWS CDK/CDK for Terraform 메커니즘에 대해 약간 언급할 거예요). 비교 차트, 의사 결정 트리, 몇 가지 팁과 FAQ도 포함할 거에요 (TL;DR: 마지막 두 섹션으로 건너뛰세요) - 일에 적합한 올바른 도구를 선택하는 데 도움이 될거에요.\n\n더 이상의 변들겋 없이, 시작합시다.\n\n# 1. 테라폼\n\nIaC 도구에 대해 이야기하고 있기 때문에 테라폼을 우회할 수 없어요. 왜냐하면 이 도구가 가장 오랜 역사를 가지고 있기 때문이에요. 네, (예: AWS CloudFormation)과 같이 더 오랜 역사를 가진 클라우드 특화 솔루션이 있을 수 있지만, 클라우드에 중립적이 아닌 것들이죠.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서, Pulumi에 대해 언급하기 전에 먼저 Terraform을 살펴보겠습니다.\n\n## 1.1. Terraform의 간단한 역사\n\nHashiCorp에서 2014년에 처음 출시된 Terraform은 2016년과 2017년에 매우 많은 흥미를 끌기 시작했습니다. 이 기간 동안 기본적으로 모든 데브옵스 엔지니어들이 테스트해 보려고 했거나 적어도 이에 대해 이야기했습니다.\n\n2021년에 처음으로 출시된 generally available 버전인 v1.0 이후에 이르기까지, 특히 2017년부터 2019년 사이의 v0.11 및 v0.12와 같은 이전 버전들은 이미 다른 비즈니스 분야의 여러 기업들에 의해 크게 수용되었으며 개발 환경뿐만 아니라 프로덕션 환경에서도 널리 사용되고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 모든 역사가 의미하는 바는, 우리가 테라폼에 대해 어느 정도의 확신을 갖을 수 있다는 것입니다: 테라폼은 실제 프로덕션 환경에서 오랜 기간 테스트되었으며 그와 같이 입증된 성과가 있으므로, 다른 대안들을 시도해본 적이 없거나 시간이 부족하더라도 테라폼으로 잘못 갈 수 없습니다.\n\n## 1.2. 테라폼의 내부 동작\n\n테라폼 (물론 다른 모든 IaC 도구들도 마찬가지지만)을 더 잘 이해하기 위해, 다음으로 테라폼이 어떻게 작동하는지 확인해보겠습니다: 핵심 플러그인 아키텍처입니다.\n\n간단히 말하면, 핵심은 상태 기계입니다. 이는 인프라 수명주기를 관리하며 현재 인프라 상태와 선언적 코드로 정의된 원하는 상태를 비교한 다음, 해당 인프라를 선언적으로 정의된 상태로 가져오기 위해 변경/작업을 수행할 계획을 세우는 방식으로 작동합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n실제 변경 또는 조작 작업은 플러그인(또는 프로바이더라고도 부르는 것이 동일한 개념)에 의해 수행됩니다. 코어는 플러그인과 소통하여 주어진 상태에서 무엇을 해야 하는지 알려줍니다.\n\n요약하면, 코어는 상태를 관리하고, 플러그인은 작업을 수행합니다. 기본적으로 이것이 모든 IaC 도구가 작동하는 방식입니다: 상태를 관리해야하며, 클라우드 인프라를 조작하는 데 필요한 무거운 작업을 수행할 수 있는 것이 필요합니다.\n\nTerraform에 관련된 몇 가지 추가 정보를 언급하면, 대부분의 플러그인은 Golang으로 구현됩니다 (Terraform의 코어-플러그인 프레임워크를 통해 다른 프로그래밍 언어로 작성된 플러그인을 사용할 수 있지만), 따라서 플러그인은 클라우드 Go SDK가 필요합니다. 이를 통해 실제로 CRUD 작업을 수행할 수 있습니다.\n\n이러한 세부 정보가 약간 복잡해 보인다면 걱정하지 마세요: Terraform 사용자로서(개발자/기여자가 아닌) 우리는 플러그인 구현에 대해 걱정할 필요가 없습니다. Go 코드를 작성하지 않고 HCL만 작성합니다. HCL을 통해 인프라를 정의하면, 내부적으로 Terraform은 일부 변환 작업을 수행하여 해당 Go 플러그인을 호출하고, 이 플러그인은 다시 클라우드 Go SDK를 사용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 1.3. 테라폼 HCL\n\n테라폼에서 인프라를 정의하는 것은 간단합니다: HCL (HashiCorp Configuration Language)이라는 구성 언어로 인프라를 정의합니다.\n\nAWS에 S3 버킷을 만드는 HCL 예제를 살펴보겠습니다:\n\n```js\nresource \"aws_s3_bucket\" \"example\" {\n  bucket = \"my-tf-test-bucket\"\n\n  tags = {\n    Name        = \"나의 버킷\"\n    Environment = \"Dev\"\n  }\n}\n```  \n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 마크업 언어나 마크다운, JSON, YAML 같은 어떤 형식이라도 익숙하다면, 위 구문을 사용하는 것이 너무 낯설지 않을 것이고 HCL이 두 가지 개념을 중심으로 구축되어 있다는 것을 분명히 이해하게 될 것입니다: 블록과 속성. 위의 예시에서:\n\n- 전체 리소스 ... '' 는 리소스를 정의하는 블록이며, 첫 번째 키워드로 나타납니다.\n- aws_s3_bucket은 리소스의 종류이다. AWS 제공업체 문서를 참조하여 지원되는 모든 AWS 리소스 목록을 얻을 수 있다.\n- 예시 부분은 리소스의 이름이다.\n- 블록 안에는 속성이나 이 리소스에 대한 인수인 키-값 쌍이 있습니다. 다시 말하지만, 지원되는 인수, 필수또는 아닌 것들을 알아내기 위해서는 제공업체 문서를 참조해야 합니다.\n\nHCL에 대한 학습곡선은 있지만, 다른 프로그래밍 언어를 배우는 것만큼 가파르지는 않습니다. 왜냐하면 HCL은 그저 설정 목적으로만 사용되는 완전한 프로그래밍 언어가 아니기 때문입니다. 이것은 당신의 철학적 성향에 따라 장단점이 될 수 있습니다:\n\n- 한편, 완전한 프로그래밍 언어가 아니라 간단한 설정 언어일 뿐이기 때문에, 큰 혜택을 가져옵니다: 이는 사실상 키-값 쌍으로 구성되어 있어서 아주 직관적이고 사람이 읽기에 편리합니다.\n- 반면에, 그 간단함으로 인해 루프나 분기 같은 복잡한 작업을 반복적으로 수행하기 어려울 수 있습니다 (특별 구문으로 이러한 것들을 달성할 수 있지만, 파이썬 같은 실제 프로그래밍 언어에서 사용하는 ... 또는 if/else와 같이 글로 쓰는 것만큼 간단하지는 않다.)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서 IaC 도구 Terraform은 어느 정도 중간 난이도의 학습 곡선과 제약 사항을 가지고 있습니다 (HCL 때문에 양: 배워야 하며, 인프라를 정의해야 합니다). 이러한 상황을 개선하기 위해 많은 다른 IaC 도구가 등장했습니다. 계속해서 읽어보세요.\n\n## 2. Pulumi\n\n이전 섹션에서 언급했듯이, Terraform은 완벽하지 않습니다. 이러한 문제를 해결하기 위해 많은 도구가 등장했으며, Pulumi는 최근 시도 중 하나입니다.\n\nPulumi란 무엇일까요? 간단히 말해, 이것은 Terraform과 마찬가지로 IaC 도구입니다. 하지만 Terraform이 특정 구문인 HCL을 사용하는 반면, Pulumi는 거의 모든 프로그래밍 언어를 사용하여 인프라를 정의할 수 있도록 허용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 이를 말하기에 극도로 정확하지는 않고 큰 저평가일 것이라는 것을 알고 있지만, 한 문장으로 Pulumi가 무엇인지 배우고 싶은 초보자들을 위해 간단히 설명하자면: Pulumi는 한 마디로 말하면 Python/Go/Java/Node.js 등에서의 Terraform이라고 볼 수 있어요.\n\n## 2.1. Pulumi의 간단한 역사\n\nPulumi는 2018년 처음 오픈 소스로 공개되었는데, 그리 새로운 것은 아니지만 현재의 버전인 v3는 이전 버전과 비교해 몇 가지 중요한 변경 사항이 있는데요, 이는 2021년에 출시되었고, 그 이후로 사람들이 이를 이전보다 훨씬 더 많이 주목하기 시작했습니다 (믿지 못하겠다면 구글 트렌드를 확인해보세요.)\n\n오늘날에는 Terraform과 비교할 때, Pulumi는 구글 검색 결과에서 훨씬 더 적은 관심을 끌고 있습니다. Pulumi의 블로그에 따르면, 2023년에 고객 수가 2000명 미만으로, 이는 Terraform의 주문량보다 훨씬 적다고 합니다 (인터넷의 여러 데이터 소스에 따르면.)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그래서, 이 프로그램은 새로운 기술로 널리 받아들여지진 않아요. 그럼에도 불구하고 Pulumi를 선택한 이유는 무엇일까요? 그 이유는 바로 Pulumi가 가진 강력한 기능 때문입니다: 다중 언어 지원입니다.\n\n## 2.2. Pulumi: 다중 언어 지원\n\n만약 Terraform을 선택한다면, HCL을 작성해야 합니다. 많은 사람들에게는 부담스러울 수 있습니다.\n\n예를 들어, 주로 Go로 프로그램을 작성하고 가끔 클라우드 인프라를 관리하는 백엔드 엔지니어들은, 인프라를 Go로 정의할 수 있는 상황에서 왜 HCL을 배워야 할까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프론트엔드 및 풀스택 엔지니어들도 JavaScript/TypeScript로 주로 코딩하는 경우가 많은데, 이미 사용 중인 기술에 HCL을 배우는 것은 부담이 될 수도 있을 뿐만 아니라 기술 스택을 복잡하게 만드는 요인이 됩니다. 보통 기술 스택을 고려할 때는 더 많이 사용하는 것보다는 오히려 덜 사용하는 것이 더 나을 때가 많습니다.\n\nPulumi에서는 이야기가 달라집니다. 다음 중 하나의 언어로 인프라를 정의할 수 있습니다:\n\n- TypeScript (Node.js)\n- Python\n- C#, VB, F# (.NET)\n- Go\n- Java\n- YAML\n\n예를 들어, 이전 섹션에서 언급된 AWS S3 버킷을 Pulumi를 사용해 Python으로 작성하려면 간단히 다음과 같이 작성하면 됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport pulumi\nimport pulumi_aws as aws\n\nbucket = aws.s3.Bucket(\"bucket\",\n    acl=\"private\",\n    tags={\n        \"Environment\": \"Dev\",\n        \"Name\": \"My bucket\",\n    })\n```\n\n혹은 파이썬이 익숙치 않고 TypeScript로 작성하고 싶다면:\n\n```js\nimport * as pulumi from \"@pulumi/pulumi\";\nimport * as aws from \"@pulumi/aws\";\n\nconst bucket = new aws.s3.Bucket(\"bucket\", {\n    acl: \"private\",\n    tags: {\n        Environment: \"Dev\",\n        Name: \"My bucket\",\n    },\n});\n```\n\n여기 완성!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 2.3. Pulumi의 내부 동작\n\n요약하자면, Pulumi는 Terraform과 동일한 방식으로 작동합니다: 두 도구 모두 언급한 코어 플러그인 아키텍처를 갖고 있습니다.\n\nTerraform과 마찬가지로, Pulumi도 내부적으로 클라우드 SDK 및 라이브러리를 사용합니다. Pulumi는 플러그인 자체가 여러 언어로 구현되어 있기 때문에 여러 언어를 지원합니다. 예를 들어, 여기서 Pulumi의 AWS 프로바이더를 보면, 서로 다른 언어로 여러 구현이 있음을 볼 수 있습니다. 이런 이유로 Python으로 인프라를 정의할 때는 `import pulumi_aws as aws`와 같이 사용하고, TypeScript로 사용할 때는 Node.js용으로 전혀 다른 패키지를 사용합니다: `import * as aws from \"@pulumi/aws\";`.\n\n언급할 가치가 있는 것은 AWS Cloud Development Kit (AWS CDK) 및 CDK for Terraform (CDKTF)와 같이 여러 언어로 인프라 코드를 정의할 수 있는 다른 옵션이 있지만, 본질적으로, 이러한 다중 언어 지원은 완전히 다른 방법으로 구현됩니다: AWS CDK와 CDKTF는 어떤 언어의 코드도 JavaScript 클래스와 자연스럽게 상호 작용할 수 있도록 하는 라이브러리 jsii에 의존합니다. 따라서 AWS CDK (그리고 CDKTF)는 TypeScript 코드를 다양한 언어로 변환하여 다국어 (여러 언어를 지원하는 것을 가리키는 어려운 용어입니다)를 지원하도록 하는 jsii를 사용하지만, Pulumi는 내부적으로 다양한 언어로 작성된 이러한 프로바이더만 갖고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 3. Pulumi 대 Terraform: 주요 유사점과 차이점\n\n## 3.1. Pulumi와 Terraform의 주요 유사점\n\n가장 큰 유사점은 작동 방식인 코어 플러그인 아키텍처입니다.\n\n우선, 핵심은, 혹은 다른 말로 하면, 실제로 상태입니다. 두 도구 모두 상태를 유지하기 위해 핵심을 사용하여 현재 인프라 및 코드로 정의된 내용에 따라 상태를 계산할 수 있도록 하고, 인프라를 정의된 상태로 가져오기 위한 연산 계획을 생성하는 데 사용합니다. 그리고 두 도구 모두 상태를 로컬, S3 버킷, 또는 클라우드/SaaS 솔루션 등 다양한 위치에 저장할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n두 번째로, 플러그인을 사용합니다. 앞에서 언급했듯이, 둘 다 상태를 관리하고 변경을 수행하기 위해 핵심 플러그인 아키텍처를 사용합니다.\n\n## 3.2. Pulumi와 Terraform의 주요 차이점\n\n가장 큰 차이는 물론 다중 언어 지원입니다.\n\nTerraform은 HCL을 사용하는데, 이는 완전한 프로그래밍 언어가 아니라 구성 언어에 불과합니다. 그러므로 본질적으로 다른 프로그래밍 언어들이 할 수 있는 것들을 모두 할 수는 없지만, 앞에서 언급한 바와 같이, 이는 당신에게 좋은 점일 수 있습니다. 왜냐하면 읽기 쉽고 간단한 것이 더 나은 경우가 있기 때문입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\nPulumi는 다양한 언어를 지원하며 이것은 단연 가장 중요한 차이점입니다. 어떤 이유로든 Python/Go/Java 또는 다른 주요 프로그래밍 언어로 인프라를 정의해야하는 경우, Terraform와 Pulumi 사이에는 경쟁이 없습니다.\n\n언급할 가치가 있는 또 다른 차이점은 Pulumi를 사용하여 인프라 코드를 테스트할 수 있는 점입니다. Pulumi를 사용하면 프로그래밍 언어와 함께 제공되는 단위 테스트 및 기능 테스트와 도구를 활용할 수 있습니다. 반면 Terraform에서는 테스트를 실행하는 방법이 주로 통합 테스트로 제한됩니다.\n\n물론 Terraform과 Pulumi 사이에는 다양한 미세한 기능 차이가 있습니다 (Pulumi의 공식 문서가 수십 개 이상을 찾는 데 놀라지 마세요), 하지만 이들은 실제로 결정적인 요인이 되지는 않습니다. 예를 들어, 오픈 소스 라이선스나 상태의 기본 구성이 가장 우선시해야 할 목록 상단에 있지는 않을 것입니다.\n\n# 4. Pulumi에 대한 오해들\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n만약 이 블로그를 읽고 계신다면, 아마도 Pulumi 대 Terraform에 관한 첫 번째 글은 아니실 것입니다. 아마도 조사를 많이 해보셨고 이에 대한 장단점을 많이 읽으신 것 같습니다.\n\n그러나 다른 많은 기사들에서 언급된 Pulumi에 관한 몇 가지 흔히 언급되는 단점들이 실제로 오해되었거나 더 이상 사실이 아닌 것들이 있다고 생각합니다. 저는 그것들을 다루어서 Pulumi에 대해 공정하고 정확한 시각을 얻을 수 있도록 하고 싶습니다. 이것은 중요해서 별도의 챕터를 할당해야할 만큼 중요합니다.\n\n## 4.1. 오해 1: Pulumi 문서 부족\n\n이제는 사실이 아닙니다 (아마도 처음 시작했을 때 그랬을 수도 있습니다).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nPulumi는 설치 방법과 시작하는 방법에 대한 매우 상세하고 단계별 설명서가 있어요. 더 깊이 알고 싶다면, Pulumi의 핵심 개념에 대한 훌륭한 섹션이 있어요. 게다가 Pulumi는 여러 클라우드 제공 업체에 대한 상세한 문서와 예제를 제공해요.\n\n플러그인/제공업체에 대해서 특정 제공업체를 검색하면, AWS와 같은 인기 있는 업체 또는 PagerDuty Pulumi 제공업체와 같은 인기 없는 업체와 비교하여 Terraform의 문서와 비교하면 \"Pulumi 문서가 부족하다\"는 결론에 도달하지 않을 거예요.  \n\n## 4.2. 오해 2: Pulumi 커뮤니티가 작다\n\n더 이상 사실이 아니에요, 다시 말해요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nPulumi의 공식 블로그에 따르면, 2000명의 고객과 15만 명의 최종 사용자가 있습니다. GitHub에 따르면, 주요 리포 pulumi/pulumi만 1.8만 개 이상의 스타를 받았으며, 1.9천개의 이슈와 184개의 오픈된 풀 리퀘스트가 있습니다.\n\n어떤 지표를 사용하더라도, 커뮤니티의 크기를 측정하는 기준이 무엇이든, Pulumi의 커뮤니티는 분명히 큽니다. 테라폼보다는 작지만, 절대적인 의미에서는 절대적으로 작은 커뮤니티가 아닙니다.\n\n## 4.3. 오해 3: Pulumi는 모든 상황에 적용할 수 없다\n\n다시 말하지만, 그렇지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n많은 사람들은 Pulumi가 더 최근에 나왔기 때문에 보편적으로 적용되지 않는다고 결론 지을 수 있지만, 실제로는 그렇지 않습니다.\n\n프로그래밍 언어에 대해 이야기할 때, Pulumi는 사실 주요 언어 대부분을 지원합니다.\n\n플러그인 및 프로바이더에 대해 이야기할 때, 새로운 도구일수록 사용 기간이 짧았기 때문에 플러그인이 적을 것으로 생각할 수 있지만, 현실은 이와 일치하지 않습니다. Pulumi는 주요 공개 클라우드 프로바이더를 모두 지원하며, 테라폼과 마찬가지로 팀 및 사용자 관리와 같은 비 클라우드 인프라 관리에서도 넓게 대상으로 합니다.\n\n예를 들어, 대기업에서는 GitHub, PagerDuty, DataDog, Sentry 등과 같은 여러 DevOps 도구를 관리해야 할 수 있습니다. 아마도 이러한 도구들의 사용자/팀/권한을 IaC를 사용하여 관리하고 싶을 수도 있습니다. 이 경우, 이러한 도구들의 플러그인을 검색하면, Pulumi가 테라폼처럼 모두 갖추고 있다는 것에 놀랄 것입니다. 이 도구들은 널리 사용되는 것이 아니라는 점에서도 클라우드와 관련된 기존 플러그인과는 조금 다를 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위에서 언급했듯이, Pulumi/Terraform을 객관적으로 평가하고 \"문서가 부족하다\"거나 \"커뮤니티가 작다\"는 곳에서 읽었기 때문에 Pulumi를 부정적으로 생각하지 않았으면 좋겠어요. \"최신 버전은 보편성이 떨어진다\"고 생각할 필요도 없습니다.\n\n# 5. Pulumi 대 Terraform: 현실에 가까운 비교\n\n이전 섹션에서 Terraform과 Pulumi의 구문과 사용법을 보여주기 위해 몇 가지 코드 조각을 제공했지만, 이 코드들은 현실 세계에서 의미가 있는 것이 아니라 너무 단순하고 \"Hello, World\" 수준이라는 것을 의미합니다. 현실에서는 대부분의 상황이 지수적으로 커지기 때문에 코드를 간단하고 가독성 있게 유지하는 것과 동시에 확장 가능하게 유지하는 것이 어렵다는 것을 의미합니다.\n\n그러므로 다음으로 Pulumi 대 Terraform을 살펴보고 이러한 현실 세계의 도전에 대해 어떻게 다루는지 비교해 보겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 5.1. Pulumi 대 Terraform: 코드 구조, 가독성 및 확장성\n\nTerraform의 경우, 모듈을 정의하고 재사용하여 최대한의 코드 재사용성을 달성할 수 있습니다. 전형적인 단일 모놀리식 Terraform 저장소는 다음과 같이 보일 수 있습니다:\n\n```js\n.\n├── dev\n│   ├── config.tf\n│   ├── main.tf\n│   ├── output.tf\n│   └── variables.tf\n├── modules\n│   ├── module_a\n│   └── module_b\n└── prod\n    ├── config.tf\n    ├── main.tf\n    ├── output.tf\n    └── variables.tf\n```\n\n단일 저장소의 강점은 아주 사람이 읽기 쉽고 설명 없이도 쉽게 이해할 수 있다는 것입니다. 그리고 Terraform의 특성으로 인해 폴더 구조의 두 수준을 가지고 있으며, 최대 세 수준까지, 이 모든 것은 한눈에 전체적인 내용을 파악하기 쉽고 쉽게 관리할 수 있다는 것을 의미합니다. 또한 다른 환경을 생성하는 것은 단순히 동일한 저장소에 \"test\"라는 이름의 추가 폴더를 생성하는 것만큼 복잡하지 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 깨끗한 코드 기반을 바탕으로 프로젝트가 커질 때 여러 가지 개선 방법이 있습니다: 인프라의 다른 부분을 별도의 리포지토리로 분리; 모듈을 다른 하나 또는 몇 개의 리포지토리로 이동; 다른 환경을 다른 리포지토리로 넣습니다. 모든 선택지는 유연하며 모두 새로운 리포지토리를 생성하여 좀 더 깨끗하고 이해하기 쉬운 디렉터리 구조를 만들어냅니다.\n\nPulumi를 사용하면 상황이 조금 복잡해질 수 있습니다. 전형적인 단일 모놀리식 Pulumi 프로젝트는 다음과 같이 보일 수 있습니다:\n\n```js\n.\n├── Pulumi.dev.yml\n├── Pulumi.prod.yml\n├── Pulumi.yml\n├── api-gateway\n│   ├── index.ts\n│   └── micro-service-01\n│       └── index.ts\n├── database\n│   └── table-01.ts\n├── index.ts\n├── package-lock.json\n├── package.json\n├── sns\n│   └── topics.ts\n└── queues.ts\n├── pkg\n│   └──application\n│     └── app.go\n└── .etc\n```\n\nTerraform과 유사하게, 프론트엔드 또는 백엔드 프로젝트에서 작업한 것과 마찬가지로 공통적인 내용을 패키지로 묶을 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프로젝트가 커지면 프로젝트를 별도로 관리되는 작은 프로젝트로 분할하는 '마이크로 스택' 접근 방식을 사용할 수 있습니다. 각 프로젝트는 위에서와 같을 수 있습니다.\n\n그러나 사물이 커지면 디렉토리 구조가 훨씬 더 복잡해지고 디렉토리가 더 많아지며 수준이 더 많아져 혼란스러울 수 있습니다. Java나 여러분이 참여한 실제 프로젝트를 상상해 보세요. 그 프로젝트 전체를 빠르게 이해하기 쉬운가요? 아니죠, 너무 많은 폴더와 수준의 디렉토리가 있어 어느 것이 무엇이며 어디서 시작해야 하는지조차 모를 수 있습니다.\n\nPulumi의 가장 강력한 장점은 다국어 지원이지만, 큰 힘에는 큰 책임이 따릅니다. 코드를 이해하고 유지하는 데 도움이 되는 방식으로 조직화하는 것이 중요합니다. 이는 사용하는 도구에 상관없이 사실입니다.\n\n## 5.2. Pulumi 대 Terraform: 통합\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n대부분의 경우 IaC가 끝나면 모든 작업이 끝나는 것은 아닙니다. 인프라 구성 부분은 CI/CD 파이프라인과 같은 다른 요소와 통합되어야 합니다. 다행히도 Terraform과 Pulumi는 변경 사항을 배포하기 위해 한 번의 명령만 필요하므로 통합하기에 이상적입니다. 그러나 차이점이 있습니다.\n\n일부 경우에는 IaC 파이프라인이 시작하기 전에 뭔가를 수행하고 싶을 수 있습니다.\n\n예를 들어 사용자, 팀, 멤버십 및 권한을 관리하기 위해 IaC를 사용하고자 한다고 가정해 봅시다. 새로운 사용자를 추가할 때 코드 베이스를 열어서 복사하여 수정하고 커밋하는 것은 너무 번거롭습니다. 어딘가에 사용자 목록이 저장되어 있고, 해당 파일을 검색하여 일부 템플릿 도구를 사용하여 IaC 코드를 자동으로 생성할 수 있다고 가정해 보겠습니다.\n\n이 경우 Terraform의 경우 추가 도구인 Python 스크립트를 사용하여 파일을 다운로드하고 구문 분석하고 템플릿을 적용한 다음 생성된 IaC 파일을 커밋하고 IaC 파이프라인을 실행하기 전에 수행해야 할 수 있습니다. Pulumi의 경우에는 하나의 패스로 모든 작업을 수행할 수 있기 때문에 상황이 훨씬 간단해질 수 있습니다. 원하는 프로그래밍 언어를 사용하여 파일을 다운로드/구문 분석하고, 동일한 언어를 사용하여 간단한 for 루프를 사용하여 작업을 생성할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n적으로 IaC가 완료된 후에 무언가를 수행하고 싶을 수도 있습니다. 예를 들어 IaC 부분의 출력에는 Helm 차트에서 사용하고 싶은 로드 밸런서 URL이 포함될 수 있습니다. 다시 말하지만, Terraform을 사용하면 아마도 스크립트를 실행해야 하는 또 다른 단계가 필요할 것입니다. 그러나 Pulumi를 사용하면 IaC 코드 이후에도 해당 작업을 수행하기 위해 계속 코드 작성을 할 수 있습니다 (여기에 일부 예시가 있습니다).\n\n간단히 말하면, Terraform과 스크립트를 통합하는 데 어려움을 겪고 있다면, Pulumi를 시도해볼 가치가 있을 것입니다.\n\n## 5.3. Pulumi 대 Terraform: 보안\n\n보안은 코드에 항상 중요한 주제이며, 인프라 코드도 마찬가지입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n코드 보안을 위해 가장 기본적인 원칙은 아마도 코드 내에서 비밀을 평문으로 저장하지 않는 것입니다. 이 부분에서 Terraform 및 Pulumi가 잘 수행됩니다. Terraform은 다양한 시크릿 매니저와 통합할 수 있고, Pulumi에서도 시크릿 매니저로부터 읽어오는 것이 한 줄의 코드로 쉽습니다. 예를 들어, 여기에 Terraform에서 시크릿을 관리하는 블로그가 있습니다.\n\n코드 보안에 대해 더 말씀드릴 수 있습니다: Terraform을 사용하면 HCL로 작성하며, 구성 코드는 API 호출로 변환되어 리소스를 생성, 읽기, 업데이트 및 삭제합니다. 물론, Terraform 코어 및 플러그인 자체에 보안 문제와 CVE가 있을 수 있지만, 다른 IaC 옵션에 대해 동일한 말을 할 수 있습니다. Pulumi의 경우, IaC 코드를 여러 언어로 작성할 수 있고 더 많은 작업을 수행할 수 있기 때문에 공격 대상이 더욱 확대될 수 있습니다. 이는 Pulumi에 대한 단점으로 보일 수 있지만 다행히도 보안을 강화하기 위한 SAST 및 DAST와 같은 최고의 실천 방법과 도구가 있습니다.\n\nTerraform 및 IaC 보안에 관심이 있다면 여기에 Terraform을 사용한 IaC 보안에 관한 블로그가 있고, 여기에는 Terraform의 일부 모베스트 프랙티스에 대한 블로그가 있습니다 (걱정하지 마세요, 이전에 읽어본 것과는 다를 것입니다).\n\n코드 보안을 제외하고, IaC 도구는 인프라를 관리하며 중요한 정보는 실제로 상태에 저장되기 때문에 상태의 보안도 중요합니다. Terraform 및 Pulumi는 민감한 정보를 상태에 평문으로 인쇄되지 않도록 암호화할 수 있으며, 두 도구 모두 상태를 암호화하여 저장하기 위한 다양한 백엔드를 지원합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 섹션 마무리를 위한 몇 가지 권장 사항:\n\n- IaC 도구로 민감한 데이터를 관리하는 경우(데이터베이스 암호, 사용자 암호 또는 개인 키 등), 상태 자체를 민감한 데이터로 취급해야 합니다. 즉,\n- 원격으로 상태를 저장하면 더 나은 보안을 제공할 수 있으므로 상태에 로컬 디스크를 사용하지 않도록 하십시오.\n- 휴식 중인 상태 데이터를 암호화할 수 있는 백엔드를 사용하세요.\n\n# 6. Summary: Choosing Your IaC Tool\n\n## 6.1. Comparison Table\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래의 표를 통해 각 도구의 주요 기능을 빠르게 비교해 보겠습니다:\n\n![Comparison Table](/assets/img/2024-05-16-PulumiVSTerraformTheDefinitiveGuidetoChoosingYourIaCTool_1.png)\n\n## 6.2. IaC 도구 선택하기\n\n더 즐겁게 선택을 할 수 있도록, 다음의 플로우 차트를 만들어 봤어요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- IaC를 시작해보려고 합니까? 예: 2번으로 이동. 아니요: 7번으로 이동.\n- 더 적은 것이 더 나은 것이라고 생각합니까? 예: 11번으로 이동. 아니요: 3번으로 이동.\n- DevOps 엔지니어이십니까? 예: 5번으로 이동. 아니요: 4번으로 이동.\n- 가끔 인프라를 관리하는 개발자이십니까? 예: 5번으로 이동. 아니요: 11번으로 이동.\n- 이미 JavaScript/Python/Go/Java로 코딩을 하고 계십니까? 예: 12번으로 이동. 아니요: 6번으로 이동.\n- 새로운 구성 언어를 배우고 싶으십니까? (새 프로그래밍 언어를 배우는 것보다 훨씬 어렵지 않습니다) 예: 11번으로 이동. 아니요: 12번으로 이동.\n- 이미 Terraform을 사용해보신 적이 있습니까? 예: 8번으로 이동. 아니요: 9번으로 이동.\n- Terraform을 사용하며 고민거리가 있습니까? 예를 들어, HCL에 만족스럽지 않거나 더 복잡한 작업을 수행하고 싶은 경우 등? 예: 10번으로 이동. 아니요: 11번으로 이동.\n- Terraform을 시도해보세요.\n- Pulumi를 시도해보세요.\n- Terraform을 계속 사용하세요.\n- 죄송합니다, 둘 다 적합하지 않습니다.\n\n## 6.3. 작업에 적합한 올바른 도구를 선택하는 방법\n\n장난은 좋지만, 올바른 도구를 선택하는 몇 가지 팁을 안내해드릴게요:\n\n- 여전히 앱 코드 작성이 주 업무인데 인프라 코드를 부분적으로 관리해야 한다면 Pulumi가 더 나은 선택이 될 수 있습니다.\n- Terraform에 경험이 있고 불만족스러운 점이 있다면, Pulumi를 사용해보세요. 안심하세요, Terraform이 할 수 있는 중요한 것은 Pulumi로 할 수 없는 게 없습니다.\n- 한 가지 전세되는 도구를 선택할 필요는 없습니다. Pulumi 대 Terraform은 경쟁이 아니에요. 어떤 것이 더 나은지, 어떤 것이 잘못된지 결정해야 한다는 것은 아니에요. 사실 둘 다 사용할 수 있습니다. 프로젝트가 성장하면 단일 인프라 저장소를 관리하기 어려워지고, 마이크로서비스와 같은 프로젝트에서는 각 부분에 적합한 도구를 사용함으로써 최선을 다할 수 있습니다. 올바른 도구를 선택하면 일부 작업을 더 쉽게 수행할 수 있습니다.\n- 직접 체험해보세요. 블로그와 기사를 모두 읽어도 괜찮지만, 마지막으로 두 도구를 간단히 시도해보면 진정한 필요를 알게 될 거예요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# FAQ\n\n## Q: Terraform은 오래된 기술인가요?\n\n네/아니요.\n\n네, Terraform은 많은 해동안 사용되어 왔고, 그만큼 자체적인 한계도 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하지만, HCL을 사용해야 하는 점을 제외하면, Terraform은 거의 모든 것을 처리하고 잘 다루어냅니다.\n\nTerraform은 이제 CDKTF를 사용할 수 있어 다른 프로그래밍 언어로 인프라를 정의할 수 있다는 점을 언급할 가치가 있습니다.\n\n## 질문: Pulumi가 Terraform보다 나은가요?\n\n그렇고 아니요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n네, 실제로 인프라를 정의하기 위해 다른 프로그래밍 언어를 선택할 수 있습니다.\n\n하지만 전체 프로그래밍 언어로 된 큰 프로젝트는 간단한 구성 언어보다 더 명확하지 않고 읽기 어려울 수 있습니다.\n\n각 도구마다 장점이 있으며 둘 중 어떤 것이 뛰어나다고 말할 수는 없습니다.\n\n## 질문: Pulumi가 Terraform이 할 수 있는 모든 것을 할 수 있나요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예.\n\n음, 그래 별로. 각각에는 각각의 특징과 장점이 있지만, IaC에 관한 이야기를 할 때 기본적으로 찾는 기능은 두 도구 모두 갖추고 있습니다. Pulumi를 선택한 후 테라폼이 훌륭하게 수행하는 어떤 마법 같은 기능을 할 수 없을 때 곤경에 처하지 않을 것입니다.\n\n## Q: Pulumi의 단점은 무엇인가요?\n\n솔직히 말해서, 아무것도 없습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해당하는 작업을 아주 잘 수행하며, 선택한 프로그래밍 언어로 할 수 있어요. 게다가 문서와 커뮤니티도 친절해요.\n\nPulumi에 대해 조금 꼭 언급하자면, Python, Go 또는 JavaScript로 큰 코드베이스를 관리하는 것은 HCL 형식의 구성 파일 저장소보다 훨씬 까다롭다는 점이죠. 하지만 이 도전을 가져온 건 Pulumi가 아니라 프로그래밍 부분입니다. 또한, HCL을 사용한다고 해서 코드베이스가 자동으로 읽기 쉽고 관리하기 쉬워지는 것은 아니에요. 분명히 혼란스럽게 만들 수 있어요. 결국 깨끗한 코드를 작성하고 유지하는 것은 프로그래머들의 몫이에요.","ogImage":{"url":"/assets/img/2024-05-16-PulumiVSTerraformTheDefinitiveGuidetoChoosingYourIaCTool_0.png"},"coverImage":"/assets/img/2024-05-16-PulumiVSTerraformTheDefinitiveGuidetoChoosingYourIaCTool_0.png","tag":["Tech"],"readingTime":17},{"title":"올라마와 오픈 웹 UI를 쿠버네티스에 배포하기","description":"","date":"2024-05-16 16:56","slug":"2024-05-16-DeployingOllamaandOpenWebUIonKubernetes","content":"\n\n여러 이유들로 인해 별도의 긴 텍스트 블로그 게시물에서 설명할 것을 계획한 대로, 저는 팀이 AI 모델을 자체 호스팅하고 개발 팀을 더 효율적으로 만들 수 있는지 조사하는 실험을 진행하기로 결정했습니다. 본문에서는 우리 팀을 위해 쿠버네티스에서 Ollama와 Open Web UI를 호스팅하기 위해 구축한 아키텍처에 대해 설명하고, 왜 그것을 선택했는지 설명하겠습니다.\n\n# IDE 플러그인 선택\n\n무언가를 구축하기 전에, Ollama와 양방향 대화 및 코드 자동 완성(FIM)을 모두 지원하는 IDE 플러그인을 찾기를 원했습니다. Cody AI와 Llama Coder를 포함한 여러 옵션을 평가한 후, VS Code에서 저희 개발자들을 위해 Twinny를 선택했습니다. (우리 둘의 IntelliJ 개발자들은 자신들의 선택을 했습니다.)\n\nCody AI는 멋지며, 제 개인 장비에서 사용 중입니다. 팀을 위해, 우리는 라이선스 문제나 구매 부분과의 충돌을 피하기 위해 모든 부분에서 오픈 소스 소프트웨어를 준수하고자 했습니다. Llama Coder는 오픈 소스이며 좋으나, 우리가 시도했을 때는 채팅 기능만 있었습니다. Twinny는 저희가 로컬 테스트 중에도 채팅 및 자동 완성 기능을 둘 다 잘 수행하는 유일한 오픈 소스 IDE 플러그인이었습니다. 플러그인 유지자는 항상 열정적으로 작업하고 문제에 신속히 대응하는 것으로 보여서 우리가 좋아하는 점입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 아키텍처\n\n첫 번째 POC에서는 Open Web UI 도커 컴포즈 파일을 EC2 인스턴스에서 실행하여 테스트했습니다. 초기 POC에서는 작업을 훌륭하게 수행했습니다. UI를 올리고 Twinny를 연결했으며, GPU 드라이버를 올바르게 설치한 후에는 성능이 양호했습니다. 이것이 잘 확장되지 않을 것을 알고 빠르게 모든 것을 쿠버네티스에 구축하는 다음 단계로 넘어갔습니다.\n\n저희는 AWS 회사이므로 이러한 워크로드를 EKS에서 호스팅하기로 결정했습니다. GPU 지원을 위해 EKS 가속화 AMI를 사용하여 Ollama 인스턴스에서 드라이버를 추가하는 작업을 저희를 도와주었습니다. NVIDIA K8s Device Plugin을 실행하는 Daemon Set으로 작동되도록 배포하는 방법은 AWS 문서에 연결된 지침을 따르세요. 클러스터를 설정한 후 아래 명령어를 사용할 수 있습니다.\n\n```js\nkubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.14.5/nvidia-device-plugin.yml\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리는 ALB 인그레스 컨트롤러를 사용하여 Open Web UI Ingress 주석에서 ALB를 생성했고, Persistent Volumes를 처리하기 위해 EBS CSI 플러그인을 사용했습니다.\n\n노드 그룹에 대해 초기 빌드를 위해 세 개의 노드 그룹을 사용했습니다: Open WebUI 서비스는 GPU가 필요하지 않기 때문에 m5a.large 인스턴스를 사용하는 노드 그룹에서 실행되며, FIM 모델 및 채팅 모델 각각에 대해 g5.2xlarge 인스턴스에서 실행되는 두 개의 별도의 Ollama 노드 그룹을 구축했습니다. GPU 메트릭스를 수집하기 위해 사용자 데이터를 통해 CloudWatch 에이전트를 설치하고 사용 패턴 및 동작을 볼 수 있도록 했습니다.\n\n처음에 이것을 구축할 때 Ollama는 메모리에 로드되지 않은 모델에 대해 사용자가 요청을 보낼 때마다 모델을 언로드 및 재로드하여 사용자가 응답을 받기까지 5-15초의 지연이 발생했습니다. 그러나 Ollama는 그 이후에 한 번에 여러 모델을로드 유지하는 기능을 출시했으나, 우리는 현재는 별도의 모델에 대해 별도의 백엔드를 계속 사용하고 있습니다.\n\n마지막으로, Ollama와 Open WebUI 서비스를 구축하기 위해 각각의 Helm 차트를 사용했습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- https://artifacthub.io/packages/helm/ollama-helm/ollama\n- https://artifacthub.io/packages/helm/open-webui/open-webui\n\n튜닝 섹션에는 서비스가 시작되자마자 최대 성능을 얻기 위해 Helm 값에 포함해야 하는 팁이 포함되어 있습니다.\n\n현재 설정에 대한 아키텍처 다이어그램은 아래에서 확인할 수 있습니다.\n\n![아키텍처 다이어그램](/assets/img/2024-05-16-DeployingOllamaandOpenWebUIonKubernetes_0.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 섬세한 조정\n\n제품이 좀 더 생산 준비 상태로 설정되어 있으므로 작은 시범 그룹에게 오픈하여 매일 테스트 중입니다. 사용자들이 들어오자, 사용자들에게 응답이나 코드 자동 완성을 받기 전에 지연이 발생한다는 보고를 받기 시작했습니다.\n\nOllama가 한 번에 한 요청에만 응답할 수 있다는 것을 발견했는데, 이는 여러 사람들에게 노출하는 목적을 상쇄시켰습니다. 다행스럽게도 Ollama의 1.34 릴리스에서 OLLAMA_NUM_PARALLEL 옵션이 추가되어 Ollama가 한 번에 여러 요청에 응답할 수 있도록 설정할 수 있게 되었습니다. 이 값을 10으로 설정하고, g5.2xlarge 인스턴스에서 10개의 응답을 동시에 받는 것이 꽤 잘 작동하는 것을 알았습니다. 약간의 속도 저하만 있어요. Ollama 배포가 고사용량 상태에 있을 때 확장하도록 메트릭을 수집하는 작업을 시작했지만, 아직 그 정도로는 못 갔습니다.\n\nOllama Helm 차트에 추가할 수 있는 다른 값은 ollama.models 값입니다. 이를 통해 Ollama 서비스가 호스팅할 모든 모델을 미리 로드할 수 있어서 첫 사용자들에게 시간을 절약할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 마무리\n\n이 블로그 글에 대해 더 많은 정보를 추가하고 업데이트할 가능성이 매우 큽니다. 미래에는 시작점으로 사용할 수 있는 몇 가지 샘플 코드를 제공할 예정이지만 거기서 약속을 드릴 수는 없습니다.\n\n의견이나 질문이 있으면 언제든지 0xthresh@proton.me로 연락해주세요. 최대한 빨리 회신 드리겠습니다.\n\n읽어 주셔서 감사합니다!","ogImage":{"url":"/assets/img/2024-05-16-DeployingOllamaandOpenWebUIonKubernetes_0.png"},"coverImage":"/assets/img/2024-05-16-DeployingOllamaandOpenWebUIonKubernetes_0.png","tag":["Tech"],"readingTime":4},{"title":"도커에서 extra_hosts를 사용하여 DNS 해결 단순화하기","description":"","date":"2024-05-16 16:56","slug":"2024-05-16-SimplifyingDNSResolutioninDockerwithextra_hosts","content":"\n\n소개: Docker 세계에서는 가장 간단한 작업조차 복잡해질 수 있습니다. 최근 Docker 컨테이너에서 Apache Airflow를 실행하는 중에 귀찮은 문제에 직면했습니다. 우리의 설정은 Airflow를 Azure PostgreSQL 데이터베이스에 연결하는 것을 포함했지만, 때때로 DNS 오류로 인해 작업 흐름이 방해받았습니다. 조사를 통해 Docker의 DNS 캐싱 부족이 문제의 주범임을 알게 되었습니다. 이 게시물에서는 Docker Compose의 extra_hosts 기능을 활용하여 문제를 해결한 방법을 공유하겠습니다. 이를 통해 팀이 불필요한 두통으로부터 구해졌습니다.\n\n문제: Docker 컨테이너는 내장된 DNS 캐싱이 없어 모든 연결 시도에 대해 DNS 해상도에 의존해야 합니다. 이는 가끔 실패로 이어질 수 있으며 특히 네트워크 트래픽이 많은 환경에서 문제가 발생할 수 있습니다. 우리의 경우, 매일 수천 개의 작업을 실행하는 Apache Airflow가 DNS 해상도 문제로 PostgreSQL 데이터베이스에 연결하는 데 어려움을 겪고 있었습니다.\n\n해결책: DNS 해상도 문제에 대처하기 위해 Docker Compose의 extra_hosts 기능을 활용했습니다. 이 편리한 기능을 사용하면 추가 호스트 이름과 IP 주소를 지정하여 DNS 해상도가 전혀 필요하지 않게 됩니다. 호스트 이름을 직접 IP 주소로 매핑함으로써 개인 DNS 서버의 부하를 줄이고 컨테이너 간 안정적인 통신을 보장할 수 있습니다.\n\n구현: 해결책을 구현하는 것은 간단했습니다. PostgreSQL 데이터베이스 호스트 이름과 해당 IP 주소에 대한 extra_hosts 항목을 Docker Compose 구성에 업데이트했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n버전: '3'\n서비스:\n  airflow:\n    이미지: airflow:latest\n    환경:\n     - AIRFLOW__CORE__EXECUTOR=LocalExecutor\n     - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://@myprivatpgsqlserver.postgres.database.azure.com:6432/mydbinstance\n     - AIRFLOW__CORE__LOAD_EXAMPLES=False\n     - AIRFLOW__CORE__LOGGING_LEVEL=INFO\n    extra_hosts:\n     - \"myprivatpgsqlserver.postgres.database.azure.com:192.168.159.84\"\n    # 기타 Airflow 구성...\n\n이 구성에서는:\n\n- airflow 서비스 하위에 extra_hosts 섹션을 추가했습니다.\n\n우리는 myprivatpgsqlserver.postgres.database.azure.com 호스트명 및 해당 IP 주소 192.168.1.100을 지정하여 PostgreSQL 데이터베이스에 대한 연결에 대한 DNS 해결을 우회했습니다.\n","ogImage":{"url":"/assets/img/2024-05-16-SimplifyingDNSResolutioninDockerwithextra_hosts_0.png"},"coverImage":"/assets/img/2024-05-16-SimplifyingDNSResolutioninDockerwithextra_hosts_0.png","tag":["Tech"],"readingTime":2}],"page":"7","totalPageCount":80,"totalPageGroupCount":4,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"7"},"buildId":"z1a6VTi5qHH9JJH7jaxL3","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>