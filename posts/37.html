<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>allround-coder</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://allround-coder.github.io///posts/37" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="allround-coder" data-gatsby-head="true"/><meta property="og:title" content="allround-coder" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://allround-coder.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://allround-coder.github.io///posts/37" data-gatsby-head="true"/><meta name="twitter:title" content="allround-coder" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | allround-coder" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZFDEQ947R4"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
  
            gtag('config', 'G-ZFDEQ947R4');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-ec7535a55e788b31.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/QH5Mz7n7Y6w0r4_gCGFQf/_buildManifest.js" defer=""></script><script src="/_next/static/QH5Mz7n7Y6w0r4_gCGFQf/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Allround Coder</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="AI 프롬프트 엔지니어링 탐구 수학적 기초와 RAG 방법론" href="/post/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AI 프롬프트 엔지니어링 탐구 수학적 기초와 RAG 방법론" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AI 프롬프트 엔지니어링 탐구 수학적 기초와 RAG 방법론" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">AI 프롬프트 엔지니어링 탐구 수학적 기초와 RAG 방법론</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">25<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="콜모고로프-아놀드 네트워크KAN가 인공지능 세계를 영원히 바꿀 것입니다" href="/post/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="콜모고로프-아놀드 네트워크KAN가 인공지능 세계를 영원히 바꿀 것입니다" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="콜모고로프-아놀드 네트워크KAN가 인공지능 세계를 영원히 바꿀 것입니다" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">콜모고로프-아놀드 네트워크KAN가 인공지능 세계를 영원히 바꿀 것입니다</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="그래프 ML NetworkX 소개" href="/post/2024-06-20-GraphMLintroductiontoNetworkX"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="그래프 ML NetworkX 소개" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="그래프 ML NetworkX 소개" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">그래프 ML NetworkX 소개</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="파이파이 앱을 코딩할 때 고려해야 할 13가지를 배운 것들" href="/post/2024-06-20-13ThingsIveLearntToConsiderWhenCodingAFastAPIApp"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="파이파이 앱을 코딩할 때 고려해야 할 13가지를 배운 것들" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-13ThingsIveLearntToConsiderWhenCodingAFastAPIApp_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="파이파이 앱을 코딩할 때 고려해야 할 13가지를 배운 것들" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">파이파이 앱을 코딩할 때 고려해야 할 13가지를 배운 것들</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="잡음 저항 칼만 필터 이동 평균KMA 대 단순 이동 평균SMA 교차 알고 트레이딩 전략 BAC 쇼케이스" href="/post/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="잡음 저항 칼만 필터 이동 평균KMA 대 단순 이동 평균SMA 교차 알고 트레이딩 전략 BAC 쇼케이스" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="잡음 저항 칼만 필터 이동 평균KMA 대 단순 이동 평균SMA 교차 알고 트레이딩 전략 BAC 쇼케이스" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">잡음 저항 칼만 필터 이동 평균KMA 대 단순 이동 평균SMA 교차 알고 트레이딩 전략 BAC 쇼케이스</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">17<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="오디오 데이터에 대한 대화형 감정 분석" href="/post/2024-06-20-ConversationalSentimentAnalysisonAudioData"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="오디오 데이터에 대한 대화형 감정 분석" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-ConversationalSentimentAnalysisonAudioData_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="오디오 데이터에 대한 대화형 감정 분석" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">오디오 데이터에 대한 대화형 감정 분석</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="웹을 당신의 최고 친구 데이터 제공업체로 만들어 보세요" href="/post/2024-06-20-MaketheWebyourbestfrienddataprovider"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="웹을 당신의 최고 친구 데이터 제공업체로 만들어 보세요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-MaketheWebyourbestfrienddataprovider_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="웹을 당신의 최고 친구 데이터 제공업체로 만들어 보세요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">웹을 당신의 최고 친구 데이터 제공업체로 만들어 보세요</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">14<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="Vercel에 Nodejs 백엔드를 배포하는 방법 단계별 가이드" href="/post/2024-06-20-HowtoDeployYourNodejsBackendonVercelAStep-by-StepGuide"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="Vercel에 Nodejs 백엔드를 배포하는 방법 단계별 가이드" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-HowtoDeployYourNodejsBackendonVercelAStep-by-StepGuide_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="Vercel에 Nodejs 백엔드를 배포하는 방법 단계별 가이드" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">Vercel에 Nodejs 백엔드를 배포하는 방법 단계별 가이드</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="내가 원하는 테크 회사에 자동 이메일을 보내는 스크립트를 작성했어요 결과 포함" href="/post/2024-06-20-IWroteAnAutomatedScripttoSendOutColdE-MailstotheTechCompaniesIWanttoWorkAtWithResults"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="내가 원하는 테크 회사에 자동 이메일을 보내는 스크립트를 작성했어요 결과 포함" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-IWroteAnAutomatedScripttoSendOutColdE-MailstotheTechCompaniesIWanttoWorkAtWithResults_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="내가 원하는 테크 회사에 자동 이메일을 보내는 스크립트를 작성했어요 결과 포함" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">내가 원하는 테크 회사에 자동 이메일을 보내는 스크립트를 작성했어요 결과 포함</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">3<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="NestJS에서 IoC 컨테이너에 접근하기 실용적인 로깅 라이브러리 예제" href="/post/2024-06-20-AccessingtheIoCContainerinNestJSAPracticalLoggingLibraryExample"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="NestJS에서 IoC 컨테이너에 접근하기 실용적인 로깅 라이브러리 예제" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-AccessingtheIoCContainerinNestJSAPracticalLoggingLibraryExample_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="NestJS에서 IoC 컨테이너에 접근하기 실용적인 로깅 라이브러리 예제" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">NestJS에서 IoC 컨테이너에 접근하기 실용적인 로깅 라이브러리 예제</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">10<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/21">21</a><a class="link" href="/posts/22">22</a><a class="link" href="/posts/23">23</a><a class="link" href="/posts/24">24</a><a class="link" href="/posts/25">25</a><a class="link" href="/posts/26">26</a><a class="link" href="/posts/27">27</a><a class="link" href="/posts/28">28</a><a class="link" href="/posts/29">29</a><a class="link" href="/posts/30">30</a><a class="link" href="/posts/31">31</a><a class="link" href="/posts/32">32</a><a class="link" href="/posts/33">33</a><a class="link" href="/posts/34">34</a><a class="link" href="/posts/35">35</a><a class="link" href="/posts/36">36</a><a class="link posts_-active__YVJEi" href="/posts/37">37</a><a class="link" href="/posts/38">38</a><a class="link" href="/posts/39">39</a><a class="link" href="/posts/40">40</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"AI 프롬프트 엔지니어링 탐구 수학적 기초와 RAG 방법론","description":"","date":"2024-06-20 04:54","slug":"2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies","content":"\n\n\n\u003cimg src=\"/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_0.png\" /\u003e\n\n## 대형 언어 모델 (LLMs)의 수학적 표현\n\n먼저 대형 언어 모델 (LLM)을 다음과 같은 공식으로 표현합니다:\n\n\u003cimg src=\"/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_1.png\" /\u003e\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n간단해 보이지만, 우리가 AI 기법과 LLM에 적용하는 방법을 이해하려면 LLM 프레임워크 내에서 𝜔, 𝑋 및 𝑌를 특정 항목으로 해석해야 합니다.\n\nLLM 가중치 (ω)\n\n매개변수 세트 𝜔는 신경망 가중치 (모델 계수) 및 편향으로, 모델 훈련 중에 업데이트됩니다. 𝜔는 LLM의 응답에 영향을 줄 수 있지만, 세밀 조정이 이루어질 때까지 고정됩니다. 이러한 매개변수는 다음과 같이 표시될 수 있습니다:\n\n![이미지](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n𝑛은 현대 LLMs에는 수십억 개에 달할 수 있는 매개변수의 수를 나타냅니다. 그러나 이 논문에서는 이러한 매개변수를 주요 주제로 삼지 않고, AI 프롬프트 엔지니어링과 RAG 방법론에 초점을 맞추고자 합니다.\n\n모델 입력 (X):\n\n입력 𝑋에는 여러 항목이 함께 작동하여 예측 𝑌를 생성하는 데 기여합니다:\n\n![image](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- X_query: 사용자로부터 특정 질문 또는 요청.\n  \n- X_prompt: 개발자가 설정한 초기 프롬프트.\n  \n- X_RAG Prompts: 데이터 소스 D로부터 X_query를 기반으로 검색한 추가 프롬프트(문서).\n  \n- X_parameters: 온도, 최대 토큰, 스트림 옵션과 같은 매개변수\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nX_매개변수는 모델 학습 매개변수가 아니지만 (예: 학습률, 신경망 레이어 수), 추론 중 LLM 동작에 유사한 역할을 합니다. 사용자가 이러한 매개변수를 지정하지 않으면, LLM은 파이썬 함수 기본값과 같은 기본값을 사용합니다. 사용자 매개변수와 기능에 대한 포괄적인 목록은 OpenAI API 문서를 참조하십시오.\n\n출력 변수 (𝑌)\n\nLLM에 의해 생성된 응답. 입력 X에 기반합니다.\n\n입력 및 매개변수 사용자 정의하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다양한 LLM은 다양한 입력 형식과 매개변수 집합이 필요할 수 있습니다. 우리는 OpenAI API를 사용하여 입력 구성에 초점을 맞춥니다. 𝑋의 각 구성 요소가 모델과 상호 작용하는 방법 및 조정이 생성된 응답 𝑌에 어떤 영향을 미치는지 살펴봅니다.\n\n![이미지](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_4.png)\n\n아래의 OpenAI 채팅 완성 API 예제를 사용하여 LLM의 표현을 보여줍니다:\n\n```js\nfrom openai import OpenAI\nclient = OpenAI()\n\nsystem_prompt = \"당신은 MSFT의 도움이 되는 HR 전문가입니다.\"\n\nrags = {'Q': \"문맥에서 혜택이란 무엇인지 설명하세요\", 'A': '회사에서 직원이 받는 혜택으로, 건강 보험, 퇴직 계획 등이 포함됩니다'}\n\nrag_prompt_question = {\"role\": \"user\", \"content\": rags['Q']}\nrag_prompt_answer = {\"role\": \"user\", \"content\": rags['A']}\nuser_query = \"MSFT의 데이터 과학자들의 혜택은 어떤가요?\"\n\nresponse = client.chat.completions.create(\n  model=\"gpt-3.5-turbo\",\n  messages=[\n    {\"role\": \"system\", \"content\": system_prompt},\n    rag_prompt_question, rag_prompt_answer,\n    {\"role\": \"user\", \"content\": user_query}\n  ]\n)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시스템 프롬프트가 X_쿼리인 경우, 모든 사용자 질문에 대한 고정 프롬프트입니다. rag_prompt_question 및 rag_prompt_answer는 X_RAG(X_query, D)이며, 여기서 D는 간단한 사전 rags로 단순화됩니다. 일반적으로 응용 프로그램에서 X_RAG는 D에서 X_쿼리를 검색하여 동적으로 얻어지지만, 이 예에서는 데모용으로 고정 X_RAG를 사용합니다.\n\n## 맥락 내 학습 LLM의 해석\n\n맥락 내 학습은 LLMs의 특정 용어로, LLMs가 사용자의 질문에 대해 입력-출력 프롬프트에 의존하여 응답하는 것을 의미합니다. 이는 LLMs가 더 적합한 프롬프트를 제공하면 사용자의 요청을 더 잘 해결할 수 있다는 것을 시사합니다. 예를 들어, 사용자가 user_query = “MSFT의 데이터 과학자들의 혜택은 어떤가요?”라는 질문을 한 경우, LLMs는 기본 추론을 사용하여 응답할 수 있으며, 이는 LLMs가 질문에 대한 가장 높은 확률로 사용하는 방식입니다:\n\n![그림](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n답변은 'MSFT가 당신을 선도하는 데이터 과학자로 만들어줄 수 있습니다'. 물론, 일부 LLM은 '혜택'의 여러 종류를 설명하는 포괄적인 답변을 제공할 수 있습니다. LLM의 응답 절차는 X_query만 가지고 있는 LLM들에게 '제로 샷 학습'을 가능케 하여 프롬프트 없이 응답할 수 있게 합니다. X_prompt 및 X_prompt와 같은 추가 프롬프트를 제공하면 LLM들이 필요한 정보를 응답합니다. 예를 들어 아래 프롬프트를 제공한다면:\n\nQ: 맥락에서 '혜택'이란 단어를 설명해주세요.\n\nA: 기업에서 직원이 받는 혜택으로, 건강 보험 등이 있습니다.\n\n그러면 LLM은 MSFT 직원 혜택에 대해 간략히 설명해줍니다. 이것이 '퓨-샷 학습'으로, LLM에게 응답 품질을 향상시키기 위한 작은 정보 조각을 제공합니다. '샷'이란 LLM이 맥락을 이해하는 데 제공되는 예시 수를 가리킵니다. '퓨-샷'은 몇 가지 예시만 제공되는 것을 의미합니다. 이는 더 많은 정보를 제공하여 질문을 특정하게 만듭니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_6.png)\n\n'Shot Learning'에서의 'learning'이 LLM에서의 학습(매개변수 업데이트)과는 다르다는 사실을 주목해야 합니다. 여기서 'few-shot context learning'은 LLM이 더 정확한 응답을 생성하는 데 도움을 주기 위해 몇 가지 프롬프트만을 입력합니다. 이는 LLM의 입력 𝑋를 업데이트하여 모델의 출력을 더 구체적이고 관련성 있게 만들어 사전 훈련된 LLM이 추가 학습(모델 훈련)이나 세부 조정 없이도 더 예측 가능하게 합니다.\n\n## RAG 프롬프트 및 개발의 수학적 해석\n\nRAG(검색 증대 생성) 프롬프트는 LLM 응용 프로그램에서 중요합니다. ChatGPT와 같은 준비된 AI 플랫폼은 종종 암묵적으로 검색을 처리하지만, ChatGPT-4는 사용자가 정보 파일을 업로드하여 최종 응답을 생성하는 데 참조합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAI 애플리케이션은 보통 RAG 기술에 영향을 받습니다. 이 기술은 모델이 다른 소스의 동일한 사용자와 호환되는 것뿐만 아니라 사용자 정보가 안전하게 보호되어 AI 언어 모델에 직접 액세스할 수 없는 시나리오를 지원합니다. RAG는 사용자나 문맥에 가장 적합한 데이터를 사용하는 상황에서 모델의 반응의 관련성과 정확성이 긍정적으로 영향을 받습니다. 사용자는 ChatGPT-4와 같은 대화식 AI 플랫폼 내에서 자주 사용하는 데이터를 업로드하거나 추가 문맥을 직접 추가할 수 있습니다. 그러나 고객 서비스 등에서 사용되는 것과 같이 더 복잡한 AI 시스템의 경우 이러한 방식으로는 불가능합니다.\n\n다음은 AI 애플리케이션 시스템에서의 RAG 기술 구조입니다:\n\n- X_query: AI 시스템에 사용자의 질문. 고객 서비스와 같은 특정 분야의 쿼리입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- X_prompt: 개발자가 만든 AI 응용 프로그램 시스템에 맞는 프롬프트입니다. 신중하게 작성된 프롬프트는 시스템이 보다 정확한 응답을 제공하도록 합니다.\n\n- X_RAG: 사용자의 쿼리, AI 프롬프트 및 사용자가 업로드한 데이터를 기반으로 시스템이 생성한 RAG 프롬프트입니다.\n\n- D: AI 시스템이나 회사의 상용 환경 안에 포함된 비공개 정보입니다. 예를 들어, LLMs는 사용자 쿼리에 추가 정보를 제공하는 추출된 문서를 사용합니다.\n\n- Y: 텍스트 답변이거나 Python 코드 실행 결과, SQL 쿼리 출력물 또는 오디오 응답을 포함한 멀티모달 콘텐츠일 수 있습니다. 사용자의 각 쿼리에 대한 솔루션으로 간주될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다양한 RAG 기술 및 해석\n\nRAG Prompt의 구조에서 우리는 RAG 기술이 다음 요소들에 의존한다는 것을 알 수 있습니다:\n\n- X_query: 사용자가 LLM에 요청하는 것.\n- 개인 데이터 (D): 사용자 또는 개발자가 데이터를 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 연관성 측정치: 쿼리와 D 간의 거리\n\n이것은 원본 또는 변환된 요소 또는 그들의 조합을 사용하여 새로운 RAG 기술을 개발할 수 있다는 것을 의미합니다.\n\nRAG 방법 1: 직접 임베딩 기반 검색\n\n직접 임베딩 기반 검색은 임베딩 모델이 텍스트를 벡터 표현으로 변환하여 데이터베이스에 저장하는 기본적인 기술입니다. 사용자가 쿼리를 보낼 때, RAG 함수는 쿼리 벡터와 가장 유사한 문서 벡터(예: 상위 𝑘 = 5)를 데이터베이스에서 검색합니다. 검색된 문서는 LLM에 의해 더 정확한 응답을 생성하기 위한 추가 프롬프트로 사용됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래와 같이, RAG 프롬프트는 쿼리와 private data 𝐷(doc) 간의 코사인 거리가 가장 짧은 5개 문서를 선택하여 검색됩니다. 여기서 우리는 코사인 거리를 역 유사성 측정으로 사용합니다.\n\n예시: 직접 임베딩 기반 검색\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 단계는 Azure OpenAI, 대화형 검색 LangChain 및 Chroma Vector 데이터베이스와 같은 도구를 사용하여 직접 삽입 기반 검색을 구현하는 방법을 보여줍니다:\n\n단계 1: Chroma에 데이터 주입\n\n```js\nloader = TextLoader('intertnet_ts.txt', encoding='utf-8')\ndocuments = loader.load()\ntext_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)\nchunks = text_splitter.split_documents(documents)\nvectordb = Chroma.from_documents(documents=chunks, embedding=Embeddings_model,\n           persist_directory=\"data/chroma_db\")\n```\n\n단계 2: 텍스트 임베딩 모델 설정\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nEmbeddings_model = AzureOpenAIEmbeddings(deployment = \"embed\",   model = \"em-ada\",\n       azure_endpoint = \"https://HD-gpt4.openai.azure.com/\", openai_api_type=\"azure\")\n```\n\n단계 3: RAG 검색기 함수 생성\n\n```js\ndef get_retriever():\n    loaded_vectordb = Chroma(persist_directory = \"data/db\", embedding_function = Embeddings_model)\n    retriever = loaded_vectordb.as_retriever(search_type=\"mmr\", k = 5)\n    return retriever\n```\n\n단계 4: LLM 초기화\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nchat_model = AzureChatOpenAI(openai_api_version=OPENAI_API_VERSION, azure_deployment=OPENAI_DEPLOYMENT_NAME, temperature=0)\nchat_retriever = get_retriever()\n```\n\n단계 5: 직접 포함 기반 검색을 위한 LangChain 설정\n\n```python\nqa_prompt = ChatPromptTemplate.from_messages(messages)\nqa_chain = ConversationalRetrievalChain.from_llm(llm=chat_model, chain_type='stuff', retriever=chat_retriever, return_source_documents=False, combine_docs_chain_kwargs={\"prompt\": qa_prompt})\n```\n\n평가\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n직접 삽입 기반 검색은 인기 있는 RAG 방법입니다. 일반적으로 코사인이나 내적을 거리 측정 항목으로 사용하는데, 이 방법은 때로 의미론적 의미를 캡처하는 데 합리적인 결과를 제공하기 어려울 때가 있습니다. 예를 들어 사용자가 \"MSFT의 시니어 데이터 과학자의 혜택은 무엇인가요?\"라고 묻는 경우 시스템이 'MSFT에서 시니어 소프트웨어 엔지니어의 직책 책임' 문서를 검색할 수 있습니다. 그러나 이 RAG 방법을 기반으로 한 다른 문서들 중에서 \"MSFT에서 시니어 직원을 위한 건강 보험 혜택, 주식 옵션, 전문 개발 프로그램\"과 같은 내용도 포함하고 있지만 이 방법에 따라 매우 유사하지 않은 문서들이 더 나은 후보가 될 수 있습니다.\n\nRAG 방법 2: 검색 재랭킹\n\n먼저 Direct Embedding-Based Retrieval 방법을 사용하는 예제를 확인해 보겠습니다:\n\n사용자의 질문: \"MSFT에서 시니어 데이터 과학자의 혜택을 알려주세요\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래와 같은 내용을 검색했습니다:\n\n1. \"마이크로소프트에서 시니어 소프트웨어 엔지니어의 직무 책임\"\n\n2. \"마이크로소프트에서 시니어 직원을 위한 건강 보험 혜택, 주식 옵션 및 전문 개발 프로그램\"\n\n3. \"쥬니어 데이터 과학자로 근무하는 장점에 대한 마이크로소프트의 혜택\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n4. \"시니어 엔지니어를 위한 MSFT의 휴가 정책\"\n\n5. \"MSFT의 직장 문화 개요\"\n\n첫 번째 문서에는 쿼리와 관련성이 적은 유사한 용어들이 많이 포함되어 있습니다. 두 번째 문서는 혜택 (의료 혜택, 주식 옵션)와 더 관련이 있는 내용이므로 더 나은 선택일 것입니다.\n\n따라서 이 문제를 해결하기 위해 RAG 재랭킹을 사용할 수 있습니다. 이 RAG 방법은 노출된 엔티티, 재랭킹 메커니즘 및 점수가 매겨진 문서를 결정하는 데 사용된 모델을 포함합니다. 문서들은 정리되어 가장 관련성이 높은 문서가 먼저 나타날 수 있도록 다시 정렬 및 필터링됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_10.png)\n\n결과적으로 RAG 다시 순위 지정은 AI 프롬프트(X_RERANKED_RAG)를 LLM에 제공합니다. 논리는 LLM이 항상 주어진 순서대로 AI 프롬프트를 고려할 것이라는 것입니다. 사용자의 질문과 일치하는 문서를 AI 프롬프트 상단에 놓으면 더 나은 답변을 제공할 수 있을 것입니다.\n\n예: 다시 순위 지정 검색\n\n다음 단계에서는 다시 순위 지정 검색 과정을 설명합니다. 이 과정에서 llama_index, RankGPTRerank 및 OpenAI API 도구를 활용합니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n문서 로드: SimpleDirectoryReader를 사용하여 문서를 로드하고 특정 데이터 형식으로 분할합니다.\n\n벡터 저장소 인덱스 생성: 문서를 로드한 후 VectorStoreIndex를 사용하여 이러한 문서의 인덱스를 작성합니다. 이 벡터 공간을 사용하여 적합한 문서를 찾습니다.\n\n리트리버 설정: 벡터 인덱스를 사용하여 리트리버를 작성합니다. 쿼리와 유사한 상위 k개의 노드를 가져 오도록 구성합니다.\n\n관련 노드 검색: 쿼리 번들을 기반으로 리트리버에서 상위 k개의 노드를 검색합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다시 랭크하는 방법: OpenAI 내장 RankGPTRerank 모델을 설정하여 노드들을 관련성 점수에 따라 내림차순으로 다시 랭크합니다.\n\n평가\n\nRAG 다시 랭크는 LLM의 응답의 정밀도를 향상시킬 수 있습니다. 이 과정은 두 단계로 구성됩니다. 첫 번째 단계는 직접 삽입 기반 검색과 동일합니다. 그런 다음, 보다 계산 집중적인 다시 랭킹이 이 문서들의 순서를 조정합니다. 마지막으로, 이러한 다시 랭크된 AI 프롬프트를 LLM에게 보내어 가장 관련성 높은 결과물을 먼저 검토하도록 합니다. 하지만 첫 번째 단계에서 여전히 코사인 거리를 기반으로 한 랭킹이므로 모든 검색된 문서가 쿼리의 의미적으로 매우 관련성이 높지 않을 수 있습니다. 다음은 예시입니다:\n\n사용자의 질문: \"MSFT에서 시니어 데이터 과학자의 혜택은 무엇입니까?\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n첫 번째 단계 검색 (코사인 거리):\n\n1. \"MSFT의 시니어 소프트웨어 엔지니어의 업무 책임\"\n\n2. \"MSFT에서 시니어 데이터 과학자 고용 프로세스\"\n\n3. \"MSFT의 사무실 문화\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n4. \"Google에서 시니어 데이터 과학자의 직업 발전\"\n\n5. \"MSFT의 주니어 직원들을 위한 혜택\"\n\n다시 순위를 매겼음에도 검색된 문서는 여전히 관련이 없습니다. 예를 들어, 첫 번째 문서와 네 번째 문서는 각각 '다른 역할'과 '다른 회사'에 관한 것입니다. 이는 첫 번째 단계의 재랭킹 방법의 한계를 보여줍니다.\n\n재랭킹의 또 다른 단점은 계산 비용입니다. 두 번째 단계에서, 의미론적 정보를 정확하게 캡쳐하기 위해 LLM은 전체 문서와 쿼리를 완전히 이해해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG 방법 3: 변환된 입력 쿼리 검색 (TQR)\n\n이 일반적인 RAG 기술에는 여러 가지 변형이 있지만, 아이디어는 비슷합니다: 원래 쿼리를 업데이트하여 개인 데이터(D)와 더 잘 일치시킵니다:\n\n![image](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_11.png)\n\n여기서 Pipe()는 사용자 정의 함수, 변환기 또는 GPT-3 또는 GPT-4와 같은 LLM(Large Language Models)을 사용하는 LangChain일 수 있습니다. TQR의 합리적 근거는 변환된 쿼리가 개인 데이터 D의 이해하기 쉬운 문서로 변환된다는 것입니다. 때로는 사용자가 매우 개인화된 질문을 할 수 있으며, LLM은 먼저 노이즈를 제거하여 질문을 새로운 문서로 변환할 수 있습니다. 이로써 다음 단계의 RAG에서 개인 데이터의 관련 문서와 더 쉽게 일치시킬 수 있습니다. 수학적으로 보면, X_(query_new)와 D 간의 전체 유사성이 X_(query)와 D 간의 것보다 높습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_12.png)\n\nRAG Method 3.1: 가상 문서 임베딩 (HyDE)\n\nHyDE는 원래 질의 X_query를 가상 문서로 변환하여 TQR로 분류될 수 있습니다. 단계 1에서, 단계 2에서, 시스템은 새로운 쿼리와 개인 데이터 D(doc) 사이의 거리를 최소화하여 상위 k개의 문서를 검색합니다. 이 변환 함수 Pipe()는 OpenAI API를 사용한 LangChain 'hyde.chain'입니다.\n\n![image](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_13.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 두 단계 프로세스는 검색된 문서의 관련성과 정확성을 향상시킬 수 있습니다. 그 이유는 LLM에 의해 생성된 가상 문서가 사용자의 쿼리 의도를 더 정확하게 파악할 수 있기 때문입니다. 논문 \"HyDE: Hypothetical Document Embeddings\"에 따르면, HyDE는 이전 최첨단 영제로 시스템보다 11개의 쿼리에서 현저히 뛰어나다는 것을 입증했습니다.\n\nHyDE RAG는 다음 인기 있는 RAG를 다루고 있습니다:\n\n- Self-querying Retrieval: LLM은 추가적인 관련 정보를 검색하기 위해 자체 쿼리를 생성하고, RAG 프롬프트가 LLM에게 전달되어 더 나은 응답을 생성합니다.\n\n- MultiQuery Retriever: LLM은 사용자의 원래 쿼리로부터 여러 쿼리를 생성하고, 그 후 HyDE 단계를 따릅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예시: HyDE\n\n우리는 다음 사용 사례를 공부합니다:\n\n사용자 질의: \"MSFT에서 시니어 데이터 과학자의 혜택은 무엇입니까?\"\n\n우선 Direct RAG 검색 결과를 확인해 보겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n1. \"MSFT에서 시니어 소프트웨어 엔지니어의 직무 책임\"\n\n2. \"MSFT에서 시니어 데이터 과학자 채용 프로세스\"\n\n3. \"MSFT의 사무실 문화\"\n\n4. \"Google의 시니어 데이터 과학자의 경력 진로\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n5. \"MSFT 주니어 직원을 위한 혜택\"\n\n검색된 문서는 '시니어 데이터 과학자의 혜택' 질의와 관련이 없습니다.\n\nHyDE RAG를 확인해 봅시다:\n\nStage 1: 쿼리 변환:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n단계 2: 관련 문서 검색\n\n변환된 쿼리를 사용하여 D에서 상위 5개 관련 문서를 검색하십시오.\n\n\"MSFT의 고위 직원들을 대상으로 하는 건강 관리 혜택, 주식 옵션 및 전문 발전 프로그램\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n“MSFT는 고급 데이터 과학자들을 위해 건강 보험, 퇴직 계획, 그리고 보너스를 제공합니다.\"\n\n\"MSFT의 고급 직원들은 유급 휴가, 웰빙 프로그램, 그리고 교육 기회를 즐길 수 있습니다.\"\n\n검색된 문서가 '고급 데이터 과학자의 혜택'에 대한 쿼리와 관련이 더 많음을 보여줍니다. HyDE의 단점은 계산 비용과 텍스트 환각의 위험입니다. 예를 들어, 생성된 가상의 문서는 첫 번째 단계에서 더 나아 보일 수 있지만, 원본 쿼리에서 벗어날 수 있어 최종 검색된 문서가 직접 검색한 것보다 못해질 수 있습니다.\n\nRAG Method 3.2: 향상된 가상 문서 임베딩(EHyDE)”\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nEHyDE는 Stage 1에서 개인 데이터 𝐷(문서)나 context 정보를 원래의 쿼리 𝑋_query에 추가하여 HyDE를 개선합니다. Stage 2에서 수정된 쿼리는 가상 문서(새로운 쿼리)로 변환됩니다. Stage 3에서는 검색 과정이 HyDE와 동일한 단계를 따릅니다. 추가 정보는 NLP 기계 학습을 통해 개인 데이터 𝐷(문서)와 대화 기록에서 얻을 수 있으며, D의 키워드 또는 빈도가 더 높은 쿼리와 같은 내용입니다.\n\nEHyDE의 이점은 개인 데이터 𝐷(문서)에서 정보를 추가하여 Stage 2의 가상 문서가 개인 데이터 D와 관련된 더 많은 근거를 가질 수 있다는 것입니다.\n\n예시: EHyDE\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기 EHyDE가 HyDE를 개선하는 예시가 있어요:\n\n사용자 질의: \"MSFT의 시니어 데이터 과학자의 혜택은 무엇인가요?\"\n\nHyDE 방식:\n\n단계 1: 질의 변환\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n변환된 쿼리를 가정 문서로 만들어보겠습니다.\n\n단계 2: 관련 문서 검색\n\n가정 문서를 사용하여 문서를 검색합니다.\n\nHyDE를 사용한 검색:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n1. \"MSFT의 시니어 직원을 위한 건강 보험 혜택, 주식 옵션 및 전문 개발 프로그램\"\n\n2. \"MSFT에서 시니어 데이터 과학자를 채용하는 프로세스\"\n\n3. \"MSFT의 사무실 문화\"\n\nHyDE는 채용 프로세스와 사무실 문화에 관한 적합하지 않은 문서도 포함되어 일치하는 문서를 검색합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nEHyDE를 사용한 검색:\n\n단계 1: 개인 데이터에서 정보 추가\n\n개인 데이터 𝐷에서 관련 키워드를 추출합니다. '의료 혜택', '주식 옵션', '전문 개발 프로그램'과 같은 내용입니다.\n\n쿼리를 이러한 키워드를 포함하도록 수정하세요: 'MSFT의 시니어 데이터 과학자를 위한 의료 혜택, 주식 옵션 및 전문 개발 프로그램은 무엇입니까?'.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nStage 2: 쿼리 변환하기\n\n수정된 쿼리를 가상의 문서로 변환해 보겠습니다: 'MSFT의 시니어 데이터 과학자들은 건강 보험 혜택, 주식 옵션 및 전문 개발 프로그램을 받습니다'.\n\nStage 3: 관련 문서 검색하기\n\n개선된 가상 문서를 사용하여 문서를 검색합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nEHyDE를 사용한 검색:\n\n1. \"MSFT의 고위 직원을 위한 건강 보험, 주식 옵션 및 전문 개발 프로그램\"\n\n2. \"MSFT는 고위 데이터 과학자를 위해 건강 보험, 퇴직 계획 및 보너스를 제공합니다\"\n\n3. \"MSFT의 고위 직원은 유급 휴가, 웰니스 프로그램 및 계속되는 교육 기회를 포함한 다양한 혜택을 누립니다\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nEHyDE는 초기 쿼리 변환 단계에서 개인 데이터에서 주요 정보를 통합하여 관련 문서를 더 많이 검색합니다.\n\nEHyDE RAG에는 다음과 같은 전형적인 RAG가 포함되어 있습니다:\n\n- Step-back Prompting: LLM 또는 지역 모델은 이전 단계나 쿼리를 검토하여 HyDE RAG 프로세스를 위해 원래 쿼리를 변환합니다.\n- 히스토리 컨텍스트를 기반으로 쿼리 재생성: LLM 또는 지역 모델은 이전 상호 작용의 역사적 컨텍스트를 사용하여 현재 쿼리를 HyDE RAG 프로세스에 업데이트합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG Method 3.3: Enhanced Direct Embedding-Based Retrieval\n\n이 방법은 단계 1에서 개인 데이터를 사용하여 원본 쿼리를 개요화하는 검색 절차를 요약하며, 단계 2에서는 직접 임베딩 기반 검색 접근 방식을 따릅니다.\n\n![이미지](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_15.png)\n\n함수 S는 개인 데이터를 기반으로 요약된 쿼리를 생성하고, 요약된 쿼리와 개인 데이터 임베딩간의 거리를 최소화하여 RAG 프롬프트를 검색합니다. 이 접근 방식은 HyDE 접근 방식과 유사하지만 가상의 문서를 생성하는 대신 문서를 개요화하는 데 초점을 맞춥니다. 주요 이점은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n· 검색시 LLM 사용 회피로 계산 양 줄이기\n\n· 텍스트 환각 발생 위험 감소\n\n이 RAG 방법은 문서 내 특정 문장 윈도우를 탐색하는 Sentence Window Retrieval을 포함하고 있습니다. 예를 들어, \"운동이 정신 건강에 미치는 영향\"이라는 쿼리에 대해 이 RAG 방법은 \"운동\"과 \"정신 건강\"이 같은 몇 문장에 나타나는 텍스트를 검색합니다.\n\nRAG 방법 4: 변환된 개인 데이터 검색 (TDR)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 TQR 방법은 원래 쿼리를 변환하여 개인 데이터 일치를 개선할 수 있습니다. 마찬가지로, 우리는 이 기술을 개인 데이터에 적용할 수 있습니다 — Transformed Private Data Retrieval (TDR). 이 방법은 먼저 개인 데이터를 변환하고 관련 문서를 검색하여 LLM에게 RAG 프롬프트를 제공합니다. 이 방법의 합리성은 변환된 개인 데이터가 더 나은 데이터 품질을 갖고 있어 소음을 제거하고 주요 목적을 강조할 수 있다는 것입니다.\n\n![이미지](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_16.png)\n\n1단계에서는 로컬 NLP 모델 또는 LLM을 기반으로 한 트랜스포머와 같은 기계 학습 모델(𝑀으로 나타냄)을 사용하여 개인 데이터에서 TF-IDF 및 Word2Vec에 따라 키워드와 같은 핵심 구성 요소 M(D(doc))을 추출합니다. 이러한 핵심 구성 요소는 인간 의미 텍스트(Prompt_text)와 결합되어 Prompt_transform을 생성합니다. 2단계에서 Prompt_transform은 LLM에게 개인 데이터를 어떻게 변환해야 하는지 알려줍니다. 3단게는 다른 방법과 유사하게, 𝑋_query와 𝐷(doc_new) 간의 5개의 최단 거리를 갖는 문서를 선택합니다.\n\nTQR 방법과 마찬가지로, TDR 기술에는 여러 가지 변형이 있습니다. 적용 시나리오에 따라 개인 데이터를 어떻게 변환해야 하는지에 영향을 받을 수 있습니다. 예를 들어, 일반적인 질문-답변 챗봇을 구축할 때 RAG 데이터로 FAQ 스타일 지식 베이스가 필요할 수 있습니다. 많은 상호 작용하는 인공 지능 에이전트들에게는 지식 그래프, 플로우차트, JSON 파일, 데이터베이스 메타데이터 및 머신 러닝 모델의 출력 패턴과 같은 더 복잡한 데이터 구조를 고려해야 합니다. 여기서 다양한 전형적인 사용 사례에 대해 TDR을 소개하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG Method 4.1: 개인 데이터 정리를 통한 TDR\n\n이 방법은 개인 데이터에서 쓸모없는 정보를 제거하는 데 목적을 두고 있습니다:\n\n- NLP에서 구두점, 불용어 및 어간추출과 같은 데이터 정리 기술 사용\n- LLMs가 이미 알고 있는 지식을 개인 데이터에서 제거\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n· 개인 데이터에서 잘못된 정보 제거하기\n\n데이터 품질을 향상하는 첫 번째 단계입니다. 두 번째 단계는 중복 정보를 걸러내어 LLM 프로세스를 간소화하는 것입니다. 세 번째 단계는 중요하지만 더 많은 확인이 필요합니다. 또한 이러한 작업은 LLM에서 수행할 수 있지만 추가 비용이 발생할 수 있습니다.\n\n예시: 개인 데이터 정리를 통한 TDR\n\n우리는 다음과 같은 RAG 프롬프팅을 위한 개인 데이터 𝐷를 가지고 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG_information = ‘’’ 사원 혜택은 회사로부터 받는 유형의 현저한 이점이나 혜택을 나타내며, 건강 보험, 퇴직 계획, 유급 휴가, 보너스 및 기타 보상 형태와 같은 것이 있습니다. 혜택은 회사에서 일하는 데서 얻는 추상적이고 무형의 이점을 의미하기도 합니다. 구체적으로 회사에서 일하는 것의 긍정적인 면이나 경험을 의미합니다. 도움을 주는 근무 환경, 성장 기회, 커뮤니티 감각 및 전반적인 직장 만족도와 같은 것들이 있습니다.’’’\n\n로컬 NLP 모델이나 LLMs에 기반한 변환기를 사용하여 𝐷에서 다음 정보를 식별할 수 있습니다:\n\n주제 = \"혜택이라는 단어의 일반적인 설명\"\n\n그런 다음 다음 프롬프트를 LLMs에 전달하여 새로운 비공개 데이터를 만들 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"테이블 태그를 Markdown 형식으로 변경해주세요.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG 방법 4.2: 비공개 데이터 생성을 통한 TDR\n\n우리는 LLMs를 사용하여 원본 비공개 데이터를 다양한 응용 프로그램에 맞게 구체적인 형태로 변환할 수 있습니다. 아래는 일반적인 예시들입니다:\n\nRAG 방법 4.2.1: 비공개 데이터 요약\n\n이 TDR 방법은 원본 비공개 데이터를 간결한 데이터로 요약하여 주요 포인트를 수집합니다. 이를 위해 LLMs(또는 트랜스포머)를 사용하여 비공개 데이터 𝐷를 RAG 데이터로 변환합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저 위의 표 태그를 마크다운 형식으로 변경해보겠습니다.\n\n\n![ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_18](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_18.png)\n\n이 방법은 동시에 다음 조치들을 최소화하도록 명시적으로 목표로 합니다:\n\n![ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_19](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_19.png)\n\n이는 결과적으로 RAG 데이터가 개인 데이터와 밀접한 관련이 있으면서도 텍스트를 최대한 간결하게 유지해야 한다는 것을 의미합니다. 또한, 결과적인 RAG 데이터에는 최소한의 중복이 있어야 하며, 관련 없는 주제를 피해야 한다는 것을 시사합니다.\n\n\n위의 내용이 도움이 되었기를 바라며, 궁금한 점이 있으면 언제든지 물어보세요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예시: 개인 데이터 요약:\n\n우리는 종종 긴 기업 정책 문서를 간단한 핵심 정책을 강조하는 RAG 데이터로 변환하기 위해 요약 TDR을 사용합니다. 그런 다음 이 RAG 데이터를 사용하여 회사를 위한 FAQ 스타일 지식 베이스를 만들 수 있습니다:\n\n- NLP 기술을 사용하여 문서에서 주요 포인트를 추출합니다.\n- 이러한 주요 포인트를 AI 프롬프트에 추가하여 개인 데이터를 요약합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLLM과 AI 프롬프트를 사용하여 RAG 데이터를 생성하세요.\n\n다음은 원본 문서의 예시입니다:\n\n“저희는 의료, 치과, 시력 보험을 포함한 종합 건강 보험을 제공합니다. 또한 401(k) 매칭 및 연금 플랜을 포함한 다양한 퇴직 계획도 제공하여 직원들이 은퇴 후 재정 안정성을 확보할 수 있도록 합니다. 유급 휴가: 모든 직원은 유급 휴가(PTO)를 받으며, 휴가 일수, 병가, 개인 사정 일수를 포함합니다. 전문 개발: 계속적인 학습을 장려하고 직무와 관련된 코스, 인증서, 그리고 컨퍼런스에 대한 보상도 제공합니다. 또한 직원들의 안전을 최우선으로 여깁니다. …”\n\n비공개 데이터 접근 방식을 요약한 후, 다음과 같은 잘 구성된 RAG 데이터가 제공됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"안녕하세요! 아래는 회사가 제공하는 혜택에 대한 몇 가지 정보입니다:\n\n1. 건강 보험: 회사는 의료, 치과 및 시력 보험을 포함한 종합 건강 보험을 제공합니다.\n\n2. 퇴직 계획: 401(k) 매칭 및 연금 플랜과 같은 다양한 퇴직 계획을 제공합니다.\n\n3. 유급 휴가: 직원들은 휴가, 병가 및 개인 날 등을 포함한 유급 휴가를 받습니다.\n\n4. 전문 개발: 직장과 관련된 과정, 자격증 및 학회에 대한 보상을 통해 지속적인 학습을 촉진합니다.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n5. 직장 안전: 직원 안전은 최우선 과제로, OSHA 규정을 준수하고 정기적인 안전 교육을 받습니다....\"\n\n참고로, 이 방법은 Parent-child Chunks Retrieval 방법을 포함하며, 문서를 계층적 청크로 나누어 메인 컨텍스트(부모) 및 구체적인 세부 사항(자식) 섹션을 검색합니다.\n\nRAG 방법 4.2.2: 개인 데이터 파라프레이징\n\n가끔 개인 데이터에는 회계, 법률, 건강과학과 같은 분야의 전문 용어가 많이 포함됩니다. 그러나 이러한 문서들은 사용자 쿼리가 동일한 기술 용어를 사용하지 않을 수 있기 때문에 AI 시스템이 RAG를 사용하기 어렵게 만들 수 있습니다. 데이터를 더 간단한 언어로 다시 표현하면 RAG에 더 적합해집니다. 이 방법은 원래 의미를 유지하면서 사용자 쿼리와 일치할 확률을 높이는 데 도움이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 방법은 동시에 다음을 동시에 최소화하기 위해 구체적으로 진행됩니다:\n\n![image](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_20.png)\n\n여기서 D(쿼리)는 비전문 사용자로부터의 일반 쿼리를 나타냅니다.\n\n'개인 데이터 패러프레이징' RAG 기술의 여러 버전은 번역과 같은 방법을 통해 데이터를 다른 언어로 변환하여 더 접근 가능하고 사용하기 쉽게 만듭니다. 이 방법은 주로 다국어 인공지능 지원 시스템을 개발하는 데 활용됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG Method 4.2.3: 특별한 구조로 개인 데이터 변환하기\n\n대부분의 AI 응용 프로그램 튜토리얼은 특정 길이의 역사적 텍스트를 추적하는 것과 같은 상호 작용적 작업을 위해 간단한 RAG 방법을 사용합니다. 그러나 실제 대화형 AI 응용 프로그램은 더 고급 접근 방식이 필요합니다. 예를 들어:\n\n- 기본 질문에 답변하는 챗봇은 사용자의 질의만 필요할 수 있습니다. 그러나 복잡한 문제를 해결하는 고객 서비스 봇은 사용자를 효과적으로 안내하기 위해 전체 대화 기록이 필요할 수 있습니다.\n\n- SQL 절이 복잡한 데이터를 검색하도록 AI 시스템에 요청하는 데이터 분석가는 메타데이터, 테이블 관계 및 출력 형식을 포함한 특별히 구조화된 프롬프트가 필요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한 가지 가능한 방법은 개인 데이터를 특수 구조(지식 그래프, 플로우차트, JSON 파일, 데이터베이스 메타데이터, 이미지 파일 및 기계 학습 결과를 포함)로 변환하는 것입니다. 이러한 구조는 고급 AI 시스템에서 RAG 성능을 향상시키는 데 입증되었습니다. 다음 공식은 이 절차를 설명합니다:\n\n![image](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_21.png)\n\n여기서 M(D(doc), Structure)는 일반 변환 함수를 나타내며, LLMs, 트랜스포머 또는 수동 절차를 포함한 로컬 NLP 모델 등이 될 수 있습니다. 두 번째 매개변수인 Structure은 위에서 언급한 데이터 구조를 나타냅니다. 여기서 Prompt는 RAG 프롬프트와 콘텍스트 프롬프트를 통합하며, 최근의 콘텍스트와 같은 대화 콘텍스트의 함수 값입니다.\n\n예시: 인터넷 문제 해결 대화 기록\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 예시는 인터넷 문제 해결 대화 내용을 사용하여 대화 바구니 분석을 생성하여 대화 바구니 시퀀스를 만드는 방법을 보여줍니다. 그런 다음 대화 바구니 시퀀스 패턴을 RAG 파일로 사용하여 LLM이 고객 문제를 대화식으로 해결하는 데 사용됩니다. 이는 기계 학습 결과를 사용한 전형적인 RAG 예시입니다.\n\n- 데이터: 과거 인터넷 문제 해결 대화 내용입니다.\n\n- 바구니 분석: 공통 대화 시퀀스를 식별하고 그 빈도 (지원)와 신뢰도 (신뢰도)를 기록합니다.\n\n- 대화 바구니 시퀀스: 식별된 패턴을 기반으로 대화 바구니 시퀀스를 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- RAG 파일 생성: 이러한 시퀀스를 구조화된 RAG 파일로 변환합니다.\n\n- LLM 통합: RAG 프롬프트를 만들어 LLM에 전달합니다.\n\n- 문제 해결: LLM은 이 대화 시퀀스를 사용하여 대화를 이끄는 데 사용하고 과거 패턴에 기반한 솔루션을 제공합니다.\n\n인터넷 문제 해결 대화를 거래 데이터로 사용하여 바구니 분석을 수행하여 다음 시퀀스를 얻습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n1. 라우터 재시작 - 케이블 확인 - 지원 연락\n\n2. 케이블 확인 - 라우터 재시작 - 지원 연락\n\n3. 케이블 확인 - 지원 연락\n\n4. 라우터 재시작 - 케이블 확인\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n5. 연결 상태 확인 - 라우터 재시작 - 케이블 확인\n\n![image](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_22.png)\n\n그런 다음 머신러닝 결과 시퀀스 또는 플롯을 LLM의 RAG 프롬프트로 직접 또는 간접적으로 사용할 수 있습니다.\n\n예시: 캐글 콘테스트 — 쿠폰 교환 예측\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nKaggle 콘테스트 '쿠폰 사용 예측'을 확인해보세요. 데이터베이스 메타데이터에 특히 관심이 있습니다:\n\n![image](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_23.png)\n\n여기서 다음 단계를 통해 LLM을 사용하여 이미지를 텍스트 메타데이터로 변환할 것입니다:\n\n- 이미지 파일을 업로드하세요\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"이 대회에 대한 설명은 다음과 같습니다: 쿠폰 사용 예측...\n\n이미지에 표시된 메타데이터와 테이블 간의 관계를 설명해주세요. 각 테이블의 필드와 그들 간의 관계를 설명해야 합니다.\"\n\n그러면 다음과 같은 RAG 데이터를 얻을 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n테이블과 해당 필드:\n\nTrain:\n\nid: 각 레코드의 고유 식별자.\n\ncampaign_id: 캠페인 데이터와 연결된 식별자.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n테이블 태그를 마크다운 형식으로 변경해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n캠페인 ID: 각 캠페인을 식별하는 고유 식별자입니다.\n\n…\n\n또한 텍스처 메타데이터를 플로차트 또는 텍스트 또는 이미지 형식의 표로 변환하여 역으로 작업을 수행할 수도 있습니다. 이러한 특별한 구조화된 데이터 또는 파일 형식은 LLM들이 복잡한 작업을 해결하는 데 직접적으로 RAG 문서로 사용될 수 있다는 점이 인상적입니다. 예를 들어 Interactive AI Agents by Using Neo4j RAG.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n개인 데이터를 쉽게 이해할 수 있는 지식 그래프로 변환하는 방법을 Neo4j에서 소개해 드리겠습니다. 이를 통해 정보를 체계적으로 구성하여 LLM이 쉽게 소화할 수 있습니다:\n\n- 그래프를 배치할 Neo4j 공간을 생성합니다.\n- LLM을 사용하여 주요 정보를 검색하고 다양한 항목을 구성합니다.\n- 위 정보를 JSON으로 변환합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n· JSON 데이터를 지식 그래프에 로드합니다.\n· GraphCypherQAChain으로 그래프에서 쿼리를 실행합니다.\n\n다음은 원본 개인 데이터에서 변환된 지식 그래프의 예시입니다:\n\nCustomer1[Customer: ID=1, Age=20–30, Status=Single] → Transaction101[Transaction: ID=101, Date=2023–05–01]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음은 Markdown 형식으로 표를 변경하였습니다.\n\n\n| 관계               | 함께 사용되는 항목                        |\n|---------------------|-----------------------------------------|\n| Transaction101     | Product1001 [제품: ID=1001, 이름=제품 A, 카테고리=전자제품] |\n| Customer2          | Customer: ID=2, 나이=30-40, 상태=기혼 |\n| Customer2 → Transaction102 | Transaction: ID=102, 날짜=2023-05-02 |\n| Transaction102     | Product1002 [제품: ID=1002, 이름=제품 B, 카테고리=가정용] |\n\n\nLLM을 위한 RAG 프롬프트에서 고객-제품 거래 데이터를 기반으로 한 응답을 개선하는데 사용할 수 있는 이 지식 그래프를 참고하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG Method 5: RPF\n\nRPF(Relevance, Precision, and Fidelity) for RAG은 RAG 데이터의 적절성, 정확성 및 충실도를 평가하고 향상시키는 프레임워크입니다. 이 측정 항목은 RPF 점수라고 하며, LLM이 미리 정의된 알고리즘을 사용하여 만듭니다.\n\n그러나 RPF는 RAG 방법은 아니지만, 해당 메커니즘이 RAG 절차를 설정하는 데 도움이 될 수 있습니다.\n\n쿼리 평가: LLM은 RPF 알고리즘을 사용하여 쿼리를 평가합니다. 개인 데이터의 각 문서에는 RPF 점수가 할당됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Exploring AI Prompt Engineering Mathematical Foundations and RAG Methodologies](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_24.png)\n\n신뢰도 평가: 가장 높은 RPF 점수 max_score_RPF를 선택하고, 가장 높은 RPF 점수를 가진 문서 X_RAG를 선택합니다. 점수 max_score_RPF가 임계값 T보다 높으면 LLM은 X_RAG를 사용하여 응답하고, 그렇지 않으면 사용자로부터 명확화를 위해 상호 작용적 피드백을 제공하여 사용자로부터 설명을 듣습니다:\n\n![Exploring AI Prompt Engineering Mathematical Foundations and RAG Methodologies](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_25.png)\n\nAI 및 사용자 상호작용: LLM은 사용자에게 질문을 명확히하거나 쿼리의 의미를 이해하기 위해 몇 가지 선택지를 제공합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n응답: LLM이 쿼리를 이해하면 응답을 검색하고 생성합니다.\n\n## 최종 생각\n\n많은 자습서에서는 대규모 언어 모델, AI 프롬프트 엔지니어링 및 RAG(Retrieval-Augmented Generation)을 소개하나, 종종 구체적인 기술과 상황에 중점을 두고 텍스트 설명이나 코드를 사용합니다. 이 글에서는 이러한 접근 방식을 수학적으로 정리하고 적용 가능성에 대해 요약했습니다. RAG 기술을 체계적으로 정리하고 이러한 모델의 설명을 했습니다. 이러한 방식을 통해 우리는 대규모 언어 모델(BLMs), 지능형 프롬프트 엔지니어링(IPE)과 RAG의 원리, 범주 및 사용 사례를 잘 이해할 수 있습니다. 더 나아가, 이는 대규모 언어 기술의 새로운 발전을 위한 자극제로 활용될 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_0.png"},"coverImage":"/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_0.png","tag":["Tech"],"readingTime":25},{"title":"콜모고로프-아놀드 네트워크KAN가 인공지능 세계를 영원히 바꿀 것입니다","description":"","date":"2024-06-20 04:51","slug":"2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever","content":"\n\n## 신경망에 대해 알고 있던 모든 것을 잊어버리세요, KAN이 규칙을 다시 쓸 예정입니다\n\n![image](/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_0.png)\n\n# 소개:\n\n머신 러닝의 계속 변화하는 풍경 속에서 최근 발표된 \"KAN: Kolmogorov-Arnold Network\"라는 연구 논문은 열광적인 열기를 불러일으켰습니다. 이 혁신적인 접근 방식은 다층 퍼셉트론(MLP)의 전통적인 지혜에 도전하여 신경망 구조에 대한 새로운 시각을 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 콜모고로프-아놀드 네트워크 (KAN's)란 무엇인가요:\n\n이 혁신적인 개념의 핵심에는 Vladimir Arnold와 Andrey Kolmogorov가 개발한 수학 이론인 콜모고로프-아놀드 표현 정리가 있습니다. 이 정리는 복잡한 다변수 함수를 보다 간단한 일차원 함수로 분해할 수 있음을 주장하여 KAN의 독특한 구조의 기초를 제공합니다.\n\n![이미지](/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_1.png)\n\n이제 당연한 질문은 이 \"더 간단한 일차원 함수\"가 무엇인가요. 수학 또는 컴퓨터 그래픽을 조금 알고 있는 사람이라면, 우리가 말하는 것은 옛날부터 신뢰받는 조각별 다항식인 Spline입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*1VcxJSh_CYAPc9-0os2-pA.gif)\n\n# KAN의 시크릿 소스, 스플라인!\n\n스플라인은 연속 점들을 연결하여 부드러운 곡선을 생성할 수 있는 수학적 함수입니다. 스플라인은 인접 세그먼트 사이의 연속성과 부드러움을 보장하면서 곡선의 모양을 조절하는 유연성을 제공합니다.\n\n스플라인을 생성하기 위해 일반적으로 곡선의 경로를 정의하는 일련의 제어점을 시작점으로 삼습니다. 그런 다음, B-스플라인이나 베지에 곡선과 같은 기저 함수를 사용하여 이러한 제어점 사이의 경로를 보간하거나 근사합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*B1MXmHF8xD_WP3GJNwbfDQ.gif)\n\n기본적으로 스플라인은 복잡한 곡선이나 표면을 정밀하고 유연하게 표현하는 다재다능한 도구를 제공하여 다양한 분야에서 귀중하게 활용됩니다.\n\n하지만, KAN 아키텍처에서 이러한 스플라인을 어떻게 사용하고 적용할까요?\n\n# KAN 작동 방식을 이해하는 가장 간단한 방법\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n전통적인 MLP들과 달리 KAN은 고정된 활성화 함수를 학습 가능한 기능(B-Splines)으로 대체하여 네트워크의 가장자리를 따라 작동합니다.\n\n이 적응형 아키텍처를 통해 KAN은 복잡한 함수를 효과적으로 모델링하면서 해석 가능성을 유지하고 필요한 매개변수의 수를 줄일 수 있습니다.\n\n![image](https://miro.medium.com/v2/resize:fit:1200/1*5hfRk7kjl-CZvyhpbfKlsw.gif)\n\nMLP의 경우 신호를 전달하는 수동적인 수단으로 기능하는 것과 달리, KAN의 뉴런들은 학습 프로세스의 적극적인 참여자로서 동적으로 동작을 조정하여 마주치는 데이터에 대응합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n네트워크의 가장자리에 배치된 학습 가능한 활성화 함수를 도입하여 가능해진 이 혁신적인 전환은, 네트워크의 에지에 배치된 학습 가능한 활성화 함수를 통해 가능케 되었습니다.\n\n![이미지](/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_2.png)\n\nB-스플라인의 표현력을 이용하여, 이러한 함수들은 KAN에 무궁무진한 유연성과 적응성을 부여하여, 복잡한 데이터 환경을 쉽게 탐색할 수 있게 만들어줍니다.\n\n# KAN의 주요 장점:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 향상된 확장성\n\nKAN은 특히 고차원 데이터 시나리오에서 MLP에 비해 우수한 확장성을 보여줍니다. 복잡한 함수를 간단한 구성 요소로 분해하는 능력으로 대용량 데이터를 효율적으로 처리할 수 있어서 방대한 양의 정보가 포함된 작업에 이상적입니다.\n\n## 향상된 정확성\n\n더 적은 매개변수를 사용하더라도 KAN은 다양한 작업에 걸쳐 전통적인 MLP보다 더 높은 정확도와 낮은 손실을 달성합니다. 이는 데이터 내에서 관계를 적응적으로 모델링하는 능력 때문에, 보다 정확한 예측과 보다 잘 일반화된 결과를 얻을 수 있다고 이해됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 해석 가능한 모델\n\nKAN의 구조는 해석 가능성을 용이하게 하여 연구자들이 학습된 패턴을 효과적으로 나타내는 상징적인 공식을 도출할 수 있게 합니다. 블랙박스 모델과는 달리, KAN은 입력 특성이 네트워크 전반에 걸쳐 어떻게 변환되는지에 대한 통찰을 제공하여 투명성과 이해를 높입니다.\n\n이제 KAN이 무엇이며 왜 인공지능 분야에서 큰 문제인지를 알게 되었지만, 세상은 이론과 논문에서 멋져 보이는 모델로만 움직이는 것이 아닙니다.\n\n하지만 KAN의 가장 좋은 점은 새로운 Python 라이브러리 \"PyKAN\"을 사용하여 자신의 데이터 과학 문제에 쉽고 간단하게 적용할 수 있다는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 텍스트를 친근한 어조로 한국어로 번역하겠습니다.\n\n우리의 토론을 파이썬으로 이 아키텍처를 어떻게 구현할 수 있는지 예제와 함께 마무리해봅시다.\n\n# Python에서 KAN의 구현 (PyKAN):\n\n우리의 데모를 위해 분류 문제를 사용해봅시다.\n\n## 데이터셋 생성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nsklearn 라이브러리의 \"make_moons\" 함수를 사용하여 합성 데이터 세트를 생성할 예정이에요.\n\n```js\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_moons\nimport torch\nimport numpy as np\n\ndataset = {}\ntrain_input, train_label = make_moons(n_samples=1000, shuffle=True, noise=0.1, random_state=None)\ntest_input, test_label = make_moons(n_samples=1000, shuffle=True, noise=0.1, random_state=None)\n\ndataset['train_input'] = torch.from_numpy(train_input)\ndataset['test_input'] = torch.from_numpy(test_input)\ndataset['train_label'] = torch.from_numpy(train_label)\ndataset['test_label'] = torch.from_numpy(test_label)\n\nX = dataset['train_input']\ny = dataset['train_label']\nplt.scatter(X[:,0], X[:,1], c=y[:])\n```\n\n## 결과 (시각화된 데이터셋)\n\n\u003cimg src=\"/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_3.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## KAN 생성 및 훈련\n\n```js\nfrom kan import KAN\n\nmodel = KAN(width=[2,2], grid=3, k=3)\n\ndef train_acc():\n    return torch.mean((torch.argmax(model(dataset['train_input']), \n    dim=1) == dataset['train_label']).float())\n\ndef test_acc():\n    return torch.mean((torch.argmax(model(dataset['test_input']), \n    dim=1) == dataset['test_label']).float())\n\nresults = model.train(dataset, opt=\"LBFGS\", steps=20, \n          metrics=(train_acc, test_acc), \n          loss_fn=torch.nn.CrossEntropyLoss())\n```\n\n## 모델로부터 심볼릭 공식 획득\n\n이후, 모델이 데이터로부터 학습한 내용을 나타내는 심볼릭 공식이 유도됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nformula1, formula2 = model.symbolic_formula()[0]\n```\n\n## 정확도 계산하기\n\n마지막으로 학습된 공식에서 정확도를 얻을 수 있습니다.\n\n```python\ndef acc(formula1, formula2, X, y):\n    batch = X.shape[0]\n    correct = 0\n    for i in range(batch):\n\n        logit1 = np.array(formula1.subs('x_1', X[i,0]).subs('x_2', X[i,1])).astype(np.float64)\n        logit2 = np.array(formula2.subs('x_1', X[i,0]).subs('x_2', X[i,1])).astype(np.float64)\n\n        correct += (logit2 \u003e logit1) == y[i]\n\n    return correct/batch\n\n# 정확도 출력\nprint('학습 데이터 정확도:', acc(formula1, formula2, dataset['train_input'], dataset['train_label']))\n\nprint('테스트 데이터 정확도:', acc(formula1, formula2, dataset['test_input'], dataset['test_label']))\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 결과\n\n```js\n수식의 학습 정확도: tensor(0.9700)\n수식의 테스트 정확도: tensor(0.9660)\n```\n\n# 결론\n\n요약하자면, 콜모고로프-아놀드 네트워크(KANs)는 신경망 구조에서 패러다임 전환을 나타냅니다. KANs는 잠재력을 최대로 발휘하기 위해 추가 연구와 실험이 필요하지만, 앞으로 몇 년 동안 기계 학습과 과학적 발견을 진전시키는 데 유용한 도구로서의 가능성을 갖고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n계속 발전하는 이 분야에서 KAN은 혁신의 선두에 서 있습니다. 지능 시스템의 미래를 형성하고 복잡한 데이터 분석과 모델링 방식을 혁명화하고 있습니다.","ogImage":{"url":"/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_0.png"},"coverImage":"/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_0.png","tag":["Tech"],"readingTime":6},{"title":"그래프 ML NetworkX 소개","description":"","date":"2024-06-20 04:49","slug":"2024-06-20-GraphMLintroductiontoNetworkX","content":"\n\n## | GRAPH| GRAPH ML| NETWORKX| PYTHON|\n\n![NetworkX](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_0.png)\n\nNetworkX는 Python에서 그래프를 분석, 시각화 및 표현하는 주요 라이브러리입니다. NetworkX에는 많은 함수 모음이 포함되어 있으며, 본 튜토리얼에서는 Python에서 그래프를 시작하고 조작하는 기본 기능을 소개하겠습니다. 다음 튜토리얼에서는 더 복잡한 기능 및 그래프를 더 잘 시각화하는 방법을 살펴볼 예정이지만, 일단은 기초부터 단계별로 시작하는 것이 좋습니다.\n\n이 글에서는 다음을 논의할 것입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- NetworkX를 사용하여 그래프를 다루는 방법\n- 다양한 유형의 그래프 생성 방법\n- 그래프를 그리는 방법\n\n이 자습서의 코드는 Google Colab에서 작성되었으며 테스트되었으며 컴퓨터에 별도로 설치할 필요없이 어떤 Colab 노트북에서도 실행할 수 있습니다.\n\n# NetworkX 소개\n\nNetworkX에서 그래프는 일반적으로 객체(클래스)이며 이러한 객체에 적용할 수 있는 다양한 메서드와 함수가 있습니다. 또한 NetworkX는 그래프 데이터 세트를 읽고 객체를 저장하며 다양한 형식으로 저장하는 기능을 제공합니다. 라이브러리는 일부 고전적인 데이터 세트도 제공하여 사용하여 놀 수 있습니다(예: 카라테 클럽 데이터 세트).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n또한 NetworkX를 설치하고 사용하는 것이 실제로 쉽다는 것을 알 수 있을 것입니다 (Python의 기본 지식이 필요합니다). NetworkX는 확장성과 이식성으로 유명하며 이러한 이유로 Python에서 그래프를 처리하는 데 가장 많이 사용되는 라이브러리입니다. 이는 NetworkX와 호환되는 다른 데이터 과학자가 작성한 확장 프로그램의 생생한 생태계를 만들어냈습니다 (또는 NetworkX 그래프의 기반으로 사용됩니다).\n\n![그림](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_1.png)\n\n어떻게 시작할까요?\n\n첫 번째 단계는 라이브러리를 가져오는 것입니다 (이미 설치했다고 가정하거나 Colab을 사용 중이면 이미 설치되어 있을 것입니다).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport networkx as nx\nimport matplotlib.pyplot as plt\n```\n\n그리고 이제는 어떻게 해야 할까요? 이전 튜토리얼에서 말했듯이 그래프는 단순히 객체(노드 또는 정점)들이 엣지를 통해 연결된 모음일 뿐입니다. 그래프는 이러한 노드들 사이의 관계를 나타내며, 이를 어떻게 표현할지 결정해야 합니다. 우리는 그래프가 직접적인 연결을 가지고 있는지, 또는 링크의 방향을 신경 쓰지 않는지를 결정해야 합니다.\n\n예를 들어, 한 그룹 내에서 다른 사람들 간의 우정 관계를 표현하고 싶다고 가정해 봅시다. 이 경우 A가 B의 친구라면 B가 A의 친구라고 가정할 수 있으며 따라서 관계를 표시할 필요가 없습니다. 만약 A에서 B로 소포가 이동하는 운송 그래프를 표현하고 있다면, 방향성 있는 그래프를 사용하는 것이 좋습니다.\n\nNetworkx에서 방향성 있는 그래프나 무방향 그래프를 구축하는 것은 매우 쉽습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n# 무방향 그래프 G 생성\nG = nx.Graph()\nprint(\"그래프 G는 방향이 지정되어 있습니다: {}\".format(G.is_directed()))\n\n# 유방향 그래프 H 생성\nH = nx.DiGraph()\nprint(\"그래프 H는 방향이 지정되어 있습니다: {}\".format(H.is_directed()))\n\n# 엣지와 노드 수 얻기\nG.number_of_nodes(), G.number_of_edges()\n\n\n![이미지](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_2.png)\n\n그래프를 구축한 후 추가 데이터를 수집하여 그래프를 업데이트해야 할 수 있습니다. NetworkX를 사용하면 노드를 추가하거나 다른 그래프를 직접 추가하기 쉽습니다.\n\n\n# 노드 추가\nG.add_node(1)\nG.add_nodes_from([2, 3])\n# 다른 그래프에서 추가할 수도 있습니다\nH = nx.path_graph(3)\nG.add_nodes_from(H)\n# 또는 그래프를 직접 추가할 수도 있습니다\nG.add_node(H)\nG.number_of_nodes(), G.number_of_edges()\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Graph](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_3.png)\n\n당연히 A가 B와 친구이고 나중에 C와도 친구가 될 수 있으므로, 또 다른 링크를 추가하려고 합니다.\n\n```js\n#엣지 추가하기\nG.add_edge(1, 2)\ne = (2, 3)\nG.add_edge(e)\nG.add_edges_from([(1, 2), (1, 3)])\nG.add_edges_from(H.edges())\n```\n\n지금까지 그래프를 요소와 관계의 집합으로 삼았습니다. 노드는 모두 같았고, 관계도 단순한 연결이었습니다. 실제로 이는 축소된 것이며, 노드와 연결은 레이블 또는 기능과 연관될 수 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, 소셜 네트워크를 만들 때 각 노드에 이름(label, 예: \"Bob\")을 부여하거나 클래스(\"스팸\" 또는 \"스팸 아님\")를 지정할 수 있지만 특성(키, 나이, 관심사)도 부여할 수 있습니다. 앞으로 볼 것처럼 노드의 특성은 다양한 알고리즘에서 사용됩니다.\n\n```js\n# 무향 그래프 G를 생성합니다\nG = nx.Graph() # 비어 있습니다\n# 첫 번째 노드에 노드 레벨 속성 추가\nG.add_node(0, feature=3, label=0)\n\n# 노드 0의 속성을 가져옵니다\nattr = G.nodes[0]\nprint(\"노드 0은 다음과 같은 속성을 가지고 있습니다: {}\".format(attr))\n```\n\n![image](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_4.png)\n\n이 경우 몇 개의 노드가 있는 그래프가 있지만, 종종 수천 개 또는 수백만 개의 노드가 있는 경우가 많으므로 더 효율적인 시스템이 필요할 수 있습니다. NetworkX를 사용하면 딕셔너리를 사용할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# 여러 노드에 속성을 포함한 노드를 추가할 수 있습니다\nG.add_nodes_from([\n  (1, {\"feature\": 1, \"label\": 1}),\n  (2, {\"feature\": 2, \"label\": 2})\n]) \n\n# 노드를 순회할 수 있습니다\n# 속성을 반환하려면 data=True 인수를 사용합니다\nfor node in G.nodes(data=True):\n  print(node)\n\n# 노드 수를 얻을 수 있습니다\nn_nodes = G.number_of_nodes()\nprint(\"G에는 {}개의 노드가 있습니다\".format(n_nodes))\n```\n\n![Graph](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_5.png)\n\n앞서 말했듯이, 관계에는 다양한 특성이 있을 수 있습니다. 가장 흔한 경우는 서로 다른 연결에 값을 (또는 가중치) 연결하는 것입니다. 예를 들어, 교통 네트워크에서 노드는 장소를 나타내고 연결은 도로를 나타낼 수 있으며, 가중치는 거리나 이동 시간을 나타낼 수 있습니다. 이는 노드 A와 B 사이의 최단 경로를 찾고 싶은 경우에 중요한 정보입니다 (나중에 이를 계산하는 알고리즘이 있다는 것을 볼 것입니다).\n\n```js\n# 가중치가 0.5인 하나의 엣지를 추가합니다\nG.add_edge(0, 1, weight=0.5)\n\n# 엣지 (0, 1)의 속성을 가져옵니다\nedge_0_1_attr = G.edges[(0, 1)]\nprint(\"(0, 1) 엣지는 다음과 같은 속성을 가지고 있습니다: {}\".format(edge_0_1_attr))\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n당연히 노드 단위로 작업할 필요는 없어요:\n\n```js\n# 엣지 가중치를 가진 여러 엣지 추가\nG.add_edges_from([\n  (1, 2, {\"weight\": 0.3}),\n  (2, 0, {\"weight\": 0.1})\n])\n\n# 모든 엣지들에 루프 적용\n# 여기서 data=True가 없으므로 엣지만 반환됩니다\nfor edge in G.edges():\n  print(edge)\n\n# 엣지의 수 구하기\nnum_edges = G.number_of_edges()\nprint(\"G에는 {}개의 엣지가 있습니다\".format(num_edges))\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_7.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n좋아요, 이제 멋진 그래프가 있어요! 그래프를 시각화해 보는 건 어떨까요?\n\n```js\n# 그래프 그리기\nnx.draw(G, with_labels=True)\n```\n\n![Graph](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_8.png)\n\n노드가 몇 개의 이웃을 가지고 있는지 알아내는 것은 종종 중요한 정보입니다. 예를 들어, 우리는 그래프를 플로팅하지 않고도 노드가 연결된 다른 노드 수를 알고 싶어합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nnode_id = 1\n\n# 노드 1의 차수\nprint(\"노드 {}의 차수는 {}\".format(node_id, G.degree[node_id]))\n\n# 노드 1의 이웃 가져오기\nfor neighbor in G.neighbors(node_id):\n  print(\"노드 {}의 이웃은 {}\".format(node_id, neighbor))\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_9.png\" /\u003e\n\n# 서로 다른 그래프 유형\n\n이전 튜토리얼에서 우리는 그래프 유형이 다양하다는 것을 알 수 있었고 이러한 정보의 많은 부분이 인접 행렬에 요약되어 있다는 것을 알았습니다. 이제 이러한 그래프를 표현하고 시각화할 수 있는 모든 요소를 갖췄습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, 가장 간단한 경우인 무방향 그래프로 시작해 보겠습니다:\n\n```js\nG = nx.Graph()\nG.add_nodes_from([\n  (1, {\"feature\": 1, \"label\": 1}),\n  (2, {\"feature\": 2, \"label\": 2}),\n  (3, {\"feature\": 2, \"label\": 3}),\n  (4, {\"feature\": 1, \"label\": 4})\n]) \nG.add_edges_from([(2, 1), (1, 4), (4, 2), (4,3)])\n# 그래프 그리기\nnx.draw(G, with_labels = True)\nA = nx.adjacency_matrix(G)\nprint(A.todense())\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_10.png\" /\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_11.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다이렉트 그래프는 다양한 응용 분야에서 사용됩니다. 소셜 네트워크(예: A가 B에게 돈을 빌려줌), 전기 회로, 프로젝트 일정, 운송 등등.\n\n화살표는 일반적으로 관계의 방향을 나타내는 데 사용됩니다. 보시다시피 행렬도 다릅니다. 기술적으로 들어오는 간선과 나가는 간선을 나타내기 위해 두 개의 다른 행렬을 가져야합니다. 일반적으로, 우리는 나가는 간선을 나타내는 것을 사용합니다. 예를 들어, 여기서 간선을 시작하는 노드 1이 있고 이를 노드 4에 연결하는 간선이 있다면, 행렬에서 이 연결을 1로 나타냈습니다(위치는 1행 4열).\n\n```python\nG = nx.DiGraph()\nG.add_nodes_from([\n  (1, {\"feature\": 1, \"label\": 1}),\n  (2, {\"feature\": 2, \"label\": 2}),\n  (3, {\"feature\": 2, \"label\": 3}),\n  (4, {\"feature\": 1, \"label\": 4})\n]) \nG.add_edges_from([(2, 1), (1, 4), (4, 2), (4,3)])\n# 그래프 그리기\nA = nx.adjacency_matrix(G)\nprint(A.todense())\nnx.draw(G, with_labels = True)\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_12.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![그래프](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_13.png)\n\n앞서 언급했듯이 가중 그래프를 사용하는 경우가 있습니다. 예를 들어, 2D 매트릭스 게임, 그래프에 제약 조건을 적용해야 하는 경우 (제품 설계, 회로 설계). 또한 가중 그래프는 우선 순위 흐름을 지정하는 의존성 그래프와 같이 가중할 수도 있습니다.\n\n```js\nG = nx.Graph()\nG.add_nodes_from([\n  (1, {\"feature\": 1, \"label\": 1}),\n  (2, {\"feature\": 2, \"label\": 2}),\n  (3, {\"feature\": 2, \"label\": 3}),\n  (4, {\"feature\": 1, \"label\": 4})\n]) \nG.add_edges_from([(2, 1, {\"weight\": 0.5}),\n                  (1, 4, {\"weight\": 4}), \n                  (4, 2, {\"weight\": 0.5}), \n                  (4,3,  {\"weight\": 1})])\n# 그래프 그리기\n# 노드\npos = nx.spring_layout(G, seed=7) \nA = nx.adjacency_matrix(G)\nprint(A.todense())\nnx.draw_networkx_nodes(G, pos, node_size=50)\nwidth = []\nfor node1, node2, data in G.edges(data=True):\n    width.append(data['weight'])\nnx.draw_networkx_edges(G, pos,  width =width)\n```\n\n![그래프](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_14.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_15.png)\n\n지금까지 우리는 자체 루프(노드가 자기 자신과 연결될 때)가 없다고 결론 지었습니다. 그러나 화학, 유전학, 게임, 대기 이론 등에서 유용한 경우도 있습니다. 이전에 대각선에 1이 없었는데 이제 있습니다(노드가 실제로 자기 자신과 연결되어 있음을 볼 수 있습니다).\n\n```js\nG = nx.Graph()\nG.add_nodes_from([\n  (1, {\"feature\": 1, \"label\": 1}),\n  (2, {\"feature\": 2, \"label\": 2}),\n  (3, {\"feature\": 2, \"label\": 3}),\n  (4, {\"feature\": 1, \"label\": 4})\n]) \nG.add_edges_from([(2, 1), (1, 4), (4, 2), (4, 3), (4, 4), (2, 2)])\n# 그래프를 그립니다.\nA = nx.adjacency_matrix(G)\nprint(A.todense())\nnx.draw(G, with_labels=True)\n```\n\n![image](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_16.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_17.png\" /\u003e\n\n지금까지 각 노드 쌍 간에 하나의 연결만 있을 수 있다고 생각했지만, 이론적으로는 두 노드 사이에 더 많은 링크를 나타내야 할 수도 있습니다. 이 경우, Multigraph가 필요합니다.\n\n```js\nG = nx.MultiGraph()\nG.add_nodes_from([\n  (1, {\"feature\": 1, \"label\": 1}),\n  (2, {\"feature\": 2, \"label\": 2}),\n  (3, {\"feature\": 2, \"label\": 3}),\n  (4, {\"feature\": 1, \"label\": 4})\n]) \nG.add_edges_from([(2, 1), (2, 1), (1, 4), (4, 2), (4,3), (4,3), (4,3)])\nA = nx.adjacency_matrix(G)\nprint(A.todense())\n# Draw the graph\npos = nx.random_layout(G)\nnx.draw_networkx_nodes(G, pos, node_color = 'r', node_size = 100, alpha = 1)\nax = plt.gca()\nfor e in G.edges:\n    ax.annotate(\"\",\n                xy=pos[e[0]], xycoords='data',\n                xytext=pos[e[1]], textcoords='data',\n                arrowprops=dict(arrowstyle=\"-\u003e\", color=\"0.5\",\n                                shrinkA=5, shrinkB=5,\n                                patchA=None, patchB=None,\n                                connectionstyle=\"arc3,rad=rrr\".replace('rrr',str(0.3*e[2])\n                                ),\n                                ),\n                )\nplt.axis('off')\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_18.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_19.png)\n\n양 부분 그래프(또는 이분 그래프)는 그래프 이론에 따르면 그래프의 꼭짓점을 두 가지 서로 다른 및 독립적인 집합으로 나눌 수 있는 그래프이며 각 간선이 꼭짓점을 서로 연결합니다. 양 부분 그래프는 암 검출, 전자 상거래 및 매칭 문제 등에서 사용됩니다.\n\n```js\nB = nx.Graph()\n# 노드 속성 \"bipartite\"를 가진 노드 추가\nB.add_nodes_from([1, 2, 3, 4], bipartite=0)\nB.add_nodes_from([\"a\", \"b\", \"c\"], bipartite=1)\n# 서로 다른 노드 집합 간에만 엣지 추가\nB.add_edges_from([(1, \"a\"), (1, \"b\"), (2, \"b\"), (2, \"c\"), (3, \"c\"), (4, \"a\")])\n# 그룹별로 분리\nl, r = nx.bipartite.sets(B)\npos = {}\n\n# 각 그룹에서 노드를 위한 위치 업데이트\npos.update((node, (1, index)) for index, node in enumerate(l))\npos.update((node, (2, index)) for index, node in enumerate(r))\n\nnx.draw(B, pos=pos)\nplt.show()\n```\n\n![이미지](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_20.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이전 글은 여기에서 찾을 수 있어요. 이 튜토리얼에서 사용된 모든 코드는 여기에서 찾을 수 있어요. 모든 튜토리얼 링크와 코드도 여기에 모아져 있을 거예요.\n\n# 결론\n\n이 튜토리얼에서는 NetworkX를 사용하여 그래프를 생성하고 노드와 엣지를 추가하고 피처를 할당하는 방법을 알아봤어요.\n다양한 종류의 그래프가 있고 NetworkX를 통해 파이썬에서 이를 정의하고 시각화할 수 있다는 것을 보았어요.\n다음 튜토리얼에서는 더 복잡한 경우와 추가적인 기능을 살펴볼 거예요. 또한, 노드를 분류하고, 노드 간 새로운 연결을 예측하거나, 노드를 커뮤니티로 그룹화하는 방법, 그래프 신경망 등을 적용하는 방법에 대해 논의할 거예요. 계속해서 주시길 바래요!\n\n# 이 내용이 흥미로웠다면:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다른 기사를 찾아보거나 LinkedIn에서 저와 연락할 수도 있어요. 매주 업데이트되는 기계 학습 및 인공 지능 뉴스가 포함된 이 저장소를 확인해보세요. 협업과 프로젝트에 열려 있고 LinkedIn을 통해 저에게 연락할 수 있습니다. 새 이야기를 게시할 때 알림을 받고 싶다면 무료로 구독할 수도 있어요.\n\n여기 GitHub 저장소 링크입니다. 기계 학습, 인공 지능 및 기타 관련 자원을 수집하고 있어요.\n\n또는 제 최근 기사 중 하나에 관심이 있을지도 모릅니다:","ogImage":{"url":"/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_0.png"},"coverImage":"/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_0.png","tag":["Tech"],"readingTime":11},{"title":"파이파이 앱을 코딩할 때 고려해야 할 13가지를 배운 것들","description":"","date":"2024-06-20 04:46","slug":"2024-06-20-13ThingsIveLearntToConsiderWhenCodingAFastAPIApp","content":"\n\n대학 시절에는 학교 프로젝트를 위해 쓸만한 한 페이지 FastAPI 백엔드 애플리케이션을 만들 수 있었어요. 솔직히 말해 많은 교수님들이 우리의 프로젝트 코드를 읽지도 않으셨다니까요.\n\n```python\n# 예시: 쓸만한 한 페이지 fastapi 앱\n\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get('/stuff')\ndef get_all():\n    return {'과일': '사과'}\n\nimport uvicorn\nuvicorn.run(app)\n```\n\n^ 우리는 이렇게 코드를 작성해서 가능한 빨리 일을 끝낼 수 있었고, 우리의 백엔드 엔드포인트가 올바른 결과를 반환하기만 하면, 대부분의 경우 우리 코드가 얼마나 잘 작성되었는지는 아무도 신경쓰지 않았어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 현재 대규모 프로덕션급 FastAPI 앱을 개발 중이에요. 만약 제가 이 중 하나라도 하게 된다면, 개발 책임자님에게 혼날 거라고 확신해요. 지난 몇 달 동안 대규모 FastAPI 앱을 만들며 배운 13가지 고려 사항을 소개해드릴게요.\n\n# 1) 타입 어노테이션 (타입 힌트)\n\n이전에 내 코드를 작성했던 방식은 다음과 같아요:\n\n```python\ndef do_stuff(a, b, c):\n    ...\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금 제가 코드를 작성하는 방식은 다음과 같습니다:\n\n```js\nfrom typing import List\n\ndef do_stuff(a: int, b: str, c: List[int]) -\u003e List[str]:\n    ...\n```\n\n여기서 내장 typing 모듈을 사용하여 몇 가지 타입 주석을 추가했습니다:\n\n- a는 정수여야 합니다.\n- b는 문자열이어야 합니다.\n- c는 정수들로 이루어진 리스트여야 합니다.\n- 함수의 반환 값은 문자열들로 이루어진 리스트여야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n노트 — 타입 어노테이션(또는 타입 힌트)은 데이터 타입을 강제하지 않습니다. 그저 제안하는 것뿐입니다. 기술적으로 잘못된 데이터 타입을 전달할 수 있지만, Python은 여전히 허용합니다.\n\n하지만, 타입 어노테이션을 작성하는 것은 내가 의도적으로 하는 선택입니다 — 나는 이것들을 다른 개발자들이 동일한 코드베이스에서 작업할 때 명확하고 이해하기 쉽도록 하기 위해 작성합니다. 이렇게 하면 다른 개발자들이 데이터 타입이 정확히 무엇인지 알아내기 위해 더 많은 시간을 낭비하지 않아도 됩니다.\n\n# 2) 정적 타입 체커를 사용하기\n\n타입 어노테이션은 데이터 타입을 강제하지 않지만, mypy와 같은 정적 타입 체커는 강제합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\ndef add(a: int, b: int) -\u003e int:\n    return a + b\n\nprint(add('hello ', 'world'))\n```\n\n여기서 a와 b는 정수형이어야 하지만 문자열을 전달했습니다.\n\n- 일반적으로 Python은 이를 허용합니다\n- mypy와 같은 정적 형 검사 도구는 허용하지 않습니다\n\n따라서 데이터 유형 위반에 대한 추가적인 보호층으로 정적 유형 검사기를 CICD(지속적 통합 지속적 배포) 파이프라인의 일부로 포함하는 것이 중요하다는 것을 깨달았습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 3) PEP8 및 코드 스타일링\n\n링크: [https://peps.python.org/pep-0008/](https://peps.python.org/pep-0008/)\n\n예전에 코드를 작성할 때 PEP8을 무시했었어요. 그러다가 코드가 금방 지저분하고 못생기게 되는 것을 깨달았죠.\n\nPEP8 문서는 우리에게 Python 코딩 규칙을 제공하여 코드베이스를 일관되고 깔끔하게 유지하는 것이 이상적이라는 것을 알려줍니다. Python에서는 이를 무시할 수 있지만, 당신의 기술 리드는 그렇게 하지 말라고 할지도 몰라요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n내 머릿속에 기억나는 몇 가지 규칙이 있어요:\n\n- 함수 간에는 1줄의 개행을 추가해 주세요, 클래스 간에는 2줄의 개행을 넣어 주세요.\n- 들여쓰기는 탭 대신 공백을 사용해야 합니다.\n- from X import * 는 좋지 않은 습관입니다.\n- import 구문은 어떤 순서로든 정리되어야 합니다.\n- 코드 라인은 79자 이상으로 길어지면 안 됩니다.\n\n파이썬 개발자가 되고 싶다면, PEP8 문서를 한 번은 꼭 살펴보기를 추천해요. 대부분의 코딩 관례를 조금이라도 익히는 데 도움이 될 거예요.\n\n참고 — 때로는 제가 코드를 작성할 때 PEP8 규칙을 무시하기도 하지만, 프로덕션 코드를 작성할 때는 최대한 모든 규칙을 준수하려 노력하고 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 4) 폴더 구조 및 도메인\n\n학교 프로젝트에서는 어디에 .py 파일을 놓느냐에 상관없이 파일을 마구 놓을 수 있지만, 제품용 코드에서는 그렇게 할 수 없습니다.\n\n제품용 코드에서는 모든 사람이 따라야 할 폴더/파일 구조가 있습니다. 각 팀마다 약간씩 다를 수 있지만, 동일한 팀 구성원 모두가 합의해야 할 사항입니다.\n\n\nsrc/\n └── sqlmodels/\n    └── dog.py\n    └── cat.py\n    └── bird.py\n └── dbchanges/\n └── code/\n    └── bin/\n    └── utils/\n    └── web_api/\n        └── domain1\n          └── router.py\n          └── service.py\n          └── models.py\n        └── domain2\n          └── router.py\n          └── service.py\n          └── models.py\n        └── domain3\n          └── router.py\n          └── service.py\n          └── models.py\n └── requirements/\n.gitignore\nREADME.md\ndockerfile\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기는 내 제품용 FastAPI 코드의 매우 간소화된 버전입니다 (실제 폴더 구조는 훨씬 더 큽니다)\n\n참고 - 우리 응용 프로그램의 각 하위 섹션은 독립된 도메인 폴더가 제공됩니다.\n\n.MD 파일을 마크다운 형식으로 변경해주세요. \n\n.py 파일을 마음대로 어디에 둘 수 있고 아무도 신경 쓰지 않는 시절은 지나갔지만, 내가 주장하는 바에 의하면 이것은 좋은 일이라고 생각합니다 - 합의된 폴더 구조는 전체 프로젝트를 더 깔끔하고 유지 관리하기 쉽게 만듭니다.\n\nORM(객체-관계 매핑)을 사용하는 것이란 SQLAlchemy와 같은 것들.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제가 학교 프로젝트에서 FastAPI 앱을 다룬 것을 기억해요:\n\n- 각 엔드포인트마다, 데이터에 접근할 때는 데이터베이스를 직접 호출했어요.\n- MongoDB에서 바로 사전을 받고, 곧바로 반환했어요.\n\n^ 다만 이 방법에는 문제가 있어요 — 앱이 커질수록 굉장히 지저분하고 유지보수하기 어려워져요. 작은 앱이라면 상관없을 수도 있지만, 대규모 앱에서는 어려울 거에요.\n\n크고 복잡한 애플리케이션에서는 SQLAlchemy와 같은 ORM (객체-관계 매핑) 시스템 사용이 좋은 아이디어라고 말할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\n# 데이터베이스를 직접 호출하기\nquery = 'select * from dogs where age \u003c 5'\n\ncursor.execute(query)\ndogs = cursor.fetchall()\n\nprint(dogs)\r\n```\n\n```js\r\n# SQLALchemy 사용하기\nstmt = select(Dog).where(Dog.age\u003c5)\ndogs = session.execute(stmt)\n\nprint(dogs)\r\n```\n\nORM은 우리 데이터베이스를 감싼 래퍼인데, 시작하는 데는 학습 곡선이 있을 수 있어요. 하지만 거대한 응용프로그램에는 구조가 필요하다는 걸 기억해봐요.\n\n만약 FastAPI 앱에서 수천 개의 문자열 SQL 쿼리를 처리해야 한다면 상황은 좀 체증스러울 거에요 (코드베이스와 정신 건강 모두 말이에요)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 6) 엔드포인트에 대한 입력 및 출력 정의\n\n나는 예전에 이렇게 엔드포인트를 작성했어요:\n\n```js\n# 나쁜 코드\n\n@app.get('/dogs')\ndef all_dogs():\n    return get_all_dogs()\n\n@app.get('/dogs/{id}')\ndef one_dog(id):\n    return get_dog(id)\n```\n\n^ 정확한 입력 및 출력 구조가 정의되지 않았어요. 문제점:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 다른 개발자들이 입력과 출력이 무엇인지 추측하는 데 시간을 낭비할 필요가 없어집니다\n- 미래에는 아마도 당신이 입력과 출력이 무엇인지 추측하는 데 시간을 낭비할 수도 있습니다\n\n결국 이렇게 코드를 작성하는 것을 배웠어요:\n\n```js\n# 덜 나쁜 코드\n\n@app.get(\n    '/dogs', \n    response_model=List[Dog],\n    name='모든 개 가져오기'\n)\ndef all_dogs() -\u003e List[Dog]:\n    return get_all_dogs()\n\n@app.get(\n    '/dogs/{id}',\n    response_model=DogWithMoreInfo,\n    name='아이디로 한 마리 개 가져오기'\n)\ndef one_dog(id: int) -\u003e Dog:\n    return get_dog(id)\n```\n\n^ 여기서 type 어노테이션을 사용하고 app.get() 내부의 response_model 키워드 인수를 사용하여 각 엔드포인트의 입력과 출력이 무엇이어야 하는지 훨씬 명확하게 만들었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 7) 모델 간의 관계\n\n우리에게는 사람과 개가 있고, 한 사람이 여러 마리의 개를 소유할 수 있다고 가정해 봅시다.\n\n모델 간의 관계를 사용하기 전에, 다음은 우리의 Dog 모델이 어떻게 보일지에 대한 예시입니다:\n\n```js\n// dog\n{\n    \"name\": \"rocky\",\n    \"age\": 3,\n    \"owner_id\": 1\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기술적으로 우리는 이렇게 작성할 수 있어요:\n\n```js\n// dog\n{\n    \"name\": \"rocky\",\n    \"age\": 3,\n    \"owner_id\": 1,\n    \"owner\": {\n        \"name\": \"tom\",\n        \"age\": 30,\n        \"job\": \"teacher\"\n    }\n}\n```\n\n하지만 특히 수백 개의 API 엔드포인트를 다루고 있다면 이것이 지루할 수 있어요.\n\n대신, SQLModels 관계를 사용하여 우리의 삶을 더 쉽게 만들 수 있어요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# 매우 간단한 예시\n\nclass Human(HumanBase, table=True):\n    __tablename__ = 'humans'\n\n    dogs: list[\"Dog\"] = Relationship(back_populates='owner')\n\nclass Dog(DogBase, table=True):\n    __tablename__ = 'dogs'\n\n    owner: Human = Relationship(back_populates='dogs')\n```\n\n우리 엔드포인트 코드에서 response_model을 Dog로 설정하면 자동으로 Human 정보도 가져올 수 있습니다:\n\n```js\n{\n    \"name\": \"rocky\",\n    \"age\": 3,\n    \"owner_id\": 1,\n    \"owner\": {\n        \"name\": \"tom\",\n        \"age\": 30,\n        \"job\": \"teacher\"\n    }\n}\n```\n\n그리고 데이터베이스 내의 다른 중요한 관계들도 함께 가져옵니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 8) 접근 제어 및 어떤 API에 누가 접근할 수 있는지\n\n학교 코드에서 기억하는 것은 모든 엔드포인트가 공개적이었다는 것입니다. 우리는 단지 엔드포인트의 입력과 출력이 올바른지에만 주의를 기울렸고, 다른 것들에는 그다지 신경을 쓰지 않았습니다.\n\n그러나 모든 것이 공개적으로 되어 있다는 것은 좋지 않은 실천 방법입니다.\n\n프로덕션 급 코드에서는 다음과 같은 시스템이 필요합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- API 호출을 하는 사용자 식별\n- 해당 사용자가 호출할 수 있는 API 엔드포인트 결정\n\n한 걸음 더 나아가면, 서로 다른 사용자가 볼 수 있는 결과를 제어할 수도 있습니다. 예를 들어:\n\n- 관리자는 모든 것을 볼 수 있음\n- 비관리자는 자신의 이름이 포함된 항목만 볼 수 있음\n\n이를 구현하는 하나의 올바른 방법이 없으므로 시간을 들여 신중하게 생각해보시기 바랍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 9) 로깅\n\n프로덕션급 FastAPI 코드에서는 아마도 독립형 스크립트를 제외하고는 print()를 사용하지 않습니다.\n\n대신 로거를 사용합니다. 로깅의 몇 가지 장점:\n\n- 정보를 캡처하는 방법이 팀 전체에서 표준화됨\n- 여러 로깅 기능이 이미 구현되어 있어 그냥 사용하기만 하면 됨\n- 다양한 로깅 레벨은 애플리케이션을 실행할 때 얼마나 많은 출력을 원하는지 결정하는 데 매우 유용함\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이썬 백엔드/풀스택 개발자가 되고 싶다면, 로깅 라이브러리에 대해 배우거나 적어도 어느 정도는 알아야 합니다. 기억하세요 — 프로덕션급 코드에서는 print()를 많이 사용하지 않아요.\n\n# 10) 예외 처리\n\n여러 해 전에 예외를 처리했던 방법은 다음과 같습니다 (나쁜 방법):\n\n```js\ntry:\n    # 내 코드\nexcept Exception as e:\n    print(e)\n```\n\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프로덕션 수준의 FastAPI 코드베이스에서는 일반적으로 다음을 갖춥니다:\n\n- 상당수의 사용자 정의 예외\n- 이러한 사용자 정의 예외를 저장하기 위한 별도의 폴더\n- 정확히 어떤 예외를 잡고자 하는지 지정하는 보다 복잡한 예외 처리문\n- 단순히 print(e)를 출력하는 것 이상의 작업을 수행하는 예외 및 마지막 문에서 더 복잡한 코드\n\n예를 들어:\n\n```python\ntry:\n    # 어떤 코드\n\nexcept CustomException1 as e:\n    # 특별 처리 코드\n    \n    logger.info(str(e))\n\nexcept CustomException2 as e:\n    # 한 번 다시 시도하는 코드\n\n    logger.info(str(e))\n\nexcept CustomException3 as e:\n    # 이 예외를 기반으로 다른 예외 발생\n\n    raise CustomException4() from e\n\nexcept Exception as e:\n    logger.info(str(e))\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프로덕션 수준의 FastAPI 앱에서는 단순히 Exception as e로 모든 예외를 처리할 수 없습니다.\n\n# 11) 단위 테스트 및 기타 테스트\n\n학교 프로젝트에서는 테스트를 작성할 필요가 없었습니다. 주로 프레젠테이션 이후에는 코드를 더 이상 사용하지 않기 때문입니다.\n\n그러나 프로덕션 수준의 코드베이스에서는 단위 테스트뿐만 아니라 통합 테스트 등이 필수적입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 수십 개의 엔드포인트를 테스트해야 한다면 일종의 자동화된 테스트를 도입할 필요가 있어요.\n- 모든 사람이 테스트를 수작업으로 모든 것을 테스트하면 만족스럽지 않을 거예요.\n\n단위 테스트를 작성하는 것이 지루할 수 있지만, 나는 대규모 코드 베이스에서는 필수적이라는 것을 깨달았어요.\n\n테스트에 익숙하지 않다면 pytest 학습을 시도해 볼 수 있어요.\n\n# 12) 데이터의 업데이트 이력 추적\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n사용자가 데이터를 생성/업데이트/삭제할 때마다 이를 이상적으로는 어떤 종류의 히스토리 테이블에 기록해야 합니다.\n\n예를 들어, 사용자가 PUT 엔드포인트 중 하나를 사용하여 그의 개의 색상을 노란색으로 업데이트하고 이를 데이터베이스에 저장했다고 가정해보겠습니다.\n\n히스토리 테이블 내에서 이 작업을 추적하기 위해 다음과 같이 보일 수 있습니다.\n\n- 우리의 주요 개 데이터가 포함된 dogs 테이블이 있다고 가정해봅시다.\n- dogs 테이블에 있는 각 개에 대해 수행된 모든 변경 사항이 포함된 dog_history 테이블이 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 예시 워크플로우입니다:\n\n- 사용자 A가 자신의 강아지 색상을 노란색으로 업데이트합니다 (강아지 ID=100).\n- 우리는 강아지 테이블을 보통대로 업데이트합니다.\n- 그런 다음 강아지 이력 테이블에 새 항목을 삽입합니다.\n- 새 항목에는 1) 사용자 2) 타임스탬프 3) 변경된 필드 4) 이전 값 5) 새 값이 포함됩니다.\n- 예를 들어, \"사용자 A가 (ID가 100인 강아지)의 색상을 초록에서 노란색으로 변경했습니다.\"\n\n```js\n{\n    user=A, \n    dog_id=100, \n    field_changed='color', \n    old_value='green', \n    new_value='yellow',\n    timestamp=178787878787\n}\n```\n\n^ 이와 같이 사용자의 업데이트 작업을 추적할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 13) 데이터베이스 변경 추적\n\n대규모 프로덕션급 앱에서는 데이터 모델에 변경 사항이 있을 수 있습니다. 이를 데이터베이스에서 (테이블 수정이 필요한 경우) 변경할 필요가 있을 수 있습니다.\n\n- 일부 테이블에 열 추가가 필요할 수 있습니다.\n- 완전히 새로운 테이블을 추가해야 할 수도 있습니다.\n\n프로덕션급 앱에서는 데이터베이스를 직접 변경하지 않습니다. 여러 이유로 이는 최악의 실천 방법입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 변경 사항은 되돌릴 수 없습니다 — 누군가 변경을 실수하면 되돌릴 수 없어요\n- 변경 사항은 추적할 수 없습니다 — 누군가 변경을 실수하면 누가 그것을 했는지 알 수 없어요\n\n보통, 팀 내 모든 사람들이 데이터베이스에 가하는 모든 변경 사항을 포함하는 전통적인 dbchanges 폴더가 있습니다\n\n- 이 dbchanges 폴더에는 보통 여러 폴더가 포함되어 있습니다.\n- 각 폴더에는 일부 .xml 파일과 .sql 파일이 들어 있습니다. 이것들을 각각 changeset이라고 합니다.\n- 우리가 changeset을 실행하면 그 안에 있는 변경 사항이 데이터베이스에 적용됩니다.\n- 만약 changeset이 실수라면 데이터베이스가 손상되지 않도록 롤백을 수행할 수 있습니다.\n\n# 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이해하기 쉽고 명확했기를 바랍니다.\n\n# 만약 나를 창작자로 지원하고 싶다면\n\n- 내 책을 구매해 주세요! — 파이썬에 대해 알지 못했던 101가지\n- 어디에서 찾을 수 있는지: https://payhip.com/b/vywcf\n- 해당 이야기에 50번의 박수를 쳐 주세요\n- 당신의 생각을 말해 주는 댓글을 남겨주세요\n- 이야기 중 가장 마음에 드는 부분을 강조해 주세요\n\n감사합니다! 이 작은 행동들은 큰 도움이 되며 정말 감사드립니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nYouTube: [https://www.youtube.com/@zlliu246](https://www.youtube.com/@zlliu246)  \n\nLinkedIn: [https://www.linkedin.com/in/zlliu/](https://www.linkedin.com/in/zlliu/)  ","ogImage":{"url":"/assets/img/2024-06-20-13ThingsIveLearntToConsiderWhenCodingAFastAPIApp_0.png"},"coverImage":"/assets/img/2024-06-20-13ThingsIveLearntToConsiderWhenCodingAFastAPIApp_0.png","tag":["Tech"],"readingTime":11},{"title":"잡음 저항 칼만 필터 이동 평균KMA 대 단순 이동 평균SMA 교차 알고 트레이딩 전략 BAC 쇼케이스","description":"","date":"2024-06-20 04:43","slug":"2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase","content":"\n\n- 대부분의 기술적거래지표(TTI)는 과거 주식 데이터에서 유래되며 미래 가격 흐름 반전을 예측하고 거래 결정을 내리는 데 거래자들에 의해 사용됩니다.\n- 금융 시장 예측은 시간에 따라 변하는 시장 소음 수준이 뒤틀리는 기본 트렌드와 계절적 주기의 이미지를 왜곡하기 때문에 매우 어려운 작업임이 널리 인정되고 있습니다.\n- 알고트레이딩에서 기술적 분석은 항상 패턴 및 신호를 식별하는 데 의존하지만 때로는 신뢰성 없는 것이 있을 수 있습니다. (신호/소음)`1.\n- 실제로, 가짜 가격 변동 및 오작동이 잘못된 TTI 신호를 초래하여 리스크-수익 최적화를 감소시키고 좋지 않은 거래 전략을 야기할 수 있습니다.\n- 본 게시물에서는 불확실하고 정확하지 않은 시계열 데이터에 기초한 숨겨진 변수의 소음이 적절한 확률 추정을 제공하는 칼만 필터(KF)를 사용하여 TTI의 상기한 단점을 다룰 것입니다.\n- KF는 선형 가우시안 상태 공간 모델에서 이론적으로 최적인 것으로 알려져 있으며, 추정된 오차 공분산을 최소화함으로써 베이지안 예측 및 수정의 최적의 재귀적 구현이라고 할 수 있습니다. \n- 여기서, 우리의 목적은 짧은 윈도우 칼만 필터 이동 평균(KMA)를 도입하여 SMA 크로스오버 거래 전략의 극심한 소음 민감성을 줄이는 것입니다.\n- 사례 예시로, BAC 주식의 예상 수익율을 비교하여 KMA, SMA 크로스오버 및 매수 \u0026 보유 알고트레이딩 전략의 백테스트 분석을 수행할 것입니다.\n- 비즈니스적인 측면에서, 제안된 연구는 계속되는 알고트레이딩 SaaS R\u0026D 노력을 촉진하여 BAC에 대한 거래 봇 및 백테스팅 결과를 업데이트합니다. 이러한 노력은 은행이 대량의 핀테크 데이터를 분석하고 신속하게 거래를 실행하여 이윤을 극대화하고 인적 오류를 최소화합니다.\n\n우리의 접근 방식을 구체적으로 살펴보겠습니다.\n\n## 기본 Imports 및 설정\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 현재 작업 디렉토리를 YOURPATH로 설정하기\n\n```python\nimport os\nos.chdir('YOURPATH')    # 작업 디렉토리 설정\nos.getcwd()\n```\n\n- Python 라이브러리 가져오고 설치하기\n\n```python\n!pip install yfinance, pykalman\n\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport requests\nimport math\nfrom termcolor import colored as cl \nimport numpy as np\nimport yfinance as yf\nimport matplotlib.pyplot as plt\nfrom pykalman import KalmanFilter\n\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = (12, 6)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 주식 데이터 입력 읽기\n\n- 야후 파이낸스에서 BAC의 과거 데이터 가져오기\n\n```js\ndata = yf.download('BAC', start='2023-01-01', end='2024-06-01')\n\ndf=data.drop(columns=['Open', 'High','Low','Adj Close','Volume'])\ndf.tail()\n\n           Close\nDate \n2024-05-24 39.700001\n2024-05-28 39.320000\n2024-05-29 38.720001\n2024-05-30 38.630001\n2024-05-31 39.990002\n```\n\n## KMA vs SMA40\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 파이칼만(pykalman)을 사용한 KF 구현 및 SMA40 계산하기\n\n```python\nkf = KalmanFilter(\n    transition_matrices=[1],\n    observation_matrices=[1],\n    initial_state_mean=0,\n    initial_state_covariance=1,\n    observation_covariance=1,\n    transition_covariance=0.01\n)\n\nstate_means, _ = kf.filter(df['Close'].values)\nstate_means = pd.Series(state_means.flatten(), index=df.index)\ndf['kma'] = state_means\ndf['sma'] = df['Close'].rolling(window=40).mean()\n\ndf.tail()\n\n           Close     kma       sma\nDate   \n2024-05-24 39.700001 38.568957 37.64750\n2024-05-28 39.320000 38.640400 37.69250\n2024-05-29 38.720001 38.647972 37.72800\n2024-05-30 38.630001 38.646262 37.75775\n2024-05-31 39.990002 38.774086 37.83450\n```\n\n- 여기에서 KF에 대해 더 알아보기.\n- KMA vs SMA40 그래프 그리기\n\n```python\nplt.figure(figsize=(12,6))\nplt.plot(df['Close'], label='BAC', linewidth=5, alpha=0.3)\nplt.plot(df['kma'], label='KMA')\nplt.plot(df['sma'], label='SMA40')\nplt.title('BAC KMA/SMA')\nplt.xlabel('Date')\nplt.ylabel('Close Price USD')\nplt.legend(loc='upper left')\nplt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_1.png\" /\u003e\n\n## KMA vs SMA20\n\n- KMA와 20일 이동평균(SMA)을 비교\n\n```js\nmean30 = df['Close'].rolling(window=20).mean()\n\n#plt.figure(figsize=(12,6))\nplt.plot(state_means)\nplt.plot(df['Close'])\nplt.plot(mean30)\nplt.title('Kalman filter estimate of average', fontsize=20)\nplt.legend(['Kalman', 'Price', '20-day MA'], fontsize=20)\nplt.xlabel('Date')\nplt.ylabel('Close Price USD')\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_2.png)\n\n## KMA-SMA40 Trading Strategy\n\n- `implement_sma_strategy` 함수를 사용하여 KMA-SMA40 트레이딩 전략 구현하기\n\n```python\ndef implement_sma_strategy(data, short_window, long_window):\n    sma1 = short_window\n    sma2 = long_window\n    buy_price = []\n    sell_price = []\n    sma_signal = []\n    signal = 0\n    \n    for i in range(len(data)):\n        if sma1.iloc[i] \u003e sma2.iloc[i]:\n            if signal != 1:\n                buy_price.append(data.iloc[i])\n                sell_price.append(np.nan)\n                signal = 1\n                sma_signal.append(signal)\n            else:\n                buy_price.append(np.nan)\n                sell_price.append(np.nan)\n                sma_signal.append(0)\n        elif sma2.iloc[i] \u003e sma1.iloc[i]:\n            if signal != -1:\n                buy_price.append(np.nan)\n                sell_price.append(data.iloc[i])\n                signal = -1\n                sma_signal.append(-1)\n            else:\n                buy_price.append(np.nan)\n                sell_price.append(np.nan)\n                sma_signal.append(0)\n        else:\n            buy_price.append(np.nan)\n            sell_price.append(np.nan)\n            sma_signal.append(0)\n            \n    return buy_price, sell_price, sma_signal\n\nsma_20 = df['kma']\nsma_50 = df['sma']\n\nbuy_price, sell_price, signal = implement_sma_strategy(df['Close'], sma_20, sma_50)\n```\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 우리 Position 생성하기\n\n```js\nposition = []\nfor i in range(len(signal)):\n    if signal[i] \u003e 1:\n        position.append(0)\n    else:\n        position.append(1)\n        \nfor i in range(len(df['Close'])):\n    if signal[i] == 1:\n        position[i] = 1\n    elif signal[i] == -1:\n        position[i] = 0\n    else:\n        position[i] = position[i-1]\n\nsma_20 = pd.DataFrame(sma_20).rename(columns = {0:'sma_20'})\nsma_50 = pd.DataFrame(sma_50).rename(columns = {0:'sma_50'}) \nsignal = pd.DataFrame(signal).rename(columns = {0:'sma_signal'}).set_index(df.index)\nposition = pd.DataFrame(position).rename(columns = {0:'sma_position'}).set_index(df.index)\n\nframes = [sma_20, sma_50, signal, position]\nstrategy = pd.concat(frames, join = 'inner', axis = 1)\nstrategy = strategy.reset_index().drop('Date', axis = 1)\n\ndf_ret = pd.DataFrame(np.diff(df['Close'])).rename(columns = {0:'returns'})\nsma_strategy_ret = []\n\nfor i in range(len(df_ret)):\n    try:\n        returns = df_ret['returns'][i]*strategy['sma_position'][i]\n        sma_strategy_ret.append(returns)\n    except:\n        pass\n    \nsma_strategy_ret_df = pd.DataFrame(sma_strategy_ret).rename(columns = {0:'sma_returns'})\n```\n\n- BAC KMA/SMA 트레이딩 신호 플로팅\n\n```js\nplt.plot(df['Close'], alpha = 0.3, label = 'BAC')\nplt.plot(sma_20, alpha = 0.6, label = 'KMA')\nplt.plot(sma_50, alpha = 0.6, label = 'SMA40')\nplt.scatter(df.index, buy_price, marker = '^', s = 200, color = 'darkblue', label = '매수 신호')\nplt.scatter(df.index, sell_price, marker = 'v', s = 200, color = 'crimson', label = '매도 신호')\nplt.legend(loc = 'lower right')\nplt.xlabel('날짜')\nplt.ylabel('종가 USD')\nplt.title('BAC KMA/SMA 트레이딩 신호')\nplt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_3.png)\n\n- 저희 전략의 백테스팅을 수행 중입니다.\n\n```python\nimport math\nfrom termcolor import colored as cl\n투자금 = 100000\n주식수 = math.floor(투자금 / df['Close'].iloc[1])\nsma_투자_수익 = []\n\nfor i in range(len(sma_strategy_ret_df['sma_returns'])):\n    수익 = 주식수 * sma_strategy_ret_df['sma_returns'].iloc[i]\n    sma_투자_수익.append(수익)\n\nsma_투자_수익_df = pd.DataFrame(sma_투자_수익).rename(columns = {0:'투자_수익'})\n총_투자_수익 = round(sum(sma_투자_수익_df['투자_수익']), 2)\nprint(cl('BAC에 10만 달러를 투자하여 전략으로 얻은 이익: ${}'.format(총_투자_수익), attrs = ['bold']))\n\nBAC에 10만 달러를 투자하여 전략으로 얻은 이익: $29026.39\n```\n\n## SMA 20–50 트레이딩 전략\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 표준 SMA 20-50 거래 전략 구현\n\n```python\ndef sma(data, n):\n    sma = data.rolling(window=n).mean()\n    return pd.DataFrame(sma)\n\nn = [20, 50]\nfor i in n:\n    df[f'sma_{i}'] = sma(df['Close'], i)\n\nClose       sma_20    sma_50         sma_40\nDate    \n2024-05-24 39.700001 38.3415 37.4868 37.64750\n2024-05-28 39.320000 38.4300 37.5650 37.69250\n2024-05-29 38.720001 38.5155 37.6192 37.72800\n2024-05-30 38.630001 38.5995 37.6712 37.75775\n2024-05-31 39.990002 38.7550 37.7360 37.83450\n```\n\n- SMA 20-50 플로팅\n\n```python\nplt.plot(df['Close'], label='BAC', linewidth=5, alpha=0.3)\nplt.plot(df['sma_20'], label='SMA 20')\nplt.plot(df['sma_50'], label='SMA 50')\nplt.title('BAC Simple Moving Averages (20, 50)')\nplt.legend(loc='upper left')\n\nplt.xlabel('Date')\nplt.ylabel('Close Price USD')\nplt.show()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_4.png\" /\u003e\n\n- implement_sma_strategy 함수를 사용하여 BAC SMA (20,50) 거래 신호를 생성합니다.\n\n```js\ndef implement_sma_strategy(data, short_window, long_window):\n    sma1 = short_window\n    sma2 = long_window\n    buy_price = []\n    sell_price = []\n    sma_signal = []\n    signal = 0\n    \n    for i in range(len(data)):\n        if sma1.iloc[i] \u003e sma2.iloc[i]:\n            if signal != 1:\n                buy_price.append(data.iloc[i])\n                sell_price.append(np.nan)\n                signal = 1\n                sma_signal.append(signal)\n            else:\n                buy_price.append(np.nan)\n                sell_price.append(np.nan)\n                sma_signal.append(0)\n        elif sma2.iloc[i] \u003e sma1.iloc[i]:\n            if signal != -1:\n                buy_price.append(np.nan)\n                sell_price.append(data.iloc[i])\n                signal = -1\n                sma_signal.append(-1)\n            else:\n                buy_price.append(np.nan)\n                sell_price.append(np.nan)\n                sma_signal.append(0)\n        else:\n            buy_price.append(np.nan)\n            sell_price.append(np.nan)\n            sma_signal.append(0)\n            \n    return buy_price, sell_price, sma_signal\n\nsma_20 = df['sma_20']\nsma_50 = df['sma_50']\n\nbuy_price, sell_price, signal = implement_sma_strategy(df['Close'], sma_20, sma_50)\n```\n\n- BAC SMA (20,50) 거래 신호를 플로팅합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\nplt.plot(df['Close'], alpha = 0.3, label = 'BAC')\nplt.plot(sma_20, alpha = 0.6, label = 'SMA 20')\nplt.plot(sma_50, alpha = 0.6, label = 'SMA 50')\nplt.scatter(df.index, buy_price, marker = '^', s = 200, color = 'darkblue', label = 'BUY SIGNAL')\nplt.scatter(df.index, sell_price, marker = 'v', s = 200, color = 'crimson', label = 'SELL SIGNAL')\nplt.legend(loc = 'upper left')\nplt.title('BAC SMA CROSSOVER TRADING SIGNALS')\nplt.xlabel('Date')\nplt.ylabel('Close Price USD')\nplt.show()\r\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_5.png\" /\u003e\n\n- 포지션 생성\n\n```js\r\nposition = []\nfor i in range(len(signal)):\n    if signal[i] \u003e 1:\n        position.append(0)\n    else:\n        position.append(1)\n        \nfor i in range(len(df['Close'])):\n    if signal[i] == 1:\n        position[i] = 1\n    elif signal[i] == -1:\n        position[i] = 0\n    else:\n        position[i] = position[i-1]\n\nsma_20 = pd.DataFrame(sma_20).rename(columns = {0:'sma_20'})\nsma_50 = pd.DataFrame(sma_50).rename(columns = {0:'sma_50'}) \nsignal = pd.DataFrame(signal).rename(columns = {0:'sma_signal'}).set_index(df.index)\nposition = pd.DataFrame(position).rename(columns = {0:'sma_position'}).set_index(df.index)\n\nframes = [sma_20, sma_50, signal, position]\nstrategy = pd.concat(frames, join = 'inner', axis = 1)\nstrategy = strategy.reset_index().drop('Date', axis = 1)\r\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 우리 전략의 백테스팅을 수행중입니다\n\n```js\nmsft_ret = pd.DataFrame(np.diff(df['Close'])).rename(columns = {0:'returns'})\nsma_strategy_ret = []\n\nfor i in range(len(msft_ret)):\n    try:\n        returns = msft_ret['returns'].iloc[i]*strategy['sma_position'].iloc[i]\n        sma_strategy_ret.append(returns)\n    except:\n        pass\n\nsma_strategy_ret_df = pd.DataFrame(sma_strategy_ret).rename(columns = {0:'sma_returns'})\n\ninvestment_value = 100000\nnumber_of_stocks = math.floor(investment_value/df['Close'].iloc[1])\nsma_investment_ret = []\n\nfor i in range(len(sma_strategy_ret_df['sma_returns'])):\n    returns = number_of_stocks*sma_strategy_ret_df['sma_returns'].iloc[i]\n    sma_investment_ret.append(returns)\n\nsma_investment_ret_df = pd.DataFrame(sma_investment_ret).rename(columns = {0:'investment_returns'})\ntotal_investment_ret = round(sum(sma_investment_ret_df['investment_returns']), 2)\nprint(cl('장기 배당 수익 전략에 $100K 투자로 얻은 이익: ${}'.format(total_investment_ret), attrs = ['bold']))\n\n장기 배당 수익 전략에 $100K 투자로 얻은 이익: $13473.41\n```\n\n## 수동 매수 \u0026 보유 전략\n\n- 일일 수익에 기반한 누적 수익률 계산 중\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndf['daily_return'] = df['Close'].pct_change()\n# 누적 수익률 계산\ndf['cum_return'] = np.exp(np.log1p(df['daily_return']).cumsum())\n\n투자금 = 100000\n수익률=(df['cum_return'].iloc[-1]-1)*투자금\nprint(round(수익률,2))\n19337.52\n\n수익=round(수익률,2)\nprint(cl('BAC에 10만 달러를 투자하여 Buy \u0026 Hold 전략에서 얻은 수익: ${} '.format(수익), attrs = ['bold']))\n\nBAC에 10만 달러를 투자하여 Buy \u0026 Hold 전략에서 얻은 수익: $19337.52 \n```\n\n- 결과 그래프 그리기\n\n```js\ndf['cum_return'].plot()\nplt.title('BAC Buy-Hold 누적 수익률')\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_6.png\" /\u003e\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 결론\n\n- 2023년 1월 3일부터 2024년 5월 31일까지의 백테스트 결과를 기반으로, KMA 알고 트레이딩 전략은 SMA 크로스오버 및 Buy \u0026 Hold 전략에 비해 매우 유망한 성과를 보여주었습니다.\n\n```js\nBAC에 10만 달러를 투자하여 KMA 전략으로 얻은 이익 : $29026.39\n\nBAC에 10만 달러를 투자하여 Buy \u0026 Hold 전략으로 얻은 이익 : $19337.52\n\nBAC에 10만 달러를 투자하여 SMA 크로스오버 전략으로 얻은 이익 : $13473.41\n```\n\n![이미지](/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_7.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 우리는 KF가 TTI의 제한을 극복하고 algo-trading 전략의 성능을 향상시킬 수 있다는 것을 보여줬어요.\n- 비선형 시스템, 이상치 및 잡음을 효율적이고 견고하게 처리하면서 동시에 최적 부드량화와 자동 매개변수 추정이 가능한 KF 프레임워크는 모든 KF 수정사항과 이점을 함께 포함할 수 있게 해 줄 거에요.\n\n## 전체 Python 코드 및 입출력\n\n```js\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport yfinance as yf\nfrom pandas_datareader import data as web\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nfrom datetime import datetime as dt, timedelta as td\nfrom pykalman import KalmanFilter\nsns.set()\n\ndata = yf.download('BAC', start='2023-01-01', end='2024-06-01')\n\ndf=data.drop(columns=['Open', 'High','Low','Adj Close','Volume'])\ndf.tail()\n\nClose\nDate \n2024-05-24 39.700001\n2024-05-28 39.320000\n2024-05-29 38.720001\n2024-05-30 38.630001\n2024-05-31 39.990002\n\nimport matplotlib.pyplot as plt \nimport requests\nimport math\nfrom termcolor import colored as cl \n\nfrom pykalman import KalmanFilter\n\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = (15, 8)\n\nkf = KalmanFilter(\n    transition_matrices = [1],\n    observation_matrices = [1],\n    initial_state_mean = 0,\n    initial_state_covariance = 1,\n    observation_covariance=1,\n    transition_covariance=0.01\n)\nstate_means, _ = kf.filter(df.values)\nstate_means = pd.Series(state_means.flatten(), index=df.index)\n\n...\n\nprint(signal)\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, ...\n\nposition = []\nfor i in range(len(signal)):\n    if signal[i] \u003e 1:\n        position.append(0)\n    else:\n        position.append(1)\n        \nfor i in range(len(df['Close'])):\n    if signal[i] == 1:\n        position[i] = 1\n    elif signal[i] == -1:\n        position[i] = 0\n    else:\n        position[i] = position[i-1]\n\nsma_20 = pd.DataFrame(sma_20).rename(columns = {0:'sma_20'})\nsma_50 = pd.DataFrame(sma_50).rename(columns = {0:'sma_50'}) \nsignal = pd.DataFrame(signal).rename(columns = {0:'sma_signal'}).set_index(df.index)\nposition = pd.DataFrame(position).rename(columns = {0:'sma_position'}).set_index(df.index)\n\n...\n\nprint(cl('100K달러를 BAC에 투자하여 전략으로 얻은 이익 : ${}'.format(total_investment_ret), attrs = ['bold']))\n\n100K달러를 BAC에 투자하여 전략으로 얻은 이익 : $13473.41\r\n```\n\n## 더 알아보기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 신호/잡음 비율이 낮은 칼만 필터 기반 객체 추적\n- 칼만 필터를 사용한 대상 궤적 추적 성능 QC 분석\n- 견고한 1차원 칼만 필터의 해부학\n- 칼만 필터를 사용한 주식 시장 변동성 예측\n\n## 참고 자료\n\n- 파이썬에서 SMA를 이용한 알고리즘 트레이딩\n- 금융 분야에서의 칼만 필터 (KF)\n- 칼만 필터를 기반으로 한 트레이딩 전략 구현\n- 파이썬에서 칼만 필터, 칼만 스무서, EM 알고리즘 구현\n- 칼만 필터를 활용한 주식 거래 마스터하기: 포괄적인 가이드\n- 파이썬에서 주식 가격 예측을 위한 칼만 필터 사용\n- 주식 거래에서의 칼만 필터\n- 시장 탁계를 탐색하는 주식 분석에서의 칼만 필터\n\n## 연락처\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 웹사이트\n- GitHub\n- X/트위터\n- 핀터레스트\n- 마스토돈\n- 텀블러","ogImage":{"url":"/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_0.png"},"coverImage":"/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_0.png","tag":["Tech"],"readingTime":17},{"title":"오디오 데이터에 대한 대화형 감정 분석","description":"","date":"2024-06-20 04:41","slug":"2024-06-20-ConversationalSentimentAnalysisonAudioData","content":"\n\n\u003cimg src=\"/assets/img/2024-06-20-ConversationalSentimentAnalysisonAudioData_0.png\" /\u003e\n\n감성 분석 또는 의견 분석은 자연어 처리(NLP)에서 널리 사용되는 작업입니다. NLP 기술을 텍스트 데이터에 특히 적용하는 맥락에서, 주요 목표는 주어진 텍스트를 다양한 감성 클래스에 분류할 수 있는 모델을 훈련하는 것입니다. 감성 분류기의 고수준 개요는 아래 이미지에 나와 있습니다.\n\n\u003cimg src=\"/assets/img/2024-06-20-ConversationalSentimentAnalysisonAudioData_1.png\" /\u003e\n\n예를 들어, 세 가지 클래스 분류 문제의 클래스는 긍정적, 부정적 및 중립일 수 있습니다. 세 가지 클래스의 감성 분석 문제의 예는 인기 있는 Twitter 감성 분석 데이터 세트입니다. 이 데이터는 트위터 사용자들이 게시한 다국어 트윗에 대한 Entity-level 감성 분석 작업입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n과거의 자연어처리(NLP) 연구 및 개발 대부분은 주로 텍스트에 감성 분석을 적용하는 데 중점을 두었습니다. 그러나 최근에는 사용자들 사이에서 음성 기반 상호 작용 도구의 대규모 채택과 인기를 볼 수 있었으며, 이는 연구자들과 기관들을 음성 영역에서 감성 분류기를 구축하도록 이끕니다.\n\n따라서 이 게시물에서는 AssemblyAI API와 Python을 사용하여 대화 데이터에 감성 분석 시스템을 구축하는 방법을 보여줄 것입니다. 이 종단 간 시스템은 엄격한 고객 지원 및 피드백 평가와 관련이 있는 영역에서 광범위한 적용 가능성을 지니며, 특히 음성 도메인에서 중요하고 가치 있는 문제를 해결하는 데 도움이 됩니다. 마지막으로 얻은 결과물을 이해하기 쉽게 향상시키고 데이터에서 적절한 통찰을 얻기 위한 분석을 보여줄 것입니다.\n\n이 글의 코드는 여기에서 찾을 수 있습니다. 게시물의 주요 내용은 다음과 같습니다:\n\n- 대화형 오디오 데이터에 대한 감성 분석\n- 감성 분석 결과\n- 감성 분석 통찰력\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 대화 오디오 데이터에 대한 감정 분석\n\n이 섹션에서는, 녹음된 음성 대화 조각에서 개별 문장을 세 가지 감정 클래스로 분류하는 AssemblyAI API의 사용을 보여드리겠습니다: 긍정적, 부정적 및 중립적.\n\n![이미지](/assets/img/2024-06-20-ConversationalSentimentAnalysisonAudioData_2.png)\n\n## 단계 1: 요구 사항 설치\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n감정 분류기를 구축하는 데 필요한 요소가 매우 적습니다. Python 라이브러리 관점에서 requests 패키지만 필요합니다. 아래와 같이 수행할 수 있습니다:\n\n```js\npip install requests\n```\n\n## 단계 2: API 토큰 생성\n\n다음 단계는 AssemblyAI 웹사이트에 계정을 생성하는 것입니다. 이 과정은 무료로 진행할 수 있습니다. 계정을 생성하면 프라이빗 API 액세스 키를 받게 되는데, 이것을 사용하여 음성을 텍스트로 변환하는 모델에 접근할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 단계 3: 오디오 파일 업로드\n\n이 튜토리얼의 목적을 위해, 두 사람 간의 미리 녹음된 오디오 대화를 사용하여 감정 분석을 수행하겠습니다. API 키를 획득하셨다면, 미리 녹음된 오디오 파일에 대한 감정 분류 작업을 진행할 수 있습니다.\n\n그러나 그 전에, 오디오 파일을 업로드하여 URL을 통해 액세스할 수 있도록 해야 합니다. AWS S3 버킷에 업로드하거나 SoundCloud 또는 AssemblyAI의 셀프-호스팅 서비스와 같은 오디오 호스팅 서비스에 업로드하는 옵션이 있습니다. 저는 오디오 파일을 SoundCloud에 업로드하여 아래에서 액세스할 수 있도록 했습니다.\n\n만약 AssemblyAI의 호스팅 서비스에 오디오 파일을 직접 업로드하고 싶다면, 그것도 가능합니다. 저는 코드 블록 안에서 이 단계별 절차를 보여드렸습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 단계 3.1: 요구 사항 가져오기\n\n프로젝트에 필요한 요구 사항을 가져오는 것으로 시작합니다.\n\n## 단계 3.2: 파일 위치 및 API 키 지정\n\n다음으로, 로컬 컴퓨터에서 오디오 파일의 위치와 가입 후 얻은 API 키를 지정해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 단계 3.3: 업로드 엔드포인트 지정\n\n- 엔드포인트: 여기서 사용할 서비스인 \"upload\" 서비스를 지정합니다.\n- 헤더: API 키 및 콘텐츠 유형을 보유합니다.\n\n## 단계 3.4: 업로드 함수 정의\n\n오디오 파일은 한 번에 5 MB(5,242,880 바이트)까지만 업로드할 수 있습니다. 따라서 데이터를 청크 단위로 업로드해야 합니다. 이후에 서비스 엔드포인트에서 이들을 합칩니다. 따라서 많은 URL을 처리할 필요가 없어집니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 단계 3.5: 업로드\n\n마지막 단계는 POST 요청을 호출하는 것입니다. POST 요청의 응답은 오디오 파일의 업로드 URL을 보유한 JSON입니다. 이 URL을 사용하여 오디오의 감정 분류를 실행하는 다음 단계에 사용할 것입니다.\n\n## 단계 4: 감정 분석\n\n이제 이 단계에서 오디오 파일에 대해 감정 분석 작업을 수행하기 위한 필요한 모든 전제조건을 충족했습니다. 이제 우리는 API를 호출하여 원하는 결과를 가져오는 것으로 계속할 수 있습니다. 이는 아래 소목록에서 설명되는 2단계 프로세스입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 단계 4.1: 전사용 파일 제출\n\n첫 번째 단계는 HTTP POST 요청을 호출하는 것입니다. 이는 기본으로 실행되는 AI 모델에 오디오 파일을 보내 전사를 위임하고, 전사된 텍스트에 대해 감정 분석을 수행하도록 지시하는 것입니다.\n\nPOST 요청에 전달되는 인수는 다음과 같습니다:\n\n- endpoint: 호출할 전사 서비스를 지정합니다.\n- json: 오디오 파일의 URL을 audio_url 키로 포함합니다. 대화 데이터에 대한 감정 분석을 수행하려면 sentiment_analysis 플래그와 speaker_labels를 True로 설정합니다.\n- headers: 허가 키와 콘텐츠 유형을 보유합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n포스트 요청의 현재 상태는 JSON 응답으로 받았을 때 대기 중인 상태입니다. 이는 현재 오디오가 변환 중임을 나타냅니다.\n\n또한, JSON 응답에서 sentiment_analysis 플래그도 True로 나와 있습니다. 그러나 sentiment_analysis_results 키에 해당하는 값은 상태가 대기 중이기 때문에 None입니다.\n\n## 단계 4.2: 변환 결과 가져오기\n\nPOST 요청의 상태를 확인하려면 위에서 받은 JSON 응답의 id 키를 사용하여 GET 요청을 해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음으로, 아래 코드 블록에 나와 있는 것처럼 GET 요청을 진행할 수 있습니다.\n\nGET 요청에 전달되는 인수는 다음과 같습니다:\n\n- endpoint: 이는 호출된 서비스를 지정하며 id 키를 사용하여 결정된 API 호출 식별자를 나타냅니다.\n- headers: 이는 귀하의 고유한 API 키를 보유합니다.\n\n여기서 중요한 점은 상태 키가 completed로 변경될 때까지 전사 결과가 준비되지 않는다는 것입니다. 전사에 걸리는 시간은 입력 오디오 파일의 길이에 따라 다릅니다. 따라서 전사 상태를 확인하기 위해 규칙적인 간격으로 반복적인 GET 요청을 수행해야 합니다. 이를 위한 간단한 방법을 아래 구현하였습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 감정 분석 결과\n\n일단 상태가 완료로 변경되면 아래와 유사한 응답을 받게 될 것입니다.\n\n- JSON 응답에서의 상태가 완료로 표시됩니다. 이는 오디오 전사에 오류가 없었음을 나타냅니다.\n- 텍스트 키에는 입력 오디오 대화의 전체 전사가 포함되어 있으며, 총 22개 문장이 포함됩니다.\n- 오디오 파일은 여러 화자로 구성되어 있기 때문에, 단어 키 내의 모든 화자 키를 Not Null로 볼 수 있습니다. 화자 키는 \"A\" 또는 \"B\"일 수 있습니다.\n- 모든 개별 단어와 전체 전사 텍스트에 대한 확신 점수를 볼 수 있습니다. 이 점수는 0부터 1까지 범위를 가지며, 0이 가장 낮고 1이 가장 높습니다.\n- 오디오의 각각 22개 문장에 대한 감정 분석 결과는 JSON 응답의 sentiment_analysis_results 키를 사용하여 액세스할 수 있습니다.\n- 각 문장에 대응하여, 4번 항목과 유사한 확신 점수를 얻을 수 있습니다.\n- 각 문장의 감정은 문장 사전의 sentiment 키를 사용하여 검색할 수 있습니다. 두 번째 문장에 대한 감정 분석 결과가 아래에 표시되어 있습니다:\n\n# 감정 분석 인사이트\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nJSON은 보통 읽고 해석하기 어렵습니다. 그래서 데이터를 시각적으로 보기 좋게 만들고 추가 분석을 수행하기 위해 위의 감정 분석 결과를 DataFrame으로 변환합시다. 우리는 문장의 텍스트, 지속 시간, 스피커, 그리고 문장의 감정을 저장할 것입니다. 이를 아래에서 구현하겠습니다:\n\n위 코드 스니펫으로 생성된 DataFrame은 아래 이미지에 표시됩니다. 여기서 대화 중 발화된 22개의 문장과 해당하는 스피커 레이블(\"A\"와 \"B\"), 문장의 지속 시간(초), 그리고 모델이 예측한 문장의 감정이 포함되어 있습니다.\n\n\u003cimg src=\"/assets/img/2024-06-20-ConversationalSentimentAnalysisonAudioData_3.png\" /\u003e\n\n## #1 스피커 분포\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n각 화자가 말한 문장 수는 아래와 같이 value_counts() 메소드를 사용하여 계산할 수 있습니다:\n\n화자들의 백분율 분포를 보려면 다음과 같이 value_counts() 메소드에 normalize = True를 전달할 수 있습니다:\n\n“A”와 “B” 두 화자 모두 문장 수 측면에서 대화에 동등하게 기여했습니다.\n\n## #2 화자 지속 시간 분포\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음으로 대화 참가자 각각의 기여도를 계산해 봅시다. 아래에서 확인할 수 있습니다:\n\ngroupby() 메서드를 사용하여 각 발화자의 발화 시간을 총합하여 계산했습니다. 발화 시간 측면에서 발화자 A가 우세한 발화자입니다.\n\n## #3 감정 분포\n\n대화 중 총 22문장 중 부정 감정으로 분류된 문장은 3개뿐이었습니다. 또한 양의 감정으로 분류된 문장은 없었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n정규화된 분포는 다음과 같이 계산할 수 있습니다:\n\n## 스피커 레벨에서 #4 감정 분포\n\n마지막으로, 개별 스피커 간의 감정 분포를 계산해 봅시다. 여기서는 groupby() 메서드 대신 더 나은 시각화를 위해 crosstab()을 사용할 것입니다. 아래에서 이를 시연합니다:\n\n\"A\" 스피커가 한 부정적 문장의 비율이 \"B\" 스피커보다 더 많았습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## #5 감정 수준별 평균 문장 지속 시간\n\n마지막으로, 우리는 개별 감정 클래스에 속하는 문장의 평균 지속 시간을 계산할 것입니다. 이는 아래의 groupby() 메서드를 사용하여 구현되었습니다:\n\n부정적인 문장의 평균 지속 시간은 중립 문장보다 작습니다.\n\n마무리로, 이 글에서는 AssemblyAI API의 특정 NLP 사용 사례에 대해 논의했습니다. 구체적으로, 여러 화자로 구성된 미리 녹음된 오디오 파일에서 감정 분류 모듈을 구축하는 방법을 살펴보았습니다. 마지막으로, 감정 분석 결과에 대해 철저한 분석을 수행했습니다. API로부터 얻은 결과는 입력 오디오 파일의 22개의 개별 문장의 감정을 강조했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 글의 코드는 여기서 찾을 수 있어요.\n\n다음 게시물에서는 어셈블리 AI API의 더 많은 사용 사례에 대해 논의할 거예요. Entity Detection, Content Moderation 등 기술적, 실용적 관점에서 더 자세하게 다루겠습니다.\n\n다음에 또 봐요. 읽어 주셔서 감사해요.\n\n🚀 매일 뉴스레터를 구독하면 320개 이상의 글이 실린 데이터 과학 PDF(550페이지)를 무료로 받을 수 있어요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003ctable\u003e\n  \u003cimg src=\"https://miro.medium.com/v2/resize:fit:1400/0*QXJuDEr_pCNDtj4D.gif\" /\u003e\n\u003c/table\u003e\n\nDDI 중간 게시글 바닥 링크(DDI)\n\nDataDrivenInvestor.com에서 방문하세요\n\nDDIntel을 여기에서 구독하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n주요 기사:\n\n여기서 우리의 창조자 생태계에 참여하세요.\n\nDDI 공식 텔레그램 채널: [https://t.me/+tafUp6ecEys4YjQ1](https://t.me/+tafUp6ecEys4YjQ1)\n\nLinkedIn, Twitter, YouTube, 그리고 Facebook에서 팔로우해보세요.","ogImage":{"url":"/assets/img/2024-06-20-ConversationalSentimentAnalysisonAudioData_0.png"},"coverImage":"/assets/img/2024-06-20-ConversationalSentimentAnalysisonAudioData_0.png","tag":["Tech"],"readingTime":7},{"title":"웹을 당신의 최고 친구 데이터 제공업체로 만들어 보세요","description":"","date":"2024-06-20 04:38","slug":"2024-06-20-MaketheWebyourbestfrienddataprovider","content":"\n\n\u003cimg src=\"/assets/img/2024-06-20-MaketheWebyourbestfrienddataprovider_0.png\" /\u003e\n\nLLM을 도구로 갖추는 아이디어는 그리 새로운 것은 아닙니다. LangChain과 Llamaindex와 같은 강력하고 잘 알려진 프레임워크는 몇 달 전에 이미 이를 실행했습니다.\n\n그들은 위험 부담에 대한 승리했어요!\n\n지금 완전히 열광 중인 AI 에이전트 혁명은 도구 패러다임을 충분히 활용하여 놀라운 결과를 얻고 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n인공지능이 지금 새로운 벽을 맞이했습니다: 계산 요구 사항과 무료로 이용 가능한 데이터의 끝.\n\n이 기사에서는 이러한 도전 과제를 다루고, 우리의 LLM 애플리케이션을 새로운 관련 데이터로 무료로 풍부하게 만드는 방법을 배울 것입니다!\n\n```js\n# 목차\n- 중립적 LLM 방향\n- 검색 보강 생성: 여전히 최고의 도구\n- 웹 검색 및 NLP 뉴스는 도구입니다\n- 단락에서 문서까지\n- 그럼 이제 무엇을 해야 할까요? 직접 문서 저장소 만들기\n```\n\n# 중립적 LLM\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기술 발전은 이미 지난 해의 많은 작업을 이미 완료했습니다. 새로운 하드웨어와 GPU 세트는 이제 더 빠르고 저렴하게 복잡한 신경망 계산을 처리할 수 있습니다.\n\n동시에 엣지-모바일 기기로의 명확한 이동이 있으며, 작은 언어 모델이 큰 모델과 경쟁할 수 있도록 하는 데 특별한 주의를 기울이고 있습니다. TinyLlama 프로젝트를 시작으로 목표는 모바일 전화 하드웨어에서 실행할만큼 충분히 작지만 환각하지 않고 유용한 모델을 만드는 것입니다.\n\n규모 법칙 이상으로, 우리는 LLM이 추상화하고 이성적으로 추론하는 능력을 잃는 한계를 이해해야 합니다. 데이터 없이 신경망을 구축할 수 없지만 동시에 우리는 새로운 위키피디아를 만들고 있지는 않습니다, 맞죠?\n\nAI 커뮤니티에서 진정한 권위자인 Cobus Greyling은 항상 이것을 강조합니다: 데이터 처리 및 데이터 처리를 LLM 응용 프로그램에서 분리하세요. 그에게는 LLM 응용 프로그램은 모델에 중립적이어야 하며 LLM을 유틸리티로 취급해야 한다 - 그러나 이는 신뢰할 수 있는 데이터, 좋은 소식 및 선별된 데이터 집합에 대해 작업해야 한다는 것을 의미합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우수한 데이터를 이용하면 작은 모델(20억 파라미터 미만)이 탁월한 성과를 거둘 수 있어요!\n\n![image](/assets/img/2024-06-20-MaketheWebyourbestfrienddataprovider_1.png)\n\n## 검색 증강 생성: 여전히 최고의 도구\n\n좋은 말들이지만, 이를 어떻게 구현할까요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRetrieval Augmented Generation (RAG)은 생성된 텍스트의 품질을 향상시키기 위해 자연어 처리에서 사용되는 기술입니다.\n\n마술은 없어요! 우리는 대규모 외부 지식 원본(데이터베이스나 문서 코퍼스 등)에서 관련 정보를 통합하여 LLM 프롬프트에 적용합니다. RAG에서는 쿼리나 프롬프트에 대한 응답을 생성할 때 모델이 매우 좋은 작업을 합니다:\n\n- 먼저 검색 메커니즘을 사용해 외부 지식 원본에서 관련 정보를 검색합니다.\n- 검색된 정보는 그 후 생성 모델로 투입되어 자신의 지식을 보완하고\n- 보다 정확하고 유익한 응답을 생성합니다.\n\n예를 들어, 특정 역사적 사건에 대한 질문을 하는 경우 RAG 모델은 먼저 역사 문서의 대규모 데이터베이스에서 해당 사건에 대한 정보를 검색하고, 그 정보를 사용하여 귀하의 질문에 대한 세부적이고 정확한 응답을 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG은 순수 생성 모델과 구체적인 사실 정보에 제한을 받을 수 있는 것을 합하고, 오직 검색 기반 모델과 창의적인 대답을 생성하는 데 어려움을 겪을 수 있는 것을 합하면서 이 둘 간의 간극을 좁히는 데 도움을 줍니다.\n\n그러니까 우리 수학 시간을 시작해 볼까요:\n\n- 좋은 이유를 제공하는 작은 LLM이 주어지면\n- 좋고 최신 정보를 위해 RAG 파이프라인을 설정하면\n\n... 전례 없는 그리고 의미 있는 문서 세트를 만드는 방법이 필요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 웹 검색 및 NLP 뉴스는 도구들입니다\n\n이전 글에서 LangChain을 DuckDuckGo 웹 검색과 함께 사용하는 방법에 대해 설명했었습니다.\n\n최신 뉴스와 업데이트된 정보를 검색 엔진을 사용하여 가져오는 것은 어떤 반 데이터 모형으로 향하는 놀라운 방법입니다. 생성 모델의 마감일 한계가 우리가 필요한 모든 것과 외부 지식을 제공할 수 있기 때문에 우회됩니다.\n\n확인되고 진실한 정보가 있는 경우, 우리의 LLM 응용 프로그램은 좋은 RAG 전략을 사용함으로써보다 효과적 일 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하지만 잘 알려진 웹 검색 도구에도 제한이 있습니다! 무료 Google Colab 노트북을 사용하여 확인해 보세요.\n\n```js\n%pip install --upgrade --quiet langchain langchain-community faiss-cpu \n%pip install tiktoken duckduckgo-search llama-cpp-agent newspaper3k\n```\n\nLangchain과 함께 duckduckgo-search와 newspaper3k(강력한 NLP 웹 HTML 문서 파서)를 설치합니다.\n\n먼저, 웹 검색의 출력이 무엇인지 살펴봅시다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nfrom langchain_community.utilities import DuckDuckGoSearchAPIWrapper\nwrapper = DuckDuckGoSearchAPIWrapper(region='us-en', \n                                   time=\"y\", \n                                   max_results=10) #time Options: d, w, m, y\n\nrawdb = wrapper.results('LLM Mixture of Agents',max_results=5)\r\n```\n\n여기서는 에이전트 도구가 아닌 wrapper 자체를 사용하여 \"LLM 혼합 에이전트\"에 대한 정보를 찾습니다. 결과를 출력하고 rawdb 변수에 저장하면 다음과 같은 내용이 나타납니다:\n\n```js\n[\n    {\n        'snippet': '대형 언어 모델(LM)의 최근 발전은 자연어 이해 및 생성 작업에서 상당한 성능을 보여줍니다. 증가하는 LLM의 수로 인해 여러 LLM의 집단적 전문지식을 어떻게 활용할지는 흥미로운 개방 방향입니다. 이 목표를 향해, 우리는 Mixture-of-Agents (MoA) 방법을 통해 여러 LLM의 집단적 강점을 활용하는 새로운 접근 방식을 제안합니다.',\n        'title': 'Mixture-of-Agents Enhances Large Language Model Capabilities',\n        'link': 'https://arxiv.org/abs/2406.04692'\n    },\n    {\n        'snippet': '첫째로, 우리는 답안 제공자들에 의해 생성된 답 중 하나를 선택하기 위해 집계 모델을 사용하는 LLM 기반 순위 결정기를 Mixture-of-Agents와 비교합니다. 쓰기 결과는 Figure 4에 나와 있으며 MoA 접근 방식이 LLM-순위 결정층 베이스라인을 크게 능가함을 관찰할 수 있습니다.',\n        'title': 'Mixture-of-Agents Enhances Large Language Model Capabilities - arXiv.org',\n        'link': 'https://arxiv.org/html/2406.04692v1'\n    },\n    {\n        'snippet': '우리는 여러 LLM의 집단적 강점을 활용하여 최첨단 품질을 향상시키기 위한 Mixture of Agents (MoA) 접근 방식을 소개합니다. 그리고 우리는 상태-of-the-art의 품질을 향상하기 위해 여러 오픈소스 LLM 에이전트들을 활용하는 참조 구현인 Together MoA을 제공합니다. Together MoA는 AlpacaEval 2.0에서 65.1%의 점수를 달성하여 이전 리더 GPT-4o (57.5%)를 능가합니다.',\n        'title': 'Together MoA — collective intelligence of open-source models pushing ...',\n        'link': 'https://www.together.ai/blog/together-moa'\n    },\n    {\n        'snippet': '이 목표를 향해, 여러 LLM의 집단적 강점을 Mixture-of-Agents (MoA) 방법론을 통해 활용하는 새로운 접근 방식을 제안합니다. 우리의 접근 방식에서는 각 층이 여러 LLM 에이전트로 이루어진 층화식 MoA 아키텍처를 구성합니다. 각 에이전트는 이전 층에서 생성된 모든 출력을 보조 정보로 받습니다.',\n        'title': 'Mixture-of-Agents Enhances Large Language Model Capabilities',\n        'link': 'https://huggingface.co/papers/2406.04692'\n    },\n    {\n        'snippet': 'Mixture of Agents (MoA)는 여러 LLM의 집단적 강점을 활용하여 성능을 향상시키는 혁신적인 접근 방식으로, 최첨단 결과를 달성합니다. 각 층이 여러 LLM 에이전트로 이루어진 층화 구조를 사용하여 MoA는 65.1%의 점수로 AlpacaEval 2.0에서 GPT-4 Omni의 57.5%를 크게 능가합니다.',\n        'title': 'GitHub - togethercomputer/MoA',\n        'link': 'https://github.com/togethercomputer/moa'\n    }\n]\r\n```\n\n결과가 정확히 5개인 것을 확인할 수 있습니다. 하지만 텍스트가 짧네요! 이 짧은 조각 텍스트는 구체적인 사실적 질문에 사용할 수는 있지만 새로운 지식 베이스를 구축하기에는 부족합니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n좋은 점은 링크도 얻었다는 것이에요 🤣\n\n![image](/assets/img/2024-06-20-MaketheWebyourbestfrienddataprovider_2.png)\n\n# 스니펫에서 문서로\n\nGitHub 레포지토리를 하나씩 검색하면서 쉽고 완벽한 웹 검색을 찾고 있었는데, newspaper3k를 만나기 전까지요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 Python 라이브러리는 검색 엔진 결과에서 전체 텍스트를 얻기 위한 입구입니다. 그게 전부가 아닙니다!\n\nnltk 라이브러리도 함께 사용되기 때문에 키워드, 설명, 이미지 URL 및 요약과 같은 다양한 메타데이터로 정보를 보완할 수 있습니다!\n\nGoogle Colab에서 항상 살펴봅시다.\n\n```js\nfrom newspaper import Article\nimport nltk\nnltk.download('punkt')\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n웹 페이지 텍스트 추출 함수들은 정말 쉽게 사용할 수 있어요. NLTK 기능을 포함하려면 우선 Punkt를 다운로드해야 해요.\n\nNLTK에서 Punkt는 문장 토큰화에 사용되는 비지도 학습 가능한 모델이에요. 이 모델은 문장을 단어로 나누어 문장 시작 단어, 전치사구, 약어에 대한 모델을 개발함으로써 문장을 분리해요.\n\n이제 우리가 작은 Neural toolkit를 준비했으니 웹 페이지에서 가능한 모든 것을 추출해 봅시다. 이전 DuckDuckGo 검색에서 추출된 링크 중 하나를 사용할 수 있어요: https://www.together.ai/blog/together-moa\n\n```js\nurl = 'https://www.together.ai/blog/together-moa'\narticle = Article(url) # payload requests를 불러와요\narticle.download()     # 로컬로 데이터와 메타데이터를 버퍼링해요\narticle.parse()        # 텍스트 추출\narticle.nlp()          # 키워드와 요약을 위해 nlp 도구 실행\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이제 모든 것이 처리되었으니 데이터를 살펴볼 수 있어요:\n\n```js\nprint(article.text)\n---\n우린 Mixture of Agents (MoA)를 소개합니다. 이는 여러 LLM들의 집합적인 강점을 활용하여 최신 기술 수준을 향상시키는 접근법입니다. 또한 우리는 몇몇 오픈 소스 LLM 에이전트를 이용하여 65.1%의 점수를 얻는 Together MoA라는 참조 구현을 제공합니다. 이로써 이전 리더인 GPT-4o (57.5%)를 능가했습니다.\\n\\n그림 1: 에이전트 혼합 구조의 그림. 이 예시 ...\n\n\nprint(article.authors)\n\nprint(article.keywords)\n---\n['에이전트', '20', '전선', '성능', '모델', 'qwen1510bchat', '응답', 'moa', 'llm', '집단', '오픈소스', 'alpacaeval', '제안자', '인텔리전스', 'gpt4o', '능력강화']\n\nprint(article.summary)\n---\n우리는 Mixture of Agents (MoA)를 소개합니다. 이는 여러 LLM들의 집단적인 강점을 활용하여 최신 기술 수준을 향상시키는 접근법입니다.\n개요: 새로운 방법인 Mixture of Agents (MoA)를 소개하게 되어 기쁩니다. 이는 여러 LLM들의 집단적인 강점을 활용하는 혁신적인 접근법입니다.\n우리의 참조 구현인 Together MoA는 오직 오픈 소스 모델을 사용하여 AlpacaEval 2.0에서 57.5%인 GPT-4o를 크게 능가하며 65.1%의 점수를 얻습니다.\n그림 2는 각 모델이 AlpacaEval 2.0에서 기존 점수를 크게 개선함을 보여줍니다. 특히, 오픈 소스 모델만을 사용하여 AlpacaEval 2.0에서 우리는 57.5% (GPT-4o)에서 65.1% (Together MoA)로 7.6%의 절대 향상을 이룩했습니다.\n\nprint(article.meta_description)\n\nprint(article.meta_img)\nhttps://cdn.prod.website-files.com/650c3b59079d92475f37b68f/6667e9c28da8569e846b4632_thumbnail.jpg\n\nprint(article.meta_keywords)\n['']\n```\n\n정말 멋지다고 생각해요!\n\n이 몇 줄의 코드로 전체 텍스트와 중요한 메타데이터를 검색했어요. 웹 리소스가 정말 좋은 경우 날짜와 주 이미지도 간단히 이렇게 얻을 수 있답니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n```js\r\narticle.top_image\r\narticle.publish_date\r\n```\r\n\r\n![image](/assets/img/2024-06-20-MaketheWebyourbestfrienddataprovider_3.png)\r\n\r\n# 그럼 이제 어떻게 하죠? 자체 문서 저장소 만들기\r\n\r\n지금까지 말한 모든 것들은 데이터/정보가 생성 AI 애플리케이션에 있어 핵심이라는 것을 고려할 때에만 관련이 있습니다. LLM은 이제 NLP 작업을 뛰어나게 수행하므로 좋은 텍스트가 필요합니다.\r\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기서 더 나아가 봅시다! 웹 검색 쿼리를 입력하면 데이터를 풍부하게 모아서 표준 Langchain 형식으로 정리하는 파이프라인을 직접 만들 수 있습니다. 언제든지 사용할 준비가 완료되었어요!\n\n## Wrapper 실행\n\n```js\nfrom newspaper import Article\nimport pickle\nfrom rich.markdown import Markdown\nimport datetime\nfrom rich.console import Console\nfrom langchain.schema.document import Document\nconsole = Console(width=90)\nimport nltk\n# DuckDuckGo 검색 엔진 래퍼 준비\nfrom langchain_community.utilities import DuckDuckGoSearchAPIWrapper\nwrapper = DuckDuckGoSearchAPIWrapper(region='us-en', time=\"y\", max_results=10) #time parameter Options: d, w, m, y\n# 사용자 쿼리 요청\nconsole.print(f'[bold red1]무엇을 검색하시겠습니까?')\nresearch = console.input(f'[bright_green]\u003e ')\nconsole.print(90*'=')\n# Wrapper 실행\nrawdb = wrapper.results(research,max_results=5)\n```\n\n저는 아이작 아시모프의 원자 폭탄에 대한 이야기를 찾아보겠습니다. 그런 다음 예상 출력 형식을 사용하여 데이터베이스를 구축할 거에요. 다시 설명드리자면, 예상 형식은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n[\n  {\n    'snippet': '비디오 콜 - 아이작 아시모프 - 다양한 패운데이션 이야기 (1950년대+) 패운데이션 시리즈는 거대한 시간과 공간을 다룹니다. ... 원자폭탄 - H.G. 웰스 - The World Set Free (1914)',\n    'title': '과학 소설이 미래 기술을 예언한 10가지 시간 - 디스트로이드',\n    'link': 'https://www.destructoid.com/10-times-sci-fi-predicted-the-future-of-technology/'\n  },\n  {\n    'snippet': '밤바람과 다른 이야기들. 아이작 아시모프의 최고의 과학 소설. 전체...'\n  }\n]\n```\n\n여기에서 이미 황금 광산을 발견했어요: 우리는 DDG 검색 필드에서 제목, 스니펫 및 링크를 얻을 수 있어요.\n\n## 신문 NLP 도구와 Wrapper 결과 병합\n\n이제 rawdb 리스트를 반복하고 각 URL을 사용하여 newspaper3k를 실행할 수 있습니다. 더 똑똒하게 만들기 위해 반복 중 LangChain Document 객체를 만들어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\ndocdocs = []\nfor items in rawdb:\n    url = items[\"link\"]\n    try:  # 만약 URL에 접속할 수 없다면 유용합니다\n        article = Article(url)\n        article.download()\n        article.parse()\n        article.nlp()\n        kw = []\n        # NLTK 키워드와 메타 웹페이지 키워드를 병합합니다\n        for i in article.keywords + article.meta_keywords:\n            if i == '':  # 우리에게는 블랙 키워드가 없습니다\n                pass\n            else:\n                kw.append(i)\n        if article.text == '':  # 때로는 구문 분석할 텍스트가 없습니다. 그래서 스니펫을 사용합니다\n            docdocs.append(Document(page_content=items[\"snippet\"], metadata={\n                'source': items[\"link\"],\n                'title': items[\"title\"],\n                'snippet': items[\"snippet\"],\n                'author': article.authors,\n                'keywords': kw,\n                'meta_description': article.meta_description,\n                'meta_img': article.meta_img,\n                'top_image': article.top_image,\n                'publish_date': article.publish_date,\n                'summary': article.summary}))\n        else:\n            docdocs.append(Document(page_content=article.text.replace('\\n\\n', ''), metadata={\n                'source': items[\"link\"],\n                'title': items[\"title\"],\n                'snippet': items[\"snippet\"],\n                'author': article.authors,\n                'keywords': kw,\n                'meta_description': article.meta_description,\n                'meta_img': article.meta_img,\n                'top_image': article.top_image,\n                'publish_date': article.publish_date,\n                'summary': article.summary}))\n    except:\n        pass\n```\n\n이제 변수 docdocs에는 메타데이터가 풍부한 LangChain 문서 목록이 있습니다. 이를 FAISS와 같은 벡터 데이터베이스에서 직접 사용하거나 로컬 파일에 저장할 수 있습니다. 저는 두 번째 옵션을 선호합니다. 그 이유는 언제든지 이러한 문서를 나중에 병합할 수 있기 때문입니다.\n\n따라서 나는 이러한 문서를 저장하기 위해 피클 형식을 선택한 것입니다. pickle 모듈은 Python 표준 라이브러리에 포함되어 있습니다. Python 개체 구조를 직렬화하고 역 직렬화하기 위한 이진 프로토콜을 구현합니다.\n\n“Pickling”은 Python 개체 계층 구조를 바이트 스트림으로 변환하는 프로세스이며, “unpickling”은 그 반대 작업으로, 바이너리 파일 또는 바이트류 객체에서 바이트 스트림을 개체 계층 구조로 변환하는 작업입니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n## 메타데이터와 함께 문서 세트를 pickle에 저장합니다.\nlcdfilename = research.replace(' ','_')+'.lcd'\noutput = open(lcdfilename, 'wb')\npickle.dump(docdocs, output)\noutput.close()\nconsole.print(Markdown(\"\u003e LangChain 문서 데이터가 저장되었습니다...\"))\n```\n\n이제 LangChain 문서를 가지고 로컬 모델을 실행해 볼 수 있어요. 여기에 하나의 도전 과제가 있네요: 왜 llama-cpp-python만 사용해서 시도해 보지 않으세요?\n\n# 결론\n\nWeb 검색 및 자연어 처리(NLP) 도구를 이용하여 최신 및 관련 데이터로 언어 학습 모델(LLM)를 풍부하게 하는 혁신적인 접근 방식을 함께 탐색했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이와 같은 전략들은 계산 요구 사항과 무료 데이터의 부족으로 인한 제한을 극복하는 데 중요합니다.\n\n어고노스틱 LLM을 달성하기 위해, 외부 지식 소스를 통합하여 LLM 응답의 정확성과 신뢰도를 향상시키는 Retrieval Augmented Generation (RAG) 기술이 결정적인 기법으로 부상합니다.\n\n저희는 웹 검색 엔진과 newspaper3k와 같은 NLP 라이브러리를 도구로 사용하여 온라인 리소스로부터 전체 텍스트와 가치 있는 메타데이터를 추출하고, 간략한 스니펫을 포괄적인 문서로 변환했습니다.\n\n이 프로세스는 생성 모델의 잘라내기 날짜 제한을 우회하는 것뿐만 아니라 개인화된 문서 저장소를 생성하는 것을 용이하게 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n무서워하지 마시고 실험해보세요. 하지만 항상 기억하세요, 도구는 좋거나 나쁘지 않습니다! 도구는 사용하는 사람만큼 좋습니다!\n\n만약 이 이야기가 가치 있었고 조금이라도 지원을 보내고 싶다면, 다음을 해볼 수 있습니다:\n\n- 이 이야기에 대해 많이 박수를 보내기\n- 기억할 가치가 있는 부분을 강조하기 (나중에 찾기가 쉽고, 나는 더 나은 기사를 쓸 수 있습니다)\n- '자체 AI 구축 방법 배우기, 이 무료 eBook 다운로드하기'\n- 내 링크를 통해 Medium 멤버십 가입하기 ($5/월로 무제한 Medium 이야기 읽기)\n- Medium에서 나를 팔로우하기\n- 내 최신 기사를 읽기: https://medium.com/@fabio.matricardi\n\n더 많은 내용을 보고 싶다면, 다음은 몇 가지 아이디어입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n구글 Colab 노트북이 있는 GitHub 저장소\n\n![GitHub Repository](/assets/img/2024-06-20-MaketheWebyourbestfrienddataprovider_4.png)\n\n이 이야기는 Generative AI에서 발행되었습니다. 최신 AI 이야기를 알고 싶다면 LinkedIn에서 저희와 연결하고 Zeniteq를 팔로우하세요.\n\n저희의 뉴스레터에 가입하여 최신 generative AI 뉴스와 업데이트를 받아보세요. 함께 AI의 미래를 함께 만들어 봅시다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n`![2024-06-20-MaketheWebyourbestfrienddataprovider_5.png](/assets/img/2024-06-20-MaketheWebyourbestfrienddataprovider_5.png)`","ogImage":{"url":"/assets/img/2024-06-20-MaketheWebyourbestfrienddataprovider_0.png"},"coverImage":"/assets/img/2024-06-20-MaketheWebyourbestfrienddataprovider_0.png","tag":["Tech"],"readingTime":14},{"title":"Vercel에 Nodejs 백엔드를 배포하는 방법 단계별 가이드","description":"","date":"2024-06-20 04:36","slug":"2024-06-20-HowtoDeployYourNodejsBackendonVercelAStep-by-StepGuide","content":"\n\n\u003cimg src=\"/assets/img/2024-06-20-HowtoDeployYourNodejsBackendonVercelAStep-by-StepGuide_0.png\" /\u003e\n\nVercel에 Node.js 백엔드를 배포하는 것은 업무를 간편화하면서 애플리케이션을 웹상에서 작동시킬 수 있는 프로세스입니다. 이 수정된 가이드에서는 가장 최신 방법을 사용하여 백엔드를 배포하는 방법을 안내해 드리겠습니다. 시작해 봅시다.\n\n# 1. Vercel 계정 생성\n\n먼저, vercel.com에서 Vercel 계정을 만들어주세요. GitHub, GitLab 또는 Bitbucket 중 선호하는 인증 방법을 선택할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 2. 간단한 Express API 만들기\n\n로컬 머신에 Node.js와 NPM이 설치되어 있는지 확인해주세요. 만약 없다면, https://nodejs.org/ 에서 다운로드할 수 있습니다.\n\n먼저, 새로운 프로젝트용 디렉토리를 만들고 해당 디렉토리로 이동한 후, 새로운 Node.js 프로젝트를 초기화하세요:\n\n```js\nmkdir my-express-api\ncd my-express-api\nnpm init -y\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nExpress를 설치하고 index.js 파일을 만드세요:\n\n```js\nnpm install express touch index.js\n```\n\n선호하는 코드 편집기에서 index.js를 열고 기본 Express API를 만들기 위한 다음 코드를 추가하세요:\n\n```js\nconst express = require(\"express\");\nconst app = express();\napp.get(\"/\", (req, res) =\u003e {\n  res.send(\"Express on Vercel\");\n});\nconst PORT = process.env.PORT || 5000;\napp.listen(PORT, () =\u003e {\n  console.log(`서버가 포트 ${PORT}에서 실행 중입니다`);\n});\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 3. Express API 내보내기\n\n원하는 위치에 있는 index.js 파일을 수정하여 Express 앱을 내보냅니다:\n\n```js\n// ... (이전 코드) module.exports = app; // Express 앱 내보내기\n```\n\n프로젝트 디렉토리에 vercel.json 파일을 생성하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ntouch vercel.json\n```\n\nvercel.json 파일 내용:\n\n```js\n{\n  \"version\": 2,\n  \"builds\": [\n    {\n      \"src\": \"index.js\",\n      \"use\": \"@vercel/node\"\n    }\n  ],\n  \"routes\": [\n    {\n      \"src\": \"/(.*)\",\n      \"dest\": \"index.js\"\n    }\n  ]\n}\n```\n\n# 5. Express API 배포하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n깃 레포지토리를 초기화하고 코드를 커밋한 후에 해당 코드를 소스 레포지토리에 푸시하세요. 이 레포지토리는 GitHub, GitLab 또는 다른 플랫폼에 있을 수 있습니다.\n\n배포가 완료되면 제공된 Vercel URL에서 API에 액세스하여 서비스가 제대로 작동하는지 확인해보세요. 예를 들면 your-app-name.vercel.app와 같이 접속할 수 있습니다.\n\n축하합니다! 이제 Node.js 백엔드가 서버리스 함수로 성공적으로 Vercel에 배포되었습니다. 프로젝트 구조와 요구사항에 맞게 가이드를 수정하여 원활한 배포 경험을 만들어보세요.\n\n원문은 https://kkupgrader.eu.org에서 확인할 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-20-HowtoDeployYourNodejsBackendonVercelAStep-by-StepGuide_0.png"},"coverImage":"/assets/img/2024-06-20-HowtoDeployYourNodejsBackendonVercelAStep-by-StepGuide_0.png","tag":["Tech"],"readingTime":2},{"title":"내가 원하는 테크 회사에 자동 이메일을 보내는 스크립트를 작성했어요 결과 포함","description":"","date":"2024-06-20 04:35","slug":"2024-06-20-IWroteAnAutomatedScripttoSendOutColdE-MailstotheTechCompaniesIWanttoWorkAtWithResults","content":"\n\n\n\u003cimg src=\"/assets/img/2024-06-20-IWroteAnAutomatedScripttoSendOutColdE-MailstotheTechCompaniesIWanttoWorkAtWithResults_0.png\" /\u003e\n\n'Cold e-mailing'은 오늘날 모든 구직자가 들어본 적이 있는 것입니다. 그러나 실제로 도움되고 쉬운 것일까요? 매번 이메일을 맞춤화하여 모든 채용 담당자 및 관리자들의 이메일을 검색하고 보내기는 귀찮은 일입니다. 굳이 그렇게 해야 하는가?\n\n어떻게하면 프로세스를 쉽게 만들 수 있을까요? LinkedIn에서 사람들에게 메시지를 보내는 것은 수백 명의 사람들이 이미 모든 채용 담당자와 리크루터에게 메시지를 보냈다는 점을 고려하면 불가능합니다 (아무도 무시하려는 것이 아닙니다. 현재는 정말 어려운 시기이며 모두 최선을 다하고 있습니다)\n\n# 생각\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n어떻게 하면 좋을까요? '회사 이름' 채용 담당자/리쿠르터의 LinkedIn을 온라인으로 검색하여 그들의 이름을 찾고, 직접적인 이메일을 보내는 스크립트를 작성한다면 어떨까요? 하지만 LinkedIn에서 이들의 이메일 주소를 어떻게 찾을까요? 각기 다른 회사에 맞춰 이메일을 어떻게 개인화할까요? 가장 중요한 것은, 이 모든 작업을 수작업으로 할 수는 없다는 것입니다.\n\n# 아이디어 발산\n\n처음에 생각한 것은, 스크립트를 작성하여 firstName+lastName@companywebsite.com의 모든 조합에 이메일을 보내는 것인데, 어떻게하면 유효한 이메일 주소인지 알 수 있을까요?\n\n이 문제는 꽤 간단하게 해결할 수 있었습니다. 유효하지 않은 이메일로 메일을 보내면 메일러 데몬(발신자와 수신자 사이의 중간 인터페이스)이 수신자의 이메일 주소가 유효하지 않아서 이메일을 보낼 수 없다는 경고를 통보해줍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n알겠어요. 이제 하나의 조합이 유효하다면 메일러 데몬으로부터 알림을 받지 않는다는 사실을 알게 되었어요. 이제 조합을 생성하는 것은 또 다른 작업이었지만, 제 경험상 회사 이메일은 일반적으로 다음과 같은 양식을 따른다는 것을 알고 있어요 -\n\n- jdoe@company.com\n- johnd@company.com\n- johndoe@company.com\n- j.doe@company.com\n- john.doe@company.com\n\n그러나 몇몇 회사 이메일을 알고 있는 것에 기반하여 스크립트에 추가적인 조합 몇 가지를 추가했어요. 따라서 여기서의 작업은 탐색 스크립트로부터 수집된 이름에서 조합을 생성하는 것이었습니다. 문자열 조작과 생성적 AI를 사용하여 이 작업은 꽤 간단한 일이었어요.\n\n# ‘맞춤’ 이메일\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n각 회사에 이메일을 맞춤화하는 것을 고려해야 하는 부분이었지만, 회사에 대한 내 흥미와 경력, 프로젝트, 학력을 언급한 일반적인 텍스트 조각을 만드는 것이 목표였어요. 또한, 이메일에 이력서를 첨부해야 했죠.\n\n내가 미리 설정한 이메일 샘플:\n\n```js\n\"안녕하세요, 제 이름은 Priyanshu입니다... 제 자격 및 성취는...\n...${companyName}에서 일하고 싶어하는 이유는...\n...SDE/풀스택 엔지니어와 같은 역할을 찾고 있습니다...\n...제 이력서를 첨부했습니다...\"\n```\n\n매우 간략한 형태로 이메일을 작성한 것을 볼 수 있어요. 회사 이름이 변수로 전달되는 것에 주목해주세요. 이 변수는 내가 최우선 순위로 둔 회사들의 배열에서 가져온 것이에요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n간단히 말씀드리면, 목록에서 각 회사에 대해 다음을 시도했습니다:\n\n- 구글 검색을 통해 회사에서 채용 담당자/리쿠르터/시니어 개발자를 찾기 위해 — Puppeteer.js를 사용한 웹 스크래핑\n- 스크랩된 텍스트에서 이름을 추출하기 위해 — 발생 모델 AI API 및 문자열 조작\n- 내 이력서와 함께 맞춤형 이메일을 모든 조합에게 보내기 — Nodemailer API\n- 이미 이메일을 보낸 주소를 저장하여 리쿠르터에게 스팸을 보내지 않도록 함 — MongoDB\n\n위의 모든 작업은 저가 Node.js를 사용하여 작성한 스크립트로 자동화했습니다.\n\n# 결과 및 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![1](/assets/img/2024-06-20-IWroteAnAutomatedScripttoSendOutColdE-MailstotheTechCompaniesIWanttoWorkAtWithResults_1.png)\n\n![2](/assets/img/2024-06-20-IWroteAnAutomatedScripttoSendOutColdE-MailstotheTechCompaniesIWanttoWorkAtWithResults_2.png)\n\n![3](/assets/img/2024-06-20-IWroteAnAutomatedScripttoSendOutColdE-MailstotheTechCompaniesIWanttoWorkAtWithResults_3.png)\n\n![4](/assets/img/2024-06-20-IWroteAnAutomatedScripttoSendOutColdE-MailstotheTechCompaniesIWanttoWorkAtWithResults_4.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n많은 추가적인 이메일도 있어요.\n\n많은 긍정적인 응답을 받기는 했지만, 아직 후속 조치는 받지 못했어요. 현재 시장 상황과 후원 요건 때문에 조금 어려울지도 모르겠지만, 희망을 잃지 말아봐요!\n\n읽어주셔서 감사합니다!","ogImage":{"url":"/assets/img/2024-06-20-IWroteAnAutomatedScripttoSendOutColdE-MailstotheTechCompaniesIWanttoWorkAtWithResults_0.png"},"coverImage":"/assets/img/2024-06-20-IWroteAnAutomatedScripttoSendOutColdE-MailstotheTechCompaniesIWanttoWorkAtWithResults_0.png","tag":["Tech"],"readingTime":3},{"title":"NestJS에서 IoC 컨테이너에 접근하기 실용적인 로깅 라이브러리 예제","description":"","date":"2024-06-20 04:34","slug":"2024-06-20-AccessingtheIoCContainerinNestJSAPracticalLoggingLibraryExample","content":"\n\n![2024-06-20-AccessingtheIoCContainerinNestJSAPracticalLoggingLibraryExample_0.png](/assets/img/2024-06-20-AccessingtheIoCContainerinNestJSAPracticalLoggingLibraryExample_0.png)\n\n안녕하세요! 이 세부적인 자습서에서는 NestJS 프로젝트를 만들고 특정 메타데이터가 지정된 모든 프로바이더 및 컨트롤러의 메서드 호출을 동적으로 탐지하고 기록하는 로깅 라이브러리를 구축할 것입니다. 이 예제는 IoC(Inversion of Control) 컨테이너에 액세스하고 등록된 프로바이더 및 컨트롤러를 조사하며 사용자 정의 데코레이터를 사용하여 동적 동작을 적용하는 방법을 이해하는 데 도움이 될 것입니다.\n\n# IoC 컨테이너란?\n\nNestJS의 IoC 컨테이너는 애플리케이션 구성 요소의 생성, 설정 및 라이프사이클을 관리하여 의존성 주입을 가능하게 합니다. 이는 컨테이너가 필요한 클래스에 자동으로 의존성을 제공하는 의존성 주입을 허용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# IoC 컨테이너에 접근하는 이유\n\nIoC 컨테이너에 접근하는 것은 다음과 같은 이유로 매우 중요합니다:\n\n- 살펴보기: 등록된 제공자(Providers) 및 컨트롤러(Controllers)를 모두 검사하기 위해.\n- 동적 동작: 로깅, 모니터링 또는 메타데이터를 기반으로 동작을 수정하는 등 동적 동작을 적용하기 위해.\n- 일반 라이브러리: 다양한 응용프로그램 구성 요소와 동적으로 상호작용해야 하는 라이브러리를 구축하기 위해.\n\n# 단계별 안내\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nNestJS 프로젝트를 만들고 동적 로깅 라이브러리를 빌드하는 단계를 함께 진행해 보겠습니다.\n\n## 단계 1: NestJS 프로젝트 설정하기\n\n- NestJS CLI를 설치합니다:\n\n```js\nnpm install -g @nestjs/cli\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2. 새로운 NestJS 프로젝트 만들기:\n\n```js\nnest new logging-library\ncd logging-library\n```\n\n3. 필수 종속성 설치:\n\n```js\nnpm install @nestjs/core @nestjs/common @nestjs-plus/discovery\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 단계 2: LoggerService 생성하기\n\nNestJS 라이프사이클 훅을 사용하여 메서드 호출 로깅을 동적으로 설정하고 지우는 LoggerService를 생성합니다.\n\n- LoggerService 생성하기:\n\n```js\nnest generate service logger\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n2. LoggerService를 구현하세요:\n\n```js\n// src/logger/logger.service.ts\nimport { Injectable, OnApplicationBootstrap, OnApplicationShutdown } from '@nestjs/common';\nimport { DiscoveryService, Reflector, MetadataScanner } from '@nestjs/core';\n\n@Injectable()\nexport class LoggerService implements OnApplicationBootstrap, OnApplicationShutdown {\n  // 원본 메소드를 저장하고 종료 시 복원하기 위한 Map\n  private readonly originals: Map\u003cany, any\u003e = new Map();\n\n  constructor(\n    // DiscoveryService는 모든 프로바이더와 컨트롤러를 찾기 위해 사용됩니다.\n    private readonly discoveryService: DiscoveryService,\n    // Reflector는 클래스와 메소드에서 메타데이터를 읽기 위해 사용됩니다.\n    private readonly reflector: Reflector,\n    // MetadataScanner는 클래스 프로토타입을 메소드 이름으로 스캔하기 위해 사용됩니다.\n    private readonly metadataScanner: MetadataScanner\n  ) {}\n\n  // 모든 모듈이 초기화된 후에 실행되는 라이프사이클 훅\n  onApplicationBootstrap() {\n    // 애플리케이션에서 모든 프로바이더(컨트롤러 포함)를 가져옵니다.\n    const providers = this.discoveryService.getProviders();\n    providers.forEach((wrapper) =\u003e {\n      // 프로바이더의 인스턴스(실제 객체) 가져오기\n      const { instance } = wrapper;\n      // 프로바이더의 프로토타입(모든 인스턴스에서 공유되는 메소드와 속성) 가져오기\n      const prototype = instance \u0026\u0026 Object.getPrototypeOf(instance);\n      // 인스턴스나 프로토타입이 없는 경우 건너뜁니다.\n      if (!instance || !prototype) {\n        return;\n      }\n      // 클래스가 @Loggable로 표시되어 있는지 확인합니다.\n      const isLoggable = this.reflector.get('LOGGABLE_KEY', instance.constructor) ?? false;\n      if (!isLoggable) {\n        return;\n      }\n      // 클래스 프로토타입에서 모든 메소드 이름 가져오기\n      const methodKeys = this.metadataScanner.getAllMethodNames(prototype);\n      methodKeys.forEach((methodKey) =\u003e {\n        // 이름으로 메소드 가져오기\n        const method = instance[methodKey];\n        // 함수(메소드)인지 확인합니다.\n        if (typeof method === 'function') {\n          // 원본 메소드 저장\n          this.originals.set(method, method.bind(instance));\n          // 원본 메소드를 로깅 래퍼로 대체합니다.\n          instance[methodKey] = (...args: any[]) =\u003e {\n            console.log(`Calling ${methodKey} with args:`, args);\n            return this.originals.get(method)(...args);\n          };\n        }\n      });\n    });\n  }\n\n  // 애플리케이션이 종료되기 전에 실행되는 라이프사이클 훅\n  onApplicationShutdown(signal?: string) {\n    // 모든 원본 메소드를 복원합니다.\n    this.originals.forEach((original, method) =\u003e {\n      method = original;\n    });\n    // 원본 메소드 Map을 비웁니다.\n    this.originals.clear();\n  }\n}\n```\n\n- Instance: IoC 컨테이너에서 생성된 실제 객체입니다. 이는 응용프로그램에서 상호작용하는 실시간 객체입니다.\n- Prototype: 객체의 청사진입니다. 클래스의 모든 인스턴스간에 공유되는 메소드와 속성이 포함되어 있습니다. 프로토타입을 사용하면 클래스 메소드의 동적 조회 및 수정이 가능합니다.\n\n# 로깅 메소드의 상세 설명\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n코드의 일부를 더 깊이 파헤쳐 보겠습니다. 여기서는 로깅 기능을 가진 메소드를 동적으로 래핑하는 부분에 집중해 봅시다:\n\n```js\nmethodKeys.forEach((methodKey) =\u003e {\n  // 메소드 이름으로 메소드를 가져옵니다\n  const method = instance[methodKey];\n  // 속성이 함수(메소드)인지 확인합니다\n  if (typeof method === 'function') {\n    // 원본 메소드를 저장합니다\n    this.originals.set(method, method.bind(instance));\n    // 원본 메소드를 로깅 래퍼로 교체합니다\n    instance[methodKey] = (...args: any[]) =\u003e {\n      console.log(`${methodKey}를 인수와 함께 호출 중:`, args);\n      return this.originals.get(method)(...args);\n    };\n  }\n});\n```\n\n## 단계별 설명\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nmethodKeys.forEach((methodKey) =\u003e {\n```\n\n- methodKeys: 프로바이더의 프로토타입에 있는 모든 메서드 이름의 배열입니다.\n\n2. 이름으로 메서드 가져오기:\n\n```js\nconst method = instance[methodKey];\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- instance[methodKey]: 이름(key)으로 인스턴스의 메서드에 액세스합니다.\n- method: 실제 메서드 함수에 대한 참조를 보유합니다.\n\n3. 속성이 함수인지 확인합니다:\n\n```js\nif (typeof method === 'function') {\n```\n\n- 속성이 실제로 함수이고 다른 유형의 속성(예: 변수)이 아님을 보장합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n4. 원본 메소드 저장:\n\n```js\nthis.originals.set(method, method.bind(instance));\n```\n\n- this.originals: 원본 메소드 참조를 저장하는 Map 객체입니다.\n- set(method, method.bind(instance)): 해당 메소드를 인스턴스에 바인딩하여 저장하여 메소드가 호출될 때 올바른 컨텍스트(this)를 유지합니다.\n\n5. 원본 메소드를 로깅 래퍼로 대체하기:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ninstance[methodKey] = (...args: any[]) =\u003e {\n  console.log(`Calling ${methodKey} with args:`, args);\n  return this.originals.get(method)(...args);\n};\n```\n\n- instance[methodKey]: 기존 메소드를 새 함수로 대체합니다.\n- (...args: any[]): '...'는 새 함수를 나타내며:\n- 메소드 호출과 인수를 기록합니다.\n- this.originals에 저장된 참조를 사용하여 원본 메소드를 호출합니다.\n\n# 실제 예시\n\ncreateUser 및 deleteUser 메소드를 갖는 UserService 클래스가 있다고 가정해보겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n@Loggable\n@Injectable()\nexport class UserService {\n  createUser(name: string) {\n    console.log(`User ${name} created.`);\n  }\n\n  deleteUser(id: number) {\n    console.log(`User with id ${id} deleted.`);\n  }\n}\n```\n\nLoggerService가 초기화될 때 다음을 합니다:\n\n- UserService 제공자를 탐색합니다.\n- UserService에 @Loggable이 표시되어 있는지 확인합니다.\n- UserService의 각 메서드(예: createUser 및 deleteUser)에 대해\n- 원본 메서드를 저장합니다.\n- 원본 메서드를 호출하기 전에 호출과 매개변수를 기록하는 새 함수로 메서드를 대체합니다\n\n## 단계 3: 사용자 정의 데코레이터 정의하기\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n클래스 및 메서드에 로깅을 위한 표시를 지정하기 위해 @Loggable 데코레이터를 정의합니다.\n\n데코레이터를 생성하세요:\n\n```js\n// src/logger/loggable.decorator.ts\nimport { SetMetadata } from '@nestjs/common';\n\n// loggable 메타데이터를 위한 키\nexport const LOGGABLE_KEY = 'LOGGABLE_KEY';\n// 로깅을 위해 클래스를 표시하는 Loggable 데코레이터\nexport const Loggable: ClassDecorator = SetMetadata(LOGGABLE_KEY, true);\n```\n\n## 스텝 4: 사용자 지정 데코레이터 사용하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n@Service 클래스에서 @Loggable 데코레이터를 사용하여 로깅해야 하는 메서드를 생성하세요.\n\n- 서비스 생성:\n\n```js\nnest generate service user\n```\n\n2. UserService를 구현하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n// src/user/user.service.ts\nimport { Injectable } from '@nestjs/common';\nimport { Loggable } from '../logger/loggable.decorator';\n\n// UserService 클래스를 로깅하기 위해 표시합니다\n@Loggable\n@Injectable()\nexport class UserService {\n  // 사용자 생성 메서드\n  createUser(name: string) {\n    console.log(`사용자 ${name}이(가) 생성되었습니다.`);\n  }\n\n  // 사용자 삭제 메서드\n  deleteUser(id: number) {\n    console.log(`ID가 ${id}인 사용자가 삭제되었습니다.`);\n  }\n}\n```\n\n3. 로깅을 테스트하기 위해 UserController를 생성합니다:\n\n```bash\nnest generate controller user\n```\n\n4. UserController를 구현합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n// src/user/user.controller.ts\nimport { Controller, Post, Body, Delete, Param } from '@nestjs/common';\nimport { UserService } from './user.service';\n\n@Controller('users')\nexport class UserController {\n  constructor(private readonly userService: UserService) {}\n\n  @Post()\n  createUser(@Body('name') name: string) {\n    return this.userService.createUser(name);\n  }\n\n  @Delete(':id')\n  deleteUser(@Param('id') id: number) {\n    return this.userService.deleteUser(id);\n  }\n}\n```\n\n5. Step 5: AppModule에서 LoggerService 통합\n\nLoggerService와 UserController가 응용 프로그램 모듈에 포함되어 있는지 확인하십시오.\n\nAppModule 업데이트:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n// src/app.module.ts\nimport { Module } from '@nestjs/common';\nimport { DiscoveryModule } from '@nestjs/core';\nimport { LoggerService } from './logger/logger.service';\nimport { UserService } from './user/user.service';\nimport { UserController } from './user/user.controller';\n\n@Module({\n  imports: [DiscoveryModule],\n  providers: [LoggerService, UserService],\n  controllers: [UserController],\n})\nexport class AppModule {\n  // Inject LoggerService to initialize it on application start\n  constructor(private readonly loggerService: LoggerService) {}\n}\n```\n\n## 단계 6: 로깅 테스트\n\ncurl을 사용하여 엔드포인트를 테스트하고 로깅 기능을 확인할 수 있습니다.\n\n- 유저 생성:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```bash\n# 사용자 추가:\ncurl -X POST http://localhost:3000/users -H \"Content-Type: application/json\" -d '{\"name\": \"John Doe\"}'\n```\n\n2. 사용자 삭제:\n\n```bash\ncurl -X DELETE http://localhost:3000/users/1\n```\n\n# 결과\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ncreateUser을 다음과 같은 args와 함께 호출했습니다: ['John Doe']\n사용자 John Doe가 생성되었습니다.\ndeleteUser을 다음과 같은 args와 함께 호출했습니다: ['1']\nid가 1인 사용자가 삭제되었습니다.\n```\n\n# 요약\n\n이 지침을 따라 NestJS 프로젝트를 생성하고, 특정 메타데이터로 표시된 모든 프로바이더 및 컨트롤러에 대한 메서드 호출을 동적으로 기록하는 로깅 라이브러리를 구축했습니다. 이 튜토리얼은 NestJS의 IoC 컨테이너에 액세스하여 등록된 프로바이더 및 컨트롤러를 검사하고 동적 동작을 적용하는 방법을 보여주었습니다.\n\n사용자 지정 데코레이터와 메타데이터 반사를 활용하여 메서드 호출을 기록하는 유연한 시스템을 구축하여, NestJS의 강력한 IoC 컨테이너를 활용하여 고급 사용 사례에 대처하는 방법을 시연했습니다. 이 접근 방식은 NestJS 애플리케이션의 다른 부분과 동적으로 상호작용해야 하는 다양한 제네릭 및 통합 라이브러리를 구축하기 위해 확장할 수 있습니다.\n","ogImage":{"url":"/assets/img/2024-06-20-AccessingtheIoCContainerinNestJSAPracticalLoggingLibraryExample_0.png"},"coverImage":"/assets/img/2024-06-20-AccessingtheIoCContainerinNestJSAPracticalLoggingLibraryExample_0.png","tag":["Tech"],"readingTime":10}],"page":"37","totalPageCount":154,"totalPageGroupCount":8,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"37"},"buildId":"QH5Mz7n7Y6w0r4_gCGFQf","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>