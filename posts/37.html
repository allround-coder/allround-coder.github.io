<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><title>allround-coder</title><meta name="description" content="I develop websites, games and apps with HTML, CSS and JS."/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:url" content="https://allround-coder.github.io///posts/37" data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta property="og:site_name" content="allround-coder" data-gatsby-head="true"/><meta property="og:title" content="allround-coder" data-gatsby-head="true"/><meta property="og:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta property="og:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta property="og:locale" content="en_US" data-gatsby-head="true"/><meta name="twitter:card" content="summary_large_image" data-gatsby-head="true"/><meta property="twitter:domain" content="https://allround-coder.github.io/" data-gatsby-head="true"/><meta property="twitter:url" content="https://allround-coder.github.io///posts/37" data-gatsby-head="true"/><meta name="twitter:title" content="allround-coder" data-gatsby-head="true"/><meta name="twitter:description" content="I develop websites, games and apps with HTML, CSS and JS." data-gatsby-head="true"/><meta name="twitter:image" content="/favicons/ms-icon-310x310.png" data-gatsby-head="true"/><meta name="twitter:data1" content="Dev | allround-coder" data-gatsby-head="true"/><meta name="next-head-count" content="18"/><meta name="google-site-verification" content="a-yehRo3k3xv7fg6LqRaE8jlE42e5wP2bDE_2F849O4"/><link rel="stylesheet" href="/favicons/favicon.ico"/><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicons/favicon-16x16.png"/><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="96x96" href="/assets/favicons/favicon-96x96.png"/><link rel="icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-icon" href="/favicons/apple-icon-180x180.png"/><link rel="apple-touch-startup-image" href="/startup.png"/><meta name="apple-mobile-web-app-capable" content="yes"/><meta name="apple-mobile-web-app-status-bar-style" content="black"/><meta name="msapplication-config" content="/favicons/browserconfig.xml"/><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-ZFDEQ947R4"></script><script>window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
  
            gtag('config', 'G-ZFDEQ947R4');</script><link rel="preload" href="/_next/static/css/6e57edcf9f2ce551.css" as="style"/><link rel="stylesheet" href="/_next/static/css/6e57edcf9f2ce551.css" data-n-g=""/><link rel="preload" href="/_next/static/css/a22d13b8e6bc8203.css" as="style"/><link rel="stylesheet" href="/_next/static/css/a22d13b8e6bc8203.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-ee6df16fdc6dae4d.js" defer=""></script><script src="/_next/static/chunks/framework-46611630e39cfdeb.js" defer=""></script><script src="/_next/static/chunks/main-cf4a52eec9a970a0.js" defer=""></script><script src="/_next/static/chunks/pages/_app-6fae11262ee5c69b.js" defer=""></script><script src="/_next/static/chunks/75fc9c18-ac4aa08aae62f90e.js" defer=""></script><script src="/_next/static/chunks/463-0429087d4c0b0335.js" defer=""></script><script src="/_next/static/chunks/873-ec7535a55e788b31.js" defer=""></script><script src="/_next/static/chunks/pages/posts/%5Bpage%5D-cd321dee6458c228.js" defer=""></script><script src="/_next/static/Y-fCAg8BUV7y2HNFwX9AA/_buildManifest.js" defer=""></script><script src="/_next/static/Y-fCAg8BUV7y2HNFwX9AA/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="posts_container__s9Z_H posts_-list__bsl0U"><header class="Header_header__Z8PUO"><div class="Header_inner__tfr0u"><strong class="Header_title__Otn70"><a href="/">Allround Coder</a></strong><nav class="Header_nav_area__6KVpk"><a class="nav_item" href="/posts/1">Posts</a></nav></div></header><div class="posts_inner__HIBjT"><article><h2 class="SectionTitle_section_title__HS_xr">Posts</h2><div class="posts_project_list__oDV_y"><div class="PostList_post_list__or0rl"><a class="PostList_post_item__gAdVi" aria-label="React를 활용하여 접근성 테스팅의 힘을 발휘하세요" href="/post/2024-06-20-UnlockthePowerofAccessibleTestingwithReact"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="React를 활용하여 접근성 테스팅의 힘을 발휘하세요" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-UnlockthePowerofAccessibleTestingwithReact_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="React를 활용하여 접근성 테스팅의 힘을 발휘하세요" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">React를 활용하여 접근성 테스팅의 힘을 발휘하세요</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">7<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="프론트엔드 엔지니어를 위한 아마존 전화 인터뷰 경험" href="/post/2024-06-20-AmazonPhoneInterviewExperienceforFront-EndEngineer"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="프론트엔드 엔지니어를 위한 아마존 전화 인터뷰 경험" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-AmazonPhoneInterviewExperienceforFront-EndEngineer_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="프론트엔드 엔지니어를 위한 아마존 전화 인터뷰 경험" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">프론트엔드 엔지니어를 위한 아마존 전화 인터뷰 경험</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">2<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="공포 주도 개발" href="/post/2024-06-20-FearDrivenDevelopment"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="공포 주도 개발" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-FearDrivenDevelopment_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="공포 주도 개발" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">공포 주도 개발</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="오디오 데이터에 대한 명명된 개체 인식Named Entity Recognition 수행하기" href="/post/2024-06-20-PerformingNamedEntityRecognitiononAudioData"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="오디오 데이터에 대한 명명된 개체 인식Named Entity Recognition 수행하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-PerformingNamedEntityRecognitiononAudioData_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="오디오 데이터에 대한 명명된 개체 인식Named Entity Recognition 수행하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">오디오 데이터에 대한 명명된 개체 인식Named Entity Recognition 수행하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="얼굴 인식을 통해 감정 해독하기" href="/post/2024-06-20-DecodingEmotionswithFacialRecognition"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="얼굴 인식을 통해 감정 해독하기" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-DecodingEmotionswithFacialRecognition_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="얼굴 인식을 통해 감정 해독하기" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">얼굴 인식을 통해 감정 해독하기</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">8<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="파이썬 인터뷰 코딩 문제 및 초보자용 해결책" href="/post/2024-06-20-PythonInterviewCodingQuestionswithSolutionsforBeginners"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="파이썬 인터뷰 코딩 문제 및 초보자용 해결책" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-PythonInterviewCodingQuestionswithSolutionsforBeginners_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="파이썬 인터뷰 코딩 문제 및 초보자용 해결책" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">파이썬 인터뷰 코딩 문제 및 초보자용 해결책</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">5<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="AI 프롬프트 엔지니어링 탐구 수학적 기초와 RAG 방법론" href="/post/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="AI 프롬프트 엔지니어링 탐구 수학적 기초와 RAG 방법론" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="AI 프롬프트 엔지니어링 탐구 수학적 기초와 RAG 방법론" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">AI 프롬프트 엔지니어링 탐구 수학적 기초와 RAG 방법론</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">25<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="콜모고로프-아놀드 네트워크KAN가 인공지능 세계를 영원히 바꿀 것입니다" href="/post/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="콜모고로프-아놀드 네트워크KAN가 인공지능 세계를 영원히 바꿀 것입니다" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="콜모고로프-아놀드 네트워크KAN가 인공지능 세계를 영원히 바꿀 것입니다" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">콜모고로프-아놀드 네트워크KAN가 인공지능 세계를 영원히 바꿀 것입니다</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">6<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="그래프 ML NetworkX 소개" href="/post/2024-06-20-GraphMLintroductiontoNetworkX"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="그래프 ML NetworkX 소개" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="그래프 ML NetworkX 소개" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">그래프 ML NetworkX 소개</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a><a class="PostList_post_item__gAdVi" aria-label="파이파이 앱을 코딩할 때 고려해야 할 13가지를 배운 것들" href="/post/2024-06-20-13ThingsIveLearntToConsiderWhenCodingAFastAPIApp"><div class="PostList_thumbnail_wrap__YuxdB"><img alt="파이파이 앱을 코딩할 때 고려해야 할 13가지를 배운 것들" loading="lazy" width="100" height="100" decoding="async" data-nimg="1" class="PostList_thumbnail__6_oQk" style="color:transparent" src="/assets/img/2024-06-20-13ThingsIveLearntToConsiderWhenCodingAFastAPIApp_0.png"/></div><div class="PostList_text_area__Hzd11"><div class="PostList_profile_area___aTjn"><div class="PostList_profile_image_wrap__tCTuE"><img alt="파이파이 앱을 코딩할 때 고려해야 할 13가지를 배운 것들" loading="lazy" width="20" height="20" decoding="async" data-nimg="1" class="PostList_profile__VGF_a" style="color:transparent" src="/assets/profile.jpg"/></div><span class="writer">Allround Coder</span></div><strong class="PostList_title__loLkl">파이파이 앱을 코딩할 때 고려해야 할 13가지를 배운 것들</strong><div class="PostList_meta__VCFLX"><span class="date">Jun 20, 2024</span><span class="PostList_reading_time__6CBMQ">11<!-- --> min read</span><span class="PostList_bookmark__PCpOK"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" aria-hidden="true"><path d="M6.75 4.5h10.5a.75.75 0 01.75.75v14.357a.375.375 0 01-.575.318L12 16.523l-5.426 3.401A.375.375 0 016 19.607V5.25a.75.75 0 01.75-.75zM16.5 6h-9v11.574l4.5-2.82 4.5 2.82V6z"></path></svg></span></div></div></a></div></div></article><div class="posts_pagination__R_03T"><button type="button" class="page_button -prev">&lt;</button><a class="link" href="/posts/21">21</a><a class="link" href="/posts/22">22</a><a class="link" href="/posts/23">23</a><a class="link" href="/posts/24">24</a><a class="link" href="/posts/25">25</a><a class="link" href="/posts/26">26</a><a class="link" href="/posts/27">27</a><a class="link" href="/posts/28">28</a><a class="link" href="/posts/29">29</a><a class="link" href="/posts/30">30</a><a class="link" href="/posts/31">31</a><a class="link" href="/posts/32">32</a><a class="link" href="/posts/33">33</a><a class="link" href="/posts/34">34</a><a class="link" href="/posts/35">35</a><a class="link" href="/posts/36">36</a><a class="link posts_-active__YVJEi" href="/posts/37">37</a><a class="link" href="/posts/38">38</a><a class="link" href="/posts/39">39</a><a class="link" href="/posts/40">40</a><button type="button" class="page_button -prev">&gt;</button></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"posts":[{"title":"React를 활용하여 접근성 테스팅의 힘을 발휘하세요","description":"","date":"2024-06-20 05:07","slug":"2024-06-20-UnlockthePowerofAccessibleTestingwithReact","content":"\n\n## 포괄적인 사용자 경험을 만들자, 한 번에 한 가지 테스트씩.\n\n![이미지](/assets/img/2024-06-20-UnlockthePowerofAccessibleTestingwithReact_0.png)\n\n테스트; 모든 개발자들이 가장 좋아하는 주제! 때로는 지루해 보일 수 있지만 견고한 테스트 작성은 좋은 소프트웨어 개발의 핵심입니다. 전체 개발자들이 고려해야 할 장치 및 차원이 무한대로 늘어나면서, 원활한 접근성을 보장하는 테스트 작성이 더 중요해졌습니다.\n\n본 문서에서는 리액트에서 테스트 접근성을 우선시하는 몇 가지 간단한 방법을 소개하겠습니다. 특정 라이브러리와 도구를 언급할 때, 일부 기본적인 이해를 전제로 하고 설정/설치 등과 같은 구체적인 세부 사항은 다루지 않겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# React Testing Library\n\n안녕하세요! React에서 테스트하는 데 가장 인기 있는 라이브러리 중 하나인 React Testing Library입니다. 현재 주간 다운로드 수가 900만을 넘습니다. React Testing Library는 React 컴포넌트를 테스트하는 가벼운 솔루션으로 사용자 상호작용 중심의 방법론을 가지고 있습니다. Jest를 사용하는 것을 추천하지만, Mocha와 같은 다른 자바스크립트 테스팅 프레임워크와 함께 사용할 수도 있습니다.\n\n## 쿼리\n\nReact 컴포넌트를 테스트할 때 쿼리는 가장 많이 사용되는 기능 중 하나입니다. 이것은 페이지에서 요소를 찾기위해 호출할 수 있는 방법입니다. 다양한 방법이 있지만, 페이지의 접근 가능한 요소들을 적절하게 테스트하는 데 있어서 모두 동일하지는 않습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 테스트를 예로 들어보겠습니다:\n\n```js\nimport {render, screen} from '@testing-library/react'\n\ntest('로그인이 되어야 합니다', () =\u003e {\n  render(\u003cLoginForm/\u003e)\n  const username = screen.getByTestId('username-input')\n  ...\n}) \n```\n\n여기서는 간단한 로그인 폼 컴포넌트를 테스트하고 있습니다. 사용자명 입력 필드를 가져오기 위해 getByTestId 메서드를 사용했습니다. 이 요소가 페이지에 존재하고 올바른 테스트 ID가 할당되어 있다면 테스트가 정상적으로 실행되고 오류가 발생하지 않을 것입니다. 그러나 사용자가 볼 수 없고(들을 수 없는) 식별자를 사용하기 때문에 접근성에는 최적이지 않습니다.\n\n이제 접근성을 고려한 향상된 버전을 살펴보겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport {render, screen} from '@testing-library/react'\n\ntest('로그인이 되어야 합니다', () =\u003e {\n  render(\u003cLoginForm/\u003e)\n  const username = screen.getByRole('textbox', {name:'Username'})\n  ...\n})\n```\n\n이 예제에서는 getByTestId를 getByRole로 대체했습니다. 또한 요소를 특정하고 해당 요소의 역할 및 관련 이름에 따라 식별할 수 있도록 추가 매개변수를 전달했습니다.\n\n이 접근 방식은 접근성 면에서 훨씬 나아지며, 접근성 트리에 노출된 요소를 쿼리하기 때문에, 보조 기술(스크린 리더 등)이 요소를 인식하고 상호 작용하는 방식과 일치하는 방식으로 테스트를 수행합니다. 따라서 테스트 ID와 같은 것에 액세스할 수 없는 최종 사용자의 더 현실적인 사용자 경험을 시뮬레이션합니다.\n\n요소를 쿼리하기 위한 기본 메소드는 getByRole 메소드여야 합니다. 대부분의 경우에 적합하겠지만, 그렇지 않은 경우를 위해 아래에 우선순위대로 나열한 메소드 목록이 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- getByRole\n- getByLabelText\n- getByPlaceholderText\n- getByText\n- getByDisplayValue\n- getByAltText\n- getByTitle\n- getByTestId\n\n하지만 이러한 다른 메서드 중 하나를 사용하기 전에 구성 요소가 어떻게 작성되었는지 더 깊이 살펴보세요. 역할의 더 나은 사용을 통해 더 접근성이 뛰어난 방식으로 작성할 수 있는 기회가 있을 수도 있습니다.\n\n이러한 메서드와 이들의 우선순위에 관한 자세한 내용은 여기서 확인할 수 있습니다.\n\n## fireEvent vs userEvent\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nReact 컴포넌트를 테스트하는 또 다른 중요한 부분은 사용자 조작을 수행할 수 있는 능력을 갖는 것입니다. React Testing Library에서 이를 달성하는 두 가지 주요 방법은 fireEvent 및 userEvent입니다.\n\n우리가 이전에 했던 테스트를 이어서, fireEvent를 사용한 예제를 먼저 살펴봅시다.\n\n```js\nimport {render, screen, fireEvent} from '@testing-library/react'\n\ntest('로그인해야 합니다', () =\u003e {\n  render(\u003cLoginForm/\u003e)\n  const username = screen.getByRole('textbox', {name:'Username'})\n  fireEvent.change(username, {target: {value: 'michaelscott'})\n})\n```\n\n이제 여기에 또 다른 예제가 있습니다. 이번에는 userEvent를 사용합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport {render, screen} from '@testing-library/react'\nimport userEvent from '@testing-library/user-event'\n\ntest('로그인되어야 함', async () =\u003e {\n  const user = userEvent.setup()\n  render(\u003cLoginForm/\u003e)\n  const username = screen.getByRole('textbox', {name:'Username'})\n  await user.type(username, 'michaelscott')\n})\n```\n\n이 두 가지 방법은 같은 결과를 얻을 수 있지만, 내부적으로는 다르게 작동합니다. 여기에 문서에서 직접 인용한 내용이 있습니다:\n\n이것이 우리의 구성요소가 접근 가능한지 확인하는 능력에 어떤 영향을 미치는지 궁금할 것입니다. fireEvent는 구성요소 내에서 특정 동작을 테스트하는 데 유용할 수 있지만, 특히 보조 기술을 사용하는 사용자들이 구성요소와 상호작용하는 실제 방식을 잘 반영하지 않습니다.\n\n또한, fireEvent를 사용할 때 실제 사용자 상호작용에 트리거되는 모든 부작용을 트리거하지 않을 수도 있다는 점을 고려하는 것이 중요합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n따라서 가능한 경우 userEvent를 사용하고 사용자 조작을 시뮬레이션하는 데 이 방법을 기본값으로 사용하는 것이 좋습니다.\n\n# jest-axe\n\n이 강력한 라이브러리는 axe(접근성 엔진)를 React 테스트에서 쉽게 사용할 수 있게 해줍니다. 본문에서는 일관성을 위해 React Testing Library와 함께 사용하겠지만 다양한 다른 라이브러리와 함께 사용할 수도 있습니다. 추가 자세한 내용은 여기서 찾아볼 수 있습니다.\n\n로그인 양식 예제를 계속 진행할 것이며, 아래에는 쉽게 따를 수 있지만 좋은 접근성 표준을 준수하지 않는 구성 요소의 간단한 버전이 제시되어 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nconst LoginForm = () =\u003e (\n  \u003cform\u003e\n    \u003cinput type=\"text\" /\u003e\n    \u003cinput type=\"password\" /\u003e\n    \u003cbutton type=\"submit\"\u003eLogin\u003c/button\u003e\n  \u003c/form\u003e\n);\n```\n\n이제 jest-axe 라이브러리를 사용하여 이 컴포넌트에 대한 테스트를 만들 수 있습니다:\n\n```js\nimport { render } from '@testing-library/react';\nimport { axe, toHaveNoViolations } from 'jest-axe';\n\ntest('접근성 위반 사항이 없어야 합니다.', async () =\u003e {\n  const { container } = render(\u003cLoginForm /\u003e);\n\n  const results = await axe(container);\n\n  expect(results).toHaveNoViolations();\n});\n```\n\n테스트를 실행하면 다음과 같은 출력이 생성되는데, 입력 필드에 레이블을 추가하는 것을 잊었다는 위반 사항을 식별했습니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-UnlockthePowerofAccessibleTestingwithReact_1.png\" /\u003e\n\n이 간단한 테스트에서 컴포넌트의 접근성 위반 사항을 식별했고, 제안된 변경 사항으로 빠르게 수정할 수 있습니다. 이것은 작은 예시지만 더 복잡한 컴포넌트에서 얼마나 강력한지 보실 수 있습니다.\n\n이 피드백을 통해 컴포넌트를 다음과 같이 개선할 수 있습니다:\n\n```js\nconst LoginForm = () =\u003e (\n  \u003cform\u003e\n    \u003clabel htmlFor=\"username\"\u003e사용자명\u003c/label\u003e\n    \u003cinput type=\"text\" id=\"username\" /\u003e\n    \u003clabel htmlFor=\"password\"\u003e암호\u003c/label\u003e\n    \u003cinput type=\"password\" id=\"password\" /\u003e\n    \u003cbutton type=\"submit\"\u003e로그인\u003c/button\u003e\n  \u003c/form\u003e\n);\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기에 접근성을 더 높일 수 있는 다른 여러 방법이 있음을 언급하는 것이 중요합니다. 예를 들어 스타일링, 양식 유효성 검사, 추가 ARIA 속성 등이 있습니다. 그러나 이것은 단지 라이브러리의 강점을 보여주고 컴포넌트의 기초를 쉽게 강화할 수 있는 작은 예시일 뿐입니다.\n\n# Storybook에서의 접근성\n\nStorybook은 UI 컴포넌트 및 페이지를 독립적으로 작성하는 데 널리 사용되는 라이브러리입니다. Storybook은 능력을 향상시킬 수 있는 멋진 애드온도 가지고 있습니다. 그 중 하나가 storybook-addon-a11y인데, 이 애드온은 컴포넌트 내의 접근성 위반 사항을 보여줍니다. 마치 jest-axe가 하는 것과 유사합니다.\n\nStorybook 구성에 이 애드온을 추가함으로써 시작할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nconst config: StorybookConfig = {\n  addons: [\n    '@storybook/addon-a11y',\n  ],\n};\nexport default config;\n```\n\n그런 다음 Storybook 환경을 시작하면 활성화성 탭이 나타나며, 여기에서 위반 사항 및 통과 사항을 볼 수 있습니다. 다소 접근하기 어려운 로그인 양식의 경우 아래 이미지와 유사한 모습이 될 것입니다.\n\n![이미지](/assets/img/2024-06-20-UnlockthePowerofAccessibleTestingwithReact_2.png)\n\n![이미지](/assets/img/2024-06-20-UnlockthePowerofAccessibleTestingwithReact_3.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이는 구성 요소가 접근성 면에서 목적에 적합한지 확인하는 또 다른 강력한 방법입니다. 특히 이미 시각 테스트용으로 Storybook을 사용 중이라면 이것은 아주 좋은 추가 기능이 될 수 있습니다.\n\n# 결론\n\nReact 애플리케이션에 접근성 테스트를 점진적으로 통합하는 여러 가지 방법 중 일부만 강조했습니다. 이것은 시작점으로 작용하고 더 나은 발전을 위한 견고한 기반을 구축하는 데 도움이 될 것입니다.\n\n이 방법이 애플리케이션이 100% 접근 가능하다고 확신할 수 있는 방법은 아닙니다. 가능하다면 실제 사용자가 사용하는 접근성 기술로 소프트웨어를 테스트해 보는 것이 좋습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n읽어주셔서 감사합니다 😊","ogImage":{"url":"/assets/img/2024-06-20-UnlockthePowerofAccessibleTestingwithReact_0.png"},"coverImage":"/assets/img/2024-06-20-UnlockthePowerofAccessibleTestingwithReact_0.png","tag":["Tech"],"readingTime":7},{"title":"프론트엔드 엔지니어를 위한 아마존 전화 인터뷰 경험","description":"","date":"2024-06-20 05:06","slug":"2024-06-20-AmazonPhoneInterviewExperienceforFront-EndEngineer","content":"\n\n프론트엔드 엔지니어 포지션(4-5년 경력)에 지원했어요. 인터뷰는 행동 질문, 프론트엔드 질문 및 역 인터뷰 세 가지 부분으로 나뉘었어요.\n\n## 행동 질문\n\n- 자기 소개해주실래요?\n- 기대 이상으로 노력한 적이 있나요?\n- 어떻게 하면 업무 효율성을 향상시키는지 알려주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 프론트엔드 질문\n\n- 제게 다음 그림이 주어졌고 사용자 인터페이스를 개발하고 해당 기능을 구현하라는 요청을 받았습니다.\n\n![이미지](/assets/img/2024-06-20-AmazonPhoneInterviewExperienceforFront-EndEngineer_0.png)\n\n인터뷰어는 위 그림을 구현해 달라고 했습니다. \"Language Name\" 및 \"Language Content\"를 제공하는 데이터를 가져오는 API 엔드포인트가 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n탭을 클릭하면 콘텐츠가 변경되고 활성화된 탭이 강조 표시되어야 합니다.\n\n면접관은 API 엔드포인트에서 전송되는 데이터 구조를 상상할 수 있도록 했다.\n\n## 역면접\n\n- Amazon에서 자랑스러워하는 프로젝트는 무엇인가요?\n- Amazon에서 주니어 개발자에서 시니어 개발자가 되기까지 어떻게 되었나요?\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 내 생각들\n\n- 다음 라운드에 진출하지 못해 전화 인터뷰 라운드에서 거절당했습니다.\n- 되돌아보면 인터뷰는 간단했지만, 제가 최선을 다할 만큼 충분히 준비되지 않은 느낌입니다.\n- 제가 잘못했다고 믿는 곳은 '행동 질문'입니다.\n- 그리고 '프런트엔드 질문'에 관해서는, 인터뷰 이전에 전적으로 확신하지 못했습니까? 어떤 종류의 질문이 있을지 약간의 두려움이 들었습니다. 프런트엔드나 Leetcode 스타일 질문에 초점을 맞출지에 대해요.\n- 모든 프런트엔드 개발자들에게, 어떤 질문이 나오고 인터뷰에서 어떤 유형의 질문에 초점을 맞출지에 대한 감을 제대로 잡는 것은 이상한 느낌입니다. 그러나 인터뷰 방식이 향상되고 많은 프런트엔드 중심의 인터뷰가 보여지고 있다는 것에 대해서 말이죠.\n\n다음 인터뷰에서 좋은 결과 있길 바랍니다. 만약 이 게시물이 인터뷰 준비에 도움이 되었다면 👏 와 팔로우 🚶‍♂️를 남겨주세요.","ogImage":{"url":"/assets/img/2024-06-20-AmazonPhoneInterviewExperienceforFront-EndEngineer_0.png"},"coverImage":"/assets/img/2024-06-20-AmazonPhoneInterviewExperienceforFront-EndEngineer_0.png","tag":["Tech"],"readingTime":2},{"title":"공포 주도 개발","description":"","date":"2024-06-20 05:05","slug":"2024-06-20-FearDrivenDevelopment","content":"\n\n\"Why Frontend Tech Choices Are Not Only Driven By Merit?\n\n어떻게 프론트엔드 프레임워크나 라이브러리를 선택하시나요?\n\n사실은, 프론트엔드 비즈니스는 매우 무자비한 곳이에요:\n\n계속해서 변화에 대해 인식하고 적절한 시점에 말을 바꾸지 않으면, 죽거나 거의 움직이지 않는 말과 함께 측면에 남게 될 수도 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"헛소리!\"라고 말할 수 있겠죠... 하지만 저는 여러분이 이야기 속에 있는 것일 수도 있기 때문에 무서운 이야기를 하나 들려드리겠습니다:\n\n\u003cimg src=\"/assets/img/2024-06-20-FearDrivenDevelopment_0.png\" /\u003e\n\n안녕하세요, Tikal의 기술 리더인 Roy Kass입니다. 프론트엔드 산업에서 16년 이상의 경험이 있습니다.\n\n옛날 옛적에, 프론트엔드 산업이 매우 어렸던 때, 아름다운 기술인 Adobe Flex가 있었습니다.\nFlex는 Flash 인프라 위에서 동작하는 화려한 기술이었는데, 브라우저에 설치하여 작동하는 벡터 드로잉 플러그인을 사용했습니다. 가장 유명한 3버전은 2007년에 소개되었고, 그것은 혁명이었습니다. Flex는 가상 스크롤링, 동적 라이브러리, 전체 정적 타이핑 및 컴파일 중 트리 쉐이킹과 같은 이전에 존재하지 않았던 다양한 기능들을 소개했습니다. Flex 개발자들은 산업에서 가장 소중한 자산이었죠. 그러나 그의 종주인 스티브 잡스, 애플의 CEO가 Adobe Flash 플러그인을 iOS 하드웨어에서 허용하지 않겠다는 편지를 써서 이 모든것이 바뀌었습니다. 결과적으로, Adobe는 Flex를 커뮤니티에 전달했고(이름은 \"Apache Flex\"로 변경되었습니다) 플러그인은 프로프리에터리로 유지했습니다. 이는 그 기술의 버려짐을 의미했습니다. 2012년, 기술이 쇠퇴의 길을 걷고 있다는 사실이 명확해졌습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nFlex에 대한 높은 관심을 받던 개발자들이 AngularJS와 같은 다른 기술로 전환해야 했어요.\n\n이 모든 걸 어떻게 알게 되었냐구요? 제가 그 Flex 개발자 중 한 명이었거든요. Flex에서 HTML5 및 AngularJS로 이동하는 것은 힘든 일이었어요.\n\n\"하지만, 그건 한 가지 사례 뿐이잖아요!\" 라고 말할 수도 있겠죠.\n\n음, 이런 일이 또 일어난 건 AngularJS에서 Angular 2로의 이동 때도 있었어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAngularJS가 어느 정도로 느려지고 낡아졌을 때가 오게 되었습니다. 구글은 breaking changes가 있는 Angular 2를 만들었습니다. 여러분은 그 이동을 하는 데 시간을 투자할지, 다른 기술(예: React)을 찾을지, 아니면 쇠말에 머물러있는 대가를 치를지를 결정해야 했습니다.\nAngularJS에 오래 머무른 회사가 많았는데, 그 결과 아주 늦은 시간에 기술 전환이 이루어진 엄청난 노력을 하게 되었죠. 머무르는 것은 어렵기만 한 게 아니었어요 — 기술이 폐기된 상태여서 보안 리스크가 발생했습니다.\n\n그리고 얼마 지나지 않아, Angular 2(이젠 몇 버전 앞으로 나가 있는)가 시장에서 소멸하기 시작했습니다. 선택의 실수(예를 들면 매우 오랜 베타로 인한 버그와 성능 저하, 많은 breaking changes, 그리고 블랙 박스 형태의 복잡함) 때문이었습니다.\n\n곧, React가 시장을 석권했습니다. 대다수의 회사들이 React를 사용하고 있었죠.\n\nReact가 배우고 사용하기 더 간단하다는 이유 때문이라고 주장하는 사람들도 있습니다. Angular 애호가들은 더 구조화된 프레임워크가 필요한 대형 규모의 프로젝트에서 실패한다고 말할 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그것은 중요하지 않았어요 — 왜냐면 결국 Meta(React)가 올바른 정치 결정들을 내려 시장에서 승리했기 때문이었어요. React와 Angular 중 뭘 선택할지에 대한 토론은 시간이 지남에 따라 사그라들었고, React가 즐겨찾기가 되었어요. Angular는 아직 살아있지만, 커뮤니티 크기는 React보다 훨씬 작아졌어요.\n\n그리고 이 글을 읽으면서 머리를 흔드는 모든 Angular 팬 여러분들께 — 저도 예전에 당신들 중 한 명이었기 때문에 정말 동정합니다.\n\n저는 JQuery, Ember, Haxe, CoffeeScript와 같은 기술들에 대해 언급하지도 않았는데, 이들도 비슷한 길을 걸어왔다는 것을 말씀드리고 싶어요. 그것들이 정말 수많다는 것을 기억해주세요.\n\n최종적으로, 이러한 프론트엔드 기술들은 오픈 소스입니다. 이는 만약 커뮤니티의 관심을 잃는다면, 지원이 줄어든다는 것을 의미해요. 토론은 더 인기 있는 라이브러리들로 방향을 전환할 것이에요. 여러분의 지식들은 새 달의 우물처럼 말라버릴 거에요. 마침내 업데이트를 받지 못할 뿐만 아니라 보안 문제도 발생할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n그리고 — 보다 인기 있는 기술에 대해서 높은 자격을 갖춘 인력을 채용하는 것이 훨씬 쉽습니다.\n\n![FearDrivenDevelopment_1](/assets/img/2024-06-20-FearDrivenDevelopment_1.png)\n\n프론트엔드 기술은 오래가지 않습니다. 시기를 맞추거나 큰 대가를 치르게 될지도 모릅니다.\n\n리액트는 이런 면에서 어딘가 이상한 존재이며, 곧 코쿤에 들어가 다음JS로 부활할 것입니다 (이에 관한 더 많은 정보는 다음 기사에서 소개될 예정입니다).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제가 이 상황을 좋아하지 않는다는 것을 말씀드릴 필요가 있습니다. 이것은 기술의 장점에 대한 냉정한 토론에서 인기로 물을 끓게 하는 선택으로 이어진다는 점이 제게 중요합니다. 일부 인기가 없는 기술은 그들의 능력만을 고려할 때 더 나은 선택일 수 있습니다. 또한 이 주제가 얼마나 논란이 많은지 이해하고 있습니다.\n\n하지만 — 이 \"공포로 이끌리는 선택\"이라는 것이 프론트엔드 분야가 15년 이상 진화해 온 방식입니다. 이를 다르게 하려면 매우 중요한 변화가 필요하며, 그 동안 이러한 고려를 주요하게 여겨야 합니다.\n\n# 그렇다면 기술의 인기를 어떻게 확인할까요?\n\n먼저, NPM Trends 웹사이트로 가서 관심 있는 기술을 해당 분야의 경쟁 상대와 비교해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, React, Angular 및 Vue를 테스트해 보겠습니다. 2022년 말에 Vue에 이상한 \"불일치\"가 있어서 무시할 필요가 있습니다. 아마 버그인 것 같아요.\n\n![그림](/assets/img/2024-06-20-FearDrivenDevelopment_2.png)\n\n그래프를 보면 React가 다운로드 측면에서 Vue와 Angular보다 훨씬 앞서 있다는 것을 알 수 있습니다. 이는 사용 범위를 파악하는 데 좋은 KPI입니다.\n\n이제 GitHub 통계를 비교해 봅시다:\nReact:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Angular](/assets/img/2024-06-20-FearDrivenDevelopment_3.png)\n\n![Vue(core)](/assets/img/2024-06-20-FearDrivenDevelopment_4.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-06-20-FearDrivenDevelopment_5.png)\n\n패턴을 볼 수 있나요?\n리액트는 다른 2개와 합친 것보다 훨씬 더 많은 트래픽을 갖고 있습니다. 더 많은 사람들이 관심을 가지고 있고, 별표를 찍고, 관심을 갖고 있습니다!\n\n더 흥미로운 체크 방법은 최근 커밋이 언제, 어디서 이루어졌는지 보는 것입니다 (왜 그런지까지).\n\n이것은 새로운 코드가 라이브러리에 삽입되었는지, 아니면 실제로 정체되어 있는지 보는 좋은 테스트입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nReact:\n\n![React](/assets/img/2024-06-20-FearDrivenDevelopment_6.png)\n\nAngular:\n\n![Angular](/assets/img/2024-06-20-FearDrivenDevelopment_7.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# Vue:\n\n![FearDrivenDevelopment](/assets/img/2024-06-20-FearDrivenDevelopment_8.png)\n\n우리가 원하는 최상의 경우는 몇 일 이내입니다. 몇 주에서 최대 1~3개월 정도면 받아들일 수 있습니다. 하지만, 4개월 이상이 보인다면, 이 라이브러리의 유지보수에 문제가 있는 것을 의미합니다.\n\n이 경우, 모두가 최근 커밋에 따르면 (1~2일 전), 반응(React)이 다른 모든 측면에서 인기를 이끌고 있다는 것은 명확합니다. Vue와 Angular보다 인기가 더 많다는 것을 알 수 있습니다.\n그런데, 모든 면에서 절대로 더 나은 것을 의미합니까? 아닙니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n하지만 주요 고려 사항 인가요? 프론트엔드 세계에서는 — 대답은 반가운 YES 입니다.\n\n프론트엔드 기술을 검토할 때, 구성 요소 라이브러리 시스템이나 심지어 단일 구성 요소와 같이 작은 것들도 선택한 것이 가능한 살아있고 인기있는 것인지 확인하세요.\n\n인기도가 프론트엔드 기술의 생존과 지속 가능성에 대한 주요 KPI로 남아 있는 한, 기술을 선택할 때 이는 주요 고려 사항이어야 합니다.\n\n죽거나 쇠약한 말은 당신을 멀리 몰아가지 않으므로 가장 활발한 것을 선택하세요 — 그리고 인기 순위에서 2위 또는 3위에 근접해 있으면 주기적으로 활발성과 인기도를 확인하세요. 이것은 궁극적으로 교육된 내기일 뿐이라고 하더라도, 가끔은 갑작스러운 변화가 발생할 수 있습니다. 단지 그러한 변화에 대해 경계를 지켜야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 기사에서는 왜 NextJS가 여러분이 선택해야 할 다음 필수 도구일 수 있는지 보여드릴게요.\n\n![Image](/assets/img/2024-06-20-FearDrivenDevelopment_9.png)","ogImage":{"url":"/assets/img/2024-06-20-FearDrivenDevelopment_0.png"},"coverImage":"/assets/img/2024-06-20-FearDrivenDevelopment_0.png","tag":["Tech"],"readingTime":6},{"title":"오디오 데이터에 대한 명명된 개체 인식Named Entity Recognition 수행하기","description":"","date":"2024-06-20 05:02","slug":"2024-06-20-PerformingNamedEntityRecognitiononAudioData","content":"\n\n![이미지](/assets/img/2024-06-20-PerformingNamedEntityRecognitiononAudioData_0.png)\n\n이 Deepnote Notebook에서이 문서에 대한 코드를 찾을 수 있습니다.\n\nNamed Entity Recognition (또는 NER)은 주어진 정보에서 실제 세계 개체를 식별하는 작업으로 정의됩니다. NER은 자연어 처리 (NLP) 기술을 사용하여 해결되는 기계 학습에서 인기있는 작업입니다. 텍스트 데이터의 경우, 목적은 주어진 텍스트를 이해하고 실제 세계 개체를 참조하는 단어를 식별하고 추출할 수 있는 모델을 교육하는 것입니다. 이러한 실제 세계 개체는 Named Entities로도 불립니다.\n\nNER 시스템의 고수준 개요는 아래 이미지에 표시되어 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](/assets/img/2024-06-20-PerformingNamedEntityRecognitiononAudioData_1.png)\n\n자연어 처리(NLP) 연구 커뮤니티에서는 텍스트 데이터에 대한 NER에 대해 다양한 접근 방식을 제안해 왔습니다. 이 도메인에서 가장 많이 실험된 데이터셋은 CoNLL 2003과 OntoNotes 데이터셋입니다. 그러나 최근에는 음성 기반 상호 작용 도구의 널리 퍼진 채택으로 인해 연구자와 기관들이 음성 공간에서 NER 시스템을 탐구하고 구축하는 모습을 볼 수 있었습니다.\n\n따라서 본 게시물에서는 AssemblyAI API 및 Python을 사용하여 음성 데이터에서 Named Entity Recognition 시스템을 구축하는 방법을 보여드리겠습니다. 이 통합 시스템은 엄격한 언어 이해, 요약 및 키워드 추출에 광범위하게 적용되며 특히 음성 도메인에서 해결해야 할 중요하고 가치 있는 문제로 여겨집니다. 이 게시물을 종합분석하여 얻은 결과를 해석하고 데이터로부터 적절한 통찰을 얻을 수 있도록 하겠습니다.\n\n이 게시물에 대한 코드는 여기에서 찾을 수 있습니다. 게시물의 하이라이트는 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n오디오 데이터의 엔터티 탐지\n엔터티 탐지 결과\n엔터티 탐지 인사이트\n\n시작해 봅시다 🚀!\n\n# 오디오 데이터의 엔터티 탐지\n\n이 섹션에서는 미리 녹음된 오디오 파일에서 명명된 엔터티를 식별하고 추출하기 위해 AssemblyAI API를 사용하는 방법을 보여드리겠습니다. 더 나아가, 추출된 엔터티는 \"런던\"과 같이 위치로 분류되는 방식과 유사하게 개인, 위치, 조직, 날짜, 이벤트, 직업 등과 같은 해당 엔터티 클래스로 분류될 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-PerformingNamedEntityRecognitiononAudioData_2.png\" /\u003e\n\n## 단계 1: 요구 사항 설치\n\n어셈블리AI API를 로컬 머신에서 호출하고 entity detection 모듈 및 entity classifier를 빌드하려면 Python의 requests 패키지가 필요합니다. 다음과 같이 설치할 수 있습니다:\n\n```js\r\npip install requests\r\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 단계 2: API 토큰 생성하기\n\n다음 단계는 AssemblyAI의 음성 대 텍스트 모델에 액세스하기 위한 API 키를 받는 것입니다. 무료로 AssemblyAI 웹 사이트에서 계정을 만들어 이 작업을 수행할 수 있습니다.\n\n## 단계 3: 오디오 파일 업로드\n\n전사 및 명명된 엔티티를 추출할 오디오 파일은 URL을 통해 액세스할 수 있어야 합니다. 따라서 음성 대 텍스트 모델을 호출하기 전에 오디오 파일을 파일 호스팅 서비스에 업로드해야 합니다. 옵션으로는 AWS S3 버킷, SoundCloud와 같은 오디오 호스팅 서비스, 그리고 AssemblyAI의 자체 호스팅 서비스 등이 있습니다. 이번 튜토리얼에서는 오디오 파일을 SoundCloud에 업로드했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 단계 4: Entity 감지 및 분류 수행하기\n\n이제 이 단계에서 오디오 파일에서 엔티티를 감지하기 위한 모든 필수 사전 요구사항을 충족했습니다. 이제 API를 호출하여 명명된 엔티티를 추출할 수 있습니다. 이는 아래 절에서 보다 상세히 설명한 두 단계 프로세스입니다.\n\n## 단계 4.1: 전사를 위해 파일 제출하기\n\n첫 번째 단계는 HTTP Post 요청을 사용하여 음성 파일을 트리거하여 텍스트 모델을 활성화하는 것입니다. POST 요청은 오디오 파일을 audio_url로 사용하고 entity_detection 플래그를 사용하여 명명된 엔티티 인식을 수행하도록 모델에 지시합니다. 오디오 파일에는 여러 화자가 포함되어 있기 때문에 speaker_labels 플래그를 True로 설정했습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n수신된 JSON 응답에 따르면, 포스트 요청의 상태가 대기 중인 것을 나타내며, 파일이 전사 대기열에 있는 것을 의미합니다.\n\n뿐만 아니라, JSON 응답에 entity_detection 플래그도 True인 것으로 나타납니다. 그러나 entities 키에 해당하는 값은 현재 대기 중인 상태이기 때문에 None입니다.\n\n## 단계 4.2: 전사 결과 가져오기\n\n우리의 POST 요청 상태를 확인하고 전사 결과를 보려면, 위에서 수신한 JSON 응답의 id 키를 사용하여 GET 요청을 해야 합니다. 우리는 POST 요청에서 받은 response_id를 전사 상태를 확인하기 위해 전달합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# Entity Detection Results\n\n상태가 완료로 변경되면 아래와 유사한 응답을 받게 됩니다.\n\n- JSON 응답에서 상태를 완료로 확인합니다. 이는 오디오의 정상적인 전사를 나타냅니다.\n- 텍스트 키에는 스피커 수준의 구분 없이 입력 오디오 파일의 전사가 문자열로 포함됩니다. 총 문장 수는 12개입니다.\n- 오디오 파일은 여러 목소리로 구성되어 있기 때문에 단어 키 내에서 모든 스피커 키를 Not Null로 볼 수 있습니다. 스피커 키는 \"A\" 또는 \"B\"입니다.\n- 확신 점수는 모델이 개별 단어와 전체 전사 텍스트를 전사하는 데 대한 확신도를 나타냅니다. 이는 0에서 1까지의 범위로, \"0\"이 가장 낮고 \"1\"이 가장 높습니다.\n- 오디오의 각각의 12개 문장에서 감지된 엔터티에 액세스하려면 JSON 응답의 entities 키를 사용할 수 있습니다.\n- 오디오 파일에서 식별된 엔터티 수는 17개입니다.\n- 각 엔터티에 대응하여 감지된 엔터티의 카테고리를 나타내는 entity_type을 얻을 수 있습니다.\n\n# Entity Detection Insights\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nJSON은 일반적으로 읽고 해석하기 어려운 편이기 때문에, 위의 엔티티 감지 결과를 DataFrame으로 변환하여 데이터를 시각적으로 보기 좋게 만들 수 있습니다. 이렇게 하면 추가적인 분석을 효과적으로 수행하는 데 도움이 될 것입니다. 우리는 텍스트, 문장의 지속 시간, 화자, 그리고 문장의 엔티티 수를 저장할 것입니다. 이를 아래 코드로 구현하였습니다:\n\n위의 코드 스니펫으로 생성된 DataFrame은 아래 이미지에 나와 있습니다. 여기에는 오디오 파일에서 발화된 12개의 문장이 포함되어 있고, 해당 화자 레이블(\"A\" 및 \"B\"), 문장의 지속 시간(초), 그리고 문장의 엔티티 수를 나타내는 필드가 포함되어 있습니다.\n\n![DataFrame](/assets/img/2024-06-20-PerformingNamedEntityRecognitiononAudioData_3.png)\n\n다음으로, 오디오 파일에서 식별된 엔티티를 취하는 또 다른 DataFrame을 생성합니다. 이는 아래의 코드 블록을 따라 구현되었습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-PerformingNamedEntityRecognitiononAudioData_4.png\" /\u003e\n\n## #1 Speaker-Sentence distribution\n\n먼저, 오디오 파일에서 각 화자가 말한 문장의 수를 계산해 봅시다. 아래와 같이 value_counts() 메서드를 사용하여 이 작업을 수행할 수 있습니다.\n\n각 화자의 분포를 백분율로 표시하려면 value_counts() 메서드에 normalize=True를 전달하면 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## #2 발화자별 시간 분포\n\n이제 개별 발화자들의 총 발화 시간을 찾아봅시다. 아래에서 확인할 수 있습니다:\n\ngroupby() 메서드를 사용하여 개별 문장의 지속 시간을 합산하여 총 지속 시간을 계산합니다. 발화자 \"B\"가 지속 시간 측면에서 우세한 발화자입니다.\n\n## #3 발화자 엔터티-카운트 분포\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n오디오 파일에서 총 17개의 엔티티가 언급되었는데, 그 중 9개는 \"A\" 스피커에 의해 발화되었고 나머지는 \"B\" 스피커가 발화했습니다.\n\n## #4 엔티티 유형 분포\n\n다음으로, 오디오 파일에서 발화된 개별 엔티티 유형의 분포를 분석해 보겠습니다. 아래에서 value_counts() 메서드를 사용하여 이를 구현했습니다:\n\n## #5 스피커-엔티티 유형 분포\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n마지막으로, 각 화자가 말한 각 Entity 유형의 수를 평가해 봅시다. 여기서는 groupby() 메소드 대신 시각화를 위해 crosstab()을 사용할 것입니다. 아래에서 이를 보여드리겠습니다:\n\n이렇게 말씀드리면, 이 게시물에서는 AssemblyAI API를 사용하여 사전 녹음된 오디오 파일에서 Named Entity Recognition 모듈을 구축했습니다. 마지막으로, 감지된 Entity들에 대한 철저한 분석을 수행했습니다. API에서 얻은 결과는 입력 오디오 파일의 12개 개별 문장 내에서 식별된 17개 Entity를 강조했습니다.\n\n독서해 주셔서 감사합니다!\n\n🚀 내 매일 뉴스레터를 구독하시면 550페이지 이상의 무료 데이터 과학 PDF와 320편 이상의 게시물을 받아 보실 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"https://miro.medium.com/v2/resize:fit:1400/0*gtA9qrsOn5ZsnBXW.gif\" /\u003e\n\nDataDrivenInvestor.com에서 저희를 방문해주세요.\n\nDDIntel을 여기서 구독하세요.\n\n주요 기사:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n우리의 창조자 생태계에 참여해보세요.\n\nDDI 공식 텔레그램 채널: [https://t.me/+tafUp6ecEys4YjQ1](https://t.me/+tafUp6ecEys4YjQ1)\n\nLinkedIn, Twitter, YouTube, 그리고 Facebook에서 팔로우해주세요.","ogImage":{"url":"/assets/img/2024-06-20-PerformingNamedEntityRecognitiononAudioData_0.png"},"coverImage":"/assets/img/2024-06-20-PerformingNamedEntityRecognitiononAudioData_0.png","tag":["Tech"],"readingTime":6},{"title":"얼굴 인식을 통해 감정 해독하기","description":"","date":"2024-06-20 05:00","slug":"2024-06-20-DecodingEmotionswithFacialRecognition","content":"\n\n\u003cimg src=\"/assets/img/2024-06-20-DecodingEmotionswithFacialRecognition_0.png\" /\u003e\n\n인간의 감정을 얼굴 표현을 통해 이해하는 것은 우리에게 자연스러운 기술이지만, 컴퓨터에게 같은 기술을 가르치는 것은 어렵게 느껴질 수 있습니다. 다행히도, 적절한 도구와 조금의 코딩을 통해 이를 실현할 수 있습니다. 이 글에서는 Python을 사용하여 감정 감지를 위한 얼굴 표현 인식을 구현하는 두 가지 방법을 탐구해 보겠습니다: DeepFace를 사용하는 방법과 Keras를 활용한 합성곱 신경망(CNN)을 사용하는 방법\n\n# 1.) Deepface 사용\n\nDeepface는 파이썬용 경량 얼굴 인식 및 얼굴 속성 분석(나이, 성별, 감정 및 인종) 프레임워크입니다. DeepFace를 몇 줄의 코드로 실행할 수 있지만, 그 뒤의 모든 과정에 대해 깊이 있는 지식을 습득할 필요가 없습니다. 사실, 라이브러리를 가져오고 정확한 이미지 경로를 입력으로 전달하기만 하면 됩니다; 그게 전부입니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n1.) .py 파일로 필요한 모듈 가져오기\n\n```js\nfrom deepface import DeepFace\nimport cv2\n```\n\n2.) 얼굴 캐스케이드 분류기 로드\n\n이 명령은 전면 얼굴 검출 모델과 함께 CascadeClassifier 객체를 초기화합니다. 그 결과인 face_cascade 객체를 사용하여 이미지에서 얼굴을 감지할 수 있습니다. Haar Cascade는 파이썬의 OpenCV 라이브러리를 사용하여 쉽게 구현할 수 있는 얼굴 검출을 위한 인기 있는 알고리즘입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\nface_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\r\n```\r\n\r\n3.) 비디오 스트림을 시작하고 분류기를 실행합니다.\r\n\r\n0은 기본 카메라를 나타냅니다. 외부 웹캠을 연결한 경우 1을 입력하세요.\r\n\r\n```js\r\ncap = cv2.VideoCapture(0)\r\n\r\nwhile True:\r\n    # 성공 또는 실패 여부를 나타내는 부울 값인 ret 및 캡쳐된 프레임인 frame을 캡쳐합니다.\r\n    ret, frame = cap.read()\r\n\r\n    # 프레임을 그레이스케일로 변환합니다.\r\n    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\r\n\r\n    # 그레이스케일 프레임을 RGB 형식으로 변환합니다.\r\n    rgb_frame = cv2.cvtColor(gray_frame, cv2.COLOR_GRAY2RGB)\r\n\r\n    # 프레임에 얼굴을 감지합니다.\r\n    faces = face_cascade.detectMultiScale(gray_frame, scaleFactor=1.1, minNeighbors=10, minSize=(30, 30))\r\n\r\n    for (x, y, w, h) in faces:\r\n        # RGB 프레임에서 y에서 y+h, x에서 x+w까지의 영역에서 얼굴 ROI(관심 영역)를 추출합니다.\r\n        face_roi = rgb_frame[y:y + h, x:x + w]\r\n\r\n        # DeepFace를 사용하여 얼굴 ROI에서 감정 분석을 수행합니다.\r\n        result = DeepFace.analyze(face_roi, actions=['emotion'], enforce_detection=False)\r\n\r\n        # 주요 감정을 결정합니다.\r\n        emotion = result[0]['dominant_emotion']\r\n\r\n        # 얼굴 주위에 직사각형을 그리고 예측된 감정과 함께 레이블을 붙입니다.\r\n        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\r\n        cv2.putText(frame, emotion, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\r\n\r\n    # 결과 프레임을 표시합니다.\r\n    cv2.imshow('실시간 감정 감지', frame)\r\n\r\n    # 종료하려면 'q'를 누르세요.\r\n    if cv2.waitKey(1) \u0026 0xFF == ord('q'):\r\n        break\r\n\r\n# 캡처를 해제하고 모든 창을 닫습니다.\r\ncap.release()\r\ncv2.destroyAllWindows()\r\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음 링크에서 haarcascade 파일을 다운로드할 수 있어요 — https://github.com/opencv/opencv/blob/4.x/data/haarcascades/haarcascade_frontalface_default.xml\n\n카스케이드 분류기에 대해 더 읽어보고 싶다면 -https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html\n\n.py 파일과 haarcascade_frontalface_default.xml 파일을 동일한 폴더에 넣고 .py 파일을 실행해주세요. 모두 잘 작동되면, 카메라 스트림이 보이는 외부 창에 감정이 표시될 거예요!\n\n# 2.) Keras를 이용한 합성곱 신경망\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n합성곱 신경망(Convolutional Neural Networks)은 이미지 처리에 사용되는 피드 포워드 네트워크의 일종입니다. 이러한 네트워크는 일반적인 완전 연결 레이어에 추가적인 합성곱(Convolutional) 및 풀링(Pooling) 레이어를 특징으로 합니다. 주로 그리드(grid) 형식의 데이터(이미지, 비디오)와 함께 작동합니다.\n\n- https://www.kaggle.com/datasets/msambare/fer2013 에서 FER-2013 데이터셋을 다운로드하세요. 훈련 및 테스트 디렉토리를 'data'라는 공통 폴더 아래에 넣으세요.\n- .py 파일에 필요한 모듈을 가져오세요\n\n```python\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import models, layers\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\nimport os\n```\n\n3. 동일한 파일에서 모델을 구축하고 훈련시키세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ntrain_data_dir='data/train/'\nvalidation_data_dir='data/test/'\n\ntrain_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=30,\n    shear_range=0.3,\n    zoom_range=0.3,\n    horizontal_flip=True,\n    fill_mode= 'nearest')\nvalidation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_data_dir,\n    color_mode='grayscale',\n    target_size=(48, 48),\n    batch_size=32,\n    class_mode='categorical' ,\n    shuffle=True)\n\nvalidation_generator = validation_datagen.flow_from_directory(\n    validation_data_dir,\n    color_mode='grayscale',\n    target_size=(48, 48),\n    batch_size=32,\n    class_mode='categorical',\n    shuffle=True)\n\nclass_labels=['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\nimg, label = train_generator.__next__()\n\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48,48,1)))\nmodel.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout (0.1))\nmodel.add (Conv2D(128, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add (Dropout(0.1))\nmodel. add (Conv2D(256, kernel_size=(3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel. add(Dropout(0.1))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout (0.2))\nmodel. add(Dense(7, activation='softmax'))\n\nmodel.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\nprint(model.summary())\n\ntrain_path = \"data/train\"\ntest_path = \"data/test\"\nnum_train_imgs = 0\nfor root, dirs, files in os.walk(train_path):\n    num_train_imgs += len(files)\nnum_test_imgs = 0\nfor root, dirs, files in os.walk(test_path):\n    num_test_imgs += len(files)\n\nprint(\"Number of training images: \", num_train_imgs)\nprint(\"Number of testing images: \", num_test_imgs)\n\nmodel.fit(train_generator, steps_per_epoch=num_train_imgs//32, epochs=50, validation_data=validation_generator, validation_steps=num_test_imgs//32)\n\nmodel.save('model.h5')  \n```\n\n모델.h5 파일이 현재 디렉토리에 저장됩니다.\n\n4. 테스트\n\n```js\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nmodel=tf.keras.models.load_model('model.h5')\n\nfaceDetect=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n\nvideo=cv2.VideoCapture(0)\n\nlabels_dict={0:'Angry',1:'Disgust', 2:'Fear', 3:'Happy',4:'Neutral',5:'Sad',6:'Surprise'}\n\nwhile True:\n    ret,frame=video.read()\n    gray=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n    faces= faceDetect.detectMultiScale(gray, 1.3, 3)\n    for x,y,w,h in faces:\n        sub_face_img=gray[y:y+h, x:x+w]\n        resized=cv2.resize(sub_face_img,(48,48))\n        normalize=resized/255.0\n        reshaped=np.reshape(normalize, (1, 48, 48, 1))\n        result=model.predict(reshaped)\n        label=np.argmax(result, axis=1)[0]\n        print(label)\n        cv2.rectangle(frame, (x,y), (x+w, y+h), (0,0,255), 1)\n        cv2.rectangle(frame,(x,y),(x+w,y+h),(50,50,255),2)\n        cv2.rectangle(frame,(x,y-40),(x+w,y),(50,50,255),-1)\n        cv2.putText(frame, labels_dict[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n        \n    cv2.imshow(\"실시간 감정 인식\",frame)\n    k=cv2.waitKey(1)\n    if k==ord('q'):\n        break\n\nvideo.release()\ncv2.destroyAllWindows()\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해당 파이썬 스크립트를 실행해보세요. 코드가 동작할 것을 기대합니다!\n\n# 개선 사항\n\n이 코드에 주의를 집중시키기 위해 Spatial Transformer의 추가를 활용할 수도 있습니다. 해당 내용은 논문에 언급되어 있습니다.\n\nDeep-Emotion: Facial Expression Recognition Using Attentional Convolutional Network- Shervin Minaee, Amirali Abdolrashidi, Expedia Group\nUniversity of California, Riverside","ogImage":{"url":"/assets/img/2024-06-20-DecodingEmotionswithFacialRecognition_0.png"},"coverImage":"/assets/img/2024-06-20-DecodingEmotionswithFacialRecognition_0.png","tag":["Tech"],"readingTime":8},{"title":"파이썬 인터뷰 코딩 문제 및 초보자용 해결책","description":"","date":"2024-06-20 04:59","slug":"2024-06-20-PythonInterviewCodingQuestionswithSolutionsforBeginners","content":"\n\n\u003cimg src=\"/assets/img/2024-06-20-PythonInterviewCodingQuestionswithSolutionsforBeginners_0.png\" /\u003e\n\n파이썬 인터뷰를 준비하실 때에는 이 인기 있는 프로그래밍 언어의 기본 개념을 이해하는 것 뿐만 아니라, 인터뷰 중에 제시된 코딩 도전 과제를 통해 실용적인 기술을 보여줘야 합니다. 이러한 도전에 만족스럽게 대응할 수 있는지 확인하고자 한다면, 인터뷰를 하러 가기 전에 이러한 질문에 대한 대답 연습을 하는 것이 좋습니다.\n\n파이썬 코딩 인터뷰에서 뛰어나기 위해 도움이 되는 자주 묻는 10가지 질문을 여기에 소개합니다. 파이썬 초보자라면, 이러한 질문들이 인터뷰 이전의 준비 상태를 평가하는 데 도움이 될 것입니다.\n\n해답을 확인하기 전에 각각의 문제를 스스로 해결해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n화이팅하세요!\n\n# 파이썬 인터뷰 코딩 문제\n\n질문 1: 주어진 문자열이 회문인지 확인하는 파이썬 프로그램을 작성하십시오.\n\n해결책:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndef is_palindrome(string):\n    reversed_string = string[::-1]\n    return string == reversed_string\n\n# Test the function\nword = \"madam\"\nif is_palindrome(word):\n    print(f\"{word} is a palindrome\")\nelse:\n    print(f\"{word} is not a palindrome\")\n```\n\nQuestion 2: Write a Python program to find the factorial of a number.\n\nSolution:\n\n```js\ndef factorial(n):\n    if n == 0:\n        return 1\n    else:\n        return n * factorial(n-1)\n\n# Test the function\nnumber = 5\nresult = factorial(number)\nprint(f\"The factorial of {number} is {result}\")\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nQuestion 3: 리스트에서 가장 큰 요소를 찾는 Python 프로그램을 작성하십시오.\n\n해결책:\n\n```python\ndef find_largest(numbers):\n    largest = numbers[0]\n    for num in numbers:\n        if num \u003e largest:\n            largest = num\n    return largest\n\n# 함수 테스트\nnums = [10, 5, 8, 20, 3]\nlargest_num = find_largest(nums)\nprint(f\"가장 큰 숫자는 {largest_num}입니다.\")\n```\n\nQuestion 4: 문자열을 뒤집는 Python 프로그램을 작성하십시오.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해결책:\n\n```python\ndef reverse_string(string):\n    return string[::-1]\n\n# 함수 테스트\ntext = \"Hello, World!\"\nreversed_text = reverse_string(text)\nprint(reversed_text)\n```\n\n질문 5: 리스트 내 각 요소의 빈도수를 세는 파이썬 프로그램을 작성하세요.\n\n해결책:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\ndef count_frequency(numbers):\n    frequency = {}\n    for num in numbers:\n        if num in frequency:\n            frequency[num] += 1\n        else:\n            frequency[num] = 1\n    return frequency\n\n# 테스트 코드\nnums = [1, 2, 3, 2, 1, 3, 2, 4, 5, 4]\nfrequency_count = count_frequency(nums)\nprint(frequency_count)\n```\n\n질문 6: 수가 소수인지 확인하는 Python 프로그램을 작성하십시오.\n\n해결책:\n\n```js\ndef is_prime(number):\n    if number \u003c 2:\n        return False\n    for i in range(2, int(number**0.5) + 1):\n        if number % i == 0:\n            return False\n    return True\n\n# 테스트 코드\nnum = 17\nif is_prime(num):\n    print(f\"{num}은 소수입니다.\")\nelse:\n    print(f\"{num}은(는) 소수가 아닙니다.\")\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n질문 7: 두 리스트 사이에 공통 요소를 찾는 파이썬 프로그램을 작성해보세요.\n\n해결책:\n\n```python\ndef find_common_elements(list1, list2):\n    common_elements = []\n    for item in list1:\n        if item in list2:\n            common_elements.append(item)\n    return common_elements\n\n# 함수 테스트\nlist_a = [1, 2, 3, 4, 5]\nlist_b = [4, 5, 6, 7, 8]\ncommon = find_common_elements(list_a, list_b)\nprint(common)\n```\n\n질문 8: 버블 소트 알고리즘을 사용하여 요소의 리스트를 정렬하는 파이썬 프로그램을 작성해보세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n해결책:\n\n```python\ndef bubble_sort(elements):\n    n = len(elements)\n    for i in range(n - 1):\n        for j in range(n - i - 1):\n            if elements[j] \u003e elements[j + 1]:\n                elements[j], elements[j + 1] = elements[j + 1], elements[j]\n\n# 함수 테스트\nnums = [5, 2, 8, 1, 9]\nbubble_sort(nums)\nprint(nums)\n```\n\nQuestion 9: 리스트에서 두 번째로 큰 숫자를 찾는 Python 프로그램을 작성하시오.\n\n해결책:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\ndef find_second_largest(numbers):\n    largest = float('-inf')\n    second_largest = float('-inf')\n    for num in numbers:\n        if num \u003e largest:\n            second_largest = largest\n            largest = num\n        elif num \u003e second_largest and num != largest:\n            second_largest = num\n    return second_largest\n\n# Test the function\nnums = [10, 5, 8, 20, 3]\nsecond_largest_num = find_second_largest(nums)\nprint(f\"The second largest number is {second_largest_num}\")\n```\n\n질문 10: 리스트에서 중복을 제거하는 Python 프로그램을 작성하세요.\n\n해결책:\n\n```python\ndef remove_duplicates(numbers):\n    unique_numbers = []\n    for num in numbers:\n        if num not in unique_numbers:\n            unique_numbers.append(num)\n    return unique_numbers\n\n# Test the function\nnums = [1, 2, 3, 2, 1, 3, 2, 4, 5, 4]\nunique_nums = remove_duplicates(nums)\nprint(unique_nums)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이썬 취업 면접에 참석해 보신 적 있나요? 어떤 종류의 질문을 받았나요? 동료 파이썬 개발자들을 돕기 위해 아래에 댓글을 달아주세요!","ogImage":{"url":"/assets/img/2024-06-20-PythonInterviewCodingQuestionswithSolutionsforBeginners_0.png"},"coverImage":"/assets/img/2024-06-20-PythonInterviewCodingQuestionswithSolutionsforBeginners_0.png","tag":["Tech"],"readingTime":5},{"title":"AI 프롬프트 엔지니어링 탐구 수학적 기초와 RAG 방법론","description":"","date":"2024-06-20 04:54","slug":"2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies","content":"\n\n\n\u003cimg src=\"/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_0.png\" /\u003e\n\n## 대형 언어 모델 (LLMs)의 수학적 표현\n\n먼저 대형 언어 모델 (LLM)을 다음과 같은 공식으로 표현합니다:\n\n\u003cimg src=\"/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_1.png\" /\u003e\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n간단해 보이지만, 우리가 AI 기법과 LLM에 적용하는 방법을 이해하려면 LLM 프레임워크 내에서 𝜔, 𝑋 및 𝑌를 특정 항목으로 해석해야 합니다.\n\nLLM 가중치 (ω)\n\n매개변수 세트 𝜔는 신경망 가중치 (모델 계수) 및 편향으로, 모델 훈련 중에 업데이트됩니다. 𝜔는 LLM의 응답에 영향을 줄 수 있지만, 세밀 조정이 이루어질 때까지 고정됩니다. 이러한 매개변수는 다음과 같이 표시될 수 있습니다:\n\n![이미지](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_2.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n𝑛은 현대 LLMs에는 수십억 개에 달할 수 있는 매개변수의 수를 나타냅니다. 그러나 이 논문에서는 이러한 매개변수를 주요 주제로 삼지 않고, AI 프롬프트 엔지니어링과 RAG 방법론에 초점을 맞추고자 합니다.\n\n모델 입력 (X):\n\n입력 𝑋에는 여러 항목이 함께 작동하여 예측 𝑌를 생성하는 데 기여합니다:\n\n![image](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_3.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- X_query: 사용자로부터 특정 질문 또는 요청.\n  \n- X_prompt: 개발자가 설정한 초기 프롬프트.\n  \n- X_RAG Prompts: 데이터 소스 D로부터 X_query를 기반으로 검색한 추가 프롬프트(문서).\n  \n- X_parameters: 온도, 최대 토큰, 스트림 옵션과 같은 매개변수\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nX_매개변수는 모델 학습 매개변수가 아니지만 (예: 학습률, 신경망 레이어 수), 추론 중 LLM 동작에 유사한 역할을 합니다. 사용자가 이러한 매개변수를 지정하지 않으면, LLM은 파이썬 함수 기본값과 같은 기본값을 사용합니다. 사용자 매개변수와 기능에 대한 포괄적인 목록은 OpenAI API 문서를 참조하십시오.\n\n출력 변수 (𝑌)\n\nLLM에 의해 생성된 응답. 입력 X에 기반합니다.\n\n입력 및 매개변수 사용자 정의하기\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다양한 LLM은 다양한 입력 형식과 매개변수 집합이 필요할 수 있습니다. 우리는 OpenAI API를 사용하여 입력 구성에 초점을 맞춥니다. 𝑋의 각 구성 요소가 모델과 상호 작용하는 방법 및 조정이 생성된 응답 𝑌에 어떤 영향을 미치는지 살펴봅니다.\n\n![이미지](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_4.png)\n\n아래의 OpenAI 채팅 완성 API 예제를 사용하여 LLM의 표현을 보여줍니다:\n\n```js\nfrom openai import OpenAI\nclient = OpenAI()\n\nsystem_prompt = \"당신은 MSFT의 도움이 되는 HR 전문가입니다.\"\n\nrags = {'Q': \"문맥에서 혜택이란 무엇인지 설명하세요\", 'A': '회사에서 직원이 받는 혜택으로, 건강 보험, 퇴직 계획 등이 포함됩니다'}\n\nrag_prompt_question = {\"role\": \"user\", \"content\": rags['Q']}\nrag_prompt_answer = {\"role\": \"user\", \"content\": rags['A']}\nuser_query = \"MSFT의 데이터 과학자들의 혜택은 어떤가요?\"\n\nresponse = client.chat.completions.create(\n  model=\"gpt-3.5-turbo\",\n  messages=[\n    {\"role\": \"system\", \"content\": system_prompt},\n    rag_prompt_question, rag_prompt_answer,\n    {\"role\": \"user\", \"content\": user_query}\n  ]\n)\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n시스템 프롬프트가 X_쿼리인 경우, 모든 사용자 질문에 대한 고정 프롬프트입니다. rag_prompt_question 및 rag_prompt_answer는 X_RAG(X_query, D)이며, 여기서 D는 간단한 사전 rags로 단순화됩니다. 일반적으로 응용 프로그램에서 X_RAG는 D에서 X_쿼리를 검색하여 동적으로 얻어지지만, 이 예에서는 데모용으로 고정 X_RAG를 사용합니다.\n\n## 맥락 내 학습 LLM의 해석\n\n맥락 내 학습은 LLMs의 특정 용어로, LLMs가 사용자의 질문에 대해 입력-출력 프롬프트에 의존하여 응답하는 것을 의미합니다. 이는 LLMs가 더 적합한 프롬프트를 제공하면 사용자의 요청을 더 잘 해결할 수 있다는 것을 시사합니다. 예를 들어, 사용자가 user_query = “MSFT의 데이터 과학자들의 혜택은 어떤가요?”라는 질문을 한 경우, LLMs는 기본 추론을 사용하여 응답할 수 있으며, 이는 LLMs가 질문에 대한 가장 높은 확률로 사용하는 방식입니다:\n\n![그림](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_5.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n답변은 'MSFT가 당신을 선도하는 데이터 과학자로 만들어줄 수 있습니다'. 물론, 일부 LLM은 '혜택'의 여러 종류를 설명하는 포괄적인 답변을 제공할 수 있습니다. LLM의 응답 절차는 X_query만 가지고 있는 LLM들에게 '제로 샷 학습'을 가능케 하여 프롬프트 없이 응답할 수 있게 합니다. X_prompt 및 X_prompt와 같은 추가 프롬프트를 제공하면 LLM들이 필요한 정보를 응답합니다. 예를 들어 아래 프롬프트를 제공한다면:\n\nQ: 맥락에서 '혜택'이란 단어를 설명해주세요.\n\nA: 기업에서 직원이 받는 혜택으로, 건강 보험 등이 있습니다.\n\n그러면 LLM은 MSFT 직원 혜택에 대해 간략히 설명해줍니다. 이것이 '퓨-샷 학습'으로, LLM에게 응답 품질을 향상시키기 위한 작은 정보 조각을 제공합니다. '샷'이란 LLM이 맥락을 이해하는 데 제공되는 예시 수를 가리킵니다. '퓨-샷'은 몇 가지 예시만 제공되는 것을 의미합니다. 이는 더 많은 정보를 제공하여 질문을 특정하게 만듭니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_6.png)\n\n'Shot Learning'에서의 'learning'이 LLM에서의 학습(매개변수 업데이트)과는 다르다는 사실을 주목해야 합니다. 여기서 'few-shot context learning'은 LLM이 더 정확한 응답을 생성하는 데 도움을 주기 위해 몇 가지 프롬프트만을 입력합니다. 이는 LLM의 입력 𝑋를 업데이트하여 모델의 출력을 더 구체적이고 관련성 있게 만들어 사전 훈련된 LLM이 추가 학습(모델 훈련)이나 세부 조정 없이도 더 예측 가능하게 합니다.\n\n## RAG 프롬프트 및 개발의 수학적 해석\n\nRAG(검색 증대 생성) 프롬프트는 LLM 응용 프로그램에서 중요합니다. ChatGPT와 같은 준비된 AI 플랫폼은 종종 암묵적으로 검색을 처리하지만, ChatGPT-4는 사용자가 정보 파일을 업로드하여 최종 응답을 생성하는 데 참조합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nAI 애플리케이션은 보통 RAG 기술에 영향을 받습니다. 이 기술은 모델이 다른 소스의 동일한 사용자와 호환되는 것뿐만 아니라 사용자 정보가 안전하게 보호되어 AI 언어 모델에 직접 액세스할 수 없는 시나리오를 지원합니다. RAG는 사용자나 문맥에 가장 적합한 데이터를 사용하는 상황에서 모델의 반응의 관련성과 정확성이 긍정적으로 영향을 받습니다. 사용자는 ChatGPT-4와 같은 대화식 AI 플랫폼 내에서 자주 사용하는 데이터를 업로드하거나 추가 문맥을 직접 추가할 수 있습니다. 그러나 고객 서비스 등에서 사용되는 것과 같이 더 복잡한 AI 시스템의 경우 이러한 방식으로는 불가능합니다.\n\n다음은 AI 애플리케이션 시스템에서의 RAG 기술 구조입니다:\n\n- X_query: AI 시스템에 사용자의 질문. 고객 서비스와 같은 특정 분야의 쿼리입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- X_prompt: 개발자가 만든 AI 응용 프로그램 시스템에 맞는 프롬프트입니다. 신중하게 작성된 프롬프트는 시스템이 보다 정확한 응답을 제공하도록 합니다.\n\n- X_RAG: 사용자의 쿼리, AI 프롬프트 및 사용자가 업로드한 데이터를 기반으로 시스템이 생성한 RAG 프롬프트입니다.\n\n- D: AI 시스템이나 회사의 상용 환경 안에 포함된 비공개 정보입니다. 예를 들어, LLMs는 사용자 쿼리에 추가 정보를 제공하는 추출된 문서를 사용합니다.\n\n- Y: 텍스트 답변이거나 Python 코드 실행 결과, SQL 쿼리 출력물 또는 오디오 응답을 포함한 멀티모달 콘텐츠일 수 있습니다. 사용자의 각 쿼리에 대한 솔루션으로 간주될 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다양한 RAG 기술 및 해석\n\nRAG Prompt의 구조에서 우리는 RAG 기술이 다음 요소들에 의존한다는 것을 알 수 있습니다:\n\n- X_query: 사용자가 LLM에 요청하는 것.\n- 개인 데이터 (D): 사용자 또는 개발자가 데이터를 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 연관성 측정치: 쿼리와 D 간의 거리\n\n이것은 원본 또는 변환된 요소 또는 그들의 조합을 사용하여 새로운 RAG 기술을 개발할 수 있다는 것을 의미합니다.\n\nRAG 방법 1: 직접 임베딩 기반 검색\n\n직접 임베딩 기반 검색은 임베딩 모델이 텍스트를 벡터 표현으로 변환하여 데이터베이스에 저장하는 기본적인 기술입니다. 사용자가 쿼리를 보낼 때, RAG 함수는 쿼리 벡터와 가장 유사한 문서 벡터(예: 상위 𝑘 = 5)를 데이터베이스에서 검색합니다. 검색된 문서는 LLM에 의해 더 정확한 응답을 생성하기 위한 추가 프롬프트로 사용됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래와 같이, RAG 프롬프트는 쿼리와 private data 𝐷(doc) 간의 코사인 거리가 가장 짧은 5개 문서를 선택하여 검색됩니다. 여기서 우리는 코사인 거리를 역 유사성 측정으로 사용합니다.\n\n예시: 직접 임베딩 기반 검색\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래 단계는 Azure OpenAI, 대화형 검색 LangChain 및 Chroma Vector 데이터베이스와 같은 도구를 사용하여 직접 삽입 기반 검색을 구현하는 방법을 보여줍니다:\n\n단계 1: Chroma에 데이터 주입\n\n```js\nloader = TextLoader('intertnet_ts.txt', encoding='utf-8')\ndocuments = loader.load()\ntext_splitter = CharacterTextSplitter(chunk_size=300, chunk_overlap=50)\nchunks = text_splitter.split_documents(documents)\nvectordb = Chroma.from_documents(documents=chunks, embedding=Embeddings_model,\n           persist_directory=\"data/chroma_db\")\n```\n\n단계 2: 텍스트 임베딩 모델 설정\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nEmbeddings_model = AzureOpenAIEmbeddings(deployment = \"embed\",   model = \"em-ada\",\n       azure_endpoint = \"https://HD-gpt4.openai.azure.com/\", openai_api_type=\"azure\")\n```\n\n단계 3: RAG 검색기 함수 생성\n\n```js\ndef get_retriever():\n    loaded_vectordb = Chroma(persist_directory = \"data/db\", embedding_function = Embeddings_model)\n    retriever = loaded_vectordb.as_retriever(search_type=\"mmr\", k = 5)\n    return retriever\n```\n\n단계 4: LLM 초기화\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nchat_model = AzureChatOpenAI(openai_api_version=OPENAI_API_VERSION, azure_deployment=OPENAI_DEPLOYMENT_NAME, temperature=0)\nchat_retriever = get_retriever()\n```\n\n단계 5: 직접 포함 기반 검색을 위한 LangChain 설정\n\n```python\nqa_prompt = ChatPromptTemplate.from_messages(messages)\nqa_chain = ConversationalRetrievalChain.from_llm(llm=chat_model, chain_type='stuff', retriever=chat_retriever, return_source_documents=False, combine_docs_chain_kwargs={\"prompt\": qa_prompt})\n```\n\n평가\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n직접 삽입 기반 검색은 인기 있는 RAG 방법입니다. 일반적으로 코사인이나 내적을 거리 측정 항목으로 사용하는데, 이 방법은 때로 의미론적 의미를 캡처하는 데 합리적인 결과를 제공하기 어려울 때가 있습니다. 예를 들어 사용자가 \"MSFT의 시니어 데이터 과학자의 혜택은 무엇인가요?\"라고 묻는 경우 시스템이 'MSFT에서 시니어 소프트웨어 엔지니어의 직책 책임' 문서를 검색할 수 있습니다. 그러나 이 RAG 방법을 기반으로 한 다른 문서들 중에서 \"MSFT에서 시니어 직원을 위한 건강 보험 혜택, 주식 옵션, 전문 개발 프로그램\"과 같은 내용도 포함하고 있지만 이 방법에 따라 매우 유사하지 않은 문서들이 더 나은 후보가 될 수 있습니다.\n\nRAG 방법 2: 검색 재랭킹\n\n먼저 Direct Embedding-Based Retrieval 방법을 사용하는 예제를 확인해 보겠습니다:\n\n사용자의 질문: \"MSFT에서 시니어 데이터 과학자의 혜택을 알려주세요\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래와 같은 내용을 검색했습니다:\n\n1. \"마이크로소프트에서 시니어 소프트웨어 엔지니어의 직무 책임\"\n\n2. \"마이크로소프트에서 시니어 직원을 위한 건강 보험 혜택, 주식 옵션 및 전문 개발 프로그램\"\n\n3. \"쥬니어 데이터 과학자로 근무하는 장점에 대한 마이크로소프트의 혜택\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n4. \"시니어 엔지니어를 위한 MSFT의 휴가 정책\"\n\n5. \"MSFT의 직장 문화 개요\"\n\n첫 번째 문서에는 쿼리와 관련성이 적은 유사한 용어들이 많이 포함되어 있습니다. 두 번째 문서는 혜택 (의료 혜택, 주식 옵션)와 더 관련이 있는 내용이므로 더 나은 선택일 것입니다.\n\n따라서 이 문제를 해결하기 위해 RAG 재랭킹을 사용할 수 있습니다. 이 RAG 방법은 노출된 엔티티, 재랭킹 메커니즘 및 점수가 매겨진 문서를 결정하는 데 사용된 모델을 포함합니다. 문서들은 정리되어 가장 관련성이 높은 문서가 먼저 나타날 수 있도록 다시 정렬 및 필터링됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_10.png)\n\n결과적으로 RAG 다시 순위 지정은 AI 프롬프트(X_RERANKED_RAG)를 LLM에 제공합니다. 논리는 LLM이 항상 주어진 순서대로 AI 프롬프트를 고려할 것이라는 것입니다. 사용자의 질문과 일치하는 문서를 AI 프롬프트 상단에 놓으면 더 나은 답변을 제공할 수 있을 것입니다.\n\n예: 다시 순위 지정 검색\n\n다음 단계에서는 다시 순위 지정 검색 과정을 설명합니다. 이 과정에서 llama_index, RankGPTRerank 및 OpenAI API 도구를 활용합니다:\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n문서 로드: SimpleDirectoryReader를 사용하여 문서를 로드하고 특정 데이터 형식으로 분할합니다.\n\n벡터 저장소 인덱스 생성: 문서를 로드한 후 VectorStoreIndex를 사용하여 이러한 문서의 인덱스를 작성합니다. 이 벡터 공간을 사용하여 적합한 문서를 찾습니다.\n\n리트리버 설정: 벡터 인덱스를 사용하여 리트리버를 작성합니다. 쿼리와 유사한 상위 k개의 노드를 가져 오도록 구성합니다.\n\n관련 노드 검색: 쿼리 번들을 기반으로 리트리버에서 상위 k개의 노드를 검색합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다시 랭크하는 방법: OpenAI 내장 RankGPTRerank 모델을 설정하여 노드들을 관련성 점수에 따라 내림차순으로 다시 랭크합니다.\n\n평가\n\nRAG 다시 랭크는 LLM의 응답의 정밀도를 향상시킬 수 있습니다. 이 과정은 두 단계로 구성됩니다. 첫 번째 단계는 직접 삽입 기반 검색과 동일합니다. 그런 다음, 보다 계산 집중적인 다시 랭킹이 이 문서들의 순서를 조정합니다. 마지막으로, 이러한 다시 랭크된 AI 프롬프트를 LLM에게 보내어 가장 관련성 높은 결과물을 먼저 검토하도록 합니다. 하지만 첫 번째 단계에서 여전히 코사인 거리를 기반으로 한 랭킹이므로 모든 검색된 문서가 쿼리의 의미적으로 매우 관련성이 높지 않을 수 있습니다. 다음은 예시입니다:\n\n사용자의 질문: \"MSFT에서 시니어 데이터 과학자의 혜택은 무엇입니까?\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n첫 번째 단계 검색 (코사인 거리):\n\n1. \"MSFT의 시니어 소프트웨어 엔지니어의 업무 책임\"\n\n2. \"MSFT에서 시니어 데이터 과학자 고용 프로세스\"\n\n3. \"MSFT의 사무실 문화\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n4. \"Google에서 시니어 데이터 과학자의 직업 발전\"\n\n5. \"MSFT의 주니어 직원들을 위한 혜택\"\n\n다시 순위를 매겼음에도 검색된 문서는 여전히 관련이 없습니다. 예를 들어, 첫 번째 문서와 네 번째 문서는 각각 '다른 역할'과 '다른 회사'에 관한 것입니다. 이는 첫 번째 단계의 재랭킹 방법의 한계를 보여줍니다.\n\n재랭킹의 또 다른 단점은 계산 비용입니다. 두 번째 단계에서, 의미론적 정보를 정확하게 캡쳐하기 위해 LLM은 전체 문서와 쿼리를 완전히 이해해야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG 방법 3: 변환된 입력 쿼리 검색 (TQR)\n\n이 일반적인 RAG 기술에는 여러 가지 변형이 있지만, 아이디어는 비슷합니다: 원래 쿼리를 업데이트하여 개인 데이터(D)와 더 잘 일치시킵니다:\n\n![image](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_11.png)\n\n여기서 Pipe()는 사용자 정의 함수, 변환기 또는 GPT-3 또는 GPT-4와 같은 LLM(Large Language Models)을 사용하는 LangChain일 수 있습니다. TQR의 합리적 근거는 변환된 쿼리가 개인 데이터 D의 이해하기 쉬운 문서로 변환된다는 것입니다. 때로는 사용자가 매우 개인화된 질문을 할 수 있으며, LLM은 먼저 노이즈를 제거하여 질문을 새로운 문서로 변환할 수 있습니다. 이로써 다음 단계의 RAG에서 개인 데이터의 관련 문서와 더 쉽게 일치시킬 수 있습니다. 수학적으로 보면, X_(query_new)와 D 간의 전체 유사성이 X_(query)와 D 간의 것보다 높습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![image](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_12.png)\n\nRAG Method 3.1: 가상 문서 임베딩 (HyDE)\n\nHyDE는 원래 질의 X_query를 가상 문서로 변환하여 TQR로 분류될 수 있습니다. 단계 1에서, 단계 2에서, 시스템은 새로운 쿼리와 개인 데이터 D(doc) 사이의 거리를 최소화하여 상위 k개의 문서를 검색합니다. 이 변환 함수 Pipe()는 OpenAI API를 사용한 LangChain 'hyde.chain'입니다.\n\n![image](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_13.png)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 두 단계 프로세스는 검색된 문서의 관련성과 정확성을 향상시킬 수 있습니다. 그 이유는 LLM에 의해 생성된 가상 문서가 사용자의 쿼리 의도를 더 정확하게 파악할 수 있기 때문입니다. 논문 \"HyDE: Hypothetical Document Embeddings\"에 따르면, HyDE는 이전 최첨단 영제로 시스템보다 11개의 쿼리에서 현저히 뛰어나다는 것을 입증했습니다.\n\nHyDE RAG는 다음 인기 있는 RAG를 다루고 있습니다:\n\n- Self-querying Retrieval: LLM은 추가적인 관련 정보를 검색하기 위해 자체 쿼리를 생성하고, RAG 프롬프트가 LLM에게 전달되어 더 나은 응답을 생성합니다.\n\n- MultiQuery Retriever: LLM은 사용자의 원래 쿼리로부터 여러 쿼리를 생성하고, 그 후 HyDE 단계를 따릅니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예시: HyDE\n\n우리는 다음 사용 사례를 공부합니다:\n\n사용자 질의: \"MSFT에서 시니어 데이터 과학자의 혜택은 무엇입니까?\"\n\n우선 Direct RAG 검색 결과를 확인해 보겠습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n1. \"MSFT에서 시니어 소프트웨어 엔지니어의 직무 책임\"\n\n2. \"MSFT에서 시니어 데이터 과학자 채용 프로세스\"\n\n3. \"MSFT의 사무실 문화\"\n\n4. \"Google의 시니어 데이터 과학자의 경력 진로\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n5. \"MSFT 주니어 직원을 위한 혜택\"\n\n검색된 문서는 '시니어 데이터 과학자의 혜택' 질의와 관련이 없습니다.\n\nHyDE RAG를 확인해 봅시다:\n\nStage 1: 쿼리 변환:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n단계 2: 관련 문서 검색\n\n변환된 쿼리를 사용하여 D에서 상위 5개 관련 문서를 검색하십시오.\n\n\"MSFT의 고위 직원들을 대상으로 하는 건강 관리 혜택, 주식 옵션 및 전문 발전 프로그램\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n“MSFT는 고급 데이터 과학자들을 위해 건강 보험, 퇴직 계획, 그리고 보너스를 제공합니다.\"\n\n\"MSFT의 고급 직원들은 유급 휴가, 웰빙 프로그램, 그리고 교육 기회를 즐길 수 있습니다.\"\n\n검색된 문서가 '고급 데이터 과학자의 혜택'에 대한 쿼리와 관련이 더 많음을 보여줍니다. HyDE의 단점은 계산 비용과 텍스트 환각의 위험입니다. 예를 들어, 생성된 가상의 문서는 첫 번째 단계에서 더 나아 보일 수 있지만, 원본 쿼리에서 벗어날 수 있어 최종 검색된 문서가 직접 검색한 것보다 못해질 수 있습니다.\n\nRAG Method 3.2: 향상된 가상 문서 임베딩(EHyDE)”\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nEHyDE는 Stage 1에서 개인 데이터 𝐷(문서)나 context 정보를 원래의 쿼리 𝑋_query에 추가하여 HyDE를 개선합니다. Stage 2에서 수정된 쿼리는 가상 문서(새로운 쿼리)로 변환됩니다. Stage 3에서는 검색 과정이 HyDE와 동일한 단계를 따릅니다. 추가 정보는 NLP 기계 학습을 통해 개인 데이터 𝐷(문서)와 대화 기록에서 얻을 수 있으며, D의 키워드 또는 빈도가 더 높은 쿼리와 같은 내용입니다.\n\nEHyDE의 이점은 개인 데이터 𝐷(문서)에서 정보를 추가하여 Stage 2의 가상 문서가 개인 데이터 D와 관련된 더 많은 근거를 가질 수 있다는 것입니다.\n\n예시: EHyDE\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기 EHyDE가 HyDE를 개선하는 예시가 있어요:\n\n사용자 질의: \"MSFT의 시니어 데이터 과학자의 혜택은 무엇인가요?\"\n\nHyDE 방식:\n\n단계 1: 질의 변환\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n변환된 쿼리를 가정 문서로 만들어보겠습니다.\n\n단계 2: 관련 문서 검색\n\n가정 문서를 사용하여 문서를 검색합니다.\n\nHyDE를 사용한 검색:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n1. \"MSFT의 시니어 직원을 위한 건강 보험 혜택, 주식 옵션 및 전문 개발 프로그램\"\n\n2. \"MSFT에서 시니어 데이터 과학자를 채용하는 프로세스\"\n\n3. \"MSFT의 사무실 문화\"\n\nHyDE는 채용 프로세스와 사무실 문화에 관한 적합하지 않은 문서도 포함되어 일치하는 문서를 검색합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nEHyDE를 사용한 검색:\n\n단계 1: 개인 데이터에서 정보 추가\n\n개인 데이터 𝐷에서 관련 키워드를 추출합니다. '의료 혜택', '주식 옵션', '전문 개발 프로그램'과 같은 내용입니다.\n\n쿼리를 이러한 키워드를 포함하도록 수정하세요: 'MSFT의 시니어 데이터 과학자를 위한 의료 혜택, 주식 옵션 및 전문 개발 프로그램은 무엇입니까?'.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nStage 2: 쿼리 변환하기\n\n수정된 쿼리를 가상의 문서로 변환해 보겠습니다: 'MSFT의 시니어 데이터 과학자들은 건강 보험 혜택, 주식 옵션 및 전문 개발 프로그램을 받습니다'.\n\nStage 3: 관련 문서 검색하기\n\n개선된 가상 문서를 사용하여 문서를 검색합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nEHyDE를 사용한 검색:\n\n1. \"MSFT의 고위 직원을 위한 건강 보험, 주식 옵션 및 전문 개발 프로그램\"\n\n2. \"MSFT는 고위 데이터 과학자를 위해 건강 보험, 퇴직 계획 및 보너스를 제공합니다\"\n\n3. \"MSFT의 고위 직원은 유급 휴가, 웰니스 프로그램 및 계속되는 교육 기회를 포함한 다양한 혜택을 누립니다\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nEHyDE는 초기 쿼리 변환 단계에서 개인 데이터에서 주요 정보를 통합하여 관련 문서를 더 많이 검색합니다.\n\nEHyDE RAG에는 다음과 같은 전형적인 RAG가 포함되어 있습니다:\n\n- Step-back Prompting: LLM 또는 지역 모델은 이전 단계나 쿼리를 검토하여 HyDE RAG 프로세스를 위해 원래 쿼리를 변환합니다.\n- 히스토리 컨텍스트를 기반으로 쿼리 재생성: LLM 또는 지역 모델은 이전 상호 작용의 역사적 컨텍스트를 사용하여 현재 쿼리를 HyDE RAG 프로세스에 업데이트합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG Method 3.3: Enhanced Direct Embedding-Based Retrieval\n\n이 방법은 단계 1에서 개인 데이터를 사용하여 원본 쿼리를 개요화하는 검색 절차를 요약하며, 단계 2에서는 직접 임베딩 기반 검색 접근 방식을 따릅니다.\n\n![이미지](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_15.png)\n\n함수 S는 개인 데이터를 기반으로 요약된 쿼리를 생성하고, 요약된 쿼리와 개인 데이터 임베딩간의 거리를 최소화하여 RAG 프롬프트를 검색합니다. 이 접근 방식은 HyDE 접근 방식과 유사하지만 가상의 문서를 생성하는 대신 문서를 개요화하는 데 초점을 맞춥니다. 주요 이점은 다음과 같습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n· 검색시 LLM 사용 회피로 계산 양 줄이기\n\n· 텍스트 환각 발생 위험 감소\n\n이 RAG 방법은 문서 내 특정 문장 윈도우를 탐색하는 Sentence Window Retrieval을 포함하고 있습니다. 예를 들어, \"운동이 정신 건강에 미치는 영향\"이라는 쿼리에 대해 이 RAG 방법은 \"운동\"과 \"정신 건강\"이 같은 몇 문장에 나타나는 텍스트를 검색합니다.\n\nRAG 방법 4: 변환된 개인 데이터 검색 (TDR)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 TQR 방법은 원래 쿼리를 변환하여 개인 데이터 일치를 개선할 수 있습니다. 마찬가지로, 우리는 이 기술을 개인 데이터에 적용할 수 있습니다 — Transformed Private Data Retrieval (TDR). 이 방법은 먼저 개인 데이터를 변환하고 관련 문서를 검색하여 LLM에게 RAG 프롬프트를 제공합니다. 이 방법의 합리성은 변환된 개인 데이터가 더 나은 데이터 품질을 갖고 있어 소음을 제거하고 주요 목적을 강조할 수 있다는 것입니다.\n\n![이미지](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_16.png)\n\n1단계에서는 로컬 NLP 모델 또는 LLM을 기반으로 한 트랜스포머와 같은 기계 학습 모델(𝑀으로 나타냄)을 사용하여 개인 데이터에서 TF-IDF 및 Word2Vec에 따라 키워드와 같은 핵심 구성 요소 M(D(doc))을 추출합니다. 이러한 핵심 구성 요소는 인간 의미 텍스트(Prompt_text)와 결합되어 Prompt_transform을 생성합니다. 2단계에서 Prompt_transform은 LLM에게 개인 데이터를 어떻게 변환해야 하는지 알려줍니다. 3단게는 다른 방법과 유사하게, 𝑋_query와 𝐷(doc_new) 간의 5개의 최단 거리를 갖는 문서를 선택합니다.\n\nTQR 방법과 마찬가지로, TDR 기술에는 여러 가지 변형이 있습니다. 적용 시나리오에 따라 개인 데이터를 어떻게 변환해야 하는지에 영향을 받을 수 있습니다. 예를 들어, 일반적인 질문-답변 챗봇을 구축할 때 RAG 데이터로 FAQ 스타일 지식 베이스가 필요할 수 있습니다. 많은 상호 작용하는 인공 지능 에이전트들에게는 지식 그래프, 플로우차트, JSON 파일, 데이터베이스 메타데이터 및 머신 러닝 모델의 출력 패턴과 같은 더 복잡한 데이터 구조를 고려해야 합니다. 여기서 다양한 전형적인 사용 사례에 대해 TDR을 소개하겠습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG Method 4.1: 개인 데이터 정리를 통한 TDR\n\n이 방법은 개인 데이터에서 쓸모없는 정보를 제거하는 데 목적을 두고 있습니다:\n\n- NLP에서 구두점, 불용어 및 어간추출과 같은 데이터 정리 기술 사용\n- LLMs가 이미 알고 있는 지식을 개인 데이터에서 제거\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n· 개인 데이터에서 잘못된 정보 제거하기\n\n데이터 품질을 향상하는 첫 번째 단계입니다. 두 번째 단계는 중복 정보를 걸러내어 LLM 프로세스를 간소화하는 것입니다. 세 번째 단계는 중요하지만 더 많은 확인이 필요합니다. 또한 이러한 작업은 LLM에서 수행할 수 있지만 추가 비용이 발생할 수 있습니다.\n\n예시: 개인 데이터 정리를 통한 TDR\n\n우리는 다음과 같은 RAG 프롬프팅을 위한 개인 데이터 𝐷를 가지고 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG_information = ‘’’ 사원 혜택은 회사로부터 받는 유형의 현저한 이점이나 혜택을 나타내며, 건강 보험, 퇴직 계획, 유급 휴가, 보너스 및 기타 보상 형태와 같은 것이 있습니다. 혜택은 회사에서 일하는 데서 얻는 추상적이고 무형의 이점을 의미하기도 합니다. 구체적으로 회사에서 일하는 것의 긍정적인 면이나 경험을 의미합니다. 도움을 주는 근무 환경, 성장 기회, 커뮤니티 감각 및 전반적인 직장 만족도와 같은 것들이 있습니다.’’’\n\n로컬 NLP 모델이나 LLMs에 기반한 변환기를 사용하여 𝐷에서 다음 정보를 식별할 수 있습니다:\n\n주제 = \"혜택이라는 단어의 일반적인 설명\"\n\n그런 다음 다음 프롬프트를 LLMs에 전달하여 새로운 비공개 데이터를 만들 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"테이블 태그를 Markdown 형식으로 변경해주세요.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG 방법 4.2: 비공개 데이터 생성을 통한 TDR\n\n우리는 LLMs를 사용하여 원본 비공개 데이터를 다양한 응용 프로그램에 맞게 구체적인 형태로 변환할 수 있습니다. 아래는 일반적인 예시들입니다:\n\nRAG 방법 4.2.1: 비공개 데이터 요약\n\n이 TDR 방법은 원본 비공개 데이터를 간결한 데이터로 요약하여 주요 포인트를 수집합니다. 이를 위해 LLMs(또는 트랜스포머)를 사용하여 비공개 데이터 𝐷를 RAG 데이터로 변환합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n먼저 위의 표 태그를 마크다운 형식으로 변경해보겠습니다.\n\n\n![ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_18](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_18.png)\n\n이 방법은 동시에 다음 조치들을 최소화하도록 명시적으로 목표로 합니다:\n\n![ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_19](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_19.png)\n\n이는 결과적으로 RAG 데이터가 개인 데이터와 밀접한 관련이 있으면서도 텍스트를 최대한 간결하게 유지해야 한다는 것을 의미합니다. 또한, 결과적인 RAG 데이터에는 최소한의 중복이 있어야 하며, 관련 없는 주제를 피해야 한다는 것을 시사합니다.\n\n\n위의 내용이 도움이 되었기를 바라며, 궁금한 점이 있으면 언제든지 물어보세요!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예시: 개인 데이터 요약:\n\n우리는 종종 긴 기업 정책 문서를 간단한 핵심 정책을 강조하는 RAG 데이터로 변환하기 위해 요약 TDR을 사용합니다. 그런 다음 이 RAG 데이터를 사용하여 회사를 위한 FAQ 스타일 지식 베이스를 만들 수 있습니다:\n\n- NLP 기술을 사용하여 문서에서 주요 포인트를 추출합니다.\n- 이러한 주요 포인트를 AI 프롬프트에 추가하여 개인 데이터를 요약합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nLLM과 AI 프롬프트를 사용하여 RAG 데이터를 생성하세요.\n\n다음은 원본 문서의 예시입니다:\n\n“저희는 의료, 치과, 시력 보험을 포함한 종합 건강 보험을 제공합니다. 또한 401(k) 매칭 및 연금 플랜을 포함한 다양한 퇴직 계획도 제공하여 직원들이 은퇴 후 재정 안정성을 확보할 수 있도록 합니다. 유급 휴가: 모든 직원은 유급 휴가(PTO)를 받으며, 휴가 일수, 병가, 개인 사정 일수를 포함합니다. 전문 개발: 계속적인 학습을 장려하고 직무와 관련된 코스, 인증서, 그리고 컨퍼런스에 대한 보상도 제공합니다. 또한 직원들의 안전을 최우선으로 여깁니다. …”\n\n비공개 데이터 접근 방식을 요약한 후, 다음과 같은 잘 구성된 RAG 데이터가 제공됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"안녕하세요! 아래는 회사가 제공하는 혜택에 대한 몇 가지 정보입니다:\n\n1. 건강 보험: 회사는 의료, 치과 및 시력 보험을 포함한 종합 건강 보험을 제공합니다.\n\n2. 퇴직 계획: 401(k) 매칭 및 연금 플랜과 같은 다양한 퇴직 계획을 제공합니다.\n\n3. 유급 휴가: 직원들은 휴가, 병가 및 개인 날 등을 포함한 유급 휴가를 받습니다.\n\n4. 전문 개발: 직장과 관련된 과정, 자격증 및 학회에 대한 보상을 통해 지속적인 학습을 촉진합니다.\"\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n5. 직장 안전: 직원 안전은 최우선 과제로, OSHA 규정을 준수하고 정기적인 안전 교육을 받습니다....\"\n\n참고로, 이 방법은 Parent-child Chunks Retrieval 방법을 포함하며, 문서를 계층적 청크로 나누어 메인 컨텍스트(부모) 및 구체적인 세부 사항(자식) 섹션을 검색합니다.\n\nRAG 방법 4.2.2: 개인 데이터 파라프레이징\n\n가끔 개인 데이터에는 회계, 법률, 건강과학과 같은 분야의 전문 용어가 많이 포함됩니다. 그러나 이러한 문서들은 사용자 쿼리가 동일한 기술 용어를 사용하지 않을 수 있기 때문에 AI 시스템이 RAG를 사용하기 어렵게 만들 수 있습니다. 데이터를 더 간단한 언어로 다시 표현하면 RAG에 더 적합해집니다. 이 방법은 원래 의미를 유지하면서 사용자 쿼리와 일치할 확률을 높이는 데 도움이 됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 방법은 동시에 다음을 동시에 최소화하기 위해 구체적으로 진행됩니다:\n\n![image](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_20.png)\n\n여기서 D(쿼리)는 비전문 사용자로부터의 일반 쿼리를 나타냅니다.\n\n'개인 데이터 패러프레이징' RAG 기술의 여러 버전은 번역과 같은 방법을 통해 데이터를 다른 언어로 변환하여 더 접근 가능하고 사용하기 쉽게 만듭니다. 이 방법은 주로 다국어 인공지능 지원 시스템을 개발하는 데 활용됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG Method 4.2.3: 특별한 구조로 개인 데이터 변환하기\n\n대부분의 AI 응용 프로그램 튜토리얼은 특정 길이의 역사적 텍스트를 추적하는 것과 같은 상호 작용적 작업을 위해 간단한 RAG 방법을 사용합니다. 그러나 실제 대화형 AI 응용 프로그램은 더 고급 접근 방식이 필요합니다. 예를 들어:\n\n- 기본 질문에 답변하는 챗봇은 사용자의 질의만 필요할 수 있습니다. 그러나 복잡한 문제를 해결하는 고객 서비스 봇은 사용자를 효과적으로 안내하기 위해 전체 대화 기록이 필요할 수 있습니다.\n\n- SQL 절이 복잡한 데이터를 검색하도록 AI 시스템에 요청하는 데이터 분석가는 메타데이터, 테이블 관계 및 출력 형식을 포함한 특별히 구조화된 프롬프트가 필요합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n한 가지 가능한 방법은 개인 데이터를 특수 구조(지식 그래프, 플로우차트, JSON 파일, 데이터베이스 메타데이터, 이미지 파일 및 기계 학습 결과를 포함)로 변환하는 것입니다. 이러한 구조는 고급 AI 시스템에서 RAG 성능을 향상시키는 데 입증되었습니다. 다음 공식은 이 절차를 설명합니다:\n\n![image](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_21.png)\n\n여기서 M(D(doc), Structure)는 일반 변환 함수를 나타내며, LLMs, 트랜스포머 또는 수동 절차를 포함한 로컬 NLP 모델 등이 될 수 있습니다. 두 번째 매개변수인 Structure은 위에서 언급한 데이터 구조를 나타냅니다. 여기서 Prompt는 RAG 프롬프트와 콘텍스트 프롬프트를 통합하며, 최근의 콘텍스트와 같은 대화 콘텍스트의 함수 값입니다.\n\n예시: 인터넷 문제 해결 대화 기록\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이 예시는 인터넷 문제 해결 대화 내용을 사용하여 대화 바구니 분석을 생성하여 대화 바구니 시퀀스를 만드는 방법을 보여줍니다. 그런 다음 대화 바구니 시퀀스 패턴을 RAG 파일로 사용하여 LLM이 고객 문제를 대화식으로 해결하는 데 사용됩니다. 이는 기계 학습 결과를 사용한 전형적인 RAG 예시입니다.\n\n- 데이터: 과거 인터넷 문제 해결 대화 내용입니다.\n\n- 바구니 분석: 공통 대화 시퀀스를 식별하고 그 빈도 (지원)와 신뢰도 (신뢰도)를 기록합니다.\n\n- 대화 바구니 시퀀스: 식별된 패턴을 기반으로 대화 바구니 시퀀스를 생성합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- RAG 파일 생성: 이러한 시퀀스를 구조화된 RAG 파일로 변환합니다.\n\n- LLM 통합: RAG 프롬프트를 만들어 LLM에 전달합니다.\n\n- 문제 해결: LLM은 이 대화 시퀀스를 사용하여 대화를 이끄는 데 사용하고 과거 패턴에 기반한 솔루션을 제공합니다.\n\n인터넷 문제 해결 대화를 거래 데이터로 사용하여 바구니 분석을 수행하여 다음 시퀀스를 얻습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n1. 라우터 재시작 - 케이블 확인 - 지원 연락\n\n2. 케이블 확인 - 라우터 재시작 - 지원 연락\n\n3. 케이블 확인 - 지원 연락\n\n4. 라우터 재시작 - 케이블 확인\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n5. 연결 상태 확인 - 라우터 재시작 - 케이블 확인\n\n![image](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_22.png)\n\n그런 다음 머신러닝 결과 시퀀스 또는 플롯을 LLM의 RAG 프롬프트로 직접 또는 간접적으로 사용할 수 있습니다.\n\n예시: 캐글 콘테스트 — 쿠폰 교환 예측\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nKaggle 콘테스트 '쿠폰 사용 예측'을 확인해보세요. 데이터베이스 메타데이터에 특히 관심이 있습니다:\n\n![image](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_23.png)\n\n여기서 다음 단계를 통해 LLM을 사용하여 이미지를 텍스트 메타데이터로 변환할 것입니다:\n\n- 이미지 파일을 업로드하세요\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\"이 대회에 대한 설명은 다음과 같습니다: 쿠폰 사용 예측...\n\n이미지에 표시된 메타데이터와 테이블 간의 관계를 설명해주세요. 각 테이블의 필드와 그들 간의 관계를 설명해야 합니다.\"\n\n그러면 다음과 같은 RAG 데이터를 얻을 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n테이블과 해당 필드:\n\nTrain:\n\nid: 각 레코드의 고유 식별자.\n\ncampaign_id: 캠페인 데이터와 연결된 식별자.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n테이블 태그를 마크다운 형식으로 변경해주세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n캠페인 ID: 각 캠페인을 식별하는 고유 식별자입니다.\n\n…\n\n또한 텍스처 메타데이터를 플로차트 또는 텍스트 또는 이미지 형식의 표로 변환하여 역으로 작업을 수행할 수도 있습니다. 이러한 특별한 구조화된 데이터 또는 파일 형식은 LLM들이 복잡한 작업을 해결하는 데 직접적으로 RAG 문서로 사용될 수 있다는 점이 인상적입니다. 예를 들어 Interactive AI Agents by Using Neo4j RAG.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n개인 데이터를 쉽게 이해할 수 있는 지식 그래프로 변환하는 방법을 Neo4j에서 소개해 드리겠습니다. 이를 통해 정보를 체계적으로 구성하여 LLM이 쉽게 소화할 수 있습니다:\n\n- 그래프를 배치할 Neo4j 공간을 생성합니다.\n- LLM을 사용하여 주요 정보를 검색하고 다양한 항목을 구성합니다.\n- 위 정보를 JSON으로 변환합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n· JSON 데이터를 지식 그래프에 로드합니다.\n· GraphCypherQAChain으로 그래프에서 쿼리를 실행합니다.\n\n다음은 원본 개인 데이터에서 변환된 지식 그래프의 예시입니다:\n\nCustomer1[Customer: ID=1, Age=20–30, Status=Single] → Transaction101[Transaction: ID=101, Date=2023–05–01]\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다음은 Markdown 형식으로 표를 변경하였습니다.\n\n\n| 관계               | 함께 사용되는 항목                        |\n|---------------------|-----------------------------------------|\n| Transaction101     | Product1001 [제품: ID=1001, 이름=제품 A, 카테고리=전자제품] |\n| Customer2          | Customer: ID=2, 나이=30-40, 상태=기혼 |\n| Customer2 → Transaction102 | Transaction: ID=102, 날짜=2023-05-02 |\n| Transaction102     | Product1002 [제품: ID=1002, 이름=제품 B, 카테고리=가정용] |\n\n\nLLM을 위한 RAG 프롬프트에서 고객-제품 거래 데이터를 기반으로 한 응답을 개선하는데 사용할 수 있는 이 지식 그래프를 참고하세요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nRAG Method 5: RPF\n\nRPF(Relevance, Precision, and Fidelity) for RAG은 RAG 데이터의 적절성, 정확성 및 충실도를 평가하고 향상시키는 프레임워크입니다. 이 측정 항목은 RPF 점수라고 하며, LLM이 미리 정의된 알고리즘을 사용하여 만듭니다.\n\n그러나 RPF는 RAG 방법은 아니지만, 해당 메커니즘이 RAG 절차를 설정하는 데 도움이 될 수 있습니다.\n\n쿼리 평가: LLM은 RPF 알고리즘을 사용하여 쿼리를 평가합니다. 개인 데이터의 각 문서에는 RPF 점수가 할당됩니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Exploring AI Prompt Engineering Mathematical Foundations and RAG Methodologies](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_24.png)\n\n신뢰도 평가: 가장 높은 RPF 점수 max_score_RPF를 선택하고, 가장 높은 RPF 점수를 가진 문서 X_RAG를 선택합니다. 점수 max_score_RPF가 임계값 T보다 높으면 LLM은 X_RAG를 사용하여 응답하고, 그렇지 않으면 사용자로부터 명확화를 위해 상호 작용적 피드백을 제공하여 사용자로부터 설명을 듣습니다:\n\n![Exploring AI Prompt Engineering Mathematical Foundations and RAG Methodologies](/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_25.png)\n\nAI 및 사용자 상호작용: LLM은 사용자에게 질문을 명확히하거나 쿼리의 의미를 이해하기 위해 몇 가지 선택지를 제공합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n응답: LLM이 쿼리를 이해하면 응답을 검색하고 생성합니다.\n\n## 최종 생각\n\n많은 자습서에서는 대규모 언어 모델, AI 프롬프트 엔지니어링 및 RAG(Retrieval-Augmented Generation)을 소개하나, 종종 구체적인 기술과 상황에 중점을 두고 텍스트 설명이나 코드를 사용합니다. 이 글에서는 이러한 접근 방식을 수학적으로 정리하고 적용 가능성에 대해 요약했습니다. RAG 기술을 체계적으로 정리하고 이러한 모델의 설명을 했습니다. 이러한 방식을 통해 우리는 대규모 언어 모델(BLMs), 지능형 프롬프트 엔지니어링(IPE)과 RAG의 원리, 범주 및 사용 사례를 잘 이해할 수 있습니다. 더 나아가, 이는 대규모 언어 기술의 새로운 발전을 위한 자극제로 활용될 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_0.png"},"coverImage":"/assets/img/2024-06-20-ExploringAIPromptEngineeringMathematicalFoundationsandRAGMethodologies_0.png","tag":["Tech"],"readingTime":25},{"title":"콜모고로프-아놀드 네트워크KAN가 인공지능 세계를 영원히 바꿀 것입니다","description":"","date":"2024-06-20 04:51","slug":"2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever","content":"\n\n## 신경망에 대해 알고 있던 모든 것을 잊어버리세요, KAN이 규칙을 다시 쓸 예정입니다\n\n![image](/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_0.png)\n\n# 소개:\n\n머신 러닝의 계속 변화하는 풍경 속에서 최근 발표된 \"KAN: Kolmogorov-Arnold Network\"라는 연구 논문은 열광적인 열기를 불러일으켰습니다. 이 혁신적인 접근 방식은 다층 퍼셉트론(MLP)의 전통적인 지혜에 도전하여 신경망 구조에 대한 새로운 시각을 제공합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 콜모고로프-아놀드 네트워크 (KAN's)란 무엇인가요:\n\n이 혁신적인 개념의 핵심에는 Vladimir Arnold와 Andrey Kolmogorov가 개발한 수학 이론인 콜모고로프-아놀드 표현 정리가 있습니다. 이 정리는 복잡한 다변수 함수를 보다 간단한 일차원 함수로 분해할 수 있음을 주장하여 KAN의 독특한 구조의 기초를 제공합니다.\n\n![이미지](/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_1.png)\n\n이제 당연한 질문은 이 \"더 간단한 일차원 함수\"가 무엇인가요. 수학 또는 컴퓨터 그래픽을 조금 알고 있는 사람이라면, 우리가 말하는 것은 옛날부터 신뢰받는 조각별 다항식인 Spline입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*1VcxJSh_CYAPc9-0os2-pA.gif)\n\n# KAN의 시크릿 소스, 스플라인!\n\n스플라인은 연속 점들을 연결하여 부드러운 곡선을 생성할 수 있는 수학적 함수입니다. 스플라인은 인접 세그먼트 사이의 연속성과 부드러움을 보장하면서 곡선의 모양을 조절하는 유연성을 제공합니다.\n\n스플라인을 생성하기 위해 일반적으로 곡선의 경로를 정의하는 일련의 제어점을 시작점으로 삼습니다. 그런 다음, B-스플라인이나 베지에 곡선과 같은 기저 함수를 사용하여 이러한 제어점 사이의 경로를 보간하거나 근사합니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*B1MXmHF8xD_WP3GJNwbfDQ.gif)\n\n기본적으로 스플라인은 복잡한 곡선이나 표면을 정밀하고 유연하게 표현하는 다재다능한 도구를 제공하여 다양한 분야에서 귀중하게 활용됩니다.\n\n하지만, KAN 아키텍처에서 이러한 스플라인을 어떻게 사용하고 적용할까요?\n\n# KAN 작동 방식을 이해하는 가장 간단한 방법\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n전통적인 MLP들과 달리 KAN은 고정된 활성화 함수를 학습 가능한 기능(B-Splines)으로 대체하여 네트워크의 가장자리를 따라 작동합니다.\n\n이 적응형 아키텍처를 통해 KAN은 복잡한 함수를 효과적으로 모델링하면서 해석 가능성을 유지하고 필요한 매개변수의 수를 줄일 수 있습니다.\n\n![image](https://miro.medium.com/v2/resize:fit:1200/1*5hfRk7kjl-CZvyhpbfKlsw.gif)\n\nMLP의 경우 신호를 전달하는 수동적인 수단으로 기능하는 것과 달리, KAN의 뉴런들은 학습 프로세스의 적극적인 참여자로서 동적으로 동작을 조정하여 마주치는 데이터에 대응합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n네트워크의 가장자리에 배치된 학습 가능한 활성화 함수를 도입하여 가능해진 이 혁신적인 전환은, 네트워크의 에지에 배치된 학습 가능한 활성화 함수를 통해 가능케 되었습니다.\n\n![이미지](/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_2.png)\n\nB-스플라인의 표현력을 이용하여, 이러한 함수들은 KAN에 무궁무진한 유연성과 적응성을 부여하여, 복잡한 데이터 환경을 쉽게 탐색할 수 있게 만들어줍니다.\n\n# KAN의 주요 장점:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 향상된 확장성\n\nKAN은 특히 고차원 데이터 시나리오에서 MLP에 비해 우수한 확장성을 보여줍니다. 복잡한 함수를 간단한 구성 요소로 분해하는 능력으로 대용량 데이터를 효율적으로 처리할 수 있어서 방대한 양의 정보가 포함된 작업에 이상적입니다.\n\n## 향상된 정확성\n\n더 적은 매개변수를 사용하더라도 KAN은 다양한 작업에 걸쳐 전통적인 MLP보다 더 높은 정확도와 낮은 손실을 달성합니다. 이는 데이터 내에서 관계를 적응적으로 모델링하는 능력 때문에, 보다 정확한 예측과 보다 잘 일반화된 결과를 얻을 수 있다고 이해됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 해석 가능한 모델\n\nKAN의 구조는 해석 가능성을 용이하게 하여 연구자들이 학습된 패턴을 효과적으로 나타내는 상징적인 공식을 도출할 수 있게 합니다. 블랙박스 모델과는 달리, KAN은 입력 특성이 네트워크 전반에 걸쳐 어떻게 변환되는지에 대한 통찰을 제공하여 투명성과 이해를 높입니다.\n\n이제 KAN이 무엇이며 왜 인공지능 분야에서 큰 문제인지를 알게 되었지만, 세상은 이론과 논문에서 멋져 보이는 모델로만 움직이는 것이 아닙니다.\n\n하지만 KAN의 가장 좋은 점은 새로운 Python 라이브러리 \"PyKAN\"을 사용하여 자신의 데이터 과학 문제에 쉽고 간단하게 적용할 수 있다는 것입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n위의 텍스트를 친근한 어조로 한국어로 번역하겠습니다.\n\n우리의 토론을 파이썬으로 이 아키텍처를 어떻게 구현할 수 있는지 예제와 함께 마무리해봅시다.\n\n# Python에서 KAN의 구현 (PyKAN):\n\n우리의 데모를 위해 분류 문제를 사용해봅시다.\n\n## 데이터셋 생성\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nsklearn 라이브러리의 \"make_moons\" 함수를 사용하여 합성 데이터 세트를 생성할 예정이에요.\n\n```js\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_moons\nimport torch\nimport numpy as np\n\ndataset = {}\ntrain_input, train_label = make_moons(n_samples=1000, shuffle=True, noise=0.1, random_state=None)\ntest_input, test_label = make_moons(n_samples=1000, shuffle=True, noise=0.1, random_state=None)\n\ndataset['train_input'] = torch.from_numpy(train_input)\ndataset['test_input'] = torch.from_numpy(test_input)\ndataset['train_label'] = torch.from_numpy(train_label)\ndataset['test_label'] = torch.from_numpy(test_label)\n\nX = dataset['train_input']\ny = dataset['train_label']\nplt.scatter(X[:,0], X[:,1], c=y[:])\n```\n\n## 결과 (시각화된 데이터셋)\n\n\u003cimg src=\"/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_3.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## KAN 생성 및 훈련\n\n```js\nfrom kan import KAN\n\nmodel = KAN(width=[2,2], grid=3, k=3)\n\ndef train_acc():\n    return torch.mean((torch.argmax(model(dataset['train_input']), \n    dim=1) == dataset['train_label']).float())\n\ndef test_acc():\n    return torch.mean((torch.argmax(model(dataset['test_input']), \n    dim=1) == dataset['test_label']).float())\n\nresults = model.train(dataset, opt=\"LBFGS\", steps=20, \n          metrics=(train_acc, test_acc), \n          loss_fn=torch.nn.CrossEntropyLoss())\n```\n\n## 모델로부터 심볼릭 공식 획득\n\n이후, 모델이 데이터로부터 학습한 내용을 나타내는 심볼릭 공식이 유도됩니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\nformula1, formula2 = model.symbolic_formula()[0]\n```\n\n## 정확도 계산하기\n\n마지막으로 학습된 공식에서 정확도를 얻을 수 있습니다.\n\n```python\ndef acc(formula1, formula2, X, y):\n    batch = X.shape[0]\n    correct = 0\n    for i in range(batch):\n\n        logit1 = np.array(formula1.subs('x_1', X[i,0]).subs('x_2', X[i,1])).astype(np.float64)\n        logit2 = np.array(formula2.subs('x_1', X[i,0]).subs('x_2', X[i,1])).astype(np.float64)\n\n        correct += (logit2 \u003e logit1) == y[i]\n\n    return correct/batch\n\n# 정확도 출력\nprint('학습 데이터 정확도:', acc(formula1, formula2, dataset['train_input'], dataset['train_label']))\n\nprint('테스트 데이터 정확도:', acc(formula1, formula2, dataset['test_input'], dataset['test_label']))\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n## 결과\n\n```js\n수식의 학습 정확도: tensor(0.9700)\n수식의 테스트 정확도: tensor(0.9660)\n```\n\n# 결론\n\n요약하자면, 콜모고로프-아놀드 네트워크(KANs)는 신경망 구조에서 패러다임 전환을 나타냅니다. KANs는 잠재력을 최대로 발휘하기 위해 추가 연구와 실험이 필요하지만, 앞으로 몇 년 동안 기계 학습과 과학적 발견을 진전시키는 데 유용한 도구로서의 가능성을 갖고 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n계속 발전하는 이 분야에서 KAN은 혁신의 선두에 서 있습니다. 지능 시스템의 미래를 형성하고 복잡한 데이터 분석과 모델링 방식을 혁명화하고 있습니다.","ogImage":{"url":"/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_0.png"},"coverImage":"/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_0.png","tag":["Tech"],"readingTime":6},{"title":"그래프 ML NetworkX 소개","description":"","date":"2024-06-20 04:49","slug":"2024-06-20-GraphMLintroductiontoNetworkX","content":"\n\n## | GRAPH| GRAPH ML| NETWORKX| PYTHON|\n\n![NetworkX](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_0.png)\n\nNetworkX는 Python에서 그래프를 분석, 시각화 및 표현하는 주요 라이브러리입니다. NetworkX에는 많은 함수 모음이 포함되어 있으며, 본 튜토리얼에서는 Python에서 그래프를 시작하고 조작하는 기본 기능을 소개하겠습니다. 다음 튜토리얼에서는 더 복잡한 기능 및 그래프를 더 잘 시각화하는 방법을 살펴볼 예정이지만, 일단은 기초부터 단계별로 시작하는 것이 좋습니다.\n\n이 글에서는 다음을 논의할 것입니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- NetworkX를 사용하여 그래프를 다루는 방법\n- 다양한 유형의 그래프 생성 방법\n- 그래프를 그리는 방법\n\n이 자습서의 코드는 Google Colab에서 작성되었으며 테스트되었으며 컴퓨터에 별도로 설치할 필요없이 어떤 Colab 노트북에서도 실행할 수 있습니다.\n\n# NetworkX 소개\n\nNetworkX에서 그래프는 일반적으로 객체(클래스)이며 이러한 객체에 적용할 수 있는 다양한 메서드와 함수가 있습니다. 또한 NetworkX는 그래프 데이터 세트를 읽고 객체를 저장하며 다양한 형식으로 저장하는 기능을 제공합니다. 라이브러리는 일부 고전적인 데이터 세트도 제공하여 사용하여 놀 수 있습니다(예: 카라테 클럽 데이터 세트).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n또한 NetworkX를 설치하고 사용하는 것이 실제로 쉽다는 것을 알 수 있을 것입니다 (Python의 기본 지식이 필요합니다). NetworkX는 확장성과 이식성으로 유명하며 이러한 이유로 Python에서 그래프를 처리하는 데 가장 많이 사용되는 라이브러리입니다. 이는 NetworkX와 호환되는 다른 데이터 과학자가 작성한 확장 프로그램의 생생한 생태계를 만들어냈습니다 (또는 NetworkX 그래프의 기반으로 사용됩니다).\n\n![그림](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_1.png)\n\n어떻게 시작할까요?\n\n첫 번째 단계는 라이브러리를 가져오는 것입니다 (이미 설치했다고 가정하거나 Colab을 사용 중이면 이미 설치되어 있을 것입니다).\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nimport networkx as nx\nimport matplotlib.pyplot as plt\n```\n\n그리고 이제는 어떻게 해야 할까요? 이전 튜토리얼에서 말했듯이 그래프는 단순히 객체(노드 또는 정점)들이 엣지를 통해 연결된 모음일 뿐입니다. 그래프는 이러한 노드들 사이의 관계를 나타내며, 이를 어떻게 표현할지 결정해야 합니다. 우리는 그래프가 직접적인 연결을 가지고 있는지, 또는 링크의 방향을 신경 쓰지 않는지를 결정해야 합니다.\n\n예를 들어, 한 그룹 내에서 다른 사람들 간의 우정 관계를 표현하고 싶다고 가정해 봅시다. 이 경우 A가 B의 친구라면 B가 A의 친구라고 가정할 수 있으며 따라서 관계를 표시할 필요가 없습니다. 만약 A에서 B로 소포가 이동하는 운송 그래프를 표현하고 있다면, 방향성 있는 그래프를 사용하는 것이 좋습니다.\n\nNetworkx에서 방향성 있는 그래프나 무방향 그래프를 구축하는 것은 매우 쉽습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n# 무방향 그래프 G 생성\nG = nx.Graph()\nprint(\"그래프 G는 방향이 지정되어 있습니다: {}\".format(G.is_directed()))\n\n# 유방향 그래프 H 생성\nH = nx.DiGraph()\nprint(\"그래프 H는 방향이 지정되어 있습니다: {}\".format(H.is_directed()))\n\n# 엣지와 노드 수 얻기\nG.number_of_nodes(), G.number_of_edges()\n\n\n![이미지](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_2.png)\n\n그래프를 구축한 후 추가 데이터를 수집하여 그래프를 업데이트해야 할 수 있습니다. NetworkX를 사용하면 노드를 추가하거나 다른 그래프를 직접 추가하기 쉽습니다.\n\n\n# 노드 추가\nG.add_node(1)\nG.add_nodes_from([2, 3])\n# 다른 그래프에서 추가할 수도 있습니다\nH = nx.path_graph(3)\nG.add_nodes_from(H)\n# 또는 그래프를 직접 추가할 수도 있습니다\nG.add_node(H)\nG.number_of_nodes(), G.number_of_edges()\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![Graph](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_3.png)\n\n당연히 A가 B와 친구이고 나중에 C와도 친구가 될 수 있으므로, 또 다른 링크를 추가하려고 합니다.\n\n```js\n#엣지 추가하기\nG.add_edge(1, 2)\ne = (2, 3)\nG.add_edge(e)\nG.add_edges_from([(1, 2), (1, 3)])\nG.add_edges_from(H.edges())\n```\n\n지금까지 그래프를 요소와 관계의 집합으로 삼았습니다. 노드는 모두 같았고, 관계도 단순한 연결이었습니다. 실제로 이는 축소된 것이며, 노드와 연결은 레이블 또는 기능과 연관될 수 있습니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, 소셜 네트워크를 만들 때 각 노드에 이름(label, 예: \"Bob\")을 부여하거나 클래스(\"스팸\" 또는 \"스팸 아님\")를 지정할 수 있지만 특성(키, 나이, 관심사)도 부여할 수 있습니다. 앞으로 볼 것처럼 노드의 특성은 다양한 알고리즘에서 사용됩니다.\n\n```js\n# 무향 그래프 G를 생성합니다\nG = nx.Graph() # 비어 있습니다\n# 첫 번째 노드에 노드 레벨 속성 추가\nG.add_node(0, feature=3, label=0)\n\n# 노드 0의 속성을 가져옵니다\nattr = G.nodes[0]\nprint(\"노드 0은 다음과 같은 속성을 가지고 있습니다: {}\".format(attr))\n```\n\n![image](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_4.png)\n\n이 경우 몇 개의 노드가 있는 그래프가 있지만, 종종 수천 개 또는 수백만 개의 노드가 있는 경우가 많으므로 더 효율적인 시스템이 필요할 수 있습니다. NetworkX를 사용하면 딕셔너리를 사용할 수 있습니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# 여러 노드에 속성을 포함한 노드를 추가할 수 있습니다\nG.add_nodes_from([\n  (1, {\"feature\": 1, \"label\": 1}),\n  (2, {\"feature\": 2, \"label\": 2})\n]) \n\n# 노드를 순회할 수 있습니다\n# 속성을 반환하려면 data=True 인수를 사용합니다\nfor node in G.nodes(data=True):\n  print(node)\n\n# 노드 수를 얻을 수 있습니다\nn_nodes = G.number_of_nodes()\nprint(\"G에는 {}개의 노드가 있습니다\".format(n_nodes))\n```\n\n![Graph](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_5.png)\n\n앞서 말했듯이, 관계에는 다양한 특성이 있을 수 있습니다. 가장 흔한 경우는 서로 다른 연결에 값을 (또는 가중치) 연결하는 것입니다. 예를 들어, 교통 네트워크에서 노드는 장소를 나타내고 연결은 도로를 나타낼 수 있으며, 가중치는 거리나 이동 시간을 나타낼 수 있습니다. 이는 노드 A와 B 사이의 최단 경로를 찾고 싶은 경우에 중요한 정보입니다 (나중에 이를 계산하는 알고리즘이 있다는 것을 볼 것입니다).\n\n```js\n# 가중치가 0.5인 하나의 엣지를 추가합니다\nG.add_edge(0, 1, weight=0.5)\n\n# 엣지 (0, 1)의 속성을 가져옵니다\nedge_0_1_attr = G.edges[(0, 1)]\nprint(\"(0, 1) 엣지는 다음과 같은 속성을 가지고 있습니다: {}\".format(edge_0_1_attr))\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n당연히 노드 단위로 작업할 필요는 없어요:\n\n```js\n# 엣지 가중치를 가진 여러 엣지 추가\nG.add_edges_from([\n  (1, 2, {\"weight\": 0.3}),\n  (2, 0, {\"weight\": 0.1})\n])\n\n# 모든 엣지들에 루프 적용\n# 여기서 data=True가 없으므로 엣지만 반환됩니다\nfor edge in G.edges():\n  print(edge)\n\n# 엣지의 수 구하기\nnum_edges = G.number_of_edges()\nprint(\"G에는 {}개의 엣지가 있습니다\".format(num_edges))\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_7.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n좋아요, 이제 멋진 그래프가 있어요! 그래프를 시각화해 보는 건 어떨까요?\n\n```js\n# 그래프 그리기\nnx.draw(G, with_labels=True)\n```\n\n![Graph](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_8.png)\n\n노드가 몇 개의 이웃을 가지고 있는지 알아내는 것은 종종 중요한 정보입니다. 예를 들어, 우리는 그래프를 플로팅하지 않고도 노드가 연결된 다른 노드 수를 알고 싶어합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\nnode_id = 1\n\n# 노드 1의 차수\nprint(\"노드 {}의 차수는 {}\".format(node_id, G.degree[node_id]))\n\n# 노드 1의 이웃 가져오기\nfor neighbor in G.neighbors(node_id):\n  print(\"노드 {}의 이웃은 {}\".format(node_id, neighbor))\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_9.png\" /\u003e\n\n# 서로 다른 그래프 유형\n\n이전 튜토리얼에서 우리는 그래프 유형이 다양하다는 것을 알 수 있었고 이러한 정보의 많은 부분이 인접 행렬에 요약되어 있다는 것을 알았습니다. 이제 이러한 그래프를 표현하고 시각화할 수 있는 모든 요소를 갖췄습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n예를 들어, 가장 간단한 경우인 무방향 그래프로 시작해 보겠습니다:\n\n```js\nG = nx.Graph()\nG.add_nodes_from([\n  (1, {\"feature\": 1, \"label\": 1}),\n  (2, {\"feature\": 2, \"label\": 2}),\n  (3, {\"feature\": 2, \"label\": 3}),\n  (4, {\"feature\": 1, \"label\": 4})\n]) \nG.add_edges_from([(2, 1), (1, 4), (4, 2), (4,3)])\n# 그래프 그리기\nnx.draw(G, with_labels = True)\nA = nx.adjacency_matrix(G)\nprint(A.todense())\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_10.png\" /\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_11.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다이렉트 그래프는 다양한 응용 분야에서 사용됩니다. 소셜 네트워크(예: A가 B에게 돈을 빌려줌), 전기 회로, 프로젝트 일정, 운송 등등.\n\n화살표는 일반적으로 관계의 방향을 나타내는 데 사용됩니다. 보시다시피 행렬도 다릅니다. 기술적으로 들어오는 간선과 나가는 간선을 나타내기 위해 두 개의 다른 행렬을 가져야합니다. 일반적으로, 우리는 나가는 간선을 나타내는 것을 사용합니다. 예를 들어, 여기서 간선을 시작하는 노드 1이 있고 이를 노드 4에 연결하는 간선이 있다면, 행렬에서 이 연결을 1로 나타냈습니다(위치는 1행 4열).\n\n```python\nG = nx.DiGraph()\nG.add_nodes_from([\n  (1, {\"feature\": 1, \"label\": 1}),\n  (2, {\"feature\": 2, \"label\": 2}),\n  (3, {\"feature\": 2, \"label\": 3}),\n  (4, {\"feature\": 1, \"label\": 4})\n]) \nG.add_edges_from([(2, 1), (1, 4), (4, 2), (4,3)])\n# 그래프 그리기\nA = nx.adjacency_matrix(G)\nprint(A.todense())\nnx.draw(G, with_labels = True)\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_12.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![그래프](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_13.png)\n\n앞서 언급했듯이 가중 그래프를 사용하는 경우가 있습니다. 예를 들어, 2D 매트릭스 게임, 그래프에 제약 조건을 적용해야 하는 경우 (제품 설계, 회로 설계). 또한 가중 그래프는 우선 순위 흐름을 지정하는 의존성 그래프와 같이 가중할 수도 있습니다.\n\n```js\nG = nx.Graph()\nG.add_nodes_from([\n  (1, {\"feature\": 1, \"label\": 1}),\n  (2, {\"feature\": 2, \"label\": 2}),\n  (3, {\"feature\": 2, \"label\": 3}),\n  (4, {\"feature\": 1, \"label\": 4})\n]) \nG.add_edges_from([(2, 1, {\"weight\": 0.5}),\n                  (1, 4, {\"weight\": 4}), \n                  (4, 2, {\"weight\": 0.5}), \n                  (4,3,  {\"weight\": 1})])\n# 그래프 그리기\n# 노드\npos = nx.spring_layout(G, seed=7) \nA = nx.adjacency_matrix(G)\nprint(A.todense())\nnx.draw_networkx_nodes(G, pos, node_size=50)\nwidth = []\nfor node1, node2, data in G.edges(data=True):\n    width.append(data['weight'])\nnx.draw_networkx_edges(G, pos,  width =width)\n```\n\n![그래프](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_14.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![image](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_15.png)\n\n지금까지 우리는 자체 루프(노드가 자기 자신과 연결될 때)가 없다고 결론 지었습니다. 그러나 화학, 유전학, 게임, 대기 이론 등에서 유용한 경우도 있습니다. 이전에 대각선에 1이 없었는데 이제 있습니다(노드가 실제로 자기 자신과 연결되어 있음을 볼 수 있습니다).\n\n```js\nG = nx.Graph()\nG.add_nodes_from([\n  (1, {\"feature\": 1, \"label\": 1}),\n  (2, {\"feature\": 2, \"label\": 2}),\n  (3, {\"feature\": 2, \"label\": 3}),\n  (4, {\"feature\": 1, \"label\": 4})\n]) \nG.add_edges_from([(2, 1), (1, 4), (4, 2), (4, 3), (4, 4), (2, 2)])\n# 그래프를 그립니다.\nA = nx.adjacency_matrix(G)\nprint(A.todense())\nnx.draw(G, with_labels=True)\n```\n\n![image](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_16.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\u003cimg src=\"/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_17.png\" /\u003e\n\n지금까지 각 노드 쌍 간에 하나의 연결만 있을 수 있다고 생각했지만, 이론적으로는 두 노드 사이에 더 많은 링크를 나타내야 할 수도 있습니다. 이 경우, Multigraph가 필요합니다.\n\n```js\nG = nx.MultiGraph()\nG.add_nodes_from([\n  (1, {\"feature\": 1, \"label\": 1}),\n  (2, {\"feature\": 2, \"label\": 2}),\n  (3, {\"feature\": 2, \"label\": 3}),\n  (4, {\"feature\": 1, \"label\": 4})\n]) \nG.add_edges_from([(2, 1), (2, 1), (1, 4), (4, 2), (4,3), (4,3), (4,3)])\nA = nx.adjacency_matrix(G)\nprint(A.todense())\n# Draw the graph\npos = nx.random_layout(G)\nnx.draw_networkx_nodes(G, pos, node_color = 'r', node_size = 100, alpha = 1)\nax = plt.gca()\nfor e in G.edges:\n    ax.annotate(\"\",\n                xy=pos[e[0]], xycoords='data',\n                xytext=pos[e[1]], textcoords='data',\n                arrowprops=dict(arrowstyle=\"-\u003e\", color=\"0.5\",\n                                shrinkA=5, shrinkB=5,\n                                patchA=None, patchB=None,\n                                connectionstyle=\"arc3,rad=rrr\".replace('rrr',str(0.3*e[2])\n                                ),\n                                ),\n                )\nplt.axis('off')\n```\n\n\u003cimg src=\"/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_18.png\" /\u003e\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n\n![이미지](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_19.png)\n\n양 부분 그래프(또는 이분 그래프)는 그래프 이론에 따르면 그래프의 꼭짓점을 두 가지 서로 다른 및 독립적인 집합으로 나눌 수 있는 그래프이며 각 간선이 꼭짓점을 서로 연결합니다. 양 부분 그래프는 암 검출, 전자 상거래 및 매칭 문제 등에서 사용됩니다.\n\n```js\nB = nx.Graph()\n# 노드 속성 \"bipartite\"를 가진 노드 추가\nB.add_nodes_from([1, 2, 3, 4], bipartite=0)\nB.add_nodes_from([\"a\", \"b\", \"c\"], bipartite=1)\n# 서로 다른 노드 집합 간에만 엣지 추가\nB.add_edges_from([(1, \"a\"), (1, \"b\"), (2, \"b\"), (2, \"c\"), (3, \"c\"), (4, \"a\")])\n# 그룹별로 분리\nl, r = nx.bipartite.sets(B)\npos = {}\n\n# 각 그룹에서 노드를 위한 위치 업데이트\npos.update((node, (1, index)) for index, node in enumerate(l))\npos.update((node, (2, index)) for index, node in enumerate(r))\n\nnx.draw(B, pos=pos)\nplt.show()\n```\n\n![이미지](/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_20.png)\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이전 글은 여기에서 찾을 수 있어요. 이 튜토리얼에서 사용된 모든 코드는 여기에서 찾을 수 있어요. 모든 튜토리얼 링크와 코드도 여기에 모아져 있을 거예요.\n\n# 결론\n\n이 튜토리얼에서는 NetworkX를 사용하여 그래프를 생성하고 노드와 엣지를 추가하고 피처를 할당하는 방법을 알아봤어요.\n다양한 종류의 그래프가 있고 NetworkX를 통해 파이썬에서 이를 정의하고 시각화할 수 있다는 것을 보았어요.\n다음 튜토리얼에서는 더 복잡한 경우와 추가적인 기능을 살펴볼 거예요. 또한, 노드를 분류하고, 노드 간 새로운 연결을 예측하거나, 노드를 커뮤니티로 그룹화하는 방법, 그래프 신경망 등을 적용하는 방법에 대해 논의할 거예요. 계속해서 주시길 바래요!\n\n# 이 내용이 흥미로웠다면:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n다른 기사를 찾아보거나 LinkedIn에서 저와 연락할 수도 있어요. 매주 업데이트되는 기계 학습 및 인공 지능 뉴스가 포함된 이 저장소를 확인해보세요. 협업과 프로젝트에 열려 있고 LinkedIn을 통해 저에게 연락할 수 있습니다. 새 이야기를 게시할 때 알림을 받고 싶다면 무료로 구독할 수도 있어요.\n\n여기 GitHub 저장소 링크입니다. 기계 학습, 인공 지능 및 기타 관련 자원을 수집하고 있어요.\n\n또는 제 최근 기사 중 하나에 관심이 있을지도 모릅니다:","ogImage":{"url":"/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_0.png"},"coverImage":"/assets/img/2024-06-20-GraphMLintroductiontoNetworkX_0.png","tag":["Tech"],"readingTime":11},{"title":"파이파이 앱을 코딩할 때 고려해야 할 13가지를 배운 것들","description":"","date":"2024-06-20 04:46","slug":"2024-06-20-13ThingsIveLearntToConsiderWhenCodingAFastAPIApp","content":"\n\n대학 시절에는 학교 프로젝트를 위해 쓸만한 한 페이지 FastAPI 백엔드 애플리케이션을 만들 수 있었어요. 솔직히 말해 많은 교수님들이 우리의 프로젝트 코드를 읽지도 않으셨다니까요.\n\n```python\n# 예시: 쓸만한 한 페이지 fastapi 앱\n\nfrom fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get('/stuff')\ndef get_all():\n    return {'과일': '사과'}\n\nimport uvicorn\nuvicorn.run(app)\n```\n\n^ 우리는 이렇게 코드를 작성해서 가능한 빨리 일을 끝낼 수 있었고, 우리의 백엔드 엔드포인트가 올바른 결과를 반환하기만 하면, 대부분의 경우 우리 코드가 얼마나 잘 작성되었는지는 아무도 신경쓰지 않았어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n저는 현재 대규모 프로덕션급 FastAPI 앱을 개발 중이에요. 만약 제가 이 중 하나라도 하게 된다면, 개발 책임자님에게 혼날 거라고 확신해요. 지난 몇 달 동안 대규모 FastAPI 앱을 만들며 배운 13가지 고려 사항을 소개해드릴게요.\n\n# 1) 타입 어노테이션 (타입 힌트)\n\n이전에 내 코드를 작성했던 방식은 다음과 같아요:\n\n```python\ndef do_stuff(a, b, c):\n    ...\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n지금 제가 코드를 작성하는 방식은 다음과 같습니다:\n\n```js\nfrom typing import List\n\ndef do_stuff(a: int, b: str, c: List[int]) -\u003e List[str]:\n    ...\n```\n\n여기서 내장 typing 모듈을 사용하여 몇 가지 타입 주석을 추가했습니다:\n\n- a는 정수여야 합니다.\n- b는 문자열이어야 합니다.\n- c는 정수들로 이루어진 리스트여야 합니다.\n- 함수의 반환 값은 문자열들로 이루어진 리스트여야 합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n노트 — 타입 어노테이션(또는 타입 힌트)은 데이터 타입을 강제하지 않습니다. 그저 제안하는 것뿐입니다. 기술적으로 잘못된 데이터 타입을 전달할 수 있지만, Python은 여전히 허용합니다.\n\n하지만, 타입 어노테이션을 작성하는 것은 내가 의도적으로 하는 선택입니다 — 나는 이것들을 다른 개발자들이 동일한 코드베이스에서 작업할 때 명확하고 이해하기 쉽도록 하기 위해 작성합니다. 이렇게 하면 다른 개발자들이 데이터 타입이 정확히 무엇인지 알아내기 위해 더 많은 시간을 낭비하지 않아도 됩니다.\n\n# 2) 정적 타입 체커를 사용하기\n\n타입 어노테이션은 데이터 타입을 강제하지 않지만, mypy와 같은 정적 타입 체커는 강제합니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```python\ndef add(a: int, b: int) -\u003e int:\n    return a + b\n\nprint(add('hello ', 'world'))\n```\n\n여기서 a와 b는 정수형이어야 하지만 문자열을 전달했습니다.\n\n- 일반적으로 Python은 이를 허용합니다\n- mypy와 같은 정적 형 검사 도구는 허용하지 않습니다\n\n따라서 데이터 유형 위반에 대한 추가적인 보호층으로 정적 유형 검사기를 CICD(지속적 통합 지속적 배포) 파이프라인의 일부로 포함하는 것이 중요하다는 것을 깨달았습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 3) PEP8 및 코드 스타일링\n\n링크: [https://peps.python.org/pep-0008/](https://peps.python.org/pep-0008/)\n\n예전에 코드를 작성할 때 PEP8을 무시했었어요. 그러다가 코드가 금방 지저분하고 못생기게 되는 것을 깨달았죠.\n\nPEP8 문서는 우리에게 Python 코딩 규칙을 제공하여 코드베이스를 일관되고 깔끔하게 유지하는 것이 이상적이라는 것을 알려줍니다. Python에서는 이를 무시할 수 있지만, 당신의 기술 리드는 그렇게 하지 말라고 할지도 몰라요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n내 머릿속에 기억나는 몇 가지 규칙이 있어요:\n\n- 함수 간에는 1줄의 개행을 추가해 주세요, 클래스 간에는 2줄의 개행을 넣어 주세요.\n- 들여쓰기는 탭 대신 공백을 사용해야 합니다.\n- from X import * 는 좋지 않은 습관입니다.\n- import 구문은 어떤 순서로든 정리되어야 합니다.\n- 코드 라인은 79자 이상으로 길어지면 안 됩니다.\n\n파이썬 개발자가 되고 싶다면, PEP8 문서를 한 번은 꼭 살펴보기를 추천해요. 대부분의 코딩 관례를 조금이라도 익히는 데 도움이 될 거예요.\n\n참고 — 때로는 제가 코드를 작성할 때 PEP8 규칙을 무시하기도 하지만, 프로덕션 코드를 작성할 때는 최대한 모든 규칙을 준수하려 노력하고 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 4) 폴더 구조 및 도메인\n\n학교 프로젝트에서는 어디에 .py 파일을 놓느냐에 상관없이 파일을 마구 놓을 수 있지만, 제품용 코드에서는 그렇게 할 수 없습니다.\n\n제품용 코드에서는 모든 사람이 따라야 할 폴더/파일 구조가 있습니다. 각 팀마다 약간씩 다를 수 있지만, 동일한 팀 구성원 모두가 합의해야 할 사항입니다.\n\n\nsrc/\n └── sqlmodels/\n    └── dog.py\n    └── cat.py\n    └── bird.py\n └── dbchanges/\n └── code/\n    └── bin/\n    └── utils/\n    └── web_api/\n        └── domain1\n          └── router.py\n          └── service.py\n          └── models.py\n        └── domain2\n          └── router.py\n          └── service.py\n          └── models.py\n        └── domain3\n          └── router.py\n          └── service.py\n          └── models.py\n └── requirements/\n.gitignore\nREADME.md\ndockerfile\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n여기는 내 제품용 FastAPI 코드의 매우 간소화된 버전입니다 (실제 폴더 구조는 훨씬 더 큽니다)\n\n참고 - 우리 응용 프로그램의 각 하위 섹션은 독립된 도메인 폴더가 제공됩니다.\n\n.MD 파일을 마크다운 형식으로 변경해주세요. \n\n.py 파일을 마음대로 어디에 둘 수 있고 아무도 신경 쓰지 않는 시절은 지나갔지만, 내가 주장하는 바에 의하면 이것은 좋은 일이라고 생각합니다 - 합의된 폴더 구조는 전체 프로젝트를 더 깔끔하고 유지 관리하기 쉽게 만듭니다.\n\nORM(객체-관계 매핑)을 사용하는 것이란 SQLAlchemy와 같은 것들.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n제가 학교 프로젝트에서 FastAPI 앱을 다룬 것을 기억해요:\n\n- 각 엔드포인트마다, 데이터에 접근할 때는 데이터베이스를 직접 호출했어요.\n- MongoDB에서 바로 사전을 받고, 곧바로 반환했어요.\n\n^ 다만 이 방법에는 문제가 있어요 — 앱이 커질수록 굉장히 지저분하고 유지보수하기 어려워져요. 작은 앱이라면 상관없을 수도 있지만, 대규모 앱에서는 어려울 거에요.\n\n크고 복잡한 애플리케이션에서는 SQLAlchemy와 같은 ORM (객체-관계 매핑) 시스템 사용이 좋은 아이디어라고 말할 수 있어요.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\r\n# 데이터베이스를 직접 호출하기\nquery = 'select * from dogs where age \u003c 5'\n\ncursor.execute(query)\ndogs = cursor.fetchall()\n\nprint(dogs)\r\n```\n\n```js\r\n# SQLALchemy 사용하기\nstmt = select(Dog).where(Dog.age\u003c5)\ndogs = session.execute(stmt)\n\nprint(dogs)\r\n```\n\nORM은 우리 데이터베이스를 감싼 래퍼인데, 시작하는 데는 학습 곡선이 있을 수 있어요. 하지만 거대한 응용프로그램에는 구조가 필요하다는 걸 기억해봐요.\n\n만약 FastAPI 앱에서 수천 개의 문자열 SQL 쿼리를 처리해야 한다면 상황은 좀 체증스러울 거에요 (코드베이스와 정신 건강 모두 말이에요)\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 6) 엔드포인트에 대한 입력 및 출력 정의\n\n나는 예전에 이렇게 엔드포인트를 작성했어요:\n\n```js\n# 나쁜 코드\n\n@app.get('/dogs')\ndef all_dogs():\n    return get_all_dogs()\n\n@app.get('/dogs/{id}')\ndef one_dog(id):\n    return get_dog(id)\n```\n\n^ 정확한 입력 및 출력 구조가 정의되지 않았어요. 문제점:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 다른 개발자들이 입력과 출력이 무엇인지 추측하는 데 시간을 낭비할 필요가 없어집니다\n- 미래에는 아마도 당신이 입력과 출력이 무엇인지 추측하는 데 시간을 낭비할 수도 있습니다\n\n결국 이렇게 코드를 작성하는 것을 배웠어요:\n\n```js\n# 덜 나쁜 코드\n\n@app.get(\n    '/dogs', \n    response_model=List[Dog],\n    name='모든 개 가져오기'\n)\ndef all_dogs() -\u003e List[Dog]:\n    return get_all_dogs()\n\n@app.get(\n    '/dogs/{id}',\n    response_model=DogWithMoreInfo,\n    name='아이디로 한 마리 개 가져오기'\n)\ndef one_dog(id: int) -\u003e Dog:\n    return get_dog(id)\n```\n\n^ 여기서 type 어노테이션을 사용하고 app.get() 내부의 response_model 키워드 인수를 사용하여 각 엔드포인트의 입력과 출력이 무엇이어야 하는지 훨씬 명확하게 만들었습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 7) 모델 간의 관계\n\n우리에게는 사람과 개가 있고, 한 사람이 여러 마리의 개를 소유할 수 있다고 가정해 봅시다.\n\n모델 간의 관계를 사용하기 전에, 다음은 우리의 Dog 모델이 어떻게 보일지에 대한 예시입니다:\n\n```js\n// dog\n{\n    \"name\": \"rocky\",\n    \"age\": 3,\n    \"owner_id\": 1\n}\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n기술적으로 우리는 이렇게 작성할 수 있어요:\n\n```js\n// dog\n{\n    \"name\": \"rocky\",\n    \"age\": 3,\n    \"owner_id\": 1,\n    \"owner\": {\n        \"name\": \"tom\",\n        \"age\": 30,\n        \"job\": \"teacher\"\n    }\n}\n```\n\n하지만 특히 수백 개의 API 엔드포인트를 다루고 있다면 이것이 지루할 수 있어요.\n\n대신, SQLModels 관계를 사용하여 우리의 삶을 더 쉽게 만들 수 있어요:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n```js\n# 매우 간단한 예시\n\nclass Human(HumanBase, table=True):\n    __tablename__ = 'humans'\n\n    dogs: list[\"Dog\"] = Relationship(back_populates='owner')\n\nclass Dog(DogBase, table=True):\n    __tablename__ = 'dogs'\n\n    owner: Human = Relationship(back_populates='dogs')\n```\n\n우리 엔드포인트 코드에서 response_model을 Dog로 설정하면 자동으로 Human 정보도 가져올 수 있습니다:\n\n```js\n{\n    \"name\": \"rocky\",\n    \"age\": 3,\n    \"owner_id\": 1,\n    \"owner\": {\n        \"name\": \"tom\",\n        \"age\": 30,\n        \"job\": \"teacher\"\n    }\n}\n```\n\n그리고 데이터베이스 내의 다른 중요한 관계들도 함께 가져옵니다.\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 8) 접근 제어 및 어떤 API에 누가 접근할 수 있는지\n\n학교 코드에서 기억하는 것은 모든 엔드포인트가 공개적이었다는 것입니다. 우리는 단지 엔드포인트의 입력과 출력이 올바른지에만 주의를 기울렸고, 다른 것들에는 그다지 신경을 쓰지 않았습니다.\n\n그러나 모든 것이 공개적으로 되어 있다는 것은 좋지 않은 실천 방법입니다.\n\n프로덕션 급 코드에서는 다음과 같은 시스템이 필요합니다:\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- API 호출을 하는 사용자 식별\n- 해당 사용자가 호출할 수 있는 API 엔드포인트 결정\n\n한 걸음 더 나아가면, 서로 다른 사용자가 볼 수 있는 결과를 제어할 수도 있습니다. 예를 들어:\n\n- 관리자는 모든 것을 볼 수 있음\n- 비관리자는 자신의 이름이 포함된 항목만 볼 수 있음\n\n이를 구현하는 하나의 올바른 방법이 없으므로 시간을 들여 신중하게 생각해보시기 바랍니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 9) 로깅\n\n프로덕션급 FastAPI 코드에서는 아마도 독립형 스크립트를 제외하고는 print()를 사용하지 않습니다.\n\n대신 로거를 사용합니다. 로깅의 몇 가지 장점:\n\n- 정보를 캡처하는 방법이 팀 전체에서 표준화됨\n- 여러 로깅 기능이 이미 구현되어 있어 그냥 사용하기만 하면 됨\n- 다양한 로깅 레벨은 애플리케이션을 실행할 때 얼마나 많은 출력을 원하는지 결정하는 데 매우 유용함\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n파이썬 백엔드/풀스택 개발자가 되고 싶다면, 로깅 라이브러리에 대해 배우거나 적어도 어느 정도는 알아야 합니다. 기억하세요 — 프로덕션급 코드에서는 print()를 많이 사용하지 않아요.\n\n# 10) 예외 처리\n\n여러 해 전에 예외를 처리했던 방법은 다음과 같습니다 (나쁜 방법):\n\n```js\ntry:\n    # 내 코드\nexcept Exception as e:\n    print(e)\n```\n\n\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프로덕션 수준의 FastAPI 코드베이스에서는 일반적으로 다음을 갖춥니다:\n\n- 상당수의 사용자 정의 예외\n- 이러한 사용자 정의 예외를 저장하기 위한 별도의 폴더\n- 정확히 어떤 예외를 잡고자 하는지 지정하는 보다 복잡한 예외 처리문\n- 단순히 print(e)를 출력하는 것 이상의 작업을 수행하는 예외 및 마지막 문에서 더 복잡한 코드\n\n예를 들어:\n\n```python\ntry:\n    # 어떤 코드\n\nexcept CustomException1 as e:\n    # 특별 처리 코드\n    \n    logger.info(str(e))\n\nexcept CustomException2 as e:\n    # 한 번 다시 시도하는 코드\n\n    logger.info(str(e))\n\nexcept CustomException3 as e:\n    # 이 예외를 기반으로 다른 예외 발생\n\n    raise CustomException4() from e\n\nexcept Exception as e:\n    logger.info(str(e))\n```\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n프로덕션 수준의 FastAPI 앱에서는 단순히 Exception as e로 모든 예외를 처리할 수 없습니다.\n\n# 11) 단위 테스트 및 기타 테스트\n\n학교 프로젝트에서는 테스트를 작성할 필요가 없었습니다. 주로 프레젠테이션 이후에는 코드를 더 이상 사용하지 않기 때문입니다.\n\n그러나 프로덕션 수준의 코드베이스에서는 단위 테스트뿐만 아니라 통합 테스트 등이 필수적입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 수십 개의 엔드포인트를 테스트해야 한다면 일종의 자동화된 테스트를 도입할 필요가 있어요.\n- 모든 사람이 테스트를 수작업으로 모든 것을 테스트하면 만족스럽지 않을 거예요.\n\n단위 테스트를 작성하는 것이 지루할 수 있지만, 나는 대규모 코드 베이스에서는 필수적이라는 것을 깨달았어요.\n\n테스트에 익숙하지 않다면 pytest 학습을 시도해 볼 수 있어요.\n\n# 12) 데이터의 업데이트 이력 추적\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n사용자가 데이터를 생성/업데이트/삭제할 때마다 이를 이상적으로는 어떤 종류의 히스토리 테이블에 기록해야 합니다.\n\n예를 들어, 사용자가 PUT 엔드포인트 중 하나를 사용하여 그의 개의 색상을 노란색으로 업데이트하고 이를 데이터베이스에 저장했다고 가정해보겠습니다.\n\n히스토리 테이블 내에서 이 작업을 추적하기 위해 다음과 같이 보일 수 있습니다.\n\n- 우리의 주요 개 데이터가 포함된 dogs 테이블이 있다고 가정해봅시다.\n- dogs 테이블에 있는 각 개에 대해 수행된 모든 변경 사항이 포함된 dog_history 테이블이 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n아래는 예시 워크플로우입니다:\n\n- 사용자 A가 자신의 강아지 색상을 노란색으로 업데이트합니다 (강아지 ID=100).\n- 우리는 강아지 테이블을 보통대로 업데이트합니다.\n- 그런 다음 강아지 이력 테이블에 새 항목을 삽입합니다.\n- 새 항목에는 1) 사용자 2) 타임스탬프 3) 변경된 필드 4) 이전 값 5) 새 값이 포함됩니다.\n- 예를 들어, \"사용자 A가 (ID가 100인 강아지)의 색상을 초록에서 노란색으로 변경했습니다.\"\n\n```js\n{\n    user=A, \n    dog_id=100, \n    field_changed='color', \n    old_value='green', \n    new_value='yellow',\n    timestamp=178787878787\n}\n```\n\n^ 이와 같이 사용자의 업데이트 작업을 추적할 수 있습니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n# 13) 데이터베이스 변경 추적\n\n대규모 프로덕션급 앱에서는 데이터 모델에 변경 사항이 있을 수 있습니다. 이를 데이터베이스에서 (테이블 수정이 필요한 경우) 변경할 필요가 있을 수 있습니다.\n\n- 일부 테이블에 열 추가가 필요할 수 있습니다.\n- 완전히 새로운 테이블을 추가해야 할 수도 있습니다.\n\n프로덕션급 앱에서는 데이터베이스를 직접 변경하지 않습니다. 여러 이유로 이는 최악의 실천 방법입니다.\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n- 변경 사항은 되돌릴 수 없습니다 — 누군가 변경을 실수하면 되돌릴 수 없어요\n- 변경 사항은 추적할 수 없습니다 — 누군가 변경을 실수하면 누가 그것을 했는지 알 수 없어요\n\n보통, 팀 내 모든 사람들이 데이터베이스에 가하는 모든 변경 사항을 포함하는 전통적인 dbchanges 폴더가 있습니다\n\n- 이 dbchanges 폴더에는 보통 여러 폴더가 포함되어 있습니다.\n- 각 폴더에는 일부 .xml 파일과 .sql 파일이 들어 있습니다. 이것들을 각각 changeset이라고 합니다.\n- 우리가 changeset을 실행하면 그 안에 있는 변경 사항이 데이터베이스에 적용됩니다.\n- 만약 changeset이 실수라면 데이터베이스가 손상되지 않도록 롤백을 수행할 수 있습니다.\n\n# 결론\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\n이해하기 쉽고 명확했기를 바랍니다.\n\n# 만약 나를 창작자로 지원하고 싶다면\n\n- 내 책을 구매해 주세요! — 파이썬에 대해 알지 못했던 101가지\n- 어디에서 찾을 수 있는지: https://payhip.com/b/vywcf\n- 해당 이야기에 50번의 박수를 쳐 주세요\n- 당신의 생각을 말해 주는 댓글을 남겨주세요\n- 이야기 중 가장 마음에 드는 부분을 강조해 주세요\n\n감사합니다! 이 작은 행동들은 큰 도움이 되며 정말 감사드립니다!\n\n\u003cdiv class=\"content-ad\"\u003e\u003c/div\u003e\n\nYouTube: [https://www.youtube.com/@zlliu246](https://www.youtube.com/@zlliu246)  \n\nLinkedIn: [https://www.linkedin.com/in/zlliu/](https://www.linkedin.com/in/zlliu/)  ","ogImage":{"url":"/assets/img/2024-06-20-13ThingsIveLearntToConsiderWhenCodingAFastAPIApp_0.png"},"coverImage":"/assets/img/2024-06-20-13ThingsIveLearntToConsiderWhenCodingAFastAPIApp_0.png","tag":["Tech"],"readingTime":11}],"page":"37","totalPageCount":154,"totalPageGroupCount":8,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true},"page":"/posts/[page]","query":{"page":"37"},"buildId":"Y-fCAg8BUV7y2HNFwX9AA","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>