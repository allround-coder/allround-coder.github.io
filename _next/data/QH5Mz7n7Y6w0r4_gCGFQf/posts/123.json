{"pageProps":{"posts":[{"title":"MERN 스택을 위한 업계 모범 사례","description":"","date":"2024-05-13 00:09","slug":"2024-05-13-IndustryBestPracticesfortheMERNStack","content":"\n\n## MERN 스택(MongoDB, Express.js, React, 그리고 Node.js)은 강력한 웹 앱을 구축하는 데 인기 있는 도구입니다! 웹 개발 세계는 계속 변화하지만, 이 스택은 여전히 많은 사람들에게 사랑받고 있어요.\n\n전문가들의 통찰력을 얻기 위해, 설명서만 의지하는 것보다는 MERN 스택 작업에 직접 경험이 있는 분과 이야기를 해보는 게 어떨까 생각했어요. 그래서 이런 생각을 했더니, Diliru Nagahawaththa씨와의 인터뷰 기회가 찾아왔답니다. 그는 경험 많은 소프트웨어 엔지니어로서 MERN 스택에 대한 업계 Best Practices에 대해 이야기 나누어 주셨습니다. 함께 알아보도록 할까요?\n\n\n\n# 전문가 소개: 딜리루 나가하와타\n\n나가하와타 씨는 스리랑카 정보기술 연구소 출신으로, 현재 클라우드 솔루션 인터내셔널에서 소프트웨어 엔지니어로 일하고 있습니다. \n\n딜리루 씨는 대학 시절과 프리랜서 활동을 통해 MERN 스택을 다루는 데 풍부한 경험을 가지고 있습니다. \n\n# 저와 딜리루가 가진 대화 중 중요한 부분들을 살펴보겠습니다.\n\n\n\n## 1. MERN 스택을 선택한 이유는?\n\n기술적인 측면과 최선의 방법에 접근하기 전에 Diliru에게 MERN 스택을 사용하는 이유 및 개발자들에게 널리 받아들여지는 이유를 물었습니다.\n\n## 2. 아키텍쳐\n\nMERN 아키텍처는 JavaScript와 JSON을 사용하여 프론트 엔드, 백 엔드, 데이터베이스의 세 가지 레벨 구조를 간단하게 만들 수 있습니다.\n\n\n\n![MERN](/assets/img/2024-05-13-IndustryBestPracticesfortheMERNStack_0.png)\n\n## 3. MERN과 함께 작업하기\n\nReact의 구성 요소 기반 아키텍처는 모듈식이고 재사용 가능한 코드를 가능하게 하여 효율성과 유지 보수성을 향상시킵니다. 백엔드에서 Express.js는 서버 측 로직을 단순화하여 경로와 미들웨어를 처리하기 쉽게 만듭니다.\n\nMERN의 주목할 만한 장점 중 하나는 클라이언트 및 서버 측에서 JavaScript를 통합적으로 사용한다는 것입니다. 이는 학습 곡선을 줄일뿐만 아니라 응용 프로그램의 다른 계층 간에보다 원활한 흐름을 용이하게 합니다. 데이터 처리에서 JSON의 강점은 이러한 일관성을 더욱 향상시킵니다.\n\n\n\n게다가, MongoDB의 유연성은 NoSQL 데이터베이스로서 스택에 매끄럽게 적응되며, 동적이고 발전하는 데이터 구조를 수용합니다. 이는 확장 가능한 애플리케이션을 위한 견고한 기반을 제공합니다.\n\n## 4. 도구 및 기술\n\n여러분도 알다시피, VS Code는 JavaScript 기반 개발에 널리 사용되는 인기 있는 IDE로, 코딩 경험을 향상시키기 위한 다양한 플러그인과 확장 기능을 제공합니다. Diliru와의 대화 중 그는 자신의 관점을 공유했어요\n\n![이미지](/assets/img/2024-05-13-IndustryBestPracticesfortheMERNStack_1.png)\n\n\n\n- 버전 관리: Diliru는 Git을 사용한 버전 관리가 중요하다고 말합니다. 변경 사항을 추적하는 것이 매우 중요합니다. 새로운 기능을 위한 별도의 브랜치를 만들어 깔끔하고 조직적으로 유지하는 것을 권장합니다.\n\n![MERN 스택을 위한 업계 모베스트 프랙티스](/assets/img/2024-05-13-IndustryBestPracticesfortheMERNStack_2.png)\n\n- 코드 품질: 그는 깨끗한 코드 작성이 중요하다고 생각합니다. ESLint 및 Prettier와 같은 도구를 사용하면 코드를 일관성 있게 작성하고 이해하기 쉽게 만들 수 있습니다. 모두가 동의하는 같은 스타일 가이드를 따르는 것과 같습니다.\n\n## 5. 모베스트 프랙티스\n\n\n\n- 데이터베이스 디자인: Nagahawaththa씨는 신중한 데이터베이스 디자인의 중요성을 강조합니다. MongoDB의 유연성을 활용하여, 응용 프로그램의 데이터 액세스 패턴과 스키마를 조율하는 것을 제안합니다.\n- 오류 처리: 견고한 오류 처리 메커니즘은 필수적입니다. Diliru는 서버 측과 클라이언트 측 오류 처리를 모두 구현하여 사용자 경험을 향상시키고 디버깅을 간소화할 것을 권장합니다.\n- 코드 모듈화: 모듈식 코드 구조를 유지하는 것은 확장성과 유지 관리성에 매우 중요합니다. Nagahawaththa씨는 코드를 작은 재사용 가능한 구성 요소로 분해하는 중요성을 강조합니다. 이 접근 방식은 개발자들 간의 협력을 강화하고 코드 테스트를 용이하게하며 미래의 업데이트나 수정을 간소화합니다.\n- 성능 최적화: 효율적인 성능은 모든 웹 응용 프로그램의 핵심 요소입니다. Diliru는 개발 프로세스 초기에 성능 최적화 전략을 통합하는 것을 권장합니다. 이는 데이터베이스 쿼리의 최적화, 서버 측 캐싱을 활용하고 클라이언트 측 렌더링 최적화를 위한 React 최상의 실천 방법을 채택하는 것을 포함합니다. 성능에 대한 선제적인 조치는 더 부드럽고 반응성 있는 애플리케이션으로 이어질 수 있습니다.\n- 보안 조치: 보안은 웹 개발에서 매우 중요합니다. Nagahawaththa씨는 잠재적인 취약점에 대비하기 위해 강력한 보안 조치를 시행하는 것을 강조합니다. 이는 사용자 입력을 유효성 검사하고 API 엔드포인트를 보안하며 최신 보안 관행에 대해 알아가는 것을 포함합니다. Diliru는 HTTPS와 같은 산업 표준 보안 프로토콜을 채택하여 데이터 무결성과 사용자 개인 정보 보호를 보장하는 것을 제안합니다.\n\n잘, 친구들, 이 훌륭한 엔지니어 Diliru Nagahawaththa와 함께 한 이 흥미로운 여정이 여기서 마무리됩니다. 그와 나눈 대화에서 많은 것을 배웠고, 그것을 여러분과 나누고 싶었기 때문에 여기 공유하게 되었습니다. 여러분도 가치 있는 인사이트를 얻으셨으면 좋겠어요. ☕💻\n\n제 SNS 계정:\n\n- GitHub\n- LinkedIn\n- Twitter","ogImage":{"url":"/assets/img/2024-05-13-IndustryBestPracticesfortheMERNStack_0.png"},"coverImage":"/assets/img/2024-05-13-IndustryBestPracticesfortheMERNStack_0.png","tag":["Tech"],"readingTime":3},{"title":"React 18에서 SSRServer Side Rendering을 구현하는 방법","description":"","date":"2024-05-13 00:08","slug":"2024-05-13-HowtoImplementSSRServerSideRenderinginReact18","content":"\n\n\"renderToPipeableStream\" 서버 API를 구현하는 방법을 배우세요. 이 API를 사용하면 React 트리를 HTML로 Node.js 스트림에 렌더링할 수 있습니다.\n\n![이미지](/assets/img/2024-05-13-HowtoImplementSSRServerSideRenderinginReact18_0.png)\n\nReact 18은 상호작용적 사용자 인터페이스를 구축하기 위한 인기있는 JavaScript 라이브러리의 최신 버전이며, 많은 새로운 기능과 개선 사항을 제공합니다. 특히 서버 측 렌더링(SSR)의 향상된 성능은 주목할 만한 기능입니다.\n\n이 글에서는 React의 SSR 기능을 유용한 코드 샘플과 예시와 함께 살펴보겠습니다. 하지만 먼저 클라이언트 측 렌더링과 서버 측 렌더링의 차이를 알아보겠습니다.\n\n\n\n클라이언트 측 렌더링 (CSR)은 웹 페이지를 클라이언트 측에서 렌더링하는 프로세스를 말합니다 (즉, 사용자의 웹 브라우저에서). 서버는 단순히 원시 데이터나 콘텐츠를 제공하며, 클라이언트 측 JavaScript가 이를 활용하여 최종 렌더링된 페이지를 동적으로 구성합니다.\n\n서버 측 렌더링 (SSR)은 서버에서 웹 페이지를 렌더링한 후 해당 페이지를 클라이언트의 웹 브라우저로 보내는 프로세스를 의미합니다. 클라이언트 측에 의존하는 대신 서버가 웹 페이지의 최종 HTML 마크업을 생성하고 이를 클라이언트로 보내는 방식을 사용합니다.\n\n# \"renderToPipeableStream\" 서버 API 구현하기\n\n단계 1: create-react-app 명령줄 도구를 사용하여 새로운 React 애플리케이션을 만듭니다. 즐겨 사용하는 터미널을 열고 아래 명령어를 입력하세요.\n\n\n\n```js\nnpx create-react-app server-api-demo-app\n```\n\n단계 2: 새로 생성된 React 앱으로 이동합니다.\n\n```js\ncd server-api-demo-app\n```\n\n단계 3: 이제 프로젝트에 라우팅을 처리하기 위해 react-router-dom을 추가해주세요.\n\n\n\n```js\nnpm install react-router-dom\n```\n\n4단계: 애플리케이션에 몇 개의 페이지를 추가해 봅시다. app.js에 아래와 같이 추가할 수 있는 샘플 라우트를 추가해보세요:\n(i) 홈\n(ii) 소개\n\n```js\nconst App = () => (\n  <div>\n    <Routes>\n      <Route path=\"/\" element={<Home />}></Route>\n      <Route path=\"/about\" element={<About />}></Route>\n    </Routes>\n  </div>\n);\n```\n\n5단계: 두 페이지에 내용을 추가해보세요. 참고를 원하시면, 여기를 클릭하세요.\n\n\n\n6단계: 루트 수준에 \"server\"라는 새 폴더를 만들고, 그 안에 index.js와 server.js라는 새 파일을 만듭니다. 아래 코드를 해당 파일에 복사하여 붙여넣기하세요.\n\n```js\n// server/index.js\nrequire(\"ignore-styles\");\n\nrequire(\"@babel/register\")({\n  ignore: [/(node_modules)/],\n  presets: [\"@babel/preset-env\", \"@babel/preset-react\"],\n});\n\nrequire(\"./server\");\n```\n\n이 코드 조각은 Babel을 코드 번역을 위해 설정하고, \"node_modules\"와 같은 특정 파일을 필터링하며, \"server\" 모듈을 가져와 서버를 실행합니다. 이 설정은 React 서버 측 렌더링에서 일반적으로 사용되며, 서버가 React 구성 요소를 처리하고 클라이언트에 제공할 수 있도록 합니다.\n\n```js\n// server/server.js\nimport express from \"express\";\nimport React from \"react\";\nimport ReactDOMServer from \"react-dom/server\";\nimport { StaticRouter } from \"react-router-dom/server\";\nimport App from \"../src/App\";\n\nconst app = express();\n\napp.get(\"/*\", (req, res) => {\n  const entryPoint = [\"/main.js\"];\n\n  const { pipe, abort: _abort } = ReactDOMServer.renderToPipeableStream(\n    <StaticRouter location={req.url}>\n      <App />\n    </StaticRouter>,\n    {\n      bootstrapScripts: entryPoint,\n      onShellReady() {\n        res.statusCode = 200;\n        res.setHeader(\"Content-type\", \"text/html\");\n        pipe(res);\n      },\n      onShellError() {\n        res.statusCode = 500;\n        res.send(\"<!doctype html><p>Loading...</p>\");\n      },\n    }\n  );\n});\n\napp.listen(3002, () => {\n  console.log(\"App is running on http://localhost:3002\");\n});\n```\n\n\n\n위 코드는 app.get(\"/*\", ...)을 사용하여 모든 경로에 대한 라우트 핸들러를 정의합니다. 이는 서버로 들어오는 모든 요청을 처리하는 라우트 핸들러를 의미합니다. 라우트 핸들러 내부에서:\n\n- entryPoint 배열은 main.js 값을 가지고 정의됩니다. 이는 클라이언트 측 코드를 부트스트랩하는 데 사용되는 JavaScript 파일을 가리킵니다.\n- ReactDOMServer.renderToPipeableStream()은 HTML 렌더링을 위한 React 노드와 스트리밍 옵션을 포함하는 선택적 옵션 객체 두 가지 인수를 받습니다. 이는 두 가지 메소드를 반환하는데, pipe와 abort입니다. pipe 메소드는 HTML을 지정된 Node.js 스트림으로 출력합니다. 우리는 onShellReady에서 스트리밍을 가능하게 하기 위해 pipe를 사용합니다. 정적 생성 및 크롤러를 위해 onAllReady도 사용할 수 있습니다.\n- onShellReady()는 렌더링 프로세스가 완료되고 HTML이 클라이언트 전송을 위해 준비된 경우 트리거됩니다. 이는 응답 상태 코드를 200으로 설정하고, 내용 유형 헤더를 text/html로 정의하며, 렌더링된 HTML을 응답에 pipe 메소드를 사용하여 보냅니다.\n- onShellError() 콜백은 렌더링 중 오류가 발생할 때 트리거됩니다. 이는 응답 상태 코드를 500으로 설정하고, HTML `p` 태그로 감싼 기본 오류 메시지를 전송합니다.\n\n7. 클라이언트 측에서는 index.js 파일에서 ReactDOM.createRoot를 ReactDOM.hydrateRoot로 업데이트해야 서버에서 생성된 HTML을 인터랙티브하게 만들 수 있습니다.\n\n```js\n// index.js\nimport React from \"react\";\nimport ReactDOM from \"react-dom\";\nimport { BrowserRouter } from \"react-router-dom\";\nimport App from \"./App\";\n\nReactDOM.hydrateRoot(\n  document,\n  <React.StrictMode>\n    <BrowserRouter>\n      <App />\n    </BrowserRouter>\n  </React.StrictMode>\n);\n```\n\n\n\n8. 서버 측에서 코드를 실행하려면 package.json 파일에 아래 스크립트를 추가하세요.\n\n```js\n\"ssr\": \"npm run build && node server/index.js\"  \n```\n\n이 명령은 프로젝트를 빌드하고 서버 측에서 코드를 실행하여 localhost:3002에 출력물을 생성합니다.\n\n9. 이제 npm run ssr 명령을 실행하여 출력물을 확인하세요.\n\n\n\n![이미지](/assets/img/2024-05-13-HowtoImplementSSRServerSideRenderinginReact18_1.png)\n\n여기에서는 \"renderToPipeableStream\" API만 소개했습니다. React는 \"renderToNodeStream\", \"renderToReadableStream\", \"renderToStaticMarkup\", \"renderToStaticNodeStream\" 및 \"renderToStream\"과 같은 다른 API도 제공하여 요구사항에 맞는 서버 측 렌더링을 지원합니다.\n\n이러한 API에 대한 자세한 정보는 공식 문서를 참조해주시기 바랍니다.\n\n# 결론\n\n\n\n새로운 서버 API로 React 컴포넌트를 서버 렌더링된 HTML로 렌더링할 수 있습니다. Node.js 스트림이나 웹 스트림으로 가능합니다.\n\n대부분의 경우에는 Next.js, Remix, Gatsby와 같은 프레임워크가 이 프로세스를 자동으로 처리합니다. 이 API는 앱의 최상위 수준에서 서버 렌더링된 HTML을 빌드하는 데만 사용됩니다. 초기 로드 시간, SEO, 사용자 경험 및 크로스사이트 스크립팅(XSS) 공격에 대한 취약성을 감소시킬 것입니다.\n\n그러나 SSR은 이점을 제공하면서도 복잡한 구현, 증가한 서버 부하로 인한 상당량의 처리 및 메모리 소비와 같은 단점도 가지고 있습니다. 또한 채팅 앱 및 멀티플레이어 게임과 같은 실시간 애플리케이션에는 적합하지 않을 수 있습니다.\n\n따라서 요구 사항을 고려하고 SSR 구현이 해당 요구 사항과 일치하는지 확인해 주세요.","ogImage":{"url":"/assets/img/2024-05-13-HowtoImplementSSRServerSideRenderinginReact18_0.png"},"coverImage":"/assets/img/2024-05-13-HowtoImplementSSRServerSideRenderinginReact18_0.png","tag":["Tech"],"readingTime":5},{"title":"개발자들이 가져야 할 미덕 게으름, 성급함, 오만함","description":"","date":"2024-05-13 00:06","slug":"2024-05-13-WhyLazinessImpatienceandHubrisAreProgrammersGoldenVirtue","content":"\n\n## 프로그래밍 이야기\n\n<img src=\"/assets/img/2024-05-13-WhyLazinessImpatienceandHubrisAreProgrammersGoldenVirtue_0.png\" />\n\n저는 회사에 처음 입사했을 때, 매일 통신 시스템의 테스트 결과 로그를 분석하는 작업을 맡았습니다. 그 당시는 90년대였고, UNIX 워크스테이션이 사용되고 있어서 핵심 작업은 텍스트를 시각적으로 따라가는 것이었습니다.\n\n각 경우마다 작업에 약 2시간이 걸렸습니다. 각 테스트마다 로그에는 200만에서 300만 줄이 들어있었는데, 물론 모든 것을 시각적으로 확인하는 것은 불가능했기 때문에 로그 분석 도구가 준비되었습니다. 그러나 여전히 많은 부분을 시각적으로 검사해야 했기 때문에 체크하기 쉽지 않았습니다. 시간이 많이 소요되는 작업이었습니다.\n\n\n\n그 일을 하루 이틀 해 본 후, 내 불만이 절정에 달했어(성급하게), 그래서 내 눈으로 탐색할 필요 없이 로그 분석 도구의 결과물을 자동으로 더 분석하기로 결정했어. 내가 했었던 것(1. 태만함).\n\n물론, 이 사실을 상사에게 이야기하면, 그들은 즉시 부인할 거야. 그래서 나는 혼자 시작하기로 결정했어(3. 오만함 → 그러나, 이게 맞는지는 모르겠어. 아마 아니야).\n\n첫 번째 버전을 만드는 데 10시간 이상이 걸렸어. 물론, 그동안 내 분석 작업은 전혀 진전되지 않았어. 그래서 실행해 보니 버그가 가득했어. 그런 걸 만드는 게 익숙하지 않아서, 이건 정상적인 일이야.\n\n그러나 나는 포기하지 않고 계속 수정작업을 반복했어. 복잡한 정규 표현식 패턴, 유한 오토마타 개념, 및 lexer와 parser를 만드는 방법을 배우며. 프로그램이 자동으로 분석할 수 있는 것을 시각적으로 확인할 필요가 없는 바보 같은 일을 하고 싶지 않았어.\n\n\n\n약 일주일 만에 우리는 간단한 언어로 확인하려는 테스트 순서를 정의할 수 있는 매우 기능적인 확인 도구를 만들었어요. 여러 차례 테스트해보았고, 완벽하게 작동함을 확인했어요.\n\n테스트 순서가 정의되면, 이 도구는 테스트 결과가 올바른지 약 10초 안에 확인할 수 있어요. 그래서 일주일 이상 방치되어 있던 분석 작업이 반나절 이내에 완료되었답니다.\n\n그래서 같은 작업을 하는 다른 팀원들에게도 사용해보라고 제안했어요. 당연히 팀의 작업 부담은 급격하게 줄었답니다.\n\n그 이후로, 몇 분 안에 수행할 수 있는 작업이라도 반복이 필요하다면 몇 시간이 걸리더라도 도구를 만들어 자동화하는 내 스타일을 고수해왔어요. 특히 업무 코딩할 때 많이 활용했답니다.\n\n\n\n가능한 한, 저는 입력 완성 기능이 없는 편집기가 없던 시절에 직접 입력하는 대신 프로그램을 자동으로 생성했어요.\n\n물론 처음에는 작업 효율이 비교적 낮았어요 (예를 들어, 2시간이 걸리는 작업을 10초로 자동화하여 10분이 걸리는 것으로 대체하는 것). 그래도 익숙해지면 약 10분 정도만에 빠르게 도구를 만들 수 있었어요.\n\n그 시기에 다른 사람들이 며칠이 걸리는 작업을 몇 시간 만에 프로그램을 만들 수 있는 사람이 되었고, 팀 내에서의 평판이 상당히 좋아졌어요.\n\n결과적으로, 내 이름은 다른 부서에도 알려지게 되었고, 회사의 운명에 따라 의존해야 하는 필수 프로젝트의 일원으로 채용되었어요. 그 중에서도 산업 최초의 Java 기반 프로젝트와 같은 중요한 프로젝트에 참여하게 되었죠.\n\n\n\n이야기가 회사에서의 네 번째 해까지의 이야기입니다. 나머지 이야기는 너무 길어서 생략하겠습니다.\n\n모든 사람들은 서로 다른 특성을 가지고 있고, 래리 월(Larry Wall)이 말하고자 하는 바와 얼마나 일치하는지 모르겠지만, 매우 일반적인 관점에서 보면 그렇게 멀지 않다고 생각해요. 그렇다고 무조건 그런 것은 아니라고 생각해요.\n\n하지만 당시에는 주변 사람들이 각자 자신만의 언어를 개발하고 그것을 전적으로 프로젝트에 활용했기 때문에, 나는 특별히 재능 있는 것은 아니었어요. 이에 대해 다른 사람이 이야기해야 한다고 생각해요. 또한 제 이야기가 그냥 '90년대 예시'에 불과하다는 점을 강조하고 싶어요.\n\n오늘날 IT 산업은 90년대보다 훨씬 밝은 발전 양식을 보여주고 있어요. 제 당시 스타일은 독이 되는 편일 것입니다. 현재의 나의 관점에서도 \"그게 무슨 문제가 있지?\"라고 생각하지만, 당시에는 그것이 통했어요. 위에 쓴 것은 참고용 예시가 아니라 설명을 위한 샘플일 뿐이에요.\n\n\n\n나에게 프로그래밍은 지루하지만 재미있고, 어려움을 겪어본 적이 없다. 처음에는 성별에 맞았던 것 같다. 사람마다 장단점이 있지요.\n\n한편, 친구는 프로그램을 몇 개 만들어도 재미있는 게 뭔지 모른다고 했다. 그런 사람들에게는 프로그래밍이 빈소 같은 건 아닐까 싶어요. \"특성\"이 이런 면을 포함한다고 말할 수 있습니다.\n\n가장 재능 없는 사람은 프로그래밍이 재밌다고 완전히 집착하고 있어요! 프로그래밍이 짐으로 여기지 않고 \"쓰는 걸 즐기는\" 사람들은 잘못된 프로그램을 만들더라도 계속해서 프로그램을 작성하는 경향이 있어요.\n\n프로그래밍 자체가 목적인 만큼, 이해가 돼요. \"유용한 도구\"를 만드는 걸 즐기고, 프로그래밍을 싫어해요. 그 차이가 클 것이라고 생각돼요.\n\n\n\n# 친절한 영어로 🚀\n\nIn Plain English 커뮤니티에 참여해 주셔서 감사합니다! 떠나시기 전에:\n\n- 작가를 클로밍하고 팔로우해 주세요️ 👏️️\n- 팔로우하기: X | LinkedIn | YouTube | Discord | Newsletter\n- 다른 플랫폼 방문하기: Stackademic | CoFeed | Venture | Cubed\n- PlainEnglish.io에서 더 많은 콘텐츠 확인하기","ogImage":{"url":"/assets/img/2024-05-13-WhyLazinessImpatienceandHubrisAreProgrammersGoldenVirtue_0.png"},"coverImage":"/assets/img/2024-05-13-WhyLazinessImpatienceandHubrisAreProgrammersGoldenVirtue_0.png","tag":["Tech"],"readingTime":3},{"title":"JavaScript 이벤트 루프와 비동기 프로그래밍 이해하기","description":"","date":"2024-05-13 00:05","slug":"2024-05-13-JavaScriptUnderstandingEventLoopAsynchronousProgramming","content":"\n\n<img src=\"/assets/img/2024-05-13-JavaScriptUnderstandingEventLoopAsynchronousProgramming_0.png\" />\n\n자바스크립트는 한 번에 하나의 작업을 이벤트 큐에서 처리하기 때문에 싱글 스레드 언어라는 점을 알고 계실 것입니다. 현재 작업이 완료되기 전까지는 다른 작업을 수행할 수 없습니다. 비동기 작업을 처리하는 방식을 이해하는 데 이 특징은 중요합니다.\n\n매우 명확해 보이죠? 그런데 비동기적으로 작업을 수행해야 한다면 어떻게 해야 할까요? 시간이 필요한 단계를 수행해야 하지만 사용자 인터페이스가 멈춰있는 것을 원치 않을 때는 어떻게 해야 할까요?\n\n예를 들어, setTimeout을 사용하여 타이머를 설정하거나 API에서 데이터를 가져올 때, 이와 같이 반만 로드된 웹 사이트를 사용자에게 보여주고 싶지는 않을 것입니다.\n\n\n\n![JavaScript Event Loop and Asynchronous Programming](/assets/img/2024-05-13-JavaScriptUnderstandingEventLoopAsynchronousProgramming_1.png)\n\n요약해보겠습니다. JavaScript를 단일 스레드 언어로 생각할 때, 위 스니펫은 \"Apple\" → \"Elephant\" → \"Orange\" 순서로 로그를 남길 것으로 생각할 수 있습니다.\n\n하지만 실제 결과는 \"Apple\" → \"Orange\" → \"Elephant\" 순서로 나타납니다.\n\n- console.log(‘Apple’) : 이 부분은 콘솔에 \"Apple\"을 동기적으로 기록합니다.\n- setTimeout(() => console.log('Elephant'), 0): 이 부분은 \"Elephant\"를 0밀리초의 지연 후 콘솔에 기록하기로 예약합니다. 그러나 지연이 0밀리초로 지정되어 있더라도, Node.js와 같은 JavaScript 엔진은 이 작업을 콜백 큐로 밀어 넣어 모든 동기적 작업이 완료된 후에 실행되도록 합니다.\n- console.log('Orange'): 이 부분은 첫 console.log('Apple') 문 이후에 콘솔에 \"Orange\"을 동기적으로 기록합니다.\n- 결국, 모든 동기적 작업이 완료된 후 이벤트 루프가 타임아웃 작업을 가져와 \"Elephant\"를 콘솔에 기록합니다.\n\n\n\n# 이벤트 루프\n\n이전에 언급한 대로 JavaScript는 한 번에 한 가지 일만 할 수 있기 때문에 비동기 작업을 관리하고 이러한 블로킹 함수가 다른 이벤트의 실행을 방해하는 것을 방지하는 메커니즘이 필요합니다.\n\n이 메커니즘을 \"이벤트 루프\"라고 합니다. 기본적으로 비동기 함수가 발견되면 이후에 실행할 콜백 대기열에 추가되어 런타임이 동기 코드를 계속 실행하도록 허용합니다.\n\n여기 JavaScript 이벤트 루프 모델이 있습니다:\n\n\n\n![이미지1](/assets/img/2024-05-13-JavaScriptUnderstandingEventLoopAsynchronousProgramming_2.png)\n\n![이미지2](/assets/img/2024-05-13-JavaScriptUnderstandingEventLoopAsynchronousProgramming_3.png)\n\n1. 호출 스택:\nJavaScript는 호출 스택을 사용하여 프로그램 내의 함수를 추적하고 동기 방식으로 함수 호출을 관리합니다. 함수가 호출되면 호출 스택의 맨 위에 추가되며, 함수가 반환되면 스택에서 제거됩니다. 이 프로세스는 나중에 추가된 것이 먼저 제거되는 (Last In, First Out, LIFO) 원칙을 따릅니다.\n\n2. 메모리 힙:\nJavaScript 런타임에서 메모리 힙은 동적으로 할당된 객체와 변수가 위치하는 메모리 영역입니다.\n\n\n\n3. Callback Queue:\n비동기 함수의 콜백이 대기열에 저장되어 있고, 호출 스택이 비어 있을 때 실행을 위해 대기하는 곳입니다. 이벤트 루프가 이를 처리하기 위해 가져와서 처리합니다.\n\n4. 이벤트 루프:\n이벤트 루프는 콜백 대기열과 호출 스택을 모니터링하는 계속적으로 실행되는 프로세스입니다. 호출 스택이 비어 있지 않으면, 이벤트 루프는 호출 스택이 비어질 때까지 기다렸다가 다음 함수를 콜백 대기열에서 호출 스택으로 이동시킵니다.\n\nJavaScript 자체는 본질적으로 동기적이지만, Web API 및 이벤트 루프와 같은 메커니즘을 통해 비동기 작업을 효과적으로 처리할 수 있습니다.\n\n# 작업 및 마이크로작업\n\n\n\n더 자세히 살펴보면, 실행 문맥에는 두 가지 다른 유형이 있습니다: 작업과 마이크로태스크가 있습니다. JavaScript의 이벤트 루프에서 언제 실행되는지에 따라 다른 우선순위를 갖습니다.\n\n호출 스택이 비어있을 때, 먼저 마이크로태스크 큐를 확인합니다. 마이크로태스크 큐도 비어있으면 태스크 큐에 있는 함수를 실행하기 시작합니다.\n\n태스크\n\n태스크는 이벤트 루프에서 더 높은 수준의 작업 단위입니다. 일반적으로 I/O 작업, 렌더링 및 사용자 입력 이벤트와 같은 다른 비동기 이벤트가 포함됩니다.\n\n\n\n일반적인 작업 예시로는 setTimeout, setInterval, DOM 조작, 그리고 사용자 상호작용을 위한 이벤트 리스너 등이 있습니다.\n\n마이크로태스크\n\n마이크로태스크는 이벤트 루프에서 작업보다 우선순위가 높은 하위 수준의 작업 단위입니다. 일반적으로 브라우저가 렌더링을 수행하거나 다른 상위 수준의 작업을 수행하기 전에 실행되어야 하는 비동기 작업에 사용됩니다.\n\n예시로는 프로미스(해결됨 또는 거부됨)과 변이 관찰자가 있습니다.\n\n\n\n![JavaScript Event Loop](/assets/img/2024-05-13-JavaScriptUnderstandingEventLoopAsynchronousProgramming_4.png)\n\n요약하자면, JavaScript의 이벤트 루프는 웹 API에 작업을 전달하고, 그 작업을 태스크 큐에서 가져와 콜 스택에서 실행하는 주기적인 프로세스를 포함합니다. 작업을 지속적으로 관리하는 이 프로세스는 JavaScript에서 실행 흐름을 주도합니다.\n\n# 참고 자료\n\n[Philip Roberts: 이벤트 루프가 도대체 뭐길래]\n(https://youtu.be/8aGhZQkoFbQ)\n\n\n\n[JavaScript의 콜 스택이란 무엇인가요?]\nhttps://www.linkedin.com/pulse/what-call-stack-javascript-jay-tillu-252vf/\n\n[이벤트 루프 - 친숙하면서도 낯선 것들]\nhttps://medium.com/@Hsu.Yang-Min/event-loop-a61631e0048b","ogImage":{"url":"/assets/img/2024-05-13-JavaScriptUnderstandingEventLoopAsynchronousProgramming_0.png"},"coverImage":"/assets/img/2024-05-13-JavaScriptUnderstandingEventLoopAsynchronousProgramming_0.png","tag":["Tech"],"readingTime":4},{"title":"네이드 포 스피드 C, NET 8 SSE  채널을 활용한 LLMs Beyond OpenAI, Llama3 및 Fireworksai","description":"","date":"2024-05-13 00:03","slug":"2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai","content":"\n\n<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*YtK6hvB_PrUvd7uwqrk0-w.gif\" />\n\n# 요약\n\n- OpenAI의 GTP-4는 일반적인 목적의 작업에 있어 압도적인 성능을 보여주지만, 전체적인 처리량(또는 오히려 그 부족함)이 많이 부족하다는 점이 매우 아쉽습니다. 이는 \"오프라인\" 작업에는 훌륭하지만, 사용자들이 더 많은 응답성을 기대하는 응용 프로그램에서는 적합하지 않을 수 있으며, 몇몇 사용 사례들은 하위 UX로 인해 배제될 수도 있습니다.\n- TheFastest.ai 팀의 최근 Hackernews 게시물은 모델과 플랫폼 모두에 대해 이런 차이가 얼마나 클 수 있는지를 강조하고 있습니다. 특히, Groq.com(Musk의 Grok와 혼동하지 말아야 합니다)와 Meta의 Llama 3 70B를 사용한 Fireworks.ai는 일부 작업에서 GPT-4와 비교했을 때 출력에 거의 희생 없이 빠른 처리량을 제공합니다.\n- C#/.NET 8 System.Threading.Channels와 서버 전송 이벤트(SSE)를 결합하면, OpenAI의 처리량과 높은 지연 시간으로 잘 동작하지 않은 작업을 구성할 수 있습니다.\n\n# 소개\n\n\n\nGPT-5를 기다리는 동안, 2024년 5월 OpenAI의 GPT-4가 여전히 LLM으로서 전반적인 성능 면에서 우수하다는 것에 대해 논쟁하는 사람은 거의 없을 것입니다. 그러나 해당 모델은 비교적 낮은 처리량과 높은 대기 시간으로 인해 UX가 더 상호 작용적인 경험을 요구하는 경우에는 최적이 아닐 수 있습니다.\n\n가장 빠른 LLM과 현재 사용 가능한 플랫폼과 OpenAI 간의 대기 시간 차이의 규모가 얼마나 큰지는 명백하지 않을 수 있습니다.\n\n최근 Hackernews 스레드를 통해 TheFastest.ai로 이동하게 되었고, Meta의 Llama 3의 높은 처리량과 Groq.com 및 Fireworks.ai라는 두 플랫폼에 흥미로웠습니다.\n\n(전자는 종종 머스크의 Grok AI와 혼동되기 때문에 불행합니다).\n\n\n\n이 기사에서는 Fireworks.ai, Meta Llama 3 8B/70B, .NET 8, System.Threading.Channels 및 Server Sent Events (SSE)를 사용하여 앱을 만드는 방법을 살펴볼 것입니다.\n\n# 차이를 측정하기\n\n스택의 상단은 Llama-3과 Groq가 지배하고 Fireworks.ai가 상위 5위를 차지하고 있습니다(각 팀이 Fireworks를 선택해야 할 이유에 대해 조금 뒤에 설명하겠습니다).\n\n![이미지](/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_0.png)\n\n\n\n대조적으로, OpenAI의 GPT-4는 거의 맨 아래쪽에 위치합니다.\n\n![이미지](/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_1.png)\n\nOpenAI의 GPT-4를 사용해본 사람이라면 이미 처리량이 얼마나 낮은지를 알고 있을 것입니다. 하지만 이렇게 측정된 값을 보면 그 간격이 얼마나 큰지 더욱 부각됩니다. Groq의 Llama-3 70B는 GPT-4보다 거의 10배 더 높은 처리량을 가지고 있습니다!\n\n이에 따라, GPT-4는 상호 작용이 필요하지 않은 경우에, 작업이 큰 문맥 창을 요구하는 경우에, 또는 복잡한 프롬프트와 문맥을 사용하여 \"벤치마크 품질\"의 결과가 필요한 경우에 실제로 매우 좋다고 생각했습니다.\n\n\n\n하지만 사용 사례에 다른 요구 사항이 있는 경우는 어떨까요? 속도가 필요한 경우는 어떨까요?\n\n# Groq와 Fireworks를 이용해 시동 걸기\n\nOpenAI의 처리량이 떨어져 사용자 경험을 나빠지게 만들 수 있는 문제 중 하나는, 최종적으로 콘텐츠가 가치를 추가한다 해도 주관적으로 사용자 경험을 나빠지게 할 수 있다는 것입니다.\n\nOpenAI의 ChatGPT를 사용할 때, 채팅 응답에 몇 초가 걸릴 수도 있다는 사실을 SSE가 가려버리기 때문에 명확하게 드러나지 않을 수 있습니다. GPT-4의 처리량이 낮다는 것은 다른 대안을 시도해보기 전까지는 쉽게 알아챌 수 없습니다.\n\n\n\n# Groq.com\n\nGroq는 LLM에 특별히 설계된 사용자 정의 하드웨어로 알려진 \"LPU\" 또는 \"언어 처리 유닛\"을 갖춘 흥미로운 플랫폼입니다:\n\n적어도 문서로 보면, 이것은 마케팅 허세 이상으로 보이며 플랫폼은 객관적으로 고 처리량을 자랑합니다.\n\n하지만 주요 문제는 현재의 SaaS 제공으로 이어집니다:\n\n\n\n![이미지](/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_2.png)\n\n무료 티어는 실험 용도로만 사용 가능하며, 그것도 겨우 가능할 뿐입니다.\n\n![이미지](/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_3.png)\n\n그래서 Groq은 꽤 빠르지만, 샌드박싱 용도 외에는 사용할 수 없으며, 가능하다면 엔터프라이즈 과금을 통해 사용할 수 있습니다.\n\n\n\n# Fireworks.ai\n\n현재 시점에서 Fireworks의 Llama-3 70B는 전체적으로 9위에 랭크되어 있으며 두 번째로 빠른 Llama-3 70B입니다:\n\n![이미지](/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_4.png)\n\n마지막 토큰까지 260ms가 소요되며, 여전히 매우 빠르며 GPT-3.5와 GPT-4 사이의 성능을 제공하여 내 사용 사례에 대한 LLM 성능이 매우 좋습니다.\n\n\n\nFireworks.ai에는 중간 유료 티어가 없지만, 600 RPM은 작은 앱에 사용하기 적합하며 하드 토큰 제한이 없습니다.\n\n![이미지](/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_5.png)\n\n오늘 빠르게 무언가를 구축하려는 팀들에게는 Fireworks.ai가 아마도 최선의 선택일 것입니다. (아니, 나는 그들로부터 돈을 받고 있지 않아요)\n\n# .NET 8, System.Threading.Channels 및 Server Sent Events (SSE)와 함께 실용적인 예제\n\n\n\n이 놀라운 처리량을 활용하기 위해서는 한 번에 여러 개의 스트림을 통해 생성한 다음 하나의 최종 출력 스트림으로 병합하는 동시 처리 전략이 필요합니다.\n\n이는 .NET의 System.Threading.Channels를 Server Sent Events (SSE)와 결합하여 이 처리량을 완전히 활용하고 높은 반응성을 갖는 생성 AI 경험을 구축하는 완벽한 사용 사례입니다.\n\n이전에 이 두 주제에 대해 별도로 다뤘었습니다:\n\n- .NET Task Parallel Library vs System.Threading.Channels\n- .NET 6의 System.Threading.Channels를 이용한 동시 처리 (보너스: 간격 트리)\n- .NET 7과 함께하는 Server Sent Events\n\n\n\n오늘은 .NET 8 채널, Semantic Kernel 및 gen AI와 함께 어떤 대화형 경험을 만들 수 있는지 함께 살펴보겠습니다!\n\n![image](/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_6.png)\n\n저희 샘플 응용 프로그램은 준비된 재료 목록과 목표 조리 시간을 받아들여서 다음을 할 것입니다:\n\n- 해당 재료로 만들 수 있는 레시피 목록 생성\n- 레시피 중 하나를 무작위로 선택\n- 레시피를 위해 필요한 모든 재료 목록 생성\n- 레시피를 위한 소개 단락 생성\n- 준비된 각 재료에 대한 영양 정보에 대한 간략한 설명 생성\n- 제안된 사이드 디시 목록 생성\n- 순서 목록 생성\n\n\n\n단계 3~6은 병렬로 실행될 수 있지만, 레시피를 먼저 선택해야 하기 때문에 단계 1~2가 먼저 실행됩니다. 그리고 단계를 생성하기 전에 재료 전체 목록을 기다려야 합니다.\n\n# .NET 채널을 이용한 병행 실행\n\nAPI 호출의 진입점은 요청을 받을 단일 POST 엔드포인트입니다:\n\n```js\n// 👇 메인 진입점.\napp.MapPost(\"/generate\", async (\n  HttpContext context,          // 의존성 주입에서 가져옴\n  RecipeGenerator generator,    // 의존성 주입에서 가져옴\n  RecipeRequest request,        // 바디에서 가져옴\n  CancellationToken cancellation = default\n) =>\n{\n  context.Response.Headers.ContentType = \"text/event-stream\";\n\n  await generator.GenerateAsync(\n    request,\n    // 각 단편에 대한 스트리밍 응답을 작성하는 핸들러\n    async (Fragment f) => {\n      await context.Response.WriteAsync(\n        $\"data: {f.Part}|{f.Content}{Environment.NewLine}{Environment.NewLine}\",\n        cancellation\n      );\n      await context.Response.Body.FlushAsync(cancellation);\n    }\n  );\n});\n```\n\n\n\nRecipeGenerator.GenerateAsync 메서드에는 메인 플로우가 포함되어 있어요:\n\n```js\n/// <summary>\n/// 주요 시작점\n/// </summary>\npublic async Task GenerateAsync(\n  RecipeRequest request,\n  Func<Fragment, Task> handler, // 👈 이것은 HTTP 응답 스트림에 연결된 후크에요\n  CancellationToken cancellation = default\n) {\n\n  var (ingredientsOnHand, prepTime) = request;\n\n  // 👇 (1) 3개의 레시피 목록을 생성하고 무작위로 하나를 선택\n  var recipes = await GenerateRecipesAsync(ingredientsOnHand, prepTime, cancellation);\n\n  Console.WriteLine($\"생성된 레시피 수: {recipes.Length}.\");\n\n  var recipe = recipes[Random.Shared.Next(0, 2)];\n\n  // 👇 (2) 모든 레시피를 보유하여 HTML 문자열로 집계\n  var alternates = recipes\n    .Where(r => r.Name != recipe.Name)\n    .Aggregate(new StringBuilder(), (html, r) => {\n      html.Append($\"<li><b>{r.Name}</b> &nbsp;\");\n      html.Append($\"<i>{r.Intro}</i></li>\");\n\n      return html;\n    }).ToString();\n\n  // 👇 (3) 읽기 채널의 리더 측에 대한 반복 작업입니다; 먼저 시작해야 해요\n  var fragmentHandler = async () => {\n    while (await _channel.Reader.WaitToReadAsync()) {\n      if (_channel.Reader.TryRead(out var fragment)) {\n        await handler(fragment);\n      }\n    }\n  };\n\n  var completion = fragmentHandler();\n\n  // 👇 (4) 이제 세대 프롬프트를 동시에 실행해요\n  Task.WaitAll([\n    handler(new (\"alt\", alternates)),\n    GenerateIngredientsAsync(recipe, ingredientsOnHand, request.PrepTime, cancellation),\n    GenerateIntroAsync(recipe, cancellation),\n    GenerateIngredientIntroAsync(ingredientsOnHand, cancellation),\n    GenerateSidesAsync(recipe, cancellation)\n  ]);\n\n  // 👇 (5) 그리고 모든 작업이 완료될 때까지 기다려요.\n  _channel.Writer.Complete();\n\n  await completion;\n}\n```\n\n여기서 Task.WaitAll의 중요한 차이점은 JavaScript의 Promise.all과 개념적으로 비슷하지만, .NET에서는 멀티 스레드인 .NET 런타임 때문에 동시성과 병렬로 실행될 수 있어요. 이 경우 스레드 풀 스케줄러가 각 작업이 다른 스레드에서 실행될지 여부를 결정할 거에요. 채널을 사용하면 출력을 하나의 스레드에 바인딩된 리더에 병합하여 동기화된 액세스가 필요 없어졌어요.\n\n각 세대 작업은 비슷한 패턴을 따라가요:\n\n\n\n```js\nprivate async Task GenerateIntroAsync(\n  RecipeSummary recipe,\n  CancellationToken cancellation = default\n) {\n  var prompt = \"...\";\n\n  await ExecutePromptAsync(\n    \"int\", // 👈 이것은 프론트엔드 출력 대상의 ID와 일치합니다\n    prompt,\n    new () {\n      MaxTokens = 250,\n      Temperature = 0.55,\n      TopP = 0\n    },\n    cancellation: cancellation\n  );\n}\n```\n\n그리고 프롬프트를 실행하는 메서드:\n\n```js\n/// <summary>\n/// 프롬프트를 실행하고 결과를 채널에 작성합니다.\n/// </summary>\nprivate async Task ExecutePromptAsync(\n  string part,\n  string prompt,\n  OpenAIPromptExecutionSettings settings,\n  Action<string>? resultHandler = null,\n  string? modelOverride = null,\n  CancellationToken cancellation = default\n) {\n  // 👇 대화를 초기화합니다\n  var chat = _kernel.GetRequiredService<IChatCompletionService>(\n    modelOverride ?? \"70b\" // 명시된 오버라이드가 없으면 70b를 사용합니다.\n  );\n\n  var history = new ChatHistory();\n  var buffer = new StringBuilder();\n\n  history.AddUserMessage(prompt);\n\n  // 👇 응답을 스트리밍하고 각 부분을 채널에 작성합니다\n  await foreach (var message in chat.GetStreamingChatMessageContentsAsync(\n      history, settings, _kernel, cancellation\n    )\n  ) {\n      await _channel.Writer.WriteAsync( // 👈 채널의 라이터 엔드\n        new(part, message.Content ?? \"\"),\n        cancellation\n      );\n\n      buffer.Append(message.Content); // 👈 전체 출력을 보유하는 버퍼\n  }\n\n  var output = buffer.ToString();\n\n  // 👇 호출자가 전체 결과를 원하는 경우 여기에서 사용할 수 있습니다\n  resultHandler?.Invoke(output);\n}\n```\n\n애플리케이션 실행 중 의존성 주입을 통해 커널 인스턴스가 구성됩니다:\n\n\n\n```js\r\n// Program.cs\nvar builder = WebApplication.CreateBuilder(args);\n\nvar fireworksEndpoint = new Uri(\"https://api.fireworks.ai/inference/v1/chat/completions\");\nvar groqEndpoint = new Uri(\"https://api.groq.com/openai/v1/chat/completions\");\n\nvar config = builder.Configuration\n  .GetSection(nameof(RecipesConfig))\n  .Get<RecipesConfig>();\n\n// Semantic Kernel을 설정하여 필요한만큼의 LLM을 등록합니다.\nvar kernelBuilder = Kernel.CreateBuilder();\nvar kernel = kernelBuilder\n  .AddOpenAIChatCompletion(\n    modelId: \"accounts/fireworks/models/llama-v3-70b-instruct\",\n    apiKey: config!.FireworksKey,\n    endpoint: fireworksEndpoint,\n    serviceId: \"70b\" // 👈 더 나은 결과를 위해 기본적으로 이 serviceId를 사용합니다\n  )\n  .AddOpenAIChatCompletion(\n    modelId: \"accounts/fireworks/models/llama-v3-8b-instruct\",\n    apiKey: config!.FireworksKey,\n    endpoint: fireworksEndpoint,\n    serviceId: \"8b\" // 👈 더 빠른 속도가 필요한 경우 이 serviceId를 사용합니다\n  )\n  .AddOpenAIChatCompletion(\n    modelId: \"llama3-8b-8192\",\n    apiKey: config!.GroqKey,\n    endpoint: groqEndpoint,\n    serviceId: \"groq-8b\" // 👈 최대 처리량을 위해 이 serviceId를 사용합니다\n  )\n  // 다른 LLM을 여기에 등록합니다.\n  .Build();\n\nbuilder.Services\n  .Configure<RecipesConfig>(\n    builder.Configuration.GetSection(nameof(RecipesConfig))\n  )\n  .AddCors()\n  .AddSingleton(kernel)  // 👈 설정된 kernel을 싱글톤으로 추가합니다\n  .AddScoped<RecipeGenerator>();\r\n```\n\nSemantic Kernel을 통해 여러 LLM 엔드포인트를 구성할 수 있습니다. 이를 사용하여 작은 빠른 LLM이 프로세스를 가속화할 수 있는 플로 구현을 단순화할 수 있습니다.\n\n# SSE를 활용한 동시 스트림\n\n컨텐츠가 생성되면 백엔드는 즉시 프론트엔드로 스트리밍하여 매우 반응이 뛰어난 사용자 경험을 제공합니다. 이 과정은 동시에(그리고 스레드 풀 스케줄러에 따라 확장하여 병렬로) 발생하며, 채널에 수집되어 클라이언트에서 소비될 응답 스트림으로 작성됩니다.\n\n\n\n이 흐름을 시각화하기 위해 아래 다이어그램을 확인해보세요:\n\n![다이어그램](/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_7.png)\n\nTask.WaitAll 코드 블록은 채널의 공유 가능하고 스레드 안전한 writer 엔드를 전달받은 상태이며, reader 엔드는 HTTP 응답 스트림과 콜백을 통해 연결됩니다.\n\n해당 콜백은 간단히 EventSource의 필요한 형식 명세에 따라 Fragment를 서식화합니다.\n\n\n\n이 경우:\n\n```js\ndata: ing|tomatoes\n\ndata: ing|basil\n\ndata: ste|3. Chop the\n```\n\n프론트엔드는 이러한 메시지 스트림을 받아 UI의 서로 다른 섹션에 누적합니다.\n\n- 첫 번째 부분인 ing은 이 내용이 속하는 프론트엔드 부분을 식별합니다 (이 경우에는 \"재료\")\n- | 이후의 텍스트는 LLM에 의해 작성된 출력 토큰 세트를 의미합니다.\n\n\n\n프론트엔드에서 @microsoft/fetch-event-source는 기본 EventSource를 대체하여 POST 사용을 가능하게 하는 폴리필(polyfill)로 사용됩니다.\n\n수신자는 각 메시지를 가져와 디코드합니다:\n\n```js\nonmessage: (msg) => {\n  var payload = msg.data\n\n  var [part, content] = payload.split('|')\n\n  if (!part || !$el(`#${part}`)) {\n    return // 이 메시지는 버립니다\n  }\n\n  // 👇 이 부분은 새 줄을 인코딩하고 여기서 대체하는 해킹입니다.\n  content = content.replace(/⮑/gi, \"\\n\")\n\n  $el(`#${part}`).innerHTML += content\n},\n```\n\ntext/event-stream의 특이점은 이중 줄바꿈이 메시지 블록의 끝을 나타낸다는 것입니다. 그래서 줄바꿈은 어떤 방식으로든 인코딩되어야 합니다 (다양한 방법이 있습니다). 이 경우, 단일 문자 ⮑을 사용하여 해당 문자를 찾아 \\n으로 대체하는 것이 간답습니다.\n\n\n\nCSS는 그냥 이 부분을 고려하면 됩니다:\n\n```js\n#add, #ing, #ste {\n  white-space: pre-line;\n}\n```\n\nHTML 자체는 간단합니다:\n\n```js\n<!-- 이 블록은 추가 재료를 보관합니다 -->\n<div class=\"additional\">\n  <h2>필요한 재료</h2>\n  <!-- 👇 이 ID는 Fragment.Part와 일치합니다 -->\n  <div id=\"add\"></div>\n</div>\n\n<!-- 이 블록은 단계를 보관합니다 -->\n<div class=\"recipe\">\n  <h2>조리 단계</h2>\n  <!-- 👇 이 ID는 Fragment.Part와 일치합니다 -->\n  <div id=\"ste\"></div>\n</div>\n```\n\n\n\n# 모두가 준비되었으니 이제 앱을 실행하면 다음과 같은 경험을 할 수 있습니다:\n\n![recipe app](https://miro.medium.com/v2/resize:fit:1400/0*uCMJGy8UoyaC4rFX.gif)\n\n레시피 목록을 생성하는 호출이 차단되므로 약간의 초기 지연이 있습니다.\n\n\n\n그러나 한 번 목록이 생성되고 무작위로 선택된 후, 추가적인 생성은 전체 재료 목록에 의해 차단되는 단계만 동시에 발생합니다. (전체 재료 목록을 사용하여 정확한 단계를 생성해야 하기 때문입니다).\n\n# 결론\n\n사용자 경험(UX)이 높은 처리량을 필요로 하며 작은 컨텍스트 창을 통해 작동할 수 있는 애플리케이션의 경우, Fireworks.ai와 Llama-3 8B/70B는 절대적으로 게임 체인저입니다. 그것은 팀이 OpenAI의 GPT 모델의 높은 지연 때문에 전반적인 UX를 희생시키지 않고 사용 사례에 대해 빌드할 수 있도록 해줍니다.\n\nSystem.Threading.Channels를 사용한 .NET 8 웹 API에 그것을 플러그인하고 SSE와 결합하면, 여러 콘텐츠 청크를 동시에 생성하고, 상호작용적인 생성 AI 경험을 더 많이 구축하거나 생성적인 워크플로우를 간단히 가속화하는 새로운 가능성을 열 수 있습니다.\n\n\n\n동일한 기술을 사용하면 (SSE를 제외하고) 낮은 지연 시간 + 높은 처리량 모델 및 플랫폼을 사용하여 여러 프롬프트를 병렬로 처리하여 서버 생성 워크로드의 처리량을 늘릴 수 있습니다.\n\n전체 repository:","ogImage":{"url":"/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_0.png"},"coverImage":"/assets/img/2024-05-13-NeedforSpeedLLMsBeyondOpenAIwithCNET8SSEChannelsLlama3andFireworksai_0.png","tag":["Tech"],"readingTime":12},{"title":"프론트엔드 성능에 대해 이야기할 때, 우리는 무엇을 얘기하고 있는 걸까요","description":"","date":"2024-05-12 23:59","slug":"2024-05-12-WhenWeTalkaboutFront-endPerformanceWhatAreWeTalkingAbout","content":"\n\n<img src=\"/assets/img/2024-05-12-WhenWeTalkaboutFront-endPerformanceWhatAreWeTalkingAbout_0.png\" />\n\n이 기사에서는 Google의 공식 도구 라이트하우스를 활용하여 최신 프런트엔드 페이지 성능 평가 표준을 분석하여 다양한 성능 지표를 이해하고 관련 프런트엔드 프로젝트를 개선하고 최적화하는 데 도움을 줍니다.\n\n프런트엔드 페이지 성능은 사용자 유지율이 페이지 로드 성능과 밀접한 연관이 있기 때문에 모두에게 항상 연속적인 관심사였습니다. 구글의 데이터 통계에 따르면, 페이지 방문 시간이 1초에서 3초로 증가할 때 사용자의 이탈률이 32% 증가합니다.\n\n프런트엔드 페이지 성능을 평가하는 두 가지 방법이 일반적으로 있습니다: 하나는 성능 분석 도구를 사용하여 온라인에서 다양한 지표를 점수화하고 평가하는 것이며, 다른 하나는 성능 모니터링을 사용하여 Performance API나 사용자의 실제 네트워크 액세스 상황을 보고한 후 통계 분석을 수행하는 것입니다.\n\n\n\n사용자 데이터를 통계적으로 수집하는 것이 더 현실적이지만 페이지 성능 평가에 대한 통일된 양적 기준을 갖기 위해 종종 페이지 성능을 평가하는 데 표준 평가 도구를 사용하기로 선택합니다.\n\n성능 분석 초기 단계에서는 Chrome 개발자 도구를 사용하여 웹 페이지를 분석하며, 로드 및 DOMContentLoaded와 같은 이벤트가 발생하는 시간을 확인합니다. 나중에 Webpage Analyzer, WebPageTest, YSlow 등과 같은 일련의 성능 분석 도구가 등장했습니다.\n\n이제 Google은 자체 개발한 Lighthouse를 공식적으로 개발자 도구 탭에 내장시켰으므로, Lighthouse를 표준 평가 도구로 고려합니다.\n\nLighthouse는 페이지의 최상의 사례에 관한 관련 권고 사항을 제공하는 오픈 소스 웹 페이지 성능 분석 도구입니다. Chrome DevTools에서 직접 사용할 수도 있을 뿐만 아니라 브라우저 확장 프로그램(Chrome 및 Firefox)이나 npm 패키지(Node API 또는 CLI)도 지원합니다.\n\n\n\nGoogle의 Web Measure 및 PageSpeed Insight와 같은 도구는 페이지를 분석하는 라이트하우스를 사용합니다.\n\n## 1. 라이트하우스의 반복 및 성능 지표 변경\n\n라이트하우스의 최초 오픈 소스 버전은 2016년으로 거슬러 올라가며, 2020년 10월 기준 최신 버전은 6.4.1이며, 총 89번의 반복을 거쳤습니다. 이들 몇 년 사이에, 라이트하우스는 성능 메트릭스(지표)를 업데이트해 왔습니다.\n\n최신 버전 6.X에서 Google은 5.X 버전과 비교해 세 가지 새로운 성능 메트릭스를 소개했습니다: FMP(첫 의미 있는 그림 렌더링), FCI(첫 CPU 비활성 및 mpFID(최대 잠재 첫 입력 지연)가 제거되었습니다.\n\n\n\nTBT (Total Blocking Time), LCP (Largest Contentful Paint), and CLS (Cumulative Layout Shift)가 추가되었습니다. 다음 섹션에서는 이러한 지표들에 대한 자세한 설명을 제공할 것입니다.\n\n![image](/assets/img/2024-05-12-WhenWeTalkaboutFront-endPerformanceWhatAreWeTalkingAbout_1.png)\n\n## 2. 페이지 성능 점수 계산 방법\n\n아래 그림에서 보듯이, 페이지 성능 섹션에서 Lighthouse는 6가지 주요 지표의 성능을 평가하고 페이지의 성능 점수를 계산할 것입니다.\n\n\n\n![표](/assets/img/2024-05-12-WhenWeTalkaboutFront-endPerformanceWhatAreWeTalkingAbout_2.png)\n\n최신 6.X 계산 방법에 따르면 각 성능 메트릭은 점수에 대응됩니다. 예를 들어, 위 그림에서 FCP, SI, LCP, TTI, TBT 및 CLS의 값은 각각 78, 62, 37, 5, 99, 92에 해당하는 개별 점수입니다. 일반적으로 메트릭 값이 작을수록 해당하는 점수가 높습니다.\n\n이 여섯 메트릭에 할당된 가중치는 각각 15%, 15%, 25%, 15%, 25%, 5%입니다. 전체 성능 점수는 가중 평균을 통해 60점으로 계산됩니다.\n\n각 메트릭 값이 해당하는 점수 계산 방법은 이 기사 끝에 있는 참고 자료 번호 다섯와 여섯에서 자세히 확인할 수 있습니다.\n\n\n\n라이트하우스 v6.0.에서는 FMP (First Meaningful Paint), FCI (First CPU Idle) 및 mpFID (Maximum Potential First Input Delay)와 같은 세 가지 핵심 성능 지표가 제거되었습니다.\n\n현재 버전이 그들의 메트릭을 선택하는 방식을 더 잘 이해하기 위해 이 세 가지 폐기된 지표의 정의를 살펴보겠습니다.\n\n## 1. FMP란 무엇이며 FCP와 어떤 차이가 있는가?\n\nFMP에 대해 이야기할 때에는 먼저 First Contentful Paint (FCP)를 소개해야 합니다: 첫 번째 콘텐츠 렌더링 시간입니다.\n\n\n\n위에서 언급한 대로, 브라우저가 처음으로 'First Page Paint' 이벤트를 트리거하면, 이 순간이 FCP가 됩니다. 하지만, 이때 렌더링되는 내용이 반드시 중요한 페이지 정보일 필요는 없습니다. 예를 들어, 헤더 액션바를 그리거나 심지어 가시적인 요소만 렌더링되는 경우도 있을 수 있습니다. Lighthouse 6.0에는 여전히 포함되어 있지만, 성능 점수에서의 비중은 23%에서 15%로 감소했습니다.\n\n그러므로, FCP는 사용자 관점에서 페이지 성능을 정확히 판단할 수 있는 지표로 사용할 수 없습니다.\n\n이 맥락에서 'FMP (First Meaningful Paint)'이 등장했습니다. 공식적인 정의에 따르면, FMP는 페이지 로딩이 시작된 후 초기 화면에 가장 많거나 주요 콘텐츠가 렌더링된 시점을 말합니다.\n\n그렇다면, FMP 타이밍은 어떻게 확인할까요? 먼저 가장 기본적인 계산 방법을 살펴보겠습니다:\n\n\n\n먼저 레이아웃 오브젝트의 수를 계산합니다 (테스트 계산을 위해 LayoutAnalyzer를 사용하십시오; 참조 17번을 참조하십시오).\n\n아래 그림에서 볼 수 있듯이 페이지 로딩 프로세스는 레이아웃 오브젝트가 레이아웃 트리로 점진적으로 들어가고 렌더링되는 과정입니다.\n\n![이미지](/assets/img/2024-05-12-WhenWeTalkaboutFront-endPerformanceWhatAreWeTalkingAbout_3.png)\n\nlayoutAnalyzer는 레이아웃 오브젝트의 수를 모으고, LayoutObjectsThatHadNeverHadLayout라는 카운터로 새로 추가된 레이아웃 오브젝트의 수를 나타냅니다.\n\n\n\n테스트를 통해 다른 카운터와 비교했을 때, 가장 변화가 많이 일어나는 순간은 종종 페이지에서 가장 중요한 요소들이 렌더링될 때입니다.\n\n따라서 FMP 지표의 계산 방법은 LayoutObjectsThatHadNeverHadLayout(새롭게 추가된 레이아웃 오브젝트)가 가장 큰 변화를 경험한 다음 순간입니다(가장 큰 레이아웃 변경을 따라오는 페인트).\n\n물론, 위의 상황이 적용되지 않는 몇 가지 시나리오도 있습니다:\n\na) 페이지가 긴 경우, 첫 화면 내에는 가시적인 레이아웃 오브젝트보다 보이지 않는 레이아웃 오브젝트가 더 많이 추가될 수 있습니다. 이 경우에는 FMP가 부정확해집니다.\n\n\n\nb) 웹 폰트를 로드하고 텍스트가 레이아웃을 위해 대체 글꼴을 사용하지만 로드 시작으로부터 3초 내에 그려지지 않는 경우; 이는 또한 FMP 계산에 영향을 줄 수 있습니다.\n\n시나리오 1의 경우, FMP는 이 문제를 해결하기 위해 \"레이아웃 중요성\" 개념을 도입했습니다; 시나리오 2의 경우, FMP는 통계를 지연시켜 지표가 페이지 상태를 더 정확하게 반영하도록 합니다. 자세한 해결책은 참조문헌 18을 참조해 주세요.\n\n그러나 FMP는 주요하게 다음 두 가지 이유로 버전 6.0에서 폐기되었습니다.\n\n- 실제 환경에서 FMP는 페이지의 작은 변경에 너무 민감하여 일관되지 않은 결과로 쉽게 이어질 수 있습니다.\n- 이 지표의 정의는 브라우저의 구체적인 구현 세부 사항에 심하게 의존하며 참조를 위한 표준화가 부족합니다.\n\n\n\n# 2. LCP가 FMP를 대체하고 나타났어요\n\n이전 섹션에서 FCP와 FMP의 단점을 언급했었는데요, 그래서 W3C의 성능 그룹은 페이지의 주요 콘텐츠를 사용자가 볼 수 있는 시간을 더 정확하게 반영하는 적절한 지표를 찾고 있었어요.\n\n가끔은 더 간단할수록 더 좋아요. 다양한 소스에서의 토론을 토대로 페이지 성능에 관한 보다 정확한 측정 방법, 즉 LCP (가장 큰 콘텐츠 렌더링)가 마침내 찾아졌어요.\n\nLCP는 뷰포트 내에서 가장 큰 콘텐츠 요소가 렌더링되는 시간을 의미해요. 이 지표는 Lighthouse 6.0에서 공식적으로 소개되었으며 최종 성능 점수에서 25%의 가중치를 갖고 있어요.\n\n\n\nLCP는 FCP와 함께 정의하기 가장 쉬운 메트릭 중 하나여야 합니다. 그 정의에는 비교할 요소 선택과 그 크기를 결정하는 두 가지 중요한 요소가 있습니다.\n\n공식 문서에 따르면, 다음 요소들이 가장 큰 콘텐츠 요소(Largest Contentful Element)의 일부로 고려될 것입니다:\n\n- `img`\n- `svg` 내부의 `image`\n- `video`\n- url() 함수를 통해 배경 이미지를 로드하는 요소\n- 텍스트 노드를 포함하거나 인라인 텍스트 자식 요소를 포함하는 블록 수준의 요소들\n\n요소의 크기를 어떻게 결정할까요? 주로 다음 네 가지 규칙에 기반하여 결정됩니다:\n\n\n\n- 화면 뷰포트 내에서 보이는 요소의 크기; 뷰포트를 벗어나거나 가려지거나 가려지거나 감춰진 경우 크기로 계산되지 않습니다.\n- 이미지 요소의 경우 크기는 실제 크기와 원래 크기 중 작은 것을 취함으로 결정됩니다.\n- 텍스트 요소의 경우 모든 텍스트를 덮는 최소 직사각형 영역만을 고려합니다.\n- 모든 요소의 경우 여백, 안쪽 여백, 테두리 등은 계산에 포함되지 않습니다.\n\n구글은 이 메트릭을 다음과 같이 평가합니다: LCP는 매우 중요한 사용자 중심 지표이며 사용자 수준에서 지각된 로딩 속도를 반영합니다. 주요 콘텐츠에서 가장 큰 콘텐츠 요소의 로딩이 완료된 것을 나타내며, 더 짧은 LCP 시간으로 사용자는 페이지를 더 빠르게 사용 가능하다고 인식하게 됩니다.\n\n# 3. 버려진 FCI와 TTI와 왜 밀접한 관련이 있는가?\n\nFCI(First CPU Idle: 첫 번째 CPU 대기)는 페이지가 최소 상호 작용 표준에 도달하는 데 얼마나 오래 걸리는지를 측정하는 메트릭입니다.\n\n\n\n최소 상호 작용성의 확인을 위해서는 다음 두 가지 조건을 동시에 충족해야 합니다:\n\na) 화면에 있는 대부분의 UI 요소가 상호 작용 가능해야 합니다\n\nb) 페이지가 일반적으로 합리적인 범위 내에서 사용자 입력에 응답해야 합니다\n\nTTI (Time To Interactive: 페이지 상호 작용까지의 시간)는 페이지가 완전히 상호 작용 가능한 상태에 도달하는 데 필요한 시간을 의미합니다.\n\n\n\n\"완전 대화형\"이란 다음 세 가지 조건을 모두 충족하는 것을 의미합니다:\n\na) FCP 이후 페이지에 유용한 콘텐츠가 렌더링되었습니다\n\nb) 가장 눈에 띄는 페이지 요소에 이벤트 콜백이 등록되었습니다\n\nc) 사용자 상호작용에 대한 페이지 응답 시간이 50ms 이내입니다\n\n\n\n2017년에 첫 번째 상호 작용 메트릭이 두 가지 메트릭, 즉 첫 상호 작용 및 일관적 상호 작용으로 나뉘었으며, 이어지는 해의 7월에 첫 상호 작용은 FCI로 변경되었고, 일관적 상호 작용은 TTI로 변경되었습니다. FCI와 TTI는 사용자 상호 작용 응답을 반영하는 두 가지 메트릭임을 볼 수 있습니다.\n\n그렇다면 최소 상호 작용 및 전체 상호 작용은 어떻게 계산되는 걸까요? 구체적인 계산 방법을 소개하기 전에 이 두 가지 메트릭이 모호하며 서로 다른 상황에서 계속 최적화되고 개선될 수 있다는 것을 알아야 합니다.\n\n- FCI의 최소 상호 작용 시간\n\n주 스레드의 타임라인에서 FMP부터 특정 작업이 끝난 후까지 길이가 f(t)인 시간 창 W를 찾습니다. W가 해당 기간 동안 어떤 지점에서도 250ms 이상의 연속적인 작업 집합이 없고, 그 끝과 직전 1초 내에 JS 실행 시간이 50ms를 초과하는 긴 작업이 없으면 해당 작업이 끝난 시점이 우리가 정의하는 FCI입니다. 여기서 f(t)=4e^(-0.045t)+1.\n\n\n\n아래 그림에서 빨간 상자로 표시된 지점이 FCI를 나타냅니다.\n\n![FCI](/assets/img/2024-05-12-WhenWeTalkaboutFront-endPerformanceWhatAreWeTalkingAbout_4.png)\n\n- TTI: 완전 상호 작용 시간\n\n네트워크 및 주 스레드의 타임라인에서 처음 5초 창기간 W을 찾으세요. W 기간 내에서 다음 조건을 충족해야 합니다: 어떤 순간에도 동시 네트워크 요청이 최대 두 개이고 50ms를 초과하는 긴 작업이 없습니다. W 이전의 마지막 긴 작업의 종료 시간을 TTI로 지칭합니다.\n\n\n\n아래 그림에서 빨간 상자로 표시된 시점은 TTI입니다:\n\n![Figure](/assets/img/2024-05-12-WhenWeTalkaboutFront-endPerformanceWhatAreWeTalkingAbout_5.png)\n\n일부 사람들은 FCI가 특정 시기에 TTI보다 의미가 더 있다고 지적했지만, 이들 사이의 차이는 여전히 라이트하우스가 두 가지 유사한 메트릭을 유지하는 것을 정당화하는데 충분하지 않습니다.\n\n그래서 라이트하우스 버전 6.0에서 최종 결정이 내려져 FCI 대신 TTI를 사용하기로 결정되었습니다.\n\n\n\n# 4. mpFID 및 새로 추가된 TBT 지표\n\nmpFID (최대 잠재적 첫 입력 지연)은 사용자 입력부터 페이지에서 이벤트 콜백을 처리하기 시작하는 실제 시간까지의 잠재적 최대 지연 시간을 나타냅니다.\n\nmpFID의 구체적인 계산 방법은 FCP부터 TTI까지의 JavaScript 실행 시간을 기준으로 가장 긴 작업을 선택한 다음 해당 작업이 소비한 시간에서 50ms를 뺀 것입니다.\n\n그러나 mpFID는 최대 지연 시간만을 나타내며, 사용자가 경험하는 실제 지연 시간과 다를 수 있습니다. 사용자가 다른 시간에 얻는 FID도 다를 수 있습니다. 따라서 mpFID는 페이지의 응답 시간을 사용자 입력에 대한 실제 반응 시간을 정확하게 반영하지 않습니다.\n\n\n\n5. X 버전에서 성능 점수를 계산할 때 mpFID는 가중치가 0으로 설정되어 점수에 기여하지 않습니다. 이 메트릭은 이제 더 이상 보고서에 나타나지 않지만, JSON 데이터에는 유지되며 공식적으로 인정받는 핵심 사용자 경험 지표로 남아 있습니다.\n\n그렇다면 TBT (Total Blocking Time)은 정확히 무엇이며 왜 성능 보고서에서 FID 대신 선택해야 하는 것인가요?\n\n먼저 정의를 살펴보겠습니다: TBT는 페이지에서 사용자 입력에 응답할 때 차단된 총 누적 시간을 의미합니다.\n\n구체적인 계산 방법은 매우 명확합니다 — FCP와 TTI 사이의 모든 긴 작업을 합산하고 그 차단 부분의 시간을 추가하여 TBT를 얻습니다. 차단 부분의 시간이란 긴 작업 실행 시간이 50ms를 초과하는 부분을 말합니다; 예를 들어, 긴 작업이 전체 70ms 걸리면 차단된 시간은 20ms가 됩니다.\n\n\n\nmpFID과 비교해 볼 때 TBT는 사용자 입력에 대한 페이지의 평균 지연 응답을 더 정확하게 반영할 수 있는 더 안정적인 지표입니다.\n\n## 5. 최근 추가된 CLS\n\nCLS (Cumulative Layout Shift)는 시각적 인터페이스의 안정성을 측정하는 지표입니다.\n\n데이터는 레이아웃 불안정성 API(참조 14 참조)에서 얻으며, 계산 방법은 다음과 같습니다:\n\n\n\n\n레이아웃 이동 점수 = 영향 분수 * 거리 분수\n\n영향 분수는 전체 뷰포트에 미치는 영향 정도를 나타냅니다. 예를 들어 아래 이미지에서 텍스트가 전체 뷰포트의 50%를 차지하고 다음 프레임에서 이전 프레임 대비 25% 아래로 이동한다면 전체 페이지의 75%에 영향을 줍니다. 따라서 영향 분수는 0.75입니다.\n\n![이미지](/assets/img/2024-05-12-WhenWeTalkaboutFront-endPerformanceWhatAreWeTalkingAbout_6.png)\n\n거리 분수는 비교적 이해하기 쉽습니다. 전체 뷰포트의 변경된 거리 비율을 의미합니다. 예를 들어 위 경우에서 25% 이동은 거리 분수가 0.25를 의미합니다.\n\n\n\n그래서, 그림으로 설명된 데모의 CLS 값은 0.75 * 0.25 = 0.1875로 계산됩니다. 더 자세한 계산 방법은 참고문헌 13과 14에서 확인할 수 있습니다.\n\nCLS가 사용자 경험에 미치는 영향을 설명하는 예시: 아래 다이어그램과 같이 사용자가 취소 버튼을 클릭하려고 할 때, 갑자기 페이지에서 레이아웃이 변경되어 취소 버튼이 있던 자리에 확인 버튼이 나타납니다...\n\n![다이어그램 이미지](/assets/img/2024-05-12-WhenWeTalkaboutFront-endPerformanceWhatAreWeTalkingAbout_7.png)\n\nCLS는 사용자 중심의 새로운 성능 평가 지표임을 알 수 있습니다.\n\n\n\n현재 CLS는 새로 추가된 지표로, 가중치가 5%뿐입니다. 하지만 Lighthouse는 다음 주요 버전에서 해당 가중치를 늘릴 계획이라고 합니다.\n\n## 6. 항상 사용되던 속도 지수\n\n속도 지수(Speed Index, SI)는 페이지에서 보이는 내용이 채워지는 속도를 측정하는 데 사용됩니다. 계산 과정은 오픈 소스 도구인 Speedline(참고 문헌 16)을 사용합니다.\n\nSpeedline은 페이지의 비디오를 기록하고 첫 프레임과 마지막 프레임 사이의 시간 차이를 측정하여 속도 지수의 값을 계산합니다.\n\n\n\nSI의 최종 점수는 데이터베이스에 있는 실제 웹 사이트의 SI 값과 비교하여 계산됩니다. 현재 SI 점수와 평가 기준은 아래 표에 표시되어 있습니다:\n\n| 항목 | 점수 |\n|:--:|:--:|\n| FMP to LCP | X |\n| FCI to TTI | Y |\n| FID to TBT | Z |\n\n위 지표들의 교체 과정을 검토하면, 성능 지표의 선택은 모두 더욱 안정적인 방향으로 나아가고 있음을 알 수 있습니다: 지표의 정의가 더욱 간결하고 명확해지고, 계산 방법 또한 표준화되는 방향으로 발전하고 있습니다.\n\n하지만 우리는 여기에 완벽한 해결책이 없다는 것을 알아야 합니다; 각 지표에는 한계가 있습니다. 많은 상황에서 낮은 점수가 반드시 페이지 경험의 품질이 나쁘다는 것을 의미하지는 않습니다. 성능 점수에 기반하여 페이지를 더 과학적으로 평가하기 위해서는 이러한 지표들 뒤의 원칙을 이해해야 합니다.\n\n\n\n성능 관련 기술의 신속한 변화로 이 문서에 빠뜨린 부분이 있을 경우 언제든지 의사 소통하여 수정해 주시기 바랍니다.\n\n- 새로운 산업 기준에 맞는 모바일 페이지 속도를 찾아보세요.\n- Performance.timing API\n- Lighthouse 6.0의 새로운 기능\n- Web Vitals\n- Lighthouse 점수 산출기\n- Lighthouse 성능 점수\n- WebPageTest 데모\n- 첫 의미 있는 페인트까지의 시간\n- 첫 상호작용 및 일관된 상호작용\n- 가장 큰 콘텐츠 페인트 (LCP)\n- 첫 상호작용 및 일관된 상호작용\n- Mercado Libre가 Web Vitals (TBT/FID)을 최적화한 방법\n- 누적 레이아웃 이동 (CLS)\n- 레이아웃 불안정성\n- 속도 지수\n- 속도 라인\n- 레이아웃 분석기\n- 첫 의미 있는 페인트까지의 시간","ogImage":{"url":"/assets/img/2024-05-12-WhenWeTalkaboutFront-endPerformanceWhatAreWeTalkingAbout_0.png"},"coverImage":"/assets/img/2024-05-12-WhenWeTalkaboutFront-endPerformanceWhatAreWeTalkingAbout_0.png","tag":["Tech"],"readingTime":10},{"title":"자바스크립트 실력 업그레이드 배열 조작 기술 마스터하기","description":"","date":"2024-05-12 23:57","slug":"2024-05-12-LevelUpYourJavaScriptMasteringArrayManipulationTechniques","content":"\n\nJavaScript에서 배열은 값들의 컬렉션을 저장하고 조작할 수 있게 해주는 기본 데이터 구조입니다.\n\n배열이 유용한 이유 중 하나는 내장된 다양한 메서드를 제공하여 배열 내 요소를 쉽게 추가, 제거, 조작할 수 있다는 점입니다.\n\n![이미지](/assets/img/2024-05-12-LevelUpYourJavaScriptMasteringArrayManipulationTechniques_0.png)\n\n## Push\n\n\n\n배열에 요소를 추가해야 할 때는 push 메서드를 사용하는 것이 좋습니다. 이 메서드는 배열의 끝에 요소를 추가하며 기존 요소에 영향을 주지 않습니다. 새 배열의 총 개수를 반환합니다.\n\n```js\nconst animals = [\"dog\", \"cat\", \"chicken\", \"shark\"];\n\nconst totalCount = animals.push(\"bird\");\n\nconsole.log(totalCount) // 5\nconsole.log(animals); // [\"dog\", \"cat\", \"chicken\", \"shark\", \"bird\"]\n```\n\n## Pop\n\n배열에서 요소를 제거하는 것은 추가하는 것만큼 간단합니다. 이 작업을 수행하는 한 가지 방법은 pop 메서드를 사용하는 것입니다. pop 메서드는 배열에서 마지막 요소를 제거하고 해당 요소를 반환합니다.\n\n\n\n```js\nconst animals = [\"dog\", \"cat\", \"chicken\", \"shark\"];\n\nconst element = animals.pop();\n\nconsole.log(element); // shark\nconsole.log(animals); // [\"dog\", \"cat\", \"chicken\"]\n```\n\n## 연결하기\n\n만약 여러 값을 추가하고 싶다면 어떻게 해야 할까요? push로는 예상한 대로 작동하지 않을 것입니다. 이럴 때는 concat 메서드를 사용하여 두 개 이상의 배열을 결합할 수 있습니다.\n\n```js\nlet animals = [\"dog\", \"cat\", \"chicken\", \"shark\"];\n\nanimals.push([\"bird\", \"eagle\"]);\nconsole.log(animals); // Nope [\"dog\", \"cat\", \"chicken\", \"shark\", [\"bird\", \"eagle\"]]\n\nanimals = [\"dog\", \"cat\", \"chicken\", \"shark\"];\n\nconst extendedAnimals = animals.concat([\"bird\", \"eagle\"]);\n\nconsole.log(extendedAnimals); // [\"dog\", \"cat\", \"chicken\", \"shark\", \"bird\", \"eagle\"]\nconsole.log(animals); // [\"dog\", \"cat\", \"chicken\", \"shark\", \"bird\"]\n```\n\n\n\n## 슬라이스\n\n슬라이스 메소드는 전체 배열의 새로운 사본을 만들거나 배열의 일부를 추출하여 새 배열에 저장하는 데 사용할 수 있습니다.\n\n음수 인덱스를 사용하면 배열 끝에서 요소에 접근해야 할 때 정확한 길이를 모르더라도 편리합니다.\n\n그러나 슬라이스에 의해 생성된 사본은 얕은 복사입니다. 이는 원래 배열이 중첩된 배열이나 객체를 포함하는 경우 사본 내의 해당 중첩된 요소에 대한 수정이 원래 배열에도 반영된다는 것을 의미합니다.\n\n\n\n```js\nconst animals = [\"dog\", \"cat\", \"chicken\", \"shark\"];\n\nconst last = animals.slice(-1);\nconst lastTwo = animals.slice(-2);\nconst first = animals.slice(0, 1);\nconst catChicken = animals.slice(1, 3);\n\nconsole.log(last); // [\"shark\"]\nconsole.log(lastTwo) // [\"chicken\", \"shark\"]\nconsole.log(first); // [\"dog\"]\nconsole.log(catChicken); // [\"cat\", \"chicken\"]\n\nconst copy = animals.slice();\n\nconsole.log(copy);\n\ncopy.push(\"spider\");\n\nconsole.log(copy); // [\"dog\", \"cat\", \"chicken\", \"shark\", \"spider\"]\nconsole.log(animals); // [\"dog\", \"cat\", \"chicken\", \"shark\"]\n```\n\n## Join\n\n가끔 배열을 문자열로 변환해야 할 때가 있습니다. 배열 항목을 출력해야 할 때 유용합니다. 항목 사이에 끼워넣을 구분자를 지정해야 합니다.\n\n```js\nconst animals = [\"dog\", \"cat\", \"chicken\", \"shark\"];\nconsole.log(animals.join(\", \")); // dog, cat, chicken, shark\n```\n\n\n\n## 스플라이스\n\n특정 위치에서 배열에 요소를 추가하거나 제거해야 할 때는 splice 메소드가 유용합니다.\n\n```js\nconst animals = [\"dog\", \"cat\", \"chicken\", \"shark\"];\nconst removed = animals.splice(1, 2);\n\nconsole.log(removed); // [\"cat\", \"chicken\"]\nconsole.log(animals); // [\"dog\", \"shark\"]\n```\n\n## Shift\n\n\n\n배열에서 요소를 제거해야 할 때는 shift 메소드가 편리한 선택지입니다. 또한 제거된 요소를 반환합니다.\n\n```js\nconst animals = [\"dog\", \"cat\", \"chicken\", \"shark\"];\n\nconst removed = animals.shift();\nconsole.log(removed); // \"dog\"\nconsole.log(animals); // [\"cat\", \"chicken\", \"shark\"]\n```\n\n## Unshift\n\nunshift 메소드를 사용하면 배열의 시작 부분에 하나 이상의 요소를 추가할 수 있습니다. push와 유사합니다. 배열의 새로운 길이를 반환합니다.\n\n\n\n```js\nconst animals = [\"dog\", \"cat\", \"chicken\", \"shark\"];\n\nconst totalCount = animals.unshift(\"deer\", \"tiger\");\nconsole.log(totalCount); // 6\nconsole.log(animals); // [\"deer\", \"tiger\", \"dog\", \"cat\", \"chicken\", \"shark\"]\n```\n\n## IndexOf\n\nindexOf 메서드를 사용하여 배열에서 항목의 위치를 쉽게 찾을 수 있습니다. 이 메서드는 배열에서 지정된 요소의 첫 번째 발생을 검색하고 해당 인덱스를 반환합니다. 요소를 찾지 못하면 indexOf는 -1을 반환합니다.\n\n추가로, indexOf에 두 번째 인수를 제공하여 배열에서 검색을 시작할 인덱스를 지정할 수 있습니다. 요소의 인덱스를 알게 되면 splice와 같은 메서드를 사용하여 쉽게 해당 요소를 교체하거나 제거할 수 있습니다.\n\n\n\n```js\nconst animals = [\"dog\", \"cat\", \"chicken\", \"shark\"];\n\nlet index = animals.indexOf(\"cat\");\nconsole.log(index); // 1\n\nindex = animals.indexOf(\"cat\", 2);\nconsole.log(index); // -1\n```\n\n## 찾기\n\n특정 조건에 맞는 요소를 찾아야 하는 경우가 있었나요? `find` 메소드는 배열에서 원하는 조건에 맞는 첫 번째 요소를 찾아줍니다.\n\n```js\nconst animals = [\n    {\n        id: 1, type: \"dog\", name: \"Luna\",\n    },\n    {\n        id: 2, type: \"cat\", name: \"Smokey\",\n    },\n];\n\nconst found = animals.find(animal => animal.id === 2);\nconst notFound = animals.find(animal => animal.id === 10);\n\nconsole.log(found); // { id: 2, type: 'cat', name: 'Smokey' }\nconsole.log(notFound); // undefined\n```\n\n\n\n## 포함 여부 확인\n\n배열에서 항목의 존재 여부를 확인해야 하는 경우 includes 메서드가 유용합니다! 이 메서드는 부울 값으로 반환됩니다.\n\n```js\nconst animals = [\"dog\", \"cat\", \"chicken\", \"shark\"];\n\nconst hasChicken = animals.includes(\"chicken\");\nconst hasTiger = animals.includes(\"tiger\");\n\nconsole.log(hasChicken); // true\nconsole.log(hasTiger); // false\n```\n\n## ForEach\n\n\n\nforEach는 배열을 반복하는 동안 현재 요소와 함께 인덱스 매개변수를 제공합니다. 이는 콜백 함수를 사용하는 장점으로 전통적인 for 루프와 유사하게 작동합니다.\n\nfor 루프와는 달리 forEach에서 탈출하는 내장 메커니즘이 없습니다. 그러나 콜백 내에서 예외를 throw하거나 조건문을 사용하여 조기 종료를 달성할 수 있습니다. 이러한 경우, 다른 옵션을 찾아보는 것이 좋습니다.\n\n```js\nconst animals = [\"dog\", \"cat\", \"chicken\", \"shark\"];\n\nanimals.forEach((animal, index) => {\n    console.log(animal, index);\n});\n\n// dog 0\n// cat 1\n// chicken 2\n// shark 3\n```\n\n## Map\n\n\n\n만약 배열의 데이터를 수정하고 수정된 데이터로 새로운 배열을 만들어야 한다면, map 메서드를 사용할 수 있어요. 콜백 함수를 통해 각 요소에 대해 원하는 작업을 수행하고 수정된 값을 반환할 수 있어요.\n\n```js\nconst animals = [\"dog\", \"cat\", \"chicken\", \"salmon\"];\n\nconst indexed = animals.map((animal, index) => {\n    return `${index}.${animal}`;\n});\n\nconsole.log(indexed);\n// [\"1.dog\", \"2.cat\", \"3.chicken\", \"4.salmon\"]\n```\n\n## Filter\n\n커스텀 조건에 따라 배열에서 일부 요소를 제거하고 원하는 요소만 포함하는 새로운 배열을 얻어야 한다면, filter 메서드를 사용할 수 있어요. 이는 원본 배열을 수정하지 않고 새로운 배열을 생성한다는 점에서 map과 다릅니다.\n\n\n\n필터에 제공하는 콜백 함수는 새 배열에 포함될 요소에 대해 true를 반환하고 제외될 요소에 대해 false를 반환해야 합니다.\n\n```js\nconst animals = [\n    {\n        id: 1, type: \"dog\", name: \"Luna\", age: 1\n    },\n    {\n        id: 2, type: \"cat\", name: \"Smokey\", age: 3,\n    },\n    {\n        id: 3, type: \"dog\", name: \"Charlie\", age: 5,\n    },\n    {\n        id: 4, type: \"cat\", name: \"Boo\", age: 1,\n    },\n];\n\nconst adultAnimals = animals.filter(animal => animal.age > 1);\nconsole.log(adultAnimals);\n// [\n//     { id: 2, type: 'cat', name: 'Smokey', age: 3 },\n//     { id: 3, type: 'dog', name: 'Charlie', age: 5 }\n// ]\n```\n\n## Reduce\n\n리듀스 메서드는 맵(map)과 필터(filter)보다 직관적이지 않습니다. 이 메서드는 배열 내 각 요소에서 작동하는 콜백 함수와 누적값(accumulated value)을 고려합니다. 누적값은 이전 반복에서 콜백 함수의 결과이며 현재 반복에서 콜백 함수에 첫 번째 인수로 전달됩니다.\n\n\n\nreduce는 다양한 작업에 사용할 수 있는 다재다능한 함수입니다. 배열의 합을 계산하거나, 다차원 배열을 평평하게 만들거나, 조건에 따라 배열을 변형하는 등의 작업에 사용할 수 있습니다.\n\n```js\nconst ages = [10, 45, 45, 8, 6, 44, 43];\nconst totalCount = ages.reduce((이전값, 현재값) => {\n    return 이전값 + 현재값;\n}, 0);\n\nconsole.log(totalCount); // 201\nconsole.log(Math.round(totalCount / ages.length)); // 29\n```\n\n## ReduceRight\n\n이 함수는 reduce와 거의 비슷하지만, 오른쪽에서 왼쪽으로 요소를 읽어옵니다. 순서가 중요할 때 유용하게 활용할 수 있습니다.\n\n\n\n```js\nconst ages = [10, 45, 45, 8, 6, 44, 43];\nconst totalCount = ages.reduceRight((previous, current) => {\n    console.log(current); // 43, 44, 6 ...\n    return previous + current;\n}, 0);\n\nconsole.log(totalCount); // 201\nconsole.log(Math.round(totalCount / ages.length)); // 29\n```\n\n## Every\n\nevery 메서드는 제공된 콜백 함수에 의해 구현된 테스트를 통과하는 배열의 모든 요소를 검증하는 데 사용됩니다.\n\nevery는 모든 요소가 콜백 함수에서 지정된 조건을 충족하는 경우에만 true를 반환합니다. 콜백 함수에서 요소 중 하나라도 테스트를 통과하지 못하면 (콜백이 false를 반환하면) every는 즉시 반복을 중지하고 false를 반환합니다.\n\n\n\n```js\nconst ages = [31, 10, 45, 8, 6, 44, 43];\nconst allOver18 = ages.every(age => {\n   console.log(age); // 31, 10\n   return age > 18\n});\nconsole.log(allOver18); // false\n```\n\n## 일부\n\nevery와 반대로 사용하며 하나 이상의 요소가 사용자 정의 조건을 충족하는지 확인하려면 some 메서드를 사용할 수 있습니다.\n\n```js\nconst ages = [10, 45, 45, 8, 6, 44, 43];\nconst isSomeoneChild = ages.some(age => age < 18);\nconsole.log(isSomeoneChild); // true\n```\n\n\n\n## Flat\n\nflat 메서드는 모든 하위 배열 요소가 연결된 새 배열을 생성합니다. 이 프로세스는 재귀적일 수 있으며 지정된 깊이까지 중첩된 하위 배열을 평탄화합니다.\n\n이전에는 reduce 메서드를 사용하여 평탄화를 수행할 수 있었지만, flat은 이 작업에 대해 더 간결하고 내장된 솔루션을 제공합니다.\n\n```js\nconst animals = [\"dog\", \"cat\", \"chicken\", \"salmon\", [\"spider\", \"horse\"]];\nconsole.log(animals.flat()); // [ \"dog\", \"cat\", \"chicken\", \"salmon\", \"spider\", \"horse\" ]\n```\n\n\n\n## FlatMap\n\n이전에 평탄화할 수 있었던 것은 map과 flat을 결합함으로써 이루어졌었습니다. 그러나 flatMap은 더 간결한 방식을 제공합니다.\n\n이 메소드는 사실상 이 두 가지 방법을 하나의 단계로 결합합니다. flatMap은 배열의 각 요소에 콜백 함수를 적용한 다음 결과를 한 단계로 평탄화하여 새 배열을 생성합니다.\n\nfilter + map을 사용한 첫 번째 예제를 살펴보겠습니다.\n\n\n\n```js\nconst owners = [\n  { name: \"Alice\", pets: [{ type: \"cat\", name: \"Luna\" }] },\n  { name: \"Bob\", pets: [{ type: \"dog\", name: \"Charlie\" }, { type: \"cat\", name: \"Whiskers\" }] },\n  { name: \"Charlie\", pets: [] },\n];\n\nconst catNames = owners.flatMap(owner => owner.pets)\n  .filter(pet => pet.type === \"cat\")\n  .map(cat => cat.name);\n\nconsole.log(catNames);\n```\n\n이제 flatMap을 사용하여 다시 작성해 봅시다.\n\n```js\nconst owners = [\n  { name: \"Alice\", pets: [{ type: \"cat\", name: \"Luna\" }] },\n  { name: \"Bob\", pets: [{ type: \"dog\", name: \"Charlie\" }, { type: \"cat\", name: \"Whiskers\" }] },\n  { name: \"Charlie\", pets: [] },\n];\n\nconst catNames = owners\n  .flatMap(owner => owner.pets.flatMap(pet => (pet.type === \"cat\" ? pet.name : [])));\n\nconsole.log(catNames); //  [\"Luna\", \"Whiskers\"]\n```\n\n## ToSpliced\n\n\n\n\n이 기능은 splice와 유사하게 작동합니다.\n\n그러나 중요한 차이점이 있습니다: splice는 원래 배열을 직접 수정하지만 toSpliced는 제거된 요소를 제외한 새로운 배열을 생성합니다. 게다가 splice는 제거된 요소를 별도의 배열로 반환하는 반면 toSpliced는 변경된 배열 자체에 중점을 둡니다.\n\n```js\nconst animals = [\"개\", \"고양이\", \"닭\", \"상어\"];\n\nconst cleanedArray = animals.toSpliced(1, 2);\n\nconsole.log(removed); // [\"개\", \"상어\"]\nconsole.log(animals); // [\"개\", \"고양이\", \"닭\", \"상어\"]\n```\n\n## 정렬\n\n\n\n배열의 요소를 기본적으로 오름차순으로 정렬합니다. 이 메서드는 정렬된 동일한 배열에 대한 참조를 반환하며, 이제 정렬되었습니다.\n\n```js\nconst animals = [\"dog\", \"cat\", \"chicken\", \"shark\"];\n\nanimals.sort();\n\nconsole.log(animals); // [\"cat\", \"chicken\", \"dog\", \"shark\"]\n```\n\n## ToSorted\n\n원 배열을 직접 수정하는 sort 메서드와 달리, toSorted는 배열의 새로운 복사본을 만듭니다. 따라서 원래 배열은 그대로 유지됩니다.\n\n\n\n```js\nconst animals = [\"dog\", \"cat\", \"chicken\", \"shark\"];\n\nconst sortedAnimals = animals.toSorted();\n\nconsole.log(sortedAnimals); // [ \"cat\", \"chicken\", \"dog\", \"shark\" ]\nconsole.log(animals); // [\"cat\", \"chicken\", \"dog\", \"shark\"]\n```\n\n## With\n\n해당 인덱스의 값을 변경합니다. 주어진 값으로 주어진 인덱스를 대체한 새로운 배열을 반환합니다. 일반적으로 대괄호와 인덱스로 이 작업을 수행하지만 기존 배열을 수정합니다.\n\n```js\nlet animals = [\"dog\", \"cat\", \"chicken\", \"shark\"];\n\nanimals[0] = \"spider\";\nconsole.log(animals); // [\"spider\", \"cat\", \"chicken\", \"shark\"]\n\nanimals = [\"dog\", \"cat\", \"chicken\", \"shark\"];\n\nconst newAnimals = animals.with(0, \"spider\");\n\nconsole.log(newAnimals); // [\"spider\", \"cat\", \"chicken\", \"shark\"]\nconsole.log(animals); // [\"dog\", \"cat\", \"chicken\", \"shark\"]\n```","ogImage":{"url":"/assets/img/2024-05-12-LevelUpYourJavaScriptMasteringArrayManipulationTechniques_0.png"},"coverImage":"/assets/img/2024-05-12-LevelUpYourJavaScriptMasteringArrayManipulationTechniques_0.png","tag":["Tech"],"readingTime":11},{"title":"러스트를 사용한 것이 괜찮았나요","description":"","date":"2024-05-12 23:55","slug":"2024-05-12-WasRustWorthIt","content":"\n\n![2024-05-12-WasRustWorthIt_0](/assets/img/2024-05-12-WasRustWorthIt_0.png)\n\n몇 년 전에 나는 모든 것을 내려놓고 WebAssembly에 100% 집중하기로 결심했습니다. 그 당시에 Rust는 WebAssembly로 컴파일하는 데 가장 좋은 지원을 제공했으며, 가장 기능이 풍부한 WebAssembly 런타임은 Rust 기반입니다. Rust가 메뉴에서 최상의 선택이었습니다. 나는 그 호기심이 어디에서 나왔는지 알기 위해 들어갔습니다.\n\n그 이후로 나는(다른 멋진 사람들과 함께) WebAssembly를 핵심 모듈 시스템으로 사용하는 응용 프레임워크 및 런타임인 Wick를 만들었습니다.\n\n![2024-05-12-WasRustWorthIt_1](/assets/img/2024-05-12-WasRustWorthIt_1.png)\n\n\n\n수년의 경력, 다양한 제품 배포, ebook, 그리고 crates.io에 배포된 ~100개의 패키지가 있으니 Rust에 대한 생각을 공유할 시간이 된 것 같아요.\n\n# 좋은 점\n\n## 더 많은 것을 적은 노력으로 유지할 수 있어요\n\n저는 테스트 주도 개발을 강력히 지지해요. 자바, 자바스크립트 같은 언어에서 테스트에 익숙해졌어요. Rust에서도 다른 언어와 마찬가지로 테스트를 작성했지만, 실패할 수 없는 테스트를 작성하게 된 걸 발견했어요. Rust 코드가 컴파일될 수 있는 지점에 도달하면 많은 오류를 고려하여 많은 일반적인 테스트 사례가 관련이 없어집니다. ''unsafe'' 블록이나 .unwrap()과 같은 패닉이 발생할 수 있는 메서드를 피한다면, 기본으로 많은 문제를 우회하는 기반이 생기게 됩니다.\n\n\n\n러스트의 빌림 검사자의 강인함, 러스트의 타입 시스템의 풍부함, 함수형 패턴 및 라이브러리, 그리고 \"null\" 값이 없는 것은 테스트하는 데 들이는 노력이 적은 상태로 더 많은 것을 유지하도록 이끕니다. Wick 프로젝트의 70,000줄 이상의 코드를 다른 언어에서 필요한 것보다 훨씬 적은 테스트로 유지했습니다.\n\n테스트를 작성해야 할 때, 그냥 추가해도 괜찮은 거예요. 러스트의 통합 테스트 하네스를 사용하면 코드 옆에 거의 생각 없이 테스트를 추가할 수 있습니다.\n\n## 이제 다른 언어에서 더 잘 코딩합니다\n\n러스트에서 코딩하는 것은 감정적으로 학대를 당하는 것과 같습니다. 러스트는 하루 종일 당신에게 소리치고, 종종 다른 생활에서는 완전히 정상적으로 여겼을 일에 대해 소리를 질러요. 결국, 그 소리를 듣는 데 익숙해져요. 그것들이 일상이 되어요. 당신은 컴파일러의 화를 부르지 않도록 갈고리를 걷는 법을 배워요. 그리고 실제 생활에서처럼, 그 행동 변화는 영원히 당신과 함께 남아 있습니다.\n\n\n\n정서적 학대는 일반적으로 변화를 격려하는 건 건강한 방법으로 여기지 않지만, 그럼에도 불구하고 변화를 일으킵니다.\n\n다른 언어로 코드를 작성할 때 순서가 맞지 않을 때나 반환 값이 확인되지 않을 때 불편함을 느낍니다. 런타임 오류가 발생하면 이성적으로 화가 나게 됩니다.\n\n![이미지](/assets/img/2024-05-12-WasRustWorthIt_2.png)\n\n## Clippy 정말 좋아요!\n\n\n\n크리피는 러스트의 린터입니다, 하지만 그것을 그냥 린터라고 부르는 것은 조금 과분한 것 같아요. 컴파일러가 당신을 울게 할 수 있는 언어에서, 크리피는 린터보다는 오히려 친절한 친구 같아요.\n\n러스트 표준 라이브러리는 거대해요. 많은 기능이 다양한 작은 유형, 트레이트, 매크로, 함수에 걸쳐 퍼져 있기 때문에 이미 존재할 것으로 알고 있는 함수를 찾기가 어려워요. 많은 크리피 규칙들(예: `manual_is_ascii_check`)은 표준 라이브러리의 메서드나 유형이 더 나은 대체물이 될 수 있는 일반적인 패턴을 찾아냅니다.\n\n크리피는 성능, 가독성 및 불필요한 간접 참조를 다루는 수백 개의 규칙을 가지고 있습니다. 가능한 경우 대체 코드를 자주 제시해 줄 거예요.\n\n또한 (곧) 프로젝트용 전역 린트를 구성할 수 있게 될 것 같아요. 지금까지는 프로젝트의 일관성을 유지하기 위해 해킹 해야만 했어요. Wick에서는 몇 십 개의 크레이트에 대한 인라인 린트 구성을 자동으로 업데이트하는 스크립트를 사용해요. 러스트 커뮤니티가 이를 위한 해결책을 찾아내기까지 몇 년이 걸렸는데, 그 결과가 이런 것이 되었군요...\n\n\n\n# 나쁜 점\n\n## 살아가야 할 공백이 있습니다\n\n제가 위의 Clippy 문제로 다시 돌아올 때마다 제 정신을 의심했어요. 분명히 제가 잘못했을 거예요. 빠뜨린 설정이 있을 테니까요. 그것을 믿을 수 없었어요. 지금도 그런 생각이 들어요. 린트를 전역으로 구성할 수 있는 방법이 있을 텐데요. 이 글을 쓸 때 현실감 있는지 확인하려고 네 번이나 확인했어요. 이제는 그 문제들이 해결되었지만 그동안 몇 년 동안 계속되었었어요.\n\nClippy는 멋지지만 이러한 사용 사례가 러스트 세계 여러 곳에서 자주 발생합니다. 내 사용 사례가 다루지 않는 라이브러리나 도구를 자주 만나게 돼요. 새로운 언어나 프로젝트에서 이것이 일반적이죠. 소프트웨어는 시간(사용)이 걸려 성숙해져야 해요. 하지만 러스트는 그렇게 새로운 게 아니에요. 러스트에는 다른 느낌이 있는 거거든요.\n\n\n\n오픈 소스에서 에지 케이스는 초기 채택자와 새로운 사용자들에 의해 자주 다뤄집니다. 그들이 바로 에지 케이스를 가지고 있는 사람들이죠. 그들의 PR은 프로젝트를 개선하여 다음 사용자들에게 더 좋은 환경을 제공합니다. Rust는 거의 10년 동안 \"가장 사랑받는 언어\"로 선정되었습니다. 새로운 사용자를 유치하는 데는 어려움이 없지만, 이로 인해 혁신적으로 개선된 라이브러리나 도구가 나오지는 않습니다. 대신 특정 사용 사례를 다루는 일회성 포크가 나오는 것이 일반적입니다. 저 또한 그 중 하나인데요, 그것은 PR을 제출하려는 노력 부족 때문은 아닙니다.\n\n왜 그럴까요. 안정적인 API를 유지하는 압력과 Rust의 세밀한 유형 시스템으로 인해 라이브러리 소유자들이 반복적인 작업을 하는 것이 어려울 수 있습니다. 만약 작은 변경 사항이 큰 버전 상향을 야기하는 경우 소수의 변경 사항을 수용하기가 어려울 수 있습니다.\n\n아니면 모든 사람을 위해 모든 일을 처리하는 Rust 코드를 작성하는 것이 극도로 어렵기 때문에 사람들이 그것을 다루고 싶어하지 않을 수도 있습니다.\n\n## Cargo, crates.io 및 프로젝트 구조화 방법\n\n\n\n다른 인기있는 프로젝트를 보고 Wick 저장소 구조를 모델로 만들었어요. 합리적으로 보였고 제대로 작동했어요, 근데 언젠가부터는 문제가 발생했어요.\n\nCargo를 이용하면 모듈 크기의 상자를 쉽게 만들고 테스트할 수 있어요. 하지만 crates.io로 배포하는 건 전혀 다른 이야기네요.\n\ncrates.io로 패키지를 게시하려면 각각의 참조된 크레이트가 개별로 게시되어 있어야 해요. 그게 납득이 가는 부분이죠. 저차원의 파일시스템에만 존재하는 패키지에 의존하고 싶지 않잖아요.\n\n하지만 많은 개발자들이 큰 프로젝트를 자연스럽게 작은 모듈로 분할하는데, 자기 자신 안에만 존재하는 하위 크레이트를 가진 상위 크레이트를 게시할 수 없어요. 심지어 로컬 개발 의존성을 가진 크레이트도 게시할 수 없답니다. 이 문제를 피하려면 무작위 유틸리티 크레이트를 게시할지, 프로젝트를 다시 구조화할지 선택해야 해요. 이 제약은 임의적이고 불필요하다는 느낌이 들어요. 이렇게 구조화된 프로젝트를 만들 수는 있지만, 게시할 수는 없다는 게 함정이죠.\n\n\n\n카고는 역시 우수한 작업 공간 지원이 있어요! 카고의 작업 공간은 대부분의 언어보다 큰 프로젝트를 더 잘 관리할 수 있는 경험을 제공해줘요. 하지만 배포 문제를 해결해 주지는 않아요. 사실, 작업 공간을 설정하는 방법은 수십 가지중 어느 것도 배포를 쉽게 해결해 주지 않아요.\n\n이 문제는 실용적인 유틸리티 크레이트 수가 많아서 발생합니다. 각각은 일부 구성과 함께 작동하며, 아직까지 작업 공간을 설정하는 \"진정한 방법\"은 제가 아직 찾지 못했어요. Wick를 게시할 때, 수동적이고 반복적인 작업을 부분적으로만 작동하는 도구와 결합하는 노력이 자주 1시간 이상 걸려요.\n\n## Async\n\nRust는 시작 이후에 비동기성을 언어에 추가했어요. 이것은 나중에 생각한 것처럼 느껴지고, 그렇게 작동하며, 종종 이해하고 해결하기 어려운 오류로 인해 방해를 받을 수 있어요. 해결책을 찾을 때는 다양한 런타임 및 이들의 비동기 스타일을 기반으로 필터링해야 해요. 비동기 라이브러리를 사용하고 싶으세요? 특정 비동기 런타임 외에서 사용할 수 없는 가능성이 있어요.\n\n\n\n두 10년 이상의 JavaScript 경험에 Go 언어로 우수한 경험이 있는 만큼, Rust에서 가장 큰 단점이자 괴로움의 원천은 비동기 처리와 관련된 부분일 것입니다. 극복할 수 있는 문제이지만, 비동기 처리 기능이 필요할 때 항상 준비돼 있어야 합니다. 다른 언어들에서는 비동기 처리가 거의 눈에 띄지 않는데, Rust에서는 그렇지 않습니다.\n\n# 까다로운 부분\n\n## 리팩터링은 지루할 수 있습니다\n\nRust의 풍부한 유형 시스템은 축복이자 저주입니다. Rust 유형으로 생각하는 것은 꿈같은 경험이 될 수 있습니다. 그러나 Rust의 유형 관리는 악몽이 될 수 있습니다. 데이터와 함수 시그니처에는 일반 유형, 일반 수명 및 특성 제약사항이 포함될 수 있습니다. 이러한 제약 조건에는 고유의 일반 유형 및 수명이 포함될 수 있습니다. 때로는 실제 코드보다 유형 제약이 더 많을 수도 있습니다.\n\n\n\n\n![이미지](/assets/img/2024-05-12-WasRustWorthIt_3.png)\n\n첫 번째로 작성할 때 일일히 제네릭을 모두 정의해야 합니다. 처음에 쓸 때는 지루하지만 리팩토링할 때는 작은 변경도 연쇄적인 문제로 이어질 수 있습니다.\n\n![이미지](/assets/img/2024-05-12-WasRustWorthIt_4.png)\n\n하나의 작업을 진행하기 전에 14개의 다른 정의를 조정해야 한다면 빠른 진전을 이루기 어려울 것입니다.\n\n\n\n이해해 줘서 고마워요! 의견에 대해 수정한 내용을 적용했습니다.\n\n# 결론\n\n러스트를 좋아해요. 무엇이든 할 수 있고 다재다능한 모습을 사랑합니다. CLI 앱, 웹 서버 및 웹 클라이언트를 동일한 언어로 작성할 수 있습니다. 웹어셈블리를 사용하면 브라우저에서도 LLM을 실행할 때와 동일한 이진 파일을 사용할 수 있습니다. 이것이 여전히 제 머릿속을 뒤흔들어요.\n\n러스트 프로그램이 얼마나 견고한지 사랑합니다. 러스트가 보호해주는 것들을 깨달은 후에는 다른 언어로 돌아가기 힘들어요. 잠시 동안 Go로 돌아갔다가 빠른 개발 속도에 다시 빠지게 되었어요. 그리고 런타임 패닉이 발생하고 유리가 깨지더라구요.\n\n\n\n하지만 러스트에는 문제점이 있어요. 채용이 어렵고 배우는 데 시간이 오래 걸리며 빠르게 반복할 수 없을 정도로 엄격해요. 특히 async 코드를 다룰 때 메모리 및 성능 문제를 해결하는 게 어렵죠. 모든 라이브러리가 안전한 코드에 대해 동일하게 좋지는 않고, 개발 도구도 많이 부족해요. 시작할 때 어려움이 많고 다른 것들도 많이 방해하겠지만, 그 장애물을 극복하면 모두를 앞지를 수 있을 거예요. 하지만 이건 커다란 가정이에요.\n\n우리에게 러스트는 가치가 있었을까요? 아직 일러본도 못했어요. 작은 팀으로 놀라운 일을 해냈지만 방해요소도 많았죠. 러스트를 더 적합하게 만든 기술적 이유도 있었어요.\n\n당신에게는 가치가 있을까요? 빠르게 반복해야 한다면 아마 그렇지 않을 거예요. 알려진 범위가 있거나 초기 비용을 조금 더 감당할 수 있다면? 분명히 고려해보세요. 견고한 소프트웨어를 만들 수 있을 거예요. 매월 더 강해지는 WebAssembly 각도로 봤을 때, 한 번 완벽한 소프트웨어를 작성하고 어디서든 재사용하는 전망이 더 빨리 현실이 될 것 같아요.","ogImage":{"url":"/assets/img/2024-05-12-WasRustWorthIt_0.png"},"coverImage":"/assets/img/2024-05-12-WasRustWorthIt_0.png","tag":["Tech"],"readingTime":6},{"title":"힙 메모리 프로파일링이 나에게 메모리 누수에 대해 가르쳐준 것","description":"","date":"2024-05-12 23:53","slug":"2024-05-12-HeresWhatHeapMemoryProfilingTaughtMeAboutMemoryLeaks","content":"\n\n![메모리 누수에 대한 Heap 메모리 프로파일링이 가르쳐 준 것](/assets/img/2024-05-12-HeresWhatHeapMemoryProfilingTaughtMeAboutMemoryLeaks_0.png)\n\n웹 개발자로서, 보통은 JavaScript(사실 TypeScript)로 코딩을 즐겨하며, 애플리케이션이 브라우저에서 실행될 때 관리되는 메모리 관리와 가비지 수집의 복잡성에 무감각하게 살아갑니다. 메모리 관리? 응, 그건 브라우저가 걱정해야 하는 문제야!\n\n가끔은 사소한 코드 변경으로 우리의 한 때는 원활하게 작동하던 애플리케이션이 녹슬은 보트처럼 갑자기 물고기처럼 움직이기 시작합니다. 느린 반응, 응달한 인터페이스, 그리고 두려운 충돌이 제 친절치 않은 동반자가 되곤 했습니다. 그래서 가끔씩, 나는 브라우저 JavaScript 메모리 개발 도구 패널의 신비한 동굴 속에서 자신을 발견하곤 합니다.\n\n개발 도구 메모리 탭의 깊은 곳으로 다시 돌아가려면 언제나 어려운 작업이 필요합니다. 거의 갈 일이 없는 이곳을 방문하려면 상기시키기가 언제나 필요하죠. 리프레셔를 통과한 후, 내 시간을 거기서 즐기기 시작했습니다. 거기에는 애플리케이션의 효율성 또는 종종 비효율성, 그리고 숨겨진 메모리 누수에 대한 통찰과 비밀이 가득한 지식의 보물창고가 있습니다.\n\n\n\n잠시만요, 브라우저 메모리 패널을 빠르게 살펴보며 만들어지는 골드를 발굴해 보겠습니다. Chrome DevTools에서 자바스크립트 힙과 메모리 할당의 신비를 풀기 위해 함께 여행을 떠날 준비가 되셨나요?\n\n# 힙이란?\n\n자바스크립트 힙은 웹 브라우저 내부의 특정 메모리 공간을 가리키며, 자바스크립트 코드에서 사용하는 데이터를 저장하는 데 전용되어 있습니다. 이는 웹 애플리케이션 실행에 특별히 예약된 대규모 메모리 풀로 이해하시면 됩니다.\n\n- 런타임 중에 자바스크립트 코드에 의해 할당된 동적 데이터를 저장합니다. 이에는 객체, 배열, 함수 및 스크립트에서 생성된 다른 데이터 구조가 포함됩니다.\n- 스택에 있는 변수(숫자나 문자열과 같은 고정 크기 데이터에 사용)와는 달리, 힙은 코드의 필요에 따라 유연하게 메모리를 할당할 수 있습니다.\n- 자바스크립트 엔진은 힙을 자동으로 관리하여 새로운 객체에 대해 메모리를 할당하고 사용되지 않는 것들에 대해서는 가비지 수집(garbage collection)이라는 과정을 통해 메모리를 회수합니다.\n\n\n\n우리는 다행히도 코드에서 직접 메모리 할당 또는 해제를 관리하지 않습니다. 하지만 힙이 작동하는 방식을 이해하면 더 효율적이고 성능이 우수한 JavaScript 코드를 작성하는 데 도움이 될 수 있어요.\n\n## 우리는 공간을 세 가지 부분으로 나눌 수 있어요\n\n- 살아 있는 객체: 현재 코드에서 사용 중인 객체로 힙 공간을 차지하고 있어요.\n- 죽은 객체: 코드에서 더는 필요하지 않지만 쓰레기 수집에 의해 회수되지 않은 객체들이에요.\n- 빈 공간: 새로운 객체를 할당하기 위해 사용 가능한 사용되지 않은 메모리공간이에요.\n\n## 이 정보를 활용해서 무엇을 할 수 있을까요?\n\n\n\n- 힙(heap)이 어떻게 작동하는지 이해하면 효율적인 메모리 관리가 가능해지며, 이는 성능과 안정성에 직접적으로 영향을 미칩니다.\n- 더 이상 필요하지 않은 객체가 의도하지 않게 보관되는 메모리 누수는 메모리 고갈, 느려짐 및 최종적으로 충돌로 이어질 수 있습니다. (오늘 이 글을 쓰게 된 동기입니다)\n\n자바스크립트 힙은 웹 애플리케이션의 메모리를 관리하는 데 중요한 역할을 합니다. 용도, 관리 전략 및 구성 요소를 이해함으로써, 보다 숙련되고 책임감 있는 개발자가 되어 효율적이고 성능이 우수한 코드를 작성하여 부드러운 사용자 경험을 제공할 수 있습니다.\n\n# 메모리 사용 분석을 위한 메모리 탭 활용 방법\n\n힙 스냅샷\n\n\n\n- 특정 시점에 전체 JavaScript 힙에 대한 스냅샷을 촬영할 수 있게 해줘요. 메모리 사용량을 캡처하는 것과 같아요. 살아있는 모든 객체와 그들의 관계를 포함하고 있어요.\n- 다른 애플리케이션 상태 간의 스냅샷을 비교하여 메모리 누수를 식별할 수 있어요.\n- 다른 객체 유형이 사용하는 메모리의 전반적인 분포를 분석할 수 있어요.\n- 불필요한 데이터를 유지하고 있는 이유를 이해하기 위해 개별 객체와 속성을 검사할 수 있어요.\n\n![이미지 파일](/assets/img/2024-05-12-HeresWhatHeapMemoryProfilingTaughtMeAboutMemoryLeaks_1.png )\n\n![이미지 파일](/assets/img/2024-05-12-HeresWhatHeapMemoryProfilingTaughtMeAboutMemoryLeaks_2.png)\n\n상호작용해보세요! 애플리케이션의 작업 흐름의 다른 단계에서 스냅샷을 찍어 메모리 사용량을 비교하고 잠재적인 누출을 식별하세요. \"스냅샷 찍기\" 버튼을 내일이 없는 것처럼 클릭해보세요!\n\n\n\n## 타임라인에 할당 계측\n\n이 옵션은 웹 애플리케이션에서 메모리 사용량을 분석하는 강력한 방법을 제공합니다. 힙 스냅숏(Heap Snapshots)과 할당 샘플링(Allocation Sampling)의 측면을 결합하여 애플리케이션 실행에 따른 메모리 할당 및 해제 이벤트를 자세히 보여줍니다.\n\n- 일정 간격으로 JavaScript 힙의 스냅숏과 해당 스냏텟들 사이에 할당 및 해제된 모든 객체에 대한 정보를 기록합니다.\n- 객체 생성(메모리 할당 이벤트) 및 객체 해제(메모리 해제 이벤트)를 나타내는 표식이 있는 시각적 타임라인을 생성합니다.\n\n![이미지](/assets/img/2024-05-12-HeresWhatHeapMemoryProfilingTaughtMeAboutMemoryLeaks_3.png)\n\n\n\n- 특정 사용자 상호 작용이나 코드 실행 중에 메모리 사용량이 어떻게 변화하는지 확인해 보세요.\n- 할당된 메모리를 정리하는 쓰레기 수집 주기의 효과를 분석하세요.\n\n![image](/assets/img/2024-05-12-HeresWhatHeapMemoryProfilingTaughtMeAboutMemoryLeaks_4.png)\n\n- 시간이 지남에 따라 메모리가 어떻게 변하는지 명확하게 시각적으로 표현하여 잠재적인 문제를 식별하기가 더 쉬워집니다.\n\n전반적으로 할당 기기 프로필 형식은 응용 프로그램의 메모리 사용량에 대한 깊은 통찰력을 얻을 수 있는 소중한 도구이며, 잠재적인 메모리 누수를 식별하는 데 도움이 됩니다. 메모리 변화를 이해하는 데 중요한 복잡한 응용 프로그램이나 상황에 특히 유용합니다.\n\n\n\n## 할당 샘플링\n\n프로필은 애플리케이션 실행 중 특정 기간 동안 새로 할당된 JavaScript 객체에 대한 정보를 기록합니다. 다른 프로필 유형과 달리 전체 힙의 스냅샷을 캡처하지는 않지만 대신 시간 경과에 따른 메모리 할당 패턴을 추적하는 데 초점을 맞춥니다.\n\n- 메모리 핫스팟 식별: 가장 많은 메모리 할당을 담당하는 애플리케이션 내 함수 또는 코드 블록을 파악하는 데 도움이 됩니다. 이를 통해 코드의 어느 부분이 전체 메모리 사용량에 가장 크게 기여하는지 이해할 수 있습니다.\n- 시간별 메모리 변화 분석: 기간 동안 데이터를 수집하여 특정 사용자 상호작용이나 코드 실행 중 메모리 사용량이 어떻게 변하는지 볼 수 있습니다. 이를 통해 할당 증가와 관련된 메모리 누수나 병목 현상을 식별할 수 있습니다.\n- 빈번한 가비지 컬렉션 진단: 애플리케이션이 빈번한 가비지 컬렉션 주기를 겪는 경우, 할당 샘플링을 통해 가장 수명이 짧은 객체를 생성하는 코드 섹션이 어디인지 이해할 수 있습니다. 이를 통해 불필요한 할당을 줄이고 가비지 컬렉션 효율성을 향상시킬 수 있습니다.\n\n<img src=\"/assets/img/2024-05-12-HeresWhatHeapMemoryProfilingTaughtMeAboutMemoryLeaks_5.png\" />\n\n\n\n<img src=\"/assets/img/2024-05-12-HeresWhatHeapMemoryProfilingTaughtMeAboutMemoryLeaks_6.png\" />\n\n## 할당 샘플링 프로필에 대한 추가 참고 사항\n\n- 전체 힙을 표시하지 않습니다: \"힙 스냅샷\"과 달리 특정 시점에 전체 JavaScript 힙을 캡처하지 않습니다. 이는 누수 가능성이 있는 객체를 직접 식별할 수 없지만 어느 영역이 많이 할당되는지만 볼 수 있음을 의미합니다.\n- 자원을 많이 소비할 수 있습니다: 많은 양의 할당된 객체를 샘플링하는 것은 응용 프로그램 실행에 약간의 부하를 추가합니다. 성능에 영향을 미치지 않도록 짧은 기간 동안 신중하게 사용하십시오.\n\n할당 샘플링 프로필은 JavaScript 애플리케이션에서 메모리 할당 패턴을 프로파일링하는 데 유용한 도구입니다. 높은 메모리 사용을 가진 코드 영역을 식별하고, 시간 경과에 따른 메모리 변화를 이해하며, 빈번한 가비지 수집과 관련된 잠재적인 성능 문제를 진단하는 데 도움이 됩니다.\n\n\n\n우리 Memory Tab 프로필 중 \"Heap Snapshots\" 또는 \"Allocation instrumentation on timeline\"과 같은 다른 프로필을 대체하려는 것이 아닙니다. 서로 다른 통찰력을 제공하는 다른 도구를 선택하세요. 특정한 요구사항과 메모리 분석 목표에 따라 올바른 도구를 선택해야 합니다.\n\n힙과 메모리 프로파일링을 탐구한 결과, JavaScript 응용 프로그램 내의 메모리 관리 세계를 탐구하기 흥미롭고 비교적 편안한 곳이라는 것을 발견했습니다.\n\n메모리 누수는 때때로 발생하는 것조차 모르기 어려울 뿐 아니라 어플리케이션이 수십만 줄 또는 수백만 줄의 코드로 이루어진 상황에서 어디서 발생했는지 정확히 파악하는 것이 어렵습니다. 실수로 유지된 객체에 대한 의도하지 않은 참조로 인한 메모리 누수는 메모리 고갈, 성능 저하 및 최종적으로 어플리케이션 충돌과 같은 여러 문제를 야기할 수 있습니다. 이는 JavaScript 힙 안에서 메모리가 어떻게 할당되고 사용되며 회수되는지를 이해하는 것이 상당히 중요하다는 것을 강조합니다.\n\n이러한 지식을 바탕으로 메모리 누수를 효과적으로 식별하고 해결하는 방법 뿐만 아니라 더 효율적이고 성능이 우수한 코드를 설계하는 방법도 익혔습니다. 브라우저의 JavaScript 힙을 탐험하는 여정은 계몽적이고 능력을 부여하는 경험이 되었습니다.\n\n\n\n\n만약 이 콘텐츠를 즐겼고 이러한 노력을 지원하고 싶다면 여기를 방문해주세요: https://ko-fi.com/jacobmacinnis.\n\n# 쉽고 날 것의 영어로 🚀\n\nIn Plain English 커뮤니티의 일원이 되어 주셔서 감사합니다! 떠나시기 전에:\n\n- 반드시 박수를 보내고 작가를 팔로우해주세요 👏️️\n- 팔로우하기: X | LinkedIn | YouTube | Discord | Newsletter\n- 다른 플랫폼 방문하기: Stackademic | CoFeed | Venture | Cubed\n- PlainEnglish.io 에서 더 많은 콘텐츠 확인하기\n","ogImage":{"url":"/assets/img/2024-05-12-HeresWhatHeapMemoryProfilingTaughtMeAboutMemoryLeaks_0.png"},"coverImage":"/assets/img/2024-05-12-HeresWhatHeapMemoryProfilingTaughtMeAboutMemoryLeaks_0.png","tag":["Tech"],"readingTime":6},{"title":"JavaScript로 Command-Line Tool 만드는 방법","description":"","date":"2024-05-12 23:52","slug":"2024-05-12-BuildingaCommand-LineToolinJavaScriptSolvingaCodingChallenge","content":"\n<img src=\"/assets/img/2024-05-12-BuildingaCommand-LineToolinJavaScriptSolvingaCodingChallenge_0.png\" />\n\n# 소개:\n\n이 가이드에 오신 것을 환영합니다! JavaScript를 사용하여 명령줄 도구를 구축하는 코딩 챌린지에 도전하게 됩니다. 우리의 목표는 텍스트 파일을 분석하고 줄 수, 단어 수, 문자 수 등 다양한 메트릭을 제공할 수 있는 다재다능한 도구를 만드는 것입니다.\n\n여기에서 다룰 도전 과제를 찾을 수 있습니다. 이 작업에는 JavaScript (JS)을 사용하겠습니다. 이제 구현 세부 정보로 바로 들어가 봅시다.\n\n# 환경 설정하기\n\n명령줄 도구를 만들 때 가장 먼저 해야 할 일 중 하나는 코드를 작성할 위치를 결정하는 것입니다. 통합 개발 환경(IDE)에서의 전통적인 개발과는 달리, 스크립팅은 약간 다른 절차를 따릅니다.\n\n먼저, 컴퓨터에 Node.js가 설치되어 있는지 확인하세요. 그런 다음 다음 단계를 따르세요:\n\n- 프로젝트의 루트 디렉토리로 이동합니다.\n- mkdir bin 명령을 사용하여 'bin'이라는 새 폴더를 만듭니다.\n- 'bin' 폴더 내부에 새 파일을 만듭니다. touch `파일이름`을 사용할 수 있습니다.\n- 텍스트 편집기로 파일을 열기 위해 nano `파일이름`을 사용합니다.\n- 파일의 맨 위에 다음 해시뱅( shebang) 라인을 추가합니다: #!/usr/local/bin/node. 이 라인은 컴파일러에게 코드를 Node.js를 사용해 해석하도록 지시합니다.\n- Ctrl + O를 눌러 변경 사항을 저장한 후 Enter를 누르고 Ctrl + X를 눌러 편집기를 종료합니다.\n- chmod +x `파일이름`을 사용하여 스크립트에 실행 권한을 부여합니다.\n- bin 폴더 내부에 export PATH=\"$HOME/bin:$PATH\"를 입력합니다.\n- 이제이 스크립트를 실행할 때마다 Node.js 스크립트로 해석됩니다.\n\n# 챌린지 해결하기\n\n## 단계 1: 파일의 바이트 수 세기\n\n우리의 첫 번째 작업은 파일의 바이트 수를 계산하고 터미널에서 제공된 인수가 ‘-c’인지 감지하는 함수를 만드는 것입니다. 다음은 이를 어떻게 달성할 수 있는지입니다:\n\n```js\nconst fs = require(\"fs\");\nfunction readFileContent(fileName) {\n  if (!fs.existsSync(fileName)) {\n    console.log(`파일을 찾을 수 없습니다: ${fileName}`);\n    process.exit(1);\n  }\n\n  fs.readFile(fileName, \"utf8\", (err, data) => {\n    if (err) throw err;\n    const fileSizeInBytes = Buffer.byteLength(data, \"utf8\");\n    displayResult(fileSizeInBytes);\n  });\n}\nfunction displayResult(fileSizeInBytes) {\n  if (commandLineOption === \"-c\") {\n    console.log(`${fileSizeInBytes} ${fileName}`);\n  }\n}\nlet fileName = process.argv[2];\nconst commandLineOption = process.argv[3];\nreadFileContent(fileName);\n```\n\n이 코드 스니펫에서는 fs.readFile 메서드를 사용하여 파일 내용을 읽고 Buffer.byteLength를 사용하여 파일 크기를 바이트 단위로 계산합니다. 그런 다음 명령줄 옵션이 ‘-c’와 일치하는 경우 결과를 표시합니다.\n\n## 단계 2: 줄, 단어 및 문자수 계산하기\n\n다음으로, 파일의 줄 수, 단어 수 및 문자 수를 계산하는 도구를 확장합니다. readFileContent 함수를 재사용하여 ‘-l’, ‘-w’ 및 ‘-m’과 같은 추가 옵션을 지원하도록 향상시킬 수 있습니다.\n\n```js\nfunction readFileContent(fileName) {\n  // 이전과 동일\n  fs.readFile(fileName, \"utf8\", (err, data) => {\n    if (err) throw err;\n    const { charactersCount, wordsCount, numberOfLines } = parseFile(data);\n    displayResult(charactersCount, wordsCount, numberOfLines);\n  });\n}\nfunction parseFile(data) {\n  const charactersCount = data.length;\n  const wordsCount = data.split(\" \").length;\n  const numberOfLines = data.split(\"\\n\").length;\n  return { charactersCount, wordsCount, numberOfLines };\n}\nfunction displayResult(charactersCount, wordsCount, numberOfLines) {\n  // 이전과 동일하며 '-l', '-w', '-m'에 대한 추가 조건이 있습니다.\n}\nlet fileName = process.argv[2];\nconst commandLineOption = process.argv[3];\nreadFileContent(fileName);\n```\n\n이 수정된 코드에서는 파일 내용을 구문 분석하여 줄 수, 단어 수 및 문자 수를 계산합니다. 그런 다음 제공된 명령줄 옵션에 따라 해당 카운트를 표시합니다.\n\n## 단계 3: 표준 입력 처리\n\n파일 이름이 지정되지 않은 경우 표준 입력에서 읽기를 지원하기 위해 코드를 수정하여 다른 명령에서 입력이 파이프될 때 (예: cat test.txt | ccwc -l) 입력이 감지되는지 확인해야 합니다. 다음과 같이 이를 달성할 수 있습니다:\n\n```js\nif (!process.stdin.isTTY) {\n  let data = \"\";\n  process.stdin.setEncoding(\"utf8\");\n  process.stdin.on(\"data\", (chunk) => {\n    data += chunk;\n  });\n  process.stdin.on(\"end\", () => {\n    const { charactersCount, wordsCount, numberOfLines } = parseFile(data);\n    displayResult(charactersCount, wordsCount, numberOfLines);\n  });\n} else {\n  // 이전과 동일하지만 약간 수정된 부분이 있음\n}\n```\n\n표준 입력이 제공되는지 확인함으로써 (!process.stdin.isTTY), 우리는 적절하게 파이프로 연결된 입력을 처리할 수 있습니다.\n\n## 결론\n\n이 안내서에서는 코딩 도전 과제를 해결하기 위해 JavaScript로 명령줄 도구를 만드는 과정을 안내했습니다. 환경 설정, 파일에서 바이트, 라인, 단어 및 문자 수를 세는 기능 구현, 그리고 표준 입력 처리까지 다루었습니다.\n\n이 튜토리얼을 따라와 주셔서 CLI 도구 구축, Node.js 파일 처리, 그리고 동적으로 명령줄 인수를 처리하는 방법에 대한 통찰력을 얻었습니다.\n\nGitHub에서 완전한 코드 솔루션과 테스트 파일을 살펴보세요.\n\n이 안내서가 도움이 되었기를 바랍니다. 궁금한 사항이나 제안 사항이 있으면 아래에 댓글을 남겨주세요. 더 많은 튜토리얼을 기대해주세요!\n\n다음 포스트에서 뵙겠습니다!\n","ogImage":{"url":"/assets/img/2024-05-12-BuildingaCommand-LineToolinJavaScriptSolvingaCodingChallenge_0.png"},"coverImage":"/assets/img/2024-05-12-BuildingaCommand-LineToolinJavaScriptSolvingaCodingChallenge_0.png","tag":["Tech"],"readingTime":4}],"page":"123","totalPageCount":154,"totalPageGroupCount":8,"lastPageGroup":20,"currentPageGroup":6},"__N_SSG":true}