{"pageProps":{"posts":[{"title":"모던 브라우저에서 AWS S3 직접 업로드하는 방법","description":"","date":"2024-05-27 18:48","slug":"2024-05-27-Simplesecuredirect-to-S3uploadsfrommodernbrowsers","content":"\n\n안녕하세요, 제 이름은 Taylor Hughes입니다. 소프트웨어 엔지니어입니다. 저는 페이스북, 구글, 클럽하우스 및 중간의 여러 스타트업에서 앱을 출시하고 팀을 구축했습니다.\n\n사용자가 S3 버킷에 파일을 업로드할 수 있는 방법을 제공하는 문제는 모든 프로젝트에서 마주치는 문제입니다. 그러나 올바른 JavaScript 구성 요소를 식별하고 모든 것을 함께 작동하도록 설정하여이 작업을 수행하는 것은 마법처럼 느껴집니다.\n\nAWS 문서에 따르면 추가 인증 서비스를 설정하고 전체 AWS JS SDK를 클라이언트 코드로 가져와야하지만 실제로 그럴 필요는 없습니다!\n\n대신 사전 서명된 URL 및 현대적인 웹 API를 사용하여 브라우저에서 손쉽게 S3로 직접 업로드 할 수 있습니다. 코드 몇 줄을 사용하면 됩니다.\n\n<div class=\"content-ad\"></div>\n\n사용자 브라우저의 관점에서 전체 솔루션은 다음과 같습니다:\n\n- 사용자가 \"파일 업로드\"를 클릭하고 파일을 선택합니다.\n- 해당 파일의 메타데이터를 기반으로 서버 측 API에서 미리 서명된 S3 PutObject URL을 요청합니다.\n- 미리 서명된 S3 URL을 제공받으면 브라우저는 XmlHttpRequest를 사용하여 파일을 PUT하고 진행 상황을 모니터링할 수 있습니다.\n- 업로드가 완료되면 브라우저는 새 키를 다시 API로 반환하여 업로드된 파일에 대해 API가 수행해야 하는 작업을 트리거합니다.\n- 이윤 창출!\n\n만약 완성된 코드로 바로 이동하고 싶다면, TypeScript 프론트엔드 및 Python API 핸들러 예시가 포함된 gist를 확인해보세요.\n\n이 게시물에서는 단계별로 진행해 보겠습니다:\n\n<div class=\"content-ad\"></div>\n\n## AWS 구성\n\n먼저, 공개 액세스가 비활성화되어 있고 액세스 정책이 없는 새 버킷 yourproject-upload을 만듭니다. (또한 이 버킷에 대해 모든 것을 24시간 후에 만료되도록 하는 라이프사이클 규칙을 추가했습니다 — 업로드된 파일을 다른 위치로 이동하여 공개적으로 사용합니다.)\n\n둘째, web-upload-only라는 새 IAM 사용자를 추가합니다. 새 사용자의 액세스 키와 비밀을 가져와서 이를 백엔드 웹 서버에 추가하세요. (이 자격 증명은 주 AWS 자격 증명과 별도여야 합니다.)\n\n셋째, web-upload-only에게 새 버킷 yourproject-upload/*의 모든 경로에 대한 s3:PutObject 액세스 권한을 부여합니다. (우리는 사전 서명된 PutObject URL을 반환할 때 쓰기 키를 제한할 것입니다.)\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-27-Simplesecuredirect-to-S3uploadsfrommodernbrowsers_0.png\" />\n\n마지막으로, 일반 AWS 역할 또는 사용자에게 yourproject-upload/* 버킷에 s3:GetObject 액세스도 부여하세요. 업로드 버킷에서 파일을 가져와 main/public 서빙 버킷으로 옮기기 위해 더 많은 권한을 가진 다른 사용자가 필요합니다.\n\n## 웹 서버: \"업로드 생성\" API 엔드포인트 추가\n\n새 IAM 사용자의 액세스 키와 시크릿을 얻었다면 이제 S3에 특정 키를 쓸 수 있는 사전 서명된 URL을 생성할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n새로운 엔드포인트로 전송되는 입력은 다음과 같습니다:\n\n- content_type — 브라우저의 PUT 요청의 컨텐츠 유형으로 설정될 파일의 MIME 유형이며, 서명에 포함되어야 합니다.\n- filename — 파일의 원본 파일명으로, 여기서 확장자를 가져와서 S3 키에 좋은 확장자를 부여할 수 있습니다.\n\n이러한 입력을 바탕으로 AWS S3 클라이언트를 생성하고 서명된 PutObject URL을 생성하세요. Python에서 boto3를 사용하면 다음과 같이 보입니다:\n\n```python\ndef upload_s3_client() -> S3Client:\n    return boto3.client(\n        \"s3\",\n        aws_access_key_id=settings.UPLOAD_AWS_ACCESS_KEY_ID,\n        aws_secret_access_key=settings.UPLOAD_AWS_SECRET_ACCESS_KEY,\n        region_name=AWS_REGION,\n    )\n\n@api_view(\"/upload/create\")\ndef create_upload(request: Request) -> Response:\n    ext = request.validated_data[\"original_filename\"].split(\".\")[-1].lower()\n    # 생성된 S3 경로에 사용자 ID와 날짜 포함하기:\n    date = datetime.now().strftime(\"%Y%m%d\")\n    key = f\"uploads/{request.user.id}/{date}-{uuid.uuid4()}.{ext}\"\n    # 서명된 URL 생성:\n    presigned_upload_url = upload_s3_client().generate_presigned_url(\n        \"put_object\",\n        Params={\n            \"Bucket\": \"yourproject-upload\",\n            \"Key\": key,\n            \"ContentType\": request.validated_data[\"content_type\"],\n        },\n        ExpiresIn=60 * 60,\n    )\n    # 클라이언트에게 키 및 서명된 PutObject URL을 반환합니다:\n    return success_response(\n        {\"key\": key, \"presigned_upload_url\": presigned_upload_url}\n    )\n```\n\n<div class=\"content-ad\"></div>\n\n## 클라이언트 측: 모두 연결하기\n\n이제 클라이언트 측에서는 파일 입력란을 추가하여 파일 객체를 가져와야합니다. 한 번 파일 객체를 가져오면 새 API 백엔드에서 미리 서명된 URL을 요청할 수 있습니다. API 요청을 보통 어떻게 만들든지 상관없습니다:\n\n```js\nfunction getPresignedUrl(file: File) {\n  return makeAPIRequest(\n    \"POST\",\n    \"upload/create\",\n    {\n      original_filename: file.name,\n      content_type: file.type,\n    },\n    (response) => response as {\n      key: string;\n      presigned_upload_url: string;\n    },\n  );\n}\n```\n\n그런 다음, XmlHttpRequest를 만들어 파일을 직접 S3로 전송할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n```js\nfunction uploadFile(\n  file: File,\n  presignedUploadUrl: string,\n  onProgress: (pct: number) => void,\n): Promise<void> {\n  return new Promise<void>((resolve, reject) => {\n    const xhr = new XMLHttpRequest();\n    xhr.upload.addEventListener(\"progress\", (e) => {\n      if (e.lengthComputable) {\n        const pct = e.loaded / e.total;\n        onProgress(pct * 100);\n      }\n    });\n    xhr.upload.addEventListener(\"error\", (e) => {\n      reject(new Error(\"Upload failed: \" + e.toString()));\n    });\n    xhr.upload.addEventListener(\"abort\", (e) => {\n      reject(new Error(\"Upload aborted: \" + e.toString()));\n    });\n    xhr.addEventListener(\"load\", (e) => {\n      if (xhr.status === 200) {\n        resolve();\n      } else {\n        reject(new Error(\"Upload failed \" + xhr.status));\n      }\n    });\n    xhr.open(\"PUT\", presignedUploadUrl, true);\n    try {\n      xhr.send(file);\n    } catch (e) {\n      reject(new Error(\"Upload failed: \" + e.toString()));\n    }\n  });\n}\n```\n\nReact Hooks를 사용하는 프로젝트라면 다음과 같이 모두 연결할 수 있습니다:\n\n```js\nexport function useUpload() {\n  const [uploadState, setUploadState] = useState<\n    \"idle\" | \"starting\" | \"uploading\" | \"finishing\" | \"done\" | \"error\"\n  >(\"idle\");\n  const [uploadProgress, setUploadProgress] = useState(0);\n  const [uploadError, setUploadError] = useState<Error | null>(null);\n\n  return {\n    uploadState,\n    uploadProgress,\n    uploadError,\n    upload: async (\n      file: File,\n      onSuccess: (uploadKey: string) => Promise<void>,\n    ) => {\n      setUploadState(\"starting\");\n\n      try {\n        // 백엔드 API에서 사전 서명된 URL 가져오기:\n        const { key, presigned_upload_url } = await getPresignedUrl(\n          file,\n        );\n        setUploadState(\"uploading\");\n        // XmlHttpRequest를 사용하여 실제 업로드:\n        await uploadFile(file, presigned_upload_url, (pct) => {\n          setUploadProgress(pct);\n        });\n        setUploadState(\"finishing\");\n        // 이 업로드된 파일을 유용하게 활용하기; 아마도 이 키를 다른 API 엔드포인트로 전달할 것입니다!\n        await onSuccess(key);\n        setUploadState(\"done\");\n      } catch (e) {\n        setUploadState(\"error\");\n        setUploadError(e);\n      }\n    },\n  };\n}\n```\n\n## 마지막으로: 새로 업로드된 파일 사용하기\n\n\n<div class=\"content-ad\"></div>\n\n업로드가 완료되면 업로드한 S3 키를 API로 전송하여 다른 곳에 저장하거나 원하는 대로 후속 처리할 수 있습니다.\n\n업로드 전용 S3 버킷 내의 경로인 업로드 키를 받는 또 다른 API 엔드포인트를 추가하세요. 그런 다음 파일을 다운로드하여 유효성을 검사하거나 다른 서비스에서 즉시 사용할 수 있도록 다른 버킷으로 복사할 수 있습니다.\n\n(저는 업로드 키에 인증된 사용자 ID를 넣는 것을 좋아합니다. 이렇게 하면 이 엔드포인트 내에서 현재 사용자로부터 업로드된 것인지 확인할 수 있습니다.)\n\n다음은 Python에서 버킷을 공개 서빙 버킷에 복사하는 예시입니다:\n\n<div class=\"content-ad\"></div>\n\n```js\nupload_key = request.validated_data[\"upload_key\"]\next = upload_key.split(\".\")[-1]\nslug = slugify(request.validated_data[\"filename\"])\ndate = datetime.now().strftime(r\"%Y%m%d_%H%M%S\")\npublic_key = f\"media/{request.user.id}/{date}-{slug}.{ext}\"\n\ntry:\n  public_content_s3_client().copy(\n    CopySource={\n      \"Bucket\": \"yourproject-upload\",\n      \"Key\": upload_key,\n    },\n    Bucket=\"yourproject-public\",\n    Key=public_key,\n  )\nexcept Exception:\n  logging.exception(f\"Failed to copy file for user={request.user.id}\")\n```\n\n요렇게 해요. 누군가에겐 도움이 되길 바래요! 혹시 다시 필요하시다면 여기 스크립트 내용이 담긴 gist 링크도 드릴게요. 🥰\n\n의견이나 피드백이 있으시면 언제든지 알려주세요! @taylorhughes\n","ogImage":{"url":"/assets/img/2024-05-27-Simplesecuredirect-to-S3uploadsfrommodernbrowsers_0.png"},"coverImage":"/assets/img/2024-05-27-Simplesecuredirect-to-S3uploadsfrommodernbrowsers_0.png","tag":["Tech"],"readingTime":7},{"title":"NestJS의 비즈니스 로직 조직 이해하기","description":"","date":"2024-05-27 18:47","slug":"2024-05-27-UnderstandingNestJSsBusinessLogicOrganization","content":"\n\n\n![Understanding NestJS's Business Logic Organization](/assets/img/2024-05-27-UnderstandingNestJSsBusinessLogicOrganization_0.png)\n\n전통적인 MVC 아키텍처에서 왔다면 NestJS는 낯설게 느껴질 수 있습니다. 물론, view(사용자 인터페이스) 계층, model(데이터베이스) 계층, 및 controller(비즈니스 로직) 간의 관심사 분리 아이디어는 존재합니다. 그러나 NestJS에서는 파일과 비즈니스 로직을 구조화하기 위한 새로운 흐름을 소개합니다. 라우팅 요청에 대한 컨트롤러, 비즈니스 로직 처리를 위한 서비스, 데이터베이스 조작을 위한 리포지토리의 패턴을 사용합니다. NestJS에서 비즈니스 로직을 어떻게 구성할지 살펴보겠습니다.\n\n## 요청 처리 새로운 방식\n\nNestJS는 구성 기반의 백엔드 프레임워크입니다. JavaScript로 작성되었지만 TypeScript를 사용할 때 가장 빛을 발합니다. 기본 NodeJS와 Express의 Wild West 접근 방식과 Ruby on Rails의 엄격한 규칙 기반 접근 방식과는 다릅니다. NestJS는 애플리케이션 개발을 위한 최상의 관행을 형성하면서도 유연한 디자인을 가능하게 하는 패턴 또는 레시피를 제공합니다.\n\n\n<div class=\"content-ad\"></div>\n\nNestJS 프로젝트의 설정은 모듈의 조율에 중점을 두고 있습니다. 모든 로직은 기능을 제공하거나 사용하는 모듈에 래핑되어 있습니다. 다른 소프트웨어와 마찬가지로 진입점이 있으며 서로 의존하는 웹이 있습니다:\n\n![이미지](/assets/img/2024-05-27-UnderstandingNestJSsBusinessLogicOrganization_1.png)\n\nNestJS는 사용자 요청을 처리하기 위해 서비스와 리포지토리를 모듈 간에 공유하면서 복잡해질 수 있습니다. 단순하게 시작하여 컨트롤러, 서비스 및 리포지토리를 포함하는 격리된 모듈부터 시작하는 것이 좋습니다. 데이터베이스 변경 요청이 NestJS 프로젝트를 통해 어떻게 라우팅되는지 살펴보겠습니다.\n\n## NestJS에서 컨트롤러는 무엇을 하는가?\n\n<div class=\"content-ad\"></div>\n\n모든 것은 컨트롤러에서 시작됩니다. 클래식 MVC 프로젝트에서는 컨트롤러가 프로젝트의 많은 부분을 책임집니다. 뷰는 서버에서 반환된 데이터를 반영합니다. 모델은 데이터 구조를 제공하고 레코드와 관련된 비즈니스 로직을 저장하며, 컨트롤러는 이들 간의 모든 것을 조율합니다.\n\nNestJS에서도 컨트롤러는 일부 비슷한 기능을 가지지만 책임은 훨씬 적습니다. 컨트롤러는 간단히 트래픽 디렉터로 기능하여 어디로 어떻게 전달해야 하는지 확인합니다. 요청 유효성 검사를 위한 파이프나 들어오는 데이터를 형성하고 유효성 검사하기 위한 DTO(데이터 전송 객체)와 같이 더 많은 기능을 추가할 수 있지만, 컨트롤러는 비즈니스 로직을 처리하지 않습니다.\n\nNestJS에서는 컨트롤러의 역할이 요청을 수락하고 일부 유효성 검사를 수행하여 요청과 데이터를 올바른 서비스로 라우트하는 것입니다. 이는 여전히 많은 책임을 요구하지만 다른 프레임워크보다는 적습니다.\n\n![이미지](/assets/img/2024-05-27-UnderstandingNestJSsBusinessLogicOrganization_2.png)\n\n<div class=\"content-ad\"></div>\n\n## NestJS에서 서비스는 무엇을 하는가요?\n\n요청 및 선택적 데이터가 어디로 가는지 알게 되면 비즈니스 로직에 맞게 형태를 변형합니다. 이것이 우리의 서비스 파일이 필요한 이유입니다. NestJS의 서비스는 컨트롤러로부터의 요청에 기반하여 데이터를 생성, 형태를 변형 또는 업데이트하는 로직을 말합니다. 신발을 구매한 사람을 위한 새로운 주문을 생성하거나 사용자의 구식 지불 수단을 제거하는 등의 작업이 일어날 수 있습니다.\n\n무엇을 하든, 서비스에서는 애플리케이션 데이터에 대한 작업을 수행하여 새 상태를 지속할 수 있게 됩니다. 서비스가 데이터를 형태로 만드는 동안, 이 새 상태를 지속하기 위해 데이터베이스와 대화하는 책임은 없습니다. 데이터를 지속시키기 위해서는 저장소가 필요합니다.\n\n## NestJS에서 리포지토리는 무엇을 하는가요?\n\n<div class=\"content-ad\"></div>\n\n저장소는 데이터베이스로의 요청을 처리합니다. 사용자의 요청이 올바른 비즈니스 로직(컨트롤러에 의해)으로 라우팅되고 데이터에 필요한 작업(서비스에 의해)이 수행되면 업데이트된 응용 프로그램 상태를 영속화할 준비가 됩니다.\n\n저장소는 CRU(D) 작업으로 구성되어 있으며 API 클라이언트와 유사한 도구로 볼 수 있습니다. 저장소의 메서드는 데이터베이스에 특정 데이터 레코드를 읽거나 쓰기를 예상합니다. 그게 전부입니다. 이는 다른 접근 방식인 ORM과는 달라요, 여기서 데이터베이스 호출이 서비스에 직접 엮이지 않습니다. 추가 파일이 늘어나는 것은 더 많은 작업이 필요해 보일 수 있지만, 별도의 저장소 파일을 갖는 것은 서비스 또는 앱 사이에서 데이터베이스 작업을 공유하고, 코드를 확장하기 위해 코드를 모듈화하는 데 도움이 됩니다.\n\n## NestJS에 대한 마지막 생각\n\nNestJS는 강력한 백엔드 프레임워크로 API를 빌드하는 프로세스를 가속화합니다. Ruby on Rails 또는 Java 배경에서 오는 것을 배워야 할 내용이 많을 수 있습니다. 다행히 문서는 방대하고 이해하기 쉽습니다. 깨끗하고 일관된 코드를 작성하기 위해 문서를 여러 번 검토하는 것을 강력히 권장합니다.","ogImage":{"url":"/assets/img/2024-05-27-UnderstandingNestJSsBusinessLogicOrganization_0.png"},"coverImage":"/assets/img/2024-05-27-UnderstandingNestJSsBusinessLogicOrganization_0.png","tag":["Tech"],"readingTime":3},{"title":"React에서 부모 컴포넌트에서 자식 함수를 호출하는 방법","description":"","date":"2024-05-27 18:46","slug":"2024-05-27-HowtoCallaChildFunctionfromaParentComponentinReact","content":"\n\n<img src=\"/assets/img/2024-05-27-HowtoCallaChildFunctionfromaParentComponentinReact_0.png\" />\n\nReact에서는 부모 컴포넌트에서 자식 컴포넌트의 메소드를 호출해야 하는 경우가 있습니다. 이를 위해 useImperativeHandle 훅과 useEffect 훅을 사용할 수 있습니다. 이 기사에서는 각 접근 방식을 사용하는 시점과 단계별 지침을 제공하겠습니다.\n\n# 방법 1: useImperativeHandle 훅 사용\n\nuseImperativeHandle 훅은 React에서 그다지 알려지지 않은 훅으로, ref를 사용할 때 부모 컴포넌트에 노출되는 인스턴스 값을 사용자 정의할 수 있습니다. 이 방법은 불필요한 재렌더링을 유발하지 않고 자식 컴포넌트에서 여러 메소드를 직접 호출해야 할 때 권장됩니다.\n\n<div class=\"content-ad\"></div>\n\n- 부모 구성 요소에서 ref를 선언하세요: useRef 훅을 사용하여 부모 구성 요소에 참조를 생성하세요.\n- 참조를 자식 구성 요소로 전달하세요: 참조를 자식 구성 요소에 prop으로 전달하세요.\n- 자식 구성 요소를 forwardRef로 감싸세요: forwardRef 하이어오더 컴포넌트를 사용하여 참조를 자식 구성 요소로 전달하세요.\n- useImperativeHandle로 자식 메소드 정의하기: 자식 구성 요소에서 useImperativeHandle 훅을 사용하여 노출하고자 하는 메소드를 정의하세요.\n\n# 예시 코드\n\n![예시 이미지 1](/assets/img/2024-05-27-HowtoCallaChildFunctionfromaParentComponentinReact_1.png)\n\n![예시 이미지 2](/assets/img/2024-05-27-HowtoCallaChildFunctionfromaParentComponentinReact_2.png)\n\n<div class=\"content-ad\"></div>\n\n# 설명\n\n- 자식 컴포넌트는 부모가 메서드에 액세스할 수 있도록 forwardRef로 래핑됩니다.\n- 자식 컴포넌트 내부에서 useImperativeHandle을 사용하여 부모에 노출할 메서드를 정의합니다.\n- 부모 컴포넌트는 useRef를 사용하여 참조를 생성하고 이를 자식에 전달한 후 이 참조를 통해 자식의 메서드를 호출합니다.\n\n# 방법 2: useEffect Hook 사용\n\n부모 컴포넌트에서 자식의 함수를 호출하는 또 다른 방법은 useEffect 훅을 사용하는 것입니다. 이 접근 방식은 부모에서 사이드 이펙트를 통해 자식 함수를 트리거하는 부모의 상태를 설정하는 것을 포함합니다.\n\n<div class=\"content-ad\"></div>\n\n- 부모 구성 요소의 트리거 상태 선언: 자식 함수를 트리거할 수 있는 부모 구성 요소에 상태를 생성합니다.\n- 자식 구성 요소로 트리거 상태 전달: 이 상태를 자식 구성 요소로 속성(prop)으로 전달합니다.\n- 자식 구성 요소에서 useEffect 사용: 자식 구성 요소에서 useEffect 훅을 사용하여 트리거 상태의 변경을 감시하고 그에 따라 함수를 호출합니다.\n\n# 예시 코드\n\n![image](/assets/img/2024-05-27-HowtoCallaChildFunctionfromaParentComponentinReact_3.png)\n\n![image](/assets/img/2024-05-27-HowtoCallaChildFunctionfromaParentComponentinReact_4.png)\n\n<div class=\"content-ad\"></div>\n\n# 설명\n\n- 상위 컴포넌트는 버튼 클릭시 증가하는 트리거 상태를 유지합니다.\n- 트리거 상태는 자식 컴포넌트에 프롭으로 전달됩니다.\n- 자식 컴포넌트는 useEffect 훅을 사용하여 트리거 상태의 변경을 감지하고 트리거가 변경될 때마다 handleSubmit을 호출합니다.\n\n# 어떤 방법을 사용해야 하나요?\n\n- 상위 컴포넌트에서 자식의 메서드를 직접 호출할 때 이상적입니다.\n- 자식을 다시 렌더링하지 않아도 되는 경우 또는 여러 메서드를 호출해야 할 때 적합합니다.\n\n<div class=\"content-ad\"></div>\n\n- 부모 상태 변경에 따라 자식에서 함수를 트리거하는 데 유용합니다.\n- 상태 변경으로 인해 부작용이 자연스럽게 발생하는 상황에 적합합니다.\n\n# 마지막으로\n\nReact에서 부모 구성 요소에서 자식의 함수를 호출할 때는 useImperativeHandle 또는 useEffect를 사용하여 효율적으로 관리할 수 있습니다. 두 가지 방법 중에서 선택하는 것은 특정 요구 사항과 구성 요소 상호 작용의 복잡성에 달려 있습니다. 이러한 메서드를 이해하고 구현함으로써 React 애플리케이션의 상호 작용성과 유지 관리성을 향상시킬 수 있습니다.\n\n좋은 코딩 되세요! 😎","ogImage":{"url":"/assets/img/2024-05-27-HowtoCallaChildFunctionfromaParentComponentinReact_0.png"},"coverImage":"/assets/img/2024-05-27-HowtoCallaChildFunctionfromaParentComponentinReact_0.png","tag":["Tech"],"readingTime":3},{"title":"웹 개발의 기초 내용들 정리","description":"","date":"2024-05-27 18:45","slug":"2024-05-27-BasicofWebDevelopment","content":"\n\n\n![Basic of Web Development](/assets/img/2024-05-27-BasicofWebDevelopment_0.png)\n\n요즘, 수천 명의 사람들이 온라인으로 일하고 있어. 사람들은 프리랜싱을 선호하고 있어. 급부상하고 있는 분야 중 하나가 웹 개발이야. 소프트웨어 공학 또는 컴퓨터 과학 전공자 뿐만 아니라 많은 비기술적인 사람들도 이 분야로 오고 있어.\n\n거의 모든 브랜드와 심지어 가게들도 웹 사이트를 갖추고 있는데, 그 웹 개발자가 그들을 위해 웹 사이트를 디자인하고 만들어 주는 거야. 이제 어떻게 웹 개발자가 되고 어떻게 시작해야 할지 궁금증이 드는데요?\n\n먼저 사람은 프런트엔드, 백엔드 또는 풀 스택 개발자 가운데 어디로 갈지 결정해야 해. 프런트엔드에 대해 이야기해 보죠.\n\n\n<div class=\"content-ad\"></div>\n\n먼저 HTML (하이퍼텍스트 마크업 언어)를 배우는 것이 첫 단계입니다. 이것은 웹사이트를 구축하는 기본 요소입니다. HTML 없이는 웹사이트를 만들 수 없습니다. HTML을 배우는 것은 정말 쉽습니다. HTML의 모든 태그를 습득하는 데 최대 1주일이 걸릴 것입니다. 제목, 단락, div, span, 테이블, 순서 있는 목록, 순서 없는 목록, 강조 효과, 양식 관련 태그를 배워야 합니다.\n\nHTML을 배운 후에는 CSS (캐스케이딩 스타일 시트)를 배우는 것이 다음 단계입니다. CSS는 HTML을 스타일링하는 것을 의미합니다. CSS를 통해 글꼴 크기, 배경색, 그리드, 테두리 색, 내비게이션 바, 그라데이션, 애니메이션, 버튼, 플렉스박스 등을 변경할 수 있습니다.\n\n마지막 단계는 JavaScript를 배우는 것입니다. JS는 기능을 제공하기 위해 사용됩니다. 이것은 코딩 언어입니다. 변수, 함수, 객체, 배열, 조건문, 반복문, 형 변환, 모듈, JSON 등에 대해 배워야 합니다.\n\n그래서 HTML, CSS 및 JavaScript를 숙달한 후에는 거의 모든 종류의 웹사이트를 만들 수 있습니다. 그러나 부트스트랩, 리액트, 앵귤러, 넥스트.제이에스, 리액트 네이티브와 같은 다른 많은 기술들은 프론트엔드 개발자가 숙달해야 할 것입니다. 이러한 기술을 숙달함으로써 웹 개발자는 소프트웨어 회사나 프리랜서로 일할 수 있으며 상당한 돈을 벌 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n![BasicofWebDevelopment_1](/assets/img/2024-05-27-BasicofWebDevelopment_1.png)","ogImage":{"url":"/assets/img/2024-05-27-BasicofWebDevelopment_0.png"},"coverImage":"/assets/img/2024-05-27-BasicofWebDevelopment_0.png","tag":["Tech"],"readingTime":2},{"title":"CSS에서 rgba 대신 color-mix를 사용해야하는 이유","description":"","date":"2024-05-27 18:44","slug":"2024-05-27-CSSGame-ChangerDitchrgbaforcolor-mix","content":"\n\n아, 당신은 Sass 변수에서 CSS 변수의 반짝이는 세계로 전환한 것인가요? 그런데 rgba() 함수를 사용하는 데 어려움을 겪고 있나요? 걱정 마세요, 혼자가 아니에요!\n\n![image](/assets/img/2024-05-27-CSSGame-ChangerDitchrgbaforcolor-mix_0.png)\n\n제가 아는 것처럼, 한 때 당신이 이렇게 Sass 변수에 의존했던 것처럼 말이에요:\n\n```js\n$primary: #00ccff;\n```\n\n<div class=\"content-ad\"></div>\n\n이제 CSS 변수의 힘을 받았군요:\n\n```js\n:root {\n  --primary : #00ccff;\n}\n```\n\n문제는 Sass를 통해 rgba() 마법을 번역하려는 것입니다:\n\n```js\nbackground-color: rgba($color: $primary, $alpha: 0.6);\n```\n\n<div class=\"content-ad\"></div>\n\n```js\n/* 안돼요, 이건 작동 안 돼요! */\n배경색 : rgba($color: var(--primary), $alpha: 0.6);\n```\n\n허무하죠? 그렇죠? 그럴 준비를 하세요. 왜냐하면 color-mix()가 여러분을 구할 거예요!\n\n## 기다려봐... color-mix()는 지원돼요?\n\n<div class=\"content-ad\"></div>\n\n짧은 대답은 단언컨대 YES입니다! 모던 브라우저(일부 이전 버전 제외)가 모두 지원하고 있습니다. MDN 웹 문서와 caniuse.com에서 지원 세부 정보를 확인해보세요.\n\n![Image 1](/assets/img/2024-05-27-CSSGame-ChangerDitchrgbaforcolor-mix_1.png)\n\n![Image 2](/assets/img/2024-05-27-CSSGame-ChangerDitchrgbaforcolor-mix_2.png)\n\n## 시간이 바꾸는 시간입니다!\n\n<div class=\"content-ad\"></div>\n\ncolor-mix()를 사용하여 rgba()로 익숙한 투명 효과를 복제하는 방법을 살펴보겠습니다.\n\n다음과 같이 작성하던 방식을 이제 안녕하세요라고 말해보세요:\n\n```js\nbackground-color: rgba($color: $primary, $alpha: 0.6);\n```\n\n<div class=\"content-ad\"></div>\n\n```js\nbackground-color: color-mix(in srgb, var(--primary) 60%, transparent);\n```\n\n여기에 대한 설명:\n\n- in srgb: 색 공간을 지정합니다 (sRGB는 웹의 표준입니다).\n- var(--primary): 신뢰할 수 있는 CSS 변수가 섞는 첫 번째 색상입니다.\n- 60%: 이는 혼합물에서 --primary 색상의 백분율을 설정합니다 (알파값 0.6과 동등합니다).\n- transparent: 혼합하는 두 번째 색상입니다 (이것이 투명 효과를 만듭니다).\n\n## color-mix()가 좋은 이유\n\n<div class=\"content-ad\"></div>\n\n- 직관적: 퍼센트 기반 접근 방식으로 투명도 수준을 시각화하는 것이 더 쉬워집니다.\n- 유연: 색상이 아닌 투명도가 있는 색 뿐만 아니라 어떤 두 가지 색도 섞어 사용할 수 있습니다.\n- 강력: 간단한 투명도 이외의 창의적인 색상 혼합 가능성을 열어줍니다.\n\n## 한 번 시도해 보세요!\n\n앞으로 나가서 color-mix()를 실험해보세요. 퍼센트를 조정하고 다양한 색상 조합을 시도해보고 어떤 놀라운 결과를 얻을 수 있는지 확인해보세요. 즐거운 스타일링 되세요!","ogImage":{"url":"/assets/img/2024-05-27-CSSGame-ChangerDitchrgbaforcolor-mix_0.png"},"coverImage":"/assets/img/2024-05-27-CSSGame-ChangerDitchrgbaforcolor-mix_0.png","tag":["Tech"],"readingTime":2},{"title":"리액트 컴파일러와 리액트 18에 대해서 알아보기","description":"","date":"2024-05-27 18:43","slug":"2024-05-27-ReactCompilerWithReact18","content":"\n\n우선, 아니요. React 컴파일러는 React 19의 일부가 아닙니다. React 19는 단순히 React 라이브러리일 뿐입니다. 빌드 변경사항은 없습니다. 따라서 React 컴파일러를 통합하려면 스스로 작업해야 합니다. 또한 React 컴파일러가 선택 사항이라는 것을 의미합니다. 이것이 좋은 점입니다.\n\nReact 19에 대한 포인트를 더 증명하기 위해 React 18 프로젝트에서 React 컴파일러를 사용하는 방법을 보여드릴게요.\n\n![ReactCompilerWithReact18_0](/assets/img/2024-05-27-ReactCompilerWithReact18_0.png)\n\n# 프로젝트 설정\n\n<div class=\"content-ad\"></div>\n\n이 예시에서는 다른 프레임워크와 달리 리액트 19가 아닌 리액트 18.2.0으로 설정되어 있어서 Vite를 사용할 것입니다.\n\n```js\npnpm create vite r18-with-compiler --template react\n```\n\n또한 TypeScript를 사용하지 않기로 했어요. 어떤 타이핑 문제를 피하기 위해서 우리가 생성한 c 훅을 반환하는 배열로 타이핑할 수 있어요.\n\n# 예제 만들기\n\n<div class=\"content-ad\"></div>\n\n컴파일러가 작동하는 방식을 보여주기 위해 최적화되지 않은 버전을 먼저 보여준 다음, 컴파일러를 설치하고 최적화된 버전을 확인해보겠습니다.\n\n다음과 같이 App 컴포넌트를 이 구현으로 대체할 것입니다:\n\n```js\nimport { useState } from \"react\";\n\nfunction Header() {\n  console.log(\"Header\", Math.random());\n  return (\n    <header>\n      <h1>React Counter</h1>\n    </header>\n  );\n}\n\nfunction App() {\n  const [count, setCount] = useState(0);\n\n  return (\n    <>\n      <Header />\n      <div>\n        <p>{count}</p>\n        <button onClick={() => setCount(count + 1)}>Increment</button>\n      </div>\n    </>\n  );\n}\n```\n\n여기에는 간단한 헤더를 표시하는 새로운 Header 컴포넌트와 Header를 사용하고 자체적인 카운터 구현을 갖는 App 컴포넌트가 있습니다.\n\n<div class=\"content-ad\"></div>\n\n최적화되지 않은 React 컴포넌트에서 Header는 매번 App이 버튼을 클릭하여 카운터를 업데이트할 때 다시 렌더링됩니다.\n\n이를 직접 확인하기 위해 응용 프로그램을 시작하고 버튼을 클릭하세요. 클릭할 때마다 Header 컴포넌트에서 console.log를 볼 수 있어야 합니다.\n\n# React 컴파일러를 사용한 최적화\n\nReact 컴파일러는 우리의 App 컴포넌트(사실 Header도)를 최적화하는 방식으로 작동합니다. App에서 Header를 렌더링할 때 Header가 의존하는지 확인합니다. 좋은 소식은, Header가 어느 것에도 의존하지 않습니다. 그래서 Header를 렌더링한 것이 처음이면 마지막이 되어야 합니다. 컴파일러를 사용하는 것이 최적화된 결과입니다.\n\n<div class=\"content-ad\"></div>\n\n잘 작업했다면 버튼을 클릭할 때 Header의 console.log에서 메시지가 표시되지 않을 것을 기대할 수 있습니다. 이는 Header 함수가 호출되지 않기 때문입니다.\n\n먼저 React 컴파일러를 설치해야 합니다:\n\n```js\npnpm add babel-plugin-react-compiler\n```\n\n그런 다음 Vite 구성에서 babel 플러그인을 구성해야 합니다. 제 경우에는 다음과 같이 보입니다:\n\n<div class=\"content-ad\"></div>\n\n```js\nimport { defineConfig } from \"vite\";\nimport react from \"@vitejs/plugin-react\";\nimport path from \"path\";\n\nconst ReactCompilerConfig = {\n  runtimeModule: \"@/mycache\",\n};\n\nexport default defineConfig({\n  resolve: {\n    alias: {\n      \"@\": path.resolve(__dirname, \"./src\"),\n    },\n  },\n  plugins: [\n    react({\n      babel: {\n        plugins: [[\"babel-plugin-react-compiler\", ReactCompilerConfig]],\n      },\n    }),\n  ],\n});\n```\n\n여기에는 두 가지 작업이 진행 중입니다. 무엇보다 defineConfig의 plugins 섹션을 사용하여 React Compiler babel 플러그인을 설치하고 구성하고 있습니다. 그리고 ReactCompilerConfig 객체로 컴파일러를 구성하고 있습니다.\n\n컴파일러 구성에서는 컴파일러가 보통 react-compiler-runtime에서 가져오는 캐시 메모이제이션 훅을 @/mycache에서 가져오도록 지정하고 있습니다.\n\n또한 @ 별칭을 설정하고 소스로 가리키도록해야 합니다. 이렇게 하면 컴포넌트가 위치한 곳과 관계없이 항상 우리의 훅을 찾을 수 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n# 무엇을 다시 하고 있나요?\n\n간단히 다시 돌아가서 무슨 일이 일어나고 있는지 이야기해 봅시다. 여기서 일어나고 있는 것은 React 컴파일러가 memoization을 사용하여 컴포넌트를 최적화한다는 것입니다. 그러나 이를 위해 전통적인 React.memo나 useMemo 또는 useCallback을 사용하는 것이 아닙니다. 대신 새로운 훅을 사용합니다. 해당 훅은 이전에는 useMemoCache로 불리다가 지금은 c로 불립니다. 그리고 react-compiler-runtime 라이브러리에 해당 훅이 내장되어 있습니다.\n\n저는 react-compiler-runtime 라이브러리가 React 19에 의존한다고 확신합니다. 따라서 React 18과 함께 사용하려면 해당 라이브러리에서 c 함수의 직접적인 구현이 필요합니다. 실제로 그 함수는 매우 간단해서 문제가 되지 않습니다. 사실 너무 쉬워서 여기에 구현해 두었습니다:\n\n```js\nimport { useState } from \"react\";\n\nexport function c(size) {\n  return useState(() => new Array(size))[0];\n}\n```\n\n<div class=\"content-ad\"></div>\n\n잠깐만요. 말 그대로 하는 게 없어요. 먼저 사전 할당된 배열의 필요한 크기를 매개변수로 사용하고, 그 크기의 배열이 있는 컴포넌트와 관련된 몇 가지 상태를 반환합니다. 그래서 useState를 사용하여 해당 배열을 만들고 배열만 반환합니다.\n\n실제로 이게 어떻게 작동하는지에 대해 조금 후에 알아보겠습니다. 지금은 src/mycache.js 파일(또는 원하는 곳)에 해당 C 구현을 저장해야 합니다. 그런 다음 어플리케이션을 실행하면, 바로! 버튼을 누르면 Header가 다시 렌더링되지 않습니다. 성공!\n\n# 약간 다른 구현\n\n다른 옵션은 사실상 패키지 관리자를 속여 ./src/mycache가 실제로 react-compiler-runtime 라이브러리라고 생각하게 하는 것입니다. 그래서 package.json 의 종속성에 이 부분을 추가할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n```js\n\"dependencies\": { ..., \"react-compiler-runtime\": \"file:./src/mycache\" }\n```\n\n그러고 나면 Vite 구성에서 ReactCompilerConfig 블록에서 runtimeModule 키를 제거할 수 있습니다.\n\n이것은 공식 폴리필이며 가장 최신 버전은 이 기스트에 있습니다.\n\n# 그래서 왜 이 C 구현이 작동합니까?\n\n<div class=\"content-ad\"></div>\n\n이제 모든 것이 원활히 진행되었으니 이 C 구현을 한 번 더 살펴보고 왜 동작하는지 알아보려고 해봅시다.\n\n```js\nimport { useState } from \"react\";\n\nexport function c(size) {\n  return useState(() => new Array(size))[0];\n}\n```\n\n여기서 상태를 생성하고 그 상태를 반환하고 있습니다. 상태 설정 함수를 반환하지 않고 상태만 반환하고 있으니, 뭔가 이상하죠?\n\n이 컴포넌트를 컴파일해보죠:\n\n<div class=\"content-ad\"></div>\n\n```js\nexport default function Hello() {\n  return <div className=\"foo\">안녕하세요</div>;\n}\n```\n\n위의 코드가 아래와 같이 변합니다:\n\n```js\nimport {c as _c} from \"/src/mycache.js\";\nexport default function Hello() {\n    const $ = _c(2);\n    if ($[0] !== \"a49bfc30998b8cb2...\") {\n        for (let $i = 0; $i < 2; $i += 1) {\n            $[$i] = Symbol.for(\"react.memo_cache_sentinel\");\n        }\n        $[0] = \"a49bfc30998b8cb2...\";\n    }\n    let t0;\n    if ($[1] === Symbol.for(\"react.memo_cache_sentinel\")) {\n        t0 = jsxDEV(\"div\", {\n            className: \"foo\",\n            children: \"안녕하세요\"\n        }, void 0, false, {\n        }, this);\n        $[1] = t0;\n    } else {\n        t0 = $[1];\n    }\n    return t0;\n}\n```\n\n컴파일된 코드의 상단에서 c 훅을 불러오고 최적화된 컴포넌트에서 사용한다는 것을 확인할 수 있습니다. 컴파일러는 초기화된 플래그를 저장하는 데 첫 번째 슬롯, 두 번째 슬롯에는 DOM 트리가 포함된 JSX의 메모이즈된 버전을 저장할 때 두 개의 슬롯만 필요하다는 사실을 알고 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n지금 c 훅이 어떻게 사용되는지 알았으니, 왜 우리의 구현이 작동하는지에 대해 조금 더 이해할 수 있게 되었습니다.\n\n첫째, 우리는 메모이징을 하고 있고, 메모이징을 통해 컴포넌트를 다시 렌더링하게 만들 필요가 없습니다. 그래서 우리는 상태 설정 함수를 호출하지 않는 것입니다. 왜냐하면 그렇게 하면 다시 렌더링이 강제되기 때문입니다.\n\n둘째, 우리는 useState로부터 배열에 대한 참조를 받기 때문에 (그리고 즉, 우리는 배열 내의 데이터를 단순히 배열 요소를 설정함으로써 변경할 수 있습니다) 데이터를 변경할 수 있고, 그 변경 사항은 유지될 것입니다. 왜냐하면 useState는 배열의 내용이 아니라 배열에 대한 참조를 유지하기 때문입니다.\n\n그 두 번째 부분이 여러분을 헷갈리게 한다면, JavaScript 메모리 관리와 참조가 배열 및 객체와 관련하여 작동하는 방식에 대한 이 비디오를 추천합니다.\n\n<div class=\"content-ad\"></div>\n\n# 공식 Polyfill\n\n만약 이를 실제로 적용하고 싶다면 c 함수의 원본 소스를 확인해보세요. 그리고 작업 그룹 기사도 살펴보세요. 이 지침 외에도 공식 Polyfill을 따를 수 있습니다.\n\n# 더 깊게 들어가보기\n\n만약 React 컴파일러와 메모이제이션 작업 방식에 대해 더 자세히 알고 싶다면 제 React 컴파일러 영상을 꼭 시청해보세요.\n\n<div class=\"content-ad\"></div>\n\n이 비디오는 메모이제이션의 메커니즘을 심도 있게 다루어서 React 컴포넌트 코드가 어떻게 변환되고 메모이징되며, 그 메모이제이션의 정밀도를 정말로 이해할 수 있도록 도와줍니다.\n\n## 가능하지만 권장되지 않는 방법\n\n무언가를 할 수 있다고 해서 반드시 해야 한다는 것은 아닙니다. 이 경우에도 그렇게 적용됩니다. React 컴파일러는 실제로 React 19 생태계 내에서 작동하도록 설계되었습니다. 그러므로 오늘 18 버전에서 사용할 수 있다고 해도, 내일 그것이 작동한다는 보장은 없습니다. 간단히 말해서, 사용 시 주의가 필요합니다. 레드 옥토버를 찾아서에서 말하는 대로 \"가능하지만 권장되지 않습니다.\"\n\n## 더욱 심화된 주제\n\n<div class=\"content-ad\"></div>\n\n만약 당신이 이러한 고급 React 주제에 관심이 있다면, 특히 NextJS에 대해, 제 ProNextJS 뉴스레터에 가입해보세요. 그것을 통해 NextJS 상태 관리와 폼 관리에 대한 두 가지 무료 자습서에 액세스 할 수 있습니다. 그리고 ProNextJS 전체 코스가 출시될 때 알림을 받을 수도 있어요! 곧 공개될 예정이에요!","ogImage":{"url":"/assets/img/2024-05-27-ReactCompilerWithReact18_0.png"},"coverImage":"/assets/img/2024-05-27-ReactCompilerWithReact18_0.png","tag":["Tech"],"readingTime":7},{"title":"프로젝트에 Nextjs 14를 더이상 사용하면 안되는 이유","description":"","date":"2024-05-27 18:42","slug":"2024-05-27-StopUsingNextjs14","content":"\n\n\n![Next.js](/assets/img/2024-05-27-StopUsingNextjs14_0.png)\n\nNext.js는 여전히 가장 훌륭한 풀스택 프레임워크 중 하나로 손꼽힙니다.\n\n하지만, 우리에게는 Next.js 버전 14 사용을 중단할 시간이 될 수도 있습니다…\n\n왜냐하면 Next.js 15 릴리스 후보 (RC) 버전이 출시되었기 때문입니다!\n\n\n<div class=\"content-ad\"></div>\n\nNext.js 15 RC에는 많은 흥미로운 새로운 기능이 약속되어 있어요. 오늘은 그 중 4가지를 살펴볼 거에요!\n\n그럼 이제... 바로 시작해 봅시다!\n\n## 1. 부분 사전 렌더링\n\n부분 사전 렌더링 (PPR)은 Next.js 14에서 소개된 특별한 기능으로, 정적 및 동적 페이지 콘텐츠가 완벽하게 공존할 수 있도록 해줘요.\n\n<div class=\"content-ad\"></div>\n\nPPR 작동 방식에 대해 더 알고 싶다면, 이 문서를 자유롭게 확인해 보세요.\n\n하지만 Next.js 15에서는 PPR의 점진적 적용이 마침내 가능해졌습니다!\n\n이는 experimental_ppr 플래그를 true로 설정하여 특정 page.tsx 및 layout.tsx 파일을 PPR에 선택적으로 선택할 수 있다는 의미입니다.\n\n```js\nimport { Suspense } from \"react\"\nimport { StaticComponent, DynamicComponent } from \"@/app/ui\"\n\n// 이 페이지만 PPR로 선택\nexport const experimental_ppr = true\n \nexport default function Page() {\n  return {\n     <>\n      <StaticComponent />\n      <Suspense fallback={...}>\n       <DynamicComponent />\n      </Suspense>\n     </>\n  };\n}\n```\n\n<div class=\"content-ad\"></div>\n\n다음으로 next.config.js 파일에서 experimental.ppr 구성을 'incremental'로 설정하세요:\n\n```js\nconst nextConfig = {\n  experimental: {\n    ppr: 'incremental',\n  },\n};\n\nmodule.exports = nextConfig;\n```\n\n# 2. next/after\n\nnext/after은 응답 스트리밍이 종료된 후 작업을 예약할 수 있는 새로운 API입니다.\n\n<div class=\"content-ad\"></div>\n\n다시 말해, 서버리스 함수가 계산을 마치면, 이제 새로운 after() 함수 내에서 추가 코드를 실행할 수 있습니다.\n\n![이미지](/assets/img/2024-05-27-StopUsingNextjs14_1.png)\n\n이것은 후속 fetch 로깅 및 분석에 매우 유용합니다.\n\n지금 next/after를 사용하려면, next.config.js 파일에 다음과 같이 experimental.after 설정을 추가할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n아래는 Next.js 서버 액션 내에서 `after()` 함수를 사용하는 예시입니다:\n\n```js\n\"use server\"\n\nfunction next_after() {\n  // 여러분의 함수 로직...\n  const something = true\n\n  // 보조 작업 - 데이터가 반환된 후에 데이터를 로깅합니다.\n  after(() => {\n    console.log(something)\n  })\n\n  // 주요 작업 - 데이터를 반환합니다.\n  return something\n}\n```\n\n# 3. 캐싱\n\n<div class=\"content-ad\"></div>\n\nThe Next.js 팀이 우리의 의견을 들어주었어요!\n\n- fetch 요청\n- GET 핸들러\n- 그리고 클라이언트 네비게이션...\n\n기본적으로 더 이상 캐시되지 않아요!\n\n이 변화는 기다리고 있던 변화였고, Next.js 15가 이를 마침내 구현했어요.\n\n<div class=\"content-ad\"></div>\n\n# 4. 리액트 19 지원\n\n공식으로, Next.js 15 RC는 리액트 19 RC와 완벽하게 호환됩니다!\n\n리액트 19 릴리스에 대해 들은 적이 없다면, 여기 리액트의 공식 트윗이 있습니다.\n\n더 알아보기 위해 여기에서 리액트 컨퍼런스 키노트를 시청할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n이 글이 Next.js 14 시대를 떠나 Next.js 15에 흥분하게 만들었으면 좋겠어요.\n\nNext.js 15는 무수히 많은 흥미로운 변화를 가져왔으며, 오늘 우리는 그 중 4가지를 상세히 다뤘습니다.\n\n# 제휴사\n\n<div class=\"content-ad\"></div>\n\n- 올인원 SaaS 프로젝트 템플릿\n- Figma 홈: 제가 모든 프로젝트에서 사용하는 UI 디자인 도구입니다.\n- Figma 프로페셔널: 당신이 필요로 할 유일한 UI 디자인 도구입니다.\n- FigJam: 직관적인 다이어그램 및 브레인스토밍으로 마음을 펼쳐 보세요.\n- 노션: 제 인생 전체를 조직하는 데 사용되는 도구입니다.\n- Notion AI: ChatGPT를 뛰어넘고 노션 워크플로우를 견고하게 만들어 줄 AI 도구입니다.\n\n# 참고 자료\n\n- https://nextjs.org/blog/next-15-rc","ogImage":{"url":"/assets/img/2024-05-27-StopUsingNextjs14_0.png"},"coverImage":"/assets/img/2024-05-27-StopUsingNextjs14_0.png","tag":["Tech"],"readingTime":3},{"title":"파이썬 농업이 최고의 지속 가능한 육식을 제공할 수 있습니다","description":"","date":"2024-05-27 18:40","slug":"2024-05-27-PythonFarmingCouldProvideTheMostSustainableMeatYet","content":"\n\n파이썬을 사육하면 지속 가능한 고기를 제공할 수 있어서 이는 전 세계적인 식량 안보를 지타주는데 도움이 될 수 있습니다. 지구를 위한 더 나은 단백질은 뱀일까요?\n\n이 글은 GrrlScientist의 Forbes 기사에서 제공되었습니다. [링크](LinkTr.ee)\n\n국제 연구팀은 동남 아시아에 위치한 두 상업용 파이썬 농장에서 12개월 동안 연구를 진행한 결과, 뱀들이 닭, 돼지, 소 등과 같은 전통적인 축산 종에 비해 식량을 체중 증가로 효율적으로 전환하는데 놀라울 정도로 좋다는 것을 발견했습니다. 뿐만 아니라, 사육된 파이썬은 불규칙하게 먹여도 빠르게 성장한다는 것이 입증되었습니다.\n\n연구의 주 저자인 파충동물학자 다니엘 나투시는 맥쿼리 대학교 자연과학 연구소 명예 연구원이자 발표문에서 “식량 및 단백질 전환 비율을 고려하면 파이썬은 현재까지 연구된 모든 주류 농가종을 압도한다”고 말했습니다.\n\n<div class=\"content-ad\"></div>\n\n\"우리는 유충이 부화 후 첫 해에 '도축 중량'에 도달하기 위해 빠르게 성장하는 것을 발견했어요.\"\n\nNatusch 박사는 뱀 고기가 흰색이며 단백질 함량이 매우 높다고 지적했습니다.\n\n최근 발표된 연구에서 Natusch 박사와 협업자들은 태국과 베트남에서 상업적으로 양식된 4,600마리의 파이썬을 연구하고 비교하였으며, 서로 다른 급여 방법의 효과를 테스트했습니다. 뱀들은 지역에서 구입한 야생 쥐, 돼지 부산물 및 어류 펠릿 등을 섞어 매주 한 번 급여를 받았으며, 연구 기간 동안 정기적으로 측정 및 체중을 쟀습니다.\n\n![이미지](/assets/img/2024-05-27-PythonFarmingCouldProvideTheMostSustainableMeatYet_0.png)\"\n\n<div class=\"content-ad\"></div>\n\n연구에서 Natusch 박사와 협업자들은 격자 뱀인 Malayopython reticulatus와 파이선인 Python bivittatus가 태어나 첫 해에 빠르게 성장한다는 것을 발견했습니다. 일일 46그램(1.6온스)까지 늘어나며 수컷보다 암컷이 더 높은 성장률을 보였습니다.\n\nNatusch 박사와 협업자들은 파이썬은 4개월 이상 음식 없이도 체중을 크게 잃지 않고, 먹이가 다시 시작되자 빠르게 성장을 재개하여 전통적 가축보다 더 적은 노동력이 필요하며 극단적 날씨 사건 등에 의한 장기적 식량 공급 장애에 쉽게 적응할 수 있다는 것을 밝혔습니다.\n\n\"Natusch 박사는 '양은 매우 적게 먹고 작물을 공격하는 쥐와 기타 해충을 먹는다.\"고 관찰했습니다.\n\n뱀을 결코 강제로 먹이를 먹인 적이 없었다고 Natusch 박사와 협업자들은 말하며, 두 파이썬 종의 성장률은 섭취한 음식의 양에 크게 영향을 받았습니다.\n\n<div class=\"content-ad\"></div>\n\n그들은 극도로 효율적입니다. 그들의 튼튼한 소화 체계는 뼈조차 분해할 수 있을 정도이며, 포유동물보다 거의 물 폐기물이 없고 고체 폐기물도 훨씬 적게 생산합니다.\n\n\"돼지를 기르는 대신 파이썬을 기르는 농부들에게는 명확한 경제적 및 적응성 이점이 있습니다,\"라고 생물학 교수이자 파충류학자인 리처드 샤인(Richard Shine) 교수가 백마리 대학교의 생물학 교수이자 연구 공동 저자로 말했습니다. 샤인 교수의 연구는 특히 파충류를 중심으로 진화와 생태학 사이의 상호작용에 대해 조사합니다.\n\n\"조류와 포유동물은 먹이로부터 얻는 에너지의 약 90%를 단지 일정한 체온을 유지하는 데 사용합니다,\"라고 샤인 교수가 설명했습니다.\n\n\"그러나 파충류와 같은 냉혈동물은 따뜻해지려고 해서 태양 아래에서 한 균을 찾습니다. 그들은 먹이를 살을 더 불고 체조부조직으로 바꾸는 데 있어서 온난한 혈통 생물보다 훨씬 더 효율적입니다.\"\n\n<div class=\"content-ad\"></div>\n\nDr. 나투치 박사와 공동 연구자들은 파이썬이 닭고기, 쇠고기, 돼지고기, 연어를 비롯한 다른 가축보다 적은 양의 사료를 필요로 한다는 것을 발견했습니다. 놀랍게도 귀뚜라미를 비롯한 다른 동물들보다도 더 적은 양의 사료가 필요합니다. 그들은 어린 파이썬에 대한 집중적인 사육이 빠른 성장률을 촉진하면서도 별다른 복지에 미치는 영향이 없다는 것을 발견했습니다. 또한 가축과 특히 소와는 달리 파이썬은 매우 적은 양의 물만 필요합니다.\n\n\"뱀은 최소한의 물만 필요하며 아침에 그들의 비늘에 떨어진 이슬로도 생존할 수 있습니다.\" 라는 나투치 박사의 말씀도 있습니다.\n\n요약하자면, 파이썬은 극히 적은 양의 것을 최대한 활용하는 전문가들입니다.\n\n뱀 고기는 지방이 적고 고품질 단백질이 풍부한 지속 가능한 고기로, 이미 동남아시아와 중국에서 널리 소비되고 있습니다. 사실, 동남아시아 많은 지역에서 그 태의 미각의 대표적인 음식으로 소품됩니다.\n\n<div class=\"content-ad\"></div>\n\n하지만 파이썬 농업은 서양 농업에서 여전히 알려지지 않았어요.\n\n“아시아에서는 대규모의 파이썬 농업이 잘 확립되어 있지만, 주류 농업 과학자들의 주목을 받지 못했습니다,” 라는 내츠치 박사의 말입니다.\n\n파이썬 농업은 현지인 고용 기회를 제공해줍니다.\n\n“우리는 또한 일부 농장이 베이비 파이썬을 현지 마을사람들에게 외주하고 있다는 것을 발견했어요. 이들은 종족들에게 현지 쥐와 남은 음식물을 먹이며, 1년 후에 농장으로 다시 판매하여 추가 수입을 올리는 경우가 많습니다.”\n\n<div class=\"content-ad\"></div>\n\n뱀은 매우 짧은 시간 안에 많은 새끼를 낳을 수 있습니다. 예를 들어, 암컷 파이썬은 1년에 50에서 100개의 알을 낳을 수 있습니다. 이에 비해 암소는 평균 0.8 마리의 새끼를 낳고, 돼지는 동일한 기간 동안 22에서 27마리의 새끼를 낼 수 있습니다 (출처).\n\n\"우리의 연구는 존자료 가축 시스템을 보완하는 파이썬 농업이 전 세계적인 식량 부족에 유연하고 효율적으로 대응할 수 있다는 것을 시사합니다,\" Natusch 박사가 지적했습니다.\n\n가공되면 파이썬의 체중의 약 82%가 고기용 드레스 처리된 시체, 가죽용 귀중한 가죽, 그리고 지방 (뱀오일)과 담낭 (뱀담즙)으로 나오게 되는데, 이 둘은 일부 국가에서 약용으로 사용됩니다.\n\n\"우리는 뱀 농장이 농업 폐기물을 효율적으로 단백질로 전환하면서 상대적으로 적은 폐기물을 생산할 수 있다는 것을 보여줬습니다,\" Natusch 박사가 말했습니다.\n\n<div class=\"content-ad\"></div>\n\n파이썬은 흥미로운 다양한 단백질 소스를 소화할 수 있어요. 이 연구에서 연구팀은 고기와 생선의 부산물로 만든 다른 종류의 '소시지'로 파이썬을 먹였어요. 야생에서는 오직 육식성인 파이썬이지만, 연구팀이 고기에 숨은 10%의 채소 단백질이 포함된 단백질 소시지를 만들면서 놀랍게도 대두 및 기타 채소 단백질도 소화할 수 있다는 것을 밝혀냈어요.\n\n\"자식들이 야채를 먹을 수 있도록 소시지에 브로콜리를 숨기는 것과 비슷하죠.\"\n\nNatusch 박사와 공동 연구자는 혈중 단위로 보았을 때 파충류가 포유류에 비해 훨씬 적은 온실가스를 생산한다고 언급했어요. 기후 변화가 계속 악화되는 가운데, 이 연구자들은 말했습니다.\n\n\"기후 변화, 질병 및 줄어드는 천연자원은 기존 가축과 작물에 압력을 가하고 있고, 이미 단백질 결핍으로 고통받는 저소득 국가 사람들에게 치명적인 영향을 미치고 있어요\"라고 Natusch 박사가 말했습니다.\n\n<div class=\"content-ad\"></div>\n\n전통적인 농업 식품 시스템의 실패로 식량 안보가 널리 퍼지고 있으며, 이는 대체 식품원에 대한 관심을 촉발하고 있다고 그는 덧붙였다.\n\n그러나, 파이썬을 재배하고 섭취하는 것으로 제시된 많은 이점과 혜택에도 불구하고, 미국인, 호주인 및 유럽인들이 털보 동물을 죽이고 먹는 대안으로 이러한 고기를 받아들이기는 어려울 것으로 보인다.\n\n\"내가 생각하기에 최애 식당에서 파이썬 버거를 내놓는 것을 보기까지는 아직 시일이 좀 걸릴 것 같아.\"\n\n# 출처:\n\n<div class=\"content-ad\"></div>\n\nD. Natusch, P. W. Aust, C. Caraguel, P. L. Taggart, V. T. Ngo, G. J. Alexander, R. Shine & T. Coulson (2024). Python farming as a flexible and efficient form of agricultural food security, Scientific Reports 14:5419 | doi:10.1038/s41598-024-54874-4\n\nSocials: Bluesky | CounterSocial | LinkedIn | Mastodon | MeWe | Post.News | Spoutible | SubStack | Tribel | Tumblr | Twitter\n\n원문은 2024 년 3 월 22 일에 Forbes.com에 게시되었습니다.","ogImage":{"url":"/assets/img/2024-05-27-PythonFarmingCouldProvideTheMostSustainableMeatYet_0.png"},"coverImage":"/assets/img/2024-05-27-PythonFarmingCouldProvideTheMostSustainableMeatYet_0.png","tag":["Tech"],"readingTime":5},{"title":"AI와 함께 하는 프로그래밍,  API 호출하기","description":"","date":"2024-05-27 18:37","slug":"2024-05-27-ProgrammingwithAICallingAPIs","content":"\n\n몇 주 전에 AI 프로그래밍 수업을 가르쳐달라는 요청을 받았어요. 그래서 슬라이드와 코드를 열심히 준비했는데, 물질들이 커져갔어요. 그래서 이 모든 자료들을 하나로 모아 시리즈 형식의 글로 만들어보자는 생각이 들었죠. 수업 이후에 이를 참고할 수 있는 사람들이 많을 것이라 생각해요. 또한 이 글들은 세션 이후에도 수업에 도움이 될 수 있는 참고 자료가 될 거예요.\n\n그래서 이 수업의 첫 번째 부분을 공유합니다. 이 부분은 REST API 및 라이브러리를 통해 AI 공급업체 API를 호출하는데 관한 내용입니다.\n\n참고: 이것은 초보자를 위한 자료이므로 제가 생략한 내용이 많습니다. 이는 포괄적인 내용이 아니고 이해를 돕기 위한 것입니다.\n\n![Programming with AI Image](/assets/img/2024-05-27-ProgrammingwithAICallingAPIs_0.png)\n\n<div class=\"content-ad\"></div>\n\n따뜻한 시작부터 시작해봅시다. 그것은 몇 가지 API를 호출하는 것을 의미합니다. AI를 활용하기 위해 API를 호출하는 것은 AI 능력에 가장 흔하고 쉬운 방법이에요. 많은 사람들이 이를 비웃고 \"충분히 AI가 아니다\" 라고 생각하지만, 그건 좀 어리석은 생각이죠 - 시스템의 가치는 사용자에게 기능을 제공하는 것이지 얼마나 많은 AI가 사용되었는지에 달려 있지 않습니다.\n\n현재 OpenAI (GPT), Google (Gemini), Anthropic (Claude), Mistral (Mistral), Cohere (Command) 등 다양한 API 제공업체들이 있어요. 이외에도 Replicate, Anyscale, Modal, Banana 등 다양한 기능을 제공하는 플랫폼 제공자들도 있습니다.\n\n이 글에서는 우리가 REST API를 호출하는 것으로 간단히 시작할 거에요.\n\n# REST APIs\n\n<div class=\"content-ad\"></div>\n\n내가 아는 바에 의하면, 각 제공업체는 REST API를 갖고 있어요. 그들을 호출하는 것은 매우 간단해요. curl과 API URL 엔드포인트 그리고 JSON 페이로드를 전달하기만 하면 돼요.\n\n여기 채팅 완성을 위해 OpenAI API를 호출하는 예시가 있어요.\n\n```js\n$ curl https://api.openai.com/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n  -d '{\n    \"model\": \"gpt-4o\",\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"You are a helpful assistant.\"\n      },\n      {\n        \"role\": \"user\",\n        \"content\": \"Why is the sky blue?\"\n      }\n    ]\n  }'\n```\n\n각 제공업체로부터 유효한 API 키가 필요해요. 대부분의 경우 계정에 가입하고 API 키를 생성하기만 하면 돼요. API 키를 얻었다면 직접 전달하거나 환경 변수로 설정할 수 있어요:\n\n<div class=\"content-ad\"></div>\n\n```js\n$ export OPENAI_API_KEY=<당신의 API 키>\n```\n\nAPI를 호출하면 다음과 같은 결과가 반환되어야 합니다:\n\n```js\n{\n  \"id\": \"chatcmpl-9RWBzicE7v7A1ZRLWUMX3a6zwooWd\",\n  \"object\": \"chat.completion\",\n  \"created\": 1716345631,\n  \"model\": \"gpt-4o-2024-05-13\",\n  \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"Rayleigh 산란이라는 현상으로 인해 하늘은 푸르게 보입니다. 더 자세한 설명은 다음과 같습니다:\\n\\n1. **태양빛 구성**: 태양빛 또는 백색광은 서로 다른 파장을 가진 색 스펙트럼으로 구성되어 있습니다. 가시 스펙트럼은 짧은 파장(파랑과 보라색)에서 긴 파장(빨강과 주황색)까지 범위에 걸쳐 있습니다.\\n\\n2. **대기와의 상호작용**: 태양빛이 지구 대기에 들어오면 분자와 작은 입자와 상호작용합니다. 짧은 파장의 빛(파랑과 보라색)은 이러한 입자에 의해 더 효과적으로 산란되며, 긴 파장(빨강, 주황, 노랑)은 그보다 적게 산란됩니다. \\n\\n3. **인간의 지각**: 보라색 빛은 파랑 빛보다 더 많이 산란되지만, 우리 눈은 파랑 빛에 민감하며, 태양빛에는 처음부터 보라색 빛이 많이 없습니다. 게다가 일부 보라색 빛은 상층 대기에 흡수됩니다. 결과적으로 우리는 하늘을 파랗게 보게 됩니다.\\n\\n4. **결과적인 푸른 하늘**: 산란된 파랑 빛이 각 방향에서 우리 눈에 도달하여, 주로 지면에서 낮에 하늘을 보면 하늘이 파랗게 보입니다.\\n\\n이 산란 효과는 태양이 하늘에 낮게 있을 때 더 명확하게 나타납니다. 그래서 일출과 일몰 시 빨간색 계열을 보게 됩니다. 이러한 경우에는 빛이 더 많은 대기를 통과하면서 파랑과 녹색빛이 더 많이 산란되고, 빨강과 주황색이 하늘을 지배하게 됩니다.\"\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 23,\n    \"completion_tokens\": 286,\n    \"total_tokens\": 309\n  },\n  \"system_fingerprint\": \"fp_729ea513f7\"\n}\n```\n\n아마도 OpenAI가 이러한 API를 처음으로 개발한 것이거나, 더 인기가 많아서 다른 많은 공급자들이 그들의 REST API에서 비슷한 형식을 사용하는 것일 수도 있습니다. 예를 들어, Anthropic의 형식은 다음과 같습니다.\n\n<div class=\"content-ad\"></div>\n\n\n$ curl https://api.anthropic.com/v1/messages \\\n  -H \"content-type: application/json\" \\\n  -H \"x-api-key: $ANTHROPIC_API_KEY\" \\\n  -H \"anthropic-version: 2023-06-01\" \\\n  -d '{\n    \"model\": \"claude-3-opus-20240229\",\n    \"max_tokens\": 1024,\n    \"messages\": [\n        {\"role\": \"user\", \"content\": \"Why is the sky blue?\"}\n    ]\n}'\n\n\n위에서 보듯이, API 키는 다른 헤더를 통해 전달되지만 페이로드는 거의 동일하지만 모델 작동 방식에 따라 약간 차이가 있습니다. 예를 들어, Anthropic에서 메시지의 일부로 시스템 역할 콘텐츠를 전달할 수 없습니다.\n\n또 다른 예시는 Mistral의 것입니다.\n\n\n$ curl https://api.mistral.ai/v1/chat/completions \\\n     --header 'Content-Type: application/json' \\\n     --header 'Accept: application/json' \\\n     --header \"Authorization: Bearer $MISTRAL_API_KEY\" \\\n     --data '{\n    \"model\": \"mistral-large-latest\",\n    \"messages\": [\n     {\n        \"role\": \"user\",\n        \"content\": \"Why is the sky blue?\"\n      }\n    ]\n  }'\n\n\n<div class=\"content-ad\"></div>\n\n그런데, Google은 실제로 API에 대해 약간 다른 방식을 사용하며 API 키를 URL 쿼리의 일부로 전달하고 모델을 URL의 일부로 포함시킵니다. 페이로드도 다르지만 아이디어는 거의 동일합니다.\n\n```js\n$ curl \"https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash-latest:generateContent?key=$API_KEY\" \\\n  -H 'Content-Type: application/json' \\\n  -d '{ \"contents\":[\n    { \"parts\":[{\"text\": \"Why is the sky blue?\"}]}\n  ]\n}'\n```\n\nREST API는 정말 유용하고 거의 보편적입니다. 제공 업체에서 직접 지원하지 않는 언어로 프로그래밍하는 경우 HTTP 클라이언트 라이브러리를 사용하여 REST API를 직접 호출할 수 있습니다. 대부분의 합리적인 프로그래밍 언어에는 표준 라이브러리나 서드 파티 라이브러리에 HTTP 클라이언트 라이브러리가 있으므로 문제 없습니다.\n\n그러나 대부분의 제공 업체는 대부분 Python을 지원하기도 합니다. 그 이유는 대부분의 AI 관련 작업이 Python으로 프로그래밍되기 때문입니다.\n\n<div class=\"content-ad\"></div>\n\n# 파이썬\n\n예를 들어, OpenAI를 호출하는 방법은 이렇습니다. Python 라이브러리를 사용합니다.\n\n```python\nfrom openai import OpenAI\nclient = OpenAI()\n\ncompletion = client.chat.completions.create(\n  model=\"gpt-4o\",\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n    {\"role\": \"user\", \"content\": \"Why is the sky blue?\"}\n  ]\n)\n\nprint(completion.choices[0].message.content)\n```\n\n너무 간단하죠? 클라이언트를 만들 때 매개변수와 옵션을 설정할 수 있지만 그게 전부입니다. API 키를 더 이상 지정할 필요가 없다는 것을 알아채셨을 것입니다. 환경 변수로 API 키를 설정했다면 Python 라이브러리가 해당 환경 변수에서 가져올 거에요.\n\n<div class=\"content-ad\"></div>\n\n안녕하세요! Anthropic과 Mistral도 마찬가지에요.\n\n```js\nimport anthropic\n\nmessage = anthropic.Anthropic().messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1024,\n    messages=[\n        {\"role\": \"user\", \"content\": \"Why is the sky blue?\"}\n    ]\n)\n\nprint(message.content)\n```\n\n프랜들리하게말하자면,\n\n```js\nfrom mistralai.client import MistralClient\nfrom mistralai.models.chat_completion import ChatMessage\n\nclient = MistralClient()\n\nchat_response = client.chat(\n    model=\"mistral-large-latest\",\n    messages=[\n        ChatMessage(role=\"user\", content=\"Why is the sky blue?\")\n    ],\n)\n\nprint(chat_response.choices[0].message.content)\n```\n\n<div class=\"content-ad\"></div>\n\nGoogle의 Python 라이브러리도 사용하기 매우 쉽지만, 다른 라이브러리들과 조금 다릅니다.\n\n```python\nimport google.generativeai as genai\n\nmodel = genai.GenerativeModel('gemini-1.5-flash-latest')\nchat = model.start_chat(history=[])\nresponse = chat.send_message(\"Why is the sky blue?\")\n\nprint(response.text)\n```\n\n파이썬은 매우 잘 지원되고 있는 것을 보실 수 있습니다. 다른 잘 지원되는 언어는 JavaScript입니다.\n\n# Javascript\n\n<div class=\"content-ad\"></div>\n\n파이썬이 가장 잘 지원되는 언어라고 해도, 인기가 많기 때문에 자바스크립트/타입스크립트도 많이 사용됩니다. 자바스크립트와 node.js를 사용하여 OpenAI API에 액세스하는 방법을 살펴봅시다.\n\n```js\nimport OpenAI from \"openai\";\n\nconst openai = new OpenAI();\n\nconst completion = await openai.chat.completions.create({\n  model: \"gpt-4o\",\n  messages: [\n      { role: \"system\", content: \"You are a helpful assistant.\" },\n      { role: \"user\", content: \"Why is the sky blue?\" }\n  ],    \n});\n\nconsole.log(completion.choices[0]);\n```\n\n파이썬 라이브러리에서와 같이 API 키를 더 이상 입력할 필요가 없었습니다. 환경 변수로 API 키를 설정한 경우, 자바스크립트 라이브러리가 환경 변수에서 API 키를 자동으로 인식합니다.\n\n이것이 JSON 결과 출력입니다 (completion.choices[0]만 표시).\n\n<div class=\"content-ad\"></div>\n\nMarkdown 형식으로 표를 변경하려면 다음과 같이 하면 됩니다.\n\n```js\n{\n  index: 0,\n  message: {\n    role: 'assistant',\n    content: \"하늘이 파란 이유는 Rayleigh 산란이라는 현상 때문입니다. 이 산란은 태양광이 지구 대기로 들어와 공기 속 분자와 작은 입자들과 상호 작용할 때 발생합니다.\\n\" +\n      '\\n' +\n      \"하늘이 파란 색으로 보이는 이유를 단계별로 살펴보겠습니다:\\n\" +\n      '\\n' +\n      '1. **태양광 조성**: 태양광 또는 백색광은 여러 색상으로 구성되어 있으며 각각 다른 파장을 가지고 있습니다. 색상은 보라색과 파랑 (파장이 짧은)에서 빨강과 주황 (파장이 긴)까지 이어집니다.\\n' +\n      '\\n' +\n      '2. **산란**: 태양광이 대기를 통과할 때 가스 분자와 작은 입자와 충돌합니다. 빛의 짧은 파장(파랑과 보라색)은 이러한 분자와 입자들에 의해 더 많이 길거나 (빨강과 주황과 같은)보다 더 넓은 범위로 산란됩니다.\\n' +\n      '\\n' +\n      '3. **인간의 지각**: 비록 보라색 빛이 파란 빛보다 더 많이 산란되지만, 우리 눈은 파란 빛에 민감하고 보라색 빛에 덜 민감합니다. 또한 일부의 보라색 빛은 상층 대기에 흡수됩니다. 따라서 우리에게는 하늘이 주로 파란색으로 보입니다.\\n' +\n      '\\n' +\n      '4. **시야각**: 하늘을 올려다볼 때, 우리는 하늘의 모든 부분에서 나오는 이 산란된 파란 빛을 보며 그 특징적인 색상을 부여합니다.\\n' +\n      '\\n' +\n      \"요약하면, 하늘이 파란 이유는 태양광의 짧은 파장인 파란색이 지구 대기의 분자들에 의해 모든 방향으로 더 넓게 산란되고, 우리 눈이 파란색 빛을 보는 데 더 잘 적응되어있기 때문입니다.\"\n  },\n  logprobs: null,\n  finish_reason: 'stop'\n}\n```\n\n마찬가지로, Javascript와 node.js를 사용하여 Anthropic API를 호출하는 방법은 아래와 같습니다.\n\n```js\nimport Anthropic from '@anthropic-ai/sdk';\n\nconst anthropic = new Anthropic();\n\nconst completion = await anthropic.messages.create({\n  model: \"claude-3-haiku-20240307\",\n  max_tokens: 1024,\n  messages: [\n    {\"role\": \"user\", \"content\": \"하늘이 파란 이유는 무엇인가요?\"}\n  ]\n});\n\nconsole.log(completion);\n```\n\n다른 공급자들로는 진행하지 않겠지만, 아이디어를 얻으실 수 있습니다. 공식적으로 지원되는 라이브러리를 사용하시려면 Python 및 Javascript가 좋습니다. REST API 외에도 Python 및 Javascript를 포함한 대부분의 공급자는 다른 언어에 대한 공식 지원이 없지만 Google은 훨씬 더 다양한 언어를 지원합니다.\n\n\n<div class=\"content-ad\"></div>\n\n그러나 다른 언어용 라이브러리가 없는 것은 아닙니다.\n\n# 서드 파티 라이브러리\n\n주변에는 다양한 서드 파티 라이브러리가 있습니다. OpenAI 문서를 살펴보면 대부분의 인기 있는 언어에 대한 서드 파티 라이브러리 지원이 있습니다. 예를 들어, go-openai 패키지를 사용하면 Go에서 OpenAI 라이브러리를 호출할 수 있습니다.\n\n```js\npackage main\n\nimport (\n \"context\"\n \"fmt\"\n \"os\"\n\n openai \"github.com/sashabaranov/go-openai\"\n)\n\nfunc main() {\n client := openai.NewClient(os.Getenv(\"OPENAI_API_KEY\"))\n resp, err := client.CreateChatCompletion(\n  context.Background(),\n  openai.ChatCompletionRequest{\n   Model: openai.GPT4o,\n   Messages: []openai.ChatCompletionMessage{\n    {\n     Role:    openai.ChatMessageRoleUser,\n     Content: \"Why is the sky blue?\",\n    },\n   },\n  },\n )\n\n if err != nil {\n  fmt.Printf(\"ChatCompletion error: %v\\n\", err)\n  return\n }\n\n fmt.Println(resp.Choices[0].Message.Content)\n}\n```\n\n<div class=\"content-ad\"></div>\n\n저기요! 여기 SwiftOpenAI라는 Swift용 써드파티 OpenAI 라이브러리가 있어요. XCode 프로젝트에서 패키지 종속성으로 추가해서 사용할 수 있어요. 이 함수는 OpenAI API를 호출하는 예시에요.\n\n```js\n    func sendMessage() async {\n        let input = userInput.trimmingCharacters(in: .whitespacesAndNewlines)\n        guard !input.isEmpty else { return }\n        \n        let message = Message(content: input, isUser: true)\n        messages.append(message)\n        userInput = \"\"\n        \n        let openAI = SwiftOpenAI(apiKey: Config.openAIKey)\n        let msgs: [MessageChatGPT] = [\n            MessageChatGPT(text: \"You are a helpful assistant.\", role: .system),\n            MessageChatGPT(text: input, role: .user)\n        ]\n        \n        let optionalParameters = ChatCompletionsOptionalParameters(\n            temperature: 0.7,\n            stream: true,\n            maxTokens: 1024\n        )\n        \n        do {\n            let stream = try await openAI.createChatCompletionsStream(\n                model: .gpt4o(.base),\n                messages: msgs,\n                optionalParameters: optionalParameters\n            )\n            \n            let resp = Message(content: \"\", isUser: false)\n            messages.append(resp)\n            \n            for try await response in stream {\n                let content = response.choices[0].delta?.content ?? \"\"\n                if let lastMessage = messages.last, !lastMessage.isUser {\n                    let updatedContent = lastMessage.content + content\n                    messages[messages.count - 1] = Message(content: updatedContent, isUser: false)\n                }\n            }\n        } catch {\n            print(\"Error: \\(error)\")\n            if let lastMessage = messages.last, !lastMessage.isUser {\n                messages[messages.count - 1] = Message(content: \"Cannot get response from OpenAI: \\(error)\", isUser: false)\n            }\n        }\n    }\n```\n\n이 모든 써드파티 라이브러리들은 좋지만 대부분이 한 제공업체만 지원해요. 여러 제공업체에 접근하려면 보통 동시에 몇 개의 라이브러리를 사용하거나 LLM 프레임워크를 시도해볼 수도 있어요.\n\n# LLM 프레임워크\n\n<div class=\"content-ad\"></div>\n\nLLM 프레임워크는 LLM 기반 어플리케이션을 작성할 수 있게 해주는 어플리케이션 프레임워크의 일종입니다. 이러한 프레임워크는 지원과 구조를 제공하며, 일반적으로 LLM 기반 어플리케이션을 작성하는 방법을 표현합니다.\n\n다양한 LLM 프레임워크가 있으며, 그 중에는 공식으로 지원되거나 제3자 라이브러리보다 인기가 있는 것도 있습니다. 이는 이러한 프레임워크가 개발자에게 다양한 능력을 제공하기 때문입니다. 이를 통해 여러 LLM 제공 업체에 동시에 연결하고, 여러 데이터 소스에 연결하며, 기본 LLM 위에 에이전트를 구현할 수 있습니다.\n\nLangchain, LlamaIndex, Haystack 등 여러 프레임워크가 있지만, 이 글에서는 LLM 기반 어플리케이션을 만들기 위한 현재 가장 인기 있는 두 프레임워크인 Langchain과 LlamaIndex에 대해 이야기하겠습니다.\n\n## Langchain 🦜️🔗\n\n<div class=\"content-ad\"></div>\n\n가장 인기 있는 프레임워크는 아마도 Langchain일 것입니다. Langchain은 2022년 10월에 처음 릴리스되었으며 그 이후로 급속하게 발전하여 LLM 세계의 거의 모든 것을 다루는데 이르렀습니다. 현재 시점에서 거의 400개의 릴리스에 이를 정도로 성장했습니다. 한 때 릴리스는 거의 매일 발생했으며 가끔은 하루에 두 번씩 이루어졌습니다!\n\n지난 1년 동안 Langchain은 비교적 단순한 Python 라이브러리에서 핵심 라이브러리부터 배포 서버, 관측성 도구 세트까지의 기능 생태계로 성장했습니다.\n\n이제 Langchain을 사용하여 OpenAI에 연결하고 그 채팅 API를 호출하는 방법에 대해 간단히 설명해드리겠습니다.\n\n```js\nfrom langchain_openai import ChatOpenAI\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.output_parsers import StrOutputParser\n\nllm = ChatOpenAI(model_name=\"gpt-4o\")\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"You are a helpful assistant.\"),\n    (\"user\", \"{input}\")\n])\noutput_parser = StrOutputParser()\n\nchain = prompt | llm | output_parser\nresults = chain.invoke({\"input\": \"why is the sky blue?\"})\n\nprint(results)\n```\n\n<div class=\"content-ad\"></div>\n\n코드를 한눈에 보면 그리 다른 것 같지는 않지만, 챗 프롬프트, LLM 및 출력 파서를 연결하여 결과를 생성했음을 알아차릴 수도 있을 것입니다. 이것은 Langchain의 더 강력한 기능 중 하나의 예시이며, Langchain에 이름을 부여한 것 중 하나인 연쇄입니다.\n\n연쇄는 서로 연결된 호출의 일련이다. 연쇄는 Langchain 표현 언어(LCEL)를 사용하여 생성되며, 가장 기본적인 연쇄는 위에서 보여진 것과 같습니다:\n\n```js\nchain = prompt | llm | output_parser\n```\n\n연쇄를 실행하기 위해, 우리는 연쇄에 대해 몇 가지 메서드 중 하나를 호출하면 됩니다(위의 코드의 경우 invoke를 사용했습니다). 적절한 입력을 사용하여 호출하면 결과를 얻을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Programming with AI: Calling APIs](/assets/img/2024-05-27-ProgrammingwithAICallingAPIs_1.png)\n\n체인은 강력하고 구성 가능합니다. 컨텍스트와 함께 질문을 LLM에 전달하여 간단한 검색 증강 생성(RAG)을 수행하는 방법을 살펴보겠습니다.\n\n이 경우 싱가포르의 통신 및 정보부 (MCI) 위원회 공급위원회에 대한 2024년 1월의 국회 회의록 텍스트 문서를 사용합니다. 해당 사이트에서 텍스트를 가져와 hansard.txt라는 텍스트 파일로 저장했습니다.\n\n```js\nfrom langchain_community.vectorstores import DocArrayInMemorySearch\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain_core.runnables import RunnableParallel, RunnablePassthrough\nfrom langchain_openai import OpenAIEmbeddings\nfrom langchain_openai import ChatOpenAI\n\ndef extract(file_path):\n    with open(file_path, 'r') as file:\n        return [line.strip() for line in file if line.strip()]\n\nmodel = ChatOpenAI(model=\"gpt-4o\")\nvectorstore = DocArrayInMemorySearch.from_texts(\n    texts=extract('data/hansard.txt'),\n    embedding=OpenAIEmbeddings(),\n)\nretriever = vectorstore.as_retriever()\ntemplate = \"\"\"다음 컨텍스트를 기반으로 질문에 답하십시오:\n{context}\n\n질문: {question}\n\"\"\"\nprompt = ChatPromptTemplate.from_template(template)\noutput_parser = StrOutputParser()\nsetup_and_retrieval = RunnableParallel(\n    {\"context\": retriever, \"question\": RunnablePassthrough()}\n)\nchain = setup_and_retrieval | prompt | model | output_parser\n\nresults = chain.invoke(\"스마트 네이션은 어떻게 시민들의 삶을 개선했습니까?\")\nprint(results)\n```\n\n\n<div class=\"content-ad\"></div>\n\n위의 코드에서는 먼저 hansard.txt 문서의 각 줄에서 인메모리 벡터 저장소를 만들고 OpenAI의 임베딩을 사용합니다. 벡터 저장소로부터 리트리버를 생성하여 프롬프트에 입력으로 적합한 줄을 가져올 수 있습니다.\n\n이제 사용자의 입력이 주어지면, 해당 입력을 리트리버에 전달하여 벡터 저장소에서 줄들을 가져올 수 있습니다. 사용자 입력은 또한 프롬프트로 전달됩니다. RunnableParallel을 통해 동시에 이 두 가지가 실행되고, 출력은 질문과 문맥으로 프롬프트로 전송됩니다.\n\n<img src=\"/assets/img/2024-05-27-ProgrammingwithAICallingAPIs_2.png\" />\n\n나머지 부분은 거의 동일하지만 여기에 출력이 있습니다.\n\n<div class=\"content-ad\"></div>\n\n```python\n% python langchain_test_rag.py\n싱가포르의 스마트 네이션 이니셔티브는 2014년부터 2023년까지 정부 서비스에 대한 만족도를 73%에서 83%로 높여 시민들의 삶을 개선했습니다. 뿐만 아니라, 싱가포르인의 84%가 디지털 기술이 그들의 삶을 더 편하게 만들었다고 느끼고 있습니다. 이 이니셔티브는 일상적인 편의성과 삶의 질을 향상시키고, 사람들이 더 의미 있는 삶을 살도록 돕고, 누구도 뒤처지지 않도록 하는 것을 목표로 합니다.\n```\n\n여러분이 보실 수 있듯이, 체인은 강력한 메커니즘입니다. 이 체인 메커니즘은 Langchain에만 해당하는 것은 아닙니다. Haystack 프레임워크는 파이프라인이라고 부르며, LLMFlows와 같은 몇 개의 다른 프레임워크는 플로우라고 합니다.\n\n## LlamaIndex\n\n다른 인기 있는 LLM 프레임워크인 LlamaIndex가 있습니다. LlamaIndex는 2022년 11월에 GPTIndex라는 이름의 프레임워크로 시작되었습니다. LlamaIndex의 기본 개념은 LLM을 데이터에 연결하는 것입니다. 실제로 LlamaIndex와 Langchain은 거의 동시에 시작되었다는 것에 주목할 수 있습니다. 사실, Langchain의 창시자인 해리슨 체이스와 LlamaIndex의 창시자인 제리 류는 인공 지능 보안 회사인 Robust Intelligence에서 동료였습니다.\n\n\n<div class=\"content-ad\"></div>\n\n빠른 대화 완성을 위해 LlamaIndex 사용 방법을 간단히 살펴봅시다.\n\n```js\nfrom llama_index.core import Settings\nfrom llama_index.core.llms import ChatMessage\nfrom llama_index.llms.openai import OpenAI\n\nSettings.llm = OpenAI(model=\"gpt-4o\")\nmessages = [\n    ChatMessage(\n        role=\"system\", content=\"You are a helpful assistant.\"\n    ),\n    ChatMessage(role=\"user\", content=\"Why is the sky blue?\"),\n]\nresp = OpenAI().chat(messages)\nprint(resp)\n```\n\n보시다시피, Langchain이나 기타 API와 크게 다르지 않지만 LlamaIndex의 장점은 데이터와의 연결에 중점을 둔다는 점입니다. 예상대로, 간단한 RAG를 수행하는 코드는 매우 간단합니다.\n\n```js\nfrom llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader\nfrom llama_index.llms.openai import OpenAI\n\nSettings.llm = OpenAI(model=\"gpt-4o\")\n\ndocuments = SimpleDirectoryReader(\"data\").load_data()\nindex = VectorStoreIndex.from_documents(documents)\nquery_engine = index.as_query_engine()\nresponse = query_engine.query(\"How has Smart Nation improved citizen's lives?\")\nprint(response)\n```\n\n<div class=\"content-ad\"></div>\n\n먼저, 데이터 디렉토리(즉, 우리의 hansard.txt 파일)에서 파일을 가져와서 벡터 저장소에 저장합니다. 그런 다음 해당 벡터 저장소를 쿼리 엔진으로 사용하여 쿼리를 보내면 문서에서 데이터를 사용하여 응답을 형성할 것입니다.\n\nLangchain과 LlamaIndex는 진화의 급격한 속도 이후 강력한 프레임워크입니다. 각각의 강점이 있으며 현재 시점에서는 주로 개인적인 선호에 따라 사용하는 것이 대부분입니다.\n\n# 요약\n\nAI 프로그래밍에 대한 수업의 첫 번째 부분입니다. 다음 글에서는 지역 LLM에 대해 더 깊이 알아볼 것입니다. 즉, 자신의 기기에 배포할 수 있는 LLM에 대해 다뤄볼 것입니다. 예를 들어, 자신의 노트북에도 배포할 수 있는 LLM입니다.","ogImage":{"url":"/assets/img/2024-05-27-ProgrammingwithAICallingAPIs_0.png"},"coverImage":"/assets/img/2024-05-27-ProgrammingwithAICallingAPIs_0.png","tag":["Tech"],"readingTime":17},{"title":"파이썬과 Redpanda를 사용하여 실시간 센서 데이터 집계하기","description":"","date":"2024-05-27 18:35","slug":"2024-05-27-AggregatingReal-timeSensorDatawithPythonandRedpanda","content":"\n\n## 간단한 Python을 사용한 스트림 처리 및 tumbling windows\n\n![이미지](/assets/img/2024-05-27-AggregatingReal-timeSensorDatawithPythonandRedpanda_0.png)\n\n이 튜토리얼에서는 Python(및 메시지 브로커로 Redpanda)만 사용하여 센서 데이터 스트림을 다운샘플링하는 방법을 보여드리고 싶습니다. 목표는 스트림 처리가 얼마나 간단할 수 있는지를 보여주는 것이며, 시작하기 위해 무겁고 복잡한 스트림 처리 프레임워크가 필요하지 않다는 것을 보여주고 싶습니다.\n\n최근까지 스트림 처리는 일반적으로 Java 전문 지식이 필요했던 복잡한 작업이었습니다. 그러나 Python 스트림 처리 생태계가 점차 성숙해지면서 Faust, Bytewax 및 Quix와 같은 Python 개발자에게 더 많은 옵션이 있어졌습니다. 나중에는 이러한 라이브러리가 기존의 Java 중심 옵션과 경쟁하기 위해 등장한 이유에 대해 조금 더 배경을 제공할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n하지만 먼저 일을 시작해 보겠습니다. 우리는 스트림 프로세서로 Quix Streams 라이브러리를 사용할 것입니다. Quix Streams는 Faust와 매우 유사하지만 구문이 더 간결하고 StreamingDataframes라는 Pandas와 유사한 API를 사용하도록 최적화되었습니다.\n\n다음 명령어로 Quix Streams 라이브러리를 설치할 수 있습니다:\n\n```js\npip install quixstreams\n```\n\n무엇을 구축할 것인가\n\n<div class=\"content-ad\"></div>\n\n간단한 애플리케이션을 개발하게 될 거에요. 이 애플리케이션은 다양한 센서에서 수신되는 온도 측정값의 롤링 집계를 계산할 거예요. 온도 측정값은 비교적 높은 빈도로 들어오며, 이 애플리케이션은 이를 집계하여 낮은 시간 해상도(10초마다)로 출력할 거에요. 너무 높은 해상도의 데이터로 작업하고 싶지 않아서 이를 압축한 것으로 생각할 수 있어요.\n\n이 GitHub 저장소에서 완성된 코드에 접근할 수 있어요.\n\n이 애플리케이션에는 합성 센서 데이터를 생성하는 코드가 포함되어 있지만, 실제 시나리오에서 이 데이터는 차량 편대나 기계가 가득한 창고와 같은 다양한 종류의 센서에서 나올 수 있어요.\n\n기본 아키텍처의 개략적인 그림을 아래에서 확인할 수 있어요:\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-27-AggregatingReal-timeSensorDatawithPythonandRedpanda_1.png\" />\n\n# 스트림 처리 파이프라인의 구성 요소\n\n이전 다이어그램은 스트림 처리 파이프라인의 주요 구성 요소를 나타냅니다. 데이터 생산자인 센서, 스트리밍 데이터 플랫폼으로 Redpanda, 그리고 스트림 프로세서인 Quix가 있습니다.\n\n데이터 생산자\n\n<div class=\"content-ad\"></div>\n\n이 코드 조각들은 ECU(Engine Control Units)의 펌웨어, 클라우드 플랫폼의 모니터링 모듈 또는 사용자 활동을 기록하는 웹 서버와 같은 데이터를 생성하는 시스템에 연결되어 있습니다. 이러한 코드는 원시 데이터를 가져와 해당 플랫폼이 이해할 수 있는 형식으로 스트리밍 데이터 플랫폼으로 보냅니다.\n\n스트리밍 데이터 플랫폼\n\n여기서는 스트리밍 데이터를 저장합니다. 정적 데이터에 대한 데이터베이스가 하는 역할과 거의 동일한 역할을 합니다. 그러나 테이블 대신 토픽을 사용합니다. 그렇지 않으면 정적 데이터베이스와 유사한 기능을 갖추고 있습니다. 데이터를 소비하고 생성할 수 있는 사용자, 데이터가 준수해야 하는 스키마 등을 관리해야 합니다. 그러나 데이터베이스와는 달리 데이터가 끊임없이 변하기 때문에 쿼리할 목적으로 설계되지 않습니다. 일반적으로 데이터를 변환하고 데이터 과학자가 탐색할 수 있는 데 옮기거나 RisingWave나 Apache Pinot과 같은 스트리밍 데이터에 최적화된 쿼리 가능 시스템에 원시 데이터를 넣기 위해 스트림 프로세서를 사용합니다. 그러나 스트리밍 데이터의 패턴에 의해 트리거된 자동화 시스템(추천 엔진과 같은)의 경우에는 이것이 이상적인 해결책이 아닙니다. 이 경우 전용 스트림 프로세서를 사용하는 것이 확실합니다.\n\n스트림 프로세서\n\n<div class=\"content-ad\"></div>\n\n이러한 엔진들은 데이터가 도착하는 대로 계속적으로 작업을 수행하는 엔진들입니다. 이들은 어플리케이션 백엔드에서 데이터를 처리하는 일반적인 마이크로서비스들과 비교될 수 있습니다. 하지만 한 가지 큰 차이가 있습니다. 마이크로서비스의 경우 데이터가 비아주로 도착하며, 각 \"물방울\"이 개별적으로 처리됩니다. 비가 많이 내려도 서비스가 \"물방울\"을 넘치지 않고 따라잡는 것은 그리 어렵지 않습니다 (물에서 불순물을 거르는 필터 시스템을 생각해보세요).\n\n스트림 프로세서의 경우 데이터가 연속적이고 넓은 물줄기로 도착합니다. 필터 시스템은 빠르게 압도되며 디자인을 변경하지 않는 이상 물줄기를 분할하고 작은 스트림을 여러 필터 시스템으로 보내야 합니다. 이것이 바로 스트림 프로세서가 작동하는 방식입니다. 그들은 수평적으로 확장 가능하게 설계되어 있으며 병렬로 작동하고 있습니다. 그리고 절대 멈추지 않고 계속해서 데이터를 처리하며, 걸러진 데이터를 스트리밍 데이터 플랫폼에 출력하는데, 이것은 스트리밍 데이터의 저장지 역할을 합니다. 조금 더 복잡하게 만들기 위해, 스트림 프로세서들은 종종 여기서 시도해볼 창 기능 예제와 같이 이전에 받았던 데이터를 추적해야 할 수도 있습니다.\n\n또한 \"데이터 컨슈머\"와 \"데이터 싱크\"라는 것도 있습니다. 처리된 데이터를 사용하는 시스템(프론트엔드 어플리케이션 및 모바일 앱과 같은)이나 오프라인 분석을 위해 데이터를 저장하는 시스템(스노우플레이크나 AWS 레드시프트와 같은 데이터 웨어하우스)이 있습니다. 이 튜토리얼에서는 이들을 다루지 않을 것이므로 일단은 생략하겠습니다.\n\n# 로컬 스트리밍 데이터 클러스터 설정하기\n\n<div class=\"content-ad\"></div>\n\n이 튜토리얼에서는 로컬 설치된 Redpanda를 활용하여 스트리밍 데이터를 관리하는 방법을 보여드릴 거에요. Redpanda를 선택한 이유는 로컬에서 쉽게 실행할 수 있기 때문이에요.\n\n먼저 도커 컴포즈를 사용하여 Redpanda 콘솔을 포함한 클러스터를 빠르게 생성할 거에요. 그러니 먼저 도커를 설치해야 해요.\n\n# 스트리밍 애플리케이션 생성\n\n먼저 스트리밍 데이터를 생성하고 처리할 개별 파일을 만들 거에요. 이렇게 하면 실행 중인 프로세스를 독립적으로 관리하기 쉬워져요. 즉, 프로듀서를 중지하더라도 스트림 프로세서를 중지하지 않아도 되요. 이제 만들 파일의 개요를 살펴보겠어요:\n\n<div class=\"content-ad\"></div>\n\n- 스트림 프로듀서: sensor_stream_producer.py\n가상 온도 데이터를 생성하고 해당 데이터를 Redpanda의 \"raw data\" 소스 토픽에 씁니다. Faust 예제와 마찬가지로 약 5초마다 약 20개의 측정 값을 생성하거나 초당 약 4개의 측정 값을 생성합니다.\n- 스트림 프로세서: sensor_stream_processor.py\n\"source\" 토픽에서 원시 온도 데이터를 소비하고 데이터의 해상도를 줄이기 위해 텀블링 윈도우 계산을 수행합니다. 10초 간격의 창에서 받은 데이터의 평균 값을 계산하여 각 10초마다 한 번의 측정 값을 얻습니다. 그런 다음 이 집계된 측정 값을 Redpanda의 agg-temperatures 토픽에 생성합니다.\n\n스트림 프로세서가 대부분의 작업을 처리하고이 튜토리얼의 핵심입니다. 스트림 프로듀서는 적절한 데이터 수집 프로세스의 대리인입니다. 예를 들어, 프로덕션 시나리오에서는 MQTT 커넥터와 같은 것을 사용하여 센서에서 데이터를 가져와 토픽에 생성할 수 있습니다.\n\n- 간단한 예제를 위해 데이터를 시뮬레이션하는 것이 더 간단하므로 먼저 설정해 봅시다.\n\n# 스트림 프로듀서 생성\n\n<div class=\"content-ad\"></div>\n\n새로운 파일인 sensor_stream_producer.py를 생성하고 주요 Quix 애플리케이션을 정의하세요. (이 예제는 Python 3.10에서 개발되었지만, Python 3의 다른 버전도 pip install quixstreams을 실행할 수 있다면 작동해야 합니다.)\n\nsensor_stream_producer.py 파일을 만들고 필요한 종속 항목(Quix Streams 포함)을 모두 추가하세요.\n\n```python\nfrom dataclasses import dataclass, asdict # 데이터 스키마를 정의하는 데 사용됩니다.\nfrom datetime import datetime # 타임스탬프를 관리하는 데 사용됩니다.\nfrom time import sleep # 데이터 생성기를 느리게 만드는 데 사용됩니다.\nimport uuid # 메시지 ID 생성에 사용됩니다.\nimport json # 데이터 직렬화에 사용됩니다.\n\nfrom quixstreams import Application\n```\n\n그런 다음, Quix 애플리케이션 및 데이터를 보낼 대상 토픽을 정의하세요.\n\n<div class=\"content-ad\"></div>\n\n```python\napp = Application(broker_address='localhost:19092')\n\ndestination_topic = app.topic(name='raw-temp-data', value_serializer=\"json\")\n```\n\n`value_serializer` 매개변수는 예상 소스 데이터의 형식을 정의합니다 (바이트로 직렬화될 데이터). 이 경우 JSON을 보낼 것입니다.\n\n온도 데이터에 대한 매우 기본적인 스키마를 정의하고 JSON으로 직렬화하는 함수를 추가하기 위해 dataclass 모듈을 사용해봅시다.\n\n```python\n@dataclass\nclass Temperature:\n    ts: datetime\n    value: int\n\n    def to_json(self):\n        # 데이터 클래스를 사전으로 변환\n        data = asdict(self)\n        # datetime 객체를 문자열로 변환\n        data['ts'] = self.ts.isoformat()\n        # 사전을 JSON 문자열로 직렬화\n        return json.dumps(data)\n```\n\n<div class=\"content-ad\"></div>\n\n다음으로, 가짜 온도 센서 데이터를 Redpanda 소스 토픽으로 보내는 코드를 추가해보세요.\n\n```js\ni = 0\nwith app.get_producer() as producer:\n    while i < 10000:\n        sensor_id = random.choice([\"Sensor1\", \"Sensor2\", \"Sensor3\", \"Sensor4\", \"Sensor5\"])\n        temperature = Temperature(datetime.now(), random.randint(0, 100))\n        value = temperature.to_json()\n\n        print(f\"생성된 값 {value}\")\n        serialized = destination_topic.serialize(\n            key=sensor_id, value=value, headers={\"uuid\": str(uuid.uuid4())}\n        )\n        producer.produce(\n            topic=destination_topic.name,\n            headers=serialized.headers,\n            key=serialized.key,\n            value=serialized.value,\n        )\n        i += 1\n        sleep(random.randint(0, 1000) / 1000)\n```\n\n이 코드는 0부터 1초 사이의 랜덤한 시간 간격으로 분리된 1000개의 레코드를 생성합니다. 또한 5가지 옵션 중에서 센서 이름을 무작위로 선택합니다.\n\n이제 명령줄에서 다음을 실행하여 프로듀서를 테스트해보세요.\n\n<div class=\"content-ad\"></div>\n\n```js\npython sensor_stream_producer.py\n```\n\n이렇게 로되 데이터를 콘솔에 확인할 수 있어요:\n\n```js\n[데이터 생성됨]\n```\n\n작동하는 것을 확인하면 일단 프로세스를 중지해주세요 (나중에 스트림 처리 프로세스와 함께 실행할 거에요).\n\n\n<div class=\"content-ad\"></div>\n\n# 스트림 프로세서 생성\n\n스트림 프로세서는 세 가지 주요 작업을 수행합니다: 1) 소스 토픽에서 원시 온도 데이터를 소비, 2) 데이터를 지속적으로 집계하고, 3) 집계된 결과를 싱크 토픽으로 전송합니다.\n\n각 작업에 대한 코드를 추가해 보겠습니다. IDE에서 sensor_stream_processor.py라는 새 파일을 만들어 주세요.\n\n먼저, 이전과 같이 종속성을 추가해주세요:\n\n<div class=\"content-ad\"></div>\n\n```js\nimport os\nimport random\nimport json\nfrom datetime import datetime, timedelta\nfrom dataclasses import dataclass\nimport logging\nfrom quixstreams import Application\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n```\n\n그리고 스트림 처리 응용 프로그램에서 필요한 몇 가지 변수를 설정해보겠습니다:\n\n```js\nTOPIC = \"raw-temperature\" # 입력 토픽을 정의합니다\nSINK = \"agg-temperature\"  # 출력 토픽을 정의합니다\nWINDOW = 10  # 시간 창의 길이를 초 단위로 정의합니다\nWINDOW_EXPIRES = 1 # 데이터가 창에서 제외되기 전에 도착할 수 있는 시간을 초 단위로 정의합니다\n```\n\n나중에 창 변수가 무엇을 의미하는지 자세히 살펴보겠지만, 지금은 주요 Quix 애플리케이션을 정의하는 데 집중해 보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\napp = Application(\n    broker_address='localhost:19092',\n    consumer_group=\"quix-stream-processor\",\n    auto_offset_reset=\"earliest\",\n)\n```\n\n지금은 몇 가지 더 많은 애플리케이션 변수들이 있는데요, consumer_group와 auto_offset_reset이 그 중 일부에요. 이러한 설정 사이의 상호작용에 대해 더 알아보려면 \"카프카의 auto offset reset 구성 이해: 사용 사례 및 함정\"이라는 기사를 확인해 보세요.\n\n다음으로, 코어 스트림 처리 함수의 양쪽에 입력 및 출력 토픽을 정의하고, 들어오는 데이터를 DataFrame에 넣는 함수를 추가하세요.\n\n```js\ninput_topic = app.topic(TOPIC, value_deserializer=\"json\")\noutput_topic = app.topic(SINK, value_serializer=\"json\")\n\nsdf = app.dataframe(input_topic)\nsdf = sdf.update(lambda value: logger.info(f\"Input value received: {value}\"))\n```\n\n<div class=\"content-ad\"></div>\n\n우리는 들어오는 데이터가 손상되지 않았는지 확인하기 위해 로깅 라인을 추가했습니다.\n\n다음으로, 메시지 페이로드에서 Kafka 타임스탬프 대신 사용할 사용자 정의 타임스탬프 추출기를 추가해봅시다. 집계를 위해 이것은 기본적으로 읽기가 생성된 시간을 사용하고 Redpanda가 수신한 시간이 아닌 것을 의미합니다. 더 간단하게 설명하면 \"Redpanda의 수신된 시간이 아닌 센서의 시간 정의를 사용하세요\".\n\n```js\ndef custom_ts_extractor(value):\n \n    # 센서의 타임스탬프를 추출하여 datetime 객체로 변환\n    dt_obj = datetime.strptime(value[\"ts\"], \"%Y-%m-%dT%H:%M:%S.%f\") # \n\n    # 효율적인 Quix 처리를 위해 Unix epoch부터의 밀리초로 변환\n    milliseconds = int(dt_obj.timestamp() * 1000)\n    value[\"timestamp\"] = milliseconds\n    logger.info(f\"새로운 타임스탬프 값: {value['timestamp']}\")\n\n    return value[\"timestamp\"]\n\n# 이전에 정의된 input_topic 변수를 덮어쓰어 사용자 정의 타임스탬프 추출기를 사용하도록 설정\ninput_topic = app.topic(TOPIC, timestamp_extractor=custom_ts_extractor, value_deserializer=\"json\") \n```\n\n왜 이렇게 하는 걸까요? 처리에 사용할 시간에 대해 철학적인 논쟁으로 빠져들 수 있겠지만, 그건 다른 기사의 주제입니다. 사용자 정의 타임스탬프로 하고자 한 것은 실시간 처리에서 시간을 해석하는 다양한 방법이 있고, 데이터 도착 시간을 반드시 사용할 필요는 없다는 것을 보여주고 싶었습니다.\n\n<div class=\"content-ad\"></div>\n\n새 창이 시작될 때 집계를 위한 상태를 초기화하세요. 창에 첫 번째 레코드가 도착할 때 집계를 준비합니다.\n\n```js\ndef initializer(value: dict) -> dict:\n\n    value_dict = json.loads(value)\n    return {\n        'count': 1,\n        'min': value_dict['value'],\n        'max': value_dict['value'],\n        'mean': value_dict['value'],\n    }\n```\n\n이것은 창을 위한 초기 값들을 설정합니다. 최솟값, 최댓값 및 평균의 경우, 처음의 센서 리딩을 시작점으로 삼기 때문에 모두 동일합니다.\n\n이제 \"리듀서\" 함수 형태로 집계 로직을 추가해보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n\ndef reducer(aggregated: dict, value: dict) -> dict:\n    aggcount = aggregated['count'] + 1\n    value_dict = json.loads(value)\n    return {\n        'count': aggcount,\n        'min': min(aggregated['min'], value_dict['value']),\n        'max': max(aggregated['max'], value_dict['value']),\n        'mean': (aggregated['mean'] * aggregated['count'] + value_dict['value']) / (aggregated['count'] + 1)\n    }\n\n\n이 기능은 창에서 여러 집계를 수행할 때만 필요합니다. 우리의 경우 각 창에 대해 count, min, max 및 mean 값을 생성하기 때문에 이러한 값을 미리 정의해야 합니다.\n\n다음으로, 중요한 부분입니다 - tumbling window 기능 추가:\n\n\n### 창 유형 및 길이와 같은 창 매개변수 정의\nsdf = (\n    # 10초의 텀블링 창 정의\n    sdf.tumbling_window(timedelta(seconds=WINDOW), grace_ms=timedelta(seconds=WINDOW_EXPIRES))\n\n    # 'reducer' 및 'initializer' 함수로 'reduce' 집계 생성\n    .reduce(reducer=reducer, initializer=initializer)\n\n    # 닫힌 10초 창에 대해서만 결과 발생\n    .final()\n)\n\n### 스트리밍 DataFrame에 창 적용 및 출력에 포함할 데이터 포인트 정의\nsdf = sdf.apply(\n    lambda value: {\n        \"time\": value[\"end\"], # 'agg-temperature' 토픽으로 보낼 메시지의 타임스탬프로 윈도우 종료 시간 사용\n        \"temperature\": value[\"value\"], # 온도 매개변수에 대한 {count, min, max, mean} 값을 포함하는 사전 전송\n    }\n)\n\n\n<div class=\"content-ad\"></div>\n\n스트림 처리가 가능한 DataFrame을 정의하는데, 이는 텀블링 윈도우를 기반으로 한 집계의 집합입니다 — 시간의 10초간의 겹치지 않는 세그먼트에 대해 수행되는 집계의 집합입니다.\n\n팁: 다양한 윈도우 계산 유형에 대해 다시 알아보려면 다음 기사를 확인해보세요: “스트림 처리에서 윈도우링하는 방법 안내”.\n\n마지막으로 결과를 다운스트림 출력 주제로 내보냅니다:\n\n```js\nsdf = sdf.to_topic(output_topic)\nsdf = sdf.update(lambda value: logger.info(f\"생성된 값: {value}\"))\n\nif __name__ == \"__main__\":\n    logger.info(\"애플리케이션 시작\")\n    app.run(sdf)\n```\n\n<div class=\"content-ad\"></div>\n\n알림: 생산자 코드가 합성 온도 데이터를 전송하는 데 사용된 생산자 코드와 매우 다르게 보일 수 있습니다 (with app.get_producer() as producer()을 사용하는 부분). 이는 Quix가 변환 작업을 위해 다른 생산자 함수를 사용하기 때문입니다 (즉, 입력 및 출력 주제 사이에 위치한 작업).\n\n따라오시면서 알게 되겠지만, 우리는 Streaming DataFrame인 sdf 변수를 최종 형태로 바꿀 때까지 반복적으로 변경합니다. 따라서 sdf.to_topic 함수는 Streaming DataFrame의 최종 상태를 단순히 출력 주제로 스트리밍하여 행 단위로 돌려줍니다.\n\n반면에 생산자 함수는 CSV 파일, MQTT 브로커 또는 우리의 경우와 같이 외부 소스에서 데이터를 수집하는 데 사용됩니다, 생성기 함수가 있습니다.\n\n# 스트리밍 애플리케이션 실행\n\n<div class=\"content-ad\"></div>\n\n마침내, 스트리밍 애플리케이션을 실행하고 모든 부분들이 원활하게 작동하는지 확인할 수 있게 되었네요.\n\n먼저 터미널 창에서 다시 프로듀서를 실행해주세요:\n\n```js\npython sensor_stream_producer.py\n```\n\n그런 다음, 두 번째 터미널 창에서 스트림 프로세서를 시작하세요:\n\n<div class=\"content-ad\"></div>\n\n```js\npython sensor_stream_processor.py\n```\n\n각 창에서 로그 출력을 주의 깊게 확인하여 모든 것이 원할하게 실행되는지 확인하세요.\n\n또한 집골 토픽에 집계된 데이터가 올바르게 스트리밍되는지 확인하려면 Redpanda 콘솔을 확인할 수 있습니다(주소: http://localhost:8080/topics).\n\n<img src=\"/assets/img/2024-05-27-AggregatingReal-timeSensorDatawithPythonandRedpanda_2.png\" />\n\n\n<div class=\"content-ad\"></div>\n\n# 마무리\n\n여기서 시도한 것은 스트림 처리를 수행하는 하나의 방법에 불과합니다. 당연히 Apache Flink 및 Apache Spark Streaming과 같은 강력한 도구들도 있습니다. 그러나 이 도구들은 주로 Java 기반입니다. Python 래퍼를 사용할 수 있지만 문제가 발생하면 여전히 Python 오류가 아닌 Java 오류를 디버깅해야 합니다. Java 기술은 데이터 엔지니어들과 함께 작업하는 소프트웨어 엔지니어들 사이에서 점점 더 중요해지는 데이터 분석가에게 일반적으로 보급되어 있는 기술은 아닙니다.\n\n이 튜토리얼에서는 스트림 처리 알고리즘으로 간단한 집계를 실행했지만, 실제로 이러한 알고리즘들은 주로 기계 학습 모델을 활용하여 데이터를 변환합니다. 또한, 기계 학습을 위한 소프트웨어 생태계는 주로 Python으로 이루어져 있습니다.\n\n자료 전문가, 기계 학습 엔지니어 및 소프트웨어 엔지니어들이 함께 작업할 때 Python이 선호되는 언어임을 자주 간과합니다. 이는 SQL보다도 더 효율적입니다. 왜냐하면 Python을 사용하여 데이터와 관련 없는 작업(예: API 호출 및 웹훅 트리거)을 수행할 수 있기 때문입니다. 이것이 Faust, Bytewax, Quix와 같은 라이브러리들이 발전해 나간 이유 중 하나입니다. 즉, 이러한 다양한 분야 사이의 임피던스 갭을 줄이기 위해 만들어졌다는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n희망을 가지고, 파이썬이 스트림 처리에 적합한 언어임을 보여드릴 수 있었으면 좋겠고, 파이썬의 스트림 처리를 위한 생태계가 꾸준히 성숙해지고 있으며, 기존의 Java 기반 생태계에 버금가는 성능을 보여줄 수 있음을 보여드릴 수 있었기를 희망합니다.\n\n- 이 튜토리얼의 모든 코드는 이 GitHub 저장소에서 확인하실 수 있습니다.","ogImage":{"url":"/assets/img/2024-05-27-AggregatingReal-timeSensorDatawithPythonandRedpanda_0.png"},"coverImage":"/assets/img/2024-05-27-AggregatingReal-timeSensorDatawithPythonandRedpanda_0.png","tag":["Tech"],"readingTime":13}],"page":"59","totalPageCount":154,"totalPageGroupCount":8,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true}