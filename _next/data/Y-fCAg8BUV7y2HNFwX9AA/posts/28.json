{"pageProps":{"posts":[{"title":"1분 만에 클라우드 아키텍처 다이어그램 만들기 이 도구 정말 빠름","description":"","date":"2024-06-22 02:46","slug":"2024-06-22-BuildcloudArchitectureDiagramsin1MinuteThisToolisCrazyFast","content":"\n\n차트태그를 마크다운 형식으로 변경해주세요.\n\n<div class=\"content-ad\"></div>\n\n스위치를 바꾸는 것은 무거운, 불편한 수트에서 매끄럽고 재빠른 도구 세트로 변하는 것 같았어요. 그래서 제가 경험한 것은:\n\n- 그리지 말고 다이어그램을 쓰기: 코드로 다이어그램을 만드는 것이 자연스럽고 빠르게 느껴졌어요. 까다로운 사용자 인터페이스와 씨름하지 않고 관계와 레이아웃을 정확하게 정의할 수 있었고, ChatGPT, BARD와 같은 생성적인 AI 도구들에게도 코드 생성을 요청할 수 있어요.\n- 재사용성: 다음 프로젝트에도 일부 요소를 재사용할 수 있어요.\n- 코드처럼 다이어그램 버전 관리: Git에 내 애플리케이션 코드와 함께 다이어그램을 저장하면 변경 사항을 추적하고 필요할 때 이전 버전으로 돌아가기 쉬워져요.\n- 다이어그램 생성 자동화: CI/CD 파이프라인에 다이어그램 생성을 추가하면 항상 최신의 다이어그램을 유지할 수 있어요. 이렇게 하면 수동 작업을 줄이고 오류를 감소시킬 수 있어요.\n- 다이어그램 쉽게 사용자 정의하기: 다이어그램 스타일과 요소를 손쉽게 조정하여 제 취향과 프로젝트 요구에 맞출 수 있었어요.\n\n# 준비 사항:\n\n## 1: Github에서 Diagrams 패키지 복제하기\n\n<div class=\"content-ad\"></div>\n\n```js \npip install diagrams \n```\n\n## 2: Graphviz 설치하기 (다이어그램 렌더링) 및 확인\n\n여기에서 Graphviz를 다운로드하고 설치하세요.\n\n# AI 사용 방법 (1분만에):\n\n<div class=\"content-ad\"></div>\n\n<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*2Zkdp3uGTEiSgChrGVw8cA.gif\" />\n\n## 단계 1: ChatGPT AI에게 다이어그램 코드를 생성해 달라고 요청하세요.\n\n해결책 세부 정보를 복사하여 붙여넣기하거나\n\n설명만 제공해주세요\n\n<div class=\"content-ad\"></div>\n\n## 지시 사항\n\n## 단계 2: 필요에 따라 AI가 제공한 코드를 수정하기\n\nAI가 제공한 코드 중 두 가지 오류를 수정해야 했습니다.\n\n- diagrams.aws.management 대신 diagrams.aws에서 KMS를 가져 오려고 했습니다.\n\n<div class=\"content-ad\"></div>\n\n보안.\n\n```js\ndiagrams.aws.management 모듈에서 KMS만 가져오셨네요.\ndiagrams.aws.general 모듈에서 InternetGateway, S3Bucket을 가져오셨네요.\n```\n\n```js\ndiagrams.aws.security 모듈에서 KMS를 가져오셨네요.\ndiagrams.aws.storage 모듈에서 S3를 가져오셨네요.\n```\n\n2. diagrams.aws.network에서 S3VPCEndpoint를 import하려고 했지만 S3VPCEndpoint가 존재하지 않아 Endpoint를 사용했습니다. 그리고 NatGateway에 관한 대소문자 문제가 있었습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nfrom diagrams.aws.network import VPC, PrivateSubnet, S3VPCEndpoint, NatGateway\ns3_endpoint = S3VPCEndpoint(\"S3 Gateway Endpoint\")\n```\n\n```js\nfrom diagrams.aws.network import VPC, PrivateSubnet, Endpoint, NATGateway\n\ns3_endpoint = Endpoint(\"S3 Gateway Endpoint\")\n```\n\n당신이 필요한 서비스가 패키지 내 어디에 정확히 위치하는지 확인할 수 있습니다.\n\n## 단계 3: 프로그램 실행하기\n\n<div class=\"content-ad\"></div>\n\n```bash\npython `filename`.py\n\n# 코드를 수동으로 작성하는 단계\n\n다이어그램 패키지를 배우고 수동으로 다이어그램을 만드는 것은 매우 쉽습니다. Diagram, Cluster, Edge 및 몇 가지 기호 등 약 6가지 항목에 대해 알고 있기만 하면 됩니다.\n\n“Diagram” — 당신의 다이어그램의 최상위 컨테이너\n```  \n\n<div class=\"content-ad\"></div>\n\n```js\n다음 코드에서,\n\nS3 to RDS는 저장할 이미지 파일의 이름을 나타냅니다\n\ndirection — 왼쪽에서 오른쪽으로(LR), 오른쪽에서 왼쪽으로, 위에서 아래로 컨테이너를 만들기 시작합니다. 필요한 경우 사용할 수 있는 옵션입니다.\n```\n\n<div class=\"content-ad\"></div>\n\n\"png\", \"jpg\", \"svg\", \"pdf\", \"dot\" 형식이 현재 지원됩니다.\n\n\"Cluster\" — 두 번째 수준 컨테이너(컨테이너의 이름 또는 레이블을 지정할 수 있습니다)\n\n```js\nwith Cluster(\"AWS\"):\n```\n\nEdge\n\n<div class=\"content-ad\"></div>\n\n\"``\" - 오른쪽으로 향하는 화살표 또는 가장자리\n\n```js\nevent_bridge >> Edge(label=\"triggers\") >> lambda1\n```\n\n\"``\" - 왼쪽으로 향하는 화살표 또는 가장자리\n\n\"-\" - 방향이 없는 엣지 또는 양방향\n\n<div class=\"content-ad\"></div>\n\n\ns3_raw_layer - Edge(label=\"push\") - lambda1\n\n\n# 샘플 출력:\n\n<img src=\"/assets/img/2024-06-22-BuildcloudArchitectureDiagramsin1MinuteThisToolisCrazyFast_0.png\" />\n\n# 다음 단계\n\n<div class=\"content-ad\"></div>\n\n잊지말고!\n\n![image](https://miro.medium.com/v2/resize:fit:960/0*BstxtFTCD4r-65Sd.gif)\n\n그리고,\n\n![image](/assets/img/2024-06-22-BuildcloudArchitectureDiagramsin1MinuteThisToolisCrazyFast_1.png)\n\n<div class=\"content-ad\"></div>\n\n그리고 만약 내 작업을 정말 좋아하신다면 커피 한 잔 사주실 수도 있어요 :).","ogImage":{"url":"/assets/img/2024-06-22-BuildcloudArchitectureDiagramsin1MinuteThisToolisCrazyFast_0.png"},"coverImage":"/assets/img/2024-06-22-BuildcloudArchitectureDiagramsin1MinuteThisToolisCrazyFast_0.png","tag":["Tech"],"readingTime":4},{"title":"파이썬에서 쓰레딩 사용 하는 방법","description":"","date":"2024-06-22 02:41","slug":"2024-06-22-ThreadinginPython","content":"\n\n<img src=\"/assets/img/2024-06-22-ThreadinginPython_0.png\" />\n\n# 소개\n\n이 게시물은 threading 모듈과 concurrent.futures 모듈의 ThreadPoolExecutor 클래스를 사용한 Python의 다중 스레딩에 대한 소개입니다.\n\n마지막에 있는 리소스 섹션에는 해당 주제를 깊이 파헤칠 수 있는 멋진 자료에 대한 링크가 있어요 🤓\n\n<div class=\"content-ad\"></div>\n\n관련 포스트\n\n- 병행성과 병렬성 소개\n- Python에서의 멀티프로세싱\n- Python에서의 ProcessPoolExecutor\n\n## 쓰레드란\n\n쓰레드는 프로세스 내에서 실행의 기본 단위입니다. 독립적인 실행 흐름으로, 동일한 프로세스 내의 다른 독립적인 실행 흐름과 동일한 주소 공간을 공유합니다. 프로세스는 하나 이상의 쓰레드를 가질 수 있으며, 이 중 하나는 메인 쓰레드입니다. 이는 Python 프로세스의 기본 쓰레드입니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-22-ThreadinginPython_1.png\" />\n\n프로그램을 작성하여 여러 스레드를 활용하면 프로그램이 하나의 코어에서 동시에 실행될 수 있습니다. 코루틴을 사용하면 하나의 스레드 프로그램을 동시에 실행할 수도 있습니다.\n\nPython (CPython 구현) 프로세스 내의 스레드는 Python의 글로벌 인터프리터 락 (GIL) 때문에 다른 프로그래밍 언어의 스레드 (예: Java, C/C++, Go)와 달리 여러 코어가 있는 경우에도 병렬로 실행되지 않습니다. Python에서 CPU 바운드 작업이 필요하고 병렬 구현이 필요한 경우 multiprocessing 모듈이나 ProcessPoolExecutor 클래스 (Python의 Multiprocessing 참조)를 사용해야 합니다.\n\n프로그램을 작성한다고 상상해보세요. 실행이 시작되면 단일 프로세스가 될 것입니다. 또한 해당 프로세스는 두 개의 스레드를 갖게 될 것입니다. 두 개의 스레드가 있으면 동시성을 활용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n싱글 코어 CPU에서는 프로그램이 동시에 실행될 수 있습니다. 하나의 코어와 두 개의 스레드로, 스레드가 동일한 코어 내에서 서로 교환될 수 있습니다. 이를 컨텍스트 스위칭이라고 합니다.\n\n컨텍스트 스위칭 중에는 한 스레드가 CPU에서 스위칭되어 다른 스레드가 실행될 수 있도록 합니다. 이를 위해 프로세스나 스레드의 상태가 저장되어 나중에 복원되어 나중에 다시 실행될 수 있게 되며, 그 후 이전에 저장된 상태가 복원됩니다.\n\n컨텍스트 스위칭은 일반적으로 계산적으로 비용이 많이 듭니다. 프로세스나 스레드 간의 스위치 컨텍스트는 레지스터 및 다른 작업의 저장 및 로드에 일정 시간이 소요됩니다. 스레드 간의 컨텍스트 전환은 일반적으로 프로세스 간의 전환보다 빠릅니다.\n\n# 스레딩 사용 사례\n\n<div class=\"content-ad\"></div>\n\n다중 스레딩이 가장 적합한 작업은 I/O 바운드 작업입니다. 예를 들어, 스레드가 데이터베이스에 요청을 보내야 하는 명령을 실행하는 경우, 응답을 기다리는 스레드로 CPU 코어를 차단하는 것은 현명하지 않습니다. 대신에 첫 번째 스레드가 기다리는 동안에 다른 스레드가 코어를 사용할 수 있도록 하는 것이 자원을 더 잘 활용하는 방법입니다.\n\n아래 그림에서 빈 원은 스레드가 무언가 발생할 때까지 기다리는 I/O 작업을 나타냅니다. 첫 번째 I/O 작업이 시작될 때(빈 녹색 원), 운영 체제는 빠르게 대기 중인 스레드를 빨간색 스레드로 전환하여 계산 자원을 더 잘 할당합니다. 이것은 OS가 하는 결정이며, 개발자는 언제 스레드간 전환을 할지 결정할 수 없습니다.\n\n프로그램이 병렬로 여러 스레드를 사용하지 않고 대신에 단일 스레드 내에서 순차적으로 작업을 실행하는 경우, 녹색 작업을 완료하기를 기다려서 빨간 작업을 실행하기 시작해야 하므로, 두 작업을 완료하는 데 더 많은 시간이 소요됩니다.\n\n<div class=\"content-ad\"></div>\n\n`<img src=\"/assets/img/2024-06-22-ThreadinginPython_3.png\" />`\n\nI/O 작업을 다룰 때 멀티스레딩은 자원을 더 잘 할당할 수 있는 좋은 선택입니다.\n\n이제 멀티스레드 프로그램 구현 몇 가지를 살펴보겠습니다! 🥷🏽\n\n# Python 스레딩 초급 단계\n\n<div class=\"content-ad\"></div>\n\n먼저 I/O 바운드와 CPU 바운드 작업을 정의해 봅시다. io_bound_operation은 지정된 초 수만큼 \"잠들어\" 있습니다. cpu_bound_operation은 지정된 숫자 범위를 더합니다. 두 함수 모두 결과를 shared_list에 추가합니다. 동일한 프로세스의 스레드는 데이터를 공유할 수 있다는 것을 기억해 주세요.\n\n```js\nimport logging\nfrom threading import Thread\nfrom time import perf_counter, sleep\n\nfrom concurrency.utils import flaten_list_of_lists, get_saving_path, postprocess_times\nfrom concurrency.visualize import barh\n\n\nformat = \"%(asctime)s: %(message)s\"\nlogging.basicConfig(format=format, level=logging.INFO, datefmt=\"%H:%M:%S\")\n\nshared_list = []  # 동일한 프로세스의 스레드는 데이터를 공유합니다.\n\ndef io_bound_operation(secs: float | int) -> None:\n    \"\"\"secs 초 동안 1개의 I/O 바운드 작업을 실행하고 결과를 shared_list에 추가합니다.\"\"\"\n    start = perf_counter()\n    sleep(secs)\n    finish = perf_counter()\n\n    shared_list.append([(start, finish)])\n\ndef cpu_bound_operation(n: int) -> None:\n    \"\"\"CPU 바운드 작업.\"\"\"\n    start = perf_counter()\n    count = 0\n    for i in range(n):\n        count += i\n    finish = perf_counter()\n\n    shared_list.append([(start, finish)])\n```\n\n이제 두 개의 새 스레드 t1과 t2를 생성할 것입니다. Thread 객체를 인스턴스화 할 때는 스레드에서 실행할 작업/함수인 target을 추가해야 합니다. 인자는 args 매개변수를 통해 전달될 수 있으며, 이는 Iterable 객체를 받습니다.\n\n이 예제에서는 I/O 바운드 작업이 1초 동안 지속되도록 하고, 프로세서가 이 100,000,000개의 숫자를 더하는 데 약 3.5초가 걸립니다.\n\n<div class=\"content-ad\"></div>\n\n```js\ndef threading_two_threads():\n    # 두 개의 스레드 객체 생성\n    t1 = Thread(target=io_bound_operation, args=(1,))\n    t2 = Thread(target=cpu_bound_operation, args=(100000000,))\n\n    # 활동 시작 -> run() 메서드를 호출\n    t1.start()\n    sleep(0.1)\n    t2.start()\n\n    # 호출 스레드 블록 -> 스레드가 완료될 때까지 계속 실행됨\n    t1.join()\n    t2.join()\n\n    logging.info(f\"shared_list {shared_list}\")\n```\n\n그런 다음 스레드 활동을 시작해야 합니다. 이는 start() 메서드를 호출하여 수행됩니다. 이는 객체의 run() 메서드가 별도의 제어 스레드에서 호출되도록 정렬합니다.\n\n또한 sleep(0.1) 함수가 있어 두 번째 스레드가 조금 늦게 시작되도록합니다. 이를 통해 시각화를 더 잘할 수 있습니다.\n\n```js\ndef threading_two_threads():\n    # 두 개의 스레드 객체 생성\n    t1 = Thread(target=io_bound_operation, args=(1,))\n    t2 = Thread(target=cpu_bound_operation, args=(100000000,))\n\n    # 활동 시작 -> run() 메서드를 호출\n    t1.start()\n    sleep(0.1)\n    t2.start()\n\n    # 호출 스레드 블록 -> 스레드가 완료될 때까지 계속 실행됨\n    t1.join()\n    t2.join()\n\n    logging.info(f\"shared_list {shared_list}\")\n```\n\n<div class=\"content-ad\"></div>\n\n마지막으로, 스레드 객체의 join() 메서드를 호출해야 스레드가 종료될 때까지 기다릴 수 있습니다.\n\n메인 스레드는 두 스레드가 모두 완료될 때까지 종료되지 않습니다.\n\n스레드를 결합하면 호출 중인 스레드(메인 스레드)가 join() 메서드가 호출된 스레드가 정상적으로 종료되거나 처리되지 않은 예외를 통해 또는 선택적으로 제한 시간이 발생할 때까지 블록됩니다.\n\n이 예제를 변경해보세요. 만약 두 join() 메서드의 주석 처리를 해도 프로그램은 예외를 발생시킬 것입니다. 왜냐하면 shared_list에는 아무것도 없기 때문에 postprocess_times 함수가 빈 목록을 색인화하려고 시도할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n```js\ndef threading_two_threads():\n    # 두 개의 스레드 객체를 생성합니다.\n    t1 = Thread(target=io_bound_operation, args=(1,))\n    t2 = Thread(target=cpu_bound_operation, args=(100000000,))\n\n    # 활동 시작 -> run() 메서드를 호출합니다.\n    t1.start()\n    sleep(0.1)\n    t2.start()\n\n    # 호출 스레드를 차단 -> 스레드가 완료될 때까지 계속 실행되지 않도록 합니다.\n    t1.join()\n    t2.join()\n\n    logging.info(f\"shared_list {shared_list}\")\n\n    # 차트 표시를 위한 일부 처리\n    start_points, end_points = postprocess_times(flaten_list_of_lists(shared_list))\n    # start_points, end_points = postprocess_times(shared_list)\n\n    barh(\n        title=\"동시 실행, 2개의 스레드, 1초의 I/O 바운드 작업 + 약 3.5초의 CPU 작업\",\n        start_points=start_points,\n        end_points=end_points,\n        path=get_saving_path(\"threading/images/first_multithreaded_program.png\"),\n        n=2,\n    )\n\nif __name__ == \"__main__\":\n    logging.info(f\"동시 작업 시작\")\n    threading_two_threads()\n    logging.info(f\"동시 작업 완료\")\n```\n\n아래 이미지는 각 스레드가 완료하는 데 소요된 시간을 보여줍니다. sleep 함수는 두 번째 스레드(cpu_bound_operation)가 조금 늦게 시작하도록 만듭니다. 그래프에서 첫 번째 스레드(0)가 시작한 후 0.1초 후 두 번째 스레드가 시작됩니다.\n\n<div class=\"content-ad\"></div>\n\nI/O 바운드 작업은 단 1초 동안 지속되고 io_bound_operation 함수는 해당 작업만 수행해야 합니다. 이 때 I/O 바운드 작업이 대기하는 동안(전체 1초 동안) CPU 바운드 작업이 실행될 수 있습니다. 이것이 CPU 바운드 작업(두 번째 스레드)이 약 3.5초 동안만 지속되며 I/O 바운드 작업에 의해 지연되지 않는 이유입니다.\n\n![image](/assets/img/2024-06-22-ThreadinginPython_4.png)\n\nThread 객체는 스레드를 만드는 가장 간단한 방법 중 하나이지만, 더 편리한 방법들이 있습니다. 그러나 더 자세히 파헤치기 전에 좀 더 간단한 예제를 살펴보겠습니다.\n\n# threading 모듈을 이용한 멀티스레딩 시간 시각화\n\n<div class=\"content-ad\"></div>\n\n## 예시 1–2 스레드\n\n- 스레드 1–1: 약 1초의 I/O-바운드 작업과 1초 정도의 CPU-바운드 작업\n- 스레드 2–1: 약 3.5초의 CPU-바운드 작업\n\n이제 첫 번째 스레드가 CPU-바운드 작업 1초 정도와 I/O-바운드 작업 1초로 구성된 작업을 실행하는 대신 I/O-바운드 작업만을 실행하는 작업이 아닌 경우를 고려해 봅시다.\n\n따라서 이제 두 개의 새로운 스레드를 생성하는 프로그램이 있습니다. 하나는 I/O-바운드 작업과 CPU-바운드 작업을 수행하고, 또 다른 하나는 약 3.5초의 CPU-바운드 작업을 수행합니다.\n\n<div class=\"content-ad\"></div>\n\n```python\ndef cpu_io_bound_operations(secs: float | int, n: int) -> None:\n    \"\"\"한 가지 I/O 바운드 작업(초 단위)과 한 가지 CPU 바운드 작업을 실행하는 함수입니다. 결과는 shared_list에 추가됩니다.\"\"\"\n    start = perf_counter()\n    count = 0\n    for i in range(n):  # CPU 바운드\n        count += i\n    sleep(secs)  # I/O 바운드\n    finish = perf_counter()\n\n    shared_list.append([(start, finish)])\n```\n\n쓰레드 2는 프로세서에서 약 3.5초가 필요하며, 쓰레드 1은 1초만에 처리합니다.\n\n쓰레드 1이 1초만에 처리하는 이유는 CPU 바운드 작업 때문이며, I/O 바운드 작업의 대기 시간은 쓰레드 2가 활용합니다.\n\n쓰레드 2(3.5초) + 쓰레드 1(1초)을 더하면 4.5초의 CPU 작업 시간이 필요합니다.\n\n<div class=\"content-ad\"></div>\n\n위의 그래프는 두 작업이 모두 4.5초 동안 실행된다는 것을 보여줍니다. 각 CPU 집약적 작업에 필요한 시간은 약간 다를 수 있습니다.\n\n<img src=\"/assets/img/2024-06-22-ThreadinginPython_5.png\" />\n\n그러나 스레드 1은 종료하는 데 3초가 걸립니다. 이는 우리가 컨텍스트 스위치가 언제 발생하는지 제어하지 않기 때문에, I/O 바운드 작업이 종료된 후에도 스레드 1이 프로세서를 사용하기 위해 얼마간의 대기 시간이 있을 수 있기 때문입니다. 컨텍스트 스위치는 개발자의 제어를 벗어나므로, 실제로 원하는 것보다 더 자주 발생할 수 있으며 다른 스레드로 스위치하고 싶지 않은 순간에 발생할 수 있습니다.\n\n이제 몇 가지 추가 예시를 빠르게 살펴보겠습니다! 이미 이해하셨다면이 부분을 건너뛰고 바로 다음 섹션인 ThreadPoolExecutor로 이동할 수 있습니다 🚀\n\n<div class=\"content-ad\"></div>\n\n## 예제 2-1 스레드\n\n- 10개의 IO 바운드 작업을 1초씩 순차적으로 수행합니다.\n\n여기서는 순차적 실행을 표현하고 더 많은 스레드를 생성할 필요가 없습니다. 메인 스레드 하나로 충분합니다.\n\n```python\ndef sequential(n: int = 10, secs: float | int = 1) -> None:\n    \"\"\"1개 스레드에서 n개의 I/O 바운드 작업을 secs 초 동안 순차적으로 수행하고 수평 막대 차트를 플롯합니다.\n    \"\"\"\n    # n개의 I/O 바운드 작업 수행, 각 작업에 대한 튜플 저장\n    times = [io_bound_operation(secs) for _ in range(n)]\n    start_points, end_points = postprocess_times(times)\n\n    barh(\n        title=\"순차 실행, 1개 스레드, 10개의 1초 IO 바운드 작업\",\n        start_points=start_points,\n        end_points=end_points,\n        path=get_saving_path(\"threading/images/ex_1_one_thread.png\"),\n    )\r\n```\n\n<div class=\"content-ad\"></div>\n\n위 그림에서 각 스레드가 작업을 수행했기 때문에 스레드가 막대로 표시되었습니다(입출력 바인드 및 CPU 바인드 작업을 결합해도 동일한 작업으로 간주했습니다).\n\n이제 10개의 다른 입출력 바인드 작업이 동일한 스레드에서 실행되므로 각 작업을 더 잘 시각화할 수 있습니다. 따라서 이 열개의 막대는 동일한 스레드에 속합니다.\n\n![이미지](/assets/img/2024-06-22-ThreadinginPython_6.png)\n\n## 예제 3–1 thread\n\n<div class=\"content-ad\"></div>\n\n- 2개의 CPU 바운드 작업\n\n만약 우리가 동일한 스레드에서 연속적으로 3.5초 정도 걸리는 CPU 바운드 작업 두 개를 실행한다면, 약 7초 정도 소요된다는 것을 확인할 수 있습니다.\n\n두 번째 작업을 시작하기 전에 첫 번째 작업이 완료되어야 합니다.\n\n```python\ndef sequential(counts: int, n: int = 10) -> None:\n    # n개의 CPU 바운드 작업 수행, 각 작업에 대한 튜플 저장\n    times = [cpu_bound_operation(counts) for _ in range(n)]\n    start_points, end_points = postprocess_times(times)\n```\n\n<div class=\"content-ad\"></div>\n\n![스레드](/assets/img/2024-06-22-ThreadinginPython_7.png)\n\n## 예제 4-2 스레드\n\n- 스레드 1–1: 대략 3.5초 소요되는 CPU 바운드 작업\n- 스레드 2–1: 대략 3.5초 소요되는 CPU 바운드 작업\n\n위의 두 CPU 바운드 작업은 동시에 실행될 때 매우 다른 차트를 보여줍니다. 두 작업은 모두 7초가 걸리는 것처럼 보이지만, 실제로는 각각 3.5초가 걸립니다. 그들은 서로 번갈아가며 작업을 완료할 때까지 전환됩니다.\n\n<div class=\"content-ad\"></div>\n\n멀티스레딩을 사용하는 방법이 제대로 되지 않았어요. 현재는 교육 목적으로만 사용하고 있어요. CPU 바운드 작업만 한다면 멀티스레딩을 사용해도 시간이 단축되지 않아요.\n\n```js\ndef thread_cpu_bound_operations(counts: int) -> None:\n    \"\"\"Run a CPU-bound task and append the results to shared_list.\"\"\"\n    shared_list.append([cpu_bound_operation(counts)])\n\n\ndef threading_two_threads() -> None:\n    # 두 개의 스레드 객체를 생성합니다. 각 스레드는 다섯 개의 I/O 바운드 작업을 수행할 거에요\n    t1 = Thread(target=thread_cpu_bound_operations, args=(100000000,))\n    t2 = Thread(target=thread_cpu_bound_operations, args=(100000000,))\n\n    # 활동 시작 -> run() 메서드를 호출합니다\n    t1.start()\n    t2.start()\n\n    # 호출한 스레드가 완료될 때까지 기다립니다 -> 스레드가 모두 끝날 때까지 진행을 막습니다\n    t1.join()\n    t2.join()\n```\n\n![이미지](/assets/img/2024-06-22-ThreadinginPython_8.png)\n\n## 예제 5-2 스레드\n\n<div class=\"content-ad\"></div>\n\n- 1초 동안 5개의 I/O 바운드 작업을 가진 스레드 1 실행\n- 1초 동안 5개의 I/O 바운드 작업을 가진 스레드 2 실행\n\n총 10개의 1초 동안 동작하는 I/O 바운드 작업과 두 개의 스레드가 있습니다. 각 스레드는 순차적으로 다섯 개의 I/O 바운드 작업을 실행하며, 두 그룹의 다섯 개의 작업은 동시에 실행됩니다.\n\n```python\ndef thread_io_bound_operations(n: int, secs: float | int) -> None:\n    \"\"\"n개의 I/O 바운드 작업을 secs 초 동안 실행하고 결과를 shared_list에 추가합니다.\"\"\"\n    shared_list.append([io_bound_operation(secs) for _ in range(n)])\n\n\ndef threading_two_threads() -> None:\n    # 각각 다섯 개의 I/O 바운드 작업을 수행할 두 개의 스레드 개체 생성\n    t1 = Thread(target=thread_io_bound_operations, args=(5, 1))\n    t2 = Thread(target=thread_io_bound_operations, args=(5, 1))\n\n    # 활동 시작 -> run() 메서드 호출\n    t1.start()\n    t2.start()\n\n    # 호출 스레드 블록 -> 스레드가 완료되지 않은 상태로 계속 실행되는 것을 방지\n    t1.join()\n    t2.join()\n```\n\n![Python에서 쓰레딩하기](/assets/img/2024-06-22-ThreadinginPython_9.png)\n\n<div class=\"content-ad\"></div>\n\n## 예제 6–10 스레드\n\n- 각 스레드 — 1초 동안의 1개의 I/O 바운드 작업\n\n지난 예제와 비슷하지만, 이제는 두 개가 아닌 열 개의 스레드가 있으며 각각은 1초 동안의 단 하나의 I/O 바운드 작업을 실행합니다.\n\n```js\ndef thread_io_bound_operations(n: int, secs: float | int) -> None:\n    \"\"\"n개의 secs 초 동안의 I/O 바운드 작업을 실행하고 결과를 shared_list에 추가합니다.\"\"\"\n    shared_list.append([io_bound_operation(secs) for _ in range(n)])\n\n\ndef threading_two_threads() -> None:\n    threads = []\n    # 열 개의 스레드 객체 생성, 각 스레드는 하나의 I/O 바운드 작업을 수행합니다\n    for _ in range(10):\n        t = Thread(target=thread_io_bound_operations, args=(1, 1))\n        t.start()\n        threads.append(t)\n\n    # 호출 스레드 블로킹 -> 스레드가 완료되지 않은 상태로 계속 실행되지 않도록 함\n    [thread.join() for thread in threads]\n```\n\n<div class=\"content-ad\"></div>\n\n\n![Example 7-2 threads](/assets/img/2024-06-22-ThreadinginPython_10.png)\n\n## Example 7-2 threads\n\n- Thread 1: CPU-bound task of approximately 3.5s\n- Thread 2: 5 I/O-bound tasks of 1s each\n\nNow we have two threads. Thread 1 executes a CPU-bound operation taking about 3.5 seconds, while thread 2 executes five I/O-bound tasks, each taking 1 second.\n\n\n<div class=\"content-ad\"></div>\n\nI/O 작업이 대기하는 동안 CPU 집약 작업이 실행됩니다. 매번 I/O 작업이 시작될 때마다 OS는 빠르게 스레드를 전환합니다.\n\n```js\ndef thread_io_bound_operations(n: int, secs: float | int) -> None:\n    \"\"\"Run n I/O-bound tasks of secs seconds and append the results to shared_list.\"\"\"\n    shared_list.append([io_bound_operation(secs) for _ in range(n)])\n\n\ndef thread_cpu_bound_operations(counts: int) -> None:\n    \"\"\"Run a CPU-bound task and append the results to shared_list.\"\"\"\n    shared_list.append([cpu_bound_operation(counts)])\n\n\ndef threading_two_threads() -> None:\n    # 두 개의 스레드 개체 생성, 각 스레드는 다섯 가지의 I/O 작업을 수행할 것입니다\n    t1 = Thread(target=thread_cpu_bound_operations, args=(100000000,))\n    t2 = Thread(target=thread_io_bound_operations, args=(5, 1))\n\n    # 활동 시작 -> run() 메서드 호출\n    t1.start()\n    t2.start()\n\n    # 호출 스레드 차단 -> 스레드가 완료될 때까지 계속 실행하지 못하도록 함\n    t1.join()\n    t2.join()\n```\n\n![image](/assets/img/2024-06-22-ThreadinginPython_11.png)\n\n## 예제 8-6 스레드\n\n<div class=\"content-ad\"></div>\n\n- Thread 1–1 CPU-bound task of 3.5s approx (bar 5)\n- Thread 2–1 CPU-bound task (bar 4)\n- Thread 3–1 CPU-bound task (bar 3)\n- Thread 4–1 I/O-bound task of 1s\n- Thread 5–1 I/O-bound task of 1s\n- Thread 6–1 I/O-bound task of 1s\n\n여기에서는 세 개의 스레드가 각각 하나의 I/O 작업을 수행하고, 세 개의 스레드가 각각 하나의 CPU 집약적인 작업을 수행합니다. 세 개의 CPU 집약적인 작업이 완료되기까지 걸리는 시간이 다릅니다.\n\n3.5초 동안 계속되는 가장 긴 작업이 처음에 시작됩니다(바 5). 다른 두 가지 CPU 집약적인 작업 때문에 거의 6초가 걸립니다.\n\n```python\ndef 스레드_io_bound_operations(n: int, secs: float | int) -> None:\n    \"\"\"n개의 secs 초동안 I/O-bound 작업을 실행하고 결과를 shared_list에 추가합니다.\"\"\"\n    shared_list.append([io_bound_operation(secs) for _ in range(n)])\n    \n\ndef 스레드_cpu_bound_operations(counts: int) -> None:\n    \"\"\"CPU-bound 작업을 실행하고 결과를 shared_list에 추가합니다.\"\"\"\n    shared_list.append([cpu_bound_operation(counts)])\n\n\ndef threading_six_threads() -> None:\n    # 두 가지 스레드 객체 생성, 각 스레드는 다섯 개의 I/O-bound 작업을 수행할 것임\n    t1 = Thread(target=thread_cpu_bound_operations, args=(100000000,))\n    t2 = Thread(target=thread_cpu_bound_operations, args=(50000000,))\n    t3 = Thread(target=thread_cpu_bound_operations, args=(20000000,))\n    t4 = Thread(target=thread_io_bound_operations, args=(1, 1))\n    t5 = Thread(target=thread_io_bound_operations, args=(1, 1))\n    t6 = Thread(target=thread_io_bound_operations, args=(1, 1))\n\n    # 활동 시작 -> run() 메서드 호출\n    t1.start()\n    t2.start()\n    t3.start()\n    t4.start()\n    t5.start()\n    t6.start()\n\n    # 호출 스레드 차단 -> 스레드가 완료되지 않은 채로 계속 실행되지 않도록 함\n    t1.join()\n    t2.join()\n    t3.join()\n    t4.join()\n    t5.join()\n    t6.join()\n```\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-22-ThreadinginPython_12.png\" />\n\n## 예제 9-4 쓰레드\n\n쓰레드 1은 각각 3.5초의 두 개의 CPU-bound 작업을 순차적으로 실행합니다(막대 6 및 7). 쓰레드 2는 각각 거의 1초의 두 개의 CPU-bound 작업을 순차적으로 실행합니다(막대 4 및 5).\n\n다른 막대는 I/O-bound 작업을 나타내며 각각 1초씩 두 개가 있습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\ndef thread_io_bound_operations(n: int, secs: float | int) -> None:\n    \"\"\"n개의 I/O 바운드 작업을 secs 초 동안 실행하고 결과를 shared_list에 추가합니다.\"\"\"\n    shared_list.append([io_bound_operation(secs) for _ in range(n)])\n\n\ndef thread_cpu_bound_operations(counts: int, n: int) -> None:\n    \"\"\"CPU 바운드 작업을 실행하고 결과를 shared_list에 추가합니다.\"\"\"\n    shared_list.append([cpu_bound_operation(counts) for _ in range(n)])\n\n\ndef threading_four_threads() -> None:\n    # 두 개의 쓰레드 객체를 생성하며 각 쓰레드는 다섯 개의 I/O 바운드 작업을 수행합니다.\n    t1 = Thread(target=thread_cpu_bound_operations, args=(100000000, 2))\n    t2 = Thread(target=thread_cpu_bound_operations, args=(20000000, 2))\n    t3 = Thread(target=thread_io_bound_operations, args=(2, 1))\n    t4 = Thread(target=thread_io_bound_operations, args=(2, 1))\n\n    # 활동 시작 -> run() 메소드를 호출합니다.\n    t1.start()\n    t2.start()\n    t3.start()\n    t4.start()\n\n    # 호출 쓰레드를 차단 -> 쓰레드들이 완료될 때까지 계속 실행되지 않도록 합니다.\n    t1.join()\n    t2.join()\n    t3.join()\n    t4.join()\r\n```\n\n<img src=\"/assets/img/2024-06-22-ThreadinginPython_13.png\" />\n\n쓰레드 1(막대 6과 7)가 첫 번째 3.5초 CPU 바운드 작업(막대 6)을 실행할 때, 다른 쓰레드들과 교차되어 최종적으로 실행을 완료하는 데 5초가 걸립니다. 모든 I/O 바운드 작업은 약 1초가 걸리지만, CPU 집약적 작업이 실행 중일 때 대기하고 있을 수 있습니다. 따라서 쓰레드 1은 첫 번째 작업을 완료하는 데 주로 쓰레드 2의 두 CPU 바운드 작업(막대 4와 5)으로 인해 5초가 걸립니다.\n\n쓰레드 1(막대 6과 7)가 두 번째 3.5초 CPU 바운드 작업(막대 7)을 실행하는 경우에는 프로세서의 모든 성능을 직접 활용할 수 있습니다. 따라서 약 3.5초가 걸립니다.\n\n<div class=\"content-ad\"></div>\n\n위에서는 이 개념을 명확히 설명하기 위한 몇 가지 예시였습니다. 이제 다른 더 편리한 방법들에 대해 알아봅시다!\n\n# ThreadPoolExecutor\n\nconcurrent.futures 모듈은 스레드를 만들기 위해 사용할 수 있는 ThreadPoolExecutor 객체와 multiprocessing을 위한 ProcessPoolExecutor 객체를 제공합니다.\n\n이 글에서는 스레드에 초점을 맞추기 때문에 ThreadPoolExecutor만 사용할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n# 이유\n\nThreadPoolExecutor 클래스는 비동기적으로 호출을 실행하는 데 쓰이는 Executor 하위 클래스입니다.\n\nThreadPoolExecutor는 스레드나 워커 스레드의 컬렉션을 생성하고 관리하여 재사용할 수 있게 합니다. 우리가 위에서 한 것처럼 작업을 동시에 실행하고자 할 때마다 스레드를 생성하고 소멸하는 것을 피할 수 있습니다. 이렇게 하면 이러한 작업이 시간이 많이 소요되기 때문에 성능이 향상됩니다.\n\n# 작동 방식\n\n<div class=\"content-ad\"></div>\n\n## The Executor 클래스\n\n`ProcessPoolExecutor` 클래스와 마찬가지로 `ThreadPoolExecutor`도 `Executor` 클래스를 확장합니다. `Executor` 클래스는 다섯 가지 메서드만을 정의하는 추상 기본 클래스로 다음과 같습니다:\n\n- `submit()`\n- `map()`\n- `shutdown()`\n\n다른 두 메서드는 사실 `__enter__()`와 `__exit__()`로, 이는 파이썬의 매직 메서드로 컨텍스트 관리 프로토콜을 구현합니다. 이들 덕분에 `ThreadPoolExecutor`를 `with` 문에서 사용할 수 있습니다(권장). `with` 문은 `__enter__()` 메서드를 호출하며, `with` 코드 블록을 벗어날 때 `__exit__()`가 호출됩니다.\n\n<div class=\"content-ad\"></div>\n\n```python\nclass Executor(object):\n    \"\"\"구체적인 비동기 업무 처리자들을 위한 추상 기본 클래스입니다.\"\"\"\n    ...\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.shutdown(wait=True)\n        return False\n```\n\nExecutor는 단지 추상 클래스이며 대부분의 로직은 ThreadPoolExecutor 메서드에서 구현됩니다. submit() 및 shutdown() 메서드는 ThreadPoolExecutor 클래스에서 구현되었으며 map() 메서드의 로직은 Executor 클래스에서 구현되었습니다. 내부적으로 submit()을 사용하기 때문입니다.\n\n## ThreadPoolExecutor 클래스\n\nPython의 concurrent.futures 모듈의 ThreadPoolExecutor는 작업을 관리하기 위해 내부적으로 큐를 사용합니다. 큐는 ThreadPoolExecutor의 생성자에서 생성됩니다.\n\n\n<div class=\"content-ad\"></div>\n\n## __init__() 메서드\n\n__init__() 메서드는 새로운 ThreadPoolExecutor 인스턴스를 초기화하고 큐 및 몇 가지 더 많은 객체를 생성합니다.\n\n아래의 SimpleQueue 클래스는 간단한 비제한 FIFO(선입선출) 큐입니다. 먼저 들어간 순서대로 큐에서 항목이 처리되거나 제거되는 선입선출 원칙을 따릅니다.\n\nmax_workers 매개변수에 인자로 전달하여 사용할 수있는 스레드의 최대 수를 설정할 수 있습니다. 그렇게 하지 않으면 기본값은 머신의 프로세서 수에 4를 더한 값이 됩니다. 그 값이 32를 초과하지 않습니다.\n\n<div class=\"content-ad\"></div>\n\n```python\nclass ThreadPoolExecutor(_base.Executor):\n    ...\n\n    def __init__(self, max_workers=None, thread_name_prefix='',\n                 initializer=None, initargs=()):\n        ...\n        if max_workers is None:\n            # 두 종류의 작업에 대해 process_cpu_count + 4를 사용합니다.\n            # 그러나 많은 코어를 가진 기계에서 예상치 못하게 많은 리소스를 소비하도록 제한합니다.\n            max_workers = min(32, (os.process_cpu_count() or 1) + 4)\n        ...\n\n        self._max_workers = max_workers\n        self._work_queue = queue.SimpleQueue()\n        ...\n```\n\n우리는 쓰레드에 선택적으로 이름 접두사를 전달하고, 워커 쓰레드를 초기화하는 데 사용되는 호출 가능한 객체, 그리고 그 인수를 포함하는 튜플을 전달할 수 있습니다.\n\n## submit() 메서드\n\nsubmit() 메서드는 호출 가능한 객체를 실행할 수 있도록 예약합니다. 호출 가능한 객체는 함수 이름과 해당 인수를 전달하는 인수로 사용됩니다.\n\n<div class=\"content-ad\"></div>\n\n```python\nwith ThreadPoolExecutor(max_workers=1) as executor:\n    future = executor.submit(pow, 323, 1235)\n    print(future.result())  # blocks\n```\n\n이 작업은 호출 가능한 함수의 비동기 실행을 나타내는 Future 객체로 래핑되어 있으며, submit() 메서드에 의해 즉시 반환됩니다.\n\nFuture는 비동기 작업의 최종 결과를 나타내는 추상화로, 초기에 결과를 알 수없는 결과를 대신하는 객체입니다. 보통 결과의 계산이 아직 완료되지 않았기 때문에 결과가 아직 알려지지 않았을 때 사용됩니다.\n\nfuture.result()는 호출한 함수(pow 함수)에서 반환된 값을 반환합니다. 호출이 아직 완료되지 않았을 경우 이 메서드는 최대 timeout 초까지 대기합니다 (timeout은 result(timeout=None)의 유일한 매개변수입니다). 호출이 timeout 초 내에 완료되지 않으면 TimeoutError가 발생합니다. timeout은 int 또는 float가 될 수 있으며, 지정되지 않거나 None인 경우 대기 시간 제한이 없습니다.\n\n\n<div class=\"content-ad\"></div>\n\n아래는 ThreadPoolExecutor 클래스의 일부 소스 코드를 볼 수 있습니다. submit() 메서드가 호출되면 Future와 _WorkItem 객체가 생성됩니다. 그런 다음 _WorkItem은 _work_queue에 넣어집니다.\n\n```js\nclass ThreadPoolExecutor(_base.Executor):\n    ...\n\n    def submit(self, fn, /, *args, **kwargs):\n        with self._shutdown_lock, _global_shutdown_lock:\n            ...\n\n            f = _base.Future()\n            w = _WorkItem(f, fn, args, kwargs)\n\n            self._work_queue.put(w)\n            self._adjust_thread_count()\n            return f\n        ...\n```\n\n_WorkItem은 작업 (fn), 인수들 (args 및 kwargs) 및 미래 객체 (_base.Future())를 함께 래핑하는 데 사용되는 객체입니다. 작업이 실행되고 결과가 Future 객체에 설정되는 run() 메서드를 구현합니다.\n\n```js\nclass _WorkItem:\n    def __init__(self, future, fn, args, kwargs):\n        self.future = future\n        self.fn = fn\n        self.args = args\n        self.kwargs = kwargs\n\n    def run(self):\n        if not self.future.set_running_or_notify_cancel():\n            return\n\n        try:\n            result = self.fn(*self.args, **self.kwargs)\n        except BaseException as exc:\n            self.future.set_exception(exc)\n            # 예외 'exc'와의 참조 순환을 끊습니다\n            self = None\n        else:\n            self.future.set_result(result)\n\n    __class_getitem__ = classmethod(types.GenericAlias)\n```\n\n<div class=\"content-ad\"></div>\n\nrun() 메서드는 작업자 스레드에서 호출됩니다. worker 모듈 함수인 _worker에 구현되어 있으며, 이 함수는 스레드에 대상으로 전달된 함수입니다.\n\n```js\ndef _worker(executor_reference, work_queue, initializer, initargs):\n    ...\n\n            if work_item is not None:\n                work_item.run()\n                # 객체에 대한 참조 삭제. GH-60488 참조\n                del work_item\n                continue\n\n            ...\n```\n\n스레드는 ThreadPoolExecutor 클래스 생성자에서 호출되는 _adjust_thread_count() 메서드에서 생성됩니다.\n\n```js\nclass ThreadPoolExecutor(_base.Executor):\n\n    def _adjust_thread_count(self):\n        ...\n        if num_threads < self._max_workers:\n            thread_name = '%s_%d' % (self._thread_name_prefix or self,\n                                     num_threads)\n            t = threading.Thread(name=thread_name, target=_worker,\n                                 args=(weakref.ref(self, weakref_cb),\n                                       self._work_queue,\n                                       self._initializer,\n                                       self._initargs))\n            t.start()\n            self._threads.add(t)\n            _threads_queues[t] = self._work_queue\n    ...\n```\n\n<div class=\"content-ad\"></div>\n\n## map() 메소드\n\nmap()은 Executor 클래스에 직접 구현되어 있으며 내부적으로 submit() 메소드를 사용합니다.\n\n```js\nclass Executor(object):\n    \"\"\"이것은 구체적인 비동기 executor를 위한 추상 기본 클래스입니다.\"\"\"\n    ...\n    def map(self, fn, *iterables, timeout=None, chunksize=1):\n        ...\n        fs = [self.submit(fn, *args) for args in zip(*iterables)]\n        ...\n```\n\nmap()은 스레드 풀에 작업을 제출하는 또 다른 방법입니다. 내장된 map(fn, *iterables) 함수와 유사하지만 fn으로 전달하는 함수는 비동기적으로 실행되며 fn에 대해 여러 호출을 동시에 수행할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n내장 map() 함수는 지연 평가를 제공합니다. 이는 해당 함수에서 반환된 iterable의 값들이 요청될 때에만 계산되고 반환된다는 것을 의미합니다.\n\n그러나 Executor.map(fn, *iterables)를 호출할 때에는 해당 함수가 제공된 iterable의 모든 항목을 미리 가져옵니다. 이는 필요시에만 처리되는 '지연 평가' 방식과 대조적입니다.\n\n이는 우리가 작업에서 값을 가져오기 위해 순서가 지정된 iterable에서 값들을 가져올 때 반복할 수 있는 iterator를 반환합니다.\n\n만약 timeout이 지정되지 않거나 None이면 대기 시간 제한이 없습니다. 따라서 반복을 시작할 때 첫 번째 요소가 이용 가능할 때까지 두 번째 요소에는 액세스하지 않습니다. timeout이 특정 int나 float로 설정된 경우 주어진 시간 초과 후 결과를 얻을 수 없는 경우 TimeoutError가 발생합니다.\n\n<div class=\"content-ad\"></div>\n\n만약 함수 호출이 예외를 발생시키면, 해당 예외는 반복자에서 값을 검색할 때 발생됩니다.\n\n예제를 살펴보겠습니다! 이 예제는 정말 멋지고, 제가 20번 정도 실행했어요 🤭\n\n기본적으로 ThreadPoolExecutor를 사용하여 5개의 워커 스레드로 위키피디아에서 20가지 이국적인 호주 동물을 로드합니다.\n\n특정 시점에는 하나의 스레드만 실행될 수 있지만, 5개의 스레드가 사용 가능합니다. 따라서 첫 번째 스레드가 실행을 시작하면 컨텍스트 스위치가 발생하고 두 번째 스레드가 시작할 수 있습니다. 왜냐하면 OS가 I/O 작업임을 감지하고 자원을 다른 스레드에 할당함으로써 시간 자원을 낭비하지 않습니다.\n\n<div class=\"content-ad\"></div>\n\n아래 표를 보면 언제나 동시에 5개의 스레드만 작동 중임을 알 수 있습니다. 하나의 스레드가 작업을 완료하면 다른 작업을 시작하기 위해 재사용됩니다. 작업을 완료하는 데는 4초 미만이 소요됩니다.\n\n![image](/assets/img/2024-06-22-ThreadinginPython_14.png)\n\n반면에, 만약 우리가 20마리의 호주 동물을 동기적으로 로드한다면 거의 15초가 걸립니다! 😱\n\n![image](/assets/img/2024-06-22-ThreadinginPython_15.png)\n\n<div class=\"content-ad\"></div>\n\n위 코드에서는 20가지의 이국적인 호주 동물을 확인할 수 있어요.\n\n```js\nimport concurrent.futures\nfrom time import perf_counter, time\nimport urllib.request\nimport logging\n\nfrom concurrency.utils import get_saving_path, postprocess_times\nfrom concurrency.visualize import barh\n\n\nformat = \"%(asctime)s: %(message)s\"\nlogging.basicConfig(format=format, level=logging.INFO, datefmt=\"%H:%M:%S\")\n\n\nURLS = [\n    \"https://en.wikipedia.org/wiki/Emu\",\n    \"https://en.wikipedia.org/wiki/Wombat\",\n    \"https://en.wikipedia.org/wiki/Kangaroo\",\n    \"https://en.wikipedia.org/wiki/Platypus\",\n    \"https://en.wikipedia.org/wiki/Koala\",\n    \"https://en.wikipedia.org/wiki/Tasmanian_devil\",\n    \"https://en.wikipedia.org/wiki/Echidna\",\n    \"https://en.wikipedia.org/wiki/Dingo\",\n    \"https://en.wikipedia.org/wiki/Kookaburra\",\n    \"https://en.wikipedia.org/wiki/Wallaby\",\n    \"https://en.wikipedia.org/wiki/Macrotis\",\n    \"https://en.wikipedia.org/wiki/Quokka\",\n    \"https://en.wikipedia.org/wiki/Cassowary\",\n    \"https://en.wikipedia.org/wiki/Sugar_glider\",\n    \"https://en.wikipedia.org/wiki/Laughing_kookaburra\",\n    \"https://en.wikipedia.org/wiki/Rainbow_lorikeet\",\n    \"https://en.wikipedia.org/wiki/Coastal_taipan\",\n    \"https://en.wikipedia.org/wiki/Mistletoebird\",\n    \"https://en.wikipedia.org/wiki/Thylacine\",\n    \"https://en.wikipedia.org/wiki/Quoll\",\n]\n\nanimals = {}\n\n\n# I/O-bound operation\ndef load_url(url: str) -> tuple[float]:\n    \"\"\"Retrieve a single page and return start and finish times.\"\"\"\n    start = perf_counter()\n    with urllib.request.urlopen(url) as conn:\n        animals[url] = conn.read()\n    finish = perf_counter()\n    return start, finish\n\n\ndef asynchronous_load_australian_animals() -> None:\n    start = time()\n    # Use ThreadPoolExecutor to manage concurrency\n    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n        # Use the map method to apply load_url to each URL\n        results = executor.map(load_url, URLS)\n\n        # Process the results and times\n        times = [time for time in results]\n        start_points, end_points = postprocess_times(times)\n    end = time()\n\n    total_time = round(end - start) + 1\n\n    barh(\n        title=\"비동기 실행, 5개 스레드, I/O 바운드 작업, 호주 동물\",\n        start_points=start_points,\n        end_points=end_points,\n        path=get_saving_path(\"thread-pool-executor/images/ThreadPoolExecutor_ex1.png\"),\n        n=len(URLS),\n        secs=total_time,\n    )\n\n\nif __name__ == \"__main__\":\n    logging.info(\"비동기 작업 초기화\")\n    asynchronous_load_australian_animals()\n    logging.info(f\"len(animals): {len(animals)}\")\n    logging.info(\"비동기 작업 완료\")\n```\n\nsubmit() 메서드를 사용하면 다음과 같이 보일 수 있지만, 실행할 때마다 많이 달라집니다.\n\n<img src=\"/assets/img/2024-06-22-ThreadinginPython_16.png\" />\n\n<div class=\"content-ad\"></div>\n\nas_completed() 함수를 사용하여 Future 인스턴스를 반복 처리해야 합니다. 그렇지 않으면 postprocess_times() 함수가 예외를 발생시킬 수 있습니다.\n\nas_completed() 함수는 결과로 제공된 Future 인스턴스에 대한 iterator를 반환하며 완료된 또는 취소된 Future를 생성합니다.\n\n```python\ndef asynchronous_load_australian_animals() -> None:\n    start = time()\n    # 동시성 관리를 위해 ThreadPoolExecutor 사용\n    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n        # submit 메서드를 사용하여 각 URL에 load_url을 적용\n        results = [executor.submit(load_url, url) for url in URLS]\n\n        # 결과 및 시간 처리\n        times = [result.result() for result in concurrent.futures.as_completed(results)]\n        start_points, end_points = postprocess_times(times)\n    end = time()\n\n    total_time = round(end - start) + 1\n```\n\n## shutdown() 메서드\n\n<div class=\"content-ad\"></div>\n\nThreadPoolExecutor을 with 문으로 context manager로 호출하면 shutdown() 메소드를 호출할 필요가 없습니다. 왜냐하면 shutdown() 메소드가 __exit__() 매직 메소드 내에서 호출되기 때문입니다. 그렇지 않으면 현재 대기 중인 futures가 실행을 완료한 후 사용 중인 모든 리소스를 해제해야 하는 executor에게 신호를 보내기 위해 호출해야 합니다.\n\n```js\nclass Executor(object):\n    \"\"\"이것은 구체적인 비동기 executor를 위한 추상 기본 클래스입니다.\"\"\"\n    ...\n    def __enter__(self):\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.shutdown(wait=True)\n        return False\n```\n\n이러한 도구들로 할 수 있는 일이 많습니다. Future 객체에는 프로그램 동작을 사용자 정의하는 데 사용할 수 있는 여러 메소드가 있습니다(예: cancel(), running(), done(), 등).\n\nconcurrent.futures 모듈에는 완료를 기다리도록 허용하는 wait() 함수도 제공됩니다. return_when 매개변수를 통해 반환할 시점을 지정할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n위에 나열한 자료들은 이 주제를 더 잘 이해하는 데 도움이 되었어요.\n\n언제든지 어떤 소셜 네트워크로든 연락 주세요. 피드백은 언제든지 환영합니다!\n\n읽어 주셔서 감사합니다 🙂\n\njavideveloper.com\n\n<div class=\"content-ad\"></div>\n\n# 기타 자료\n\n- 동시성 및 병렬성 소개\n- threading 모듈 문서\n- threading 모듈 소스 코드. Python 3.13\n- concurrent.futures 모듈 문서\n- concurrent.futures 모듈 소스 코드\n- queue 모듈 소스 코드\n- thread pool 위키백과\n- map(fn, *iterables) 내장 함수\n- concurrency-python 저장소\n- 파이썬 스레딩: SuperFastPython의 완전 가이드\n- Python의 ThreadPoolExecutor: SuperFastPython의 완전 가이드","ogImage":{"url":"/assets/img/2024-06-22-ThreadinginPython_0.png"},"coverImage":"/assets/img/2024-06-22-ThreadinginPython_0.png","tag":["Tech"],"readingTime":29},{"title":"주니어 엔지니어를 위한 지속적이고 내재된 학습 방법","description":"","date":"2024-06-22 02:39","slug":"2024-06-22-Continuousandembeddedlearningasajuniorengineer","content":"\n\n맥쿼리 그룹의 시니어 어소시에이트인 자밀라 사바조바입니다\n\n![image](/assets/img/2024-06-22-Continuousandembeddedlearningasajuniorengineer_0.png)\n\n## 개요\n\n기술의 역동적인 영역에서 시니어 엔지니어들의 지도와 강력한 학습 문화는 저의 주니어 엔지니어로서의 여정을 형성하는 데 중추적인 역할을 하였습니다.\n\n<div class=\"content-ad\"></div>\n\n2023년 맥쿼리에 시니어 어소시에이트 엔지니어로 합류한 이후로 여러 종류의 흥미로운 시스템, 클라우드 및 온프렘 시스템에 대해 배울 수 있는 기회를 가졌습니다. C++, Python, Java, Scala, React, JSON 및 YAML과 같은 다양한 프로그래밍 언어로 많은 시스템을 다루며 주로 리눅스 환경에서 실행됩니다. 컨테이너 오케스트레이션 플랫폼 및 관리형 관계형 데이터베이스와 같은 공개 클라우드 서비스를 활용합니다. 다양한 기술 스택과 개발환경에서 일하며 문제 해결 능력을 향상시키고 지속적인 학습과 성장을 위한 튼튼한 기반을 마련할 수 있다고 믿습니다.\n\n주니어 시절의 열정적인 학습자와 경험 많은 멘토 사이의 관계는 맥쿼리에서 번영하는 엔지니어링 문화에 기여합니다. 여기서는 C++로 작성된 맞춤형 거래 및 위험 플랫폼을 개발할 기회를 가지고 있습니다.\n\n본 글에서는 맥쿼리에서 엔지니어로서 성장하는 데 필수적인 세 가지 요인에 대해 살펴보겠습니다.\n\n## 지원하는 환경\n\n<div class=\"content-ad\"></div>\n\n팀 내에서는 주니어 엔지니어로서 처음에 바로 모든 것을 올바르게 할 수는 없다는 점을 이해하고 있습니다. 시니어 엔지니어들로부터의 지도를 받으면서 또한 배운 내용을 실천함으로써 중요성을 두는 환경 속에서, 우리는 이러한 경험을 통해 시스템을 개선하고 방향을 잡을 수 있는 기회를 얻게 됩니다.\n\n예를 들어, 제 팀이 기능 브랜치에서 겹치는 작업으로 인한 Git 버전 관리의 문제에 직면했을 때, 우리는 스택 방식을 도입하도록 협력했습니다. 단일 에픽 브랜치를 마스터로 사용하고 각자의 브랜치를 일관되게 리베이스해 나가면서, 워크플로우를 최적화하고 생산성을 크게 향상시킬 수 있었습니다. 이 예는 지원적인 학습 환경이 도전을 성장의 기회로 변화시킬 수 있다는 것을 보여줍니다.\n\n맥쿼리가 전문 개발에 대한 헌신을 나타내는 또 다른 사례는 내부 교육 제공을 통한 것입니다. 이러한 노력은 외부 벤더 트레이닝 기회 및 Coursera, Udemy와 같은 온라인 자원에 대한 접근을 통해 모든 맥쿼리 엔지니어가 클라우드 개발 및 아키텍처 스킬을 갖추도록 목표로 합니다.\n\n저는 아마존 사무실에서 개최된 'AWS 아키텍처 구축' 과정을 수강할 기회를 갖게 되어 직접적인 지원을 경험해볼 수 있었습니다. 이 과정은 AWS 대표에 의해 진행되었으며, 다양한 산업 및 기술 팀에서 전문가들의 다양한 필요에 부합하도록 설계되었습니다.\n\n<div class=\"content-ad\"></div>\n\n그러한 노력들은 귀중한 것이며, 우리의 기술 능력을 확장할 뿐만 아니라 리더들로부터 받는 신뢰를 증명합니다. 학습 문화는 우리가 최신 지식과 최상의 실천 방법을 갖추고 현장의 동적인 도전에 대처할 수 있도록 보장합니다. 이는 혁신이 일반적인 상황을 유지하고, 직원들이 자신들의 경력에서 새로운 높이에 이를 수 있도록 촉진합니다.\n\n맥쿼리는 우리의 전문적 발전을 적극적으로 지원하는 다양한 학습 포럼을 제공합니다:\n\n* 내부 기술 이벤트: 맥쿼리는 전 세계의 엔지니어링 길드, 점심시간 학습 세션 및 '엔지니어링 사무실 시간' - 매일 엔지니어들이 모여 서로 소프트웨어 관련 질문을 도와주는 전용 시간을 정기적으로 만드는 등 이러한 노력은 엔지니어링 커뮤니티에서 협업과 지식 공유를 촉진하며 업계의 최신 기술 동향과 최상의 실천 방법을 제공합니다.\n\n* 워크숍: 특정 기술이나 방법론에 대해 더 깊이 파고들기 위한 실습 세션을 진행하며, 프로젝트에 직접 적용할 수 있는 실용적인 경험과 지식을 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n- 맞춤형 교육: 내부 교육 프로그램은 주제 전문가에 의해 전달되며 제품 및 시스템이 어떻게 작동하는지 이해하는 데 도움이 됩니다. 다양한 엔지니어링 레벨에 맞게 설계된 구조화된 학습 경로를 통해 우리가 필요로 하는 리소스를 이해하고 발전하는 기술 스택에서 능숙해질 수 있도록 지원합니다.\n\n- 온라인 학습: 다양한 교육 도구를 제공하는 온라인 학습 플랫폼을 통해 기술 및 엔지니어링 분야에서 학습을 향상시키는 데 도움이 되는 광범위한 교육 도구 모음을 이용할 수 있습니다. 기술자들을 발전시키기 위해 특별히 디자인된 워크샵, 교육 세션 및 리소스가 제공됩니다.\n\n이러한 학습 기회는 다양한 학습 스타일을 고려하고 기술 전문가들과 상호작용할 수 있는 공간을 제공합니다. 맥쿼리 엔지니어는 이러한 포럼에서 얻은 지식을 실제 시나리오에 적용함으로써 지속적으로 기술을 향상시키고 혁신적인 프로젝트에 기여할 수 있습니다.\n\n## 다른 사람들의 경험을 활용하기\n\n<div class=\"content-ad\"></div>\n\n우리 CGM 비즈니스를 지원하는 시스템의 복잡한 코딩 풍경 속에서, 광범위한 코드베이스를 신속하게 이해하는 것은 내 전문 지식을 확장할 수 있는 기회였습니다. 한 번에, 독점 기술을 이해하는 것은 어려운 과제처럼 보였습니다. 그러나, 경험이 풍부한 개발자의 지침을 구하여 학습을 가속화시켰습니다. 팀원들이 제공한 예시는 복잡한 코드를 해석하는 데 도움이 되었을 뿐만 아니라 프로젝트에 의미 있는 기여를 할 수 있도록 했습니다. 우리 팀 내에서 경험을 활용하는 중요성을 강조했습니다.\n\n시니어 엔지니어들과 긴밀히 협업함으로써 실시간 데이터 처리와 복잡한 알고리즘 최적화와 같은 고급 기능들과 관여할 수 있는 기회가 있었습니다. 이 협업은 동시 컴퓨팅과 고장 허용 시스템과 같은 기술 스킬을 가속화시켰습니다. 이는 거래 플랫폼에서 중요한 부분입니다.\n\n우리 독점 기술을 현대화하는 과정에서, 기존 시스템과 통합 중인 최첨단 기술 모두를 배울 수 있는 독특한 기회를 가졌습니다. 내부 교육 아카데미는 엔지니어들이 이해하고 숙련하기 위한 구조적 학습 경로를 제공해줌으로써 매우 중요한 부분을 담당하고 있습니다.\n\n## 지속적인 학습과 발전\n\n<div class=\"content-ad\"></div>\n\n맥쿼리에서는 지속적인 학습에 대한 강조가 우리 문화 속에 자리 잡혀 있습니다. 클라우드 시험과 자격증을 위해 협력적으로 준비하는 스터디 그룹을 통해 우리는 집단 성장 문화를 육성하고 있습니다. 이러한 스터디 세션은 강의 자료를 탐구하고 챕터를 심층적으로 이해하며 어려움을 공동으로 해결할 수 있는 공간을 제공합니다. 이러한 역량 강화는 우리의 전문적 성장을 육성하는 데 중요한 역할을 합니다.\n\n준 엔지니어로서 우리는 최신 산업 지식과 새로운 기술을 경험할 수 있는 다양한 학습 기회를 제공받습니다. 맥쿼리는 주제 전문가들과 소통하고 배운 내용을 실제 상황에 적용할 수 있도록 지원함으로써 우리의 성장을 지원합니다.\n예를 들어, 최근 새 웹 애플리케이션을 구현하는 프로젝트에 참여할 기회를 얻었는데, 이를 통해 기술 발전에 대한 책임감을 느낄 수 있었습니다. 쿠버네티스 컨테이너와 리액트 프레임워크와 직접 작업하면서 프로젝트 전반을 이끌어 갈 수 있는 기회를 얻었습니다. 선임 엔지니어들로부터의 학습 기회와 기술적 시범이 나를 지원하고, 웹 애플리케이션의 GUI 디자인, 프론트엔드 기능과 기능성, 백엔드 데이터 관리, 테스트, 배포 등을 포함한 웹 애플리케이션을 만드는 방법에 대한 소중한 경험을 쌓을 수 있었습니다.\n\n## 결론\n\n맥콰리의 문화는 선임 전문가들이 다음 세대 엔지니어들을 키워내기 위해 시간과 경험을 투자하는 문화입니다. 내장형 학습 관행은 번창하는 엔지니어링 경력을 위한 견고한 기반을 형성합니다. 지식 공유와 지속적인 전문적 발전에 대한 확고한 헌신은 모든 수준의 엔지니어의 성장을 지원합니다.\n\n<div class=\"content-ad\"></div>\n\n학습을 촉진하고 최첨단 프로젝트에 참여할 수 있는 기회를 제공하는 데 헌신하는 태도 때문에 Macquarie가 이렇게 멋진 경력을 쌓을 수 있는 곳이 되었습니다. Macquarie와 같이 다양한 기술 스택을 다루는 것은 그저 흥미로운 기술적 연습 이상의 것입니다. 이는 경력 가능성, 리더십 역할의 기회, 기술 혁신의 최전선에 있는 기회를 제공합니다.\n\n더 알고 싶으세요? Macquarie에서의 경력이 어디로 안내해 줄 수 있는지 알아보세요.","ogImage":{"url":"/assets/img/2024-06-22-Continuousandembeddedlearningasajuniorengineer_0.png"},"coverImage":"/assets/img/2024-06-22-Continuousandembeddedlearningasajuniorengineer_0.png","tag":["Tech"],"readingTime":5},{"title":"Python Async Await  사용해본 후 배운 7가지 교훈","description":"","date":"2024-06-22 02:38","slug":"2024-06-22-PythonAsyncAwait7ThingsILearntAfterDealingWithThemForAWhile","content":"\n\n\n![이미지](/assets/img/2024-06-22-PythonAsyncAwait7ThingsILearntAfterDealingWithThemForAWhile_0.png)\n\n# 1) \"async def\"를 사용하면 비동기 함수를 작성할 수 있습니다\n\n```python\ndef hello():\n    return 'hello'\n\nprint(hello)  # <function hello at 0x100ce8e00>\n```\n\n^ 여기에 일반 함수가 있습니다\n\n\n<div class=\"content-ad\"></div>\n\n```python\nasync def hello():\n    return 'hello'\n\nprint(hello)  # <function hello at 0x102b58e00>\n```\n\n여기에 async def 키워드를 사용하여 생성된 비동기 함수가 있습니다. 출력했을 때에도 여전히 함수 형식으로 출력되는 것을 볼 수 있습니다.\n\n# 2) 비동기 함수 호출은 코루틴을 반환합니다.\n\n```python\ndef hello():\n    return 'hello'\n\nprint(hello())  # hello\n```\n\n<div class=\"content-ad\"></div>\n\n^ 일반 함수 호출 예입니다 - 'hello' 문자열을 반환하는단 뜻이에요\n\n```js\nasync def hello():\n    return 'hello'\n\nprint(hello())  \n\n# <coroutine object hello at 0x10276f320>\n\n# RuntimeWarning: coroutine 'hello' was never awaited\n```\n\n^ 일반 함수처럼 async 함수를 호출할 때 반환 값 대신 코루틴 객체가 반환됩니다.\n\n^ 또한 RuntimeWarning: coroutine 'hello' was never awaited 메시지가 표시됩니다 - 코루틴은 일반적으로 await를 사용하여 대기해야 합니다(잠시 후에 설명하겠습니다)\n\n<div class=\"content-ad\"></div>\n\n# 3) 코루틴의 의미\n\n코루틴은 일시적으로 일시 중단 및 재개될 수있는 특별한 기능인 함수입니다. 다른 작업이 실행 중일 때 일시 중단 및 재개될 수 있는 기능이기도 합니다. 또한 다른 코루틴에게 일시적으로 제어를 양도할 수도 있습니다.\n\n이를 통해 우리는 동시에 하나 이상의 작업을 동시에 실행할 수 있게 됩니다.\n\n# 4) “asyncio.run()”을 사용하여 코루틴을 직접 실행할 수 있습니다\n\n<div class=\"content-ad\"></div>\n\n```js\nasync def hello():\n    return 'hello'\n\nprint(hello())\n\n# <coroutine object hello at 0x10276f320>\n\n# RuntimeWarning: coroutine 'hello' was never awaited\n```\n\n^ 이것이 코루틴을 실행하는 방법이 아닙니다.\n\n```js\nimport asyncio\n\nasync def hello():\n    print('running hello coroutine')\n    return 'hello'\n\nasyncio.run(hello()) # running hello coroutine\n```\n\n^ 이것이 코루틴을 실행하는 방법입니다.\n\n<div class=\"content-ad\"></div>\n\n주의 — asyncio는 파이썬 표준 라이브러리의 일부이므로 Python과 함께 설치되어 있으며이 작동하도록 추가로 제3자 라이브러리를 설치할 필요가 없습니다. asyncio를 가져와서 사용할 수 있습니다.\n\n# 5) 코루틴 실행에 \"await\" 사용하기\n\nhello 코루틴과 main 코루틴이 있다고 가정해 봅시다.\n\n```python\nimport asyncio\n\nasync def hello():\n    print('hello 코루틴 실행 중')\n    return 'hello'\n\nasync def main():\n    x = await hello()\n    print(x)\n\nasyncio.run(main())    \n\n# hello 코루틴 실행 중\n# hello\n```\n\n<div class=\"content-ad\"></div>\n\n^ 다른 코루틴 메인 안에서 hello를 호출하려면 await 키워드를 사용해야 합니다.\n\nawait hello()를 \"hello()가 끝날 때까지 기다렸다가 반환 값을 x에 할당한다\"고 생각할 수 있습니다. 이것이 x를 출력할 때 hello를 얻는 이유입니다.\n\n# 6) \"await\"는 \"async def\"를 사용하여 정의된 함수에서만 사용할 수 있습니다\n\n```python\nimport asyncio\n\nasync def hello():\n    print('hello 코루틴 실행 중')\n    return 'hello'\n\nasync def test():\n    x = await hello()\n    print(x)\n\nasyncio.run(test())\n```\n\n<div class=\"content-ad\"></div>\n\n여기서는 일반 함수 테스트 안에 await를 사용하려고 시도했기 때문에 SyntaxError가 발생합니다.\n\nawait 키워드를 사용하려면 async def를 사용하여 정의된 async 함수 내에 있어야 합니다.\n\nasyncio.gather를 사용하여 둘 이상의 코루틴을 동시에 실행할 수 있습니다.\n\n```python\nimport asyncio\n\nasync def hello():\n    print('시작')\n    await asyncio.sleep(1)\n    print('끝')\n\nasync def main():\n    await asyncio.gather(hello(), hello(), hello())\n\nasyncio.run(main())\n\n# 시작\n# 시작\n# 시작\n# 끝\n# 끝\n# 끝\n```\n\n<div class=\"content-ad\"></div>\n\n- 이 스크립트를 실행할 때, 먼저 3개의 start가 출력됩니다.\n- 약 1초 지연 후, 3개의 end가 출력됩니다.\n\n무슨 일이 일어나고 있을까요?\n\n- asyncio.sleep(1)은 우리의 코루틴을 1초간 재우게 합니다.\n- asyncio.gather는 3개의 hello() 코루틴을 동시에 동시에 실행시킵니다.\n- 이것이 모든 start가 함께 출력되고, 모든 end도 함께 출력되는 이유입니다.\n\n# 만약 제작자로서 저를 지원하고 싶다면\n\n<div class=\"content-ad\"></div>\n\n- 이 이야기에 대해 50번 박수를 쳐주세요\n- 여러분의 생각을 말씀해 주세요\n- 이야기에서 가장 좋았던 부분을 강조해 주세요\n\n감사합니다! 이 작은 행동들이 큰 도움이 되고, 정말 감사드립니다!\n\nYouTube: https://www.youtube.com/@zlliu246\n\nLinkedIn: https://www.linkedin.com/in/zlliu/\n\n<div class=\"content-ad\"></div>\n\n제 Ebooks: [https://zlliu.co/ebooks](https://zlliu.co/ebooks)","ogImage":{"url":"/assets/img/2024-06-22-PythonAsyncAwait7ThingsILearntAfterDealingWithThemForAWhile_0.png"},"coverImage":"/assets/img/2024-06-22-PythonAsyncAwait7ThingsILearntAfterDealingWithThemForAWhile_0.png","tag":["Tech"],"readingTime":4},{"title":"Streamlit으로 Kaggle 같은 플랫폼을 만드는 방법 학생들을 위한 프로젝트 사례","description":"","date":"2024-06-22 02:33","slug":"2024-06-22-HowICreatedaKaggle-LikePlatformforMyStudentsUsingStreamlitandHowYouCanDoItasWell","content":"\n\n![How I Created a Kaggle-Like Platform for My Students Using Streamlit and How You Can Do It as Well](/assets/img/2024-06-22-HowICreatedaKaggle-LikePlatformforMyStudentsUsingStreamlitandHowYouCanDoItasWell_0.png)\n\n안녕하세요! 저는 Kaggle을 좋아하고 데이터 과학과 머신 러닝을 보급하는 데 그가 한 기여가 매우 갓큼하다고 믿습니다. 비디오 게임과 게임화를 즐기는 사람으로서, Kaggle의 랭킹 및 포인트 시스템이 참가자들이 건강하고 건설적인 경쟁을 통해 모델을 개선하도록 장려하는 방법을 인정합니다. Kaggle은 매우 인기가 높아져 많은 교수들이 기계 학습을 가르치는 데 선호하는 도구 중 하나로 Kaggle을 포함시켜왔다.\n\n그러나 기계 학습 강의를 하는 비즈니스 스쿨의 교수로서, Kaggle을 사용하여 학생들의 최종 기계 학습 프로젝트를 평가하는 도구로 사용하는 것이 조금은 복잡하다는 것을 느꼈습니다. 먼저, 학생들의 제출물을 추적하는 것이 지루하고 수동적이며, 제가 가르치는 학생들(대부분 데이터 과학 및 프로그래밍 초보자임을 유의해 주세요)이 자신들의 노력의 결과가 Kaggle 랭킹의 맨 아래에 배치된 것을 보는 것이 좌절스러울 수 있다고 생각합니다. 이러한 이유로 Kaggle이 가르치는 도구로 설계된 것은 아니라는 점을 인지하는 것이 중요하다고 생각합니다.\n\n항상 제 학생들에게 맞춤화된 Kaggle의 소형 버전을 만들고 싶어했습니다. 이 플랫폼은 Kaggle의 게임화 성공을 반영하고, 수학 프로그래밍 및 조합 최적화를 포함하여 여러 주제의 템플릿으로 서비스를 제공할 수 있게 해줍니다. 처음에는 일반적인 파이썬 웹 개발 프레임워크인 Django나 Flask를 사용하여 이러한 플랫폼을 구축하는 데 필요한 노력에 despondent해졌습니다.\n\n<div class=\"content-ad\"></div>\n\nStreamlit을 최근에 알게 되어서 정말 기뻤어요! Streamlit은 Google Sheets와 상호 작용할 수 있는 능력을 갖추고 있어요. 이 글에서는 Python, Streamlit, 그리고 Google Sheets를 사용하여 Kaggle과 유사한 웹 애플리케이션을 만들어 수업을 게임으로 변화시킬 수 있는 방법을 보여드릴 거에요. 이 앱을 통해 학생들은 개별 계정으로 로그인하고, CSV 파일을 업로드하여 해결책을 제출하고, 다양한 머신 러닝 메트릭을 기반으로 해결책을 평가하고, 제출물들의 순위를 동적으로 확인할 수 있어요. 무엇보다도, 무료로 이 앱을 배포하는 방법도 설명할 거에요.\n\n손을 더럽히며 배우시기 준비되셨나요? 최종 앱 결과물을 한 눈에 확인해 볼까요...\n\n![앱 결과물](https://miro.medium.com/v2/resize:fit:1200/1*SUhDDLi4ozYwvL1hoShNGA.gif)\n\n이 글이 길 수도 있음을 참고해 주세요. 가능한 한 자세하게 설명드리려고 노력하고 있어요. 데이터 과학 전문가일 필요는 없지만 Python에 서툰 교사나 교수님들에게 많은 도움이 될 수 있다고 생각하기 때문이에요. 이미 Python 전문가라면, 이 글은 건너뛰고 아래 프로젝트의 GitHub 저장소로 바로 이동하실 수도 있어요.\n\n<div class=\"content-ad\"></div>\n\n내가 학생들과 함께 구현한 원래 프로젝트에서 앱에는 세 가지 다른 기계 학습 섹션이 포함되어 있었습니다: 회귀 문제용 하나, 이진 분류 문제용 하나, 시계열 예측 문제용 하나입니다. 이 간단한 튜토리얼에서는 이 중 하나에 초점을 맞출 것입니다: UC Irvine Machine Learning Repository의 유명한 Pima 당뇨병 데이터셋을 사용한 이진 분류 문제입니다. 이 데이터셋은 Kaggle에서도 다운로드할 수 있습니다.\n\n## 기사 색인:\n\n- Streamlit과 Google Sheets\n- 앱 디자인\n- 앱 구현 및 배포\n- [1] — 프로젝트 환경 설정\n- [2] — Google Sheets 데이터베이스 설정\n- [3] — 데이터 개인 정보 및 보안\n- [4] — Google Sheets 연결 설정\n- [5] — 라이브러리, 상태 세션 변수 및 앱 구성\n- [6] — 로그인 모듈\n- [7] — 결과 제출 모듈\n- [8] — 동적 순위 매기기 모듈\n- [9] — 제출 로그 모듈\n- [10] — 앱 배포\n- 현실 성과\n- 결론\n- 참고 문헌\n\n# Streamlit과 Google Sheets\n\n<div class=\"content-ad\"></div>\n\n2023년 1.28 버전부터 Streamlit은 사용자가 st.connection 메서드를 사용하여 Google Sheets에 연결할 수 있게 되었습니다. 이 방법을 사용하면 Google Sheets를 데이터베이스로 활용하여 CRUD (생성, 읽기, 업데이트, 삭제) 작업을 수행할 수 있습니다. 이 기능에 대해 알게 된 것은 Sven | Coding Is Fun이 만든 YouTube 비디오에서 알게 되었습니다. 시청하고 싶다면 아래 링크를 남겨 놓겠습니다.\n\n당신이 생각하는 것을 알겠어요. 하지만 겁먹지 마세요. Excel (Google Sheets)이 데이터베이스가 아님을 잘 알고 있습니다. 그리고 동의합니다. 회사가 데이터베이스로 사용하는 것에 대해 악몽을 꾸기도 합니다. 그러나 우리가 만들고자 하는 앱을 위해서는 충분히 좋습니다. 필요한 모든 작업을 수행할 수 있으며 온라인에서 사용할 수 있으며, 개인 정보를 보호해줍니다 (우리와 앱만 액세스할 수 있음 — 제 구글 계정을 해킹할 만한 능력이 있는 사람이 아니라면), 그리고 가장 중요한 것은 무료입니다. 이 부분을 개선할 수 있는 여지가 있다는 것을 인지하고 있으며, Google Sheets를 Supabase와 연결하는 가능성을 탐색하고 있습니다.\n\n![image](/assets/img/2024-06-22-HowICreatedaKaggle-LikePlatformforMyStudentsUsingStreamlitandHowYouCanDoItasWell_1.png)\n\n구현에 바로 들어가기 전에, 앱이 반드시 갖춰야 할 다른 모듈들과 구현 전략을 신중하게 검토하는 것이 중요합니다.\n\n<div class=\"content-ad\"></div>\n\n# 앱 디자인\n\n저희가 만들고자 하는 앱은 여러 과정을 필요로 합니다. 먼저, 오직 우리 학생들만이 액세스할 수 있도록 보장하기 위해 로그인 시스템이 필요합니다. 사용자가 로그인하면 결과를 제출할 모듈이 필요합니다. 이에는 .csv 파일을 업로드하는 과정, 파일이 예상되는 행 수와 요청된 열과 일치하는지 확인하는 과정, 모델 예측과 실제 테스트 데이터 간의 평가 지표를 계산하는 과정이 필요합니다. 이후 학생은 강의실 순위와 결과를 동료들과 비교할 수 있는 기능이 있어야 합니다. 마지막으로 학생은 그룹 프로젝트이기 때문에 모든 제출물과 팀원들의 제출물을 볼 수 있어야 합니다. Figure 3은 앱의 사용자 플로우 다이어그램의 전반적인 개요를 보여줍니다.\n\n<img src=\"/assets/img/2024-06-22-HowICreatedaKaggle-LikePlatformforMyStudentsUsingStreamlitandHowYouCanDoItasWell_2.png\" />\n\n# 앱 구현\n\n<div class=\"content-ad\"></div>\n\n이 앱에는 Visual Studio Code를 사용할 것입니다. 귀하는 귀하의 기기에 새 프로젝트 폴더를 만들고 해당 폴더에서 Visual Studio Code를 열 것을 강력히 권장합니다. 제 경우에는 폴더 이름을 project_app_medium으로 지정하기로 결정했습니다.\n\n## 프로젝트 환경 설정\n\n다른 Python 프로젝트와의 의존성 충돌을 피하기 위해 각 Streamlit 앱을 위한 가상 환경을 생성하는 것을 강력히 권장합니다. 가상 환경을 생성하고 활성화한 후 아래 라이브러리를 설치해야 합니다.\n\n```js\npandas == 1.5.3\nnumpy == 1.26.4\nmatplotlib\nstreamlit\nstreamlit_option_menu\nstreamlit-extras\nst-gsheets-connection\nscikit-learn\n```\n\n<div class=\"content-ad\"></div>\n\n라이브러리를 설치하려면 새 텍스트 파일을 만들고 requirements.txt라는 이름을 지정하십시오. 이 비어 있는 텍스트 파일 안에 위에 나열된 라이브러리들을 복사하여 저장하세요; 우리 앱을 배포할 때 이 파일이 필요합니다. 그런 다음 터미널에 다음 명령어를 입력하세요.\n\n```js\npip install -r requirements.txt\n```\n\n이 명령은 requirements.txt 파일에 나열된 모든 라이브러리를 설치합니다. 우리가 사용하는 라이브러리에 대해 설명하자면, 모든 데이터 과학 프로젝트의 \"미레푸아\"로 시작하는 것이 좋습니다: numpy, pandas 및 matplotlib이 있습니다. 또한 streamlit이 필요합니다, 이는 우리의 프레임워크를 포함하는 기본 라이브러리입니다. Streamlit의 기능을 확장하기 위해 streamlit_option_menu와 같은 커뮤니티에서 개발된 확장들을 가져올 것입니다. 이는 간단한 사이드바 메뉴를 만들 수 있는 streamlit_option_menu와 맞춤화 기능을 많이 포함하는 streamlit-extras가 있습니다. 추가로 st-gsheets-connection를 사용하여 Google Sheets와 연결하는 데 도움을 줄 것입니다. 위에 나열된 라이브러리들 외에도 데이터 보안 및 보호를 위해 hashlib를 사용할 것입니다. 데이터베이스의 세부 정보를 정의할 때 더 자세히 이야기하겠습니다.\n\n이 튜토리얼 동안 다음 폴더 구조가 사용되며 다음 구성 요소가 포함됩니다.\n\n<div class=\"content-ad\"></div>\n\n- .streamlit: 이 폴더에 Streamlit 관련 설정이 저장됩니다. 이 폴더 안에는 Google Sheets API와 연결하기 위해 필요한 인증 정보가 포함된 secrets.toml 파일이 저장됩니다.\n- app.py: 메인 Streamlit 스크립트입니다.\n- .gitignore: Git에서 무시할 파일들이름대로, 프로젝트 커밋 시 무시됩니다.\n- logo.png (선택 사항): 회사 로고가 있는 이미지로, 앱의 사이드바 메뉴 상단에 표시됩니다. 완전히 선택 사항이며, 저는 제 회사 SAVILA GAMES 로고를 표시하고 있습니다.\n- requirements.txt: 앱을 실행하는 데 필요한 Python 종속성입니다.\n- README.md: 프로젝트 설명\n\n\nproject_app_medium/\n│\n├── .streamlit/                # 일반 Streamlit 설정\n│   └── secrets.toml           # Google Sheets 연결에 필요한 인증 정보\n├── app.py                     # 앱 코드\n├── .gitignore\n├── logo.png               \n├── requirements.txt           # Python 종속성\n└── README.md \n\n\n## Google Sheets 데이터베이스 설정\n\n환경이 설정되었으니, Google Sheets 데이터베이스 구조를 만들어야 합니다. Google Sheets 앱을 열고 새 파일을 만들어주세요. 저는 프로젝트 데이터베이스라고 이름 지었습니다. 그리고 파일에 네 개의 탭을 만드세요. 첫 번째로 \"users\" 탭은 모든 사용자 로그인 자격 증명과 사용자 그룹 구성 정보를 포함할 것입니다. 이 탭의 정보를 사용하여 애플리케이션의 로그인 모듈을 만들 것입니다. 탭은 다음과 같은 열 구조여야 합니다:\n\n<div class=\"content-ad\"></div>\n\n```js\n| email                  | name    | last name | password  | group    |\n|------------------------|---------|-----------|-----------|----------|\n| john.doe@example.com   | John    | Doe       | Pass1234  | G1       |\n| jane.smith@example.com | Jane    | Smith     | SecurePwd | G2       |\n| alex.jones@example.com | Alex    | Jones     | MyPass789 | G1       |\n| emma.brown@example.com | Emma    | Brown     | Emma12345 | G3       |\n```\n\n다음 탭은 “log” 탭입니다. 이 탭은 사용자가 제출한 작업의 과거 정보를 저장할 것입니다. 또한 랭킹 및 이력 제출 모듈의 로직을 위해서도 사용될 것입니다. 이 탭은 다음과 같은 열 구조를 가져야 합니다:\n\n```js\n| user                  | group     | time             | score |\n|-----------------------|-----------|------------------|-------|\n| john                  | G1        | 2024-06-17 10:00 | 0.85  |\n| jane                  | G2        | 2024-06-17 11:00 | 0.72  |\n| alex                  | G1        | 2024-06-17 12:00 | 0.90  |\n| emma                  | G3        | 2024-06-17 13:00 | 0.65  |\n```\n\n다음 탭은 “test_data” 탭입니다. 이 탭은 학생들이 제출한 출력물의 품질을 평가하는 데 사용되는 실제 테스트 y 데이터를 포함할 것입니다. 이 튜토리얼에서는 Pima 데이터세트를 분할하고 마지막 78행을 테스트 데이터 세트로 선택할 것입니다. 이 탭은 이진 결과 데이터만 포함하며 다음과 같은 열 구조를 갖게 될 것입니다:\n\n<div class=\"content-ad\"></div>\n\n```js\n| y          |\n|------------|\n| 0          |\n| 1          |\n| 1          |\n| 0          |\n```\n\n마지막으로 만들 표는 'configuration' 탭입니다. 이 탭에는 프로젝트에 대한 사용자 정의 가능한 매개변수가 포함될 것입니다. 이러한 매개변수에는 마감일과 팀 당 하루에 허용된 시도 횟수가 포함될 수 있습니다 (참고로, Kaggle은 팀 당 하루에 다섯 번의 시도를 허용합니다). 이 탭을 통해 프로젝트 특성을 동적으로 변경하여 서로 다른 학기에 쉽게 적용할 수 있습니다. \"configuration\" 탭은 하나의 행만 있고 다음과 같은 열 구조를 가져야 합니다:\n\n```js\n| deadline              | max_per_day     |\n|-----------------------|-----------------|\n| 2024-07-01 23:59      | 5               |\n```\n\n이 튜토리얼 프로젝트에서 사용된 구글 시트의 예제를 다음 링크를 클릭하여 다운로드하고 확인할 수 있습니다:\n\n\n<div class=\"content-ad\"></div>\n\n## 데이터 개인 정보 보호 및 보안\n\n이것은 우리가 통제하고 우리 학생들만 이용할 수 있는 작은 프로젝트입니다. 그러나 학생들의 개인 정보에 대한 데이터 보안에 대해 주의를 기울여야 합니다. 만약 어떤 이유로인지 데이터베이스가 유출되어 사기꾼이나 악의적인 주체들의 손에 넘어간다면 상황은 어떨까요? 우리 학생들의 이름, 이메일 및 비밀번호에 접근할 수 있다면 그들을 위험에 빠트릴 수 있습니다. 그러므로, 이러한 상황이 발생해도 데이터가 이 악의적인 주체들에게는 의미가 없도록 보장해야 합니다.\n\n최소 비용으로 이러한 시스템을 구현할 수 있는지 궁금해 할 수 있습니다. 이것이 해싱과 hashlib 라이브러리가 구원해줍니다.\n\n해싱은 입력 데이터를 수학적 알고리즘을 사용하여 일정 크기의 문자열, 일반적으로 해시 코드로 변환하는 과정입니다. 데이터 무결성을 보장하고 빠른 데이터 검색을 용이하게 하며 민감한 정보를 안전하게 보관합니다. 사용 가능한 해싱 알고리즘은 무엇이 있을까요? 다행히 파이썬에는 hashlib를 포함해 여러 해싱 알고리즘을 제공하는 라이브러리가 함께 제공됩니다.\n\n<div class=\"content-ad\"></div>\n\n- MD5 (md5)\n- SHA-1 (sha1)\n- SHA-224 (sha224)\n- SHA-256 (sha256)\n- SHA-384 (sha384)\n- SHA-512 (sha512)\n- SHA-3 family (sha3_224, sha3_256, sha3_384, sha3_512)\n- BLAKE2 family (blake2b, blake2s)\n\n저희 튜토리얼에서는 hashlib에서 제공하는 사용 가능한 해싱 알고리즘 중 하나인 SHA-256을 사용하여 학생들의 이메일과 비밀번호를 해시 코드로 변환할 것입니다. 이 해시 코드는 데이터베이스에 저장될 것입니다. 이렇게 함으로써, 데이터베이스가 누출되더라도 그들의 데이터는 보호될 것입니다. 해싱의 장점은 해싱된 코드를 브루트 포스를 통해 원래 정보로 역으로 변환하는 것이 사실적으로 매우 어렵다는 사실에 있습니다. 이메일이 SHA-256을 사용하여 해싱된 경우, 이전 섹션의 이메일은 안전하고 해독 불가능한 것으로 됩니다.\n\n```js\n# 원본 이메일\n\n['john.doe@example.com',\n 'jane.smith@example.com',\n 'alex.jones@example.com',\n 'emma.brown@example.com']\n```\n\n```js\n# 해싱된 이메일\n\n['836f82db99121b3481011f16b49dfa5fbc714a0d1b1b9f784a1ebbbf5b39577f',\n 'f2d1f1c853fd1f4be1eb5060eaae93066c877d069473795e31db5e70c4880859',\n '134318bc6349ad35d7e6b95123898eecdd437ad9b0c49cc4bdd66a811afc6909',\n 'd41d9b2f5671358bc6faf79b7435b4a9805a72d012f06d4804815328f39aed1e']\n```\n\n<div class=\"content-ad\"></div>\n\n인식하기가 꽤 어려운 게 아닌가요? 아래에서 데이터프레임과 열이 주어지면 지정된 열의 해시된 항목을 반환하는 함수를 찾을 수 있습니다. 이렇게 하면 데이터베이스 정보를 해싱하고 이 값을 온라인 구글 시트 데이터베이스에 저장할 수 있습니다.\n\n```js\nimport hashlib\n\ndef hashit(df, column):\n  return_list = []\n  for data in df[column].tolist():\n    hash_object = hashlib.sha256()\n    hash_object.update(data.encode())\n    return_list.append(hash_object.hexdigest())\n\n  return return_list\n```\n\n일반적으로 생각할 수 있겠지만, 만약 유저들이 사용자 이름과 비밀번호를 알고 있다면 학생 중 한 명으로 사칭할 수 있을 거라고 생각할 수 있습니다. 그러나 이 상황은 이미 고려되었습니다. 학생들은 우리가 제공한 이메일 주소와 비밀번호로 앱에 로그인하지만, 실제 이메일과 암호를 로그인 화면에 입력합니다. 그런 다음 앱은 그들의 로그인 자겁을 가져와 SHA-256을 사용하여 이를 해싱한 후 해싱된 결과를 데이터베이스와 대조합니다.\n\n따라서 데이터베이스가 유출되고 누군가 정보를 사용하여 로그인을 시도하더라도, 그것이 작동하지 않을 것입니다. 왜냐하면 그들의 입력이 다시 해싱되어 저장된 해시와 일치하지 않기 때문입니다. 아래의 코드와 출력 예시를 살펴봅시다.\n\n<div class=\"content-ad\"></div>\n\n```js\n비밀번호 = \"password\"\n해시_객체.update(비밀번호.encode())\n해싱된_비밀번호 = 해시_객체.hexdigest()\n\nprint(해싱된_비밀번호)\n```\n\n출력 결과:\n\n```js\n\"5377a16433598554e4a73a61195dbddea9d9956a22df04c3127c698b0dcdee48\"\n```\n\n이제 이미 해싱된 비밀번호를 다시 해싱하면 아래 코드와 같이 됩니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nhash_object.update(hash_password.encode())\ndouble_hash_password = hash_object.hexdigest()\nprint(double_hash_password)\n```\n\n다음과 같은 결과를 얻습니다:\n\n```js\n\"dfd4bb46c954f3802c7c2385b1a6b625b3cf0b4ce6adf59d3eec711c293994bb\"\n```\n\n이 두 암호가 일치하지 않는 것을 쉽게 확인할 수 있습니다. 이전에 해싱된 비밀번호를 다시 해싱하면 완전히 새로운 결과가 생성되는 것을 보실 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## Google Sheets 연결 설정하기\n\n연결을 설정하는 데 필요한 모든 지침은 st-gsheets-connection 패키지의 GitHub 리포지토리에서 찾을 수 있습니다. 함께 지침을 따라봅시다:\n\n- Google 개발자 콘솔로 이동하여 새 프로젝트를 만듭니다. Google Cloud 아이콘 바로 옆에는 드롭다운 메뉴가 있습니다. 클릭한 다음 \"새 프로젝트 만들기\"를 클릭합니다. 프로젝트 이름은 자유롭게 지정할 수 있습니다; 저의 경우에는 project_app_medium로 지정하겠습니다.\n\n![Alt text](https://miro.medium.com/v2/resize:fit:1200/1*cB8ePsTHYUxlcVs23UGd4w.gif)\n\n<div class=\"content-ad\"></div>\n\n- 이제 선택한 프로젝트로 두 가지 다른 API를 활성화해야 합니다: Google 드라이브 및 Google 시트. 페이지 상단의 검색 창에 \"Google 드라이브\"를 입력하고 API를 선택한 다음 \"활성화\"를 클릭하세요. Google 시트에 대해서도 동일한 단계를 반복하세요.\n\n![이미지](https://miro.medium.com/v2/resize:fit:1200/1*qzHDsIgXl7UYbFpztJuBmg.gif)\n\n- 프로젝트 API가 활성화된 상태에서 이제 이에 접근할 수 있는 기술 사용자를 생성해야 합니다. \"자격 증명\"을 클릭한 후 \"자격 증명 생성\"을 클릭하고 \"서비스 계정\" 옵션을 선택하세요. 기술 사용자에게 이름을 할당하세요. 저의 경우에는 \"medium-project-google-sheets\"로 이름을 지었습니다. 기술 사용자에게 \"편집자\" 역할을 할당하고 마지막으로 \"완료\"를 클릭하세요.\n\n![이미지](https://miro.medium.com/v2/resize:fit:1200/1*q-X587bUfw893wKpAygU9w.gif)\n\n<div class=\"content-ad\"></div>\n\n- 기술 사용자가 생성되었으므로, 이 사용자의 자격 증명을 생성해야 합니다. 방금 만든 사용자를 클릭한 후 \"Keys\"를 클릭하고, \"Add Key\"를 클릭한 다음 \"Create New Key\"를 선택하십시오. JSON 옵션을 선택하고 \"Done\"을 클릭하세요. 그러면 앱에서 Google Sheets를 사용하는 데 필요한 모든 자격 증명이 포함된 JSON 파일이 자동으로 다운로드됩니다.\n\n![이미지](https://miro.medium.com/v2/resize:fit:1200/1*-364Zn18VbaeLdU0uXMvaA.gif)\n\n- 마지막 단계는 방금 다운로드한 자격 증명을 secrets.toml 파일에 저장하는 것입니다. 아직 수행하지 않았다면 프로젝트 폴더 안에 .streamlit이라는 새 폴더를 만드세요. 이 폴더 안에 secrets.toml이라는 새 파일을 생성하세요. 선택한 텍스트 편집기(예: VS Code)로 파일을 열고 아래 정보를 붙여넣으세요.\n\n```js\n# .streamlit/secrets.toml\n\n[connections.gsheets]\nspreadsheet = \"<스프레드시트 이름 또는 URL>\"\nworksheet = \"<워크시트 GID 또는 폴더 ID>\" # 워크시트 GID는 공개 스프레드시트 URL을 사용할 때 사용되며, service_account를 사용할 때에는 폴더 ID로 선택됩니다.\ntype = \"\" # 공개 스프레드시트 URL을 사용할 때는 비워두세요. service_account를 사용할 때 -> type = \"service_account\"\nproject_id = \"\"\nprivate_key_id = \"\"\nprivate_key = \"\"\nclient_email = \"\"\nclient_id = \"\"\nauth_uri = \"\"\ntoken_uri = \"\"\nauth_provider_x509_cert_url = \"\"\nclient_x509_cert_url = \"\"\n```\n\n<div class=\"content-ad\"></div>\n\n- secrets.toml 파일의 각 요소를 Google에서 다운로드한 JSON 자격 증명 파일의 데이터로 대체하세요. \"spreadsheet\" 필드에는 프로젝트용으로 만든 Google 스프레드 시트 데이터베이스의 URL을 복사하세요. 그다음 JSON 파일에서 \"client_email\" 데이터를 복사하고 Google 스프레드 시트 데이터베이스로 이동하세요. 스프레드 시트에서 \"공유\"를 클릭한 다음 \"client_email\"을 텍스트 입력란에 붙여넣기하고, \"편집자\" 권한이 선택되어 있는지 확인한 후 \"전송\"을 클릭하세요.\n\n이 모든 준비가 끝나면 이제 앱을 코딩할 준비가 되었습니다.\n\n## 라이브러리, 상태 세션 변수 및 앱 구성\n\n이제 앱에 필요한 라이브러리를 가져와 앱이 사용할 세션 상태 변수를 만들 것입니다. 대부분의 세션 상태 변수는 로그인 모듈과 관련이 있을 것입니다. Streamlit에서 세션 상태 변수는 세션 내의 다른 상호 작용 사이에서 정보를 저장합니다. 이 정보는 사용자 입력 또는 선택과 같은 상태를 유지하여 앱을 다시 실행할 때마다 유지하는 데 도움이 됩니다. 처음에는 이러한 변수를 빈 문자열로 설정하고 앱이 실행됨에 따라 업데이트될 것입니다. 우리의 특정 앱에서는 사용자 이름(학생 이메일을 사용), 비밀번호 및 사용자가 속한 그룹을 위한 상태 변수를 만들 것입니다. 또한 st.set_page_config() 메서드를 사용하여 페이지 제목과 페이지 아이콘(favicon)을 설정할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport datetime\nfrom pathlib import Path\nimport streamlit as st\nfrom streamlit_option_menu import option_menu\nfrom streamlit_extras.add_vertical_space import add_vertical_space\nfrom streamlit_extras.stylable_container import stylable_container \nfrom streamlit_gsheets import GSheetsConnection\nfrom sklearn import metrics\nimport hashlib\n\nif 'user_name' not in st.session_state:\n    st.session_state['user_name'] = ''\n\nif 'student_name' not in st.session_state:\n    st.session_state['student_name'] = ''\n\nif 'password' not in st.session_state:\n    st.session_state['password'] = ''\n\nif 'group' not in st.session_state:\n    st.session_state['group'] = ''\n\nst.set_page_config(\n        page_title='Medium Project', \n        page_icon='📈' \n    )\n```\n\n작업이 정상적으로 진행되고 있는지 테스트하려면 다음 명령어를 터미널에서 실행하여 디렉토리 루트에서 애플리케이션을 실행할 수 있습니다. 이렇게 하면 로컬호스트에서 앱이 실행됩니다.\n\n```js\nstreamlit run app.py\n```\n\n\"Medium Project\"라는 빈 페이지와 선택한 파비콘 📈이 표시된 Figure 8이 나타납니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-22-HowICreatedaKaggle-LikePlatformforMyStudentsUsingStreamlitandHowYouCanDoItasWell_3.png\" />\n\n## 로그인 모듈\n\n이제 세션 상태 변수가 생성되었으니, 앱의 첫 번째 모듈인 로그인 모듈을 코드로 작성할 수 있습니다. 이 모듈은 Figure 9에 설명된 논리를 포함할 것입니다.\n\n<img src=\"/assets/img/2024-06-22-HowICreatedaKaggle-LikePlatformforMyStudentsUsingStreamlitandHowYouCanDoItasWell_4.png\" />\n\n<div class=\"content-ad\"></div>\n\n먼저, Google Sheets 데이터베이스와 연결을 설정할 것입니다. 그다음, st.sidebar 방법을 사용하여 옵션_메뉴 방법과 결합하여 사이드바 내비게이션 메뉴를 만들어 앱의 다른 페이지를 쉽게 생성할 수 있게 할 것입니다. 이 설정이 완료되면 로그인 모듈의 로직을 구성할 것입니다.\n\n사용자가 로그인되어 있지 않은 경우, 다음 모듈에 액세스하는 것을 방지할 것입니다. 로그인 모듈에서 사용자 이름(이메일)과 비밀번호를 요청할 것입니다. 이 자격 증명은 데이터베이스와 일치하는지 확인됩니다. 일치하는 경우, 사용자 자격 증명은 세션 상태 변수에 저장되고 사용자는 성공적인 로그인이 확인된 메시지를 받게 됩니다. 일치하지 않는 경우 사용자는 로그인에 실패했다는 경고 메시지를 받게 됩니다. 또한 데이터베이스로부터 프로젝트 구성 데이터(프로젝트 마감일 및 하루 최대 제출 횟수)를 저장할 것입니다. 위의 논리는 아래 코드를 따라 구현됩니다.\n\n```js\n테이블 태그를 마크다운 형식으로 변경하실 수 있습니다.'''\n## 제출 결과 모듈\n```\n\n<div class=\"content-ad\"></div>\n\n지금은 로그인 모듈이 준비되어 있으므로, 제출 모듈을 만들어 나갈 수 있습니다. 이 모듈에서는 학생들이 모델의 예측 결과를 담은 CSV 파일을 업로드할 수 있습니다. 이 모듈에는 Figure 10에 설명된 로직이 포함될 것입니다.\n\n![Figure 10](/assets/img/2024-06-22-HowICreatedaKaggle-LikePlatformforMyStudentsUsingStreamlitandHowYouCanDoItasWell_5.png)\n\n프로젝트 마감 기한이 지나지 않았고 해당 팀이 하루 최대 제출 횟수를 초과하지 않은 경우에만 학생들이 이 모듈에 접근할 수 있습니다 (앱 스팸 방지 및 테스트 데이터셋에 과적합되는 위험을 피하기 위함). 이 중 하나라도 만족하지 않는 경우, 학생은 해당 문제를 안내하는 경고를 받게 됩니다. 모든 조건이 충족된다면, 학생은 CSV 파일을 업로드하여 결과물을 제출할 수 있습니다. 파일의 형태가 요구 사항(테스트 데이터셋 크기와 동일한 행의 수, 그리고 \"predictions\"이라는 열이 포함)와 일치하는 경우 제출이 승인될 것입니다. 형태가 일치하지 않는 경우, 학생은 문제에 대한 자세한 내용을 담은 경고 메시지를 받게 됩니다.\n\n모든 것이 일치하는 경우, 모듈은 모델 평가 지표를 계산할 것입니다. 이 특정 케이스에서는 정확도 점수를 사용하고 있지만 원하는 경우 F1 점수를 사용할 수도 있습니다. 코드를 쉽게 수정할 수 있습니다. 이 작업을 마친 후, 모듈은 학생의 제출을 구글 시트 데이터베이스의 \"log\" 탭에 저장할 것입니다. 위의 로직은 아래의 코드를 따라 구현될 것입니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nif selected == '결과 제출':\n\n  st.markdown(\"\"\"\n      <style>\n      div[data-testid=\"stMetric\"] {\n          background-color: #EEEEEE;\n          border: 2px solid #CCCCCC;\n          padding: 5% 5% 5% 10%;\n          border-radius: 5px;\n          overflow-wrap: break-word;\n      }\n      </style>\n      \"\"\"\n      , unsafe_allow_html=True)\n\n  st.header('예측 결과 제출')\n  st.subheader(\"머신러닝 분류\")\n  st.divider()\n  st.subheader(f\" 남은 시간: {days} 일, {hours} 시간 및 {minutes} 분\")\n  st.divider()\n\n  if st.session_state['user_name'] == '':\n      st.warning('프로젝트 솔루션을 제출하려면 로그인하세요')\n  else:\n          \n      group_log_df = conn.read(worksheet=\"log\", usecols=list(range(log_df_n_cols)), ttl=1).dropna(how=\"all\")\n      group_log_df = group_log_df[group_log_df['group'] == st.session_state['group']]\n      group_log_df['time'] = pd.to_datetime(group_log_df['time'])\n\n      test_data = conn.read(worksheet=\"test_data\", usecols=list(range(1)), ttl=30).dropna(how=\"all\")\n      test_data_y = test_data['y']\n\n      n_test = len(test_data)\n\n      current_date = pd.Timestamp.today()\n\n      submissions_count = group_log_df[(group_log_df['time'].dt.date == current_date.date())].shape[0]\n\n      time_diff = deadline - current_date\n      time_diff = time_diff.dt.total_seconds().iloc[0]\n\n\n      if time_diff <= 0:\n          st.warning('죄송합니다. 이미 마감된 프로젝트 기한으로 더 이상 제출할 수 없습니다')\n      else:\n          if submissions_count >= max_per_day:\n              st.warning(f'죄송합니다. 팀이 하루에 {submissions_count}번 이미 제출하여 하루 제출 한계를 초과했습니다')\n          else:\n\n              user_file = st.file_uploader(\"예측 파일을 업로드하세요\",type=['csv'])\n              st.caption(f\"당신의 파일은 'predictions'라는 적어도 하나의 열과 {n_test}개의 행이 필요합니다\")\n\n              if user_file is not None:\n\n                  submit_pred = st.button('제출',type=\"primary\",key=\"submit_pred\")\n\n                  if submit_pred:\n\n                      pred_df = pd.read_csv(user_file) \n\n                      if 'predictions' not in pred_df.columns.to_list():\n                          st.error('죄송합니다. 파일에 \"predictions\" 열이 없습니다', icon=\"🚨\")\n                      elif len(pred_df) != n_test:\n                          st.error(f'죄송합니다. 파일의 행 수({len(pred_df)})가 예상 길이({n_test})와 일치하지 않습니다', icon=\"🚨\")\n                      else:\n                          with st.spinner('소금 구륗기 해결책 데이터베이스에 업로드 중'):\n                              user_predictions = pred_df['predictions']\n\n                              timestamp = datetime.datetime.now()\n                              timestamp = timestamp.strftime(\"%d/%m/%Y, %H:%M:%S\")\n                              st.write(f'제출일: {timestamp}')                \n                      \n                              ACC = metrics.accuracy_score(test_data_y,user_predictions)\n\n                              F1 = metrics.f1_score(test_data_y,user_predictions)\n\n                              cm = pd.DataFrame(metrics.confusion_matrix(test_data_y,user_predictions),\n                                              columns = [\"T 예측\",\"F 예측\"],index=[\"T 실제\",\"F 실제\"])\n\n                              columns_part_2 = st.columns(3)\n\n                              with columns_part_2[0]:\n                                  st.metric(\"정확도\",f\"{100*ACC:.1f} %\")\n                              with columns_part_2[1]:\n                                  st.metric(\"F1-점수\",f'{F1:.3f}')\n                              \n                              with columns_part_2[2]:\n                                  st.dataframe(cm,use_container_width=True)\n\n                              solution_dict = dict()\n                              solution_dict['user'] = st.session_state['student_name']\n                              solution_dict['group'] = st.session_state['group']\n                              solution_dict['time'] = timestamp\n                              solution_dict['score'] = ACC\n\n                              logs_df_2 = conn.read(worksheet=\"log\", usecols=list(range(log_df_n_cols)), ttl=1).dropna(how=\"all\")\n                              solution_2 = pd.DataFrame([solution_dict])\n                              updated_log_2 = pd.concat([logs_df_2,solution_2],ignore_index=True)\n                              conn.update(worksheet=\"log\",data = updated_log_2)\n                              st.success(f'당신의 솔루션이 {timestamp}에 업로드되었습니다',icon=\"✅\")\n                              st.balloons()\r\n```\n\n## 동적 랭킹 모듈\n\n로그인한 사용자가 이미 솔루션을 제출할 수 있는 앱을 보유하고 있습니다. 이제 앱의 게임화 요소를 추가하여 학생들이 다른 팀이 제출한 솔루션과 어떻게 비교되는지 보여주는 동적 랭킹을 만들어야 합니다. 이 모듈의 논리는 간단하며 다이어그램이 필요하지 않습니다. 기본적으로 구글 시트 데이터베이스의 \"log\" 탭에서 모든 데이터를 수집하고, 각 팀의 최상의 점수를 찾아내어 이 점수를 테이블로 제공해야 합니다. 최고 점수를 가진 팀이 최상위 위치에 있고, 그래로 이어지며 동일한 점수를 가진 두 개 이상의 팀이 있는 경우, 앱은 더 빨리 솔루션을 제출한 팀에 대해 더 높은 순위를 부여할 것입니다. 위의 논리는 아래 코드를 따라 구현될 것입니다.\n\n```js\nif selected == \"순위\":\n    st.header('순위')\n    \n    if st.session_state['user_name'] == '':\n        st.warning('랭킹을 확인하려면 로그인하세요')\n    else:\n        st.write('아래 테이블에 프로젝트의 순위가 표시됩니다')\n\n        rank_df = conn.read(worksheet=\"log\", usecols=list(range(log_df_n_cols)), ttl=1).dropna(how=\"all\")\n        GROUPS = list(rank_df['group'].unique())\n        default_time = pd.to_datetime('01/01/1901, 00:00:00')\n\n        st.header(\"머신러닝 분류 부분\")\n        st.divider()\n\n        ranking_list_2 = []\n        for gr in GROUPS:\n\n            mini_df_2 = rank_df[rank_df['group'] == gr]\n            if len(mini_df_2) == 0:\n                row = {'group':gr,'정확도':0,'time':default_time}\n                ranking_list_2.append(row)\n                continue\n            else:\n                best_idx_2 = np.argmax(mini_df_2['score'])\n                best_value_2 = mini_df_2.iat[best_idx_2,-1]\n                best_time_2 = pd.to_datetime(mini_df_2.iat[best_idx_2,2])\n                row = {'group':gr,'정확도':best_value_2,'time':best_time_2}\n                ranking_list_2.append(row)\n        ranking_df_2 = pd.DataFrame(ranking_list_2).sort_values(by = ['정확도','time'],ascending=[False, True])\n        ranking_df_2 = ranking_df_2.reset_index(drop=True)\n        ranking_df_2.iat[0,0] = ranking_df_2.iat[0,0] + \"   🥇\"\n        ranking_df_2.iat[1,0] = ranking_df_2.iat[1,0] + \"   🥈\"\n        ranking_df_2.iat[2,0] = ranking_df_2.iat[2,0] + \"   🥉\"\n        st.dataframe(ranking_df_2,use_container_width=True,hide_index=True)\r\n```\n\n<div class=\"content-ad\"></div>\n\n## 제출 로그 모듈\n\n마지막에 구현할 모듈은 제출 로그 모듈입니다. 이 모듈을 통해 각 학생은 프로젝트 기간 동안 자신과 팀원이 제출한 모든 제출물에 대한 이력 로그에 액세스할 수 있습니다. 이 모듈의 논리는 간단하며 다이어그램이 필요하지 않습니다. 우리는 Google Sheets 데이터베이스의 \"log\" 탭에서 모든 데이터를 수집하고, 현재 사용자 그룹에 대해 필터링한 후 정보를 테이블 형식으로 제시해야 합니다. 위의 논리는 아래 코드를 따라 구현될 것입니다.\n\n```js\nif selected == '내 그룹 제출물':\n    st.header('내 그룹 제출물')\n    \n    if st.session_state['user_name'] == '':\n        st.warning('제출 이력을 확인하려면 로그인해주세요')\n    else:\n        st.write(f'아래 테이블은 당신의 그룹인 **{st.session_state[\"group\"]}**의 제출 이력을 보여줍니다.')\n        group_log_df = conn.read(worksheet=\"log\", usecols=list(range(log_df_n_cols)), ttl=1).dropna(how=\"all\")\n        group_log_df = group_log_df[group_log_df['group'] == st.session_state['group']]\n        group_log_df = group_log_df[['user','time','score']]\n        \n       \n        st.subheader('제출 이력:')\n        st.dataframe(group_log_df,use_container_width=True,hide_index=True)    \n```\n\n마지막 모듈을 코드화하면 앱이 완료됩니다. 전체 코드는 아래 링크에서 찾을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 앱 배포\n\n지금까지 우리 앱은 로컬에서 매끄럽게 실행되었습니다. 그러나 이를 구축한 주요 목적은 여러분의 학생들과 그들의 최종 프로젝트에 사용하기 위함입니다. 이제 배포가 중요해집니다. 이 프로젝트에서는 Streamlit Community Cloud를 사용하여 앱을 배포하기로 결정했습니다. 무료이며 쉽게 사용할 수 있습니다. 이 서비스는 GitHub을 사용하여 앱을 배포하는데, 유일한 단점은 GitHub 리포지토리가 공개되어야 한다는 것입니다. 따라서 Google에서 다운로드한 기술 사용자 자격 증명과 같은 민감한 정보를 업로드하지 않도록 주의해야 합니다. 이 정보는 Streamlit Community Cloud 서비스 내에서 직접 관리될 것이므로 걱정하지 마세요. 다른 배포 옵션을 살펴보고 싶다면 Damian Boh가 작성한 훌륭한 아래 기사를 읽어보기를 권장합니다.\n\n우리 앱을 배포하려면 다음 단계를 따라주세요:\n\n- 새로운 공개 GitHub 리포지토리를 만듭니다. README.md 파일은 리포를 만들 때 직접 생성할 수 있습니다.\n- 아래 파일을 업로드하거나 커밋하되, 반드시 secrets.toml 파일은 업로드하지 않습니다:\n\n\n<div class=\"content-ad\"></div>\n\n- app.py\n- requirements.txt\n- logo.png (옵션, 대학 로고 또는 회사 로고로 앱을 사용자 정의하고 싶을 때)\n\n당신의 저장소는 Figure 11과 유사해야 합니다.\n\n![Figure 11](/assets/img/2024-06-22-HowICreatedaKaggle-LikePlatformforMyStudentsUsingStreamlitandHowYouCanDoItasWell_6.png)\n\n3. Streamlit Community Cloud 사이트 https://streamlit.io/cloud 에 가서 로그인합니다. 계정이 없다면 계정을 생성합니다.\n\n<div class=\"content-ad\"></div>\n\n4. 한 번 사인 인했으면 사이트 오른쪽 상단에 있는 \"앱 생성\" 버튼을 클릭하고, 그런 다음 GitHub에서 앱 코드를 가져올 옵션을 선택합니다.\n\n5. 앱 파일을 포함하는 레포의 이름을 입력하고, 기본 브랜치를 선택하고, Python 파일의 이름을 입력하세요 (우리의 경우 app.py). 또한 앱 URL 이름을 사용자 정의할 수 있습니다; medium-kaggle-like-app을 선택했습니다. 폼은 Figure 12와 비슷해야 합니다.\n\n![Figure 12](/assets/img/2024-06-22-HowICreatedaKaggle-LikePlatformforMyStudentsUsingStreamlitandHowYouCanDoItasWell_7.png)\n\n6. \"배포\" 버튼을 클릭하세요. 몇 분 정도 걸릴 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n7. 앱을 배포하면 즉시 Streamlit에서 오류 메시지를 받게 됩니다. 그림 13에서 보는 것처럼요. 이것은 완전히 정상적인 현상입니다. 배포된 앱은 기술 사용자 자격 증명에 액세스할 수 없기 때문에 GitHub에 secrets.toml 파일을 업로드하지 않았거든요. 하지만 걱정하지 마세요. 다음 단계에서 이 오류를 해결할 거예요.\n\n![이미지](/assets/img/2024-06-22-HowICreatedaKaggle-LikePlatformforMyStudentsUsingStreamlitandHowYouCanDoItasWell_8.png)\n\n8. 페이지 오른쪽 아래 구석에 \"앱 관리\"라는 메뉴가 있습니다. 클릭하고, 샌드위치 메뉴를 열어 \"설정\"을 선택한 다음 \"Secrets\"를 선택하고 secrets.toml 파일의 내용을 그곳에 복사해주세요. 앱이 자동으로 다시 시작되고 정상적으로 작동해야 할 거예요.\n\n![이미지](https://miro.medium.com/v2/resize:fit:1200/1*IAqyQoKrSUpH1a4C7nG8RQ.gif)\n\n<div class=\"content-ad\"></div>\n\n아래 링크를 클릭하여 최종 배포된 앱을 확인할 수 있어요. john.doe@example.com을 사용하여 계정에 로그인하고, 패스워드는 pass1234입니다. 이 프로젝트의 GitHub 저장소에는 결과물로 제출할 수 있는 .csv 파일이 포함되어 있어요.\n\n# 실제 적용 결과\n\n이 튜토리얼의 프레임워크를 활용하여, 저는 제가 석사생들에게 가르치는 파이썬 금융 수업의 최종 프로젝트를 게임화했어요. 솔직히 말해서, 이 프로젝트에 대한 제 기대는 저조했어요. 각 팀이 프로젝트 기한 내에 플랫폼과 최소한 두 번 이상 상호 작용할 것을 기대했기 때문에, 7개팀과 3개 프로젝트 섹션 전체에서 50-60회의 상호 작용이 이루어지면 성공으로 간주될 것이었죠.\n\n그러나 학생들은 제게 인도자로서 받을 수 있는 최고의 선물 중 하나를 주었어요. 한 달 후에 앱은 690회 이상의 제출을 받았는데, 제 초기 기대의 거의 12배에 달하는 수치였죠. 이 수준의 참여는 저에게 있어서 전례가 없었어요. 각 그룹은 프로젝트 섹션 당 평균 30회 이상의 제출을 제출했는데, 이는 섹션 당 거의 하루에 한 번의 제출에 해당했어요. 첫 제출과 각 섹션 및 팀의 최고 제출을 비교했을 때, 평균적으로 21%의 개선이 있었고, 일부 팀은 제출물을 60% 이상 개선했어요. 일반적인 버전의 프로젝트를 게임화된 버전 대신에 구현했다면, 이 수준의 개선은 실현되지 않았을 것으로 생각돼요. 이는 게임화의 힘을 입증하는 것이에요. 이제 이 앱을 교실에서 쉽게 구현할 수 있고, 모든 것이 무료에요. 멋지죠, 그렇지 않나요?\n\n<div class=\"content-ad\"></div>\n\n게임화에 대해 더 많이 알고 싶다면, 내 이전 글을 꼭 읽어보세요. 그 글에서는 게임화의 논리와 참여 및 학습을 촉진하는 방법에 대해 논의했습니다.\n\n# 결론\n\n이 글은 Streamlit을 사용하여 Google Sheets와 통합하여 CRUD 앱을 만드는 전체 과정을 안내했습니다. 이 앱은 학생들을 위한 기계 학습 프로젝트에 게임 요소를 도입하는 데 사용할 수 있습니다. 또한 Streamlit Community Cloud 서비스를 사용하여 앱을 배포하는 방법도 보여드렸습니다. 이 코드는 매우 유연하며 기계 학습 프로젝트에만 국한되지 않습니다. 저는 이를 제 프로젝트 예약 수업 중 하나에 적용하고 탁월한 결과를 얻었습니다.\n\n아래 게시글에서 Bruno Scalia C. F. Leite는 Streamlit을 사용하여 물류 앱을 배포하는 방법에 대해 소개합니다. Streamlit을 사용하여 운영 연구 애플리케이션을 만드는 방법에 대해 알고 싶다면 아래 링크를 통해 그의 글을 확인해보세요.\n\n<div class=\"content-ad\"></div>\n\n이 글이 유익하고 즐거웠기를 진심으로 바랍니다. 그렇다면 귀하의 생각을 듣고 싶어요! 댓글을 남기거나 👏로 감사를 표현해 주시면 감사하겠습니다. 최신 기사 업데이트를 받고 싶다면 저를 Medium에서 팔로우해 주세요. 여러분의 지원과 피드백이 제게 지속적인 탐구와 공유를 이끄는 원동력이 되어요. 읽어 주셔서 감사합니다. 다음 글에서 더 많은 통찰을 기대해 주세요!\n\n# 참고 자료\n\n- Python 및 Streamlit으로 Google Sheets 데이터 입력 폼 만들기 | 빠르고 쉬운 튜토리얼 : https://www.youtube.com/watch?v=_G5f7og_Dpo&t=66s\n- 학생 그룹 프로젝트를 개선하는 방법: 게이미피케이션 기법으로 학습 향상 : https://medium.com/@luisfernandopa1212/transforming-group-projects-enhancing-learning-with-gamification-techniques-81e2ba2e02ff\n- 운영 연구 솔루션 설계: Streamlit을 활용한 사용자 친화적 라우팅 애플리케이션 : https://medium.com/towards-data-science/designing-operations-research-solutions-a-user-friendly-routing-application-with-streamlit-17212553861d\n- Streamlit 웹 앱 온라인으로 쉽게 배포하는 방법 3가지 : https://towardsdatascience.com/3-easy-ways-to-deploy-your-streamlit-web-app-online-7c88bb1024b1\n- Penard, Wouter; van Werkhoven, Tim. “보안 해시 알고리즘 패밀리에 대해”. staff.science.uu.nl. 2016–03–30.\n- 연방 등록 호시즈 02–21599, FIPS 게시물 180–2 승인 공지.","ogImage":{"url":"/assets/img/2024-06-22-HowICreatedaKaggle-LikePlatformforMyStudentsUsingStreamlitandHowYouCanDoItasWell_0.png"},"coverImage":"/assets/img/2024-06-22-HowICreatedaKaggle-LikePlatformforMyStudentsUsingStreamlitandHowYouCanDoItasWell_0.png","tag":["Tech"],"readingTime":28},{"title":"결정 트리Decision Trees를 사용한 탐색적 데이터 분석 방법","description":"","date":"2024-06-22 02:31","slug":"2024-06-22-UsingDecisionTreesforExploratoryDataAnalysis","content":"\n\n\n![Decision Tree](/assets/img/2024-06-22-UsingDecisionTreesforExploratoryDataAnalysis_0.png)\n\n# 소개\n\n의사 결정 트리(DT)는 가장 직관적인 머신러닝 알고리즘입니다.\n\n내 의견이죠. 하지만 데이터 과학 분야에서도 흔히 느껴지는 감정이라고 확신합니다.\n\n\n<div class=\"content-ad\"></div>\n\n운영 연구와 데이터 과학 분야에서 매우 활용되는 DT(의사 결정 트리)의 성공 요인은 인간의 의사 결정 과정과 유사한 프로세스를 따라가기 때문입니다. 이 과정은 각 노드가 주어진 변수에 대해 간단한 이진 결정을 갖는 플로 차트에 기반하며, 최종 결정에 이르기까지 계속됩니다.\n\n간단한 예를 들어, 티셔츠 구매. 저는 셔츠를 사려고 할 때 가격, 브랜드, 사이즈, 색상과 같은 몇 가지 변수를 고려할 수 있습니다. 따라서 저는 결정 프로세스를 예산에서 시작합니다:\n\n- 가격이 $30 이상이면 구매하지 않을 것입니다. 그렇지 않은 경우에는 구매할 것입니다.\n- $30 미만으로 무언가를 찾으면 좋아하는 브랜드의 제품이어야 합니다. 그렇다면 결정 과정을 계속합니다.\n- 이제, 제 사이즈에 맞는지 확인해보죠. 맞다면 계속 진행합니다.\n- 마지막으로, $30 미만, 브랜드 X, 사이즈 S인 검은색 티셔츠라면 구매할 것이고, 그렇지 않다면 계속 찾거나 \"구매하지 않을 것\"으로 결정 프로세스를 마칠 수 있습니다.\n\n![의사 결정 트리 샘플](/assets/img/2024-06-22-UsingDecisionTreesforExploratoryDataAnalysis_1.png)\n\n<div class=\"content-ad\"></div>\n\n이 프로세스는 매우 논리적이고 간단하여 모든 종류의 데이터에 적용할 수 있습니다. 이 알고리즘의 단점은 데이터 세트의 변화에 매우 민감하여 특히 데이터가 작을 때 민감하다는 것입니다. 따라서 데이터의 작은 변동성을 쉽게 학습하여 기계 학습 모델을 과적합시킬 수 있습니다.\n\n이러한 결정 트리(DT)의 이러한 특성은 예측에 위협이 될 수 있지만 탐색적 데이터 분석 과정 중에 이를 활용하고자 하는 것입니다.\n\n이 게시물에서는 데이터에서 더 나은 통찰력을 추출하기 위해 DT의 힘을 어떻게 활용하는지 배워보겠습니다. 계속 진행합시다.\n\n# EDA란 무엇인가요?\n\n<div class=\"content-ad\"></div>\n\n탐색적 데이터 분석 또는 EDA는 데이터 과학 프로젝트의 단계 중 하나로, 데이터 세트를 가져와 변수를 탐색하여 대상 변수에 가장 큰 영향을 미치는 요소를 최대한 파악하려는 과정입니다.\n\n이 단계에서 데이터 과학자는 데이터를 이해하고 분포가 어떤지, 오류나 누락된 데이터가 있는지, 데이터의 첫 인사이트를 추출하고 설명 변수가 대상 변수에 어떻게 영향을 미치는지 시각화하여 학습하고자 합니다.\n\n# 결정 트리 사용하기\n\nDT가 데이터의 가장 작은 변동을 포착할 수 있는 능력 때문에, 변수 간 관계를 이해하는 데 도움이 됩니다. 여기서는 데이터를 탐색 중이므로 데이터 분할이나 알고리즘 세밀 조정에 대해 신중할 필요가 없습니다. 우리는 그저 최상의 통찰을 얻기 위해 DT를 실행하기만 하면 됩니다.\n\n<div class=\"content-ad\"></div>\n\n그것을 어떻게 하는지 봅시다.\n\n## 데이터셋\n\n이 연습에 사용될 데이터셋은 Paulo Cortez가 작성한 UCI Repository의 학생 성적 데이터입니다. 이 데이터셋은 크리에이티브 커먼즈 저작자표시 4.0 국제 라이선스(CC BY 4.0) 하에 배포됩니다.\n\n```python\n# 라이브러리 불러오기\nimport pandas as pd\nimport seaborn as sns\nsns.set_style()\nimport matplotlib.pyplot as plt\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.tree import plot_tree\n\n# 데이터셋 불러오기\nfrom ucimlrepo import fetch_ucirepo\n\n# 데이터셋 가져오기\nstudent_performance = fetch_ucirepo(id=320)\n\n# 데이터 (판다스 데이터프레임 형식)\nX = student_performance.data.features\ny = student_performance.data.targets\n\n# 시각화를 위해 X와 Y 모으기\ndf = pd.concat([X,y], axis=1)\n\ndf.head(3)\n```\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-22-UsingDecisionTreesforExploratoryDataAnalysis_2.png)\n\n이 데이터에서 어떤 변수가 최종 성적 G3에 더 큰 영향을 미치는지 결정하려고 합니다.\n\n## 회귀 DT로 탐색하기\n\n이제 실패, 결석 및 공부 시간이 G3에 미치는 영향을 확인하기 위해 DT를 생성해보겠습니다.\n\n\n<div class=\"content-ad\"></div>\n\n```js\n# 탐색할 컬럼\ncols = ['failures', 'absences', 'studytime']\n\n# X & Y 분리\nX = df[cols]\ny = df.G3\n\n# 의사결정트리 학습\ndt = DecisionTreeRegressor().fit(X, y)\n\n# 의사결정트리 그리기\nplt.figure(figsize=(20,10))\nplot_tree(dt, filled=True, feature_names=X.columns, max_depth=3, fontsize=8);\n```\n\n이것이 생성된 의사결정트리입니다.\n\n<img src=\"/assets/img/2024-06-22-UsingDecisionTreesforExploratoryDataAnalysis_3.png\" />\n\n이제 우리는 나열한 변수들 간의 관계를 이해하기 위한 좋은 시각화가 있습니다. 이 트리에서 얻을 수 있는 인사이트는 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n- 각 상자 안의 첫 번째 줄의 조건에 따라 왼쪽이 \"예\"를, 오른쪽이 \"아니오\"를 의미한다는 것을 알고 계셔야 합니다.\n- 실패 횟수가 적은 학생들(0.5 또는 0이라고 말해야 할 정도)이 더 높은 성적을 받습니다. 왼쪽 상자의 값이 오른쪽보다 높은 것을 관찰할 수 있습니다.\n- 실패한 학생들 중 공부 시간이 2.5 미만인 학생들이 더 높은 성적을 받습니다. 값이 거의 1점 더 높습니다.\n- 실패 횟수와 공부 시간이 1.5 미만, 그리고 결석이 22회 미만인 학생들은 공부 시간이 적고 결석률이 높은 학생들보다 더 높은 최종 성적을 받습니다.\n\n## 여유 시간과 외출\n\n여가 시간의 양과 외출 빈도에 기반하여 더 높은 성적을 받는 학생들을 알아보고 싶다면 여기에 있는 코드입니다.\n```js\n# 탐색할 열\ncols = ['여가시간', '외출']\n\n# X와 Y 분리\nX = df[cols]\ny = df.G3\n\n# 의사결정 트리 피팅\ndt = DecisionTreeRegressor().fit(X,y)\n\n# DT 플롯\nplt.figure(figsize=(20,10))\nplot_tree(dt, filled=True, feature_names=X.columns, max_depth=3, fontsize=10);\n```\n\n<div class=\"content-ad\"></div>\n\n![Decision Trees for Exploratory Data Analysis](/assets/img/2024-06-22-UsingDecisionTreesforExploratoryDataAnalysis_4.png)\n\ngoout와 freetime 변수는 1= 매우 낮음부터 5= 매우 높음까지의 척도로 조정되어 있습니다. 자주 외출하지 않는 사람들(1.5)과 여가 시간이 없는 사람들(1.5)은 많이 외출하고 어느 정도 여가 시간이 있는 사람들과 마찬가지로 낮은 성적을 받을 수 있음을 주목해주세요. 가장 높은 성적을 받는 사람들은 외출과 여가 시간이 균형을 이루고 있습니다(외출 1.5, 여가 시간 1.5에서 2.5 사이).\n\n## Classification DT로 탐색하기\n\n동일한 연습을 Classification Tree 알고리즘을 사용해 할 수 있습니다. 논리와 코딩은 동일하지만, 결과 값은 이제 값이 아닌 예측된 클래스를 보여줍니다. Seaborn 패키지(3-Clause BSD License)에서 가져온 뉴욕 시티의 택시 운행 데이터셋을 사용한 간단한 예제를 살펴봅시다.\n\n<div class=\"content-ad\"></div>\n\n만약 우리가 런 총액과 결제 방법 간의 관계를 탐구하고 싶다면, 다음 코드를 확인해보세요.\n\n```js\n# 데이터셋 로드\ndf = sns.load_dataset('taxis').dropna()\n\n# 탐색할 열\ncols = ['total']\n\n# X & Y 분리\nX = df[cols]\ny = df['payment']\n\n# 의사결정 트리 적합\ndt = DecisionTreeClassifier().fit(X,y)\n\n# 트리 시각화\nplt.figure(figsize=(21,10))\nplot_tree(dt, filled=True, feature_names=X.columns, max_depth=3, \n          fontsize=10, class_names=['cash', 'credit_card']);\n```\n\n<img src=\"/assets/img/2024-06-22-UsingDecisionTreesforExploratoryDataAnalysis_5.png\" />\n\n결과 트리를 눈으로 확인해본 결과, 총액이 낮은 경우 현금으로 결제하는 가능성이 훨씬 높다는 것을 알 수 있습니다. $9.32 미만의 총액은 일반적으로 현금으로 결제됩니다.\n\n<div class=\"content-ad\"></div>\n\n좋죠, 그렇죠?\n\n# 이제 가기 전에\n\n이 튜토리얼에서는 데이터셋 내 변수들 간의 관계를 탐색하는 빠른 방법인 결정 트리를 사용하는 방법에 대해 배웠습니다.\n\n이 알고리즘은 처음에 쉽게 찾아지지 않는 패턴을 빠르게 포착할 수 있습니다. 우리는 데이터의 그 절삭을 찾기 위해 결정 트리의 힘을 활용하여 거기서 훌륭한 통찰을 얻을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n빠른 코드에 대한 노트하나: plot_tree() 함수에서 max_depth 기능을 사용하여 원하는 수준을 설정할 수 있습니다. 또한 sklearn의 DT 인스턴스에서 해당 하이퍼파라미터를 설정할 수도 있습니다. 선택은 당신의 몫입니다. plot_tree에서 사용하는 장점은 모델을 다시 훈련시킬 필요 없이 다양한 깊이를 빠르게 테스트할 수 있다는 것입니다.\n\n```js\nplot_tree(dt, filled=True, feature_names=X.columns, max_depth=3);\n```\n\n만약 이 내용을 좋아하신다면, 더 많은 내용을 위해 저를 팔로우해주세요.\n\nLinkedIn에서 저를 찾아서 연결해요. 함께해요!\n\n<div class=\"content-ad\"></div>\n\n# 참고 자료\n\n제가 소개하고 싶은 좋은 참고 자료가 있어요. 이 기술은 멋진 브라질 데이터 과학자 Teo Calvo로부터 배웠어요. 그는 Teo Me Why 채널에서 매일 생방송으로 멋진 프로그램을 제공하고 계세요. 포르투갈어를 구사하신다면, 그의 작품에 대해 더 알아보세요.","ogImage":{"url":"/assets/img/2024-06-22-UsingDecisionTreesforExploratoryDataAnalysis_0.png"},"coverImage":"/assets/img/2024-06-22-UsingDecisionTreesforExploratoryDataAnalysis_0.png","tag":["Tech"],"readingTime":6},{"title":"Nodejs와 Reactjs에서 Razorpay 결제 게이트웨이 통합 방법","description":"","date":"2024-06-22 02:29","slug":"2024-06-22-RazorpayPaymentGatewayIntegrationInNodeJSReactJS","content":"\n\n# Node.js 및 React JS에서 Razorpay 결제 게이트웨이 통합\n\n<img src=\"/assets/img/2024-06-22-RazorpayPaymentGatewayIntegrationInNodeJSReactJS_0.png\" />\n\n# Node.js에서 Razorpay 결제 API 구현\n\n많은 시장에서 제공되는 결제 게이트웨이는 온라인 거래가 처리되는 곳입니다. 여기에서 Node.js를 사용하여 온라인 상점에 Razorpay 결제 API를 구현하는 방법을 설명하겠습니다.\n\n<div class=\"content-ad\"></div>\n\n우리는 ReactJS에서 Node.js로 작성된 API를 사용하여 Razorpay 결제 게이트웨이를 통합하는 방법에 대해 이야기할 것입니다.\n\n물론 로직은 동일하기 때문에 사용하는 언어가 중요하지 않습니다. 그러니 시작해 봅시다!\n\n## 단계 1:\n\nRazorpay 웹사이트에서 계정을 만들어 여기에서 Key Id 및 Key Secret을 받으세요.\n이 정보는 설정 - `API keys`에서 얻을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n노트- 테스트 모드에 계십니까? 확인 부탁드립니다.\n\n## 단계 2:\n\n이번 단계에서는 Razorpay 결제 게이트웨이가 어떻게 작동하는지 이해해 보겠습니다. Razorpay 결제 게이트웨이의 흐름은 무엇인가요?\n\n다음 단계들은 Razorpay에서의 결제 흐름의 주요 구성 요소입니다-\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-22-RazorpayPaymentGatewayIntegrationInNodeJSReactJS_1.png\" />\n\n- 고객이 주문을 생성합니다.\n- Razorpay는 주문에 대한 주문 ID를 생성하고, 우리는 이를 통합에 사용합니다.\n- 주문 ID를 사용하여 결제 UI가 열리며, 고객은 세부 정보를 입력하고 결제 수단을 선택하고 금액을 지불합니다.\n- 그런 다음,이 단일 지불에는 처리를 받는 결제 ID이 있으며 우리는 응답으로 razorpay_signature, razorpay_order_id 및 razorpay_payment_id를 받습니다.\n- 그런 다음,이 결제를 인증하고 캡처하여 전체 거래를 정리하고 완료해야 합니다.\n\n## 단계 3:\n\n이제 코드를 작성합시다.\n\n<div class=\"content-ad\"></div>\n\n## 백엔드\n\nRazorpay를 초기화합니다.\n\n```js\nnpm i razorpay\n```\n\n## 비밀 키 사용하기\n\n<div class=\"content-ad\"></div>\n\nRazorpay의 모든 API에 접근하려면 먼저 Razorpay 패키지를 설치한 다음 시크릿 키를 사용해야 합니다.\n\n```js\nconst Razorpay = require('razorpay')\n```\n\n```js\nconst razorpay = new Razorpay({\nkey_id: 'rzp_test_uGoq5ADrFTgYRAhk',\n   key_secret: 'FySe2f58UYtg6Hjkj1a5s6clk9B'\n})\n```\n\n## 주문 생성을 위한 API 경로\n\n<div class=\"content-ad\"></div>\n\n우리는 주문을 배치하고 아래 나열된 API를 호출해야 합니다. 주문에 관한 기본 정보를 유지하고 주문을 반환해야 합니다. 나는 Razorpay를 위한 이 API의 요청 본문을 구성하고 create order 함수를 호출했습니다. 그런 다음에는 주문 ID를 프론트엔드 팀에 보내야 했으므로 그들이 이를 활용할 수 있고 Razorpay 체크아웃 페이지의 비밀키도 사용할 수 있습니다. 지불이 성공하면 상태가 \"Failed\"에서 \"Authorized\"로 변경됩니다. Razorpay 대시보드에서 확인할 수 있습니다.\n\n```js\napp.post('/order', async (req, res) => {\n    // razorpay 초기화\n    const razorpay = new Razorpay({\n        key_id: req.body.keyId,\n        key_secret: req.body.keySecret,\n    });\n\n    // razorpay 주문에 대한 옵션 설정\n    const options = {\n        amount: req.body.amount,\n        currency: req.body.currency,\n        receipt: \"각 주문에 대한 고유 ID\",\n        payment_capture: 1\n    };\n    try {\n        const response = await razorpay.orders.create(options)\n        res.json({\n            order_id: response.id,\n            currency: response.currency,\n            amount: response.amount,\n        })\n    } catch (err) {\n       res.status(400).send('주문을 생성할 수 없습니다. 다시 시도해주세요!');\n    }\n});\n```\n\n## 지불 캡처를 위한 API 경로\n\nRazorpay 설정에서 다음 URL을 웹훅에 특별한 비밀 키로 입력하고 \"payment.capture\" 열을 선택해야 하며, 이렇게하면 지불이 성공할 때마다 활성화됩니다.\n\n<div class=\"content-ad\"></div>\n\nWebhook에서 제공한 비밀 키를 사용하여 이 URL에서 서명을 확인해야 합니다. 지불 상태는 확인 후 \"캡처됨\"으로 변경됩니다.\n\n```js\nconst crypto = require('crypto')\n\nconst secret_key = '1234567890'\n\napp.post('/paymentCapture', (req, res) => {\n\n   // 유효성 검사 수행\n\nconst data = crypto.createHmac('sha256', secret_key)\n\n   data.update(JSON.stringify(req.body))\n\n   const digest = data.digest('hex')\n\nif (digest === req.headers['x-razorpay-signature']) {\n\n       console.log('요청이 유효합니다')\n\n       // 응답을 보내고 정보를 데이터베이스에 저장할 수 있습니다.\n\n       res.json({\n\n           status: 'ok'\n\n       })\n\n} else {\n\n       res.status(400).send('유효하지 않은 서명');\n\n   }\n\n})\n```\n\n## 환불\n\n지불이 완료된 후 환불할 수 있습니다. 요청할 API 호출과 함께 지불 ID와 금액을 제공하면 내부적으로 Razorpay의 환불 함수가 호출되어 돈을 동일한 계좌로 반환합니다.\n\n<div class=\"content-ad\"></div>\n\n```javascript\napp.post('/refund', async (req, res) => {\n\n   try {\n\n       // 먼저 결제 ID를 확인한 후 Razorpay API에 액세스합니다.\n\n       const options = {\n\n           payment_id: req.body.paymentId,\n\n           amount: req.body.amount,\n\n       };\n\nconst razorpayResponse = await razorpay.refund(options);\n\n       // 응답을 보내고 데이터베이스에 정보를 저장할 수 있습니다.\n\n       res.send('환불 성공')\n\n   } catch (error) {\n\n       console.log(error);\n\n       res.status(400).send('환불 발행에 문제가 있습니다');\n\n   }\n\n})\n```\n\n## 장점\n\nRazorpay Payment Gateway와 통합하는 이점은 아래에 나열되어 있습니다.\n\nOnboarding\n\n\n<div class=\"content-ad\"></div>\n\n표 태그를 Markdown 형식으로 변경해주세요.\n\n<div class=\"content-ad\"></div>\n\n은행으로부터 수신한 오류 코드에 기초하여 Razorpay는 실패한 API 환불을 지능적으로 다시 시도합니다. 당사의 인스턴트 환불 도구 덕분에 최상의 환불 경험을 고객에게 제공할 수 있습니다.\n\n확장성과 가용성\n\n당사 시스템은 1초에 800개의 트랜잭션 요청을 처리할 수 있으며 성능이 저하되지 않습니다. 상태 페이지와 대시보드 외에도 장애 업데이트 이메일을 전송합니다.\n\n정산 조정\n\n<div class=\"content-ad\"></div>\n\n거래 처리를 추적하려면 특정 날짜나 월에 지불된 지불, 환불, 이체 및 조정을 모두 추적하기 위해 결제 조정을 사용하십시오.\n\n보상\n\n우리 회사는 국내외 다양한 카드, 다양한 인터넷뱅킹 대안, UPI 수집 및 의도, EMI, 무카드 EMI 및 Paytm 및 PhonePe와 같은 지갑을 모두 지원합니다.\n\n## 단계 4: 프론트엔드 (React js)\n\n<div class=\"content-ad\"></div>\n\n다음은 Razorpay를 렌더링하는 코드입니다.\n\n```js\nimport { useEffect, useRef } from 'react';\nimport crypto from 'crypto-js';\nimport PropTypes from 'prop-types';\nimport Axios from 'axios';\n\n// 스크립트를로드하고 DOM 트리에 추가하는 함수\nconst loadScript = src => new Promise((resolve) => {\n  const script = document.createElement('script');\n  script.src = src;\n  script.onload = () => {\n    console.log('razorpay가 성공적으로로드되었습니다');\n    resolve(true);\n  };\n  script.onerror = () => {\n    console.log('razorpay로드 중 오류 발생');\n    resolve(false);\n  };\n  document.body.appendChild(script);\n});\n\n\nconst RenderRazorpay = ({\n  orderId,\n  keyId,\n  keySecret,\n  currency,\n  amount,\n}) => {\n  const paymentId = useRef(null);\n  const paymentMethod = useRef(null);\n\n  // razorpay 체크아웃 모달 스크립트로드\n  const displayRazorpay = async (options) => {\n    const res = await loadScript(\n      'https://checkout.razorpay.com/v1/checkout.js',\n    );\n\n    if (!res) {\n      console.log('Razorpay SDK를로드하지 못했습니다. 온라인 상태이십니까?');\n      return;\n    }\n    // 모든 정보가 나중에 논의 할 options에로드됩니다.\n    const rzp1 = new window.Razorpay(options);\n\n    // 선택한 결제 방법을 검색하려는 경우\n    rzp1.on('payment.submit', (response) => {\n      paymentMethod.current = response.method;\n    });\n\n    // 거래 실패시 결제 ID를 검색\n    rzp1.on('payment.failed', (response) => {\n      paymentId.current = response.error.metadata.payment_id;\n    });\n\n    // razorpay 체크아웃 모달 열기\n    rzp1.open();\n  };\n\n\n  // 결제 서버에 알리기\n  const handlePayment = async (status, orderDetails = {}) => {\n    await Axios.post(`${serverBaseUrl}/payment`,\n      {\n        status,\n        orderDetails,\n      });\n  };\n\n\n  // 다음 단계에서이 객체를 작성 할 것입니다.\n  const options = {},\n\n  useEffect(() => {\n    console.log('레이저페이');\n    displayRazorpay(options);\n  }, []);\n\n  return null;\n};\n\nexport default RenderRazorpay;\n```\n\n<div class=\"content-ad\"></div>\n\n이제 통합의 가장 중요한 부분입니다.\n\n```js\nconst options = {\n    key: keyId, // 프롭스로부터 키 ID\n    amount, // 프롭스로부터 최소 단위 금액\n    currency, // 프롭스로부터 통화\n    name: 'amit', // 결제 모달에 표시할 조직의 제목\n    // image, // 사용자 정의 로고 URL\n    order_id: orderId, // 프롭스로부터 주문 ID\n    // 이 핸들러 메서드는 항상 결제에 성공했을 때 실행됩니다. \n    handler: (response) => {\n      console.log('succeeded');\n      console.log(response);\n      paymentId.current = response.razorpay_payment_id;\n\n      // 지불을 캡처하고 승인하는 가장 중요한 단계입니다. 이 작업은 백엔드 서버에서 수행할 수 있습니다.\n      const succeeded = crypto.HmacSHA256(`${orderId}|${response.razorpay_payment_id}`, keySecret).toString() === response.razorpay_signature;\n\n      // 성공적으로 승인되면 결제를 성공으로 간주할 수 있습니다.\n      if (succeeded) {\n        handlePayment('succeeded', {\n          orderId,\n          paymentId,\n          signature: response.razorpay_signature,\n        });\n      } else {\n        handlePayment('failed', {\n          orderId,\n          paymentId: response.razorpay_payment_id,\n        });\n      }\n    },\n    modal: {\n      confirm_close: true, // true로 설정하면 × 버튼을 클릭했을 때 확인이 필요합니다.\n      // 체크아웃 모달이 닫힐 때 실행되는 함수입니다.\n      // 이 모달이 닫히는 이유는 3가지가 있을 수 있습니다.\n      ondismiss: async (reason) => {\n        const {\n          reason: paymentReason, field, step, code,\n        } = reason && reason.error ? reason.error : {};\n        // 이유 1- 지불이 취소될 때. 이는 × 아이콘을 클릭하거나 명시적으로 지불을 취소할 때 발생할 수 있습니다.\n        if (reason === undefined) {\n          console.log('cancelled');\n          handlePayment('Cancelled');\n        } \n        // 이유 2- 시간 초과로 인해 모달이 자동으로 닫힐 때\n        else if (reason === 'timeout') {\n          console.log('timedout');\n          handlePayment('timedout');\n        } \n        // 이유 3- 지불이 실패했을 때\n        else {\n          console.log('failed');\n          handlePayment('failed', {\n            paymentReason, field, step, code,\n          });\n        }\n      },\n    },\n    // 이 속성을 사용하여 재시도를 활성화/비활성화할 수 있습니다.\n    // 기본적으로 활성화되어 있습니다.\n    retry: {\n      enabled: false,\n    },\n    timeout: 900, // 시간 제한(초) \n    theme: {\n      color: '', // 체크아웃 모달에 대한 사용자 정의 색상\n    },\n  };\n```\n\n## 단계 5: 이제 결제를 진행해 봅시다.\n\n이렇게 보입니다.\n\n<div class=\"content-ad\"></div>\n\n\n![2024-06-22-RazorpayPaymentGatewayIntegrationInNodeJSReactJS_2](/assets/img/2024-06-22-RazorpayPaymentGatewayIntegrationInNodeJSReactJS_2.png)\n","ogImage":{"url":"/assets/img/2024-06-22-RazorpayPaymentGatewayIntegrationInNodeJSReactJS_0.png"},"coverImage":"/assets/img/2024-06-22-RazorpayPaymentGatewayIntegrationInNodeJSReactJS_0.png","tag":["Tech"],"readingTime":9},{"title":"제로부터 챗봇까지 대형 언어 모델LLMs의 동작 원리 및 쉽게 활용하는 방법","description":"","date":"2024-06-22 02:27","slug":"2024-06-22-FromZerotoChatbotHowLargeLanguageModelsLLMsWorkandHowtoHarnessThemEasily","content":"\n\n# Node.js, OpenAI와 차 한 잔으로 즐거운 시간을 보내세요.\n\n![이미지](/assets/img/2024-06-22-FromZerotoChatbotHowLargeLanguageModelsLLMsWorkandHowtoHarnessThemEasily_0.png)\n\n인터넷의 모든 책, 기사 및 블로그 글을 읽어 버린 초지능 친구가 있다고 상상해보세요. 이 친구는 당신의 질문에 답변하고 창의적인 글쓰기를 돕며, 해변 거리의 어떤 주제에 대해 당신과 이야기를 나누어 줄 수 있습니다. 그것이 바로 Large Language Model (LLM) 입니다!\n\n이제 상상해 보세요, 여러분이 직접 하나를 만들 수 있다는 것을!\n\n<div class=\"content-ad\"></div>\n\n## 대형 언어 모델 (LLMs)\n\n대형 언어 모델(Large Language Models, LLMs)인 OpenAI의 GPT(Generative Pre-trained Transformer)와 같은 모델들은 기술과 상호 작용하는 방식을 혁신하고 있습니다. 이러한 모델들은 방대한 양의 텍스트 데이터로 학습되어 인간과 유사한 텍스트를 이해하고 생성할 수 있으며, 챗봇과 같은 응용 프로그램에 이상적입니다. 이 기사에서는 LLMs의 기본 개념, 프롬프트 엔지니어링의 개념, 그리고 Node.js, LangChain 및 OpenAI를 사용하여 챗봇을 구축하는 방법을 살펴보겠습니다.\n\nLLMs의 주요 특징:\n\n- 문맥적인 이해: LLMs는 주어진 입력의 문맥을 이해하여 그들의 응답을 일관되고 문맥적으로 관련성 있게 만듭니다.\n- 다용도성: 이러한 모델들은 번역, 요약 및 대화를 포함한 다양한 작업을 처리할 수 있습니다.\n- 확장성: LLMs는 특정 응용 프로그램에 대해 세밀하게 조정될 수 있어 특정 사용 사례의 성능을 향상시킬 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## LLM(언어 모델) 활용 방법\n\nLLM을 효과적으로 활용하려면, 입력을 처리하고 출력을 생성하는 방법을 이해하는 것이 중요합니다. 이는 모델이 원하는 응답을 생성하도록 이끄는 입력인 프롬프트를 만드는 것을 포함합니다.\n\n프롬프트 구조: 잘 구조화된 프롬프트는 명확한 지시사항과 충분한 맥락을 제공합니다. 프롬프트의 품질은 출력의 품질에 직접적으로 영향을 미칩니다.\n\n토크나이제이션: LLM은 텍스트를 토큰이라고 불리는 더 작은 단위로 분해하여 처리합니다. 각 토큰은 한 글자에서 한 단어까지일 수 있습니다. 모델의 이해는 이러한 토큰들에 기반합니다.\n\n<div class=\"content-ad\"></div>\n\n온도 및 최대 토큰:\n\n- 온도: 출력의 무작위성을 조절합니다. 낮은 값은 출력을 더 결정론적으로 만들고, 높은 값은 무작위성을 높입니다.\n- 최대 토큰: 생성된 응답의 길이를 제한합니다. 적절한 최대 토큰 값을 설정하면 응답이 간결하고 관련성이 있도록 보장합니다.\n\n## 프롬프트 엔지니어링\n\n![이미지](/assets/img/2024-06-22-FromZerotoChatbotHowLargeLanguageModelsLLMsWorkandHowtoHarnessThemEasily_1.png)\n\n<div class=\"content-ad\"></div>\n\n상당히 지식이 풍부한 친구와 대화하고 있다고 상상해보세요. 그는 당신이 가진 모든 질문에 대답할 수 있는 친구입니다. 일반적인 질문을 시작하여도, 그는 귀하가 정확히 필요한 것을 이해하기 위해 명확하게 질문합니다. 이러한 주고받음은 명확하고 유용한 답변을 제공할 때까지 계속됩니다.\n\n이것은 AI와의 프롬프트 엔지니어링과 유사합니다. 우리가 OpenAI의 GPT-3와 같은 대형 언어 모델(LLM)과 상호작용할 때, 관련 응답을 생성하는 데 충분한 맥락을 제공하는 잘 가공된 프롬프트를 제공합니다.\n\n예를 들어, AI 챗봇에 \"Node.js의 이점은 무엇입니까?\"라고 묻는다면 기술적인 응답을 받을 수 있습니다. 더 명확한 프롬프트로 수정할 수 있습니다. \"웹 개발에 Node.js의 장점을 설명해 줄 수 있나요?\" 이러한 구조화된 접근 방식은 AI가 귀하의 질의를 이해하고 정확한 응답을 제공하는 데 도움이 됩니다.\n\n프롬프트 엔지니어링을 통해 개발자들은 AI와 효과적으로 소통하여 다양한 작업을 지원할 수 있는 스마트하고 반응성 있는 챗봇을 만들 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n효과적인 프롬프트 엔지니어링 팁:\n\n- 명확하고 구체적으로: 프롬프트가 작업을 명확하게 정의하는지 확인하세요. 모호한 프롬프트는 모호한 응답으로 이어질 수 있습니다.\n- 맥락 제공: 모델이 요청의 맥락을 이해할 수 있도록 충분한 정보를 제공하세요.\n- 반복하고 개선하기: 다양한 프롬프트로 실험을 해보고 모델의 응답에 따라 프롬프트를 개선하세요.\n\n## Node.js와 LangChain로 챗봇 만들기\n\n이제 즐거운 부분인 Node.js, LangChain 및 OpenAI를 사용하여 챗봇을 만드는 것에 대해 알아봅시다. 우리는 프롬프트 엔지니어링이 챗봇의 응답을 강화하는 방법에 초점을 맞출 것입니다.\n\n<div class=\"content-ad\"></div>\n\n환경 설정하기:\n\n- Node.js 프로젝트 초기화하기:\n\n```js\nmkdir chatbot-app\ncd chatbot-app\nnpm init -y\nnpm install langchain openai axios\n```\n\n- 챗봇 구조 생성하기:\n\n<div class=\"content-ad\"></div>\n\n```js\nconst { OpenAI } = require('langchain');\nconst axios = require('axios');\n\nconst openai = new OpenAI({\n    apiKey: 'YOUR_OPENAI_API_KEY',  // OpenAI API 키로 바꿔주세요\n});\n\nasync function generateResponse(prompt) {\n    const response = await openai.complete({\n        model: 'text-davinci-003',  // 다른 사용 가능한 모델을 사용할 수 있어요\n        prompt: prompt,\n        maxTokens: 150,\n    });\n\n    return response.data.choices[0].text.trim();\n}\n```\n\n- LangChain을 사용한 프롬프트 엔지니어링 구현:\n\n```js\nconst { OpenAI, PromptTemplate } = require('langchain');\n\nconst openai = new OpenAI({\n    apiKey: 'YOUR_OPENAI_API_KEY',\n});\n\nconst template = new PromptTemplate({\n    inputVariables: ['query'],\n    template: `도움이 되는 어시스턴트입니다. 다음 질문에 답변하세요: {query}`\n});\n\nasync function generateResponse(query) {\n    const prompt = await template.format({ query });\n    const response = await openai.complete({\n        model: 'text-davinci-003',\n        prompt: prompt,\n        maxTokens: 150,\n    });\n\n    return response.data.choices[0].text.trim();\n}\n\n// 예시 사용법\n(async () => {\n    const userQuery = \"Node.js를 사용하는 장점은 무엇인가요?\";\n    const response = await generateResponse(userQuery);\n    console.log(response);\n})();\n```\n\n## 챗봇 테스트 및 개선하기\n\n<div class=\"content-ad\"></div>\n\n테이블 태그를 Markdown 형식으로 변경해주세요.\n\n<div class=\"content-ad\"></div>\n\n- 사용자: \"Node.js에서 비동기 프로그래밍은 어떻게 작동하나요?\"\n- 챗봇: \"Node.js에서의 비동기 프로그래밍은 블로킹되지 않는 작업을 가능하게 하며, 이는 이전 작업이 완료될 때까지 기다리지 않고 여러 작업을 동시에 처리할 수 있다는 것을 의미합니다.\"\n\n프롬프트와 응답을 반복하여 자신의 챗봇을 계속 향상시킬 수 있습니다.\n\n## 결론\n\nNode.js, LangChain 및 OpenAI를 활용하여 챗봇을 구축하는 것은 LLM(Large Language Model)의 능력을 활용하기 위한 흥미진진하고 접근성 있는 방법입니다. LLM의 기본 원리를 이해하고 프롬프트 엔지니어링을 숙달하는 것은 정확하고 맥락에 맞는 응답을 제공하는 챗봇을 만드는 데 필수적입니다. 본 안내서가 여러분의 응용 프로그램에서 LLM의 잠재력을 탐험하며 영감을 주기를 바랍니다.\n\n<div class=\"content-ad\"></div>\n\n행복한 코딩!\n\n#AI, #인공지능, #챗봇, #오픈AI, #LangChain, #머신러닝, #NodeJS, #웹개발, #풀스택개발, #API개발, #프로그래밍, #기술튜토리얼, #소프트웨어공학, #자연어처리","ogImage":{"url":"/assets/img/2024-06-22-FromZerotoChatbotHowLargeLanguageModelsLLMsWorkandHowtoHarnessThemEasily_0.png"},"coverImage":"/assets/img/2024-06-22-FromZerotoChatbotHowLargeLanguageModelsLLMsWorkandHowtoHarnessThemEasily_0.png","tag":["Tech"],"readingTime":5},{"title":"npm 링크 사용 방법 2024 최신 가이드","description":"","date":"2024-06-22 02:26","slug":"2024-06-22-npmlink","content":"\n\nnpm 링크는 반복적으로 npm 패키지를 개발하고 테스트할 때 꾸준히 다시 빌드할 필요 없이 사용할 수 있는 필수 도구입니다. 원하는 대상 코드베이스에서 패키지를 직접 테스트할 수 있어요. 게시 후 불쾌한 놀라움을 피할 수 있어요. 저는 이것을 오랫동안 사용해왔어요. 처음에는 매우 간단했어요. 하지만 nvm, Webpack 등과 같은 도구를 사용하여 코드베이스가 복잡해지면서 작업하는 데 문제가 있었어요. 이 글은 npm 링크에 대한 제 경험에서 배운 것에 대한 내용입니다.\n\n# 사용 사례\n\n본 토론에서는 다음과 같은 사용 사례를 고려해 보세요.\n\n~/Documents/workspace/app에 node 앱인 app이라는 이름의 앱이 있고 이 앱은 utils라는 패키지를 사용합니다. utils는 이미 npm에 발행되어 있어요. utils에서 새로운 기능을 개발하고 이를 app에서 테스트하고 싶어요. 이를 위해 ~/Documents/workspace/utils에서 패키지를 확인했어요. utils 패키지에는 package.json에서 메인 파일로 src/index.js를 가지고 있어요.\n\n<div class=\"content-ad\"></div>\n\nutils에서 app으로 새 기능을 테스트하기 위한 링크를 생성할 예정입니다.\n\n# 사용법\n\n또 다른 코드베이스로부터 패키지를 연결하는 것은 2단계로 이루어집니다.\n\n## 단계 1\n\n<div class=\"content-ad\"></div>\n\n테스트할 패키지가 있는 디렉토리에서 npm link를 실행해주세요.\n\n그렇게 하면 패키지 디렉토리에서 전역 node_modules 디렉토리로 심볼릭 링크가 생성됩니다. 이 디렉토리는 'prefix'/lib/node_modules/`package-name` 에 위치해 있습니다. 또한 패키지 내의 모든 실행 파일들도 'prefix'/bin/`bin-name`에 링크됩니다.\n\n여기서 `package-name`은 package.json 파일에 있는 패키지의 이름을 가리키며, 패키지 코드가 있는 디렉토리의 이름은 아닙니다.\n\n'prefix'는 npm prefix -g의 출력을 나타냅니다. 저의 macOS에서는 homebrew를 통해 node가 설치되었으므로 /usr/local에 위치합니다. 따라서 전역 node_modules는 /usr/local/lib/node_modules에 있습니다.\n\n<div class=\"content-ad\"></div>\n\nutils 디렉터리에서 npm link를 실행하면 /usr/local/lib/node_modules/utils에서 ~/Documents/workspace/utils로 심볼릭 링크가 생성됩니다. 전역 노드 모듈 디렉터리로 이동하면 ls 명령어의 결과는 다음과 같습니다.\n\n![이미지](/assets/img/2024-06-22-npmlink_0.png)\n\n## 단계 2\n\n테스트하려는 패키지가 있는 코드베이스에서 npm link `package-name`을 실행하세요.\n\n<div class=\"content-ad\"></div>\n\nnpm 문서에 따르면, 이 코드베이스 내 node_modules/`package-name`에 심볼릭 링크를 생성하여 글로벌 node_modules 즉 'prefix'/lib/node_modules/`package-name` 로 연결해줍니다. 그러나 제가 8버전 이후의 새로운 npm 버전인 경우에 이 동작이 변경된 것을 알게 되었습니다. 새로운 버전에서는 심볼릭 링크가 node_modules/`package-name`에서 바로 로컬 패키지 저장소로 만들어집니다.\n\n내 앱 디렉토리에서 npm link utils를 실행하면, ~/Documents/workspace/app/node_modules/utils 에서 utils 패키지 위치인 ~/Documents/workspace/utils 로 심볼릭 링크가 생성됩니다. 이것은 npm 8.11에서 실행 중이기 때문에 ls 명령어의 출력은 app 디렉토리의 node_modules 디렉토리에 표시됩니다.\n\n![이미지](/assets/img/2024-06-22-npmlink_1.png)\n\n저는 npm 6.14.4에서도 동일한 작업을 시도해 보았습니다. 이 경우 utils는 npm 문서에서 언급된대로 글로벌 node_modules에 대한 링크가 생성됩니다. 즉 /usr/local/lib/node_modules/utils 입니다.\n\n<div class=\"content-ad\"></div>\n\n# nvm 사용 방법\n\nnvm을 사용하면 같은 컴퓨터에서 다양한 버전의 노드를 전환할 수 있습니다. 여러 버전의 노드가 설치되어 있더라도, 오직 1개의 버전만이 현재 버전으로 설정됩니다. nvm을 사용하는 경우, 패키지에서 npm link를 실행하면 현재 노드 버전(nvm use를 통해 설정됨)의 전역 node_modules에 링크가 생성됩니다. 이후 대상 코드베이스에서 npm link `패키지 이름`을 실행할 때, nvm의 현재 노드 버전이 변경되었다면, 링크가 생성되지 않습니다.\n\n## 사용 사례\n\n초기 사용 사례에서, 앱이 노드 18이 필요하고 utils는 적어도 노드 16이 필요한 경우를 가정해봅시다. 이들을 링크하려면 다음 작업을 수행해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n- nvm을 사용하여 노드 18로 변경합니다.\n- npm linkin utils를 실행합니다. 이렇게 하면 해당 패키지가 노드 v18의 전역 node_modules에 연결됩니다.\n- 앱에서 npm link utils을 실행합니다.\n\n이제 utils를 사용하는 app_1이 있고, 이 앱은 노드 16에서만 작동하는 경우를 가정해 봅시다. app_1을 utils에 연결하려면 다음을 수행해야 합니다.\n\n- nvm을 사용하여 노드 16로 변경합니다.\n- utils에서 다시 npm link를 실행하여 노드 v16의 전역 node_modules에 연결되도록 합니다.\n- app_1에서 npm link utils을 실행합니다.\n\n# 웹팩과의 사용법\n\n<div class=\"content-ad\"></div>\n\n링크를 설정하면 애플리케이션이 Webpack과 번들로 결합된 패키지의 경우 몇 가지 문제가 발생할 수 있습니다.\n\n## resolve.symlinks 설정 문제\n\n내 앱 중 일부에서 링크된 패키지가 포함된 앱을 번들링할 때, Webpack이 연결된 모듈에서 수입을 해결할 수 없는 문제가 발생했습니다. 이는 아마도 Webpack 구성의 resolve.symlinks 설정 때문일 것입니다. 기본적으로이 boolean은 true이며, 패키지는 심볼릭 링크 위치가 아닌 실제 경로로 해결됩니다. 따라서 이 문제가 발생하면 webpack 구성에서 resolve.symlinks를 false로 설정하면 문제가 해결될 것입니다.\n\n우리가 따르고있는 사용 사례에는 resolve.symlinkswith 값에 해당합니다.\n\n<div class=\"content-ad\"></div>\n\n- true를 사용하면 utils가 ../utils/src/index.js로 해석됩니다.\n- false를 사용하면 utils가 ./node_modules/utils/src/index.js로 해석됩니다.\n\n이 차이가 언제 문제가 될지 정확히 알 수 없었습니다. 일부 코드베이스에서는 링크된 모듈이 제대로 작동하여 resolve.symlinks를 설정하지 않아도 완벽하게 작동합니다. 반면에 일부 다른 코드베이스에서는 false로 설정하지 않으면 빌드가 실패합니다. 이 속성에 대한 Webpack 문서의 설명은 약간 모호합니다. — 패키지를 심볼릭 링크하는 도구를 사용할 때 모듈 해결에 실패할 수 있음을 참고하세요.\n\n## React 패키지를 링크하는 중 문제\n\nReact 컴포넌트를 포함한 패키지를 개발 중이라고 가정해보겠습니다. 이를 앱에서 링크하고 테스트하고자 합니다. Webpack 빌드는 잘 처리됩니다. 그러나 브라우저에서 애플리케이션을 로드할 때, 앱이 오류와 함께 크래시된 것을 확인할 수 있습니다 — 동일한 앱에서 React의 복사본이 여러 개 있는 것으로 보입니다.\n\n<div class=\"content-ad\"></div>\n\n리액트 컴포넌트가 npm에 발행되면 해당 컴포넌트가 번들에 포함되지 않도록 하기 위해 리액트 패키지를 피어 종속성으로 추가해야 합니다. 피어 종속성으로 표시하면 다른 리액트 앱에서 해당 컴포넌트를 사용할 때 그 앱의 node_modules에서 리액트를 가져옵니다.\n\n따라서 이 문제를 마주하게 되면,\n\n- 반드시 확인해야 할 점은 컴포넌트의 package.json에서 dependencies가 아닌 peerDependencies로 리액트가 추가되었는지 확인하는 것입니다.\n- 컴포넌트의 번들러(Webpack의 externals 및 Rollup의 external)에서도 리액트를 외부 종속성으로 표시해야 합니다. 이렇게 하면 번들에 추가되지 않습니다.\n- 이상적으로는 위 두 가지가 문제를 해결해야 합니다. 그러나 문제가 지속되는 경우, 앱의 개발 Webpack 구성에서 리액트에 대한 별칭을 작성하고 아래와 같이 앱의 리액트 버전으로 해결합니다.\n\n```js\n// webpack.config.js\nresolve: {\n  alias: {\n    react: path.resolve('./node_modules/react'),\n}\n```\n\n<div class=\"content-ad\"></div>\n\n## TypeScript\n\nTypeScript에는 preserveSymlinks 옵션이 있어요. 문서에 따르면, 이 옵션은 Webpack의 resolve.symlinks와 반대 효과를 나타냅니다. 그런데 제가 지금까지 제 어플리케이션에 이 옵션을 조정해야 했던 적은 없어요. preserveSymlinks의 효과를 확인한 케이스가 두 가지 있었어요.\n\n- TypeScript를 활성화하고 Webpack으로 번들링한 프로젝트\n- TypeScript를 활성화하고 tsc를 사용해 변환한 NodeJS 프로젝트\n\n두 경우 모두, preserveSymlinks: true로 생성된 파일은 preserveSymlinks: false로 생성된 파일과 동일했어요. 그래서 이 옵션의 유틸리티를 확인하지 못했습니다.\n\n<div class=\"content-ad\"></div>\n\n# NodeJS\n\nNodeJS에는 링킹과 관련된 2가지 옵션이 있어요\n\n- — preserve-symlinks\n- — preserve-symlinks-main\n\n이 옵션들에 대한 자세한 설명은 NodeJS 문서에 있어요. 하지만 제가 어떤 앱에서도 이것들을 사용하지 않고도 링킹이 잘 동작했어요.\n\n<div class=\"content-ad\"></div>\n\n# 다른 링킹 문제 \n\n링크 명령은 항상 전체 종속성 트리를 해결합니다. 즉 npm install 처럼 노드_모듈을 삭제하고 npm install A 라고 쓴다면, package.json에 있는 전체 종속성 목록이 A와 함께 설치된다는 것을 알 수 있습니다. 마찬가지로 npm link A 를 실행할 때, npm은 패키지 A를 연결하고 package.json의 다른 종속성을 모두 설치합니다.\n\n나는 npm link의 이 동작과 관련된 몇 가지 링킹 문제를 알아 냈습니다.\n\n## 여러 패키지 연결\n\n<div class=\"content-ad\"></div>\n\n가정하자면 여러분이 패키지 A를 연결해 놓은 코드베이스가 있다고 해봅시다. 이제 동일한 코드베이스에 다른 패키지 B를 연결해야 합니다. npm link B 명령을 실행하면 A가 더 이상 연결되지 않는 것을 확인할 수 있을 겁니다. 이는 npm link B가 npm에게 B 패키지를 연결하고 package.json에 있는 모든 다른 의존성을 설치하도록 지시하기 때문입니다. npm이 이 작업을 수행하면 package A에 대한 연결이 덮어씌워지고 레지스트리에서 다운로드한 A의 버전으로 대체됩니다. package.json에 명시된 A의 버전이 레지스트리에 없으면 package A에 대한 터미널에서 404 오류가 발생하여 연결에 실패합니다. 그래서 A와 B를 모두 코드베이스에 연결하려면 npm link A B를 실행하세요.\n\n## 다른 패키지 설치하기\n\n가정하자면 여러분이 패키지 A를 연결해 놓은 코드베이스가 있다고 해봅시다. 새 패키지를 설치하면 A에 대한 연결이 사라지는 것을 알 수 있을 겁니다. 이는 npm install이 전체 트리를 다시 해석하고 A를 레지스트리에서 설치하여 연결을 덮어씌웠기 때문입니다. 만약 package.json에 명시된 A의 버전이 레지스트리에 없었다면 npm install이 404로 실패했을 겁니다. 이 문제를 해결하려면 모든 npm install 후에 연결해야 하는 모든 패키지들을 다시 연결하시면 됩니다.","ogImage":{"url":"/assets/img/2024-06-22-npmlink_0.png"},"coverImage":"/assets/img/2024-06-22-npmlink_0.png","tag":["Tech"],"readingTime":7},{"title":"HTTP2 특징 총정리","description":"","date":"2024-06-22 02:24","slug":"2024-06-22-OverviewofHTTP2Features","content":"\n\n![HTTP/2 Features](/assets/img/2024-06-22-OverviewofHTTP2Features_0.png)\n\nHTTP는 보안 부재와 최적 성능 부족이라는 두 가지 주요 단점이 있습니다.\n\nSSL/TLS의 도입으로 보안 문제는 극복되었지만, 성능 향상 측면에서는 부족했습니다. 이는 핸드쉐이크 암호화 프로세스를 최적화했지만, 전체 데이터 전송에 대한 더 나은 해결책을 제시하지 않았으며 여전히 \"장기 연결\"이라는 구식 기술에 의존하고 있었습니다.\n\n따라서 HTTPS가 성숙해지자, HTTP는 성능에 초점을 맞추고 또 다른 진화의 길을 걸어왔습니다.\n\n<div class=\"content-ad\"></div>\n\nHTTP의 역사로 돌아가면, 구글은 SPDY 프로토콜을 개척했고 이를 크롬 브라우저에 적용하여 HTTP 성능을 최적화한 “첫발”을 내딛었습니다.\n\n이어서 인터넷 공학 작업 국(IETF)은 다양한 당사자들의 참여를 통합하여 SPDY를 기반으로 하여 HTTP/1의 후계자인 오늘날의 주인공인 “HTTP/2”를 소개함으로써 성능 면에서 큰 도약을 이루었습니다.\n\n# 왜 HTTP/2.0 이 아닌가\n\n과연 이전 버전인 “1.0”과 “1.1.”처럼 HTTP/2가 “2.0”으로 명명되지 않은 이유가 궁금할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n실은 HTTP/2에 새로운 사용자들이 가장 자주 묻는 질문 중 하나이며, HTTP/2 작업 그룹은 이에 대한 설명을 제공했습니다.\n\n과거에 \"1.0\" 및 \"1.1\"을 사용한 것이 혼란과 오해를 초래하여 실제 사용 중인 버전을 구별하기 어렵게 만들었다고 믿습니다. 그래서, HTTP 프로토콜은 이제 미니 버전 번호를 사용하지 않고 주 버전 번호만 사용하기로 결정했습니다. 앞으로 \"HTTP/2.0\" 또는 \"HTTP/2.1\" 같은 것은 더 이상 없을 것이며 오직 \"HTTP/2\", \"HTTP/3\" 등만 사용될 것입니다.\n\n이 방식은 프로토콜 버전의 \"도약\"을 명확하고 모호하지 않게 하는데 도움이 되며, 이는 프로토콜이 더 오랜 기간 동안 안정적으로 유지되도록 합니다. HTTP 프로토콜의 각 새 버전은 상당한 차이를 가지며, 점진적인 개선은 없을 것입니다.\n\n# HTTP/1과의 호환성\n\n<div class=\"content-ad\"></div>\n\nHTTPS가 이미 보안에서 뛰어났기 때문에 HTTP/2의 유일한 초점은 성능 향상입니다.\n\n그러나 HTTP/2는 방대한 기대뿐만 아니라 HTTP/1의 거대한 역사적 부담도 갖고 있습니다. 따라서 어떠한 프로토콜 수정도 호환성을 주요 목표로 신중히 고려되어야 합니다. 그렇지 않으면 TLS 사례에서와 같이 기존 자산들에 심각한 혼란을 초래할 수 있습니다 (TLS 1.2와 호환성을 위해 \"위장\"이 필요했던 것과 같이).\n\n그럼 HTTP/2는 어떻게 이를 달성할까요?\n\n기능적 호환성을 유지하기 위해 HTTP/2는 HTTP를 \"의미론\"과 \"구문\" 두 부분으로 분할합니다. \"의미론\" 레이어는 동일하게 유지되어 HTTP/1과 완전히 일관성이 있습니다 (즉, RFC 7231). 요청 방법, URI, 상태 코드 및 헤더 필드와 같은 개념은 모두 유지되어 다시 배우는 필요가 없습니다. HTTP 위에 구축된 응용 프로그램도 수정이 필요 없이 HTTP/2로 원활하게 전환할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nhttps://developer.mozilla.org/ko/docs/Web/HTTP/Headers/Accept-Encoding\n\n<div class=\"content-ad\"></div>\n\n먼저, HTTP/2는 메시지 헤더를 주요하게 개선했어요.\n\nHTTP/1에서는 \"Content-Encoding\" 헤더 필드를 사용하여 바디의 인코딩을 지정할 수 있었어요. 예를 들어 gzip 압축을 사용하여 대역폭을 저장할 수 있죠. 그러나 메시지의 다른 구성 요소인 헤더는 무시되고 최적화가 부족했어요.\n\n보통 메시지의 헤더는 \"User Agent\", \"Cookie\", \"Accept\", \"Server\"와 같은 많은 고정 헤더 필드를 가지고 있어요. 이는 수백 바이트에서 심지어 몇 천 바이트에 이르기도 하죠. 한편, 바디는 종종 GET 요청이나 204/301/304 응답과 같이 몇십 바이트만 포함하곤 해요. 이러한 이유로 헤더가 '지배적인 요인'으로 나타났어요. 게다가, 수천이나 수백만에 이르는 요청-응답 메시지 중 많은 필드 값이 반복되면서 상당한 낭비가 발생했어요. \"롱테일 효과\"는 이러한 고도 중복 데이터로 인해 상당한 대역폭이 소비되는 결과를 가져와요.\n\n그래서 HTTP/2는 주요 성능 향상으로 '헤더 압축'에 초점을 맞추었어요. 예상하신 대로, 최적화 방법은 여전히 '압축'이에요.\n\n<div class=\"content-ad\"></div>\n\n그러나 HTTP/2는 전통적인 압축 알고리즘을 사용하지 않습니다. 대신 전용 \"HPACK\" 알고리즘을 개발했는데, 이는 클라이언트와 서버 양쪽에서 \"사전\"을 설정합니다. 반복되는 문자열을 나타내는 데 인덱스 번호를 사용하고 허프만 코딩을 사용하여 정수와 문자열을 압축하여 50%에서 90%의 높은 압축률을 달성합니다.\n\n# 이진 형식\n\nHTTP/1의 메시지의 평문 형식에 이미 익숙할 수 있습니다. 이 형식은 \"이해하기 쉬우며\" 간단한 도구로 개발 및 디버그할 수 있어 매우 편리합니다.\n\n그러나 HTTP/2는 이러한 측면에서 \"타협\"하지 않으며 10년이 넘도록 지속되어 온 현재 상태를 변경하기로 결정했습니다. 인간이 읽을 수 있는 ASCII 코드 대신 하위 수준의 TCP/IP 프로토콜에 더 가까워지는 쪽으로 이동하여 완전히 이진 형식을 채택합니다.\n\n<div class=\"content-ad\"></div>\n\n비록 사용자 친화적이지는 않지만 컴퓨터 구문 분석을 크게 용이하게 만든다. 일반 텍스트의 경우, 대소문자 구분, 공백 문자, 캐리지 리턴, 줄 바꿈, 부족하거나 추가된 문자 등과 같은 모호성이 쉽게 발생할 수 있다. 이러한 것들을 처리하기 위해 프로그램은 복잡한 상태 기계를 사용해야 하며, 이는 비효율적이고 번거로울 수 있다.\n\n반면에 이진(binary)은 오직 \"0\"과 \"1\"로 이루어져 있어 필드 크기, 순서, 플래그 비트 및 기타 형식을 엄격히 정의할 수 있다. 구문 분석은 모호하지 않고, 구현은 간단하며, 콤팩트하고 빠르며 \"내부 효율성\"을 달성할 수 있다.\n\n이진 형식을 기반으로, HTTP/2는 \"급진적인\" 개혁을 시작했다.\n\nTCP 프로토콜의 일부 기능을 응용 계층으로 이동하여 원래의 \"헤더+바디(본문)\" 메시지를 여러 개의 작은 이진 \"프레임\"으로 분해하였으며, \"헤더\" 프레임은 헤더 데이터를 포함하고 \"데이터\" 프레임은 엔티티 데이터를 포함하고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n그 접근 방식은 \"Chunked\" 전송 인코딩과 약간 유사하며, \"작은 부분으로 분해\"하는 원칙을 따릅니다. 그러나 HTTP/2가 데이터를 프레임으로 분할한 후에는 메시지의 \"Header+Body\" 구조가 완전히 사라지고 프로토콜은 \"조각\"만을 처리합니다.\n\n![HTTP/2 Features](/assets/img/2024-06-22-OverviewofHTTP2Features_1.png)\n\n# 가상 '스트림'\n\n메시지의 조각들이 목적지에 도착하면 어떻게 조립될까요?\n\n<div class=\"content-ad\"></div>\n\nHTTP/2는 \"스트림\"이라는 개념을 정의하는데, 이는 이진 프레임의 양방향 시퀀스입니다. 각 메시지 왕복은 고유한 스트림 ID가 할당됩니다. 이를 가상의 \"데이터 스트림\"으로 생각할 수 있는데, 순서대로 데이터 프레임의 시리즈가 흐르는 것입니다. 이러한 데이터 프레임은 HTTP/1의 요청 및 응답 메시지를 형성하기 위해 순서대로 조립됩니다.\n\n\"스트림\"이 가상이며 실제로 존재하지 않기 때문에, HTTP/2는 단일 TCP 연결을 사용하여 여러 \"단편화된\" 메시지를 동시에 전송할 수 있습니다. 이를 \"다중화\"라고 하며, 단일 연결을 통해 여러 양방향 통신이 처리되는 것입니다.\n\n\"스트림\"의 관점에서 메시지는 순서가 지정된 \"프레임\"의 시퀀스이며, \"연결\"의 관점에서 메시지는 순서대로 받아들여지고 보내집니다. 여러 요청/응답이 있을 때 순차적인 관계가 더 이상 존재하지 않으므로, 줄 서서 기다릴 필요가 없어지며 \"헤드오브라인 차단\" 문제가 제거되고 지연 시간이 줄어들며 연결 활용도가 크게 증가합니다.\n\n![이미지](/assets/img/2024-06-22-OverviewofHTTP2Features_2.png)\n\n<div class=\"content-ad\"></div>\n\n네트워크 연결을 더 잘 활용하고 처리량을 늘리기 위해 HTTP/2는 가상 \"스트림\"을 관리하기 위해 일부 제어 프레임을 추가했습니다. 이는 우선순위 및 플로우 제어와 같은 기능을 구현하며 TCP 프로토콜과 매우 유사합니다.\n\n또한 HTTP/2는 기존의 \"요청-응답\" 작업 방식을 어느 정도 변경합니다. 서버는 더 이상 요청에 순응적으로 응답하는 것이 아니라, 클라이언트에게 메시지를 전송하기 위해 \"스트림\"을 미리 생성할 수도 있습니다. 예를 들어, 브라우저가 HTML을 요청할 때 서버가 클라이언트에게 사용할 수 있는 JS 및 CSS 파일을 푸시할 수 있어 대기 시간이 줄어듭니다. 이를 \"서버 푸시\"라고 하며, 캐시 푸시로도 알려져 있습니다.\n\n# 보안 강화\n\n호환성을 고려해 HTTP/2는 HTTP/1의 평문 기능을 계속 유지하여 데이터를 평문으로 전송할 수 있도록 합니다. 이는 암호화된 통신을 요구하지 않지만, 여전히 형식은 이진(binary)이며 복호화할 필요가 없습니다.\n\n<div class=\"content-ad\"></div>\n\n그러나 HTTPS가 주류이며 Chrome 및 Firefox와 같은 주요 브라우저는 암호화된 HTTP/2만 지원한다고 공개적으로 발표했기 때문에 실제로 HTTP/2는 암호화됩니다. 이것은 인터넷에서 흔히 볼 수 있는 HTTP/2가 TLS를 통해 실행되는 \"https\" 프로토콜 이름을 사용한다는 것을 의미합니다.\n\n암호화된 버전과 평문 버전을 구별하기 위해 HTTP/2 프로토콜은 두 개의 문자열 식별자를 정의합니다. 암호화된 HTTP/2의 경우 \"h2\"이고 평문 HTTP/2의 경우 \"h2c\"이며 여기서 \"c\"는 \"클리어 텍스트\"를 나타냅니다.\n\nHTTP/2 표준이 2015년에 제정될 때 SSL/TLS의 많은 취약점이 이미 발견되었고 새로운 TLS1.3이 아직 출시되지 않은 상황이었습니다. 따라서 HTTP/2의 암호화된 버전은 보안 측면에서 강화되었으며 기본 통신 프로토콜이 적어도 TLS1.2 이상이어야 하며 포워드 시크리시와 SNI(서버 이름 지칭)를 지원하고 약간의 여전콜 암호 알고리즘 몇백 개를 블랙리스트에 올려두었습니다. DES, RC4, CBC 및 SHA-1과 같은 약한 암호 알고리즘은 HTTP/2에서 사용할 수 없으며 이는 하위 수준에서 \"TLS1.25\"를 사용하는 것과 같습니다.\n\n# 프로토콜 스택\n\n<div class=\"content-ad\"></div>\n\n다음 다이어그램은 HTTP/1, HTTPS 및 HTTP/2의 프로토콜 스택을 비교한 것입니다. HTTP/2는 \"HPack,\" \"Stream,\" 및 \"TLS1.2\" 위에 구축되어 있어 HTTP/1 및 HTTPS보다 약간 더 복잡한 것을 명확히 볼 수 있습니다.\n\n![](/assets/img/2024-06-22-OverviewofHTTP2Features_3.png)\n\nHTTP/2의 내부 구현은 복잡할지라도, 그 \"의미론\"은 여전히 간단한 HTTP/1과 같습니다. 이전에 학습한 지식은 더 이상 사용되지 않지 않고 여전히 적용할 수 있습니다.\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\n오늘은 HTTP/2의 중요한 기능들을 간단히 소개했어요. 이론에 더 초점을 맞춰서 설명했어요. 다음에는 Wireshark를 사용하여 패킷을 캡처하고 HTTP/2의 헤더 압축, 이진 프레임, 스트림 기능에 대해 자세히 설명할 거예요.\n\n- HTTP 프로토콜에서는 작은 버전 번호를 제거했기 때문에 HTTP/2의 공식 이름은 2.0이 아니에요.\n- HTTP/2는 HTTP/1과 의미론적으로 호환되며, 요청 방법 및 URI와 같은 전통적인 개념을 유지해요.\n- HTTP/2는 헤더 정보를 압축하는 \"HPACK\" 알고리즘을 사용하여 중복 데이터를 제거하여 대역폭을 절약해요.\n- HTTP/2의 메시지는 더 이상 \"헤더+바디\" 형식이 아니라 여러 이진 \"프레임\"으로 분산돼요.\n- HTTP/2는 가상 \"스트림\"을 사용하여 메시지를 전송하며, \"헤드-오브-라인 차단\" 문제를 해결하고 \"멀티플렉싱\"을 통해 연결 이용률을 향상시켜요.\n- HTTP/2는 보안을 강화하며, 최소 TLS 1.2를 요구하고 많은 취약한 암호 스위트를 비활성화해요.\n\n![HTTP/2 기능 개요](/assets/img/2024-06-22-OverviewofHTTP2Features_4.png)","ogImage":{"url":"/assets/img/2024-06-22-OverviewofHTTP2Features_0.png"},"coverImage":"/assets/img/2024-06-22-OverviewofHTTP2Features_0.png","tag":["Tech"],"readingTime":7}],"page":"28","totalPageCount":154,"totalPageGroupCount":8,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true}