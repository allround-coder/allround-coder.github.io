{"pageProps":{"posts":[{"title":"파스트 API와 RabbitMQ를 이용한 엔드-투-엔드 마이크로서비스 구축하기 포괄적 안내","description":"","date":"2024-06-20 01:54","slug":"2024-06-20-BuildingEnd-to-EndMicroserviceswithFastAPIandRabbitMQAComprehensiveGuide","content":"\n\n\n![image](/assets/img/2024-06-20-BuildingEnd-to-EndMicroserviceswithFastAPIandRabbitMQAComprehensiveGuide_0.png)\n\n# 소개:\n\n최근 몇 년간, 마이크로서비스 아키텍처는 확장 가능하고 유지보수 가능하며 유연한 애플리케이션을 만드는 능력 때문에 인기를 얻었습니다. 이 블로그 포스트에서는 마이크로서비스 아키텍처의 개념을 탐구하고, 파이썬 생태계의 강력한 도구인 FastAPI와 RabbitMQ를 사용하여 간단한 마이크로서비스를 구축하는 방법을 보여드리겠습니다.\n\n# 몰리딕 아키텍처란? \n\n\n<div class=\"content-ad\"></div>\n\n단일체 아키텍처는 모든 비즈니스 관심을 결합하는 단일 대규모 컴퓨팅 네트워크로, 하나의 코드 베이스로 생각해 볼 수 있습니다. 애플리케이션의 모든 구성 요소를 하나의 지붕 아래에 모아둔 거대하고 빙하처럼 보이는 구조라고 상상해보세요. 단일체에서 변경을 하려면 전체 스택을 업데이트해야 하며, 이는 시간이 많이 소요되고 엄격할 수 있습니다. 아래 다이어그램에서 단일체 아키텍처의 예시를 볼 수 있습니다.\n\n![단일체 아키텍처 다이어그램](/assets/img/2024-06-20-BuildingEnd-to-EndMicroserviceswithFastAPIandRabbitMQAComprehensiveGuide_1.png)\n\n# 마이크로서비스 아키텍처란?\n\n반면에, 마이크로서비스 아키텍처는 응용 프로그램이 작은, 독립적으로 배포 가능한 서비스로 분할되는 접근 방식입니다. 각 서비스는 해당하는 비즈니스 로직과 데이터베이스를 갖고 있으며, 가벼운 프로토콜을 통해 다른 서비스와 통신합니다. 이 접근 방식은 빠른 개발 주기, 쉬운 유지보수, 그리고 더 나은 확장성을 가능하게 합니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-BuildingEnd-to-EndMicroserviceswithFastAPIandRabbitMQAComprehensiveGuide_2.png\" />\n\n# Monolithic vs. Microservice의 차이\n\n<img src=\"/assets/img/2024-06-20-BuildingEnd-to-EndMicroserviceswithFastAPIandRabbitMQAComprehensiveGuide_3.png\" />\n\n# RabbitMQ는 무엇이며, 왜 마이크로서비스를 구축하는 데 사용되는가?\n\n<div class=\"content-ad\"></div>\n\nRabbitMQ는 진보된 메시지 큐잉 프로토콜(AMQP)을 구현하는 메시지 브로커입니다. RabbitMQ는 분산 시스템의 다양한 구성 요소 사이에서 중개자 역할을 하여 효율적으로 통신하고 작업을 조정할 수 있도록 합니다. RabbitMQ가 마이크로서비스 아키텍처에서 흔히 사용되는 이유는 다음과 같습니다:\n\n- Decoupling: RabbitMQ는 시스템 구성 요소들을 비동기적으로 통신할 수 있게 함으로써 시스템을 분리하는 데 도움을 줍니다. 이는 서비스가 서로의 응답을 기다리지 않고 독립적으로 작동할 수 있어 더 견고하고 확장 가능한 시스템을 이끌어냅니다.\n- Load Balancing: RabbitMQ는 메시지를 여러 소비자 인스턴스에 분배함으로써 부하를 균형 있게 분배하고 효율적인 자원 활용을 보장합니다.\n- Fault Tolerance: RabbitMQ는 클러스터링과 복제를 지원하여 노드가 실패해도 메시지가 손실되지 않도록 합니다. 이는 시스템을 더욱 고장 내성이 뛰어나고 신뢰할 수 있도록 만듭니다.\n- Scalability: RabbitMQ를 사용하면 소비자 인스턴스나 클러스터에 노드를 추가하여 시스템을 확장할 수 있어 애플리케이션이 성장함에 따라 증가하는 메시지 트래픽을 처리할 수 있습니다.\n- Message Routing: RabbitMQ는 직접, 주제, 팬아웃과 같은 다양한 메시지 라우팅 메커니즘을 지원하여 라우팅 키나 패턴에 따라 특정 큐로 메시지를 전달할 수 있습니다.\n- Message Acknowledgment: RabbitMQ는 메시지 승인을 지원하여 메시지가 한 번만 처리되고 전송 중에 손실되지 않도록 보장합니다.\n- 전반적으로 RabbitMQ는 확장 가능하고 분리되고 고장 내성이 뛰어난 마이크로서비스 아키텍처를 구축하는 데 도움이 되는 견고하고 신뢰할 수 있는 메시징 시스템입니다.\n\n# 마이크로서비스 응용프로그램 코딩\n\n# 1. 프로젝트 소개\n\n<div class=\"content-ad\"></div>\n\n저희 어플리케이션은 네 가지 주요 서비스로 구성되어 있습니다:\n\n- Gateway Service: 이 서비스는 모든 들어오는 요청의 진입 지점 역할을 합니다. 요청을 적절한 마이크로서비스로 라우팅하고 어플리케이션의 전체적인 조정을 담당합니다.\n- ML Service: ML 서비스는 이미지 데이터를 처리하는 역할을 합니다. Keras OCR을 사용하여 이미지에서 텍스트를 추출하고 Gateway Service와 통신하여 이미지 데이터를 받아 추출된 텍스트를 전송합니다.\n- Auth Service: Auth 서비스는 사용자 인증 및 이메일 인증을 처리합니다. 사용자 등록, OTP 생성 및 검증, 이메일 인증 확인 기능이 포함되어 있습니다.\n- Notification Service: 이 서비스는 사용자에게 이메일을 보내는 역할을 합니다. 프로세스가 완료될 때 트리거됩니다.\n\n## 2. 준비 사항\n\n시작하기 전에 다음 사항을 확인해주세요:\n\n<div class=\"content-ad\"></div>\n\n- 시스템에 Docker가 설치되어 있습니다.\n- 시스템에 Python이 설치되어 있습니다.\n- Docker, Python 및 PostgreSQL에 대한 기본 지식이 있습니다.\n\n# 3. 요구 사항 설정\n\n## Docker를 사용하여 PostgreSQL 설치\n\nPostgreSQL을 Docker를 사용하여 설치하려면 다음 명령을 실행하십시오:\n\n<div class=\"content-ad\"></div>\n\n```js\n도커를 사용하여 RabbitMQ를 설치하기 위해서는 다음 명령어를 실행하세요:\n\n도커를 실행하여 RabbitMQ를 설치하려면 다음 명령어를 실행하세요:\n\n<div class=\"content-ad\"></div>\n\n# 4. 프로젝트 설정하기\n\n## A. 프로젝트 폴더 설정하기\n\nmicroservices-demo/\n│\n├── gateway/\n│ ├── rpc_client.py\n│ ├── .env \n│ ├── requirements.txt\n│ └── main.py\n│\n├── ml_services/\n│ ├── requirements.txt\n│ ├── artifacts/\n│ ├── .env\n│ └── main.py\n│\n├── notification_service/\n│ ├── email_service.py\n│ ├── requirements.txt\n│ ├── .env\n│ └── main.py\n│\n├── auth/\n│ ├── database.py\n│ ├── models.py\n│ ├── schemas.py\n│ ├── service.py\n│ ├── requirements.txt\n│ ├── .env\n│ └── main.py\n│\n└── README.md\n\n## B. 게이트웨이 구현하기\n\n<div class=\"content-ad\"></div>\n\n이제 게이트웨이 서비스를 구현해 봅시다. gateway/ 디렉토리에 main.py 파일을 만들어 아래 코드를 추가해주세요:\n\nfrom fastapi import FastAPI, HTTPException, File, UploadFile\nimport fastapi as _fastapi\nfrom fastapi.security import OAuth2PasswordBearer\nfrom dotenv import load_dotenv\nfrom jwt.exceptions import DecodeError\nfrom pydantic import BaseModel\nimport requests\nimport base64\nimport pika\nimport logging\nimport os\nimport jwt\nimport rpc_client\n\napp = FastAPI()\noauth2_scheme = OAuth2PasswordBearer(tokenUrl=\"token\")\n\n# 환경 변수 로드\nload_dotenv()\nlogging.basicConfig(level=logging.INFO)\n\n# 환경 변수 가져오기\nJWT_SECRET = os.environ.get(\"JWT_SECRET\")\nAUTH_BASE_URL = os.environ.get(\"AUTH_BASE_URL\")\nRABBITMQ_URL = os.environ.get(\"RABBITMQ_URL\")\n\n# RabbitMQ에 연결\nconnection = pika.BlockingConnection(pika.ConnectionParameters(RABBITMQ_URL))\nchannel = connection.channel()\nchannel.queue_declare(queue='gatewayservice')\nchannel.queue_declare(queue='ocr_service')\n\n# JWT 토큰 유효성 검사\nasync def jwt_validation(token: str = _fastapi.Depends(oauth2_scheme)):\n    try:\n        payload = jwt.decode(token, JWT_SECRET, algorithms=[\"HS256\"])\n        return payload\n    except DecodeError:\n        raise HTTPException(status_code=401, detail=\"Invalid JWT token\")\n\n# 요청 바디를 위한 Pydantic 모델\nclass GenerateUserToken(BaseModel):\n    username: str\n    password: str\n\nclass UserCredentials(BaseModel):\n    username: str\n    password: str\n\nclass UserRegisteration(BaseModel):\n    name: str\n    email: str\n    password: str\n\nclass GenerateOtp(BaseModel):\n    email: str\n\nclass VerifyOtp(BaseModel):\n    email: str\n    otp: int\n\n# 인증 라우트\n@app.post(\"/auth/login\", tags=['Authentication Service'])\nasync def login(user_data: UserCredentials):\n    try:\n        response = requests.post(f\"{AUTH_BASE_URL}/api/token\", json={\"username\": user_data.username, \"password\": user_data.password})\n        if response.status_code == 200:\n            return response.json()\n        else:\n            raise HTTPException(status_code=response.status_code, detail=response.json())\n    except requests.exceptions.ConnectionError:\n        raise HTTPException(status_code=503, detail=\"Authentication service is unavailable\")\n\n@app.post(\"/auth/register\", tags=['Authentication Service'])\nasync def registeration(user_data: UserRegisteration):\n    try:\n        response = requests.post(f\"{AUTH_BASE_URL}/api/users\", json={\"name\": user_data.name, \"email\": user_data.email, \"password\": user_data.password})\n        if response.status_code == 200:\n            return response.json()\n        else:\n            raise HTTPException(status_code=response.status_code, detail=response.json())\n    except requests.exceptions.ConnectionError:\n        raise HTTPException(status_code=503, detail=\"Authentication service is unavailable\")\n\n@app.post(\"/auth/generate_otp\", tags=['Authentication Service'])\nasync def generate_otp(user_data: GenerateOtp):\n    try:\n        response = requests.post(f\"{AUTH_BASE_URL}/api/users/generate_otp\", json={\"email\": user_data.email})\n        if response.status_code == 200:\n            return response.json()\n        else:\n            raise HTTPException(status_code=response.status_code, detail=response.json())\n    except requests.exceptions.ConnectionError:\n        raise HTTPException(status_code=503, detail=\"Authentication service is unavailable\")\n\n@app.post(\"/auth/verify_otp\", tags=['Authentication Service'])\nasync def verify_otp(user_data: VerifyOtp):\n    try:\n        response = requests.post(f\"{AUTH_BASE_URL}/api/users/verify_otp\", json={\"email\": user_data.email, \"otp\": user_data.otp})\n        if response.status_code == 200:\n            return response.json()\n        else:\n            raise HTTPException(status_code=response.status_code, detail=response.json())\n    except requests.exceptions.ConnectionError:\n        raise HTTPException(status_code=503, detail=\"Authentication service is unavailable\")\n\n# 확장 서비스 OCR 라우트\n@app.post('/ocr', tags=['Machine learning Service'])\ndef ocr(file: UploadFile = File(...), payload: dict = _fastapi.Depends(jwt_validation)):\n    # 파일을 임시 위치에 저장\n    with open(file.filename, \"wb\") as buffer:\n        buffer.write(file.file.read())\n\n    ocr_rpc = rpc_client.OcrRpcClient()\n\n    with open(file.filename, \"rb\") as buffer:\n        file_data = buffer.read()\n        file_base64 = base64.b64encode(file_data).decode()\n\n    request_json = {\n        'user_name': payload['name'],\n        'user_email': payload['email'],\n        'user_id': payload['id'],\n        'file': file_base64\n    }\n\n    # OCR 마이크로서비스에 요청 JSON을 사용하여 호출\n    response = ocr_rpc.call(request_json)\n\n    # 임시 이미지 파일 삭제\n    os.remove(file.filename)\n    return response\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=5001, reload=True)\n\n게이트웨이 환경을 설정하려면 gateway 폴더에 .env 파일을 만드세요.\n\nAUTH_BASE_URL=http://0.0.0.0:5000\nJWT_SECRET=e56623570e0a0152989fd38e13da9cd6eb7031e4e039e939ba845167ee59b496\nRABBITMQ_URL=localhost\n\n<div class=\"content-ad\"></div>\n\n다른 마이크로서비스와 통신하기 위해 RabbitMQ를 사용할 것입니다. 이는 서비스 간 비동기 메시징을 가능하게 하는 메시지 브로커입니다. RabbitMQ 서버와의 통신을 처리하기 위해 gateway/ 디렉토리에 rpc_client.py 파일을 생성할 것입니다.\n\nimport pika\nimport uuid\nimport json\nfrom dotenv import load_dotenv\nimport os\n\n# 환경 변수 로딩\nload_dotenv()\nRABBITMQ_URL = os.environ.get(\"RABBITMQ_URL\")\n\nclass OcrRpcClient(object):\n\n    def __init__(self):\n        self.connection = pika.BlockingConnection(\n            pika.ConnectionParameters(host=RABBITMQ_URL))\n\n        self.channel = self.connection.channel()\n\n        result = self.channel.queue_declare(queue='', exclusive=True)\n        self.callback_queue = result.method.queue\n\n        self.channel.basic_consume(\n            queue=self.callback_queue,\n            on_message_callback=self.on_response,\n            auto_ack=True)\n\n    def on_response(self, ch, method, props, body):\n        if self.corr_id == props.correlation_id:\n            self.response = body\n\n    def call(self, message):\n        self.response = None\n        self.corr_id = str(uuid.uuid4())\n        self.channel.basic_publish(\n            exchange='',\n            routing_key='ocr_service',\n            properties=pika.BasicProperties(\n                reply_to=self.callback_queue,\n                correlation_id=self.corr_id,\n            ),\n            body=json.dumps(message))\n        while self.response is None:\n            self.connection.process_data_events()\n        response_json = json.loads(self.response)\n        return response_json\n\n이 코드는 RabbitMQ를 사용하여 OCR 마이크로서비스(ML 마이크로서비스)로 메시지를 보내기 위한 클라이언트 클래스인 OcrRpcClient를 정의합니다. 연결을 초기화하고, 응답을 위한 콜백 큐를 설정하고, 메시지를 보내고 응답을 비동기적으로 받을 수 있는 방법을 제공합니다.\n\n- 초기화(__init__):\n\n<div class=\"content-ad\"></div>\n\nRabbitMQ에 연결을 설정합니다. 채널을 생성하고 고유한 콜백 큐를 선언합니다. 콜백 큐에서 응답을 수신하기 위해 소비자를 설정합니다.\n\n2. 요청 보내기 (호출):\n\nOCR 마이크로서비스(ML 마이크로서비스)에 메시지를 보냅니다. 콜백 큐에서 응답을 기다리고 반환합니다.\n\n이 클래스는 RabbitMQ를 사용하여 게이트웨이 서비스가 OCR 마이크로서비스와 효율적으로 통신할 수 있게 합니다.\n\n<div class=\"content-ad\"></div>\n\n## C. Auth 마이크로서비스 구현\n\n이 코드는 FastAPI를 사용하여 사용자 등록, 로그인, JWT 토큰 생성, OTP를 사용한 이메일 확인 및 사용자 프로필 검색을 제공하는 인증 서비스를 구현합니다. 데이터베이스 작업에는 SQLAlchemy를 사용하고 OTP 이메일을 보내기 위해 RabbitMQ를 사용합니다. 이 서비스에는 사용자 생성, JWT 토큰 생성, 사용자 프로필 검색 및 이메일 확인을 위한 OTP 확인에 대한 엔드포인트가 포함되어 있습니다.\n\nfrom typing import List\nfrom fastapi import HTTPException \nimport fastapi as _fastapi\nimport schemas as _schemas\nimport sqlalchemy.orm as _orm\nimport models as _models\nimport service as _services\nimport logging\nimport database as _database\nimport pika\n\n# rabbitmq connection\nconnection = pika.BlockingConnection(pika.ConnectionParameters(host=\"localhost\"))\nchannel = connection.channel()\nchannel.queue_declare(queue='email_notification')\n\ndef get_db():\n    db = _database.SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n\napp = _fastapi.FastAPI()\nlogging.basicConfig(level=logging.INFO)\n_models.Base.metadata.create_all(_models.engine)\n\n@app.post(\"/api/users\", tags=['사용자 인증'])\nasync def create_user(\n    user: _schemas.UserCreate, \n    db: _orm.Session = _fastapi.Depends(_services.get_db)):\n    db_user = await _services.get_user_by_email(email=user.email, db=db)\n\n    if db_user:\n        logging.info('해당 이메일로 이미 가입된 사용자가 있습니다')\n        raise _fastapi.HTTPException(\n            status_code=200,\n            detail=\"해당 이메일로 이미 가입된 사용자가 있습니다\")\n\n    user = await _services.create_user(user=user, db=db)\n\n    return _fastapi.HTTPException(\n            status_code=201,\n            detail=\"사용자 등록이 완료되었습니다. 계정을 활성화하려면 이메일을 확인하세요!\")\n\n# API 상태 확인 엔드포인트\n@app.get(\"/check_api\")\nasync def check_api():\n    return {\"status\": \"API와 연결되었습니다\"}\n\n@app.post(\"/api/token\", tags=['사용자 인증'])\nasync def generate_token(\n    user_data: _schemas.GenerateUserToken,\n    db: _orm.Session = _fastapi.Depends(_services.get_db)):\n    user = await _services.authenticate_user(email=user_data.username, password=user_data.password, db=db)\n\n    if user == \"is_verified_false\":\n        logging.info('이메일 확인이 필요합니다. 계속하려면 이메일을 확인하세요.')\n        raise _fastapi.HTTPException(\n            status_code=403, detail=\"이메일 확인이 필요합니다. 계속하려면 이메일을 확인하세요.\")\n\n    if not user:\n        logging.info('잘못된 자격 증명')\n        raise _fastapi.HTTPException(\n            status_code=401, detail=\"잘못된 자격 증명\")\n\n    logging.info('JWT 토큰이 생성되었습니다.')\n    return await _services.create_token(user=user)\n\n@app.get(\"/api/users/me\", response_model=_schemas.User, tags=['사용자 인증'])\nasync def get_user(user: _schemas.User = _fastapi.Depends(_services.get_current_user)):\n    return user\n\n@app.get(\"/api/users/profile\", tags=['사용자 인증'])\nasync def get_user(email: str, db: _orm.Session = _fastapi.Depends(_services.get_db)):\n    return db.query(_models.User and _models.Address).filter_by(id=1).first()\n\n@app.post(\"/api/users/generate_otp\", response_model=str, tags=[\"사용자 인증\"])\nasync def send_otp_mail(userdata: _schemas.GenerateOtp, db: _orm.Session = _fastapi.Depends(_services.get_db)):\n    user = await _services.get_user_by_email(email=userdata.email, db=db)\n\n    if not user:\n        raise _fastapi.HTTPException(status_code=404, detail=\"사용자를 찾을 수 없습니다\")\n\n    if user.is_verified:\n        raise _fastapi.HTTPException(status_code=400, detail=\"이미 확인된 사용자입니다\")\n\n    # OTP 생성 및 전송\n    otp = _services.generate_otp()\n    print(otp)\n    _services.send_otp(userdata.email, otp, channel)\n\n    # OTP를 데이터베이스에 저장\n    user.otp = otp\n    db.add(user)\n    db.commit()\n\n    return \"이메일로 OTP가 전송되었습니다\"\n\n@app.post(\"/api/users/verify_otp\", tags=[\"사용자 인증\"])\nasync def verify_otp(userdata: _schemas.VerifyOtp, db: _orm.Session = _fastapi.Depends(_services.get_db)):\n    user = await _services.get_user_by_email(email=userdata.email, db=db )\n\n    if not user:\n        raise _fastapi.HTTPException(status_code=404, detail=\"사용자를 찾을 수 없습니다\")\n\n    if not user.otp or user.otp != userdata.otp:\n        raise _fastapi.HTTPException(status_code=400, detail=\"잘못된 OTP\")\n\n    # 사용자의 is_verified 필드 업데이트\n    user.is_verified = True\n    user.otp = None  # OTP 초기화\n    db.add(user)\n    db.commit()\n\n    return \"이메일 확인이 성공적으로 완료되었습니다\"\n\nif __name__ == \"__main__\":\n    import uvicorn\n    uvicorn.run(\"main:app\", host=\"0.0.0.0\", port=5000, reload=True)\n\n이 코드는 PostgreSQL 데이터베이스에 연결하기 위해 SQLAlchemy 엔진과 세션 메이커를 설정합니다. dotenv를 사용하여 환경 변수에서 데이터베이스 연결 세부 정보를 로드합니다. DATABASE_URL은 호스트, 데이터베이스 이름, 사용자 이름 및 암호를 포함하여 검색된 환경 변수를 사용하여 구성됩니다. 데이터베이스 연결 세부를 사용하여 create_engine를 사용하여 엔진을 생성하고 해당 엔진에 바인딩된 세션 메이커인 SessionLocal을 정의합니다. ORM 모델을 정의하는 Declarative Base로 사용하기 위해 Base 변수가 초기화됩니다.\n\n<div class=\"content-ad\"></div>\n\nimport sqlalchemy as _sql\nimport sqlalchemy.ext.declarative as _declarative\nimport sqlalchemy.orm as _orm\nfrom dotenv import load_dotenv\nimport os\n\n# .env 파일에서 환경 변수를 불러옵니다\nload_dotenv()\n\n# 환경 변수를 가져옵니다\npostgres_host = os.environ.get(\"POSTGRES_HOST\")\npostgres_db = os.environ.get(\"POSTGRES_DB\")\npostgres_user = os.environ.get(\"POSTGRES_USER\")\npostgres_password = os.environ.get(\"POSTGRES_PASSWORD\")\n\n# PostgreSQL 서버가 로컬에서 실행 중이라고 가정하고 'mydatabase'라는 이름의 데이터베이스가 있다고 가정합니다\nDATABASE_URL = f\"postgresql://{postgres_user}:{postgres_password}@{postgres_host}/{postgres_db}\"\n\nengine = _sql.create_engine(DATABASE_URL)\nSessionLocal = _orm.sessionmaker(autocommit=False, autoflush=False, bind=engine)\nBase = _declarative.declarative_base()\r\n\n이 코드는 사용자 및 주소 테이블에 대한 SQLAlchemy 모델을 정의하며, 사용자 정보 및 주소를 저장하고 이들 사이의 관계를 설정합니다. 또한 제공된 엔진을 사용하여 데이터베이스에 테이블을 생성합니다.\n\nimport datetime as _dt\nimport sqlalchemy as _sql\nimport sqlalchemy.orm as _orm\nimport passlib.hash as _hash\nfrom database import Base, engine\nimport database as _database\n\nBase.metadata.create_all(engine)\n\nclass User(_database.Base):\n    __tablename__ = \"users\"\n    id = _sql.Column(_sql.Integer, primary_key=True, index=True)\n    name = _sql.Column(_sql.String)\n    email = _sql.Column(_sql.String, unique=True, index=True)\n    is_verified = _sql.Column(_sql.Boolean, default=False)\n    otp = _sql.Column(_sql.Integer)\n    hashed_password = _sql.Column(_sql.String)\n    addresses = _orm.relationship(\"Address\", back_populates=\"user\")\n    date_created = _sql.Column(_sql.DateTime, default=_dt.datetime.utcnow)\n\n    def verify_password(self, password: str):\n        return _hash.bcrypt.verify(password, self.hashed_password)\n\nclass Address(_database.Base):\n    __tablename__ = \"addresses\"\n    id = _sql.Column(_sql.Integer, primary_key=True, index=True)\n    street = _sql.Column(_sql.String)\n    landmark = _sql.Column(_sql.String)\n    city = _sql.Column(_sql.String)\n    country = _sql.Column(_sql.String)\n    pincode = _sql.Column(_sql.String)\n    user_id = _sql.Column(_sql.Integer, _sql.ForeignKey(\"users.id\"))\n    user = _orm.relationship(\"User\", back_populates=\"addresses\")\n    latitude = _sql.Column(_sql.Float)\n    longitude = _sql.Column(_sql.Float)\r\n\n이 코드는 사용자 관련 데이터 구조에 대한 Pydantic 모델을 정의하며, 사용자 생성, 인증 및 OTP 확인용입니다. 위치 정보를 위한 주소 모델도 포함되어 있습니다. 이 모델들은 사전 속성으로부터 인스턴스를 자동으로 생성하도록 구성되어 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이 코드는 사용자 인증 및 OTP(일회용 비밀번호) 생성 및 확인을 위한 다양한 함수 및 종속성을 정의합니다. HTTP 요청을 처리하기 위해 FastAPI를 사용하며, 데이터베이스 작업을 위해 SQLAlchemy를 사용하고 데이터 유효성 검사 및 직렬화를 위해 Pydantic을 사용하며, 인증을 위해 JWT를 사용하고, 이메일 알림을 보내기 위해 RabbitMQ를 사용합니다. 이 함수들은 데이터베이스 생성, 데이터베이스 세션 가져오기, 새 사용자 생성, 사용자 인증, JWT 토큰 생성, JWT 토큰에서 현재 사용자 가져오기, 무작위 OTP 생성, RabbitMQ에 연결 및 OTP 이메일 알림 전송 등이 포함됩니다.\n\n환경 변수 로드\n\nJWT_SECRET = os.getenv(\"JWT_SECRET\")\nRABBITMQ_URL = os.getenv(\"RABBITMQ_URL\")\noauth2schema = _security.OAuth2PasswordBearer(\"/api/token\")\n\n데이터베이스 생성\n\ndef create_database():\n    # 데이터베이스 테이블 생성\n    return _database.Base.metadata.create_all(bind=_database.engine)\n\n데이터베이스 세션 가져오기\n\ndef get_db():\n    # 데이터베이스 세션을 얻는 의존성\n    db = _database.SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n\n이메일별 사용자 가져오기\n\nasync def get_user_by_email(email: str, db: _orm.Session):\n    # 데이터베이스에서 이메일별로 사용자 검색\n    return db.query(_models.User).filter(_models.User.email == email and _models.User.is_verified == True).first()\n\n새 사용자 생성\n\nasync def create_user(user: _schemas.UserCreate, db: _orm.Session):\n    # 데이터베이스에 새 사용자 생성\n    try:\n        valid = _email_check.validate_email(user.email)\n        name = user.name\n        email = valid.email\n    except _email_check.EmailNotValidError:\n        raise _fastapi.HTTPException(status_code=404, detail=\"정확한 이메일을 입력하세요\")\n\n    user_obj = _models.User(email=email, name=name, hashed_password=_hash.bcrypt.hash(user.password))\n    db.add(user_obj)\n    db.commit()\n    db.refresh(user_obj)\n    return user_obj\n\n사용자 인증\n\nasync def authenticate_user(email: str, password: str, db: _orm.Session):\n    # 사용자 인증\n    user = await get_user_by_email(email=email, db=db)\n\n    if not user:\n        return False\n    \n    if not user.is_verified:\n        return 'is_verified_false'\n    \n    if not user.verify_password(password):\n        return False\n\n    return user\n\nJWT 토큰 생성\n\nasync def create_token(user: _models.User):\n    # 인증을 위한 JWT 토큰 생성\n    user_obj = _schemas.User.from_orm(user)\n    user_dict = user_obj.model_dump()\n    del user_dict[\"date_created\"]\n    token = jwt.encode(user_dict, JWT_SECRET, algorithm=\"HS256\")\n    return dict(access_token=token, token_type=\"bearer\")\n\n현재 사용자 가져오기\n\nasync def get_current_user(db: _orm.Session = _fastapi.Depends(get_db), token: str = _fastapi.Depends(oauth2schema)):\n    # JWT 토큰에서 현재 인증된 사용자 가져오기\n    try:\n        payload = jwt.decode(token, JWT_SECRET, algorithms=[\"HS256\"])\n        user = db.query(_models.User).get(payload[\"id\"])\n    except:\n        raise _fastapi.HTTPException(status_code=401, detail=\"유효하지 않은 이메일 또는 비밀번호\")\n    return _schemas.User.from_orm(user)\n\n랜덤 OTP 생성\n\ndef generate_otp():\n    # 랜덤 OTP 생성\n    return str(random.randint(100000, 999999))\n\nRabbitMQ에 연결\n\ndef connect_to_rabbitmq():\n    # RabbitMQ에 연결\n    while True:\n        try:\n            connection = pika.BlockingConnection(pika.ConnectionParameters(RABBITMQ_URL))\n            return connection\n        except pika.exceptions.AMQPConnectionError:\n            print(\"RabbitMQ에 연결하지 못했습니다. 5초 후 다시 시도 중...\")\n            time.sleep(5)\n\nOTP 이메일 알림 전송\n\ndef send_otp(email, otp, channel):\n    # RabbitMQ를 사용하여 OTP 이메일 알림 전송\n    connection = connect_to_rabbitmq()\n    channel = connection.channel()\n    message = {'email': email,\n               'subject': '계정 확인 OTP 알림',\n               'other': 'null',\n               'body': f'계정 확인을 위한 OTP는 다음과 같습니다: {otp} \\n 계정 설정을 완료하려면 확인 페이지에 이 OTP를 입력하세요. \\n 이 OTP를 요청하지 않았다면 이 메시지를 무시해주세요.\\n 감사합니다 '\n               }\n\n    try:\n        queue_declare_ok = channel.queue_declare(queue='email_notification', passive=True)\n        current_durable = queue_declare_ok.method.queue\n\n        if current_durable:\n            if queue_declare_ok.method.queue != current_durable:\n                channel.queue_delete(queue='email_notification')\n                channel.queue_declare(queue='email_notification', durable=True)\n        else:\n            channel.queue_declare(queue='email_notification', durable=True)\n\n        channel.basic_publish(\n            exchange=\"\",\n            routing_key='email_notification',\n            body=json.dumps(message),\n            properties=pika.BasicProperties(\n                delivery_mode=pika.spec.PERSISTENT_DELIVERY_MODE\n            ),\n        )\n        print(\"OTP 이메일 알림 전송 완료\")\n    except Exception as err:\n        print(f\"메시지 전송 실패: {err}\")\n    finally:\n        channel.close()\n        connection.close()\n\n## D. 머신 러닝 마이크로서비스 구현\n\n<div class=\"content-ad\"></div>\n\n이 Python 스크립트는 RabbitMQ 서버에 연결하여 'ocr_service'라는 큐에서 메시지를 소비합니다. 메시지를받으면 OCRService 객체를 사용하여 처리하고 send_email_notification 함수를 사용하여 이메일 알림을 보내며, 그런 다음 응답을 응답 큐에 발행합니다. 각 메시지를 처리한 후 RabbitMQ에 메시지 전달을 인식합니다. 스크립트는 RabbitMQ가 전달할 수 있는 미인증 메시지의 수를 제한하는 prefetch count 1을 사용합니다.\n\nimport pika\nimport json\nfrom utils import OCRService\nfrom utils import send_email_notification\n\n# RabbitMQ에 연결\nconnection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost'))\nchannel = connection.channel()\nchannel.queue_declare(queue='ocr_service')\n\n# OCR 요청을 처리하기 위한 콜백 함수\ndef on_request(ch, method, props, body):\n    # OCR 서비스 초기화\n    ocr_service = OCRService()\n    # OCR 요청 처리\n    response = ocr_service.process_request(body)\n\n    # 이메일 알림 전송\n    send_email_notification(response['user_email'], response['ocr_text'], channel)\n\n    # 응답을 응답 큐에 발행\n    ch.basic_publish(exchange='',\n                     routing_key=props.reply_to,\n                     properties=pika.BasicProperties(correlation_id = \\\n                                                         props.correlation_id),\n                     body=json.dumps(response))\n    # 메시지 전달을 인식\n    ch.basic_ack(delivery_tag=method.delivery_tag)\n# prefetch count를 1로 설정\nchannel.basic_qos(prefetch_count=1)\n# 'ocr_service' 큐에서 메시지 수신\nchannel.basic_consume(queue='ocr_service', on_message_callback=on_request)\n# 메시지 수신 시작\nprint(\" [x] RPC 요청 대기중\")\nchannel.start_consuming()\r\n\nimport json\nimport base64\nimport pandas as pd\n#keras ocr pipeline and imports\nimport keras_ocr\nimport pika\n\nclass OCRService:\n   \n    def __init__(self):\n        self.keras_pipeline = keras_ocr.pipeline.Pipeline()\n\n    def keras_ocr(self, image_path):\n        results = self.keras_pipeline.recognize([image_path])\n        df = pd.DataFrame(results[0], columns=['text', 'bbox'])\n        words = df['text'].tolist()\n        sentence = ' '.join(words)\n        return sentence\n\n    def process_request(self, message):\n        message_body = json.loads(message)\n        user_name = message_body['user_name']\n        user_email = message_body['user_email']\n        user_id = message_body['user_id']\n        file_base64 = message_body['file']\n        print(f\" [x]user_id: {user_id} request recieved from gateway..\")\n        print(f\" [x]processing request for {user_name}\")\n\n        # file_base64에 base64로 인코딩된 문자열이 포함되어 있다고 가정\n        file_data = base64.b64decode(file_base64.encode())\n        # 디코드된 파일 데이터를 새 파일에 작성\n        with open('artifacts/decoded_file.png', 'wb') as f:\n            f.write(file_data)\n\n        image_path = \"artifacts/decoded_file.png\"\n        ocr_text = self.keras_ocr(image_path)\n        print(\" [^] OCR 처리 완료 !!!\")\n\n        response = {\n            \"user_id\": user_id,\n            \"user_name\": user_name,\n            \"user_email\": user_email,\n            \"ocr_text\": ocr_text\n        }\n\n        return response\n\ndef send_email_notification(email, ocr_text, channel):\n    # RabbitMQ를 사용하여 이메일 알림 전송\n    message = {\n        'email': email,\n        'subject':'OCR 처리 완료 !!',\n        'body':f'이미지에 대한 OCR (광학 문자 인식) 프로세스가 성공적으로 완료되었음을 알려드립니다.\\n 추출된 텍스트가 처리되어 사용할 준비가되었습니다.\\n\\n  OCR 텍스트 : {ocr_text}',\n        'other': 'null',\n       }\n\n    try:\n        channel.basic_publish(\n            exchange=\"\",\n            routing_key='email_notification',\n            body=json.dumps(message),\n            properties=pika.BasicProperties(\n                delivery_mode=pika.spec.PERSISTENT_DELIVERY_MODE\n            ),\n        )\n        print(\"OCR 처리 완료 이메일 알림 전송됨\")\n    except Exception as err:\n        print(f\"메시지 게시 실패: {err}\")\r\n\n## D. 알림 마이크로서비스 구현\n\n<div class=\"content-ad\"></div>\n\n이 스크립트는 \"email_notification\" 큐에서 메시지를 수신하는 RabbitMQ 소비자를 설정합니다. 메시지를 받으면 email_service 모듈의 notification 함수를 호출하여 알림 프로세스를 처리합니다. 성공하면 메시지를 확인하고, 그렇지 않으면 메시지를 거부하고 오류 메시지를 출력합니다.\n\nimport pika\nimport sys\nimport os\nimport time\nimport email_service\nfrom dotenv import load_dotenv\n\n# 환경 변수 로드\nload_dotenv()\nRABBITMQ_URL = os.environ.get(\"RABBITMQ_URL\")\n\ndef main():\n    # rabbitmq 연결\n    connection = pika.BlockingConnection(pika.ConnectionParameters(host=RABBITMQ_URL))\n    channel = connection.channel()\n\n    def callback(ch, method, properties, body):\n        try:\n            err = email_service.notification(body)\n            if err:\n                ch.basic_nack(delivery_tag=method.delivery_tag)\n            else:\n                ch.basic_ack(delivery_tag=method.delivery_tag)\n        except Exception as e:\n            print(f\"메시지 처리 중 오류 발생: {e}\")\n            ch.basic_nack(delivery_tag=method.delivery_tag)\n\n    channel.basic_consume(\n        queue=\"email_notification\", on_message_callback=callback\n    )\n\n    print(\"메시지 수신 대기 중. 종료하려면 CTRL+C를 누르세요\")\n\n    channel.start_consuming()\n\n\nif __name__ == \"__main__\":\n    try:\n        main()\n    except KeyboardInterrupt:\n        print(\"중단됨\")\n        try:\n            sys.exit(0)\n        except SystemExit:\n            os._exit(0)\n\nimport smtplib, os, json\nfrom email.message import EmailMessage\nfrom dotenv import load_dotenv\nfrom email.mime.text import MIMEText\n\nload_dotenv()\n\ndef notification(message):\n    try:\n        message = json.loads(message)\n        receiver_address = message[\"email\"]\n        subject = message[\"subject\"]\n        body = message[\"body\"]\n        other = message[\"other\"]\n\n        sender_address = os.environ.get(\"GMAIL_ADDRESS\")\n        sender_password = os.environ.get(\"GMAIL_PASSWORD\")\n\n        # Gmail SMTP 서버 설정\n        smtp_server = 'smtp.gmail.com'\n        smtp_port = 587\n\n        server = smtplib.SMTP(smtp_server, smtp_port)\n        server.starttls()\n        server.login(sender_address, sender_password)\n\n        # 이메일 메시지 작성\n        msg = MIMEText(body)\n        msg['Subject'] = subject\n        msg['From'] = sender_address\n        msg['To'] = receiver_address\n\n        server.sendmail(sender_address, receiver_address, msg.as_string())\n        server.quit()\n\n        print(\"이메일 발송 완료\")\n    except Exception as e:\n        print(f\"이메일 발송 실패: {e}\")\n\n# 애플리케이션 데모\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n마지막으로, FastAPI와 RabbitMQ를 사용하여 엔드 투 엔드 마이크로서비스 아키텍처를 성공적으로 구현했습니다. 사용자 인증 서비스, OCR 처리를 위한 머신 러닝 서비스 및 이메일 알림을 위한 알림 서비스를 어떻게 만드는지 보여드렸습니다.\n\n이 블로그를 통해 서비스 격리, 메시징 큐를 통한 통신, 확장성 및 성능을 위한 비동기 처리의 장점과 같은 마이크로서비스의 주요 개념에 대해 배웠습니다.\n\n프로젝트를 실행하려면 GitHub 저장소의 README 파일에 있는 지침을 따르세요. 읽어 주셔서 감사합니다. 이 프로젝트가 여러분께 영감을 주어 직접 마이크로서비스 아키텍처를 탐구하고 구현하는 데 도움이 되기를 바랍니다.\n\n<div class=\"content-ad\"></div>\n\n깃허브: [https://github.com/shantanu1905/fastapi-microservice-demo](https://github.com/shantanu1905/fastapi-microservice-demo)","ogImage":{"url":"/assets/img/2024-06-20-BuildingEnd-to-EndMicroserviceswithFastAPIandRabbitMQAComprehensiveGuide_0.png"},"coverImage":"/assets/img/2024-06-20-BuildingEnd-to-EndMicroserviceswithFastAPIandRabbitMQAComprehensiveGuide_0.png","tag":["Tech"],"readingTime":29},{"title":"파이썬을 활용한 비즈니스 계획 - 재고 및 현금 흐름 관리","description":"","date":"2024-06-20 01:50","slug":"2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement","content":"\n\n## 데이터 분석을 활용하여 소기업이 재고를 관리하고 유동성 요구를 예측하며 수익을 극대화하는 방법은 무엇인가요?\n\n![Business Planning with Python: Inventory and Cash Flow Management](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_0.png)\n\n현금 흐름 관리란 현금 수거액에서 현금 비용을 뺀 순액을 모니터링하고 최적화하는 프로세스로 정의될 수 있습니다.\n\n중소기업을 경영하는 친구와 대화한 후, 성장에 있어 현금이 가장 큰 병목 현상일 수 있다는 것을 알게 되었습니다.\n\n<div class=\"content-ad\"></div>\n\n공급망 데이터 과학자로서, 나는 이 문제를 공급망, 재고 관리 및 유통 계획에 빠르게 연결했습니다.\n\n이 기사에서는 이 문제의 간단한 모델링을 구축하는 데 사용된 접근 방식과 도구를 공유하겠습니다.\n\n![Business Planning with Python Inventory and Cash Flow Management](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_1.png)\n\n우리는 제 친구의 소규모 사업을 예로 들 것입니다. 그들은 재생 가능한 재료로 만든 컵을 커피숍과 유통업체에 판매합니다.\n\n<div class=\"content-ad\"></div>\n\n💌 무료로 새로운 기사를 이메일로 받아보세요: 뉴스레터\n📘 공급망 분석에 대한 완벽한 가이드: 분석 요약 시트\n\n```js\n요약\n\nI. 문제 상황: 비즈니스 계획\n재생 에코 컵을 판매하는 회사를 돕기 위해 비즈니스 분석을 어떻게 사용할 수 있을까요?\n  1. 재고 관리 시뮬레이션\n고객 수요를 충족시키기 위한 재고 관리 규칙을 실행합니다.\n  2. 재무 분석: 비용 및 수익\n비용 및 수익을 포괄하는 모든 재무 흐름을 연도별로 매핑합니다.\n  3. 현금 흐름 시뮬레이션\n비즈니스를 운영하기 위해 매주 가지고 있을 현금은 얼마나 될까요?\nII. 비즈니스 계획 최적화\n유동성 및 수익성 문제를 해결하기 위해 무엇을 할 수 있을까요?\n  1. 시나리오 1: 주문 수량 최적화\n주문 수량을 8주에서 6주로 줄인다면 어떻게 될까요?\n  2. 시나리오 2: 인바운드 물류용 항공화물\n항공화물을 사용해 재생 재고의 리드타임을 단축한다면 어떨까요?\n  3. 시나리오 3: 판매 채널 최적화\n대리점에 판매함으로써 영업 대표를 뛰어넘을 수 있다면 어떨까요?\n  4. 최적 시나리오\n두 가지 최상의 옵션을 결합해 봅시다.\nIII. 결론\n진보된 분석 솔루션을 통해 지속가능성과 수익성을 향상시키세요\n```\n\n# 문제 상황: 비즈니스 계획\n\n이 부분은 내 친구의 비즈니스 모델을 이해하기 위해 수집한 요소들을 간단히 소개합니다.\n\n<div class=\"content-ad\"></div>\n\n이러한 포인트들이 포함되어 있습니다:\n\n- 재고 관리: 제품 주문, 수령, 보관 및 배송\n❓ 고객 수요를 충족시키려면 언제 주문해야 할까요?\n- 재무: 비용 및 수익 흐름\n💡 주간 손익 분석.\n- 상업: 판매 채널, 서비스 수준 협약 및 수수료\n❔ XXX에 판매하면 얼마의 이익을 올릴까요?\n\n![이미지](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_2.png)\n\n우리는 이러한 요소를 모델링하여 서로 어떻게 상호 작용하고 전체 가치 사슬을 최적화할 수 있는지 이해할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n## 재고 관리 시뮬레이션\n\n먼저, 우리는 고객의 요구를 가장 낮은 비용으로 충족시키기 위해 모델의 핵심에 재고 관리 규칙을 구현할 것입니다.\n\n![image](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_3.png)\n\n재고 관리 규칙은 기계 속의 한 부분입니다.\n\n<div class=\"content-ad\"></div>\n\n- 재고는 상업 성장을 막을 수 있어요.\n손에 없는 아이템은 발송할 수 없어요.\n- 충전 능력은 재무 상황으로 제한됩니다.\n주문 지불을 위해 손에 있는 현금이 필요해요.\n- 전략적 결정은 재고 관리 방식에 영향을 미칩니다.\n예를 들어, 화물(항공, 해상) 소요 시간이 재고의 안정성에 영향을 줍니다.\n\n이 모듈은 고객 수요, 자기 시간, 그리고 안전 재고 매개변수에 기반하여\n보충 주문을 생성합니다.\n\n![이미지](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_4.png)\n\n이 연습에서는 2023년의 역사적 판매 데이터를 사용하여\n최적의 재고 관리가 무엇이었을 지 모사했어요.\n\n<div class=\"content-ad\"></div>\n\n안녕하세요! 이 요청에 대한 답변으로 지속적 검토 정책인 (s, Q)을 소개해보려고 해요.\n\n- 지속적 검토는 재고 팀이 매일 재고 수준을 확인하는 것을 의미해요.\n- (s, Q)는 만약 재고 수준이 특정 수준 s(Pallets) 아래로 내려가면, Q(Pallets)를 주문해야 한다는 것이에요.\n\n![이미지](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_5.png)\n\n재주문 지점은 발주가 도착할 때까지 고객 요구를 충족하기 위해 필요한 재고 수준을 의미해요.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_6.png)\n\n재고 보충 소요시간, 목표 주기 서비스 레벨 및 고객 수요의 표준 편차를 사용하여 정의합니다.\n\n결과는 아래 차트와 같습니다.\n\n![이미지](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_7.png)\n\n\n<div class=\"content-ad\"></div>\n\n📈 전설\n\n- 파란색 산점도는 최적 주문 정책을 나타냅니다.\n- 녹색 플롯은 창고에 보관된 파레트 수인 재고 현황(ioh)을 의미합니다.\n- 세 번째 차트의 점선은 재주문 점 s를 나타냅니다.\n\n재고 현황이 점선을 넘어갈 때 보충 주문이 있는 것을 관찰할 수 있습니다.\n\n💡 관찰 결과\n\n<div class=\"content-ad\"></div>\n\n- 이 정책이 최적인지 확실하지 않아요.\n우리는 내 친구의 표준 운영 모델을 알고리즘으로 번역할 뿐이에요.\n- 주문 수량과 보충 리드 타임을 최소화하기 위해 조정할 수 있다는 것을 염두에 두세요.\n\n재주문 시기를 알게 되었으니, 현금 보유액을 시각화하기 위해 재무 흐름을 포함할 수 있어요.\n\n## 재무 분석: 비용 및 수익\n\n이전 섹션은 재무 흐름을 고려하지 않고 물류 관점에서 비즈니스를 설명해 왔어요.\n\n<div class=\"content-ad\"></div>\n\n하지만 내 친구의 주요 문제는 재고를 보충하기 위해 주문 가능한 유동성이 제한된 것입니다.\n\n![Business Planning with Python Inventory and Cash Flow Management](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_8.png)\n\n그래서 우리는 재무 흐름을 매핑하여 매주 보유 현금을 계산할 것입니다.\n\n수익\n역사적 판매액은 판매 채널 별로 분할됩니다.\n\n<div class=\"content-ad\"></div>\n\n- 배급업체는 출하 후 4 주 후 지급합니다.\n각 판매 후 4 주 후, 송장 금액 (단가 x 수량)이 입금됩니다.\n- 커피숍은 주문 시 지불합니다.\n매주 끝날 때 마다, 송장 금액 (단가 x 수량)이 입금됩니다.\n\n![이미지](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_9.png)\n\n💡 관찰 사항\n직전 연도의 판매 수치를 고려하지 않으므로, 배급 채널이 처음 4 주 동안 수익을 얻지 못하는 것은 정상입니다.\n\n고정 및 가변 비용\n\n<div class=\"content-ad\"></div>\n\n- 조달 및 인바운드 물류 비용\n공급업체 및 화물 운송업자는 공장에서 선적이 이뤄지면 지불되어야 합니다.\n\n![이미지](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_10.png)\n\n💡 관찰\n주문은 생성된 후 일주일 후에 선적 준비가 됩니다.\n\n- 보관 및 구조 비용\n이에는 팔레트 보관(팔레트당 단위 가격 사용) 및 인력 비용, 설비 비용 등과 같은 반복 비용이 포함됩니다.\n\n<div class=\"content-ad\"></div>\n\n\n![](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_11.png)\n\n💡 관찰\n내 친구는 창고에 팔렛을 보관하는 데 최소 요금을 지불할 필요가 없었다고 운이 좋았어요.\n\n- 비반복 비용\n이 비용은 일시불로 지불되며, 마케팅 자료 구매, 특별 직원 보너스 또는 유통업체 벌금을 포함할 수 있습니다.\n- 수수료 비용\n내 친구는 커피숍에 대한 판매 시 독립적인 영업 대행사와 함께 일하며, 이들은 매출의 30%의 수수료를 받습니다.\n\n![](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_12.png)\n\n\n<div class=\"content-ad\"></div>\n\n만약 요약하자면, 다음과 같습니다:\n\n- 수익 흐름에는 두 채널에서의 매출이 포함됩니다.\n총 매출 = (유통업체 매출 + 커피 샵 매출)\n- 총 비용에는 고정비용, 가변비용 및 비반복 비용이 모두 포함됩니다.\n총 비용 = (가변 비용 + 고정 비용 + 비반복 비용)\n\n![이미지](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_13.png)\n\n💡 관찰 사항\n\n<div class=\"content-ad\"></div>\n\n- 우리는 구조 비용이 매우 낮습니다. 고정 비용의 10% 미만입니다.\n- 수수료는 두 번째로 큰 비용 항목을 차지합니다.\n\n## 현금 흐름 시뮬레이션\n\n주간 현금 흐름을 계산하면 연말까지 이 활동을 유지하기 위해 얼마나 많은 현금이 필요한지 이해할 수 있습니다.\n\n- 현금 흐름 = 매출액 — 비용\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_14.png)\n\n💡 관찰 사항\n\n- 현금 흐름은 공급 업체 및 화물 수송업자에게 지불할 때를 제외하고 항상 양수입니다.\n\n만약 우리가 현금이 없는 상태에서 연도를 시작한다고 가정해보자 (나쁜 아이디어),\n\n\n<div class=\"content-ad\"></div>\n\n아래는 Markdown 형식으로 변경된 내용입니다.\n\n![Business Planning with Python](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_15.png)\n\n- 현금 최소 잔고는 -124,733 달러입니다.\n- 현금 잔고가 3주차와 4주차에 음수입니다.\n\n💡 결론\n\n활동을 원활하게 운영하고 제 시간에 공급 업체에 지불하려면 적어도 연초에 125,000 달러 이상이 필요합니다.\n\n<div class=\"content-ad\"></div>\n\n다음 섹션에서는 여러 성과 지표를 정의하고 시나리오를 시뮬레이션하여 데이터 기반 비즈니스 통찰력을 제공할 것입니다.\n\n# 비즈니스 기획 최적화\n\n모델이 마련되었으므로 매개변수를 조절하고 다양한 시나리오를 시뮬레이션할 수 있습니다.\n\n각 시나리오는 네 가지 지표를 사용하여 평가될 것입니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_16.png\" />\n\n- Initial cash on hand needed at the beginning of the year: coh_0 ($)\nInitial Scenario: coh_0 = 124,733 ($)\n- Average cost of goods sold (COGS): cogs ($/Pallet)\nInitial Scenario: cogs = 5,057 ($/Pallet)\n- Average logistics costs per pallet: log_cost ($/Pallet)\nInitial Scenario: log_cost= 417 ($/Pallet)\n- Average profitability per pallet: avg_profit ($/Year)\nInitial Scenario: avg_profit = 3,686 ($/Year)\n\nThe idea is to measure the business and operational performance along the value chain versus the initial scenario.\n\n## Scenario 1: Order Quantity Optimization\n\n<div class=\"content-ad\"></div>\n\n공급망 엔지니어로서, 나는 물류 흐름과 재고 관리 규칙을 조사해보겠어요.\n\n친구가 유동성 문제를 설명할 때, 내 첫 반응은 주문 수량에 대해 의심해 보는 것이었어요.\n\n평균 8주 분량을 주문하는 것은 그가 재고 부족에 대해 걱정하지 않고 출고 취소(즉, 재고 부족으로 인한 주문 취소)를 피하기 위한 방법이에요.\n\n이제 우리가 안전 재고를 갖춘 최적의 재고 관리 규칙을 갖고 있으니, 주문 수량을 Q = 6주 용량으로 줄일 수 있을 거예요.\n\n<div class=\"content-ad\"></div>\n\n![BusinessPlanningwithPythonInventoryandCashFlowManagement](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_17.png)\n\n예상 재고 손실을 방지하여 수익에 미치는 영향이 무시할 수 없습니다.\n\n- 연습 시작 시 손에 현금이 더 적게 필요합니다.\n시나리오 1: coh_0 = 74,733($) | -41%\n- 매출원가(COGS)가 크게 감소합니다.\n시나리오 1: cogs = 4,928($/파렛) | -2.6%\n- 각각의 판매 팔렛당 더 나은 이익을 창출합니다.\n시나리오 1: avg_profit = 3,815($/팔렛) | +3%\n\n💡 결론\n이 빠른 승리는 유동성 요구 사항에 대한 여유를 제공하고 추가 수익을 가져다줍니다.\n\n<div class=\"content-ad\"></div>\n\n이 피드백으로 인해 이 비즈니스 가치 사슬의 전략적 비전에 대해 심층적으로 고찰하게 되었습니다.\n\n- 🙋‍♂️ 왜 인바운드 물류를 항공 운송으로 전환하지 않을까요?\n항공 운송은 매우 비싸지만 더 많은 유연성을 제공합니다. 즉, 평균 재고가 낮아집니다.\n- 🙋‍♀️ 유통 업체에만 판매해야 할까요?\n유통업체의 지불 조건은 더 길지만(4주), 영업 수수료를 지불할 필요가 없고, 아웃바운드 물류 비용이 낮아집니다.\n\n이런 의문점들은 합당하지만, 이에 답하기 위해서는 복잡한 계산이 필요하며, 우리 모델이 이를 완벽히 자동화할 수 있습니다.\n\n## 시나리오 2: 인바운드 물류용 항공 운송\n\n<div class=\"content-ad\"></div>\n\n내 경험상, 항공 화물 운송은 주로 빠른 배송이 필요한 고가 제품에 사용됩니다(주로 명품이나 자동차 부품).\n\n그러나 제 친구에게 운동하라고 제안했습니다\n\n- 화물 중개인이 제안한 항공 운송 요금은 3배 높음\n- 배송 리드타임은 4주에서 1주로 단축됨\n\n이제 주문 수량을 8주에서 3주로 줄일 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_18.png\" />\n\n💡 관찰 사항\n\n- 평균 재고 수준이 이전보다 낮아졌습니다. 이는 저장 비용을 줄일 수 있습니다.\n- 주문 빈도가 더 높고 수량이 적습니다.\n\n안타깝게도, 이는 고비용의 항공 운송 비용을 상쇄하지 못합니다.\n\n<div class=\"content-ad\"></div>\n\n- 이로 인해 판매원가(COGS)가 증가합니다.\n시나리오 2: cogs = 5,511 ($/팔렛) | +8 %\n- 이로 인해 팔렛 당 수익성이 낮아집니다.\n시나리오 2: avg_profit = 3,232 ($/팔렛) | -12 %\n- 다행히도, 연초에 필요한 현금이 줄어듭니다.\n시나리오 2: coh_0 = 17,288 ($) | -86 %\n\n요약하면, 장기적으로 수익성이 감소하므로 이 아이디어는 좋은 아이디어가 아닙니다.\n\n## 시나리오 3: 판매 채널 최적화\n\n마지막 시나리오에서는 판매 채널 전략에 초점을 맞출 것입니다.\n\n<div class=\"content-ad\"></div>\n\n현재 상황에서는 바로 커피숍에 직접 판매하는 것과 유통업체와의 협력이 혼합되어 있습니다.\n\n![2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_19.png](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_19.png)\n\n만약 우리가 유통업체만 사용한다면,\n\n- 출하 후 4주 후에 결제를 받게 됩니다.\n- 판매 수수료를 지불할 필요가 없습니다.\n    - 직접 판매의 경우 30%의 판매 수수료 vs. 0%의 판매 수수료\n- 결합 출하로 배송을 최적화할 수 있습니다.\n- 직접 판매와 비교했을 때 경비 운송 비용이 50% 절감됩니다.\n\n<div class=\"content-ad\"></div>\n\n첫 번째 영향은 처음 지불을 받기까지 4주를 기다려야 한다는 것이며, 이는 유동성 요구에 영향을 미칩니다.\n\n<img src=\"/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_20.png\" />\n\n- 연습 시작 시 더 많은 현금이 필요합니다.\n시나리오 3: coh_0 = 197,602 달러 | -58 %\n\n그러나 수수료 비용을 줄이고 수익성을 향상시키고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n- Cost of Goods Sales (COGS)에 큰 영향.\n새 시나리오: cogs = 3,172 ($/Pallet) | -38 %\n- 판매 당 더 나은 수익성.\n새 시나리오: avg_profit = 5,068 ($/Pallet) | +37 %\n\n## 최적 시나리오\n\n이 작은 연습은 비즈니스에 영향을 미치지 않고 수익을 극대화하는 데 더 나은 가시성과 통찰력을 제공합니다.\n\n![이미지](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_21.png)\n\n<div class=\"content-ad\"></div>\n\n친구가 비즈니스 수익을 극대화하고 싶다면\n\n- 유통 업체로부터 주문을 더 받아야 하며 직접 판매는 중지해야 합니다.\n- 공급 업체로부터 주문 시 6주분의 재고를 유지해야 합니다.\n\n이 계획을 따른다면 데이터에 따르면 수익을 33% 증가시킬 수 있을 것입니다.\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\n이 방법은 애매한 운영 절차와 비즈니스 관행을 간단한 모델로 번역할 수 있게 해줍니다.\n\n이 모델을 통해 가치 사슬의 각 구성 요소가 서로 상호 작용하는 방식을 이해할 수 있습니다.\n\n![이미지](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_22.png)\n\n한 번의 클릭으로 질문에 대한 답변을 제공하는 것이 목표였습니다.\n\n<div class=\"content-ad\"></div>\n\n- 바다 화물에서 항공 화물로 바꾸면 어떨까요?\n- 최고의 판매 채널이 무엇인가요?\n- 물류 비용이 전체 수익에 미치는 영향은 무엇인가요?\n\n이 간단한 모형은 전략적인 통찰력을 제공하지만 제한 사항이 있습니다.\n\n- 구매 비용 구조에는 MOQ 및 감소 가격이 포함되어야 합니다.\n\n이러한 구조를 바탕으로 제품을 주문하고 수령하는 비용을 최소화하는 최적 주문 수량을 찾을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이 기사에는 더 많은 세부 내용이 있습니다.\n\n- 화물운송업체와 운송회사는 용량과 서비스 수준 계약에 따라 청구서를 작성합니다.\n\n물류 서비스 제공업체들이 유연성을 제공한다면, 자신들의 경로를 최적화하고 가격을 줄일 수 있는 기회가 더 많아질 것입니다.\n\n저는 공급망 솔루션 매니저로 일하면서 이와 같은 연습을 자주 했습니다; 이 기사에 예시가 있습니다.\n\n<div class=\"content-ad\"></div>\n\n- 고정 비용은 범주별로 구체적으로 나누어야 합니다: CAPEX, 인력, 공과금 등\n\n저는 제 YouTube 채널에서 창고 운영 비용 분석 예시를 공유했습니다.\n\n- 판매 가격에는 결제 기간이 짧은 경우의 할인이나 주문량에 따라 감소하는 금액이 포함될 수 있습니다.\n- 판매 대상을 다수의 품목으로 확장하고 비용과 수익을 최적화하기 위해 다양한 제품 조합을 고려할 수 있습니다.\n\n우리는 선형 프로그래밍과 Python을 사용하여 제 친구가 올바른 품목을 판매하면서 유동성, 저장 공간, 공급 업체 용량 제약을 고려하여 수익을 극대화하는 데 도움을 줄 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이 방법론에 대해 더 자세히 알고 싶다면, 이 기사를 참고해보세요.\n\n- 우리는 수익성 또는 지속 가능성 제한을 기반으로 공급 업체 선정을 최적화할 수 있습니다.\n\n초기 모델은 커피잔을 위한 단일 공급 업체를 고려하고 있습니다. 그러나 제 친구는 세계 각지의 공급 업체를 자격을 부여하여 소싱을 다각화하는 작업을 하고 있습니다.\n\n이러한 다양한 공급 업체로부터 데이터를 수집한 후, 저희는 제가 개발한 간단한 웹 애플리케이션을 사용하여 최적의 공급망 네트워크를 설계하는 데 도움을 받을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_23.png\" />\n\n특정 환경 메트릭 또는 비용 최소화를 목표로 하는 경우, 알고리즘은 자동으로 최적의 공급업체를 선택합니다.\n\n<img src=\"/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_24.png\" />\n\n이는 귀하의 고객에게 제품을 생산하고 전달하기 위한 공급망 흐름을 생성합니다.\n\n<div class=\"content-ad\"></div>\n\n더 많은 세부 정보를 보려면 이 기사를 확인해보세요.\n\n## 다음은 무엇인가요?\n\n이 아이디어는 수익을 극대화하고 환경 영향을 줄이며 유동성에 대한 압력을 피하기 위해 사용할 수 있는 모든 개선 도구들을 수집하는 것입니다.\n\n![이미지](/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_25.png)\n\n<div class=\"content-ad\"></div>\n\n다음 기사에서는 제 친구가 그의 비즈니스에 도입한 변화와 모델화에 대한 업데이트를 공유할 것입니다.\n\n# 나에 대해\n\nLinkedIn 및 Twitter에서 연락해요. 저는 데이터 분석을 사용하여 물류 영업을 개선하고 비용을 줄이는 공급망 엔지니어입니다.\n\n데이터 분석과 공급망에 관심이 있다면 제 웹사이트를 방문해주세요.","ogImage":{"url":"/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_0.png"},"coverImage":"/assets/img/2024-06-20-BusinessPlanningwithPythonInventoryandCashFlowManagement_0.png","tag":["Tech"],"readingTime":13},{"title":"파이스파크 인터뷰 질문 by COFORGE","description":"","date":"2024-06-20 01:48","slug":"2024-06-20-PySparkInterviewQuestionbyCOFORGE","content":"\n\n이 글에서는 고객 거래 데이터 세트를 사용하여 PySpark를 사용하여 데이터 변환 및 분석을 수행하는 방법을 살펴보겠습니다.\n\n문제 명시:\n\n-PySpark 코드를 작성하여 $10,000보다 큰 고객 거래를 필터링하고, 고객 이름을 첫 글자는 대문자로 변환하고 나머지는 소문자로 변환하고, 각 제품 카테고리별 평균 거래 금액을 계산하십시오.\n\n해결책:\n\n<div class=\"content-ad\"></div>\n\nPySpark 스크립트는 네 가지 주요 단계에서 다음 작업을 수행합니다:\n\n1. **데이터 수집 및 변환:**\n- 샘플 고객 거래 데이터를 Spark DataFrame으로 읽어옵니다.\n- 고객 이름을 `initcap` 형식으로 변환합니다 (첫 글자를 대문자로 변환하고 나머지는 소문자로 변환).\n\n2. **데이터 필터링:**\n- 거래를 10,000 이상인 것만 포함하도록 필터링합니다.\n\n3. **집계:**\n- 각 제품 카테고리별 평균 거래 금액을 계산합니다.\n\n<div class=\"content-ad\"></div>\n\n4. **결과 표시:**\n- 제품 카테고리별 평균 거래액과 함께 변환된 고객 데이터를 표시합니다.\n\n```python\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, avg, initcap\n\n# SparkSession 생성\nspark = SparkSession.builder \\\n    .appName(\"CustomerTransactionAnalysis\") \\\n    .getOrCreate()\n\n# 대문자로 된 고객 이름이 포함된 고객 거래의 샘플 데이터\ndata = [\n    (1, \"ALICE\", 12000, \"전자제품\"),\n    (2, \"BOB\", 9000, \"가전제품\"),\n    (3, \"CHARLIE\", 15000, \"패션\"),\n    (4, \"DANIEL\", 8000, \"전자제품\"),\n    (5, \"EMMA\", 11000, \"패션\"),\n    (6, \"FRANK\", 13000, \"가전제품\"),\n    (7, \"GINA\", 10000, \"전자제품\"),\n    (8, \"HENRY\", 14000, \"패션\"),\n    (9, \"ISABELLA\", 9500, \"가전제품\"),\n    (10, \"JACK\", 10500, \"전자제품\")\n]\n\n# 샘플 데이터로부터 DataFrame 생성\ncustomer_df = spark.createDataFrame(data, [\"customer_id\", \"customer_name\", \"transaction\", \"product_category\"])\n\n# 초기 데이터 표시\nprint(\"초기 데이터:\")\ncustomer_df.show()\n\n# 고객 이름을 initcap 형식으로 변환\ntransformed_df = customer_df.withColumn(\"customer_name_transformed\", initcap(col(\"customer_name\")))\n\n# 10,000보다 큰 고객 거래 필터링\nfiltered_transactions = transformed_df.filter(col(\"transaction\") > 10000)\n\n# 각 제품 카테고리별 평균 거래액 계산\navg_transaction_by_category = filtered_transactions.groupBy(\"product_category\") \\\n    .agg(avg(\"transaction\").alias(\"avg_transaction\"))\n\n# 평균과 함께 변환된 데이터 표시\nprint(\"\\n평균이 포함된 변환된 데이터:\")\nresult = filtered_transactions.select(\"customer_name_transformed\", \"product_category\", \"transaction\") \\\n    .join(avg_transaction_by_category, \"product_category\") \\\n    .orderBy(\"product_category\")\n\nresult.show(truncate=False)\n\n# SparkSession 중지\nspark.stop()\n```\n\n출력:\n\n<img src=\"/assets/img/2024-06-20-PySparkInterviewQuestionbyCOFORGE_0.png\" />","ogImage":{"url":"/assets/img/2024-06-20-PySparkInterviewQuestionbyCOFORGE_0.png"},"coverImage":"/assets/img/2024-06-20-PySparkInterviewQuestionbyCOFORGE_0.png","tag":["Tech"],"readingTime":3},{"title":"Node Version Manager NVM를 사용하여 Nodejs와 npm을 설치하는 방법","description":"","date":"2024-06-20 01:46","slug":"2024-06-20-HowtoinstallNodejsandnpmusingNodeVersionManagerNVM","content":"\n\n## Node.js, npm\n\n![Node.js and npm](/assets/img/2024-06-20-HowtoinstallNodejsandnpmusingNodeVersionManagerNVM_0.png)\n\n# NVM을 이용하여 Node.js와 npm 설치하기\n\nNode.js를 설치하는 대안으로, Node Version Manager(NVM)라는 도구를 사용할 수 있습니다. NVM은 운영 체제 수준이 아닌 홈 디렉토리 내의 독립적인 디렉토리 수준에서 작동합니다. 이는 전체 시스템에 영향을 미치지 않고 여러 개의 독립된 Node.js 버전을 설치할 수 있다는 것을 의미합니다.\n\n<div class=\"content-ad\"></div>\n\nNVM(노드 버전 관리자)은 여러 활성 노드.js 버전을 관리하는 데 사용되는 bash 스크립트입니다. NVM을 사용하면 사용하거나 테스트하려는 원하는 특정 노드.js 버전을 설치하거나 제거할 수 있습니다.\n\nUbuntu 시스템에서 NVM을 사용하여 노드.js 및 npm을 설치하려면 다음 단계를 수행하세요:\n\n## 1. NVM(노드 버전 관리자) 스크립트 설치\n\nnvm 스크립트를 다운로드하고 설치하려면 다음을 실행하세요:\n\n<div class=\"content-ad\"></div>\n\n```js\n✔ curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.35.3/install.sh | bash\n```\n\n위 명령어는 Github의 NVM 저장소를 ~/.nvm 디렉토리로 클론합니다:\n\n```js\n출력\n=> nvm을 사용하기 위해 터미널을 닫았다가 다시 열거나 아래 명령어를 실행하세요:\n\nexport NVM_DIR=\"$HOME/.nvm\"\n[ -s \"$NVM_DIR/nvm.sh\" ] && \\. \"$NVM_DIR/nvm.sh\"  # 이 명령은 nvm을 불러옵니다\n[ -s \"$NVM_DIR/bash_completion\" ] && \\. \"$NVM_DIR/bash_completion\"  # 이 명령은 nvm bash_completion을 불러옵니다\n```\n\n## ⭕ 참고 :\n터미널에서 “curl: command not found” 오류가 발생하는 경우.\n\n<div class=\"content-ad\"></div>\n\nDebian에서 Curl 유틸리티 설치\n\nCurl은 Debian 10 운영 체제의 공식 APT 패키지 저장소에서 설치할 수 있습니다.\n\n먼저 아래 명령을 사용하여 시스템의 저장소 캐시를 업데이트하세요:\n\n```bash\nsudo apt update\n```\n\n<div class=\"content-ad\"></div>\n\n이제 아래 명령을 사용하여 설치된 패키지를 업그레이드하세요:\n\n```js\n✔ sudo apt upgrade\n```\n\n시스템을 성공적으로 업데이트하고 업그레이드한 후에는 데비안 10 시스템에 Curl을 설치하기 위해 아래 명령을 입력하세요.\n\n```js\n✔ sudo apt install curl\n```\n\n<div class=\"content-ad\"></div>\n\nCurl 라이브러리 설치가 시작되어 다운로드되고, 곧 설치될 것입니다.\n\n설치가 완료되면 NVM 설치 명령을 실행할 수 있어요...👍\n— ⭕\n\n## 2. 터미널을 다시 시작해주세요\n\n프로필의 변경 사항을 반영하려면 터미널을 닫고 다시 열어주세요\n\n<div class=\"content-ad\"></div>\n\n## 3. 확인해 보세요\n\nnvm이 제대로 설치되었는지 확인하려면 다음을 입력하세요:\n\n```js\nnvm --version\n출력\n0.34.0\n```\n\n## 4. 어떤 일을 하는지 확인해 보세요\n\n<div class=\"content-ad\"></div>\n\nnvm ls-remote 명령어를 실행하여 사용 가능한 모든 버전의 목록을 확인해보세요.\n\n```js\n출력\n       v14.13.0\n       v14.13.1\n       v14.14.0\n       v14.15.0   (LTS: Fermium)\n       v14.15.1   (LTS: Fermium)\n       v14.15.2   (LTS: Fermium)\n       v14.15.3   (LTS: Fermium)\n       v14.15.4   (LTS: Fermium)\n       v14.15.5   (LTS: Fermium)\n       v14.16.0   (LTS: Fermium)\n       v14.16.1   (LTS: Fermium)\n       v14.17.0   (LTS: Fermium)\n       v14.17.1   (LTS: Fermium)\n       v14.17.2   (LTS: Fermium)\n       v14.17.3   (LTS: Fermium)\n       v14.17.4   (LTS: Fermium)\n       v14.17.5   (LTS: Fermium)\n       v14.17.6   (LTS: Fermium)\n       v14.18.0   (LTS: Fermium)\n       v14.18.1   (LTS: Fermium)\n       v14.18.2   (LTS: Fermium)\n       v14.18.3   (LTS: Fermium)\n       v14.19.0   (LTS: Fermium)\n       v14.19.1   (LTS: Fermium)\n       v14.19.2   (LTS: Fermium)\n       v14.19.3   (Latest LTS: Fermium)\n        v15.0.0\n        v15.0.1\n        v15.1.0\n        v15.2.0\n        v15.2.1\n        v15.3.0\n        v15.4.0\n        v15.5.0\n        v15.5.1\n        v15.6.0\n        v15.7.0\n        v15.8.0\n        v15.9.0\n       v15.10.0\n       v15.11.0\n       v15.12.0\n       v15.13.0\n       v15.14.0\n        v16.0.0\n        v16.1.0\n        v16.2.0\n        v16.3.0\n        v16.4.0\n        v16.4.1\n        v16.4.2\n        v16.5.0\n        v16.6.0\n        v16.6.1\n        v16.6.2\n        v16.7.0\n        v16.8.0\n        v16.9.0\n        v16.9.1\n       v16.10.0\n       v16.11.0\n       v16.11.1\n       v16.12.0\n       v16.13.0   (LTS: Gallium)\n       v16.13.1   (LTS: Gallium)\n       v16.13.2   (LTS: Gallium)\n       v16.14.0   (LTS: Gallium)\n       v16.14.1   (LTS: Gallium)\n       v16.14.2   (LTS: Gallium)\n       v16.15.0   (Latest LTS: Gallium)\n        v17.0.0\n        v17.0.1\n        v17.1.0\n        v17.2.0\n        v17.3.0\n        v17.3.1\n        v17.4.0\n        v17.5.0\n        v17.6.0\n        v17.7.0\n        v17.7.1\n        v17.7.2\n        v17.8.0\n        v17.9.0\n        v18.0.0\n        v18.1.0\n        v18.2.0\r\n```\n\n## 5. 최신 LTS 버전의 Node.js 및 npm 설치하기\n\n이제 nvm을 설치했으니, 현재 LTS 버전의 Node.js를 설치하고 사용해봅시다!\n\n<div class=\"content-ad\"></div>\n\n```js\n✔ nvm install --lts\n출력\n현재 node v16.15.0을 사용 중입니다 (npm v8.5.5)\n기본 별칭 생성: default -> lts/* (-> v16.15.0)\n```\n\n작동하는지 확인하고 버전이 올바른지 확인하세요:\n\n```js\n✔ node --version\n출력\nv16.15.0\n--------------------------------------------------------------------\n✔ npm --version\n출력\n8.5.5\n```\n\n## Node의 기본 버전 설정하기\n\n<div class=\"content-ad\"></div>\n\n만약 여러 개의 Node 버전이 설치되어 있다면, 그 목록을 얻으려면 ls를 실행할 수 있어요:\n\n```js\n✔ nvm ls\n출력\n->     v16.15.0\ndefault -> lts/* (-> v16.15.0)\nnode -> stable (-> v16.15.0) (default)\nstable -> 16.15 (-> v16.15.0) (default)\niojs -> N/A (default)\nunstable -> N/A (default)\nlts/* -> lts/gallium (-> v16.15.0)\nlts/argon -> v4.9.1 (-> N/A)\nlts/boron -> v6.17.1 (-> N/A)\nlts/carbon -> v8.17.0 (-> N/A)\nlts/dubnium -> v10.24.1 (-> N/A)\nlts/erbium -> v12.22.12 (-> N/A)\nlts/fermium -> v14.19.3 (-> N/A)\nlts/gallium -> v16.15.0\n```\n\n또한 원하는 버전을 기본값으로 설정할 수도 있어요:\n\n```js\n✔ nvm alias default 16.15.0\n\n출력\ndefault -> 16.15.0 (-> v16.15.0)\n```\n\n<div class=\"content-ad\"></div>\n\n새 세션을 생성하면 이 버전이 자동으로 선택됩니다. 또한 다음 명령의 예시에서와 같이 별칭을 사용하여 이를 참조할 수 있습니다:\n\n```js\n✔ nvm use default\nOutput\nNow using node v16.15.0 (npm v8.5.5)\n```\n\n각 Node.js 버전은 자체 패키지를 추적하고 이를 관리하는 데 사용할 수 있는 npm을 가지고 있습니다.\n\n# Node.js 제거하기\n\n<div class=\"content-ad\"></div>\n\nNode.js를 삭제하는 방법은 설치된 버전에 따라 apt 또는 nvm을 사용할 수 있어요. 기본 저장소 버전을 제거하려면 시스템 수준에서 apt를 사용할 거예요. 이 명령어는 패키지를 제거하고 구성 파일을 유지합니다. 나중에 다시 패키지를 설치할 계획이 있다면 유용해요:\n\n```bash\n✔ sudo apt remove nodejs\n```\n\n나중에 구성 파일을 사용할 계획이 없다면 다음 명령어를 실행하여 해당 패키지와 관련된 구성 파일을 함께 제거할 수 있어요:\n\n```bash\n✔ sudo apt purge nodejs\n```\n\n<div class=\"content-ad\"></div>\n\n마지막으로 제거한 패키지와 함께 자동으로 설치된 사용하지 않는 패키지를 제거할 수 있습니다:\n\n```js\n✔ sudo apt autoremove\n```\n\nnvm을 사용하여 활성화한 Node.js 버전을 제거하려면 먼저 제거하려는 버전이 현재 활성 버전인지 확인하세요:\n\n```js\n✔ nvm current\n```\n\n<div class=\"content-ad\"></div>\n\n대상이 되는 버전이 현재 활성 버전이 아닌 경우, 다음을 실행할 수 있습니다:\n\n```js\n✔ nvm uninstall node_version\n출력\nnode_version 노드를 제거했습니다\n```\n\n이 명령은 선택한 Node.js 버전을 제거합니다.\n\n제거하려는 버전이 현재 활성 버전인 경우, 변경 사항을 적용하려면 먼저 nvm을 비활성화해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n✔ nvm deactivate\n```\n\n이제 이전에 사용한 삭제 명령을 사용하여 현재 버전을 삭제할 수 있습니다. 이는 Node.js의 대상 버전과 관련된 모든 파일을 제거하지만 다시 설치하는 데 사용할 수 있는 캐시된 파일은 제외됩니다.\n\n여러분 모두가 제 글을 이해하고 즐기셨으면 좋겠습니다. 더 많은 업데이트를 받기 위해 제 페이지를 팔로우해 주세요.\n\n다른 글을 확인하기 전에, 이미 팔로우하고 있지 않다면 제 페이지를 팔로우해 주십시오. 여러분의 팔로우는 테크 커뮤니티에 더 유용한 콘텐츠를 만드는 데 도움이 됩니다.\n\n<div class=\"content-ad\"></div>\n\n✍️\nVinojan Veerapathirathasan\nDecHorizon의 창업자 및 CEO\nLinkedIn: [링크](https://www.linkedin.com/in/imvinojanv/)\nGithub: [링크](https://github.com/imvinojanv)\n이메일: vinojan@dechorizon.com | 전화번호: +94 77 573 7782\n\n감사합니다…!","ogImage":{"url":"/assets/img/2024-06-20-HowtoinstallNodejsandnpmusingNodeVersionManagerNVM_0.png"},"coverImage":"/assets/img/2024-06-20-HowtoinstallNodejsandnpmusingNodeVersionManagerNVM_0.png","tag":["Tech"],"readingTime":7},{"title":"데이터베이스에 연결이 과부하될 때 암시적 연결 풀링","description":"","date":"2024-06-20 01:44","slug":"2024-06-20-ImplicitConnectionPoolingwhenconnectionsoverloadyourdatabase","content":"\n\n긴 실행 앱에서 앱 수명 동안 데이터베이스 연결을 열어 두면 연결이 자주 유휴 상태이고 SQL 문을 실행하는 데 사용되지 않을 가능성이 높습니다. 그러나 이는 연결의 서버 프로세스와 세션 메모리를 데이터베이스 호스트에서 유지하며 결국 연결할 수 있는 다른 사용자 수를 제한합니다. Oracle 애플리케이션 연결 풀을 사용하여 재아키텍처링하는 것이 불가능할 때는 간단한 연결 문자열 변경을 통해 Oracle Database 23ai의 \"암시적 연결 풀링\"을 사용하여 데이터베이스 호스트 리소스를 공유할 수 있습니다. 이를 통해 필요한 메모리가 줄어들고 데이터베이스가 확장 가능해집니다.\n\n![Implicit Connection Pooling when connections overload your database](/assets/img/2024-06-20-ImplicitConnectionPoolingwhenconnectionsoverloadyourdatabase_0.png)\n\n이전 블로그 포스트인 \"Connection Pool를 사용하지 않는 앱을 돕는 DRCP\"는 자주 연결 및 끊김이 발생하지만 연결 풀을 사용하지 않는 예제를 보여주었습니다. 이는 앱이 데이터베이스 주요 연결 풀링(DRCP)에서 얻을 수 있는 이점에 대해 설명합니다. 왜냐하면 이러한 자주 발생하는 애플리케이션 끊김 호출은 데이터베이스에게 다른 애플리케이션 사용자를 위해 데이터베이스 서버 프로세스를 재사용할 때 안전한 시점인지 알려줍니다.\n\n다음 예제는 긴 실행 애플리케이션이 종료될 때만 연결 해제 호출이 발생하는 점에서 다릅니다. 순수 DRCP는 도저히 도움이 되지 않습니다. 왜냐하면 데이터베이스 서버 프로세스를 재사용할 때 \"경계\"인 연결 사용이 없기 때문입니다. 다행히도 Oracle Database 23ai의 \"암시적 연결 풀링\"이 이를 해결해 줄 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n데모를 살펴보겠습니다. 다음 간단한 Python 앱인 long_run.py은 연결을 열고 루프를 실행합니다. 각 반복에서는 쿼리가 실행되며 쿼리 사이에 사용자 \"생각 시간\"을 모방하는 sleep이 존재합니다. 앱이 종료될 때 연결이 닫힙니다 (with context 블록 끝에서 처리됨). 이는 SQL 문을 실행하지 않을 때도 연결을 유지하는 장기 실행 앱을 모방합니다:\n\n```js\n# long_run.py\n\nimport os\nimport time\n\nimport oracledb\nimport sample_env  # 자격 증명이 포함된 python-oracledb 샘플 참조\n\n# 스크립트 수명 내에서 실행할 쿼리 수\nNUMSQLS = globals().get(\"NUMSQLS\", 0)\n\n# SQL 문 실행 사이에서 대기할 시간(초)\nSLEEPTIME = globals().get(\"SLEEPTIME\", 0)\n\n# 각 스크립트 실행 중에 고유한 끝 \"사용자\"의 이름\nAPPUSERNAME = globals().get(\"APPUSERNAME\", None)\n\nsql = \"\"\"select unique sid||'-'||serial# as sidser,\n                       current_timestamp as ct\n         from v$session_connect_info\n         where sid = sys_context('USERENV', 'SID')\"\"\"\n\nwith oracledb.connect(\n    user=sample_env.get_main_user(),\n    password=sample_env.get_main_password(),\n    dsn=sample_env.get_connect_string(),\n) as connection:\n    for i in range(NUMSQLS):\n        with connection.cursor() as cursor:\n            for s, d in cursor.execute(sql):\n                print(f\"{APPUSERNAME} sid-ser {s} at time {d}\")\n        time.sleep(SLEEPTIME)\r\n```\n\n응용 프로그램 쿼리는 현재 시간 및 세션 식별자/일련 번호를 얻습니다 -이 쌍은 사용 중인 데이터베이스 서버 프로세스 세션을 보여줍니다. 각 반복의 쿼리는 다음과 같은 줄을 출력합니다:\n\n```js\nUser01 sid-ser 407-62786 at time 2024-06-11 20:29:34.632666\n```\n\n<div class=\"content-ad\"></div>\n\n연결 문자열은 localhost/orclpdb1과 같이 간단한 형태입니다. DRCP는 사용되지 않았습니다.\n\n도우미 스크립트인 runner.py는 여러 사용자가 동시에 long_run.py를 실행하도록 모의하는 데 사용됩니다. 이 도우미 스크립트는 스레드를 이용하여 long_run.py를 10회 (NUMUSERS로 설정됨) 호출합니다. 각각의 long_run.py 호출에는 고유한 \"사용자 이름\" (예: User01, APPUSERNAME로 전달), 실행할 SQL 문의 수 (NUMSQLS), 그리고 실행 사이의 슬립 시간 (SLEEPTIME)이 전달됩니다. 슬립 시간은 애플리케이션 사용자가 비활동 상태이고 SQL 문을 실행하지 않는 것을 흉내냅니다. 도우미 스크립트는 다음과 같습니다:\n\n```js\n# runner.py\n\nimport threading\nimport time\n\nimport sample_env  # 자격 증명을 포함하고 있습니다. python-oracledb 샘플 참조\n\nNUMUSERS = 10      # 동시에 long_run.py를 호출하는 회수\n\ndef start_app(tn):\n    app_globals = {\n        \"APPUSERNAME\": \"User{:02d}\".format(tn + 1),  # long_run.py를 실행하는 \"사용자\" 이름\n        \"NUMSQLS\": 5,     # long_run.py 수명 내에서 실행할 쿼리 수\n        \"SLEEPTIME\": 5,   # SQL 문 사이에 잠자는 시간 (초)\n    }\n    exec(open(\"long_run.py\").read(), app_globals)\n\ndef start_workload():\n    thread = []\n    for i in range(NUMUSERS):\n        t = threading.Thread(target=start_app, args=(i,))\n        t.start()\n        thread.append(t)\n\n    for i in range(NUMUSERS):\n        thread[i].join()\n\nif __name__ == \"__main__\":\n\n    print(f\"연결 문자열 사용 중: {sample_env.get_connect_string()}\")\n\n    start = time.time()\n    start_workload()\n    elapsed = time.time() - start\n    print(\"작업 완료!\")\n    print(\"소요 시간 {:04.2f} 초\".format(elapsed))\n```\n\n현재 구현된 대로, 각 long_run.py 프로세스는 5개의 쿼리를 실행하고 각 쿼리 사이에 5초의 슬립 시간을 갖습니다. (실제로는 애플리케이션에서 훨씬 오랫동안 실행될 수 있습니다). 오버헤드, 연결 및 문 실행을 추가하면 총 예상 소요 시간은 25초보다 약간 더 걸릴 것으로 예상됩니다:\n\n<div class=\"content-ad\"></div>\n\n```js\n$ python3 runner.py\nUsing connection string: localhost/orclpdb1\nUser01 sid-ser 407-62786 at time 2024-06-11 20:29:34.632666\nUser03 sid-ser 26-48119 at time 2024-06-11 20:29:34.802162\nUser02 sid-ser 172-37948 at time 2024-06-11 20:29:34.973973\nUser04 sid-ser 272-26116 at time 2024-06-11 20:29:35.146129\nUser05 sid-ser 398-8361 at time 2024-06-11 20:29:35.315068\nUser07 sid-ser 33-58745 at time 2024-06-11 20:29:35.485322\nUser08 sid-ser 154-64891 at time 2024-06-11 20:29:35.667774\nUser09 sid-ser 268-40439 at time 2024-06-11 20:29:35.837789\nUser10 sid-ser 408-62081 at time 2024-06-11 20:29:36.013276\nUser06 sid-ser 10-45069 at time 2024-06-11 20:29:36.189829\nUser01 sid-ser 407-62786 at time 2024-06-11 20:29:39.653528\n...\n\nAll done!\nTime 26.85 seconds\n```\n\n중요한 점은 각각의 10개의 프로세스가 연결을 열고 long_run.py 앱이 실행되는 동안 항상 열려 있도록 유지한다는 것입니다. 이는 각 사용자 스크립트가 항상 동일한 세션 식별자/일련 번호 조합을 사용하여 쿼리를 실행함으로써 나타납니다. 예를 들어, User01은 항상 407-62786을 사용합니다. 이로 인해 항상 열려 있는 10개의 연결이 있으며, 각각에는 해당 서버 프로세스 및 세션 메모리를 사용하여 데이터베이스 호스트 리소스를 소비합니다.\n\n# Oracle Database 23ai 암시적 연결 풀링\n\n암시적 연결 풀링은 데이터베이스 서버 프로세스 및 세션 메모리를 공유하기 위해 데이터베이스 주거 연결 풀링을 활용하는 Oracle Database 23ai의 기능입니다. 이는 python-oracledb, node-oracledb, JDBC를 포함한 인기 있는 Oracle Database 드라이버에서 지원됩니다.\n\n\n<div class=\"content-ad\"></div>\n\nImplicit Connection Pooling은 데이터베이스 작업을 수행하지 않을 때 연결을 보유하는 응용 프로그램에 적합합니다. 이에는 데이터베이스와의 연결을 풀의 수명 동안 열어둔 채 자체 연결 풀 솔루션을 구현하는 응용 프로그램이 포함됩니다.\n\nImplicit Connection Pooling은 응용 프로그램이 열려 있는 연결을 사용하지 않을 때 경계를 투명하게 인식하여, 첫 번째(현재 여유 상태인) 연결의 서버 프로세스와 세션 메모리를 다른 응용 프로그램 연결이 사용하도록 허용합니다. 그리고 첫 번째 응용 프로그램이 후속 데이터베이스 요청을 시작할 때, 무료 데이터베이스 서버 프로세스가 다시 할당되어 응용 프로그램은 서버 프로세스의 일시적 \"도난\"에 대해 알 필요가 없이 계속 진행됩니다. 응용 프로그램 코드를 변경할 필요가 없습니다. 데이터베이스의 자원이 공유되어 더 큰 확장성이 가능합니다.\n\nImplicit Connection Pooling은 순수 DRCP와 다릅니다. 순수 DRCP에서는 데이터베이스 서버 프로세스의 매핑 및 매핑 해제가 Oracle에 의해 암시적으로 수행됩니다. 순수 DRCP에서는 애플리케이션이 get-connection 및 close-connection 호출을 시작할 때만 매핑 및 매핑 해제가 수행됩니다.\n\nlong_run.py는 한 번의 open/close 쌍만 갖고 있으므로(Implicit Connection Pooling의 이상적인 대상입니다. 데이터베이스에서 DRCP를 시작하고, 연결 문자열을 DRCP 풀 서버 사용하도록 변경하고, 연결 문자열에 POOL_BOUNDARY 매개변수를 추가 설정하는 것만으로 구현 가능합니다. 응용 프로그램 코드를 수정할 필요가 없습니다. 데모를 다시 실행하면 결과가 출력됩니다:\n\n<div class=\"content-ad\"></div>\n\n```plaintext\r\n$ python3 runner.py\nUsing connection string: localhost/orclpdb1:pooled?pool_boundary=statement\nUser01 sid-ser 399-25678 at time 2024-06-11 20:28:46.803668\nUser02 sid-ser 399-25678 at time 2024-06-11 20:28:46.830118\nUser05 sid-ser 399-25678 at time 2024-06-11 20:28:46.840759\nUser04 sid-ser 399-25678 at time 2024-06-11 20:28:46.867337\nUser03 sid-ser 152-55977 at time 2024-06-11 20:28:46.908656\nUser08 sid-ser 152-55977 at time 2024-06-11 20:28:46.978751\nUser09 sid-ser 152-55977 at time 2024-06-11 20:28:47.045773\nUser06 sid-ser 152-55977 at time 2024-06-11 20:28:47.106757\nUser10 sid-ser 152-55977 at time 2024-06-11 20:28:47.169244\nUser07 sid-ser 152-55977 at time 2024-06-11 20:28:47.229357\nUser01 sid-ser 152-55977 at time 2024-06-11 20:28:51.844053\nUser02 sid-ser 399-25678 at time 2024-06-11 20:28:51.844449\nUser05 sid-ser 152-55977 at time 2024-06-11 20:28:51.855879\nUser04 sid-ser 152-55977 at time 2024-06-11 20:28:51.883601\nUser03 sid-ser 152-55977 at time 2024-06-11 20:28:51.940661\nUser08 sid-ser 152-55977 at time 2024-06-11 20:28:51.990124\nUser09 sid-ser 152-55977 at time 2024-06-11 20:28:52.058879\nUser06 sid-ser 152-55977 at time 2024-06-11 20:28:52.120180\nUser10 sid-ser 152-55977 at time 2024-06-11 20:28:52.182709\nUser07 sid-ser 152-55977 at time 2024-06-11 20:28:52.243295\nUser01 sid-ser 152-55977 at time 2024-06-11 20:28:56.874489\nUser02 sid-ser 399-25678 at time 2024-06-11 20:28:56.874487\nUser04 sid-ser 399-25678 at time 2024-06-11 20:28:56.895112\nUser03 sid-ser 399-25678 at time 2024-06-11 20:28:56.954245\nUser05 sid-ser 277-27334 at time 2024-06-11 20:28:56.969050\nUser08 sid-ser 277-27334 at time 2024-06-11 20:28:56.997923\nUser09 sid-ser 277-27334 at time 2024-06-11 20:28:57.072845\nUser06 sid-ser 277-27334 at time 2024-06-11 20:28:57.131504\nUser10 sid-ser 277-27334 at time 2024-06-11 20:28:57.195656\nUser07 sid-ser 277-27334 at time 2024-06-11 20:28:57.257700\nUser01 sid-ser 399-25678 at time 2024-06-11 20:29:01.903889\nUser02 sid-ser 277-27334 at time 2024-06-11 20:29:01.903889\nUser04 sid-ser 152-55977 at time 2024-06-11 20:29:01.910282\nUser03 sid-ser 152-55977 at time 2024-06-11 20:29:01.968523\nUser05 sid-ser 152-55977 at time 2024-06-11 20:29:01.997715\nUser08 sid-ser 152-55977 at time 2024-06-11 20:29:02.011130\nUser09 sid-ser 152-55977 at time 2024-06-11 20:29:02.086866\nUser06 sid-ser 152-55977 at time 2024-06-11 20:29:02.139241\nUser10 sid-ser 152-55977 at time 2024-06-11 20:29:02.209716\nUser07 sid-ser 152-55977 at time 2024-06-11 20:29:02.271144\nUser01 sid-ser 152-55977 at time 2024-06-11 20:29:06.940760\nUser02 sid-ser 277-27334 at time 2024-06-11 20:29:06.940760\nUser04 sid-ser 399-25678 at time 2024-06-11 20:29:06.940760\nUser03 sid-ser 399-25678 at time 2024-06-11 20:29:06.982961\nUser05 sid-ser 399-25678 at time 2024-06-11 20:29:07.010853\nUser08 sid-ser 399-25678 at time 2024-06-11 20:29:07.023677\nUser09 sid-ser 399-25678 at time 2024-06-11 20:29:07.102189\nUser06 sid-ser 399-25678 at time 2024-06-11 20:29:07.152508\nUser10 sid-ser 399-25678 at time 2024-06-11 20:29:07.223001\nUser07 sid-ser 399-25678 at time 2024-06-11 20:29:07.284733\nAll done!\nTime 25.96 seconds\r\n```\r\n\r\nThis shows that server process and session memory are being reused across different users' queries. For example, the first two lines have the same session identifier/serial number:\r\n\r\n```plaintext\r\nUser01 sid-ser 399-25678 at time 2024-06-11 20:28:46.803668\r\nUser02 sid-ser 399-25678 at time 2024-06-11 20:28:46.830118\r\n```\r\n\r\nIf you analyze the output, you can see that in this run, only three servers are used for all the queries being executed. The session identifier/serial number pairs are:\r\n\n\n\n<div class=\"content-ad\"></div>\n\n```js\n152-55977\n277-27334\n399-25678\n```\n\n이는 암시적 연결 풀링 없이 필요한 서버가 열 개보다 훨씬 적습니다. 절대 결과는 타이밍과 같은 요소에 따라 다를 수 있습니다.\n\n두 실행 간의 총 시간 차이는 비교에 중요하지 않지만 이 작은 테스트에서는 유의미하지 않습니다. 일반적으로 암시적 연결 풀링은 리소스를 공유하고 오라클 스택에 추가 작업을 수행해야 하기 때문에 암시적 연결 풀링으로 이동할 때 총 시간이 느려질 수 있습니다. — 심지어 정확하게 측정 가능한 차이가 있는 경우에도. 이는 애플리케이션이 SQL을 실행하는 빈도에 따라 달라질 수 있습니다. 그러나 데이터베이스 계층은 서버 프로세스 수가 적기 때문에 더 적은 메모리를 사용하므로 더 효율적일 수 있습니다 — 그리고 다른 애플리케이션에서 더 많은 사용자 연결을 처리할 수 있습니다.\n\n# 암시적 연결 풀링 구성하기\n\n\n<div class=\"content-ad\"></div>\n\nDRCP는 암시적 연결 풀링에서 사용하는 데이터베이스 서버 프로세스의 구성 가능한 풀을 제공합니다. DRCP는 데이터베이스에서 활성화, 모니터링 및 조정되어야 하며, 기술 브리프 'Database Resident Connection Pooling으로 극한의 Oracle 데이터베이스 연결 확장성 실현'을 참조하십시오.\n\n응용 프로그램 측에서 연결 문자열은 간단히 DRCP 풀 서버를 요청해야 합니다. 예를 들어, \":pooled\"나 \"(SERVER=POOLED)\"와 같이. 또한 새로운 POOL_BOUNDARY 매개변수를 포함해야 합니다. 이 블로그 게시물에서 사용된 연결 문자열은 Easy Connect 문자열 localhost/orclpdb1:pooled?pool_boundary=statement이었습니다. tnsnames.ora 파일에서 동일한 연결 기술자는 \"...(POOL_BOUNDARY=STATEMENT)...\"를 포함하게 됩니다.\n\nPOOL_BOUNDARY 매개변수에는 STATEMENT 또는 TRANSACTION 값이 있을 수 있습니다:\n\n- STATEMENT: 연결이 암시적으로 상태를 유지하지 않을 때, 즉 연결에 활성 커서가 없고(커서의 모든 행이 내부적으로 검색되었음), 활성 트랜잭션이 없음, 임시 테이블도 없고 임시 LOB도 없는 경우, 연결은 DRCP 연결 풀로 반환됨.\n- TRANSACTION: 응용 프로그램에서 커밋이나 롤백이 시작될 때 연결이 DRCP 연결 풀로 반환됩니다. 암시적 연결 풀링을 사용할 때는 \"autocommit\" 설정을 활성화하지 않는 것이 좋습니다. 만약 활성화한다면, 데이터베이스로 여러 번의 왕복이 필요한 데이터를 가져올 수 없게 되며, 스트리밍 LOB 데이터와 같은 데이터를 가져올 수 없게 됩니다.\n\n<div class=\"content-ad\"></div>\n\n보안을 위한 표준 DRCP 권장 사항에 따라, 연결 문자열에 POOL_CONNECTION_CLASS 매개변수를 추가하여 유사한 모든 애플리케이션에 동일한 값을 사용해야 합니다. 예를 들어:\n\nlocalhost/orclpdb1:pooled?pool_boundary=statement&pool_connection_class=myappname\n\nImplicit Connection Pooling에서 사용하는 DRCP \"순도\"는 기본적으로 SELF로 설정되어 있어 서버 프로세스 세션 메모리를 재사용할 수 있습니다. 연결 문자열 매개변수 POOL_PURITY=NEW를 추가하면 이를 변경하고 각 연결 사용 시 세션 메모리를 다시 생성합니다.\n\n선택적으로 PL/SQL 패키지 ORA_CPOOL_STATE를 만들어 연결 세션 상태를 가져오고 재설정할 수 있는 프로시저를 만들 수 있습니다. 오라클 콜 인터페이스 문서를 참조하세요.\n\n<div class=\"content-ad\"></div>\n\n# 암시적 연결 풀링을 사용하지 말아야 하는 경우\n\n만약 귀하의 응용 프로그램을 Oracle이 제공하는 응용 프로그램 연결 풀을 사용하도록 다시 구성할 수 있다면, 이것이 가장 효율적인 결과가 될 수 있습니다. 응용 프로그램 연결 풀은 리소스 공유를 제공하며 Oracle 데이터베이스 고가용성 기능을 제공합니다. 응용 프로그램 연결 풀(예: python-oracledb 연결 풀이나 node-oracledb 연결 풀과 같은)을 사용하는 것이 종종 다중 사용자 응용 프로그램에 가장 적합하며, 가끔씩 연결을 사용하는 단일 사용자 응용 프로그램조차도 혜택을 제공할 수 있습니다. Desktop applications with node-oracledb and electron 블로그 포스트는 이러한 시나리오 중 하나를 보여줍니다. 응용 프로그램이 Oracle 응용 프로그램 연결 풀을 효율적으로 사용하고 자주 연결을 가져오고 반환한다면, 암시적 연결 풀링은 혜택을 제공하지 않습니다.\n\n귀하의 응용 프로그램을 Oracle 응용 프로그램 연결 풀을 사용하도록 변경할 수 없지만, 응용 프로그램이 자주 연결을 여닫는 경우, 암시적 연결 풀링을 활성화하지 않고도 DRCP를 통해 혜택을 받을 수 있을 수도 있습니다. Connection Pool을 사용하지 않는 앱에 도움을 주는 DRCP helps apps that don’t use a Connection Pool 블로그 포스트를 참조하세요.\n\n응용 프로그램 수준에서 암시적 연결 풀링이 맞지 않는 경우도 있습니다. 이 게시물의 예제에서 보았듯이 각각의 SQL 문에 대해 \"사용자\"가 본 세션 식별자와 일련 번호는 해당 사용자 스크립트의 수명 동안 변할 수 있습니다. 그래서 귀하의 앱이 값이 변경되지 않는 것을 의존한다면, 암시적 연결 풀링이 적합하지 않을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n여러 개의 커서를 동시에 사용하거나 LOB를 스트리밍할 때 TRANSACTION을 문 단위로 사용하는 것은 문제가 발생할 수 있는 적합한 예입니다. 이러한 시나리오에서는 어떤 어플리케이션 커밋이든 열린 커서를 무효화하거나 LOB 스트리밍을 방해할 수 있습니다.\n\nImplicit Connection Pooling을 사용할 때 어플리케이션을 철저히 테스트해야 합니다. 이렇게 하면 데이터베이스 서버와 세션의 내부 재사용이 문제를 일으키지 않도록 할 수 있습니다.\n\n# 결론\n\nImplicit Connection Pooling을 사용하면 연결을 오랫동안 유지하는 애플리케이션이 데이터베이스 서버 프로세스와 세션 메모리를 공유할 수 있습니다. 이는 데이터베이스 호스트의 메모리 부하를 줄이고 전체 시스템을 확장 가능하게 만듭니다. Implicit Connection Pooling은 단일 연결을 열거나 Oracle이 제공하는 애플리케이션 연결 풀을 사용하는 대신 자체 연결 풀링 솔루션을 구현하는 앱에 유용할 수 있습니다. 인기 있는 Oracle 데이터베이스 드라이버에서 지원됩니다.\n\n<div class=\"content-ad\"></div>\n\n이 게시물은 암시적 연결 풀링이 DRCP를 사용하는 방법에 대해 논의했습니다. 또한 귀하의 시스템이 Oracle Connection Manager를 Traffic Director 모드로 사용하는 경우 PRCP를 사용할 수도 있습니다.\n\n암시적 연결 풀링에 대한 동영상은 동료 Sharad Chandran R의 노력 없는 연결 관리와 Oracle Database 23c의 암시적 풀링을 참조하십시오.\n\n# 참고 자료\n\n- 동영상: Oracle Database 23c의 암시적 풀링을 통한 노력 없는 연결 관리 (비디오).\n- Python-oracledb 문서: 암시적 연결 풀링.\n- Node-oracledb 문서: 암시적 연결 풀링.\n- 블로그 게시물: 항상 연결 풀을 사용하십시오 - 및 방법.\n- 블로그 게시물: DRCP는 연결 풀을 사용하지 않는 앱에 도움을 줍니다.\n- 기술 브리프: 데이터베이스 레지던트 연결 풀링 (DRCP)을 사용한 Oracle 데이터베이스 연결 확장 가능성.\n- 기술 브리프: CMAN-TDM - 확장 가능하고 고가용성 애플리케이션용 Oracle 데이터베이스 연결 프록시.","ogImage":{"url":"/assets/img/2024-06-20-ImplicitConnectionPoolingwhenconnectionsoverloadyourdatabase_0.png"},"coverImage":"/assets/img/2024-06-20-ImplicitConnectionPoolingwhenconnectionsoverloadyourdatabase_0.png","tag":["Tech"],"readingTime":14},{"title":"NestJS에서의 Lazy Loading 성능과 효율성 향상","description":"","date":"2024-06-20 01:43","slug":"2024-06-20-LazyLoadinginNestJSBoostingPerformanceandEfficiency","content":"\n\n<img src=\"/assets/img/2024-06-20-LazyLoadinginNestJSBoostingPerformanceandEfficiency_0.png\" />\n\n게으른로딩은 실제로 필요할 때까지 리소스의 초기화를 지연시키는 강력한 디자인 패턴입니다. 이는 응용 프로그램의 성능과 리소스 관리를 현저히 개선할 수 있습니다. NestJS에서는 동적 모듈과 @nestjs/core의 LazyModuleLoader를 사용하여 게으른 로딩을 구현할 수 있습니다. 이 문서에서는 두 가지 방법을 탐구하며 자세한 예제를 제공하여 NestJS 응용 프로그램에서 게으른 로딩을 구현하는 데 도움을 줍니다.\n\n## 게으른 로딩의 이점\n\n게으른 로딩은 다음을 도와줍니다:\n\n<div class=\"content-ad\"></div>\n\n- 초기 로드 시간 단축: 모든 것을 시작할 때 불러오지 않아도 애플리케이션이 더 빨리 시작됩니다.\n- 리소스 사용 최적화: 실제로 필요한 경우에만 구성 요소 또는 모듈을 로드합니다.\n- 확장성 향상: 리소스를 효율적으로 사용하면 애플리케이션이 더 잘 확장될 수 있습니다.\n\n# Lazy Loading을 위해 LazyModuleLoader 사용하기\n\nNestJS에서 Lazy Loading을 구현하려면 @nestjs/core의 LazyModuleLoader를 사용합니다.\n\n## 단계 1: Lazy Loading할 모듈 생성하기\n\n<div class=\"content-ad\"></div>\n\n이전과 같이 ReportsModule을 생성하세요.\n\n```js\n// reports.module.ts\nimport { Module } from '@nestjs/common';\nimport { ReportsService } from './reports.service';\nimport { ReportsController } from './reports.controller';\n\n@Module({\n  controllers: [ReportsController],\n  providers: [ReportsService],\n})\nexport class ReportsModule {}\n```\n\n## 단계 2: Lazy Loaded Module을 위한 서비스 생성\n\nReportsModule을 위한 서비스를 정의하세요.\n\n<div class=\"content-ad\"></div>\n\n```js\n// reports.service.ts\nimport { Injectable } from '@nestjs/common';\n\n@Injectable()\nexport class ReportsService {\n  getReport(): string {\n    console.log('lazily loaded reports module');\n    return 'This is a report!';\n  }\n}\n```\n\n## Step 3: Define the Main Module\n\nReportsModule을 나중에 import할 것이기 때문에 AppModule을 정의합니다.\n\n```js\n// app.module.ts\nimport { Module } from '@nestjs/common';\nimport { AppController } from './app.controller';\nimport { AppService } from './app.service';\n\n@Module({\n  imports: [],\n  controllers: [AppController],\n  providers: [AppService],\n})\nexport class AppModule {}\n```\n\n<div class=\"content-ad\"></div>\n\n## 단계 4: 레이지 로딩 및 기타 로직을 처리하는 컨트롤러 생성\n\nReportsModule을 동적으로 로드하는 LazyModuleLoader를 사용하는 컨트롤러를 생성하세요.\n\n```js\n// app.controller.ts\nimport { Controller, Get } from '@nestjs/common';\nimport { LazyModuleLoader } from '@nestjs/core';\nimport { ReportsModule } from './reports/reports.module';\nimport { ReportsService } from './reports/reports.service';\n\n@Controller()\nexport class AppController {\n  constructor(private readonly lazyModuleLoader: LazyModuleLoader) {}\n\n  @Get()\n  async getLazyReport(): Promise<string> {\n    // ReportsModule의 초기화 시간을 알아내기 위해 console.time() 및 console.timeEnd() 사용\n    console.time();\n    const moduleRef = await this.lazyModuleLoader.load(() => ReportsModule);\n    const reportsService = moduleRef.get(ReportsService);\n    console.timeEnd();\n    return reportsService.getReport();\n  }\n}\n```\n\n# 예시 사용법\n\n<div class=\"content-ad\"></div>\n\n엔드포인트에 처음 요청이 발생하면 ReportsModule이 게으르게 로드되며, ReportsService가 요청을 처리하고 보고서를 반환할 것입니다.\n\n```js\n$ curl http://localhost:3000/lazy-reports\n이것은 보고서입니다!\n```\n\n그리고 여러 요청을 생성하면 각 연속적인 시도마다 ReportsModule을 로드하는 것이 훨씬 빨라집니다. load 메서드는 모듈의 캐시된 인스턴스를 반환합니다.\n\n한 번 이상의 요청을 생성하면 앱 로그에 이와 같은 출력이 표시됩니다.\n\n<div class=\"content-ad\"></div>\n\n```js\ndefault: 6.226ms\nReports 모듈을 게으르게 로드했습니다\n[Nest] 208649  - 2024년 5월 26일, 오후 8:33:22     LOG [LazyModuleLoader] ReportsModule 종속성이 초기화되었습니다\ndefault: 2.323ms\nReports 모듈을 게으르게 로드했습니다\n[Nest] 208649  - 2024년 5월 26일, 오후 8:33:22     LOG [LazyModuleLoader] ReportsModule 종속성이 초기화되었습니다\ndefault: 2.012ms\nReports 모듈을 게으르게 로드했습니다\n```\n\n# 결론\n\nNestJS에서 게으른 로딩을 구현하면 응용프로그램의 성능과 자원 효율성을 크게 향상시킬 수 있습니다.\n\nNestJS에서 LazyModuleLoader를 사용하면 모듈이 처음으로 게으르게 로드되고 캐시되어 성능 및 자원 사용량을 최적화합니다. 이 접근 방식은 동적 모듈 로딩을 효율적으로 관리하여 초기 로드 시간과 런타임 효율성 사이의 균형을 제공합니다.","ogImage":{"url":"/assets/img/2024-06-20-LazyLoadinginNestJSBoostingPerformanceandEfficiency_0.png"},"coverImage":"/assets/img/2024-06-20-LazyLoadinginNestJSBoostingPerformanceandEfficiency_0.png","tag":["Tech"],"readingTime":4},{"title":"웹 개발을 위한 상위 10개 Nodejs 프레임워크","description":"","date":"2024-06-20 01:40","slug":"2024-06-20-Top10NodejsFrameworksForWebDevelopment","content":"\n\n## 웹 개발을 위한 최고의 Node.js 프레임워크에 대한 포괄적인 가이드\n\n![이미지](/assets/img/2024-06-20-Top10NodejsFrameworksForWebDevelopment_0.png)\n\n노드.js는 논블로킹 및 이벤트 기반 아키텍처로 인해 웹 개발에서 인기 있는 선택지가 되었습니다.\n\n이를 통해 빠르고 확장 가능하며 실시간 응용 프로그램을 구축할 수 있습니다. 개발을 쉽게하고 기능을 향상시키기 위해 Node.js 기반으로 여러 프레임워크가 구축되었습니다.\n\n<div class=\"content-ad\"></div>\n\n이 프레임워크들은 웹 및 API 개발을 더 쉽고 효율적으로 만드는 데 필수적입니다.\n\nNode.js가 2009년에 등장하기 전에는 웹 개발자들이 주로 클라이언트 측 스크립팅에 JavaScript를 사용하는 제약을 겪었습니다. 그 전에도 몇 가지 서버 측 JavaScript 프레임워크가 있었지만 널리 사용되지는 않았습니다. Node.js는 JavaScript를 클라이언트 쪽 및 서버 쪽 개발 모두에 사용할 수 있게 함으로써 같은 언어를 전체 애플리케이션에서 사용할 수 있도록 하여 게임을 바꿨습니다.\n\n이 가이드는 웹 개발을 위한 최고의 Node.js 프레임워크를 탐색하며, 주요 기능과 이상적인 사용 사례를 강조하여 프로젝트에 완벽하게 맞는 것을 선택하는 데 도움을 줍니다.\n\n# Node.js Frameworks: A Quick Look\n\n<div class=\"content-ad\"></div>\n\n![Node.js Frameworks](/assets/img/2024-06-20-Top10NodejsFrameworksForWebDevelopment_1.png)\n\nNode.js는 기술적으로 JavaScript 런타임 환경이지만 종종 프레임워크로 불립니다.\n\nNode.js는 이를 기반으로 하는 JavaScript 프레임워크와 함께 개발자들에게 사전 작성된 코드, 도구 및 라이브러리를 제공하여 웹 개발을 더 쉽고 빠르게 만듭니다.\n\n어떤 Node.js 프레임워크의 핵심 부분은 그 아키텍처와 기능입니다. 이에는 보안 지원, 다른 라이브러리와의 호환성, 유연성 및 사용자 정의 가능성이 포함됩니다.\n\n<div class=\"content-ad\"></div>\n\n웹 개발을 위해 Node.js를 사용하는 것에는 여러 가지 이점과 단점이 있습니다. 이러한 장단점을 이해하는 것은 이러한 기능이 개발 요구 사항을 얼마나 잘 충족시키는지에 따라 달라집니다.\n\n# 웹 개발을 위한 최고의 10가지 Node.js 프레임워크\n\n## 1. Express.js\n\nExpress.js는 Node.js 프레임워크 중에서도 최소주의 챔피언으로 높이 평가받고 있습니다. 유연성과 사용 편의성을 우선시하며, 모든 경험 수준의 개발자들 사이에서 인기가 있습니다. 이것이 Express.js를 웹 개발에 강력한 도구로 만드는 이유입니다:\n\n<div class=\"content-ad\"></div>\n\n주요 특징:\n\n- 고유한 미니멀리즘 및 고인물 없는 코어로 높은 유연성을 제공합니다.\n- 서드 파티 미들웨어 및 플러그인의 방대한 생태계가 있습니다.\n- 다양한 URL 요청을 처리하는 강력한 라우팅 시스템이 있습니다.\n- 14가지 이상의 옵션과 함께 작동하는 견고한 템플릿 엔진 지원이 있습니다.\n- 사용자 경험을 고려한 내장된 오류 처리가 있습니다.\n- 자산 효율적 전달을 위한 정적 파일 제공이 있습니다.\n- 플러그인 및 미들웨어를 통한 확장 가능한 아키텍처가 있습니다.\n- 문제 해결을 간소화하는 디버깅 기능이 있습니다.\n- 다양한 HTTP 도우미 함수가 있습니다.\n- 최적의 콘텐츠 전달을 위한 향상된 콘텐츠 협상이 있습니다.\n\n이상적인 용도:\n\n- 일반 웹 애플리케이션, RESTful API, 싱글 페이지 애플리케이션(SPA), 실시간 애플리케이션, 미들웨어 풍부한 애플리케이션에 적합합니다.\n\n<div class=\"content-ad\"></div>\n\n왜 Express.js를 고려해야 하는가:\n\n- 쉽고 포괄적인 학습 자료 덕분에 초보자에게 이상적입니다.\n- 프로젝트의 특정 요구 사항에 맞게 매우 유연하게 사용할 수 있습니다.\n- 개발 시간을 절약할 수 있는 다양한 미리 제작된 도구 생태계가 있습니다.\n- 대부분의 웹 개발 시나리오에 대해 잘 동작하는 성능을 제공합니다.\n\n## 2. NestJS\n\nNestJS는 Express.js와 다르게 다가갑니다. Express 위에 구축된 완벽한 프레임워크로 TypeScript를 활용해 구조를 강제하고 깨끗한 코드 아키텍처를 촉진합니다. NestJS가 제공하는 것은 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n키 특징:\n\n- 클래스와 데코레이터를 활용한 객체지향 개발\n- 더 깔끔한 코드를 위한 내장형 의존성 주입\n- 확장 가능한 모듈식 아키텍처\n- 견고한 어플리케이션을 위한 테스트 유틸리티\n\n이상적인 사용 용도:\n\n- 기업 어플리케이션, API, 마이크로서비스 아키텍처\n\n<div class=\"content-ad\"></div>\n\nNestJS를 고려해야 하는 이유:\n\n- 대형 프로젝트의 코드 유지 보수성 및 확장성을 촉진합니다.\n- 의존성 주입과 같은 기능으로 보일러플레이트 코드를 줄입니다.\n- 복잡한 응용프로그램을 구축하기 위한 구조화된 접근 방식을 제공합니다.\n\n## 3. Koa.js\n\nKoa.js는 다음 세대의 Node.js 프레임워크로 간주되며 종종 Express.js의 후속작으로 여겨집니다. Express.js에 비해 응용프로그램을 보다 더 세밀하게 제어할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n중요 기능:\n\n- 현대 웹 애플리케이션에 이상적인 비동기 기본 설정.\n- 유연성을 위한 미들웨어 기반 아키텍처.\n- 비동기 작업 처리를 위한 제너레이터 함수.\n- 맞춤화에 초점을 맞춘 작은 코어.\n\n적합한 용도:\n\n- API, 마이크로서비스, 실시간 애플리케이션\n\n<div class=\"content-ad\"></div>\n\n코드를 Markdown 형식으로 바꿔드릴게요.\n\n왜 Koa.js를 고려해야 하나요:\n\n- Express.js보다 사용자 정의 기능을 구축하기 위한 유연성이 더 큼\n- 비동기 작업에 초점을 맞춘 현대적인 웹 애플리케이션에 적합\n- 작은 코어 크기로 가벼운 프레임워크가 필요한 프로젝트에 이상적\n\n## 4. Fastify\n\nFastify는 초고속 성능을 우선시하여, 빠른 속도와 낮은 대기 시간을 요구하는 응용 프로그램에 적합합니다.\n\n<div class=\"content-ad\"></div>\n\n키 특징:\n\n- 효율적인 라우팅 및 플러그인 아키텍처로 인한 초고속 성능.\n- 자동 라우트 등록을 통한 쉬운 플러그 앤 플레이 아키텍처.\n- 견고한 데이터 처리를 위한 스키마 유효성 검사.\n- 깔끔한 API로 우수한 개발자 경험을 제공.\n\n이상적인 용도:\n\n- 실시간 애플리케이션, 성능 중요한 API, 대규모 웹 애플리케이션에 적합합니다.\n\n<div class=\"content-ad\"></div>\n\n빠른 Fastify의 이유를 고려해보세요:\n\n- 최상의 성능을 요구하는 애플리케이션에 이상적입니다.\n- 개발자 친화적인 API로 쉽게 배우고 사용할 수 있습니다.\n- 모듈식 아키텍처를 통해 플러그인을 사용하여 맞춤 설정이 가능합니다.\n\n## 5. Hapi.js\n\nHapi.js는 견고한 보안 기능과 프로덕션 준비 기능으로 잘 알려진 기업용 프레임워크입니다.\n\n<div class=\"content-ad\"></div>\n\n주요 기능:\n\n- 다양한 기능을 위한 폭넓은 플러그인 생태계.\n- 데이터 무결성을 위한 내장 검증.\n- 인증 및 권한 부여와 같은 견고한 보안 기능.\n- 훌륭한 문서 및 다양하고 지원하는 커뮤니티.\n\n이상적인 사용처:\n\n- 대규모 기업 애플리케이션, 중요한 API에 적합합니다.\n\n<div class=\"content-ad\"></div>\n\n왜 Hapi.js를 고려해야 하는가:\n\n- 뛰어난 보안 기능으로 민감한 데이터를 보호하기에 이상적이다.\n- 방대한 문서와 다양한 커뮤니티가 지원을 보장한다.\n- 신뢰할 수 있는 어플리케이션을 구축하기 위한 성숙하고 안정적인 프레임워크를 제공한다.\n\n## 6. Sails.js\n\nSails.js는 실시간 기능과 데이터 주도 개발에 중점을 둔 MVC 프레임워크입니다.\n\n<div class=\"content-ad\"></div>\n\n주요 기능:\n\n- 실시간 통신을 위한 내장된 웹 소켓 지원.\n- 풍부한 모델 기능으로 데이터 기반 개발.\n- 효율적인 API 개발을 위한 자동 REST API 생성.\n- 설정보다 규칙에 중점을 둔 개발자 생산성에 초점.\n\n이를 통해 실시간 웹 애플리케이션, 채팅 애플리케이션, 협업 편집 도구에 이상적입니다.\n\n<div class=\"content-ad\"></div>\n\n왜 Sails.js를 고려해야 하는가:\n\n- 내장된 웹 소켓을 통해 실시간 기능의 개발을 간소화합니다.\n- 데이터 중심 웹 애플리케이션을 쉽게 구축할 수 있습니다.\n- 더 빠른 개발을 위한 관례 기반 접근 방식을 제공합니다.\n\n## 7. Meteor.js\n\n대부분의 프레임워크와 달리, Meteor.js는 웹, 모바일 및 데스크톱 애플리케이션을 구축하기 위한 풀 스택 솔루션을 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n주요 기능:\n\n- 클라이언트와 서버 간 실시간 데이터 동기화.\n- 자동 데이터 업데이트를 위한 반응형 프로그래밍 모델.\n- 웹, 모바일 (iOS, Android), 데스크탑 (Windows, macOS, Linux)에서 작동.\n- 쉬운 배포를 위한 내장된 빌드 도구.\n\n이상적인 용도:\n\n- 실시간 협업 애플리케이션, 채팅 애플리케이션, 소셜 네트워킹 플랫폼에 적합합니다.\n\n<div class=\"content-ad\"></div>\n\n왜 Meteor.js를 고려해야 하는가:\n\n- 자동 데이터 동기화로 실시간 애플리케이션을 구축을 간단하게 만들어줍니다.\n- 크로스 플랫폼 애플리케이션 (웹, 모바일, 데스크톱)을 개발하는 데 사용할 수 있습니다.\n- 풀 스택 애플리케이션에 대한 통합 개발 경험을 제공합니다.\n\n## 8. LoopBack\n\nLoopBack은 빠른 API 개발과 내장된 접근 제어에 중점을 둔다.\n\n<div class=\"content-ad\"></div>\n\n주요 기능:\n\n- RESTful API를 위한 자동 API 생성 기능.\n- 사용자 권한 관리를 위한 내장된 액세스 제어 (ACL).\n- 다양한 데이터베이스 통합을 위한 포괄적인 커넥터.\n- 클라우드 플랫폼과 쉽게 통합 가능.\n\n이상적인 용도:\n\n- RESTful API, 모바일 백엔드, 사물인터넷 (IoT) 애플리케이션 백앤드.\n\n<div class=\"content-ad\"></div>\n\nLoopBack을 고려해야 하는 이유:\n\n- 자동 API 생성으로 빠른 API 개발에 적합합니다.\n- 기본 액세스 제어가 사용자 권한 관리를 간단하게 만들어 줍니다.\n- 다양한 데이터 소스에 연결되는 API 구축에 적합합니다.\n\n## 9. Feathers.js\n\nFeathers.js는 마이크로서비스 아키텍처를 활용한 현대적인 웹 애플리케이션을 개발하는 데 적합한 경량 프레임워크입니다.\n\n<div class=\"content-ad\"></div>\n\n주요 기능:\n\n- 확장성과 유지보수성을 위한 마이크로서비스 아키텍처.\n- 웹소켓 지원을 내장한 실시간 기능.\n- 효율적인 데이터 처리를 위한 클라이언트-서버 통신에 집중.\n- 커스터마이징을 위한 강력한 훅을 갖춘 RESTful API.\n\n이 제품은 다음에 최적화되어 있습니다:\n\n- 확장 가능한 API, 마이크로서비스 아키텍처, 실시간 웹 애플리케이션 구축\n\n<div class=\"content-ad\"></div>\n\n표를 마크다운 형식으로 변경하세요.\n\n\n| 왜 Feathers.js를 고려해야 하는가:\n\n- 마이크로서비스 아키텍처로 구축된 현대 웹 애플리케이션에 적합합니다.\n- 실시간 통신 및 유연성에 중점을 둔 경량 프레임워크입니다.\n- 복잡한 애플리케이션을 구축하기 위한 모듈식 접근 방식을 제공합니다.\n\n## 10. Adonis.js\n\nAdonis.js는 내장된 ORM(Object-Relational Mapper)을 갖춘 객체지향 MVC 프레임워크이며, 데이터베이스 상호작용을 간소화합니다.\n\n\n<div class=\"content-ad\"></div>\n\n주요 기능:\n\n- 관심사의 명확한 분리를 통한 객체지향 개발.\n- 간소화된 데이터베이스 상호작용을 위한 내장 Adonis ORM.\n- 효율적인 성능을 위한 비동기 프로그래밍.\n- 깔끔하고 간결한 구문으로 개발자 경험에 중점을 둠.\n\n이상적인 대상:\n\n- 일반적인 웹 애플리케이션, 데이터베이스 주도 애플리케이션, API\n\n<div class=\"content-ad\"></div>\n\n왜 Adonis.js를 고려해야 하는가:\n\n- 깔끔한 구문 및 객체 지향 접근 방식은 학습과 사용이 쉽습니다.\n- 내장 ORM은 데이터베이스 상호 작용을 단순화합니다.\n- 다양한 웹 개발 프로젝트에 대한 훌륭한 프레임워크를 제공합니다.\n\n# XongoLab과 함께 노드.js의 파워를 경험해보세요\n\nXongoLab은 경험이 풍부한 개발팀을 보유한 선도적인 노드.js 개발 회사입니다. 우리는 최신 기술과 도구를 사용하여 인기 있는 노드.js 프레임워크로 고품질이면서 확장 가능한 웹 애플리케이션을 구축합니다.\n\n<div class=\"content-ad\"></div>\n\n우리의 다양한 NodeJS 개발 서비스는 모든 사용자 정의 요구 사항을 충족합니다. 우리 팀은 최고의 Node.js 프레임워크를 사용하여 모든 규모의 비즈니스를 위한 웹 앱이나 API를 개발하는 데 능숙합니다. Node.js 개발자를 고용하고 오늘부터 웹 개발 프로젝트를 시작해보세요.\n\n# 마무리\n\nNode.js 프레임워크 랜드스케이프는 다양한 옵션으로 풍부합니다. 각 프레임워크의 강점과 약점을 이해하고 프로젝트 요구 사항을 신중하게 평가함으로써, 강력하고 확장 가능하며 효율적인 Node.js 애플리케이션을 구축하는 최적의 선택을 할 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-20-Top10NodejsFrameworksForWebDevelopment_0.png"},"coverImage":"/assets/img/2024-06-20-Top10NodejsFrameworksForWebDevelopment_0.png","tag":["Tech"],"readingTime":7},{"title":"NodeJS 유닛 테스팅 튜토리얼 포괄적 가이드","description":"","date":"2024-06-20 01:38","slug":"2024-06-20-NodeJSUnitTestingTutorialAComprehensiveGuide","content":"\n\n![Node.js Unit Testing Tutorial](/assets/img/2024-06-20-NodeJSUnitTestingTutorialAComprehensiveGuide_0.png)\n\n안녕하세요! Node.js는 서버 측에서 JavaScript를 실행하는 인기 있는 JavaScript 엔진입니다. 세계적인 최고의 기술 회사들이 Node.js를 사용하여 효율적이고 효과적인 소프트웨어 개발을 해 왔기 때문에 JavaScript를 사용한 서버 측 개발에서는 사실상 표준으로 자리 잡았습니다.\n\n소프트웨어 공학에서 소프트웨어 테스팅은 중요한 단계로, 결함을 제거하고 테스트 중인 소프트웨어가 요구 사항을 준수하는지 확인하는 데 도움이 됩니다.\n\nMocha를 사용하여 소프트웨어 테스팅을 구현하는 것이 몇 년 동안 다른 도구보다 증가하는 이점을 보여 주었습니다. 이렇게 하면 TDD(Test-Driven Development) 및 BDD(Behavior-Driven Development)를 위한 단언 라이브러리 사이를 쉽게 전환할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nNodeJS 단위 테스트 튜토리얼에서는 Node.js를 사용하여 효과적인 소프트웨어 테스트를 수행하고, Mocha와 Chai를 사용하여 효율적인 테스트 케이스를 작성하는 방법을 탐색할 것입니다. 또한, Chai와 Mocha를 결합하여 Node에서 자동화된 테스트를 실행함으로써 더 나은 품질의 코드를 작성하는 방법을 배울 수 있을 것입니다.\n\n## NodeJS 단위 테스트란?\n\nNodeJS 단위 테스트는 전문 자동화 테스트 프레임워크와 라이브러리를 사용하여 Node.js 애플리케이션의 개별 단위나 구성 요소를 테스트하는 것을 의미합니다.\n\n이러한 테스트에는 개별 함수, 모듈 또는 클래스의 기능을 테스트하거나 애플리케이션의 서로 다른 부분 간의 상호 작용을 테스트하는 것이 포함될 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n인기있는 NodeJS 단위 테스트 프레임워크에는 Jest, Mocha, AVA 등이 있습니다. 그러나 이 NodeJS 단위 테스트 튜토리얼에서는 Mocha와 Chai를 사용한 NodeJS 단위 테스트에 대해 살펴볼 것입니다.\n\n## Mocha와 Chai를 사용한 NodeJS 단위 테스트\n\nMocha.js는 Node.js 및 브라우저에서 실행되는 인기있는 JavaScript 테스트 프레임워크입니다. 다양한 환경에서 테스트를 구조화하고 실행하는 간단하고 유연한 방법을 제공합니다.\n\nChai는 Mocha와 결합하여 더 자연스럽고 표현력 있는 방식으로 테스트 어설션을 작성할 수 있는 어설션 라이브러리입니다. Mocha와 Chai를 사용하면 Node.js 애플리케이션의 단위 테스트를 쉽게 작성하고 실행할 수 있습니다. 이 Mocha NodeJS 튜토리얼을 통해 Mocha를 사용하여 NodeJS 모듈을 테스트하는 방법에 대해 더 배울 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n현재로서 Chai와 Mocha는 각각 Github와 npmtrends.com을 기준으로 사용량과 월간 다운로드 수를 토대로 상당한 인기를 얻고 있습니다.\n\n![image](/assets/img/2024-06-20-NodeJSUnitTestingTutorialAComprehensiveGuide_1.png)\n\n이 NodeJS 단위 테스트 튜토리얼의 다음 섹션에서는 Mocha와 Chai를 사용하여 단위 테스트를 작성하는 방법에 대해 알아보겠습니다.\n\n## Mocha와 Chai로 단위 테스트 작성하는 방법은?\n\n<div class=\"content-ad\"></div>\n\n이 섹션에서는 단위 테스트를 구현하기 위해 Mocha 테스팅 라이브러리와 Chai 어설션 라이브러리를 사용하는 방법을 배우게 됩니다.\n\nNodeJS 단위 테스트를 작성하기 위해 Mocha와 Chai를 설치하고 구성하기 전에 Mocha와 Chai에서 자주 사용되는 메서드 중 일부를 살펴보겠습니다.\n\n### Describe:\n\n`describe()` 메서드는 그룹화된 테스트 스위트의 블록입니다. 이는 테스트를 위해 그룹화된 테스트 스크립트 모음입니다. 두 개의 매개변수를 사용하며, 첫 번째는 스위트의 이름으로 사용되는 문자열이고, 두 번째는 테스트 케이스를 그룹화하는 콜백 함수입니다.\n\n<div class=\"content-ad\"></div>\n\n```js\ndescribe('테스트 도우미', function () {\n /**\n  * 여기에 모든 관련 테스트 케이스를 추가하세요\n  *\n  */\n});\n```\n\nIt():\n\n`it()` 메서드는 실행할 가장 작은 테스트 케이스입니다. 두 개의 매개변수를 가져옵니다. 첫 번째는 suite의 이름인 문자열이고 두 번째는 테스트 케이스를 실행할 콜백 함수입니다.\n\n```js\ndescribe('테스트 도우미', function () {\n it('피보나치 수열을 계산해야 합니다', function () {\n   /*...*/\n });\n});\n```\n\n<div class=\"content-ad\"></div>\n\n기대:\n\n`expect()` 메서드는 행동 주도 개발 (BDD) 스타일 라이브러리에서 단언문을 체이닝하기 위해 사용됩니다. 대부분 불리언이나 숫자 등으로 해결되는 주제에 사용됩니다.\n\n```js\nit('피보나치 수열을 계산해야 합니다', function () {\n   const fib = fibonacci(4);\n   expect(fib).toEqual(5);\n });\n```\n\n해야 할 일:\n\n<div class=\"content-ad\"></div>\n\n`should()` 메서드는 BDD-style 라이브러리에서도 사용되어, 단언문을 연결하는 데 사용됩니다. 그러나 각 객체에 should 속성이 추가되어 체인을 시작합니다.\n\n```js\nit('일부 챌린지 업데이트 - 찾을 수 없음', async () => {\n const response = await chai.request(app)\n should.equal(response.status, 404)\n should.equal(response.body.message, 'Challenge with id: ${notFoundId} doesn't exist')\n})\n```\n\nAssert:\n\n`assert()` 메서드는 테스트 주도 개발 (TDD) 스타일 라이브러리에서 사용되어, 단언문을 연결하는 데 사용됩니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nit('partially update challenge - not found', async () => {\n assert('foo' !== 'bar', 'foo is not bar');\n assert(Array.isArray([]), 'empty arrays are arrays');\n})\n```\n\nMocha 및 Chai를 설치하는 방법은 무엇인가요?\n\nMocha와 Chai를 시작하려면 먼저 프로젝트에 설치해야 합니다. 터미널에서 다음 명령을 실행하여 설치할 수 있습니다. LambdaTest로 JavaScript 자동화를 빠르게 시작해 보세요!\n\n<div class=\"content-ad\"></div>\n\n이 프로젝트를 위해 새 프로젝트를 생성하거나 이 저장소를 복제할 수 있어요:\n\n```js\nnpm install --save-dev mocha \nnpm install --save-dev chai\n```\n\n여기서 저장소를 다운로드할 수 있어요.\n\nMocha와 Chai가 설치되었으면, 테스트 파일을 만들기 시작할 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n아래는 마크다운 형식으로 변경한 내용입니다.\n\n![NodeJSUnitTestingTutorialAComprehensiveGuide_2](/assets/img/2024-06-20-NodeJSUnitTestingTutorialAComprehensiveGuide_2.png)\n\n프로젝트 폴더 구조를 보면 다음 샘플과 같이 tests 폴더가 포함되어 있어야 합니다.\n\n![NodeJSUnitTestingTutorialAComprehensiveGuide_3](/assets/img/2024-06-20-NodeJSUnitTestingTutorialAComprehensiveGuide_3.png)\n\nMocha는 기본적으로 test라는 디렉토리에서 테스트 파일을 찾지만 다른 디렉토리나 파일 패턴을 지정하여 테스트 파일을 찾을 수도 있습니다. 각 테스트 파일은 `.test.js` 또는 `.spec.js` 파일 확장자를 가져야 합니다.\n\n<div class=\"content-ad\"></div>\n\n그 다음, 새 프로젝트를 만들었다면 package.json 파일을 열고 아래 코드에서 \"scripts\" 블록을 \"mocha\"로 변경하세요:\n\n```js\n\"scripts\": {\n   \"test\": \"mocha\",\n   \"start\": \"node app.js\"\n },\n```\n\n테스트를 실행하기 전에 .env 파일에서 다음 환경 변수를 설정해주세요. LambdaTest 프로필 페이지에서 사용자 이름과 액세스 키를 찾을 수 있습니다.\n\n여기서는 실제 브라우저, 기기 및 운영 체제 조합 3000개 이상에서 웹 및 모바일을 위한 수동 및 자동화 테스트를 수행할 수 있는 LambdaTest에서 Node.js 단위 테스트를 실행하고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nLT_USERNAME= \nLT_ACCESS_KEY= \nGRID_HOST=hub.lambdatest.com/wd/hub\n```\n\n라이브러리를 설치하고 환경 변수를 설정한 후에, 아래는 웹 계산기의 구현입니다:\n\n## 간단한 NodeJS 앱을 만드는 방법\n\n먼저 NodeJS 애플리케이션을 만들어서 Node 어플리케이션에 전달된 입력을 계산하고 결과를 응답으로 반환하는 간단한 NodeJS 애플리케이션을 만들어보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n아래 애플리케이션에서는 Node.js를 사용하여 간단한 계산기 애플리케이션을 만들고 프로덕션 서버에 배포했습니다. 다음은 두 개의 입력값을 받아 계산된 결과를 반환하는 애플리케이션입니다.\n\n![calculator](/assets/img/2024-06-20-NodeJSUnitTestingTutorialAComprehensiveGuide_4.png)\n\n이미 라이브 서버에 애플리케이션이 배포되어 있으므로 계산하여 결과를 반환할 것입니다. 아래는 LambdaTest 클라우드 Selenium 그리드를 사용하여 계산을 수행하는 코드입니다.\n\n```js\nconst { Builder, By } = require('selenium-webdriver');\nlet driver;\nconst USERNAME = process.env.LT_USERNAME ?? '';\nconst KEY = process.env.LT_ACCESS_KEY ?? '';\nconst GRID_HOST = 'hub.lambdatest.com/wd/hub';\n\nconst searchCapabilities = {\n  browserName: 'Chrome',\n  browserVersion: '110.0',\n  'LT:Options': {\n    username: USERNAME,\n    accessKey: KEY,\n    geoLocation: 'US',\n    platformName: 'Windows 10',\n    build: 'calculate',\n    project: 'Calculate',\n    w3c: true,\n    plugin: 'node_js-node_js',\n  },\n};\n\nconst searchGridUrl = 'https://' + USERNAME + ':' + KEY + '@' + GRID_HOST;\n\nasync function calculateWithLambdaTest(num1 = 5, num2 = 5) {\n  try {\n    driver = await new Builder()\n      .usingServer(searchGridUrl)\n      .withCapabilities(searchCapabilities)\n      .build();\n\n    await driver.get(\n      'https://www.lambdatest.com/selenium-playground/simple-form-demo'\n    );\n\n    const inputSum1 = await driver.findElement(By.id('sum1'));\n    const inputSum2 = await driver.findElement(By.id('sum2'));\n    const button = await driver.findElement(\n      By.xpath(\n        '/html/body/div[1]/div/section[3]/div/div/div[2]/div[2]/div[2]/div/div[1]/form/button'\n      )\n    );\n\n    inputSum1.sendKeys(num1);\n    inputSum2.sendKeys(num2);\n\n    button.click();\n\n    const result = await driver.findElement(By.id('addmessage'));\n\n    return await result.getText();\n  } catch (error) {\n    throw new Error(error);\n  } finally {\n    await driver.quit();\n  }\n}\n\nmodule.exports = {\n  calculate: calculateWithLambdaTest,\n};\n```\n\n<div class=\"content-ad\"></div>\n\n안내:\n\n코드를 함께 살펴보고 이해해 봅시다.\n\n단계 1: 필요한 패키지 추가 및 Selenium 기능 생성\n\n먼저 selenium-webdriver 패키지가 필요합니다. 작업을 실행하기 전에 필요한 것을 초기화했습니다.\n\n<div class=\"content-ad\"></div>\n\n다음으로, Markdown 형식으로 테이블 태그를 변경해주세요.\n\n다음으로, LambdaTest Capabilities Generator를 사용하여 Selenium 구성을 생성합니다. 구성을 설정하고 아래에 표시된 대로 JavaScript 객체를 코드에 복사하세요.\n\n![LambdaTest Capabilities Generator](/assets/img/2024-06-20-NodeJSUnitTestingTutorialAComprehensiveGuide_5.png)\n\n단계 2: 작업 수행.\n\n다음으로, 구성 및 용량을 사용하여 드라이버를 생성한 후 `calculateWithLambdaTest()` 함수를 사용하여 LambdaTest 그리드를 사용하여 계산을 수행했습니다.\n\n<div class=\"content-ad\"></div>\n\n함수 내에서 위의 구성을 사용하여 드라이버의 인스턴스를 생성합니다.\n\n![image](/assets/img/2024-06-20-NodeJSUnitTestingTutorialAComprehensiveGuide_6.png)\n\n다음으로 `driver.get()` 함수를 사용하여 계산기가 있는 웹페이지를 엽니다.\n\n![image](/assets/img/2024-06-20-NodeJSUnitTestingTutorialAComprehensiveGuide_7.png)\n\n<div class=\"content-ad\"></div>\n\n마지막으로 Selenium `findElement` 함수를 사용하여 페이지에서 요소를 찾습니다.\n\n![이미지](/assets/img/2024-06-20-NodeJSUnitTestingTutorialAComprehensiveGuide_8.png)\n\n아래 이미지는 HTML 페이지의 모든 요소의 전체 XPath를 검색하는 방법을 보여줍니다. 요소의 HTML 태그를 마우스 오른쪽 단추로 클릭하고 copy full XPath 또는 Copy XPath를 클릭하여 복사할 수 있습니다.\n\n![이미지](/assets/img/2024-06-20-NodeJSUnitTestingTutorialAComprehensiveGuide_9.png)\n\n<div class=\"content-ad\"></div>\n\n또한 calculateWithLambdaTest 함수 내부에서는 findElement 함수를 사용하여 가져온 input 요소에 숫자 입력을 전달하는 데 sendKeys() 함수를 사용했습니다.\n\n아래 이미지를 참조하세요:\n\n![image](/assets/img/2024-06-20-NodeJSUnitTestingTutorialAComprehensiveGuide_10.png)\n\n마지막으로 form을 제출하고 계산을 수행하기 위해 click() 함수를 사용했습니다. 계산 결과를 얻기 위해 findElement(By.id('addmessage'))를 사용하여 결과를 검색하고 getText() 함수를 사용하여 결과 요소의 텍스트 값을 가져옵니다. Selenium에서 요소의 텍스트를 가져오는 방법에 대해 더 알고 싶다면 이 블로그를 참조해보세요.\n\n## Express를 사용하여 Node 서버 생성\n\n<div class=\"content-ad\"></div>\n\n간단한 Node.js 서버 Express를 만들어 Mocha 프레임워크를 사용하기 전에 수동으로 구현을 테스트해 봅니다.\n\n먼저 아래 명령어를 사용하여 ExpressJS를 설치해 주세요:\n\n```js\nnpm install express\n```\n\n위 명령어의 결과는 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-NodeJSUnitTestingTutorialAComprehensiveGuide_11.png\" />\n\n루트 디렉토리에 `app.js`라는 파일을 만들고 아래 스니펫을 `app.js` 파일에 붙여넣으세요:\n\n```js\nconst express = require('express');\n\nconst Calculator = require('./calculate');\nconst app = express();\nconst port = 3002;\n\napp.use(express.json());\napp.use(express.urlencoded({ extended: false }));\n\n\napp.get('/calculate', async (request, response) => {\ntry {\nconst num1 = request.query?.num1 ?? 4;\nconst num2 = request.query?.num2 ?? 6;\nconst data = await Calculator.calculate(num1, num2);\nconsole.log(num1, num2, data);\nresponse.status(200).json(data);\n} catch (error) {\nresponse.status(500).json({\nmessage: '서버 오류가 발생했습니다',\n});\n}\n});\n\napp.listen(port, () => {\nconsole.log('예시 앱이 http://localhost:${port}에서 수신 대기 중입니다');\n});\n```\n\n이 NodeJS 테스트 튜토리얼의 다음 섹션에서는 Mocha 및 Node.js를 사용하여 Node.js 애플리케이션을 테스트하는 방법을 살펴볼 것입니다. 그러나 프로젝트를 수동으로 테스트하면 입력값에 따라 결과가 나타날 것입니다.\n\n<div class=\"content-ad\"></div>\n\n## Mocha를 이용한 NodeJS 단위 테스트하는 방법\n\nNode 애플리케이션을 위해 테스트 디렉토리에 파일을 생성하고 `tests/chai-calculate.spec.js` 파일을 만들어서 다음 코드 스니펫을 추가하세요. 아래는 코드 스니펫입니다:\n\n```js\nconst chai = require('chai').expect;\nconst request = require('request');\nlet url;\n\nbeforeEach(async () => {\n    url = 'http://localhost:3002/calculate';\n});\n\ndescribe('Calculate', () => {\n\n    it('두 값의 합을 계산합니다', async () => {\n        request(url, function (error, response, body) {\n            expect(response.statusCode).to.equal(200);\n            expect(body[0]).to.equal(9);\n            done();\n        });\n    });\n\n    it('잘못된 두 값의 합을 계산합니다', async () => {\n        request(url + '?num1=5&num2=6', function (error, response, body) {\n            expect(response.statusCode).to.equal(200);\n            expect(body[0]).to.not.equal(9);\n            done();\n        });\n\n    });\n\n});\n```\n\n마지막으로, 다른 모든 테스트 케이스를 Describe 블록 안에 포함시켰습니다. 각 테스트 케이스는 특정 동작이나 기능 구현을 테스트합니다.\n\n<div class=\"content-ad\"></div>\n\n# 테스트 실행하기\n\n테스트를 실행하려면 루트 터미널에 다음 명령을 입력하십시오.\n\n```js\nyarn start\n\nyarn test\n```\n\n테스트를 성공적으로 실행한 후에는 아래 스크린샷과 같이 테스트에 대한 녹색 통과 메시지를 확인할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-06-20-NodeJSUnitTestingTutorialAComprehensiveGuide_12.png)\n\n지금까지는 테스트가 통과하는지 확인하기 위해 위 명령을 수동으로 실행했습니다. 이제 앞으로 전개해 나가기 전에 배포하기 전에 테스트가 통과하는지 확인해야 합니다.\n\nLambdaTest Grid를 사용하여 이 프로세스를 자동화할 수도 있습니다. 이를 통해 배포 프로세스 중에 테스트 전략을 실행할 수 있습니다.\n\n이 자격증은 자바스크립트 개발자로서 자동화 테스트 분야에서 성공을 위해 필요한 포괄적인 지식과 필수 기술을 제공하여, 어떤 자바스크립트 자동화 역할에서도 뛰어날 수 있도록 돕습니다.\n\n<div class=\"content-ad\"></div>\n\n소프트웨어 테스트는 소프트웨어 개발 중이나 이후에 소프트웨어가 요구 사항과 일치하는지 확인하는 방법입니다. 버그를 줄이고 결함이 있는 소프트웨어 제품을 배포하는 데 매우 중요한 소프트웨어 엔지니어링 측면입니다.\n\nMocha는 Chai와 결합하여 BDD 또는 TDD 접근 방식을 사용하여 NodeJS 단위 테스트를 수행하는 강력한 도구입니다. 테스트를 간단하고 유연하게 만드는 유연한 자바스크립트 테스트 프레임워크입니다.\n\n이 NodeJS 단위 테스트에서는 Mocha와 Chai를 사용하여 NodeJS 단위 테스트를 수행하는 방법을 탐색했습니다.\n\n원문은 https://www.lambdatest.com에서 확인하실 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-20-NodeJSUnitTestingTutorialAComprehensiveGuide_0.png"},"coverImage":"/assets/img/2024-06-20-NodeJSUnitTestingTutorialAComprehensiveGuide_0.png","tag":["Tech"],"readingTime":12},{"title":"Nodejs는 빠르다고 하면 어떻게 생각하시나요","description":"","date":"2024-06-20 01:36","slug":"2024-06-20-WhatdoyouthinkwhenIsayNodejsisfast","content":"\n\n<img src=\"/assets/img/2024-06-20-WhenYouHearNodejsIsFast_0.png\" />\n\n만약 Node.js 개발자에게 플랫폼에 대한 좋은 점에 대해 물어보면 \"Node.js가 빠르다\"고 들을 확률이 높습니다. 왜 빠른지 묻는다면 JavaScript가 빠르거나 비동기성, 싱글 스레드, 또는 V8 엔진 때문이라고 들을 수도 있습니다...\n\n이러한 모든 이유들은 어떤 면에서는 타당할 수 있습니다. 어떻게 작동하든 Node.js의 메커니즘은 궁극적으로 처리 능력을 높이기 위해 노력합니다. 하지만 이러한 기능을 구현하는 것은 Node.js뿐만이 아니며, 많은 다른 언어나 플랫폼에서도 구현되어 있고 때로는 더 나은 방식으로 구현되어 있을 수도 있습니다.\n\n따라서, Node.js는 정말로 얼마나 빠를까요? 이 글에서는 \"Node.js가 빠르다\"라는 문제에 대한 내 견해를 제시하겠습니다.\n\n<div class=\"content-ad\"></div>\n\n하지만 먼저, 대부분의 사람들이 Node.js가 빠르다고 결론 내릴 때 자주 언급하는 메커니즘을 살펴보겠습니다.\n\n# Single Thread\n\nNode.js는 비동기 작업을 처리하기 위해 이벤트 루프를 통해 단일 스레드 모델을 사용합니다. 이를 통해 Node.js는 동시에 여러 요청을 쉽게 처리할 수 있습니다.\n\n이 개념을 이해하기 위해, PHP와 같이 단일 스레드 모델을 따르지 않는 언어를 생각해보십시오. 각 연결에 대해 PHP는 처리하기 위한 스레드를 생성합니다. 명백하게, 서버는 생성된 각 스레드에 대해 CPU 및 메모리와 같은 자원을 할당해야 합니다. 이제 여러 요청이 전송될 때 무슨 일이 발생하는지 상상해보세요.\n\n<div class=\"content-ad\"></div>\n\n이 모델은 Node.js에 일부 이점을 제공합니다. 리소스 소비를 최소화하기 위해 스레드 수를 줄이면서도 많은 수의 동시 요청을 처리할 수 있습니다.\n\n# 비동기 I/O\n\n웹 응용 프로그램이 데이터베이스와 상호 작용할 필요가 없는 경우는 거의 없습니다. 데이터베이스에 연결하고 쿼리하는 데는 일반 명령보다 더 많은 시간이 걸린다는 것을 우리는 다 알고 있습니다. 예를 들어 API 엔드포인트가 2초가 소요되는 쿼리를 수행해 결과를 반환해야 한다고 가정해 봅시다. Node의 단일 스레드 모델에서 두 번째 요청은 처리되기까지 적어도 2초를 기다려야 할까요? 세 번째, 네 번째... 요청은 어떨까요? 이로 인해 지연 시간이 기하급수적으로 증가하지 않을까요?\n\n걱정하지 마세요, 왜냐하면 Node.js의 강점 중 하나는 비동기 I/O를 처리할 수 있는 능력입니다. 특정 수의 요청을 거의 동시에 처리할 수 있습니다. 그러나 Node.js는 각 요청에 차례로 응답하며, 이 프로세스는 보통 매우 빠르게 진행됩니다. PHP에서는 스레드가 독립적이기 때문에 편안하게 결과를 동시에 반환할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# V8 Engine\n\nNode.js를 언급할 때 V8 엔진을 무시할 수 없어요. 이 도구는 JS 코드를 기계 코드로 번역하고 실행하는 JIT 컴파일러입니다. V8의 속도는 모든 JavaScript 엔진 중에서도 극도로 인상적입니다.\n\n그렇다면, Node.js는 정확히 얼마나 빠를까요?\n\nNode.js가 특히 API 시스템, 채팅과 같은 실시간 애플리케이션, 또는 많은 I/O를 필요로 하는 작업과 같은 특정 시나리오에 적합하다고 누군가 추천했다는 소문을 들었을 수 있어요. 하지만 Node.js의 처리 속도를 칭찬하는 글은 매우 드물죠.\n\n<div class=\"content-ad\"></div>\n\n성능은 많은 동시 요청을 처리할 때 모든 언어 또는 플랫폼에 대한 고민입니다. 각 언어는 특정 문제를 해결하기 위해 만들어졌습니다. 따라서 Node.js가 빠르다고 말하는 것은 정확하지 않습니다. 오히려 Node.js가 적절한 선택인 경우와 그 이유를 평가해야 합니다.\n\n그렇다고 해서 Node.js가 \"빠르지 않다\"는 것은 아닙니다. 다만, Node.js의 속도는 배포와 릴리스 속도에 있다고 생각합니다.\n\nNode는 JS 실행 환경을 제공하며, JS는 프로그래밍 언어 분야에서 매우 인기가 있습니다. 따라서 Node 커뮤니티는 크고, 프로젝트를 위한 개발 파트너를 빨리 찾을 수 있습니다. 또한, 이 개발을 통해 npm을 통해 Node를 위해 무수한 라이브러리가 구현되었습니다. 커뮤니티가 도와줄 것이기 때문에 바퀴를 다시 발명할 필요가 없습니다.\n\n결론적으로, 강력한 언어 또는 플랫폼을 결정하는 것은 개발자의 태도와 커뮤니티 내에서의 보급 범위입니다.\n\n<div class=\"content-ad\"></div>\n\n# 다른 언어나 플랫폼과의 Node.js 성능 비교\n\n만약 아직 Node.js가 \"빠르다\"고 믿지 못하신다면, [Techempower](https://www.techempower.com/benchmarks/#section=data-r21&test=plaintext)가 다양한 언어나 플랫폼의 성능을 서로 비교한 결과를 쉽게 확인할 수 있습니다. 공정성을 보장하기 위해 같은 환경에서 여러 언어나 플랫폼에 대해 여러 테스트를 실행하며 최신 버전의 언어나 플랫폼을 꾸준히 업데이트하고 재테스트합니다.\n\n2022년 7월 최근 측정 결과에 따르면, \"hello world\"과 같은 텍스트 응답 서버 테스트에 대해 Node.js와 [fastify](https://www.npmjs.com/package/fastify) 같은 인기 있는 프레임워크는 575,967 req/s의 처리량으로 156위에 랭크되었습니다. 이는 C#, Java 또는 Golang과 같은 언어로 구성된 다른 프레임워크들보다 훨씬 낮은 수치입니다. 특히, C#을 사용한 aspcore는 7백만 req/s 이상의 처리량을 달성할 수 있습니다.\n\n![2024-06-20-WhatdoyouthinkwhenIsayNodejsisfast_1.png](/assets/img/2024-06-20-WhatdoyouthinkwhenIsayNodejsisfast_1.png)\n\n<div class=\"content-ad\"></div>\n\n데이터베이스 쿼리 속도 테스트를 위해 fastify-mysql은 9,383 req/s를 처리할 수 있으나, 여전히 C#이 달성한 20,000 이상의 응답 속도에는 훨씬 못 미칩니다.\n\n더 많은 성능 테스트가 있습니다. 독자 여러분은 [프로젝트 정보 프레임워크 테스트 개요](https://github.com/TechEmpower/FrameworkBenchmarks/wiki/Project-Information-Framework-Tests-Overview)에서 Techempower의 벤치마크 기준과 함께 자세히 알아볼 수 있습니다.\n\n# 결론\n\n본 글에서는 “Node.js가 빠르다”고 말할 때 무슨 의미인지 밝히고자 합니다. 동시에 각 언어나 플랫폼에는 존재 이유가 있으며, 그들의 속도를 비교하는 것이 모든 강점을 반영하지는 않는다는 점을 강조하고자 합니다. 대신, 우리는 각각의 강점과 약점을 이해하고 문제에 적절히 적용해야 한다는 것을 이해해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n어떻게 생각하세요? Node.js가 정말 \"빠르다\"고 생각하시나요? 아래 댓글로 의겢을 나누어 주세요!","ogImage":{"url":"/assets/img/2024-06-20-WhatdoyouthinkwhenIsayNodejsisfast_0.png"},"coverImage":"/assets/img/2024-06-20-WhatdoyouthinkwhenIsayNodejsisfast_0.png","tag":["Tech"],"readingTime":4},{"title":"NextJS에서 Node Cron을 사용해 예약 작업 실행하기","description":"","date":"2024-06-20 01:35","slug":"2024-06-20-RunningaScheduledjobinNextJSwithNodeCron","content":"\n\n![2024-06-20-RunningaScheduledjobinNextJSwithNodeCron](/assets/img/2024-06-20-RunningaScheduledjobinNextJSwithNodeCron_0.png)\n\nNext.js에서 Cron 작업을 소개합니다. Vercel Cron과 같은 외부 서비스를 의존하지 않고 Next.js 프레임워크 내에서 예약된 작업을 통합하는 주제입니다. Cron 작업은 데이터 가져오기, 이메일 알림, 또는 웹 애플리케이션에서 시스템 유지보수와 같은 반복적인 작업을 자동화하는 데 중요한 역할을 합니다. Vercel은 내장된 cron과 유사한 기능을 제공하지만 Next.js 내에서 cron 작업을 직접 구현하는 방법을 이해하면 애플리케이션의 예약된 작업에 더 많은 유연성과 제어를 제공할 수 있습니다. 이 블로그 포스트에서는 cron 작업의 기본 원리를 살펴보고 Node.js를 사용하여 Next.js 프로젝트에 이를 원활하게 통합하는 방법을 보여드리겠습니다. 함께 알아보겠습니다!\n\n**단계 1**\n\n필요한 패키지를 설치하세요.\n\n<div class=\"content-ad\"></div>\n\n```js\nnpm i node-cron\n```\n\n단계 2\n\n서버.js 설정\n\n```js\nconst express = require('express');\nconst next = require('next');\nconst axios = require('axios');\n\nconst dev = process.env.NODE_ENV !== 'production';\nconst app = next({ dev });\nconst handle = app.getRequestHandler();\n\n//\nconst http = require('http');\nconst socketIO = require('socket.io');\n//\n\napp.prepare().then(async () => {\n    const server = express();\n    const httpServer = http.createServer(server);\n\n    // 스케줄러\n    const runScheduler = async () => {\n        try {\n            const response = await axios.post(`${당신의_기본_URL}/api/services/scheduler`,\n                {\n                    headers: {\n                        \"Content-Type\": \"application/json\"\n                    }\n                }\n            )\n        } catch (error) {\n            console.log(error)\n        }\n    }\n\n    server.all('*', (req, res) => {\n        return handle(req, res);\n    });\n\n    const PORT = process.env.PORT || 3000;\n    httpServer.listen(PORT, () => {\n        console.log(`서버가 http://localhost:${PORT}에서 실행 중입니다.`);\n\n        runScheduler();\n    });\n});\n```\n\n<div class=\"content-ad\"></div>\n\n스텝 3\n\n'api/services/scheduler' 경로에 라우트를 생성하세요.\n\n```js\nimport { NextResponse } from \"next/server\";\n\nvar cron = require('node-cron');\n\nexport async function POST(req, res) {\n\n    try {\n\n        cron.schedule('*/20 * * * *', async () => {\n\n            console.log('')\n            console.log('######################################')\n            console.log('#                                    #')\n            console.log('# 매 20분마다 스케줄러 실행됨              #')\n            console.log('#                                    #')\n            console.log('######################################')\n            console.log('')\n\n            // 여기에서 작업을 수행하세요\n        });\n\n        return NextResponse.json({ data: '성공', status: 200 });\n\n    } catch (error) {\n        console.log(error)\n        return NextResponse.json({ error: error }, { status: 500 })\n    }\n\n}\n```\n\n- 크론 타이밍은 Crontab.guru를 통해 설정할 수 있습니다. — 크론 스케줄 표현식 생성기\n\n<div class=\"content-ad\"></div>\n\nNext.js에서 cron 작업을 구현하는 것을 살펴봐 주셔서 감사합니다. 이 가이드가 Next.js 애플리케이션에서 예약 작업을 활용하는 데 유용한 통찰을 제공했기를 바랍니다. 궁금한 점이 있거나 도전에 직면하거나 단순히 생각을 공유하고 싶다면 망설이지 말고 연락해 주세요. 귀하의 피드백은 저희에게 매우 소중합니다. 귀하와 같은 개발자들을 위해 콘텐츠를 만들어 가는 데 큰 영감을 받습니다. 즐거운 코딩하세요!\n\n참고 자료\n\n- node-cron — npm (npmjs.com)","ogImage":{"url":"/assets/img/2024-06-20-RunningaScheduledjobinNextJSwithNodeCron_0.png"},"coverImage":"/assets/img/2024-06-20-RunningaScheduledjobinNextJSwithNodeCron_0.png","tag":["Tech"],"readingTime":3}],"page":"46","totalPageCount":154,"totalPageGroupCount":8,"lastPageGroup":20,"currentPageGroup":2},"__N_SSG":true}