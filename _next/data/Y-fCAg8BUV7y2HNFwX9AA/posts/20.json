{"pageProps":{"posts":[{"title":"파이썬으로 모멘텀 전략 구현하는 방법","description":"","date":"2024-06-22 05:44","slug":"2024-06-22-MomentumStrategyusingPython","content":"\n\n이번 주에는 점심 시간에 몇몇 동료들과 흥미로운 대화를 나누었습니다. 그들은 투자에 어떤 방법론을 사용하는지 물어보았어요. 저는 '모멘텀 투자'를 사용한다고 언급했는데, 그들은 정확히 무슨 의미인지 이해하기 어려워했어요. 그래서 이 기사를 쓰기로 결심했습니다. 제가 모멘텀 투자를 위해 따르는 단계를 설명하겠습니다.\n\n# 모멘텀 투자란?\n\n모멘텀 투자는 시장에서 이미 존재하는 추세를 기반으로 이익을 얻고자 하는 강력한 전략입니다. 지난 성과가 우수한 주식에 집중함으로써, 투자자들은 모멘텀의 흐름을 타고 인상적인 수익을 얻을 수 있을지도 모릅니다. 이 기사에서는 Nifty 50 주식을 위한 모멘텀 전략에 대해 자세히 살펴보고, 그 방법론을 설명하며 해당 전략을 구현하는 데 도움이 되는 Python 코드 조각을 제공할 것입니다.\n\n모멘텀 투자는 과거에 우수한 성과를 보인 주식이 가까운 미래에도 계속 우수한 성과를 내리라는 전제에 기반합니다. 이 전략은 특정 기간 동안(예: 지난 1년) 우수한 성과를 보인 주식을 매수하고, 일정 기간(예: 1개월) 보유한 후 포트폴리오를 재평가하는 것을 포함합니다.\n\n<div class=\"content-ad\"></div>\n\n# 전략 개요\n\n우리의 모멘텀 전략은 다음과 같은 간단한 단계로 구성되어 있습니다:\n\n- 주식의 우주 선택: 여기서는 Nifty 50 주식에 초점을 맞출 것입니다.\n- 과거 수익률 계산: 각 주식에 대해 12개월 수익률을 계산합니다.\n- 주식 순위 매기기: 주식을 12개월 수익률에 기반하여 순위 매깁니다.\n- 최고 주식 선택: 수익률이 가장 높은 상위 10개 주식을 선택합니다.\n- 매월 리밸런싱: 매달 포트폴리오를 재평가하고 리밸런싱합니다.\n\n# 전략 백테스팅\n\n<div class=\"content-ad\"></div>\n\n백테스팅은 거래 전략의 성과를 평가하는 데 중요합니다. 이전 데이터에 전략을 적용하여 과거 성과를 평가하고 잠재적인 미래 성과에 대한 통찰력을 얻을 수 있습니다.\n\n파이썬을 사용하여 이 전략을 3년 동안 백테스트하고 해당 결과를 지수(여기서는 Nifty50)의 매수 및 보유 전략과 비교해보겠습니다.\n\n## 단계 1: 데이터 수집\n\n먼저, 지난 3년간 Nifty 50 주식의 히스토리컬 가격 데이터를 수집해야 합니다. 여기서는 야후 파이낸스 API를 사용하여 지난 3년간의 히스토리컬 데이터를 가져왔습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nimport yfinance as yf\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\n\n# Nifty 50 주식 기호 목록\nnifty50_symbols = [\"RELIANCE.NS\", \"HDFCBANK.NS\", \"INFY.NS\", \"ICICIBANK.NS\", \"TCS.NS\", \"KOTAKBANK.NS\", \n                   \"HINDUNILVR.NS\", \"SBIN.NS\", \"BHARTIARTL.NS\", \"HDFC.NS\", \"ITC.NS\", \"BAJFINANCE.NS\", \n                   \"ASIANPAINT.NS\", \"HCLTECH.NS\", \"LT.NS\", \"MARUTI.NS\", \"AXISBANK.NS\", \"ULTRACEMCO.NS\", \n                   \"WIPRO.NS\", \"NESTLEIND.NS\", \"ONGC.NS\", \"TITAN.NS\", \"SUNPHARMA.NS\", \"M&M.NS\", \n                   \"POWERGRID.NS\", \"JSWSTEEL.NS\", \"TATASTEEL.NS\", \"TECHM.NS\", \"HDFCLIFE.NS\", \"COALINDIA.NS\", \n                   \"BPCL.NS\", \"INDUSINDBK.NS\", \"BAJAJ-AUTO.NS\", \"IOC.NS\", \"BRITANNIA.NS\", \"HEROMOTOCO.NS\", \n                   \"ADANIPORTS.NS\", \"DRREDDY.NS\", \"GRASIM.NS\", \"CIPLA.NS\", \"DIVISLAB.NS\", \"EICHERMOT.NS\", \n                   \"BAJAJFINSV.NS\", \"SHREECEM.NS\", \"TATAMOTORS.NS\", \"SBILIFE.NS\", \"ADANIENT.NS\", \n                   \"DABUR.NS\", \"VEDL.NS\", \"APOLLOHOSP.NS\"]\n\n# 시간 범위 정의\nend_date = datetime.today()\nstart_date = end_date - timedelta(days=365*3)  # 최근 3년간\n\n# 데이터 가져오기\ndata = yf.download(nifty50_symbols, start=start_date, end=end_date)['Adj Close']\n\n# 누락된 값 채우기\ndata = data.fillna(method='ffill').dropna()\n\n# 데이터의 처음 몇 행 표시\nprint(data.head())\n```\n\n## 단계 2: 전략 구현 및 수익률 계산\n\n그다음, 모멘텀 전략을 구현하고 지난 3년간 포트폴리오 수익률을 계산합니다.\n\n```js\ndef calculate_portfolio_returns(data, top_n=10):\n    # 월간 수익률 계산\n    monthly_returns = data.resample('M').ffill().pct_change()\n    \n    # 12개월 수익률 계산\n    twelve_month_returns = monthly_returns.rolling(window=12).apply(lambda x: np.prod(1 + x) - 1, raw=True)\n    \n    # 월별 포트폴리오 가치를 저장할 빈 목록 초기화\n    portfolio_values = []\n    \n    # 초기 자본 부여\n    initial_capital = 100000  # 1 lakh\n    capital = initial_capital\n    \n    # 13번째 달부터 시작하여 각 월 반복\n    for i in range(12, len(twelve_month_returns)):\n        # 현재 달의 12개월 수익률 가져오기\n        current_returns = twelve_month_returns.iloc[i]\n        \n        # 주식을 12개월 수익률에 따라 순위 매기기\n        ranked_stocks = current_returns.sort_values(ascending=False)\n        \n        # 상위 N개 주식 선택\n        top_stocks = ranked_stocks.head(top_n).index\n        \n        # 각 주식에 대한 동일 가중치 계산\n        weight = 1 / top_n\n        \n        # 현재 달의 포트폴리오 수익률 계산\n        portfolio_return = (monthly_returns.iloc[i][top_stocks] * weight).sum()\n        \n        # 자본 업데이트\n        capital = capital * (1 + portfolio_return)\n        \n        # 현재 자본을 포트폴리오 가치 목록에 추가\n        portfolio_values.append(capital)\n    \n    # 포트폴리오 가치 목록을 pandas Series로 변환\n    portfolio_values = pd.Series(portfolio_values, index=twelve_month_returns.index[12:])\n    \n    return portfolio_values\n\n# 포트폴리오 수익률 계산\nmomentum_portfolio_returns = calculate_portfolio_returns(data)\n\n# 포트폴리오 수익률 표시\nprint(momentum_portfolio_returns)\n```\n\n<div class=\"content-ad\"></div>\n\n## 단계 3: Nifty 50 지수와 비교\n\n모멘텀 전략의 성능을 평가하기 위해 해당 전략의 수익률을 동일 기간 동안 Nifty 50 지수의 수익률과 비교합니다.\n\n```js\n# Nifty 50 지수 데이터 가져오기\nnifty50_index = yf.download(\"^NSEI\", start=start_date, end=end_date)['Adj Close']\n\n# Nifty 50 월간 수익률 계산하기\nnifty50_monthly_returns = nifty50_index.resample('ME').ffill().pct_change()\n\n# Nifty 50 누적 수익률 계산하기\nnifty50_cumulative_returns = (1 + nifty50_monthly_returns).cumprod()\n\n# 모멘텀 포트폴리오 누적 수익률 계산하기\nmomentum_cumulative_returns = (1 + momentum_portfolio_returns.pct_change()).cumprod()\n\n# 결과 그래프로 플로팅하기\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 6))\nplt.plot(momentum_cumulative_returns, label='모멘텀 포트폴리오')\nplt.plot(nifty50_cumulative_returns, label='Nifty 50 지수', linestyle='--')\nplt.title('모멘텀 포트폴리오 vs Nifty 50 지수')\nplt.xlabel('날짜')\nplt.ylabel('누적 수익률')\nplt.legend()\nplt.grid(True)\nplt.show()\n```\n\n<img src=\"/assets/img/2024-06-22-MomentumStrategyusingPython_0.png\" />\n\n<div class=\"content-ad\"></div>\n\n# 결과 및 분석\n\n위의 그림은 지난 3년간 모멘텀 포트폴리오의 누적 수익률을 Nifty 50 지수와 비교한 것입니다. 다음은 주요 관측 사항입니다:\n\n- 이 기간 동안 모멘텀 포트폴리오가 일반적으로 Nifty 50 지수를 능가하여 모멘텀 전략의 효과를 입증했습니다.\n- 모멘텀 포트폴리오가 상당한 변동을 겪는 등의 변동성이 있었는데, 이는 모멘텀 기반 전략에 특징적인 것입니다.\n- 전반적으로, 모멘텀 전략은 Nifty 50 지수를 단순 보유하는 것보다 더 높은 투자 수익을 제공했습니다.\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\n니프티 50 주식들에 대한 모멘텀 투자 전략은 지난 3년 동안 기대를 불러일으켰어요. 12개월 수익률에 기반한 상위 10개 주식을 선택하고 매월 포트폴리오를 리밸런싱 함으로써, 이 전략은 니프티 50 지수를 능가했어요. 하지만 과거 성과가 미래 성과를 반영한다는 점을 명심해야 하며, 투자자는 이 전략을 실행하기 전에 위험 허용 수준 및 투자 목표를 신중히 고려해야 해요.\n\n제공된 Python 코드 스니펫을 사용하여 이 모멘텀 전략을 백테스트하고 원하는 대로 사용자 정의할 수 있어요. 모멘텀 투자는 투자자의 무기로 강력할 수 있지만, 일관된 성공을 거두기 위해서는 규율과 체계적인 접근이 필요해요.","ogImage":{"url":"/assets/img/2024-06-22-MomentumStrategyusingPython_0.png"},"coverImage":"/assets/img/2024-06-22-MomentumStrategyusingPython_0.png","tag":["Tech"],"readingTime":6},{"title":"PostgreSQL 데이터베이스 변경 사항을 벡터 스토어로 스트리밍하는 방법","description":"","date":"2024-06-22 05:42","slug":"2024-06-22-StreamChangesfromaPostgreSQLDatabasetoaVectorStore","content":"\n\n## CDC (Change Data Capture)를 사용하여 벡터 저장소를 최신 상태로 유지하는 방법, Python 및 Redpanda\n\n![Image](/assets/img/2024-06-22-StreamChangesfromaPostgreSQLDatabasetoaVectorStore_0.png)\n\n벡터 데이터베이스와 의미론적 검색의 등장으로 많은 애플리케이션의 검색 결과 품질이 향상되었습니다. 그러나 전통적인 인덱스 유지 보수 문제는 여전히 존재합니다. \"검색 가능한 콘텐츠\"(제품 설명, 웹 페이지, 연구 논문 요약)가 지속적으로 업데이트될 때 사용자의 검색 경험을 방해하지 않고 검색 인덱스를 새로 고치는 방법은 무엇일까요? 많은 팀은 이 문제를 점진적 색인화로 해결합니다.\n\n예를 들어, DoorDash 엔지니어링 팀이 2021년에 점진적 색인화에 대해 쓴 글에서는 CDC와 Apache Kafka를 사용하여 색인을 점진적으로 업데이트하는 방법을 설명했습니다.\n\n<div class=\"content-ad\"></div>\n\n이 글에서는 일반적인 검색 인덱스보다 계산량이 많을 수 있는 벡터 데이터베이스로 동일한 작업을 수행하는 방법을 보여드리려고 합니다.\n\n# 점진적 인덱싱을 위한 지속적인 이벤트 기반 벡터 입력 사용하기\n\nCDC를 기반으로 한 인덱싱 파이프라인의 간소화된 버전을 살펴봅시다. 데이터베이스에 새 제품 항목이 추가되는 즉시, 변경 내용의 세부 정보와 함께 이벤트가 Redpanda(카프카와 유사한 메시지 브로커)로 전송됩니다. 소비자 프로세스는 이벤트가 도착하는 즉시 이를 임베딩 모델에 전달합니다. 임베딩이 생성되고 세부 정보가 관련 벡터로 보강됩니다. 이 데이터는 다른 Kafka 토픽으로 스트리밍되어 인계 처리 프로세스가 이를 소비하고 벡터 데이터베이스가 처리할 수 있는 속도에 맞춰 벡터를 업서트합니다.\n\n저는 여러분이 직접 복제할 수 있는 프로토타입 애플리케이션을 작성했습니다. 메시지 브로커로 Redpanda의 로컬 설치를 사용합니다. 파이프라인의 각 단계는 각각의 Docker 컨테이너에서 실행되며, 각 컨테이너는 Quix Streams의 인스턴스를 실행합니다. Quix Streams는 Kafka 프로듀서/컨슈머(예: kafka-python)와 강력한 스트림 처리 라이브러리(예: Faust)인 오픈소스 파이썬 라이브러리입니다.\n\n<div class=\"content-ad\"></div>\n\n아래 다이어그램은 파이프라인의 구성 요소를 보여줍니다.\n\n![다이어그램](/assets/img/2024-06-22-StreamChangesfromaPostgreSQLDatabasetoaVectorStore_1.png)\n\n이 파이프라인은 Qdrant(벡터 저장소)와 PostgreSQL(소스 데이터베이스)의 로컬 인스턴스를 사용하며, Redpanda의 토픽을 통해 Quix Streams를 사용하여 변경 사항을 스트리밍합니다.\n\n이 프로토타입의 전체 코드는 동봉된 GitHub 저장소에서 확인할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 준비물\n\n- 파이프라인을 시도하려면 도커가 설치되어 있어야 합니다. 이를 설치하는 가장 간단한 방법은 Linux, Windows 또는 Mac에 Docker Desktop Docker를 설치하는 것입니다.\n- 또한 Git도 필요합니다. 이미 Git이 없다면 Git 웹 사이트에서 다운로드할 수 있습니다.\n\n먼저, 파이프라인을 실행하고 데이터를 입력하고 검색에 미치는 영향을 관찰하는 방법을 안내해 드리겠습니다. 그 후에는 파이프라인을 구동하는 코드를 안내해 드리겠습니다.\n\n# 코드 가져오기\n\n<div class=\"content-ad\"></div>\n\n터미널에서 다음 Git 명령을 실행하여 코드를 가져올 수 있어요.\n\n```js\ngit clone https://github.com/quixio/template-vector-cdc-local\n```\n\n그런 다음, Docker Compose를 실행하세요:\n\n```js\ndocker compose up -d\n```\n\n<div class=\"content-ad\"></div>\n\n이 명령은 8080, 8082 및 5050 포트를 필요로 하는 여러 서비스를 시작합니다. 해당 포트에서 실행 중인 애플리케이션이 있으면 먼저 중지해야 합니다.\n\n콘솔에 다음 예제와 유사한 출력이 표시됩니다:\n\n```js\n[+] Running 10/10\n ✔ Network template-vector-cdc-local_default               Created                                                 0.0s\n ✔ Container template-vector-cdc-local-console-1           Started                                                 0.1s\n ✔ Container template-vector-cdc-local-redpanda-1          Started                                                 0.1s\n ✔ Container postgresdb                                    Started                                                 0.1s\n ✔ Container qdrant                                        Started                                                 0.1s\n ✔ Container create_embeddings                             Started                                                 0.0s\n ✔ Container template-vector-cdc-local-postgresql_cdc-1    Started                                                 0.0s\n ✔ Container streamlit_search                              Started                                                 0.0s\n ✔ Container template-vector-cdc-local-postgresql_admin-1  Started                                                 0.0s\n ✔ Container ingest_to_qdrant                              Started                                                 0.0s\n```\n\n# 데이터베이스 설정\n\n<div class=\"content-ad\"></div>\n\n먼저, 기본 테스트 데이터벤스에 테이블을 생성하고 일부 데이터를 추가하겠습니다.\n\n전자 상거래에 중점을 두고 있으므로 온라인 서점을 운영하고 있으며 도서 카탈로그를 지속적으로 업데이트하고 있습니다. 새로운 책이 추가될 때마다 최신 책 설명에 대한 임베딩이 있는 벡터 저장소를 확인해야 합니다.\n\n여기서 책 카탈로그 업데이트를 시뮬레이션하기 위해 pgAdmin을 사용하여 쿼리를 실행할 것입니다. 이는 PimCore와 같은 \"실제\" PIM(Product Information Management) 시스템을 대신하는 역할을 할 것입니다.\n\n먼저, demo PostgreSQL DB에 pgAdmin을 연결해 보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n## pgAdmin에 로그인하기\n\n- 브라우저에서 http://localhost:5050으로 접속하여 pgAdmin UI를 엽니다.\n- 사용자 이름 \"admin@admin.com\"과 비밀번호 \"root\"로 pgAdmin에 로그인합니다.\n\n## PostgreSQL 데이터베이스에 대한 연결 구성\n\n- `Servers`를 클릭하고 `Register` 서버를 선택합니다.\n\n<div class=\"content-ad\"></div>\n\n![이미지](/assets/img/2024-06-22-StreamChangesfromaPostgreSQLDatabasetoaVectorStore_2.png)\n\n- 나타나는 대화 상자에서 \"일반\" 탭에 이름을 입력한 후, 호스트를 \"postgresdb\"로 설정하고 \"root\"를 사용자 이름과 암호로 설정하고 저장을 클릭하세요.\n\n![이미지](/assets/img/2024-06-22-StreamChangesfromaPostgreSQLDatabasetoaVectorStore_3.png)\n\n# 데이터 추가\n\n<div class=\"content-ad\"></div>\n\n저희 데모 Postgresql 데이터베이스에는 “books” 테이블이 미리 구성되어 있어서 데이터를 추가하기만 하면 됩니다.\n\n- 서버 ' postgresdb ' 데이터베이스로 이동하여 test_db를 마우스 오른쪽 버튼으로 클릭하고 '쿼리 도구'를 선택합니다.\n\n![이미지](/assets/img/2024-06-22-StreamChangesfromaPostgreSQLDatabasetoaVectorStore_4.png)\n\n- 나타나는 쿼리 도구에 다음 쿼리를 붙여넣고 실행하여 첫 번째 일괄 Sci-fi 책을 추가합니다:\n\n<div class=\"content-ad\"></div>\n\n```js\nINSERT INTO books (name, description, author, year) VALUES\n('The Time Machine', 'A man travels through time and witnesses the evolution of humanity.', 'H.G. Wells', 1895),\n('Brave New World', 'A dystopian society where people are genetically engineered and conditioned to conform to a strict social hierarchy.', 'Aldous Huxley', 1932),\n('An Absolutely Remarkable Thing', 'A young woman becomes famous after discovering a mysterious alien artifact in New York City.', 'Hank Green', 2018),\n('Dune', 'A desert planet is the site of political intrigue and power struggles.', 'Frank Herbert', 1965),\n('Foundation', 'A mathematician develops a science to predict the future of humanity and works to save civilization from collapse.', 'Isaac Asimov', 1951),\n('Snow Crash', 'A futuristic world where the internet has evolved into a virtual reality metaverse.', 'Neal Stephenson', 1992),\n('The War of the Worlds', 'A Martian invasion of Earth throws humanity into chaos.', 'H.G. Wells', 1898),\n('The Hunger Games', 'A dystopian society where teenagers are forced to fight to the death in a televised spectacle.', 'Suzanne Collins', 2008);\r\n```\n\n위 내용대로 변경하면 자동으로 채택되고 데이터는 파이프라인을 통해 전송됩니다.\n\n로컬 Redpanda 인스턴스에서 Redpanda 콘솔로 확인할 수 있습니다: http://localhost:8080/overview\n\nTopics로 이동하여 `postgres-cdc-data`를 확인하세요.\n\n<div class=\"content-ad\"></div>\n\n“OFFSET” 드롭다운에서 “Newest”를 선택하면 메시지가 들어오기 시작해야 해요:\n\n<img src=\"/assets/img/2024-06-22-StreamChangesfromaPostgreSQLDatabasetoaVectorStore_5.png\" />\n\n이제 벡터가 제대로 소화되었는지 확인해봐요.\n\n# Streamlit Vector Search UI 사용하기\n\n<div class=\"content-ad\"></div>\n\n데모 애플리케이션에는 벡터 검색을 테스트할 수 있는 간단한 검색 UI(스트림릿으로 구축됨)가 포함되어 있어요.\n\n다음 URL을 통해 액세스할 수 있어요: http:// localhost:8082\n\n검색 UI에서 \"battle in space\"를 검색해보세요 — 최상위 결과는 \"The War of the Worlds\"여야 해요. 지금은 지구에서 벌어지는 전투에 관한 책이지만, 우리 도서 카탈로그에서 현재 최고의 배치로 보여요.\n\n![이미지](/assets/img/2024-06-22-StreamChangesfromaPostgreSQLDatabasetoaVectorStore_6.png)\n\n<div class=\"content-ad\"></div>\n\n우리는 \"화성\"이 \"우주\"와 의미적으로 가깝고 \"침공\"이 \"전투\"와 의미적으로 가깝기 때문에 상위 결과와 일치했을 가능성이 있다고 추측할 수 있습니다. 그러나 문장 임베딩 모델 같이 더 정교한 모델을 사용하면 결과가 다를 수 있습니다. 그러나 그 모델은 꽤 무거운 라이브러리이기 때문에 이 프로토타입에서는 제외했습니다.\n\n이제 목록에 몇 권의 책을 추가하고 검색 결과를 개선할 차례입니다.\n\npgAdmin (http://localhost:5050/)로 돌아가서 다음 SQL 쿼리를 실행하세요.\n\n```js\nINSERT INTO books (name, description, author, year) VALUES\n('Childhood''s End', '평화로운 외계 침공으로 인해 인류의 어린 시절이 종말을 맞이한다.', '아서 C. 클라크', 1953),\n('The Day of the Triffids', '유성우로 대부분의 인구가 실명하면서 공격적인 식물이 지배를 시작한다.', '존 윈덤', 1951),\n('The Three-Body Problem', '인류가 위기의 먼 외계 문명으로부터 가능한 침공을 직면한다.', '류씬', 2008),\n('The Puppet Masters', '찐렁이 모양의 외계인이 지구를 침공하여 인간에 붙어 그들의 마음을 통제한다.', '로버트 A. 하인라인', 1951),\n('The Kraken Wakes', '해양 심층에서 나오는 외계 생명체가 인류를 공격하기 시작한다.', '존 윈덤', 1953),\n('The Invasion of the Body Snatchers', '작은 마을이 주민 중 일부가 식물과 같은 씨앗에서 나오는 완벽한 물리적 사본에 교체되는 것을 발견한다.', '잭 핀니', 1955),\n('Out of the Dark', '외계종족이 지구를 침공하여 인류의 생존 의지를 과소평가한다.', '데이비드 웨버', 2010),\n('Old Man''s War', '지구의 노인들이 별간 전쟁에 참전하게 되며 새로운 외계 문화와 위협을 발견한다.', '존 스캘지', 2005);\n```\n\n<div class=\"content-ad\"></div>\n\n만약 이것이 프로덕션 상황이었다면, 새로운 제목은 책 카탈로그에 등록될 수 있지만 벡터 DB에는 등록되지 않을 수 있어요. 이 때문에 재고 팀에게 정기적으로 책 카탈로그의 스냅샷을 내보내서 벡터 스토어로 가져와야 할지도 모를 거예요. 한편으로, \"우주 전투\"에 관한 책을 찾는 사용자들은 그냥 기다려야 할 수도 있어요. 이건 그냥 안돼요! 그럼 그들이 카탈로그에 등록되면 바로 제목을 찾을 수 있게 해주는게 어때요?\n\n첫 번째 단계에서 한 것과 이번에 두 번째 단계에서 다시 한 것입니다. 벡터 DB를 책 카탈로그와 실시간으로 동기화했어요.\n\n우리의 유사성 검색 결과에 이 업데이트가 어떤 영향을 미쳤는지 확인해보세요.\n\nStreamlit 검색 UI에서 다시 \"우주 전투\"를 검색해보세요 - 이제 상위 결과는 \"Old man's war\"가 될 거예요 - 더 적절한 매치겠죠.\n\n<div class=\"content-ad\"></div>\n\n\n\n![StreamChangesfromaPostgreSQLDatabasetoaVectorStore_7](/assets/img/2024-06-22-StreamChangesfromaPostgreSQLDatabasetoaVectorStore_7.png)\n\n\"The War of the Words\"이 상위 자리에서 밀려난 이유는 새로 추가된 용어가 의미론적으로 더 관련된 설명을 갖고 있기 때문이다: 설명에서 \"전쟁\"이라는 용어는 의미에서 \"전투\"에 더 가깝고, \"국제 우주\"는 \"화성\"보다 \"우주\"라는 검색어에 의미론적으로 더 가까워진다.\n\n# 하드웨어 하에서 작동하는 방식\n\n이제 이 프로토타입이 무엇을 하는지 이해했으니, 어떻게 작동하는지 살펴보겠습니다.\n\n\n<div class=\"content-ad\"></div>\n\n먼저, 아키텍처 다이어그램의 처리 부분에 초점을 맞춰 봅시다.\n\n![이미지](/assets/img/2024-06-22-StreamChangesfromaPostgreSQLDatabasetoaVectorStore_8.png)\n\n세 개의 서비스를 볼 수 있어요(메시지 브로커는 물론) — 각각은 작고 계속 실행 중인 파이썬 애플리케이션입니다: \"CDC\", \"임베딩 생성\", \"벡터 DB로 업서트\"\n\n각 애플리케이션은 데이터를 수신하고 처리한 후 Kafka 토픽으로 보내거나 어떠한 형태의 싱크에 쓰기 위해 Quix Streams 파이썬 라이브러리를 사용합니다.\n\n<div class=\"content-ad\"></div>\n\n각 응용 프로그램의 소스 코드를 함께 살펴봅시다.\n\n## CDC 구성\n\nCDC 프로세스 뒤의 코드로 들어가기 전에, 자체 PostgreSQL 데이터베이스에서 CDC를 수행하려면 몇 가지 추가 전제 조건을 언급하는 것이 좋습니다:\n\n1) Write Ahead Log를 논리적으로 설정해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n- \"SHOW wal_level;\" SQL 쿼리를 실행하여 현재 설정을 확인할 수 있어요.\n- 이미 \"logical\"로 설정이 되어 있지 않다면, postgresql.cong 파일을 업데이트하고 wal_level을 wal_level=logical로 설정해 주세요.\n\n2) PostgreSQL이 실행 중인 서버 또는 컨테이너에 wal2json 플러그인을 설치해야 해요.\n\n이 튜토리얼의 PostgreSQL 데이터베이스에는 이미 이러한 선행 조건이 준비되어 있어요. Debezium Source PostgreSQL Connector 대신 Quix Python CDC 커넥터를 사용합니다. 전체 CDC 코드 파일은 이 GitHub 폴더에서 찾을 수 있어요.\n\n## PostgreSQL 데이터베이스에 연결\n\n<div class=\"content-ad\"></div>\n\n포스트그레SQL 연결은 환경 변수를 통해 postgres_helper.py 파일에서 정의됩니다. 따라서, 여러분이 자신의 데이터베이스에 연결하고 싶다면, 관련 변수를 변경하기만 하면 됩니다.\n\n```js\nimport psycopg2\nimport os\n\ndef connect_postgres():\n    # PostgreSQL 상수\n    PG_HOST = os.environ[\"PG_HOST\"] # 기본값은 localhost\n    PG_PORT = os.environ[\"PG_PORT\"] # 기본값은 ??\n    PG_USER = os.environ[\"PG_USER\"] # 기본값은 ??\n    PG_PASSWORD = os.environ[\"PG_PASSWORD\"] # 기본값은 ??\n    PG_DATABASE = os.environ[\"PG_DATABASE\"] # 기본값은 ??\n    \n    conn = psycopg2.connect(\n        database=PG_DATABASE, user=PG_USER, password=PG_PASSWORD, host=PG_HOST, port=PG_PORT\n    )\n    return conn\n… \n```\n\n## 카프카로 변경 로그 항목 생성하기\n\n글을 간결하게 유지하기 위해서, 이 기사에서는 변경 데이터가 어떻게 캡처되는지에 대해 다루지 않겠습니다. 그러나 변경 사항을 캡처하는 데 write-ahead log가 어떻게 사용되는지에 대한 자세한 내용은 postgres_helper.py 파일을 확인해주세요.\n\n<div class=\"content-ad\"></div>\n\n여기서는 데이터의 구조와 Kafka로 생성되는 방법에 초점을 맞춰 봅시다.\n\n먼저, Kafka 프로듀서를 초기화합니다. 저희는 프로듀서로 Quix Streams Python 라이브러리를 사용합니다. 이 라이브러리는 Streaming Dataframes 개념을 사용하여 데이터를 처리하고 정적 데이터셋에 대해 작성된 Pandas 코드를 재사용하기 쉽게 만들어줍니다.\n\nQuix Streams를 사용하여 main.py에서 어플리케이션 및 초기 출력 토픽을 정의합니다:\n\n```js\nfrom quixstreams import Application\n...\napp = Application(broker_address=os.environ['BROKER_ADDRESS']) # Redpanda의 기본값은 'localhost:19092'입니다.\n... \noutput_topic = app.topic(output_topic_name) # 토픽 이름은 환경 변수에 정의되어 있으며, 기본값은 \"posgres-cdc-source\"입니다.\n```\n\n<div class=\"content-ad\"></div>\n\n그런 다음 최신 데이터베이스 변경 사항을 가져와 버퍼에 추가하고, 버퍼를 반복하여 결과를 출력 Kafka 주제로 전송하는 함수를 추가합니다.\n\n```js\n...\n# 네트워크 트래픽을 줄이기 위해 메시지를 100밀리초 동안 버퍼링합니다\ndef main():\n    buffer = []\n    last_flush_time = time.time()\n\n    while run:\n        records = get_changes(conn, PG_SLOT_NAME)\n        for record in records:\n            changes = json.loads(record[0])\n            for change in changes[\"change\"]:\n                buffer.append(change)\n                \n        # 100밀리초가 지났는지 확인\n        current_time = time.time()\n        if (current_time - last_flush_time) >= 0.5 and len(buffer) > 0:\n           # 500밀리초가 지났다면, 버퍼에 있는 모든 메시지 전송\n    with app.get_producer() as producer:\n            for message in buffer:\n                producer.produce(topic=output_topic.name,\n                                    key=PG_TABLE_NAME,\n                                    value=json.dumps(message))\n                print(\"Kafka로 메시지 전송 완료\")\n                # 생산자를 플러시하여 메시지 전송\n                \n            # 버퍼 비우기\n            buffer = []\n            # 마지막 플러시 시간 업데이트\n            last_flush_time = current_time\n        time.sleep(WAIT_INTERVAL) # main.py의 전역 변수로 정의된 대기 간격(현재 0.1초)\r\n```\n\n결과 payload는 다음 구조를 가지고 있습니다:\n\n```js\r\n{\n  \"kind\": \"insert\",\n  \"schema\": \"public\",\n  \"table\": \"books\",\n  \"columnnames\": [\n    \"id\",\n    \"name\",\n    \"description\",\n    \"author\",\n    \"year\"\n  ],\n  \"columntypes\": [\n    \"integer\",\n    \"character varying(255)\",\n    \"text\",\n    \"character varying(255)\",\n    \"integer\"\n  ],\n  \"columnvalues\": [\n    60,\n    \"Old Man's War\",\n    \"지구의 어르신들이 화성간 전쟁에 참전하게 되어, 새로운 외계 문화와 위협을 발견하게 되는 이야기입니다.\",\n    \"John Scalzi\",\n    2005\n  ]\n}\r\n```\n\n<div class=\"content-ad\"></div>\n\n나중에는 이 구조를 간단하게 만들어서 처리하기 쉽게 할 거예요.\n\n# 임베딩 생성\n\n이것이 우리가 \"변환\" 프로세스라고 부르는 것인데, 다른 말로 하면 두 개의 Kafka 토픽 사이에 위치하여 한 쪽에서 읽고 다른 쪽으로 쓰는 역할을 합니다. 전체 소스 코드 파일은 이 GitHub 폴더에 있습니다.\n\nQuix Streams 라이브러리는 변환을 구현하는 간단한 프로세스를 제공합니다. 다른 라이브러리와 달리 생산자와 소비자를 정의하는 대신, 관련 설정을 Application 생성자에 넣어주고 app 인스턴스를 통해 입력 및 출력 토픽을 정의합니다.\n\n<div class=\"content-ad\"></div>\n\n예시:\n\n```js\nfrom quixstreams import Application\n...\napp = Application(\n    broker_address=os.environ['BROKER_ADDRESS'],\n    consumer_group=\"vectorsv1\",\n    auto_offset_reset=\"earliest\",\n    auto_create_topics=True,  # Quix 앱은 아직 존재하지 않는 경우 주제를 자동으로 생성하는 옵션이 있습니다\n)\n\n# JSON 변환기를 사용하여 입력 및 출력 주제 정의\ninput_topic = app.topic(os.environ['input'], value_deserializer=\"json\")\noutput_topic = app.topic(os.environ['output'], value_serializer=\"json\")\n```\n\n아래에서는 app.dataframe 메서드를 사용하여 데이터를 생산하고 소비하는 방법을 볼 수 있지만 먼저 데이터에 적용할 함수를 정의합니다.\n\n첫 번째 함수는 변경 데이터 캡처 페이로드의 구조를 압축합니다.\n\n<div class=\"content-ad\"></div>\n\n```python\ndef simplify_data(row):\n\n    # 새로운 딕셔너리를 생성하여 'kind' 및 zips 열 이름과 값으로 구성\n    new_structure = {\"kind\": row[\"kind\"],\"table\": row[\"table\"]}\n    new_structure.update({key: value for key, value in zip(row[\"columnnames\"], row[\"columnvalues\"])})\n\n    # 선택적으로 정수를 문자열로 변환\n    new_structure[\"year\"] = str(new_structure[\"year\"])\n\n    return new_structure\n```\n\n다음과 같은 페이로드 구조를 얻게 됩니다:\n\n```python\n{\n \"kind\": \"insert\",\n \"table\": \"books\",\n \"id\": 60,\n \"name\": \"Old Man's War\",\n \"description\": \"Earth's senior citizens are recruited to fight in an interstellar war, discovering new alien cultures and threats.\",\n \"author\": \"John Scalzi\",\n \"year\": 2005\n}\n```\n\n두 번째 함수는 단순화된 페이로드의 \"description\" 필드에 대한 임베딩을 생성하기 위해 Qdrant의 FastEmbed 라이브러리를 사용합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\r\n# 기존 모델 다운로드 및 초기화가 트리거됩니다.\nembedding_model = TextEmbedding()\nprint(\"모델 BAAI/bge-small-en-v1.5을 사용할 준비가 되었습니다.\")\n\n...\n\n# 임베딩 함수 정의\ndef create_embeddings(row):\n    text = row['description']\n    embeddings = list(embedding_model.embed([text]))\n    embedding_list = [embedding.tolist() for embedding in embeddings]\n    finalembedding = embedding_list[0]\n    print(f'벡터 생성됨: \"{finalembedding}\"')\n\n    return finalembedding\r\n```\n\n마지막으로 데이터를 소비하고 함수를 적용하여 데이터를 downstream Kafka 주제로 생성합니다.\n\n```js\r\n# 입력 주제의 메시지 스트림을 기반으로 스트리밍 데이터프레임 초기화:\nsdf = app.dataframe(topic=input_topic)\n\nsdf = sdf.filter(lambda data: data[\"table\"] == targettable) # \"books\" 테이블의 변경 사항만 필터링합니다.\n\nsdf = sdf.apply(simplify_data)\n\nsdf = sdf.update(lambda val: logger.info(f\"수신된 업데이트: {val}\"))\n\n# 필터링된 SDF에서 감지된 새 메시지(행)에 대해 임베딩 함수 트리거\nsdf[\"embeddings\"] = sdf.apply(create_embeddings, stateful=False)\n\n# 타임스탬프 열을 현재 시간(나노초 단위)으로 업데이트합니다.\nsdf[\"Timestamp\"] = sdf.apply(lambda row: time.time_ns())\r\n```\n\nsdf.apply()과 sdf.update()의 차이점에 유의하세요.\n\n<div class=\"content-ad\"></div>\n\n`apply()`은 콜백 함수의 결과를 하류로 전달합니다. 원본 데이터를 가져와 처리하여 새 데이터를 생성합니다. 이 메서드는 원본 데이터 자체를 변경하지 않고 대신 원본을 기반으로 새 버전을 생성합니다.\n\n- 예를 들어, apply()를 사용하여 사전에 새 키를 추가하면 실제로 해당 추가가 포함된 새 사전이 생성됩니다.\n- 우리의 경우, sdf.apply(simplify_data)를 사용하여 CDC 페이로드를 간단한 사전으로 변환하고 sdf.apply(create_embeddings)를 사용하여 벡터를 계산하고 해당 사전 내의 새로운 \"embeddings\" 필드에 기록합니다.\n\n`update()`는 실제 콜백 인수를 하류로 전달합니다. 원본 데이터를 직접 수정하거나 사용할 수 있게 합니다. 그러나 주로 콘솔에 데이터를 기록하거나 외부 데이터베이스에 쓰는 데 사용됩니다(Kafka Streams의 peek() 메서드와 유사합니다).\n\n마지막으로, 우리는 sdf.to_topic을 사용하여 변환된 데이터를 하류 토픽으로 생성합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nsdf = sdf.to_topic(output_topic)\napp.run(sdf)\n```\n\n# 벡터 DB에 Upserting\n\n이 프로세스는 sdf.update() 방법을 다시 사용하지만 먼저 sdf.update()에 전달 할 함수를 정의해야합니다. 즉, 들어오는 벡터와 메타데이터를 벡터 DB에 입력하는 함수를 정의해야합니다. 전체 코드는 이 GitHub 폴더에서 찾을 수 있습니다.\n\n여기서는 환경 변수를 사용하여 벡터 DB에 연결을 정의하고, 스트리밍 데이터프레임 행에서 관련 데이터를 추출하며, upload_points() 메서드를 사용하여 벡터 DB(이 경우 로컬 Qdrant DB)에 항목을 추가합니다.\n\n\n<div class=\"content-ad\"></div>\n\n```python\nfrom quixstreams import Application\nfrom qdrant_client import models, QdrantClient\nimport os\n\nhost = os.getenv(\"qd_host\", \"\")\nport = os.getenv(\"qd_port\", \"\")\ncollection = os.getenv(\"qd_collection\", \"\")\n\nqdrant = QdrantClient(host=host, port=port)\ncollection = collection\n\n# Create collection to store items\nif not qdrant.collection_exists(collection):\n    # Define the collection parameters\n    vector_size = 384\n    # Create the collection\n    qdrant.create_collection(\n        collection_name=collection,\n        vectors_config=models.VectorParams(\n            size=vector_size,  # Vector size is defined by used model\n            distance=models.Distance.COSINE\n        )\n    )\n    print(f\"Collection '{collection}' created.\")\nelse:\n    print(f\"Collection '{collection}' already exists.\")\n\n# Define the ingestion function\ndef ingest_vectors(row):\n\n  single_record = models.PointStruct(\n    id=row['id'],\n    vector=row['embeddings'],\n    payload={key: row[key] for key in ['name', 'description', 'author', 'year']}\n    )\n\n  qdrant.upload_points(\n      collection_name=collection,\n      points=[single_record]\n    )\n\n  print(f'Ingested vector entry id: \"{row[\"id\"]}\"...')\n\napp = Application(\n    consumer_group=\"ingesterV1\",\n    auto_offset_reset=\"earliest\",\n    auto_create_topics=True,  # Quix app has an option to auto create topics\n)\r\n```\n\n마지막으로, 입력 토픽에서 읽어와서 `ingest_vectors` 함수를 `sdf.update()`에 전달합니다. 상기한 바와 같이, 우리는 파이프라인의 종점에 도달했기 때문에 `sdf.update()`를 사용합니다. 데이터를 전달할 다운스트림 토픽이 없으므로 데이터를 \"위치에\" 업데이트하고(즉, 벡터 DB로 보내는 것) 있습니다.\n\n```python\n# JSON 디시리얼라이저와 함께 입력 토픽 정의\ninput_topic = app.topic(os.environ['input'], value_deserializer=\"json\")\n\n# 입력 토픽의 메시지 스트림을 기반으로 스트리밍 데이터프레임을 초기화합니다:\nsdf = app.dataframe(topic=input_topic)\n\n# 데이터 삽입이 이곳에서 발생합니다\nsdf = sdf.update(lambda row: ingest_vectors(row))\napp.run(sdf)\r\n```\n\n# 배운 점\n\n<div class=\"content-ad\"></div>\n\n기본 데이터를 신선하게 유지하는 것은 검색 품질의 중요한 구성 요소입니다. 제품 카탈로그에 새로운 항목이 도착할 때마다 벡터 저장소를 업데이트하여 사용자에게 의미론적으로 정확한 검색 결과를 제공할 수 있었음을 보았습니다.\n\n우리는 데이터베이스에서 데이터를 내보내어 일괄적으로 벡터 저장소에 쓰는 것과 같이 벡터 저장소를 수동으로 업데이트할 수 있었을 것입니다. 그러나 이렇게 하면 제품 카탈로그가 계속 변경되는 프로덕션 전자 상거래 시나리오에서 어떻게 작동하는지, 배치를 어떻게 조직화하며 제품이 카탈로그에 도착한 후에 사용자 검색 쿼리에 포함되기까지 허용할 수 있는 지연 시간이 어떻게 되는지와 관련된 여러 질문이 생깁니다.\n\n데이터가 입력됨과 동시에 임베딩이 생성되고 흡수되는 이벤트 기반 시스템을 설정하면(CDC를 통해), 이러한 질문들을 처리할 필요가 없습니다. 이것이 카프카 기반 아키텍처가 인기 있는 이유입니다.\n\n<div class=\"content-ad\"></div>\n\n많은 대규모 기업이 이미 DoorDash 예제에서 본 것처럼 전통적인 검색 색인 작업을 위해 Apache Kafka와 같은 이벤트 기반 솔루션을 사용하고 있습니다. 텍스트 임베딩을 최신 상태로 유지하는 데 관련된 도전 과제는 비슷하기 때문에 텍스트 임베딩에도 동일한 접근을 적용하는 것이 합리적입니다.\n\n프로덕션에서 점진적으로 데이터를 수집하는 경우 한 가지 주의할 점은 벡터 인덱스를 다시 완전히 계산해야 할 수도 있다는 것입니다. \"6 hard problems scaling vector search\" 라는 기사는 이 문제에 대해 자세히 다루고 있으며 규모에 맞게 이를 수행하려면 좋은 참고 자료가 될 것입니다. 서로 다른 벡터 데이터베이스는 이 문제를 다르게 해결합니다. 예를 들어 특정 벡터 저장소 세그먼트만 다시 계산함으로써 이 문제를 해결합니다. 따라서 프로덕션용 벡터 데이터베이스를 선택할 때 그들의 색인 전략을 고려하는 것이 중요합니다.\n\n그래도 이 간단한 프로토타입이 외부 소스에서 주기적으로 업데이트되는 신선한 데이터에 의존하는 검색 애플리케이션에 벡터 기반 검색을 통합하는 데 출발점을 제공했기를 희망합니다.\n\n- 만약 프로토타입을 작동시키는 데 문제가 있었다면, Quix Streams 사용자를 위한 Slack 커뮤니티에서 내게 메시지를 보내 주시기 바랍니다: https://stream-processing.slack.com/.","ogImage":{"url":"/assets/img/2024-06-22-StreamChangesfromaPostgreSQLDatabasetoaVectorStore_0.png"},"coverImage":"/assets/img/2024-06-22-StreamChangesfromaPostgreSQLDatabasetoaVectorStore_0.png","tag":["Tech"],"readingTime":20},{"title":"NumPy 마스터하기 효율적인 배열 처리 종합 가이드 Part 2","description":"","date":"2024-06-22 05:37","slug":"2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22","content":"\n\n## 빠르고 똑똑한 데이터 조작을 위한 NumPy의 힘을 활용하세요.\n\n# 소개\n\nNumPy 튜토리얼의 두 번째 파트에 오신 것을 환영합니다! 이전에는 다음 목록의 처음 7개 챕터를 다루었습니다. 이번 포스트에서는 8장부터 14장까지 진행하려고 합니다.\n\n- NumPy 설치\n- 배열 초기화\n- NumPy 배열 제한\n- 계산 속도와 메모리 사용량\n- 데이터 유형\n- 색인 및 슬라이싱\n- 배열 생성 함수\n- 난수 생성\n- 보기 및 복사\n- 수학 함수\n- 논리 및 비트 연산자\n- 검색 및 정렬\n- 모양 및 재구성\n- 연결 및 분할\n\n<div class=\"content-ad\"></div>\n\n참고: 이 문서에서 사용된 모든 자료는 제 GitHub 저장소에서 확인할 수 있습니다. 여기에 링크를 남깁니다.\n\n# 8. 랜덤 숫자\n\nNumPy를 사용하면 랜덤 숫자를 생성할 수 있습니다. 제 경우에는 이 기능을 사용하여 기계 학습 및 딥 러닝 모델에서 무작위 가중치를 초기화하는 데 사용해 보았습니다. 제가 처음부터 구현하려고 노력했던 그때입니다. 이러한 유형의 NumPy 기능에는 다른 응용 프로그램이 있을 것이라고 믿습니다.\n\n## 균일 분포\n\n<div class=\"content-ad\"></div>\n\n이제 np.random.rand()로 시작해 봅시다. 이 함수는 [0.0, 1.0) 범위 내에서 균일 분포에서 무작위 숫자를 생성합니다. 이는 숫자가 정확히 0.0이 될 수는 있지만, 1.0에 근접할 뿐입니다. 이 함수를 사용하려면 우리가 원하는 배열의 형태를 전달해주기만 하면 됩니다. np.random.random()은 사실상 np.random.rand()와 동일합니다. 그러나 이 함수에 대한 입력은 튜플 형태여야 한다는 것을 염두에 두세요. 이 두 함수 중 어느 것이든 실제로 서로 교차하여 사용할 수 있습니다. 이는 단지 사용자의 취향에 따라 다를 뿐입니다.\n\n```js\n# Codeblock 1\nnp.random.rand(10,3)\n\n### 대안\n# np.random.random((10,3))\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_0.png\" />\n\n아직 무작위 균일 분포와 관련하여, 더 많은 유연성이 필요하다면 np.random.uniform()를 사용할 수 있습니다. 이 함수를 사용하면 분포의 범위를 지정할 수 있어 [0.0, 1.0)에 고정되어 있는 것보다 더 유연해집니다. 아래 코드 블록에서 수를 90부터 100 사이로 범위 설정하는 방법을 보여드리겠습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n# 코드 블록 2\nnp.random.uniform(low=90, high=100, size=(5,5))\n```\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_1.png)\n\n만약 균일 분포에서 숫자를 np.histogram()에 넣으면, 모든 바구니(첫 번째 인덱스의 배열)에 유사한 빈도의 발생이 있음을 볼 수 있습니다. 아래 예제에서는 10개의 바구니로 분배된 50,000개의 숫자를 생성합니다. 이렇게 하면 각 바구니에 약 5,000개의 발생 횟수가 있습니다. 무작위 균일 함수의 세 가지 변형(np.random.rand(), np.random.random() 및 np.random.uniform())이 모두 이렇게 동작합니다.\n\n```js\n# 코드 블록 3\nnp.histogram(np.random.uniform(size=(50000)))\n\n### 유사한 결과를 제공합니다\n# np.histogram(np.random.rand(50000))\n# np.histogram(np.random.random(50000))\n```\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_2.png\" />\n\n## 정규 분포\n\n균일 분포 뿐만 아니라 np.random.randn()을 사용하여 정규 분포의 데이터도 생성할 수 있습니다. 여기서 전달할 수 있는 유일한 매개변수는 생성될 배열의 모양입니다.\n\n```js\n# 코드 블록 4\nnp.random.randn(6,4)\n```\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_3.png)\n\n안타깝게도 np.random.randn() 함수는 분포의 평균과 표준 편차를 변경할 수 있는 기능을 제공하지 않습니다. 이 함수에서 두 매개변수는 각각 0과 1로 고정되어 있습니다. 만약 이러한 값을 사용자 정의하고 싶다면 np.random.normal()을 사용해야 합니다. np.random.normal()에서는 평균을 loc 매개변수를 사용하여 조절하고, 표준편차는 scale 매개변수를 통해 수정할 수 있습니다.\n\n```js\n# Codeblock 5\nnp.random.normal(loc=8, scale=3, size=(5,5))\n```\n\n![Image](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_4.png)\n\n\n<div class=\"content-ad\"></div>\n\n제가 앞서 사용한 np.histogram() 함수는 np.random.randn() 및 np.random.normal()에 의해 생성된 배열이 실제로 정규 분포를 따르는지 확인하는 데 사용될 수 있습니다. 아래 그림 6은 이를 설명하는데, 첫 번째 배열을 통해 가운데 있는 bin이 가장 빈도가 높음을 보여줍니다.\n\n```js\n# 코드 블록 6\nnp.histogram(np.random.normal(loc=0, scale=1, size=50000))\n\n### 비슷한 결과를 출력\n# np.histogram(np.random.randn(50000))\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_5.png\" />\n\n지금까지 많은 유사한 함수가 존재한다는 것을 알아차렸습니다. 특히, 무작위 숫자를 생성하는 데 사용되는 함수들은 균일 및 정규 분포와 관련된 함수들이 많습니다. 그런 경우에는 np.random.uniform() 및 np.random.normal()만 사용하는 것을 권장드립니다. 두 함수가 가장 유연하기 때문입니다.\n\n<div class=\"content-ad\"></div>\n\n## 랜덤 정수\n\n우리가 이전에 논의한 함수들은 주로 랜덤 소수점 숫자를 생성하는 데 초점을 맞췄습니다. 실제로 Numpy는 랜덤 정수를 생성하는 함수인 np.random.randint()를 제공합니다. 이 함수의 매개변수 및 동작은 np.random.uniform()와 동일합니다. 지정된 범위 내의 모든 숫자는 선택될 확률이 완전히 동일합니다. 다시 말해, np.random.randint()는 숫자 선택을 위해 균일한 이산 분포를 사용합니다. 아래 예시에서 생성된 숫자들은 [5,10) 범위 내에 있을 것입니다 (즉, 10은 포함되지 않음).\n\n```js\n# Codeblock 7\nnp.random.randint(low=5, high=10, size=(20,3))\n```\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_6.png)\n\n<div class=\"content-ad\"></div>\n\n## 배열 섞기\n\n다음으로 이야기하고 싶은 함수는 np.random.shuffle()입니다. 그러나 더 진행하기 전에 먼저 배열 K를 초기화하고 싶습니다.\n\n```js\n# 코드 블록 8\nK = np.random.randint(1, 30, size=10)\nK\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_7.png\" />\n\n<div class=\"content-ad\"></div>\n\n아마 알아챌 수 있었던 것처럼, np.random.shuffle()은 배열의 요소 순서를 섞어주는 함수입니다. 이 함수는 배열을 그 자리에서 섞기 때문에, 새로운 배열을 만드는 것이 아니라 원본 배열을 직접 섞는다는 것을 명심해 주세요.\n\n```js\n# 코드 블록 9\nprint('섞기 전 K\\t: ', K)\nnp.random.shuffle(K)\nprint('섞은 후 K\\t: ', K)\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_8.png\" />\n\n## 랜덤 선택\n\n<div class=\"content-ad\"></div>\n\n아직 배열 K와 작업 중이시군요. 이제 그 중에서 숫자를 무작위로 선택하는 방법을 알려드릴게요. np.random.choice()를 사용하면 간단하죠. 아래 코드 블록에서 함수를 사용하는 여러 예제를 보여드릴게요.\n\n```js\n# 코드 블록 10\nprint(np.random.choice(K), end='\\n\\n')                #(1)\nprint(np.random.choice(K, size=(2,3)), end='\\n\\n')    #(2)\nprint(np.random.choice(K, size=(2,4), replace=False)) #(3)\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_9.png\" />\n\n(1)에서 지정된 줄에서, 함수에 배열만 전달하면 해당 배열에서 한 개의 숫자를 반환합니다. (2)의 size 매개변수를 사용하여 출력의 차원을 지정할 수도 있어요. 출력 결과를 보면 16이 두 번 나타나는 것을 알 수 있어요. 이는 기본적으로 함수가 복원 선택으로 무작위 숫자를 선택하기 때문인데요, 즉, 원래 배열에서 하나의 숫자가 여러 번 선택될 수 있습니다. 이를 원치 않는 경우, replace=False를 써서 다음과 같이 쓸 수 있어요. (3)에서처럼요. 이렇게 하면 결과 배열의 요소 수가 원본 배열의 요소 수보다 크면 안 된다는 점에 유의하세요. 궁금하시다면, 세 번째 출력에서 두 번 나타나는 12는 배열 K에 12가 실제로 두 번 나타난 것 때문입니다.\n\n<div class=\"content-ad\"></div>\n\n## 시드\n\n생성된 무작위 숫자를 재현 가능하게 하는 경우가 많습니다. 이를 위해 np.random.seed()를 사용할 수 있습니다. 사용 방법은 간단합니다. 단지 인수로 숫자를 넣고 동일한 숫자를 출력을 정확히 원하는 노트북 셀에서 사용하면 됩니다. 다음 예제를 살펴봅시다. 여기서 np.random.randint()로 생성된 배열이 두 연속된 코드 블록에서 정확히 동일하게 나오기를 원합니다. 이 예에서 시드를 99로 설정하기로 결정했습니다(원하는 정수를 선택할 수 있습니다). np.random.randint()가 정확히 동일한 숫자를 반환하려면, 동일한 시드로 np.random.seed()를 다시 호출해야 합니다.\n\n```python\n# 코드 블록 11\nnp.random.seed(99)\nnp.random.randint(low=0, high=10, size=(2,5))\n```\n\n<div class=\"content-ad\"></div>\n\n```json\n# 코드 블록 12\nnp.random.seed(99)\nnp.random.randint(low=0, high=10, size=(2,5))\n```\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_11.png)\n\n# 9. 뷰(View)와 복사(Copy)\n\n## 뷰(View)\n\n\n<div class=\"content-ad\"></div>\n\n한 변수에서 다른 변수로 배열을 할당할 때 Numpy의 성질을 고려해야 합니다. 다음 예제를 살펴보겠습니다.\n\n```js\n# 코드 블록 13\nL = np.array([55, 66, 77, 88, 99])\nM = L\nprint(M)\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_12.png\" />\n\n여기서 배열 L을 변수 M에 할당했으므로 두 변수가 동일한 배열을 포함하게 됩니다. 다음으로, 아래 코드 블록 14를 사용하여 M의 0번 인덱스를 변경하려고 합니다. 그러나 M의 첫 번째 요소만 바꾸려고 했지만 배열 L의 요소도 변경됩니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n# 코드 블록 14\nM[0] = 15\nprint('L:', L)\nprint('M:', M)\n```\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_13.png)\n\n이 결과가 나온 이유는 M이 단순히 L의 \"뷰(view)\"일 뿐이기 때문입니다. 다시 말해 위에서 보여준 방법은 배열을 복사하는 것이 아니라 두 변수가 여전히 \"연결\"되어 있기 때문입니다.\n\n## 복사\n\n\n<div class=\"content-ad\"></div>\n\n위의 경우가 발생하지 않도록하려면, M에 할당할 때 copy() 메서드를 L에 넣으면 됩니다. 이렇게 하면 M에 저장된 배열이 완전히 다른 배열이 되어, 하나의 배열에 대한 수정이 다른 배열에 영향을 미치지 않도록 보장됩니다.\n\n```js\n# Codeblock 15\nL = np.array([55, 66, 77, 88, 99])\nM = L.copy()\nM[0] = 15\n\nprint('L:', L)\nprint('M:', M)\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_14.png\" />\n\n# 10. 수학 함수\n\n<div class=\"content-ad\"></div>\n\n## 기본 수학 연산\n\n이 장에서는 Numpy의 수학 기능을 사용하는 방법에 대해 알아보려고 합니다. 시작하기 전에 사전에 배열 N과 O를 초기화해 봅시다.\n\n```js\n# Codeblock 16\nN = np.array([1,2,3], dtype='int32')\nO = np.array([4,5,6], dtype='int32')\n```\n\n우리는 가장 기초적인 것부터 시작할 것입니다: 덧셈, 뺄셈, 곱셈 및 나눗셈입니다. Numpy에서 배열에 이러한 연산자를 적용하면 연산은 요소별로 수행됩니다. 이러한 이유로 배열 피연산자의 차원이 정확히 일치하는지 확인해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n\n# 코드 블록 17\nprint(N + O)\nprint(N - O)\nprint(N * O)\nprint(N / O)\n\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_15.png)\n\n위의 코드블록 17에서 소개된 방법들은 Numpy 배열에서만 작동합니다. 리스트에 똑같은 작업을 시도하면 모든 예제가 오류가 발생할 것이며, 덧셈 연산은 두 리스트를 연결할 것입니다.\n\n대안으로 np.add(), np.subtract(), np.multiply() 및 np.divide()와 같은 Numpy에서 제공하는 함수들을 사용할 수도 있습니다. 연산자 기호와 함수 모두 정확히 같은 결과를 생성합니다. 따라서 이 경우에는 개인 취향에 따라 선택하면 됩니다. 아래 코드블록은 이러한 함수들을 어떻게 사용하는지 보여줍니다. 결과 출력은 Figure 16에 표시된 것과 완전히 동일합니다.\n\n\n<div class=\"content-ad\"></div>\n\n```js\n# Codeblock 18\nprint(np.add(N, O))\nprint(np.subtract(N, O))\nprint(np.multiply(N, O))\nprint(np.divide(N, O))\n```\n\n넘파이(Numpy)에서 \"브로드캐스팅(broadcasting)\"이라는 개념이 있습니다. 이는 기본적으로 크기가 다른 배열 또는 배열과 스칼라 간의 연산을 수행할 수 있다는 것을 의미합니다. 다음 경우에는 숫자 5가 배열 N의 모든 요소로 브로드캐스팅된다고 말할 수 있습니다.\n\n```js\n# Codeblock 19\nprint(N + 5)\nprint(N - 5)\nprint(N * 5)\nprint(N / 5)\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_16.png\" />\n\n<div class=\"content-ad\"></div>\n\n제가 다음으로 논의하고 싶은 것은 행렬 곱셈입니다. 이전에 언급한 대로, 네 가지 기본 수학 연산 함수는 요소별로 작동합니다. 이는 np.multiply() 함수가 행렬 곱셈을 위해 의도된 것이 아니라는 것을 의미합니다. 대신 np.matmul()을 사용해야 합니다. 이 경우 두 입력 행렬이 연산 가능한지 확인해야 합니다. 다음 예제에서는 각각 크기가 (4,3)과 (3,2)인 배열 O와 P 사이의 곱셈을 수행합니다.\n\n```js\n# 코드블록 20\nO = np.array([[2, 1, 0], \n              [5, 4, 3], \n              [8, 7, 6], \n              [1, 0, 9]])\n\nP = np.array([[4, 3], \n              [6, 5], \n              [8, 7]])\n\nnp.matmul(O, P)\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_17.png\" />\n\n여전히 기본 수학 연산과 관련된 다른 함수에는 np.sign(), np.negative() 및 np.abs()가 있습니다. 이러한 함수들의 사용법을 배열 Q에 대해 보여드리겠습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n# 코드 블록 21\nQ = np.array([-56, 92, -24, -66, 72, -75, 90, 0, 32, 51])\n\nprint(np.sign(Q))\nprint(np.negative(Q))\nprint(np.abs(Q))      # 대안: np.absolute()\n```\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_18.png)\n\n함수 이름대로, np.sign()은 배열의 각 요소의 부호를 취하는 데 사용됩니다. -1, 0 또는 1만 표시됩니다. 다음으로, np.negative()를 사용하여 숫자의 부호를 뒤집을 수 있습니다. 위의 예시에서 -56은 56이 되고, 92는 -92가 됩니다. 마지막으로, np.abs() 또는 np.absolute()를 사용하여 숫자의 절대값을 취할 수 있습니다.\n\n## 최대공약수(GCD)와 최소공배수(LCM)\n\n<div class=\"content-ad\"></div>\n\n최대공약수(GCD)와 최소공배수(LCM)는 Numpy에서 각각 np.gcd()와 np.lcm()으로 구현되어 있습니다. 이러한 함수들을 사용하려면, 간단히 두 숫자나 배열을 입력인수로 넣으면 됩니다.\n\n```js\n# 코드블록 22\nprint(np.gcd(81, 72))    #(1)\nprint(np.lcm([3, 6, 9], 24))    #(2)\nprint(np.lcm([3, 12, 9], [24, 16, 3]))    #(3)\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_19.png\" />\n\n위 코드블록 22의 예제를 살펴봅시다. #(1)으로 표시된 줄은 81과 72의 최대공약수인 하나의 숫자를 반환합니다. 한편, #(2) 줄에서는 숫자 24가 첫 번째 인수에 브로드캐스트되어 LCM이 24와 목록의 각 숫자 간에 계산됩니다. 마지막으로, 두 인수에 대해 리스트를 전달하면, LCM 또는 GCD 계산이 요소별로 수행됩니다 (#(3)).\n\n<div class=\"content-ad\"></div>\n\n## 지수 함수\n\nnp.power() 함수를 사용하여 지수 연산을 수행할 수 있습니다. 이 함수는 두 개의 입력을 받습니다: 밑수와 지수입니다. 해당 함수는 지수로 분수를 전달하여 루트를 계산할 수 있도록 매우 유연합니다.\n\n```js\n# Codeblock 23\nprint(np.power(8, 3))\nprint(np.power([1,2,3,4], 2))\nprint(np.power(144, 1/2))\n```\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_20.png)\n\n<div class=\"content-ad\"></div>\n\n유연성이 있긴 하지만, np.power()은 실제로 연산 속도에 있어서 최상이라고 할 수는 없습니다. 실제로 더 빠른 계산을 제공하는 몇 가지 특정 목적을 위한 대안들이 있습니다. np.square(), np.sqrt(), np.cbrt() 및 np.exp()가 그 예입니다. 아래 코드 블록은 np.power()와 이러한 함수들의 동등한 사용법을 보여줍니다.\n\n```js\n# 코드 블록 24\nprint(np.square(6))             # np.power(6,2)와 동일\nprint(np.sqrt([144,16,9,4]))    # np.power([144,16,9,4], 1/2)와 동일\nprint(np.cbrt([343,27]))        # np.power([343,27], 1/3)와 동일\nprint(np.exp([2,3,4]))          # np.power(np.e, [2,3,4])와 동일\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_21.png\" />\n\n## 각도 변환 및 삼각함수\n\n<div class=\"content-ad\"></div>\n\n넘파이에서는 삼각함수를 사용할 수 있습니다. np.sin(), np.cos() 및 np.tan()을 사용할 때 주의해야 할 점은 이 함수들이 라디안 단위의 각도를 입력으로 받는다는 것입니다. 따라서 각도가 도(degree)로 주어진 경우 np.deg2rad()를 사용하여 라디안으로 변환해야 합니다. 아래 Codeblock 25에서는 각도를 도와 라디안으로 변환하는 방법을 보여줍니다.\n\n```js\n# Codeblock 25\nR = np.array([0, 90, 180, 270])    # 각도 (도)가 담긴 배열\nS = np.array([0, np.pi/2, np.pi, np.pi*3/2])    # 각도 (라디안)가 담긴 배열\n\nprint(np.deg2rad(R))\nprint(np.rad2deg(S))\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_22.png\" />\n\n각도 변환 방법을 이해했으니, 이제 삼각함수의 사용법을 실제로 보여드리겠습니다. 다음 코드에서 숫자 0, 45, 60이 각도 (도)를 나타낸다고 가정합니다. 이 숫자들은 라디안으로 변환된 후 배열 T에 저장되어 np.sin(), np.cos(), np.tan()의 입력으로 사용됩니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n# 코드 블록 26\nT = np.deg2rad([0, 45, 60])\n\nprint(np.sin(T))\nprint(np.cos(T))\nprint(np.tan(T))\n```\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_23.png)\n\n## 로그 함수\n\n로그 함수에 대해 이야기할 때, 적어도 가장 기본적이라고 생각되는 세 가지 함수가 있습니다. 아래 코드 블록 27에서는 배열 U에 np.log(), np.log2() 및 np.log10() 함수를 어떻게 사용하는지 보여줍니다.\n\n\n<div class=\"content-ad\"></div>\n\n\n# 코드 블록 27\nU = [1, 2, 10, np.e]\n\nprint(np.log(U))\nprint(np.log2(U))\nprint(np.log10(U))\n\n\n![Image](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_24.png)\n\nNumpy에서 np.log()는 수학의 ln() 함수와 동일합니다 (밑이 e인 로그). 한편, np.log2()와 np.log10()은 각각 밑이 2와 10인 로그입니다.\n\n## 통계 함수\n\n\n<div class=\"content-ad\"></div>\n\n만약 숫자 데이터 분포를 가지고 있다면, 통계적 특성을 계산하여 추가 분석을 수행할 수 있습니다. 우리에게 운이 좋은 것은 Numpy가 이 작업을 쉽게 수행할 수 있는 다양한 함수를 제공해준다는 것입니다. 이와 관련된 모든 함수들 — 아마도 이들 모두가 명확히 이해할 만한 함수들로 보입니다 — 이 코드 블록 28에 나와 있습니다.\n\n```js\n# 코드 블록 28\nV = np.array([1, 5, 4, 6, 8, 5, 4, 3, 2, 4, 7, 9, 5, 4, 3, 2, 0, 7, 9])\n\nprint('sum\\t:', np.sum(V))\nprint('mean\\t:', np.mean(V))\nprint('median\\t:', np.median(V))\nprint('var\\t:', np.var(V))\nprint('stddev\\t:', np.std(V))\nprint('q1\\t:', np.quantile(V, 0.25))\nprint('q2\\t:', np.quantile(V, 0.5))\nprint('q3\\t:', np.quantile(V, 0.75))\nprint('min\\t:', np.min(V))\nprint('max\\t:', np.max(V))\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_25.png\" />\n\n이 주제 외에도 통계 측정과 직접적인 관련이 없지만 여전히 유용할 수 있는 두 가지 다른 함수가 실제로 있습니다. 말하고자 하는 두 함수는 np.argmin()과 np.argmax()인데, 이 두 함수는 배열에서 가장 작은 값과 가장 큰 값이 들어 있는 인덱스를 반환합니다. 가장 작거나 큰 값이 여러 개인 경우, 이 두 함수는 가장 낮은 인덱스를 반환합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n# 코드 블록 29\nprint('argmin\\t:', np.argmin(V))\nprint('argmax\\t:', np.argmax(V))\n```\n\n![image](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_26.png)\n\n## 선형 대수\n\n넘파이는 선형 대수 계산을 수행하는데 다양한 도구를 제공합니다. 여기서 여러분께 보여드릴 수 있는 몇 가지 사항들이 있습니다. 코드 블록 30에 표시된 두 배열이 있다고 가정해 봅시다.\n\n<div class=\"content-ad\"></div>\n\n```js\n# 코드 블록 30\nW = np.array([10, 20, 30, 40])\nX = np.array([3, 4, 5, 6])\n```\n\n넘파이에서 1차원 배열은 벡터로 생각할 수 있습니다. 따라서 np.dot()을 사용하여 W와 X의 내적을 계산할 수 있습니다.\n\n```js\n# 코드 블록 31\nnp.dot(W, X)\n```\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_27.png)\n\n<div class=\"content-ad\"></div>\n\n또한 NumPy는 np.inner() 및 np.outer()를 통해 내적과 외적을 계산할 수 있도록 합니다.\n\n```python\n# Codeblock 32\nprint(np.inner(W, X))\nprint(np.outer(W, X))\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_28.png\" />\n\n이제 2D 배열을 다루고 있다면 우리가 할 수 있는 것들에 대해 좀 더 자세히 알아보겠습니다. 이를 시연하기 전에 배열 Y를 미리 초기화하고 싶습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n# 코드 블록 33\nY = np.array([[2, 1, 0],\n              [0, 4, 5],\n              [2, 6, 3]])\n```\n\n행렬의 전치(transpose)를 얻으려면 np.transpose()를 사용하거나 해당 행렬의 T 속성을 사용할 수 있습니다. 아래 코드 블록을 확인해보세요.\n\n```js\n# 코드 블록 34\nnp.transpose(Y)\n\n### 대안\n# Y.T\n```\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_29.png)\n\n\n<div class=\"content-ad\"></div>\n\n넘파이는 행렬의 역행렬을 계산하는 함수도 제공합니다. `np.linalg.inv()`를 사용하면 행렬 Y의 역행렬을 계산할 수 있습니다. \n\n```js\n# 코드 블록 35\nnp.linalg.inv(Y)\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_30.png\" />\n\n그러나 중요한 점은 행렬이 특이행렬일 때, 즉 행렬식이 0일 때 `np.linalg.inv()`가 오류를 반환한다는 것입니다. 따라서 역행렬을 계산하기 전에 행렬의 행렬식 값을 확인하는 것이 좋은 아이디어라고 생각합니다. 확인을 위해 `np.linalg.det()`을 사용하세요.\n\n<div class=\"content-ad\"></div>\n\n```js\n# Codeblock 36\nnp.linalg.det(Y)\n```\n\n![Image](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_31.png)\n\n더불어 Numpy는 np.linalg.eig()를 사용하여 고유값과 고유벡터를 계산할 수 있습니다. 이 함수는 두 값 모두 반환하므로 출력을 위해 두 변수를 할당해야 합니다.\n\n```js\n# Codeblock 37\neigenvalues, eigenvectors = np.linalg.eig(Y)\n\nprint(eigenvalues, end='\\n\\n')\nprint(eigenvectors)\n```\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_32.png\" />\n\n지금까지 Numpy에서 다양한 수학 함수에 대해 많이 이야기했습니다. 실제로 더 설명하지 않은 것도 많이 있습니다. 더 탐구하고 싶다면 [이 사이트](1)를 방문해보세요.\n\n# 11. 논리 및 비트 연산자\n\n## 논리 연산자\n\n<div class=\"content-ad\"></div>\n\n이 기사의 맨 처음에, NumPy가 우리에게 boolean 자료형의 배열을 만들 수 있게 한다고 언급했지만, 이 주제에 대해 아직 자세히 다루지는 않았습니다. 그리고 이제, 이 장에서 그에 대해 이야기하고 싶습니다. 먼저, Z와 AA라는 이름으로 두 배열을 초기화하는 것으로 시작합시다.\n\n```js\n# 코드블록 38\nZ = np.array([True, True, True])\nAA = np.array([False, True, True])\n```\n\nboolean 연산을 수행하는 가장 간단한 방법은 `np.logical_and()`, `np.logical_or()`, 및 `np.logical_xor()`를 사용하는 것입니다. 우리가 이 함수들을 인수로써 같은 차원의 두 배열을 넣어주면, 이 함수들은 요소별 연산을 수행할 것입니다. 다음 예제를 참조해주세요.\n\n```js\n# 코드블록 39\nprint(np.logical_and(Z, AA))\nprint(np.logical_or(Z, AA))\nprint(np.logical_xor(Z, AA))\n```\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_33.png)\n\nOR 및 AND 연산자와 약간 비슷한 두 가지 특수 기능이 실제로 있는데, np.any()와 np.all()입니다. np.any()는 배열에 하나 이상의 True가 있으면 True를 반환합니다. 반면에 np.all()은 배열의 모든 요소가 True인 경우에만 True를 반환합니다. 아래 코드 블록 40에서는 배열 Z와 AA에 대해 이 두 함수를 어떻게 사용하는지 보여줍니다.\n\n```js\n# 코드 블록 40\nprint('np.any(Z): ', np.any(Z))\nprint('np.all(Z): ', np.all(Z), end='\\n\\n')\nprint('np.any(AA):', np.any(AA))\nprint('np.all(AA):', np.all(AA))\n```\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_34.png)\n\n\n<div class=\"content-ad\"></div>\n\n우리는 실제로 np.any()와 np.all()을 좀 더 고급으로 사용할 수 있어요. 다음 코드 블록에서 #(1) 행에서, np.any()는 배열 AB에서 4보다 큰 숫자가 하나 이상 있는 경우 True를 반환할 거에요. 다음으로, #(2) 행에서는 AB의 모든 요소가 4보다 큰 경우에만 True를 반환할 거에요.\n\n```js\n# Codeblock 41\nAB = np.array([2, 0, 3, -5, 5, -1, 2, -4])\n\nprint(np.any(AB > 4))    #(1)\nprint(np.all(AB > 4))    #(2)\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_35.png\" />\n\n## 비트 연산자\n\n<div class=\"content-ad\"></div>\n\n비트 연산자는 논리 연산자만큼 직관적으로 보이지 않을 수 있습니다. 그럼에도 불구하고 두 가지의 기본 아이디어는 정확히 같습니다. 차이는 비트 연산자가 정수를 입력으로 사용한다는 점뿐입니다. 연산 중에 이러한 정수들은 이진으로 먼저 변환된 후 비트 단위로 작동됩니다. 아래 예시에서는 np.bitwise_and(), np.bitwise_or() 및 np.bitwise_xor()에 12와 13을 입력 인수로 넣었습니다.\n\n```js\n# Codeblock 42\nprint(np.bitwise_and(12, 13))\nprint(np.bitwise_or(12, 13))\nprint(np.bitwise_xor(12, 13))\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_36.png\" />\n\n위 함수들은 모두 처음에 12와 13을 이진으로 변환하여 작동합니다: 1100과 1101. 이 값을 AND 연산자로 처리하면 1100이 됩니다. 한편 OR 연산자는 1101을 반환하고 XOR는 0001을 반환합니다. 이진 수열을 10진수로 변환하면 최종 결과로 12, 13 및 1이 나옵니다.\n\n<div class=\"content-ad\"></div>\n\n이 주제에 추가로, np.binary_repr()을 사용하여 10진수의 이진 표현을 확인할 수 있습니다.\n\n```js\n# 코드 블록 43\nprint(np.binary_repr(12))\nprint(np.binary_repr(13))\n```\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_37.png)\n\n# 12. 검색 및 정렬\n\n<div class=\"content-ad\"></div>\n\n특정 숫자를 찾을 때에는 불리언 인덱싱이라는 기법을 사용할 수 있어요. 이 방법을 마스킹처럼 생각할 수도 있죠. 여기서 저는 다음 코드 블록에서 초기화한 배열 AC를 이 아이디어로 설명하고 싶어요.\n\n```js\n# 코드블록 44\nAC = np.array([9, 4, 5, 3, 2, 6, 8, 6, 5, 4, 5, 5, 3, 2])\n\nmask = AC > 5  #(1)\nmask\n```\n\n이름이 \"mask\"인 것은 사실상 AC와 길이가 정확히 같은 다른 배열이며, 여기에는 불리언 값만 포함돼요. 이렇게 배열을 생성하려면 (1) 라인에서 하는 것처럼 조건을 적용하면 되요. 이 코드 라인에서는 배열 AC의 모든 요소가 지정된 조건을 충족하는지 확인해요. 만약 조건을 충족한다면 해당 인덱스는 True로 할당돼요.\n\n<div class=\"content-ad\"></div>\n\n실제 마스킹은 아래의 코드블록 45를 사용하여 실행됩니다. 이렇게 하면 우리의 기준을 충족하는 숫자만 출력됩니다.\n\n```js\n# 코드블록 45\nAC[mask]\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_39.png\" />\n\n사실, 마스크를 별도의 변수에 저장할 필요는 없습니다. 대신, 다음과 같이 간단히 작성할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n```js\n# 코드블록 46\nAC[AC > 5]\n```\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_40.png)\n\n논리 연산자도 사용할 수 있습니다. 다음 예시는 9를 제외한 모든 요소 중 5보다 큰 모든 요소를 출력합니다.\n\n```js\n# 코드블록 47\nAC[(AC > 5) & (AC != 9)]\n```\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_41.png)\n\n실제로 np.where()를 사용하여 동일한 결과를 얻을 수 있습니다. 아래는 그 방법입니다. 결과 출력은 이전 것과 정확히 동일하기 때문에 나타내지 않습니다.\n\n```python\n# Codeblock 48\nAC[np.where((AC > 5) & (AC != 9))]\n```\n\nnp.where() 함수 자체는 배열에서 지정된 기준을 충족하는 색인을 반환하여 작동합니다. 이 특정 경우에는 선택된 색인이 6, 8 및 6에 해당하는 5, 6 및 7이며, 이는 배열 AC에서의 값들과 일치합니다.\n\n\n<div class=\"content-ad\"></div>\n\n\n# 코드블록 49\nnp.where((AC > 5) & (AC != 9))\n\n# AC의 요소를 떠올려보세요: [9, 4, 5, 3, 2, 6, 8, 6, 5, 4, 5, 5, 3, 2].\n\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_42.png)\n\nnp.where() 함수는 3개의 인수를 전달할 때 더 유용할 수 있습니다. 즉, 조건, x 및 y를 정확한 순서로 전달합니다. 이러한 인수를 다음과 같이 생각할 수 있습니다: \"조건이 True를 반환하면 x를 수행하고, 그렇지 않으면 y를 수행합니다.\" 이를 더 잘 설명하기 위해 다음 코드는 배열 AC의 모든 요소를 5보다 큰 경우 0으로 변환합니다. 그렇지 않으면 숫자가 2씩 추가됩니다.\n\n\n# 코드블록 50\nprint(AC)\nprint(np.where(AC > 5, 0, AC+2))\n\n\n\n<div class=\"content-ad\"></div>\n\n\n![마스터링 넘파이 효율적인 배열 처리를 위한 포괄적인 가이드 22_43 이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_43.png)\n\n만약 배열 내의 고유한 값의 수를 찾는다는 요청이 오면, np.unique()를 사용할 수 있습니다. 이 함수를 사용하는 방법은 간단합니다. 배열을 유일한 매개변수로 넣기만 하면 됩니다. 또는 만약 원한다면, return_counts=True를 사용하여 해당 값들의 발생 횟수도 얻을 수 있습니다.\n\n```python\n# 코드블록 51\nnp.unique(AC, return_counts=True)\n```\n\n![마스터링 넘파이 효율적인 배열 처리를 위한 포괄적인 가이드 22_44 이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_44.png)\n\n\n<div class=\"content-ad\"></div>\n\n## 정렬\n\n함수의 이름이 나타내듯이, 배열을 정렬하는 데 필요한 것은 np.sort()입니다. 예를 들어, 여기서 배열 AD와 AE를 가지고 정렬 작업을 수행할 것입니다.\n\n```js\n# 코드 블록 52\nAD = np.array([77,33,44,99,22,88,55,11,66])\nAE = np.array([\"Elon Musk\", \"Bill Gates\", \"Joe Biden\", \"Barack Obama\"])\n\nprint(np.sort(AD))\nprint(np.sort(AE))\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_45.png\" />\n\n<div class=\"content-ad\"></div>\n\n위의 결과에서 두 배열이 오름차순으로 정렬되어 있음을 확인할 수 있습니다. 실제로 np.sort()에는 결과 배열을 내림차순으로 정렬할 수 있는 매개변수가 없습니다. 따라서, 만일 원한다면 np.flip()을 사용하여 내림차순으로 정렬할 수 있습니다.\n\n```js\n# Codeblock 53\nprint(np.flip(np.sort(AD)))\nprint(np.flip(np.sort(AE)))\n\n### 대체 방법\n# print(np.sort(AD)[::-1])\n# print(np.sort(AE)[::-1])\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_46.png\" />\n\n만약 배열을 정렬하긴 하되 값이 아닌 인덱스만 필요한 경우, np.argsort()를 사용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n# 코드블록 54\nnp.argsort(AD)\n\n# AD의 요소들을 상기해 봅시다: [77, 33, 44, 99, 22, 88, 55, 11, 66].\n\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_47.png)\n\nFigure 48에 표시된 출력은 기본적으로 AD 배열에서 가장 작은 숫자를 포함하는 7번째 인덱스를 보여줍니다. 이후로 AD[4], AD[1], 등이 따릅니다. 정렬이 제대로 작동하는지 확인하기 위해 np.argsort()의 전체 출력을 사용하여 다음과 같이 인덱싱을 수행할 수 있습니다:\n\n\n# 코드블록 55\nAD[np.argsort(AD)]\n\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_48.png\" />\n\n2차원 배열의 경우, axis 매개변수를 사용하여 정렬 방향을 결정할 수 있습니다. 이는 np.sort()와 np.argsort() 둘 다에 적용할 수 있습니다. 아래 배열 AF를 고려해 봅시다.\n\n```js\n# 코드블록 56\nAF = np.array([[3, 1, 5, 7],\n               [8, 9, 3, 2], \n               [4, 8, 2, 6]])\n```\n\n만약 위 행렬을 열을 따라 정렬하고 싶다면, axis=0을 사용해야 합니다. 반면, axis=1은 행을 따라 정렬할 수 있게 합니다. 아래 코드블록 57는 그 방법을 보여줍니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n# Codeblock 57\nprint(np.sort(AF, axis=0), end='\\n\\n')\nprint(np.sort(AF, axis=1))\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_49.png\" />\n\n이 장에 대해 이야기하고 싶은 마지막 주제는 실제로는 정렬과는 크게 관련이 없지만, 여전히 배열 순서와 관련이 있는 주제입니다. 이야기하려는 함수는 np.roll()인데, 이 함수를 사용하여 요소들에 대한 순환 이동을 수행할 수 있습니다. 이 아이디어를 설명하기 위해 먼저 한 시퀀스를 생성할 것입니다.\n\n```js\n# Codeblock 58\nAG = np.arange(13)\nAG\n```\n\n<div class=\"content-ad\"></div>\n\n아래는 codeblock를 사용하여 시퀀스를 shift 매개변수에 전달한 값에 따라 회전시킬 수 있습니다. 이 경우에는 AG를 오른쪽으로 3번(#(1)) 회전하고 왼쪽으로 3번(#(2)) 회전해 봅니다.\n\n```js\n# Codeblock 59\nprint(np.roll(AG, shift=3))     #(1)\nprint(np.roll(AG, shift=-3))    #(2)\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_51.png\" />\n\n<div class=\"content-ad\"></div>\n\n# 13. 형태와 변경\n\nPython 리스트에서는 len() 함수를 사용하여 요소의 개수를 알 수 있습니다. 그러나 이 방법은 다차원 배열에는 효과적이지 않을 수 있습니다. 다차원 배열에서는 len() 함수가 가장 바깥쪽 차원만을 세기 때문입니다. 아래의 코드 블록에서 len() 함수가 5를 반환하는 것을 볼 수 있습니다. 이는 전체 배열 차원을 나타내지 않습니다.\n\n```js\n# 코드 블록 60\nAH = np.array([[0,   1,  2,  3,  4,  5], \n               [6,   7,  8,  9, 10, 11], \n               [12, 13, 14, 15, 16, 17], \n               [18, 19, 20, 21, 22, 23], \n               [24, 25, 26, 27, 28, 29]])\n\nlen(AH)\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_52.png\" />\n\n<div class=\"content-ad\"></div>\n\nlen() 함수와 다르게 Numpy 배열의 shape 속성을 활용하면 더 정확한 결과를 얻을 수 있어요. 아래의 코드블록 61의 출력 결과를 보면 배열 AH가 5개의 내부 배열로 구성되어 있고, 각 내부 배열은 6개의 요소로 이루어져 있음을 알 수 있어요. 이를 이전 챕터에서 설명했던 대로 5×6 크기의 행렬로 생각할 수 있어요. 또는 이미지 처리에 관심이 있는 경우, 이는 높이가 5이고 너비가 6인 픽셀을 가진 이미지에 해당해요.\n\n```js\n# 코드블록 61\nAH.shape\n```\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_53.png)\n\nNumpy는 reshape() 메소드를 통해 배열의 모양을 변경할 수 있게 해줘요. 다음 예제에서는 AH를 사이즈 (3,10)으로 재구성하는 방법을 보여드릴게요.\n\n<div class=\"content-ad\"></div>\n\n```js\n# Codeblock 62\nAH.reshape(3,10)\n```\n\n![Image](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_54.png)\n\n배열을 재구성할 때 중요한 점은 재구성 전후의 총 요소 수가 일정해야 한다는 것입니다. 다시 말해, 배열 차원은 총 요소 수의 인수여야 합니다. 이 요구 사항을 충족하지 못하면 오류가 발생합니다.\n\n배열 재구성은 2D 배열에만 국한되지 않습니다. 아래 코드 블록에서 배열을 3D로 변환하는 예시를 보여드리겠습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n# 코드 블록 63\nAH.reshape(2,3,5)\n```\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_55.png)\n\n축에 대해 선택할 숫자를 확신할 수 없는 경우, 간단히 -1을 쓰면 Numpy가 해당 값을 자동으로 설정해줍니다. 그러나 한 번에 둘 이상의 -1을 전달할 수 없다는 점을 염두에 두세요.\n\n```js\n# 코드 블록 64\nAH.reshape(-1,5)\n```\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_56.png\" />\n\n다음은 또 다른 예시입니다. 이 경우에는 배열을 30행 1열로 설정했습니다.\n\n```js\n# 코드 블록 65\nAH.reshape(-1,1)\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_57.png\" />\n\n\n<div class=\"content-ad\"></div>\n\n만약 다차원 배열을 1차원 배열로 재구성하고 싶다면 flatten()이나 reshape(-1) 메소드를 사용할 수 있어요.\n\n```js\n# Codeblock 66\nAH.flatten()\n\n### 대안\n# AH.reshape(-1)\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_58.png\" />\n\n이 주제 외에도, 만약 배열에 빈 축을 추가하고 싶다면 np.newaxis를 사용할 수 있어요. 솔직히 말해서, 이 기술은 조금 직관적이지 않아요. 그래서, 제가 일반적으로 Codeblock 65에서 한 것과 같은 작업을 하는 데 np.reshape()를 사용해요.\n\n<div class=\"content-ad\"></div>\n\n\n# 코드 블록 67\nAH.flatten()[:, np.newaxis]\n\n### 대안\n# AH.flatten().reshape(-1,1)\n\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_59.png)\n\n아래는 np.newaxis에 대한 또 다른 예제입니다. 여기서는 행에 새로운 축을 추가하는 데 사용했습니다.\n\n\n# 코드 블록 68\nAH.flatten()[np.newaxis, :]\n\n### 대안\n# AH.flatten().reshape(1,-1)\n\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_60.png)\n\n# 14. Concatenation and Splitting\n\n파이썬 리스트에 새 요소를 추가하려면 append() 메소드를 사용할 수 있습니다. Numpy에서는 np.vstack(), np.hstack(), np.append(), np.concatenate()와 같은 다양한 대안이 있습니다. 이러한 함수들은 모두 여러 배열을 결합하는 것이라는 기본 아이디어를 가지고 있지만, 이러한 함수들은 각각 다른 용도를 가지고 있습니다.\n\n이 주제를 논의하기 전에 먼저 두 개의 새 배열 AI와 AJ를 초기화하고 싶습니다.\n\n\n<div class=\"content-ad\"></div>\n\n```js\n# 코드블록 69\nAI = np.array(np.random.randint(0, 5, (2,4)))\nAJ = np.array(np.random.randint(5, 10, (2,4)))\n\nprint(AI, end='\\n\\n')\nprint(AJ)\n```\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_61.png)\n\n두 배열을 수직으로 연결하여 결합하려면 np.vstack()을 사용할 수 있습니다.\n\n```js\n# 코드블록 70\nnp.vstack((AI,AJ))\n```\n\n<div class=\"content-ad\"></div>\n\n알수 있듯이, np.hstack()은 두 배열을 수평으로 쌓는 데 사용됩니다.\n\n```js\n# 코드 블록 71\nnp.hstack((AI, AJ))\n```\n\n<div class=\"content-ad\"></div>\n\nnp.vstack()과 np.hstack() 함수는 여러 배열을 한 번에 쌓을 수 있습니다. 주의할 점은 배열의 열 수가 동일한 경우 수직 스택이 가능하다는 것입니다. 수평 스택의 경우, 배열의 행 수가 동일할 때만 작동합니다.\n\n```js\n# 코드블록 72\nprint(np.vstack((AI,AJ,AJ,AJ,AI)), end='\\n\\n')\nprint(np.hstack((AI,AJ,AJ,AJ,AI)))\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_64.png\" />\n\n또한, np.append() 함수는 배열을 연결하기 전에 먼저 배열을 평평하게 만든 후 작동합니다. 따라서 결과적으로 얻는 출력물은 1차원 배열이 됩니다. 이 기본 동작과는 상관없이 np.append() 함수를 np.vstack() 및 np.hstack()와 동일하게 작동하도록 axis 매개변수를 사용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n# 코드 블록 73\nprint(np.append(AI, AJ), end='\\n\\n')\nprint(np.append(AI, AJ, axis=0), end='\\n\\n')\nprint(np.append(AI, AJ, axis=1))\n\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_65.png\" />\n\n사실 np.append() 함수는 한 번에 두 개 이상의 배열을 결합할 수 없습니다. 만약 그렇게 하고 싶다면 np.concatenate()를 사용할 수 있습니다. axis 매개변수도 np.append()와 동일하게 작동합니다. 만약 axis에 값을 지정하지 않으면 np.concatenate() 함수는 수직 스택을 수행합니다.\n\n\n# 코드 블록 74\nprint(np.concatenate([AI, AI, AI], axis=None), end='\\n\\n')\nprint(np.concatenate([AI, AI, AI]), end='\\n\\n')\nprint(np.concatenate([AI, AI, AI], axis=1))\n\n\n<div class=\"content-ad\"></div>\n\n<table> 태그를 Markdown 형식으로 바꿔보세요.\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_66.png\" />\n\n## Splitting\n\n스택에 사용되는 것뿐만 아니라 Numpy는 분할을 위한 몇 가지 함수도 제공합니다. 아래의 배열 AK를 고려해 봅시다.\n\n```js\n# Codeblock 75\nAK = np.random.randint(0, 10, (20))\nAK\n```\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_67.png)\n\nnp.split() 함수를 먼저 소개하겠습니다. 이 함수는 두 가지 주요 매개변수를 받습니다: ary (나눌 배열) 및 indices_or_sections (분할 지점). 다음 코드에서는 배열 AL을 인덱스 3과 5에서 나누어 세 개의 새 배열을 얻으려고 합니다. 각 배열은 원본 배열에서 0부터 2까지, 3부터 4까지, 5부터 19까지의 범위를 갖습니다.\n\n```js\n# 코드 블록 76\nnp.split(AK, indices_or_sections=[3,5])\n```\n\n![이미지](/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_68.png)\n\n\n<div class=\"content-ad\"></div>\n\n2D 배열을 나누려면 np.hsplit() 또는 np.vsplit()을 사용할 수 있습니다. 사실 np.split()에 축 매개변수를 전달하여 동일한 작업을 수행할 수도 있습니다. 주요 아이디어는 기본적으로 동일하지만, np.vsplit() 및 np.hsplit()을 사용하여 분할 지점은 각각 행 번호와 열 번호를 참조합니다. 이러한 두 함수를 배열 AL에 대해 시연하겠습니다.\n\n```js\n# 코드블록 77\nAL = np.random.randint(0, 10, (5,6))\nAL\n```\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_69.png\" />\n\n아래는 np.vsplit()을 사용하는 방법입니다.\n\n<div class=\"content-ad\"></div>\n\n\n# 코드 블록 78\nnp.vsplit(AL, [2,4])\n\n### 대안\n# np.split(AL, [2,4], axis=0)\n\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_70.png\" />\n\n마지막으로 np.hsplit() 사용법입니다.\n\n\n# 코드 블록 79\nnp.hsplit(AL, [3,4])\n\n### 대안\n# np.split(AL, [3,4], axis=1) #동등한\n\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_71.png\" />\n\n# 마무리\n\n드디어 끝났어요! 지금까지 저가 자주 사용하는 NumPy 함수들을 다뤄봤어요. 사실 더 설명하지 않은 기능들도 많이 남아 있어요. 하지만 걱정하지 마세요. 이제 모든 기초를 마스터했기 때문에 쉽게 배울 수 있을 거예요.\n\n읽어 주셔서 감사해요. 이 글이 유용했기를 바라며, 다음 글에서 만나요. 안녕히 계세요!\n\n<div class=\"content-ad\"></div>\n\n# 참고 자료\n\n[1] Universal functions (ufunc). NumPy. https://numpy.org/doc/stable/reference/ufuncs.html [접속일: 2024년 1월 8일].\n\n# 쉽게 이해하기 🚀\n\nIn Plain English 커뮤니티의 일원이 되어 주셔서 감사합니다! 떠나시기 전에:\n\n<div class=\"content-ad\"></div>\n\n- 작가를 칭찬하고 팔로우하려면 클랩을 눌러주세요! 👏\n- 팔로우하기: X | LinkedIn | YouTube | Discord | 뉴스레터\n- 다른 플랫폼에서 저희를 만나보세요: CoFeed | Differ\n- 더 많은 콘텐츠: PlainEnglish.io","ogImage":{"url":"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_0.png"},"coverImage":"/assets/img/2024-06-22-MasteringNumPyAComprehensiveGuidetoEfficientArrayProcessingPart22_0.png","tag":["Tech"],"readingTime":32},{"title":"세션 고정이란 무엇인가요 Nodejs에서 방지하는 방법","description":"","date":"2024-06-22 05:31","slug":"2024-06-22-WhatisSessionFixationandHowtoPreventitinNodejs","content":"\n\n세션 고정(Session Fixation) 공격자는 유효한 사용자 세션을 탈취할 수 있으므로 이 취약점과 그에 대한 보호에 대해 알아야 합니다.\n\n![이미지](/assets/img/2024-06-22-WhatisSessionFixationandHowtoPreventitinNodejs_0.png)\n\n이를 알아가기 전에 세션이란 무엇이고 세션 인증이 어떻게 작동하는지 알아야 합니다. 이미 알고 계시다면 \"세션 고정이란 무엇이며 세션 고정을 방지하는 방법\" 부분으로 건너뛸 수 있습니다.\n\n# 세션이란 무엇인가요?\n\n<div class=\"content-ad\"></div>\n\nHTTP 요청이 상태를 유지하지 않는다는 것을 알고 계셨을 것입니다. 즉, 로그인 요청을 보내고 유효한 사용자 이름과 비밀번호가 있는 경우, 다음 요청을 보내는 같은 사람임을 알 수 있는 기본 메커니즘이 없습니다. 이 문제를 해결하고 요청을 상태 유지할 수 있도록 하는 방법으로 쿠키, 숨김 폼 필드, URL 매개변수, HTML5 웹 스토리지, JWT 및 세션과 같은 제안된 방법이 있습니다. 이 문서에서는 세션에 초점을 맞추었습니다.\n\n세션은 서버에 저장된 데이터입니다. 각 클라이언트는 서버에 있는 이 데이터와 관련된 고유한 식별자를 받습니다. 클라이언트는 각 요청에 이 고유한 식별자를 보내야 합니다. 이를 통해 누가 이 요청을 보내는지 알 수 있습니다. 이 식별자는 쿠키나 URL 매개변수로 전송될 수 있습니다.\n\nexpressjs 애플리케이션에서 세션과 식별자 (세션 ID)를 표시하는 간단한 예제입니다:\n\n```js\nconst app = require('express')();\nconst session = require('express-session');\napp.use(require('cookie-parser')());\napp.use(require('body-parser').json());\n\napp.use(session({\n    secret: 'secret',\n    cookie: { maxAge: 60000 },\n    name: 'sessionId'\n}));\n\napp.get('/', (req, res) => {\n    res.send('ping');\n});\n\napp.listen(3000, () => {\n    console.log('Server is running on port 3000');\n});\n```\n\n<div class=\"content-ad\"></div>\n\n처음 요청을 보낼 때 express-session 미들웨어는 새로운 고유 식별자를 생성하고 이를 쿠키로 설정한 후 어딘가에 저장합니다(이 경우에는 메모리에 저장되지만 사용자 정의 저장소도 전달할 수 있습니다). 세션 미들웨어의 옵션에서 sessionId를 우리가 이 고유 식별자를 저장하는 키의 이름으로 사용했기 때문에 요청을 보내면 다음과 같은 결과를 볼 수 있습니다:\n\n![이미지](/assets/img/2024-06-22-WhatisSessionFixationandHowtoPreventitinNodejs_1.png)\n\n이제 브라우저는 이 쿠키를 설정하고 나중 요청을 위해 자동으로 저장합니다. 유효한 세션을 포함하는 요청을 보내면(세션은 세션 저장소에 존재함 - 이 경우에는 메모리에) 응답에 Set-Cookie 헤더가 반환되지 않습니다:\n\n![이미지](/assets/img/2024-06-22-WhatisSessionFixationandHowtoPreventitinNodejs_2.png)\n\n<div class=\"content-ad\"></div>\n\n사용자가 로그인하면 사용자 정보를 쿠키에 저장(직렬화)하거나 데이터베이스에 저장하고 데이터를 세션 ID와 연결할 수 있습니다. 우리는 맵을 데이터베이스로 사용해 보겠습니다:\n\n```js\nconst db = new Map();\napp.get('/me', (req, res) => {\n    const user = db.get(req.sessionID);\n    res.json({ mySessionId: req.sessionID, me: user ? user : 'anonymous' });\n});\nconst users = [{ name: 'bob', age: 19 }, { name: 'joe', age: 20 }];\napp.post('/login', (req, res) => {\n    const { name } = req.body;\n    const user = users.find(u => u.name === name);\n    if (user) {\n        db.set(req.sessionID, user);\n        res.send('ok');\n    } else {\n        res.send('try again');\n    }\n});\n```\n\n로그인한 다음 쿠키를 사용하여 /me로 다른 요청을 보내면 다음 결과를 얻습니다:\n\n![이미지](/assets/img/2024-06-22-WhatisSessionFixationandHowtoPreventitinNodejs_3.png)\n\n<div class=\"content-ad\"></div>\n\n이것은 세션을 사용해야 하는 이유와 그 방법을 간단히 요약한 것이었습니다.\n\n## 공격자가 유효한 세션 ID를 생성할 수 있나요?\n\nExpress-session을 사용하고 있는 경우에는 세션 미들웨어에 secret를 전달했음을 보았습니다. 이 secret는 쿠키 값에 서명을 하는 데 사용됩니다. 이것은 단순히 sessionId를 생성한 것이 우리임을 확신할 수 있도록 합니다. 클라이언트로 서명된 값을 보내고 있다면, 공격자가 세션 ID를 생성하는 것은 불가능합니다.\n\n세션의 샘플:\nsessionId=s%3AL6j4T8hBwMk1ulJqGoisZbAxUOkOuQqP.x5UxPQEtKrj3sWrIy6S01CQRjAtp4biVs4H2zgqmSs\n\n<div class=\"content-ad\"></div>\n\n첫 번째 부분: s%3A는 단순히 s:이라는 것을 의미합니다. 이는 우리의 쿠키-세션이 서명되었음을 나타내는 접두사입니다!\n\n두 번째 부분: L6j4T8hBwMk1ulJqGoisZbAxUOkOuQqP 이것은 세션 ID입니다. 데이터를 연관시키기 위해 데이터베이스에서 사용하고 있습니다.\n\n세 번째 부분: 이 부분은 세 번째 부분입니다. x5UxPQEtKrj3sWrIy6S01CQRjAtp4biVs4H2zgqmSs 이것은 서명 부분입니다. 이 텍스트는 우리의 비밀 정보를 사용하여 생성했으므로, 이 쿠키가 우리에 의해 생성되었음을 확신할 수 있습니다.\n\n우리는 이 서명을 간단히 다시 생성하고 이게 유효한지 확인할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n```js\nconst crypto = require('crypto');\nconst secret = 'secret';\nconst sessionId = 'L6j4T8hBwMk1ulJqGoisZbAxUOkOuQqP';\nconst hmac = crypto.createHmac('sha256', secret);\nhmac.update(sessionId);\nconst signature = hmac.digest('base64').replace(/\\=+$/, '');\nconsole.log(signature); // x5UxPQEtKrj3sWrIy6S01CQRjAtp4biVs4H2zgqmSs\n```\n\n이렇게 express-session이 확인하는 것이에요.\n\n# 세션 고정이란?\n\n세션 고정 공격에서 공격자는 유효한 사용자 세션을 탈취합니다. 쿠키를 서명하여 다른 사용자의 유효한 세션을 탈취할 수 없도록 하는 걸로 말씀드렸죠. 그런데 만약 공격자가 자신의 유효한 세션을 가지고 또 다른 사용자와 연관시키려고 한다면 어떨까요? 이 경우에 공격자는 피해자를 대신하여 작업을 수행할 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n문제는 로그인과 같은 작업에서 새로운 sessionId(고유 식별자)를 생성하지 않는 경우 발생합니다.\n\n## 공격자가 이를 어떻게 할 수 있을까요?\n\n공격자가 컴퓨터에 물리적으로 접근할 수 있는 경우가 있습니다. 예를 들어 공격자로서 대학에 가서 공유 컴퓨터 중 하나를 선택하고 취약한 웹사이트(vulnerablewebsite.com)에 내 계정으로 로그인한 다음 로그아웃을 하지 않고(일반적으로 서버 스토어에서 세션을 제거하는 작업), 취약한 웹사이트(vulnerablewebsite.com)에 로그인 페이지를 열어둔 채로, 그 전에 유효한 sessionId를 복사해야 합니다. 이제 피해자가 이 컴퓨터를 사용하고 있고 피해자가 로그인하면 공격자의 sessionId가 피해자의 계정에 연결됩니다. 복잡해 보일 수 있지만 전혀 그렇지 않습니다, 이를 실제로 확인해 봅시다.\n\n첫 번째 사용자인 Bob(공격자)로 로그인해 봅시다:\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-22-WhatisSessionFixationandHowtoPreventitinNodejs_4.png)\n\n이제 브라우저는이 웹 사이트에 대해 이 쿠키를 설정합니다. 다른 사람이 로그인 요청을 보내려고 시도하면 express-session이 새로운 세션 ID를 생성하지 않고 기존 세션 ID를 덮어쓰는 것을 의미합니다.\n\nJoe(피해자)가 이 공유 컴퓨터를 사용하기로 결정하면, Bob의 쿠키와 유효한 세션이 함께 전송된다:\n\n![이미지](/assets/img/2024-06-22-WhatisSessionFixationandHowtoPreventitinNodejs_5.png)\n\n\n<div class=\"content-ad\"></div>\n\n우리는 새 세션이나 쿠키를 받지 못했어요!\n\n이런 일이 일어나버렸어요. 이제는 밥의 세션 ID가 조의 사용자와 연관되어 있어요. 그래서, 공격자(밥)가 /me로 요청을 보내면 조의 데이터를 돌려받게 될 거에요:\n\n![이미지](/assets/img/2024-06-22-WhatisSessionFixationandHowtoPreventitinNodejs_6.png)\n\n밥의 세션을 이용해서 조의 데이터를 얻는 데 성공했어요. 이 예시에서 공격자는 물리적 접근이 있었지만, XSS와 같은 다른 취약점이 있는 경우 물리적 접근 없이도 이를 할 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n일부 웹사이트는 요청 시 URL 매개변수로 sessionId를 전달합니다. 이 경우, 공격자가 URL 매개변수에 자신의 sessionId를 포함한 로그인 페이지 링크를 제공하면 악용 가능성이 있습니다.\n\n![이미지](/assets/img/2024-06-22-WhatisSessionFixationandHowtoPreventitinNodejs_7.png)\n\n이 방법의 보안 도전 과제에 대해 더 알고 싶다면, 스택 익스체인지 질문에서 확인하세요.\n\n# 세션 고정 방지 방법\n\n<div class=\"content-ad\"></div>\n\n## 로그인 시 새 세션 생성!\n\n메인 솔루션은 정말 쉬운데, 그렇게 하면 항상 이 세션 덮어쓰기가 발생하지 않는지 확신할 수 있어요!\n\n우리 코드를 다음과 같이 변경해요:\n\n```js\napp.post('/login', (req, res) => {\n    const { name } = req.body;\n    req.session.regenerate(err => {\n        if (err) {\n            res.send('error');\n        } else {\n            const user = users.find(u => u.name === name);\n            if (user) {\n                db.set(req.sessionID, user);\n                res.send('ok');\n            } else {\n                res.send('try again');\n            }\n        }\n    });\n});\n```\n\n<div class=\"content-ad\"></div>\n\n로그인할 때마다 새로운 세션을 할당하기 위해 regenerate 함수를 사용할 수 있습니다. 이제 세션 쿠키를 전달하든 말든 상관없이 새로운 세션 ID를 생성하여 Set-Cookie 헤더를 통해 클라이언트에게 전송합니다.\n\n![이미지](/assets/img/2024-06-22-WhatisSessionFixationandHowtoPreventitinNodejs_8.png)\n\n## 오직 HTTP Only 쿠키를 사용하세요\n\nHTTP Only를 사용하면 서버만 Set-Cookie 헤더를 통해 쿠키를 설정할 수 있고 클라이언트 측 (브라우저 JavaScript)는 변경할 수 없습니다. 따라서 앱에 XSS 취약점이 있는 경우에도 공격자는 세션 ID (쿠키)를 변경할 수 없습니다.\n\n<div class=\"content-ad\"></div>\n\n## XSS 공격으로부터 보호하기\n\n세션 고정을 XSS 공격과 결합하여 더 효과적으로 사용할 수 있으므로 세션 고정에 대해 걱정한다면 XSS 공격에도 심각하게 대응하는 것이 좋습니다.\n\n## 합리적인 세션 만료 시간\n\n세션 만료 시간은 애플리케이션의 특정 요구 사항과 일치해야 합니다. 보안에 더 많은 관심을 가진다면 짧게 설정하는 것이 좋습니다. 반대로, 그렇지 않다면 더 길게 설정할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n## 올바른 로그아웃 구현\n\n로그아웃 시 기존 세션을 올바르게 제거하여 관련 데이터와의 연결을 끊어야 합니다. 그렇지 않으면 로그아웃 이후에도 이 세션을 사용할 수 있습니다. (클라이언트 브라우저에서 쿠키를 제거하는 것만으로는 충분하지 않습니다!)\n\n# Passportjs가 세션 결정에 취약했나요?\n\n네, 0.6.0 버전 이전에는 이 문제가 있었습니다. Passport 개발자들은 세션 재생성을 애플리케이션 측에서 수행해야 한다고 생각했지만, 얼마 지나지 않아 이 문제의 중요성을 깨달았고 0.6.0 버전에서 수정되었습니다. 이 수정의 자세한 내용에 관심이 있다면 여기에서 자세한 내용을 읽을 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n세션 고정이 발생할 수 있습니다. 기존 세션 ID를 다른 사용자 데이터로 덮어쓸 경우 발생할 수 있습니다. 이 문제를 해결하는 방법은 매번 누군가 로그인할 때마다 새 세션을 생성하고, HTTP Only 쿠키를 사용하며, 적절한 만료 시간을 설정하고, 올바른 로그아웃을 구현하는 것입니다.\n\n# 참고 자료\n\n[OWASP - 세션 고정](https://owasp.org/www-community/attacks/Session_fixation#)\n\n<div class=\"content-ad\"></div>\n\nhttps://developer.mozilla.org/ko/docs/Web/Security/Types_of_attacks#session_fixation","ogImage":{"url":"/assets/img/2024-06-22-WhatisSessionFixationandHowtoPreventitinNodejs_0.png"},"coverImage":"/assets/img/2024-06-22-WhatisSessionFixationandHowtoPreventitinNodejs_0.png","tag":["Tech"],"readingTime":8},{"title":"V8 자바스크립트 엔진의 모든 것 속도, 기능, 사용법","description":"","date":"2024-06-22 05:30","slug":"2024-06-22-TheV8JavaScriptEngine","content":"\n\n## Node.js 내부 심층 분석\n\n![이미지](/assets/img/2024-06-22-TheV8JavaScriptEngine_0.png)\n\n안녕하세요! 이 글은 고급 Node.js를 위한 시니어 엔지니어 시리즈의 첫 번째 글입니다. 이 글에서는 V8 엔진에 대한 자세한 설명과 작동 방식에 대해 설명하겠습니다. 고급 Node.js를 위한 시니어 엔지니어 시리즈의 다른 글은 아래에서 찾아볼 수 있습니다:\n\n```js\n포스트 시리즈 로드맵\n\n* The V8 JavaScript Engine (이 글)\n* Node.js의 비동기 IO\n* Node.js의 이벤트 루프\n* Worker Threads: Node.js의 멀티태스킹\n* Child Processes: Node.js의 멀티태스킹\n* 클러스터링 및 PM2: Node.js의 멀티태스킹\n* 흔한 Node.js 오해 해소\n```\n\n<div class=\"content-ad\"></div>\n\n\n내용 목차\n\n* V8를 선택한 이유는?\n* Node.js에서 어떻게 사용되는가?\n* V8는 어떻게 작동하는가?\n* 자체적인 JavaScript 런타임 만들기\n\n\n우리는 Node.js의 가장 낮은 수준에 도달했는데, 여기서는 사물이 혼란스럽고 복잡해집니다. JavaScript는 동적으로 타입이 지정되고 해석되는 언어이며, 우리가 JavaScript에서 실행하는 모든 것은 엔진에 전달됩니다. 그런 다음 엔진은 환경과 상호 작용하여 기계가 프로그램을 실행할 수 있도록 필요한 바이트 코드를 생성합니다. 이를 담당하는 엔진은 Google에서 개발한 오픈 소스 고성능 JavaScript 및 WebAssembly 엔진인 V8입니다. V8는 C++로 작성되었으며 Chrome(또는 유사한 환경)과 Node.js에서 모두 사용됩니다. V8는 ECMAScript와 WebAssembly를 완전히 지원합니다. 흥미로운 점은 V8가 브라우저에만 제한되지 않고 독립적으로 실행되어 모든 C++ 애플리케이션에 임베드될 수 있다는 것입니다.\n\n# V8를 선택한 이유는?\n\n<img src=\"/assets/img/2024-06-22-TheV8JavaScriptEngine_1.png\" />\n\n\n<div class=\"content-ad\"></div>\n\n더 낮은 레벨에 있을수록 더 많은 책임이 있습니다. C/C++을 어셈블리어(assembly)로 변환하기 위해서는 컴파일러가 필요합니다. 어셈블리를 기계어로 변환하기 위해서는 어셈블러(assembler)가 필요합니다. 그래서 Js를 실행 가능한 코드로 변환하기 위해서는 JS 엔진이 필요합니다. Firefox에서 Spidermonkey를 사용했으며 이후 Google Chrome에서 사용하기 위해 V8이 만들어졌고, 현재 Nodejs에서 사용되고 있습니다.\n\nSpidermonkey와 V8 사이의 주목할만한 차이점은, 코드를 바이트코드(bytecode는 기계 코드의 추상화)로 변환한 후 중간 언어로, 그리고 기계 코드로 변환해야 한다는 것입니다. 이것이 Spidermonkey의 작동 방식입니다. 그러나 V8은 JS를 바로 기계 코드로 변환합니다.\n\n# Nodejs에서는 어떻게 사용되는가?\n\nV8 코드 소스 코드를 살펴보면 객체, JSON, 날짜 등의 구현을 찾을 수 있지만 Chrome에서 사용되는 document 객체나 Nodejs에서 사용되는 require()와 같은 요소는 찾을 수 없을 것입니다. 왜냐하면 Nodejs와 Chrome은 이러한 새로운 기능을 C++에서 구현하고 V8을 통해 JavaScript 함수에 바인딩하기 때문입니다. 왜 이렇게 하는 걸까요? 앞서 말했듯이, 더 낮은 수준은 더 많은 책임과 권한을 의미합니다. 그래서 C/C++은 네트워크 카드와 같은 저수준 자원에 액세스하고 활용하는 방법이 있습니다. 그래서 JS는 cpp를 사용하여 자신이 원하는 작업을 수행합니다. 이에 따라 NodeJS 소스 코드에는 V8이 아닌 required가 나타납니다.\n\n다른 사람들도 자신의 사용 사례를 위해 동일한 작업을 수행할 수 있기 때문에 JavaScript가 많은 곳에서 사용되고 있는 이유입니다. 예를 들어, 자신의 cpp 기능 구현을 생성하고 이를 이동 오른쪽, 왼쪽과 같은 js 함수에 바인딩하여 로봇 공학에서 JavaScript를 사용하고 있습니다. 이에 따라 V8은 이 특정 사용 사례에 적합하지 않을 수 있으며, Duktape 또는 Jerryscript JS 엔진이 더 나은 선택일 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nNode.js에서 V8은 결국 종속성이 되는데, 이는 공식 웹사이트에서 확인할 수 있어요.\n\n![V8 GIF](https://miro.medium.com/v2/resize:fit:448/1*YPcaZUJzouB2OhVpyzxv6w.gif)\n\n# V8 작동 방식\n\n![V8](/assets/img/2024-06-22-TheV8JavaScriptEngine_2.png)\n\n<div class=\"content-ad\"></div>\n\nV8 엔진은 코드를 두 단계로 컴파일합니다. 먼저 빠르지만 최적화되지 않은 기계 코드로 컴파일하는 단계가 있습니다. 이는 충분히 시작하는 데 도움이 됩니다. 이 과정이 진행되는 동안 뒤에서 매우 최적화된 코드를 생성하는 느린 컴파일이 이루어집니다. 이렇게 생성된 느린 컴파일된 코드가 작성되면 Javascript는 이 최적화된 코드로 전환됩니다. 이 두 단계는 Ignition(빠르고 저수준 레지스터 기반 해석기)와 Turbofan(최적화 컴파일러)로 알려져 있습니다. Just-in-Time (JIT) 컴파일이라는 새로운 접근 방식이 만들어졌습니다. 이는 해석과 컴파일의 장점을 결합한 것입니다.\n\nV8는 Ignition이라는 해석기를 사용합니다. 먼저 추상 구문 트리를 받아 바이트 코드를 생성합니다. Ignition은 어느 정도 진행되지만, 함수가 충분히 최적화된 경우 컴파일러인 Turbofan을 통해 빠르게 만들어집니다.\n\n단계별로 살펴보겠습니다:\n\n- V8이 원시 코드를 구문 분석하여 Abstract Syntax Tree (AST)로 변환합니다. V8은 JS 코드를 이해하지 못하기 때문에 이 형태로 만들어야 합니다. 그리고 스코프도 생성됩니다.\n- 그 AST 및 스코프를 바탕으로 Ignition 해석기는 바이트 코드를 생성할 수 있습니다.\n- 엔진이 코드를 실행하고 타입 피드백을 수집하기 시작합니다. (실행 단계에서 코드에 대한 타입 피드백을 제공합니다.)\n- 코드를 더 빠르게 실행하기 위해 바이트 코드를 최적화하는 컴파일러에 타입 피드백 데이터와 함께 전달할 수 있습니다. 최적화 컴파일러는 이를 기반으로 가정을 설정하고 고효율의 머신 코드를 생성합니다. 이 과정은 병렬로 이루어지며 V8은 자주 사용되는 바이트 코드를 \"핫\" 코드로 표시하여 더 효율적인 머신 코드로 변환합니다. 그러나 바이트 코드 대신 머신 코드를 바로 사용하는 이유는 다음과 같습니다.\n- 머신 코드는 많은 메모리를 필요로 합니다.\n- 머신 코드가 항상 바이트 코드보다 빠르지 않습니다. 머신 코드는 컴파일하는 데 시간이 오래 걸리지만 실행 단계에서는 빠릅니다. 반면 바이트 코드는 컴파일하는 데 더 적은 시간이 필요하지만 실행 단계는 느립니다.\n- 어떤 가정이 잘못된 경우 최적화 컴파일러는 비최적화를 수행하고 해석기로 돌아갑니다.\n\n<div class=\"content-ad\"></div>\n\n# 자체 JavaScript 런타임 만들기\n\n자체 JS 런타임을 만들거나 이것이 가능한지 확인해보고 싶다면, 제가 최근에 만든 자체 JavaScript 런타임을 확인해보세요! 놀라운 V8 자바스크립트 엔진과 Libuv로 구동됩니다. V8, Libuv 및 C++로 구축된 기초 위에 놓여 있는데, 저는 강력한 Node.js를 처음부터 다시 만들기 위해 떠났습니다. JavaScript 런타임 개발의 세계로 깊이 파고들며 함께해 주세요.\n\n# 떠나시기 전에!\n\n- 더 많은 통찰을 기다려주세요! 팔로우하고 구독해 주세요.\n- 👏 버튼을 클릭하고 누르고 있는 동안 생기는 일을 보셨나요?","ogImage":{"url":"/assets/img/2024-06-22-TheV8JavaScriptEngine_0.png"},"coverImage":"/assets/img/2024-06-22-TheV8JavaScriptEngine_0.png","tag":["Tech"],"readingTime":4},{"title":"Nodejs에서 스트림 사용하는 방법 2024 트렌드","description":"","date":"2024-06-22 05:29","slug":"2024-06-22-StreamsinNodejs","content":"\n\n<img src=\"/assets/img/2024-06-22-StreamsinNodejs_0.png\" />\n\n새로운 웹 개발자들에게는 메모리 관리와 데이터 스트리밍 같은 개념이 무서울 수 있습니다. 이러한 내용은 보통 웹 개발 튜토리얼의 일부가 아니지만, 인터넷에서 가장 인기 있는 사이트 중 일부에 필수적입니다: YouTube, Netflix, Spotify와 같은 스트리밍 사이트들이 있습니다.","ogImage":{"url":"/assets/img/2024-06-22-StreamsinNodejs_0.png"},"coverImage":"/assets/img/2024-06-22-StreamsinNodejs_0.png","tag":["Tech"],"readingTime":1},{"title":"2024년 최고의 Nodejs 백엔드 프레임워크 5가지","description":"","date":"2024-06-22 05:27","slug":"2024-06-22-Top5NodejsBackendFrameworksin2024","content":"\n\n## 2024년 API를 구축하기 위해 Hapi, Express.js, NestJS, Koa.js 및 Adonis.js를 탐험해보세요\n\n# 소개\n\nNode.js는 2009년 이후로 핫한 주제였으며 대부분의 백엔드 개발자들은 Node.js를 선호합니다. 그 인기는 지난 몇 년간 계속 증가해 왔습니다.\n\n![이미지](/assets/img/2024-06-22-Top5NodejsBackendFrameworksin2024_0.png)\n\n<div class=\"content-ad\"></div>\n\n인기 증가의 이유는 로딩 시간의 감소와 성능 향상 때문입니다. 따라서, 2024년을 위한 상위 5개 Node.js 백엔드 프레임워크를 분석하는 것이 중요합니다.\n\n따라서 이 기사에서는 2024년을 위한 상위 5개 Node.js 백엔드 프레임워크, 그들의 특징, 그리고 일반적인 사용 사례에 대해 다룰 것입니다.\n\n![image](/assets/img/2024-06-22-Top5NodejsBackendFrameworksin2024_1.png)\n\n# Express.js: 검증된 챔피언\n\n<div class=\"content-ad\"></div>\n\n![Express.js](/assets/img/2024-06-22-Top5NodejsBackendFrameworksin2024_2.png)\n\nExpress.js는 Node.js의 가장 유명한 백엔드 프레임워크 중 하나입니다. 오픈 소스 웹 어플리케이션 프레임워크로, Node.js 플랫폼 위에 만들어져 있어 무료로 이용할 수 있습니다. Express.js는 미니멀한 프레임워크이기 때문에 초보자부터 경험이 풍부한 웹 개발자들이 선호합니다. 웹 애플리케이션 및 RESTful API를 작성하는 데 주로 사용됩니다.\n\n# 주요 기능: 높은 효율의 라우팅\n\n<div class=\"content-ad\"></div>\n\nExpress.js는 다양한 HTTP 요청을 관리하고 특정 작업에 할당하는 간단하고 깔끔한 방법을 제공합니다. 아래 예제를 살펴봅시다.\n\n```js\n// app.js\nconst express = require('express');\nconst app = express();\nconst port = 3000;\n\n// 홈페이지 라우트\napp.get('/', (req, res) => {\n  res.send('홈페이지에 오신 것을 환영합니다!');\n});\n\n// 사용자 라우트\napp.get('/user/:id', (req, res) => {\n  const userId = req.params.id;\n  res.send(`사용자 프로필 페이지 - ID: ${userId}`);\n});\n```\n\n2. 미들웨어 지원\n\nExpress.js는 HTTP 요청을 처리하기 위한 미들웨어 지원을 제공합니다. HTTP 요청 세부 정보를 기록하는 미들웨어를 만드는 간단한 예제를 살펴봅시다.\n\n<div class=\"content-ad\"></div>\n\n```js\nconst express = require('express');\nconst app = express();\nconst port = 3000;\n\napp.use((req, res, next) => {\n  console.log(`[${new Date().toLocaleString()}] ${req.method} ${req.url}` );\n  next();\n});\n```\n\n3. 쉬운 데이터베이스 통합\n\nExpress.js는 데이터베이스에 구애받지 않습니다. 특정 데이터베이스 선택을 강요하지 않습니다. 개발자들은 원하는 데이터베이스를 선택할 수 있습니다. Express.js와 데이터베이스를 통합시키는 것은 모듈식이고 유연한 성질과 데이터베이스 연결을 제공하는 npm 패키지의 풍부한 생태계 덕분에 쉽습니다.\n\n4. 배우기 쉽습니다\n\n\n<div class=\"content-ad\"></div>\n\nExpress.js는 간결하고 최소주의 디자인으로 유명하며, 특히 JavaScript와 Node.js에 익숙한 개발자들에게 배우기 쉬운 것으로 알려져 있어요.\n\n게다가 Bit와 같은 도구를 사용하여 Express.js를 쉽게 시작할 수 있어요. Bit는 추가 구성 가능한 소프트웨어를 위한 차세대 빌드 시스템입니다.\n\n예를 들어 미들웨어 구성 요소를 만들어 필요할 때마다 끼워 넣거나 빼낼 수 있어요.\n\n![이미지](/assets/img/2024-06-22-Top5NodejsBackendFrameworksin2024_3.png)\n\n<div class=\"content-ad\"></div>\n\n제목: Bit 및 독립 컴포넌트를 사용하여 설계된 Express API의 범위\n\n두 개의 컴포넌트를 볼 수 있어요: Authorizer와 API 앱입니다. 이 두 컴포넌트는 독립적인 Bit 컴포넌트로 구현되어 있으며 별도의 공간에서 유지 및 버전 관리됩니다.\n\n이렇게 함으로써 앱을 조합 가능한 방식으로 빠르게 설계할 수 있어요!\n\n이 완벽한 구현을 보려면 Bit Scope를 확인해주세요.\n\n<div class=\"content-ad\"></div>\n\n# NestJS: 현대적이고 체계적인 방법\n\n![image](/assets/img/2024-06-22-Top5NodejsBackendFrameworksin2024_4.png)\n\nNestJS는 확장 가능하고 효율적인 Node.js 서버 측 애플리케이션을 구축하는 데 알려진 프레임워크입니다. Progressive JavaScript를 사용하며 TypeScript로 코드를 작성할 수 있는 기능을 갖추고 있습니다. TypeScript를 완전히 지원하지만, 순수 JavaScript로 코드를 작성할 수 있으며 객체지향 프로그래밍, 함수형 프로그래밍 및 함수형 반응형 프로그래밍을 포함하고 있습니다.\n\n# 주요 기능: 높게 평가되는 이유\n\n<div class=\"content-ad\"></div>\n\n1. 모듈성\n\nNest.js는 코드를 별도의 관리 가능한 모듈로 분할할 수 있어 유지 보수가 더 쉬워집니다. 예를 들어 아래 모듈을 살펴봅시다.\n\n```js\nimport { Module } from '@nestjs/common';\n\n@Module({\n imports: [\n  CacheModule\n ],\n controllers: [PaymentController],\n providers: [PaymentService],\n})\nexport class PaymentModule {}\n```\n\n이 결제 모듈은 다른 모듈로 내보낼 수 있습니다. 이 예시에서는 이 모듈 내에서 공통 캐시 모듈을 내보냈습니다. Nest.js는 모듈 구조를 가지고 있기 때문에 관리가 용이합니다.\n\n<div class=\"content-ad\"></div>\n\n### 2. 확장 가능성\n\nNest.js는 어플리케이션을 관리 가능한 모듈로 분할하여 확장을 용이하게 합니다. 유연한 컴포넌트 교체를 지원하며, 마이크로서비스 및 비동기 작업을 통해 고트래픽을 처리할 수 있습니다. 늘어난 작업 부하를 효율적으로 처리하면서도 안정성을 유지합니다.\n\n### 3. 의존성 주입\n\n의존성 주입은 외부 종속성을 클래스 내부에서 생성하는 대신 클래스에 추가하는 간단한 방법입니다. 예제를 살펴보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nimport {\n HttpException, Injectable, NotFoundException\n} from '@nestjs/common';\n\n@Injectable()\nexport class PaymentService {\n\n constructor() {}\n\n getReceipt() {\n   return 'Payment Receipt';\n }\n\n}\n```\n\n저희는 결제 서비스를 만들었고 @Injectable() 어노테이션을 추가하여 주입 가능하게 만들었습니다. 아래와 같이 만들어진 서비스를 사용할 수 있습니다.\n\n```js\nimport { Controller, Get, Post, Body } from '@nestjs/common';\nimport { PaymentService } from './payment.service';\n@Controller('payment')\nexport class PaymentController {\n constructor(private readonly paymentService: PaymentService) {}\n@Get()\n getPaymentReceipt() {\n return this.paymentService.getReceipt();\n }\n}\n```\n\n4. 타입 안전성\n\n<div class=\"content-ad\"></div>\n\n`Nest.js`에서는 TypeScript를 사용하여 유형 안전성을 제공하며, 개발 중 잠재적인 오류를 찾아내고 코드 유지보수성을 개선하는 데 사용할 수 있습니다. 예를 살펴봅시다.\n\n```js\nexport class PaymentDto {\n\n  @IsNotEmpty()\n  @IsEnum(SERVICE_PROVIDER_SLUG, {\n    message: `Invalid serviceProvider. Valid options are: ${Object.values(SERVICE_PROVIDER_SLUG).join(', ')}`,\n  })\n  serviceProvider: string;\n\n  @IsNotEmpty()\n  @IsNumber()\n  value: number;\n\n  @IsNotEmpty()\n  @IsString()\n  validityPeriod: string;\n\n  @IsNotEmpty()\n  @IsArray()\n  @ArrayNotEmpty()\n  @ValidateNested()\n  @Type(() => PaymentAttributesDto)\n  paymentAttributes: PaymentAttributesDto[]\n\n}\n```\n\n이 예시에서, 우리는 여러 매개변수를 포함하는 DTO를 생성하고 매개변수 유형을 유효성 검사하는 어노테이션을 추가했습니다. 예를 들어, \"value\" 매개변수에 문자열 값을 보내면 오류가 발생합니다.\n\n# Koa.js: 우아하고 가벼운\n\n<div class=\"content-ad\"></div>\n\n\n<img src=\"/assets/img/2024-06-22-Top5NodejsBackendFrameworksin2024_5.png\" />\n\nKoa.js는 Express.js 팀이 설계한 더 작고 표현력 있는 웹 프레임워크입니다. 이를 사용하면 콜백을 버릴 수 있고 async 함수를 활용하여 오류를 처리할 수 있습니다.\n\n# 주요 기능: 눈에 띄는 특징\n\n1. 컨텍스트 객체(ctx)\n\n\n<div class=\"content-ad\"></div>\n\nKoa.js에는 요청과 응답 세부 사항을 캡처하는 ctx라는 기능이 포함되어 있습니다. 이 컨텍스트는 각 미들웨어에 전달됩니다. 이 예시에서는 ctx 객체에서 메서드와 요청을 기록했습니다.\n\n```js\nconst Koa = require('koa');\nconst app = new Koa();\n\napp.use(async (ctx) => {\n  const { method, url, request, response } = ctx;\n  console.log('Method :' + method + ' Request : ' + request);\n});\n\napp.listen(3000);\n```\n\n2. 미들웨어 조합\n\nExpress Js와 유사하게, Koa는 HTTP 요청과 응답을 처리하기 위한 미들웨어 함수를 지원합니다. 이 예시에서는 간단한 미들웨어를 만들었습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nconst Koa = require('koa');\nconst app = new Koa();\n\napp.use(async (ctx, next) => {\n  await next(); \n});\n\napp.listen(3000);\n```\n\n3. Async/Await Support\n\nKoa는 비동기 코드를 더 동기적으로 보이게 작성하기 위해 async/await 구문을 사용합니다. 아래 예제는 async/await 키워드를 사용하는 예시입니다.\n\n```js\nconst Koa = require('koa');\nconst app = new Koa();\n\napp.use(async (ctx) => {\n  const data = await fetchData();\n  ctx.body = `Data: ${data}`;\n});\n\napp.listen(3000);\n```\n\n<div class=\"content-ad\"></div>\n\n4. 오류 처리\n\nKoa.Js는 다양한 종류의 오류 처리를 지원합니다. 오류를 처리하기 위해 app.emit() 또는 ctx.throw()를 사용할 수 있습니다. 아래 예시는 언급된 오류 처리 방법을 포함하고 있습니다.\n\n```js\nconst koa = require('koa');\nconst app = new koa();\n\n// 오류 처리 방법 1\napp.use(async (ctx, next) => {\n  try {\n    await Promise.reject('문제가 발생했습니다');\n  } catch (err) {\n    ctx.status = err.status || 500;\n    ctx.body = err.message;\n    ctx.app.emit('error', err, ctx);\n  }\n});\n\n// 오류 처리 방법 2\napp.use(async (ctx, next) => {\n  ctx.throw(500, '에러');\n});\n\napp.on('error', (err, ctx) => {\n  console.log(err);\n});\n\napp.listen(3000);\n```\n\n# Hapi.js\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-22-Top5NodejsBackendFrameworksin2024_6.png\" />\n\nHapi.js는 Http-API를 축약한 것으로, 확장 가능한 웹 애플리케이션을 개발하기 위한 오픈 소스 프레임워크입니다. hapi의 가장 기본적인 사용 사례 중 하나는 REST API를 구축하는 것입니다.\n\n# 주요 기능: 뛰어나게 만드는 요소\n\n1. 구성 중심 설계\n\n<div class=\"content-ad\"></div>\n\nHapi.js의 구성 객체를 사용하면 라우트, 설정 및 플러그인을 설정할 수 있습니다.\n\n```js\nconst Hapi = require('@hapi/hapi');\n\nconst server = Hapi.server({\n  port: 3000,\n  routes: {\n    cors: true,\n  },\n});\n\nserver.route({\n  method: 'GET',\n  path: '/',\n  handler: (request, h) => {\n    return 'Hello, Hapi!';\n  },\n});\n\nasync function start() {\n  await server.start();\n  console.log('서버가 ${server.info.uri}에서 실행 중');\n}\n\nstart();\n```\n\n2. 강력한 플러그인 시스템\n\nHapi.js는 플러그인을 간편하게 통합할 수 있는 기능을 제공합니다. 다음 예제를 살펴봅시다.\n\n<div class=\"content-ad\"></div>\n\n```js\nconst start = async function () {\n\n    const server = Hapi.server();\n\n    await server.register([{\n        plugin: require('plugin1'),\n        options: {}\n    }, {\n        plugin: require('plugin2'),\n        options: {}\n    }]);\n};\n```\n이 예제에서는 두 개의 플러그인이 통합되었습니다. 옵션은 options 키를 사용하여 플러그인에 전달할 수 있습니다.\n\n3. 인증 및 권한\n\nHapi.js는 다양한 인증 전략에 대한 내장 지원을 제공하며, 개발자들이 쉽게 액세스 제어 정책을 정의할 수 있도록 합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nserver.route({\n  method: 'GET',\n  path: '/private-data',\n  handler: (request, h) => {\n    // 인증된 경우에만 개인 데이터에 액세스합니다\n    const user = request.auth.credentials;\n    return `환영합니다, ${user.username}!`;\n  },\n  options: {\n    auth: 'jwt', // JWT 인증 전략 사용\n  },\n});\n```\n\n이 예제를 기반으로하여, 우리는 인증 전략을 'jwt'로 직접 정의할 수 있습니다.\n\n4. 입력 유효성 검사\n\n입력 유효성 검사는 hapi.js의 또 다른 중요한 측면입니다. route의 options 객체에서 어떤 입력을 검증해야 하는지 정의할 수 있습니다. 기본 validate 객체는 아래 값으로 구성됩니다.\n\n\n<div class=\"content-ad\"></div>\n\n```js\n{ \n   headers: true, \n   params: true, \n   query: true, \n   payload: true, \n   state: true, \n   failAction: 'error'\n}\n```\n\n# Adonis.js\n\n![Adonis.js Logo](/assets/img/2024-06-22-Top5NodejsBackendFrameworksin2024_7.png)\n\nAdonis.js는 Node.js를 위한 전체 기능을 갖춘 MVC 프레임워크입니다. 확장 가능하고 유지 보수 가능한 애플리케이션을 구축할 수 있습니다. Adonis.js는 Laravel과 유사한 구조를 따르며 ORM, 인증 및 라우팅과 같은 기능을 기본 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n# 핵심 기능: 두드러지는 이유\n\n1. 풀 스택 MVC 프레임워크\n\nAdonis.js는 MVC 아키텍처 패턴을 따릅니다. MVC 프레임워크를 사용하면 코드를 조직화하고 유지 관리하고 확장하기 쉬워집니다.\n\n2. 데이터베이스 상호 작용을 위한 통합된 ORM(Lucid)\n\n<div class=\"content-ad\"></div>\n\nAdonis.js는 Lucid라는 자체 ORM을 가지고 있어요. Lucid는 표현적인 쿼리 빌더를 제공하며 다양한 데이터베이스 시스템을 지원해요. Lucid에서는 데이터베이스에 읽고 쓰기 위해 모델을 생성할 수 있어요. 아래 예시를 살펴보세요.\n\n```js\nconst Model = use('Model')\n\nclass User extends Model {\n}\n\nmodule.exports = User\n```\n\n우리는 이 사용자 모델을 데이터베이스 쿼리 대신 사용하고 있어요. 이제 라우트를 생성하는데, 해당 내부에서 사용자를 가져오고 있어요. 사용자를 가져오기 위해, 간단히 `User.all()`을 사용할 수 있어요.\n\n```js\nconst Route = use('Route')\nconst User = use('App/Models/User')\n\nRoute.get('users', async () => {\nreturn await User.all()\n})\n```\n\n<div class=\"content-ad\"></div>\n\n3. 인증 시스템\n\nAdonis.js에는 사용자 인증 및 권한 부여를 위한 기본 지원이 있습니다. 사용자 세션, 비밀번호 해싱, 및 접근 제어를 다루는 일련의 메서드와 미들웨어를 제공합니다.\n\n# 결론\n\n2024년에는 위에서 언급한 백엔드 프레임워크들이 시장에서 높은 위치를 차지하고 있습니다.\n\n<div class=\"content-ad\"></div>\n\nExpress.js는 간결함 때문에, Nest.js는 구조 때문에, Adonis.js는 생산성 때문에, Koa.js는 우아함 때문에 선택했을지라도, 올바른 프레임워크를 선택하는 것이 중요합니다.\n\n또한, 2024년에 성공적인 백엔드 개발 여정을 하려면 최신 트렌드, 기존 프레임워크의 새로운 기능, 그리고 새로운 프레임워크를 찾는 것이 중요합니다.\n\n# 더 알아보기","ogImage":{"url":"/assets/img/2024-06-22-Top5NodejsBackendFrameworksin2024_0.png"},"coverImage":"/assets/img/2024-06-22-Top5NodejsBackendFrameworksin2024_0.png","tag":["Tech"],"readingTime":10},{"title":"Nodejs 마스터하기 고급 개발 및 성능 향상 팁","description":"","date":"2024-06-22 05:26","slug":"2024-06-22-NodejsMasteryAdvancedDevelopmentPerformanceTips","content":"\n\n![이미지](/assets/img/2024-06-22-NodejsMasteryAdvancedDevelopmentPerformanceTips_0.png)\n\n프론트엔드 열정가인 당신, 백엔드 개발의 세계로 다이빙하시나요? 🤔 Node.js의 복잡한 풍경을 통해 즐거운 여정을 준비하세요! 🎢\n\n이 모험에서는 Node.js 프레임워크를 사용하여 백엔드를 빠르게 만들고 성능 분석, 테스트, 메모리에 대해 심층적으로 다루는 백엔드의 수많은 이야기를 탐험할 겁니다...","ogImage":{"url":"/assets/img/2024-06-22-NodejsMasteryAdvancedDevelopmentPerformanceTips_0.png"},"coverImage":"/assets/img/2024-06-22-NodejsMasteryAdvancedDevelopmentPerformanceTips_0.png","tag":["Tech"],"readingTime":1},{"title":"MongoDB에서 PostgreSQL로 대규모 전환 가이드","description":"","date":"2024-06-22 05:24","slug":"2024-06-22-TheGreatMigrationfromMongoDBtoPostgreSQL","content":"\n\n![이미지](/assets/img/2024-06-22-TheGreatMigrationfromMongoDBtoPostgreSQL_0.png)\n\n지난 해에 Infisical은 급속히 성장하여 플랫폼이 매일 5000만 개 이상의 비밀을 처리하고 있습니다. 이 비밀은 애플리케이션 구성 및 비밀 데이터를 필요로 하는 팀, CI/CD 파이프라인 및 서버/애플리케이션으로 전송됩니다.\n\n사용량이 계속 증가함에 따라 계속해서 스택을 업그레이드해야 했습니다. 더 최근에 Infisical은 MongoDB에서 PostgreSQL로의 전체 데이터베이스 이전을 진행했습니다. 이 프로세스에는 계획 수립, 새 기술 도입, 새 데이터베이스 스키마 생성, 로직 연결 변경, 쿼리 재작성 및 수십억 개 이상의 데이터베이스 레코드를 PostgreSQL로 마이그레이션하는 작업이 포함되었습니다. 복잡한 프로세스였지만, 플랫폼의 발전을 위해 필요한 작업이었습니다.\n\n이는 MongoDB에서 PostgreSQL로 이동한 이유와 그 과정에 대한 우리의 의사결정 이야기입니다. 아마도 이 글은 흥미로운 내용으로, 그 어느 날 비슷한 데이터베이스 이전을 고려할 여러분들에게 유용할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n# 시작점\n\n인피시컬(Invisical)을 처음 만들 때, 팀이 가장 익숙한 스택으로 만들었습니다. 그 스택 중 하나로 MongoDB + Mongoose ORM을 선택한 이유는 해당 조합이 최소한의 오버헤드를 제공하고 품질있는 기능을 빠르게 출시할 수 있었기 때문입니다. Tony Hoare 선생이 말하듯이 \"조기 최적화는 모든 악의 근원이다,\" 그 때는 확실히 더 나은 최적화가 필요하지 않았습니다.\n\n그 당시에는 인피시컬 클라우드를 구축하는 데 더 주력했었고, 이 중점 때문에 제품을 직접 호스팅하는 사용자가 많을 것이라고 예상하지 않았으므로 해당 사용 사례를 염두에 두지 않고 설계되지는 않았습니다.\n\n# 왜 MongoDB가 아닌가요?\n\n<div class=\"content-ad\"></div>\n\n몽고DB가 초기에 인피지칼에 잘 도움이 되었지만, 제품의 사용 사례가 관리 서비스를 넘어선 경우에 한계를 보이기 시작했습니다. 시간이 지남에 따라, 특히 규정 준수와 보안이 교차하는 기업들 중 많은 조직이 인피지칼을 자체 호스팅하는 것을 선호했으며, 다른 일부는 만족해야 하는 온프렘 요구 사항이 있었습니다.\n\n인피지칼의 자체 호스팅 수요가 증가함에 따라, 우리는 인피지칼을 자체 호스팅하는 데 필요한 학습 곡선을 줄이기 위해 여러 기능을 제공하고, 이 과정에서 몽고DB를 포스트그리스로 전환했습니다.\n\n실제로, 우리와 고객들은 자주 몽고DB의 기능과 사용성과 관련된 제약사항에 부딪히곤 했습니다. 트랜잭션 지원 부족, 정리, 클라우드 제공 업체의 관리 서비스 간 불일치한 버전 관리, 그리고 스키마 없는 데이터베이스 설계 구조와 관련된 문제 등이 있었습니다.\n\n위 몇 가지 도전 과제에 대해 자세히 설명하겠습니다:\n\n<div class=\"content-ad\"></div>\n\n- 데이터베이스 트랜잭션 구성의 어려움: MongoDB에서는 트랜잭션을 설정하는 것이 쉽지 않았습니다. 클러스터 모드에서 MongoDB를 실행해야 했으며 다양한 구성 오버헤드가 필요했습니다. 이로 인해 고객이 Infisical의 간단한 POC를 실행하기가 굉장히 어렵게 되었는데, 이는 MongoDB의 프로덕션 환경 설정을 필요로 했기 때문입니다. 데이터 무결성이 반드시 유지되어야 하는 매우 민감한 데이터를 다루는 제품에서는 적합하지 않았습니다.\n\n- 관계형 기능 부재: MongoDB에서는 선택할 수 있는 CASCADE와 같은 관계형 세계의 많은 편리한 기능을 잃게 되었습니다. 이 기능은 목표 리소스를 삭제할 때 다른 테이블을 통해 참조된 모든 리소스를 삭제합니다. 우리의 데이터가 매우 관계적이었기 때문에 특히 아플 정도였습니다. 그 결과, 우리는 이전 코드베이스에서 완전히 수행되지 않았고 MongoDB 데이터베이스에 매달려있는 리소스를 남기는 무거운 삭제 기능을 사용했습니다.\n\n- 클라우드 제공자 간 지원 부족: MongoDB의 라이선스 변경(SSPL) 이후 많은 클라우드 제공 업체가 MongoDB의 이전 버전을 제공하기 시작했습니다. 결과적으로, MongoDB의 최신 안정 버전 이외의 버전을 실행 중인 고객을 위해 Infisical의 기능의 가용성을 보장하는 것이 어렵다는 것을 깨달았습니다.\n\n- MongoDB 경험 부족: 더 많은 사람들이 SQL 기반 데이터베이스를 배포하는 데 친숙했기 때문에 MongoDB를 확장하고 적절히 구성하는 데 어려움을 겪기도 했습니다. 이로 인해 MongoDB에 익숙하지 않았기 때문에 특히 고객들에게 제공해야 하는 서비스 양이 불균형하게 증가했습니다.\n\n여러 이유 중에서 우리는 Infisical을 전 세계의 팀과 조직에 더욱 접근 가능하게 만들기 위해 궁극적인 기능으로 더욱 보편적인 것으로의 완전한 데이터베이스 이전이 필요하다는 깨달음을 얻었습니다.\n\n# 왜 PostgreSQL을 선택했는가?\n\n새 데이터베이스를 찾을 때, 우리는 우리에게 가장 중요한 측면을 나열하여 시작했습니다: 관리의 용이성(즉, 구성, 배포 및 확장 포함), 트랜잭션을 위한 내장 지원 및 관계적 기능. 논의의 일환으로, 우리는 직접 통합 저장소를 구축할지 외부 저장소 솔루션을 추구할지에 대해 고민하기도 했습니다.\n\n<div class=\"content-ad\"></div>\n\n각 옵션에 대한 의미는 다음과 같습니다:\n\n- 통합 스토리지: 우리는 SQLite와 같은 데이터베이스 시스템을 직접 Infisical에 포함시키고 추가 네트워크 합을 피해 지연 시간을 줄이기 위해 수평 복제 전략을 채택할 수 있었습니다. 이 모델에서 시스템의 확장은 Infisical의 여러 인스턴스를 배포하고 Raft와 같은 일치 알고리즘을 통해 서로 통신하도록 하는 것을 의미했습니다. 고객이 Infisical을 실행하기 위해 종속성을 연결할 필요가 없다는 점이 훌륭한 해결책으로 보였지만, 이 비전을 실행하기 위한 도구 생태계는 미숙하게 느껴지고, 그에 필요한 공학 노력은 어마어마한 것으로 느껴졌습니다.\n- 외부 스토리지: 우리는 단순히 MongoDB를 PostgreSQL이나 MySQL과 같은 다른 데이터베이스로 교체하고 내장된 확장 능력을 사용할 수 있었습니다. 이 해결책은 Infisical을 사용하기 위해 외부 종속성이 필요하다는 마찰을 완전히 제거하지는 않았지만, MongoDB가 아니라는 점만으로도 중요한 혜택을 제공한다고 느꼈습니다. 하나 이상의 데이터베이스를 지원하는 데 있어서 여러 데이터베이스를 지원한다면 각 솔루션의 고유한 장점을 놓칠 수 있을 뿐만 아니라 엔지니어링 부담도 증가할 것으로 판단했습니다.\n\n신중한 고려 끝에, 우리는 PostgreSQL을 선택했습니다. 활기찬 커뮤니티, 방대한 문서화, 다양한 솔루션과 확장 프로그램이 제공되는 것을 넘어서, 우리는 PostgreSQL의 오픈 소스 특성과 대부분의 클라우드 제공업체에서 PostgreSQL의 관리 서비스를 제공한다는 점을 가장 감사했습니다.\n\n이 모든 선택은 Infisical의 사용자들이 어떤 클라우드 제공 업체에서도 우리 플랫폼을 쉽게 자체 호스팅하고 해당 관리형 PostgreSQL 서비스와 함께 사용할 수 있음을 의미합니다. 더욱이, 이 데이터베이스가 널리 채택되었다는 점을 고려할 때, 사용자들이 Infisical을 사용할 때 데이터베이스를 운영하는 데 더 적은 문제가 있을 것으로 확신했습니다.\n\n<div class=\"content-ad\"></div>\n\n# ORM은 어떻게 됐나요?\n\nPostgreSQL을 선택한 후, 어플리케이션이 데이터베이스와 상호작용하는 방법을 결정해야 했습니다. MongoDB에서 Mongoose ORM을 사용한 경험과 유사한 것을 원했기에 즉시 Drizzle ORM, Prisma ORM, TypeORM 및 질의 빌더인 Knex.js를 중점적으로 검토하기 시작했습니다.\n\n결국, 우리는 더 좋은 데이터베이스 제어를 위해 ORM 대신 쿼리 빌더인 Knex.js를 사용하기로 결정했습니다. 말은 듣기 어려워서 작업 유지가 어렵고, 특히 적절한 TypeScript 지원 없이는 실수하기 쉬울 것 같은 생각이 들었기 때문입니다. 게다가 Knex.js는 순수 SQL에 가깝지만 시드 및 마이그레이션을 위한 도구가 탑재되어 있었으며, 훌륭한 문서와 거의 모든 쿼리에 대한 답변을 갖춘 성숙한 생태계를 갖췄습니다. 몇 가지 사용자 정의 Zod 통합 작업과 결합하여 TypeScript 지원을 만족스러운 수준으로 유지할 수 있었습니다.\n\n데이터베이스와 ORM을 결정한 후, 이어지는 과정에서 수십 개의 데이터 구조 및 수백 개의 쿼리를 어플리케이션 전반에 걸쳐 다시 작성하는 작업을 시작했습니다.\n\n<div class=\"content-ad\"></div>\n\n# 마이그레이션 계획은 어떻게 세웠나요?\n\n코드 재작성이 끝나가는 시점에, 우리는 MongoDB 데이터를 PostgreSQL로 매핑하는 마이그레이션 작업을 수행하는 방법에 대해 고민하기 시작했습니다. 이 작업은 Infisical Cloud 플랫폼에 최소한의 방해를 주며 실시하는 것이 목표였습니다.\n\nInfisical이 고객 인프라에서 중대한 역할을 하는 점을 감안하여 절대 다운타임은 허용할 수 없다는 결론을 즉시 도출했습니다. 마이그레이션 기간 동안 쓰기 작업을 금지하는 것으로 일시적으로 타협해야 했지만(즉, 고객이 응용 프로그램 구성을 생성하거나 업데이트할 수 없는 경우), 더 높은 데이터 무결성을 보장하는 대신 이를 선택한 것이었습니다. 이러한 트레이드오프는 고객이 주로 Infisical에서 시크릿을 검색하고, 그 다음으로 두 번째로 응용 프로그램 구성을 초 단위로 업데이트하는 경우에 수용 가능해 보였습니다.\n\n이어서 실제 마이그레이션 작업에 대해 고민할 때 MongoDB에서 데이터를 덤프하고 신중히 변환한 후 PostgreSQL로 다시 삽입해야 했습니다. 마이그레이션 순서를 심사하면서, NoSQL에서 가져온 다양한 트리 형태의 구조를 관련된 상대적인 구조로 올바르게 변환해야 하는 등 다양한 어려움을 겪었습니다; 특히 재귀적인 고려가 필요한 폴더와 같은 데이터 구조에 대해 민감했습니다. 또한, MongoDB에서 PostgreSQL로 식별자를 저장하고 매핑하는 지속적인 방법이 필요하다는 사실을 발견했으며, 메모리에 저장하면 처리할 데이터 양을 고려할 때 동작하지 않을 것 같았습니다. 결과적으로, 우리는 식별자 저장 및 조회 작업을 돕기 위해 LevelDB 키-값 저장소를 사용하기로 결정했습니다. 이를 통해 결과적으로 각 테이블을 순차적으로 PostgreSQL로 이동할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n# 위대한 이주\n\n드디어, 우리는 이주를 진행할 준비가 되었습니다. 이 시점에서 코드베이스 재작성에 직접 관여하지 않은 사람들은 Infisical의 기타 측면을 개선하는 데 매우 중요한 한 분기를 보내었는데, 프런트엔드 변경사항을 만들고 유지 관리 패치를 수행하며 클라이언트 기능을 확장하고 더 나은 문서를 작성했습니다. 이제 이주 자체를 준비하기 위해 모두가 모여 새로운 애플리케이션 코드베이스로 교체하고 데이터를 MongoDB에서 PostgreSQL로 이전하는 작업을 시작했습니다.\n\n준비과정에서 우리는 예상 일정을 포함한 자세한 이주 체크리스트를 작성했습니다.\n\n전반적으로 계획은 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n- 이주 동안 이주를 준비하는 동안, 사용자들에게 장기적인 데이터베이스 업그레이드에 대해 미리 이메일과 앱 내 배너를 통해 통지하겠습니다. 플랫폼의 모든 기능 flow에 대한 철저한 테스트를 수행하고, 이주를 위한 시범 운영도 진행할 것입니다.\n- 이주 자체는 단순히 소요되는 6시간 동안에만 읽기 작업만 허용되는 창을 통해 진행됩니다. 이 기간 동안 MongoDB에서 PostgreSQL로 데이터를 이동하는 이주 스크립트를 실행하고, 데이터 손실이 없는지 확인한 후 성공적으로 DNS를 새 인스턴스로 전환할 것입니다. 물론, 상황이 역행할 경우를 대비한 백업 계획도 마련되어 있습니다.\n- 마침내 이주 후, 어떠한 잔여 문제도 해결하고 Infisical과 PostgreSQL을 사용하여 새로운 문서를 점차 배포할 것입니다.\n\n계획이 준비되어 있다면, 실행으로 나아갑시다.\n\n# 결과\n\n다행히도, 이주 실행은 원활하게 진행되어 데이터 손실이 없었고, 몇 가지 중요하지 않은 기능 장애 사례만 발생했습니다. 이러한 버그는 소비자에게 미미한 영향을 미친 채 36시간 이후에 해결하였습니다.\n\n<div class=\"content-ad\"></div>\n\n이주 후에 우리는 많은 이점을 발견했습니다:\n\n- 쿼리 최적화와 조인을 통한 성능 향상으로 인해 플랫폼이 상당한 성능 향상을 경험했습니다. MongoDB를 사용할 때, 필요한 기능을 얻기 위해 종종 비효율적인 집계 쿼리와 여러 네트워크 항해를 거쳐야 했었습니다. 핵심 데이터의 관계적 특성으로 인해 SQL에서 조인을 모방하려면 많은 $lookup 작업을 수행해야 했는데, 이러한 작업은 비효율적이었고 데이터베이스와 응용 프로그램 인스턴스를 모두 확장해야 했습니다. PostgreSQL로 이전하면서 이러한 비효율적인 작업을 피하고 데이터베이스 청구서 비용을 50% 절감했습니다.\n- 플랫폼은 이제 어플리케이션 레벨이 아닌 데이터베이스 레벨에서 더 나은 데이터 유효성 검사를 하게 되었습니다. MongoDB는 설계상 스키마가 없기 때문에 데이터 유형, 필수 필드 및 유효성 규칙을 정의하기 위해 Mongoose 프레임워크에 의존했습니다. PostgreSQL이 구축된 상태로 데이터 불일치를 더 이상 경험하지 않았으며, Mongoose 판권 범위를 벗어난 데이터베이스에 액세스하거나 수정시 발생하던 문제를 더 이상 겪지 않았습니다.\n- 마지막으로 매우 중요한 점은 고객이 MongoDB의 복제 집합을 다루는 추가 구성 부담 없이 증명 사례를 수행할 수 있는 등 Infisical이 이제 훨씬 쉽게 자체 호스팅될 수 있다는 것입니다.\n\n전체적으로, 목표, 업무 범위 및 실행 결과를 고려할 때, 이 이니셔티브를 매우 성공적으로 평가했습니다. 미래에 더 많은 데이터를 보유할 때 구체적인 결과를 발표할 계획입니다.\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\n몽고디비에서 포스트그레스큐엘로 이전하기로 한 결정은 처음부터 쉬운 일은 아니었습니다. 모든 과정을 신중하게 계획하고 논의한 후, 우리는 이 일을 수행하기 위해 3~4개월이 걸렸습니다. 왜 이렇게 해야 하는지, 어떻게 실행할 것인지에 대해 심도있게 고민한 끝에 모든 것을 신중히 실행할 수 있었습니다. 이 글을 읽는 누구에게든, 이러한 큰 작업에 속해들기 전에 사용 사례와 구현을 심각하게 고려하는 것을 강력히 권장합니다. 결국 모든 것이 계획대로 진행되어 매우 만족스럽습니다. 앞으로 인피지컬 사용자들에게 큰 변화를 가져다 줄 이런 거대한 업데이트를 성공적으로 전달할 수 있어 기쁩니다.\n\n몽고디비에서 포스트그레스큐엘로의 이주 계획을 완벽히 수행한 Akhil Mohan과 인피지컬의 다른 모든 분들께 감사드립니다.\n\n# 인피지컬 - 오픈 소스 시크릿 관리 플랫폼\n\n![이주 이미지](/assets/img/2024-06-22-TheGreatMigrationfromMongoDBtoPostgreSQL_1.png)\n\n<div class=\"content-ad\"></div>\n\nInfisical (11.6K+ ⭐️)은 수천 개의 팀과 조직이 팀 및 인프라 전반에 걸쳐 비밀을 저장하고 동기화하는 데 도움을 줍니다.\n\nGitHub 저장소: https://github.com/Infisical/infisical","ogImage":{"url":"/assets/img/2024-06-22-TheGreatMigrationfromMongoDBtoPostgreSQL_0.png"},"coverImage":"/assets/img/2024-06-22-TheGreatMigrationfromMongoDBtoPostgreSQL_0.png","tag":["Tech"],"readingTime":8},{"title":"UUID7이 RDBMS에서 클러스터드 인덱스로 UUID4보다 더 나은 이유","description":"","date":"2024-06-22 05:23","slug":"2024-06-22-WhyUUID7isbetterthanUUID4asclusteredindexinRDBMS","content":"\n\n데이터베이스 색인 소개 기사에서는 데이터베이스 인덱스, 그 종류, 표현 방법 및 사용 사례에 대해 논의했습니다.\n\n이 기사에서는 클러스터링된 인덱스로서 더 나은 성능을 발휘하는지 확인하기 위해 UUID 버전 4 대 UUID 버전 7 또는 6의 실험을 진행할 것입니다. 그런 다음 그 이유에 대해 논의할 것입니다.\n\n# UUID 버전 4란?\n\nUUID는 `Universally Unique Identifier`의 약자로, 대시로 구분된 문자와 숫자의 32자 시퀀스로 표현되는 128비트 식별자입니다. '8-4-4-4-12' 형식으로 포맷되며, \"123e4567-e89b-12d3-a456-426655440000\"와 같이 UUID 버전 4의 구조는 각 문자가 '1'에서 'f'까지의 16진수 값을 보여줍니다. 완전히 무작위로 생성되었던지 아니면 유사 난수 생성기를 통해 생성되었던지에 관계없이, UUID 버전 4는 그 독특한 고유성을 유지합니다.\n\n<div class=\"content-ad\"></div>\n\n참고 자료 #2에서 자세한 계산 내용을 찾을 수 있어요.\n\n# UUID 버전 7이 무엇인가요?\n\nUUID v7은 UUID v4와 유사한 128비트 식별자로, 문자와 숫자의 32글자 시퀀스로 표시되며, 8-4-4-4-12 형식으로 구성됩니다. UUID v7의 독특한 특징은 Unix 타임스탬프를 밀리초 단위로 가장 유의미한 48비트에 인코딩하는 시간순서 UUID로 있는 것입니다. UUID 형식에 따라 4비트는 UUID 버전을 지정하고, 2비트는 변형을 나타냅니다. 나머지 74비트는 무작위로 생성되어 이 식별자의 고유성에 기여합니다.\n\n![이미지](/assets/img/2024-06-22-WhyUUID7isbetterthanUUID4asclusteredindexinRDBMS_0.png)\n\n<div class=\"content-ad\"></div>\n\n# 왜 UUID를 사용해야 할까요?\n\nUUID와 연속적인 ID를 비교한 장단점을 알아보겠습니다.\n\n- 장점:\n1. 충돌 확률 낮음: UUID는 구조상 충돌 확률이 매우 낮아서 서버가 레코드 삽입 전에 ID를 생성할 수 있습니다.\n2. 분산 시스템에 적합: UUID는 분산 데이터베이스 및 시스템에 적합하며 서버에서 독립적으로 생성할 수 있습니다.\n3. 향상된 보안: UUID는 레코드를 익명으로 유지하여 사용자(또는 악성 주체)가 레코드 생성 순서에 대한 정보를 유추하는 것을 방지하여 데이터베이스 보안에 기여합니다.\n\n- 단점:\n1. 저장 공간 증가: UUID는 전통적인 ID(예: INT에 4바이트 또는 BIGINT에 8바이트)보다 더 많은 공간(16바이트)을 차지합니다.\n2. 수동 데이터 입력의 어려움: UUID의 복잡성으로 인해 수동 데이터 입력이 어려울 수 있습니다.\n3. 쿼리 성능 감소: 큰 UUID 크기는 쿼리 성능을 감소시킵니다. 레코드 크기의 증가로 인해 데이터베이스 페이지 당 저장되는 레코드가 줄어들어 I/O 작업이 늘어나고 전체적인 성능이 감소합니다.\n4. 인덱스와 데이터 단편화: UUID는 인덱스 및 데이터 단편화에 영향을 줄 수 있어 데이터베이스 효율성에 영향을 미칠 수 있습니다.\n\n# 실험을 시작해봅시다!\n\n<div class=\"content-ad\"></div>\n\n## 개요:\n\n이 실험에서는 MySQL, Docker, Node 및 Go를 사용합니다.\nMySQL을 실행하고 구성하며 데이터를 볼륨에 저장하는 docker-compose 파일을 만들었습니다 (이 실험 후에는 이 볼륨을 자동으로 정리합니다).\n\n참고: MySQL은 기본적으로 기본 키에 대해 클러스터화된 인덱싱을 사용하므로 PostgreSQL에는 없는 기능이기 때문에 MySQL을 선택했습니다.\n\n노드.js 스크립트와 Go를 사용하여 100만 개의 레코드를 하나씩 삽입하여 삽입 성능을 테스트할 것입니다 (대량 사용 시 DB 엔진이 레코드를 정렬하고 실험을 망칠 수 있습니다). Go와 고루틴을 사용하여 여러 서버가 하나의 DB에 연결하여 200만 개의 레코드를 삽입하는 시나리오를 시뮬레이션할 것입니다. 코어 당 1개의 스레드를 실행하여 7개의 스레드를 실행합니다. 도커 데몬을 실행할 코어는 1개가 남도록합니다.\n\n<div class=\"content-ad\"></div>\n\n실험에서는 채팅 데이터베이스를 시뮬레이션했습니다. \"chat_messages\"라는 테이블 하나만 가지고 있으며 id, chat_id, sender_id, message 및 created_at이라는 열이 있습니다. id, chat_id 및 sender_id의 유형은 데이터를 Integer 또는 UUID v4 또는 UUID v7로 입력하는 방식에 따라 INT에서 BINARY(16)으로 다양합니다.\n\n## 메모:\n\n- 저는 삽입 시간을 애플리케이션 수준에서 측정했습니다. 이 방법이 가장 정확한 방법은 아니며 트리거 또는 저장 프로시저를 사용할 수도 있지만, 이 방법이 더 빨랐습니다. 실험을 한 번 이상 반복하고 서로 다른 기계 및 프로그램(node 및 go)에서 수행하여 결과가 유사한 것으로 확인했습니다.\n- 실험은 전용 기계에서 진행되었으며 실험 과정 중 시스템 자원이 동시에 사용되지 않도록 보장했습니다. 이러한 의도적인 격리는 측정된 삽입 시간에 영향을 줄 수 있는 외부 요소를 최소화하여 결과의 신뢰성을 향상시킵니다.\n\n## 단계:\n\n<div class=\"content-ad\"></div>\n\n위 실험의 개요를 아래와 같이 정리해 봤어요:\n\n- 도커 컴포즈 파일 실행\n- 데이터베이스에 연결\n- chat_messages 테이블 생성 (UUID v4)\n- 레코드 삽입 및 시간 측정 (모든 삽입의 합) (UUID v4)\n- 도커 중지 및 볼륨 삭제 (UUID v7 삽입에 영향을 주지 않기 위해 매우 중요)\n- 이후 1초 대기 (시스템이 메모리와 스왑을 청소할 수 있도록)\n- chat_messages 테이블 생성 (UUID v7)\n- 레코드 삽입 및 시간 측정 (UUID v7)\n- 도커 중지 및 볼륨 삭제\n- 이후 1초 대기\n- chat_messages 테이블 생성 (정수)\n- 레코드 삽입 및 시간 측정 (정수)\n- 도커 중지 및 볼륨 삭제\n- 이후 1초 대기\n\n만약 원하신다면 이 리포지토리를 복제하고 실험을 직접 실행해 보실 수 있어요.\n\n## 결과:\n\n<div class=\"content-ad\"></div>\n\n노드 프로세스가 100만 개의 레코드를 삽입하는 중입니다:\nUUIDV4: 24345338.406382076\nUUIDV7: 23579840.35688359\nINT: 23678315.194741927\nUUID V4 / UUID V7 비율: 1.0324640895745087\n\n여기서도 UUID V4가 UUID V7보다 3% 더 많은 시간을 소요한 것을 볼 수 있어요.\n\nGoLang 프로세스가 100만 개의 레코드를 삽입 중입니다:\nUUIDV4: 2.6320770985406373e+07\nUUIDV7: 2.5592608053863425e+07\nINT: 2.5759889825318027e+07\nUUID V4 / UUID V7 비율: 1.0284520799916297\n\n여기서도 UUID V4가 UUID V7보다 3% 더 많은 시간을 소요한 것을 볼 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n7개의 스레드로 5백만 개의 레코드를 삽입하는 MultiThreaded Go 프로그램:\n8개의 코어를 사용하기 때문에 각 스레드를 하나의 코어에 고정시키려고 시도했습니다.\n\nUUID V4: 20634873.5100111 밀리초\nUUID V7: 16750775.02223781 밀리초\nINT: 164567295.36401817 밀리초\nUUID V4 / UUID V7 백분율: 1.2318757479947573\n\n여기서 UUID v4가 UUID v7보다 약 23.1% 더 오래 걸렸음을 볼 수 있습니다.\n그리고 정수보다 약 25.3% 더 오랜 시간이 걸렸습니다. (결과가 한 번 실행에서 다른 결과가 나올 수 있다는 점을 유의해 주세요)\n\n# UUID v7이 UUID v4보다 왜 더 빨랐을까요?\n\n<div class=\"content-ad\"></div>\n\n## 인덱스 지역화:\n\n공유된 이해를 확립하기 위해, 참조된 기사에서 이전에 소개된 개념인 클러스터형 인덱스를 다시 살펴보겠습니다. 클러스터형 인덱스의 저장 메커니즘은 결과를 이해하는 데 중요합니다.\n\n클러스터형 인덱스는 어떻게 저장되나요?\n\n각 데이터 조각이 페이지에 저장된다고 언급했습니다. 그런 다음 인덱스는 페이지 내에 b+ 트리로 저장됩니다. 이것은 인덱스 내의 키가 정렬되어 있다는 것을 의미합니다. 따라서 새 키를 기존 키 사이에 삽입하는 경우에는 저장된 인덱스의 재조직이 필요합니다. 이 재조직 프로세스에는 여러 페이지를 검색하고 해당 페이지를 읽은 다음 새 페이지를 삽입하면서 다음 및 이전 포인터를 조정하는 작업이 포함될 수 있습니다 (페이지를 분할하는 대신).\n\n<div class=\"content-ad\"></div>\n\n\n![Link to WhyUUID7isbetterthanUUID4asclusteredindexinRDBMS_1.png](/assets/img/2024-06-22-WhyUUID7isbetterthanUUID4asclusteredindexinRDBMS_1.png)\n\n![Link to WhyUUID7isbetterthanUUID4asclusteredindexinRDBMS_2.png](/assets/img/2024-06-22-WhyUUID7isbetterthanUUID4asclusteredindexinRDBMS_2.png)\n\n새 레코드 ID 8이 추가되었음을 알 수 있습니다. Figure 4에서 10, 15, 및 20을 포함하는 페이지가 분할되었습니다. 이 과정에서 데이터 페이지도 분할되었음을 강조해야 합니다.\n\n![Link to WhyUUID7isbetterthanUUID4asclusteredindexinRDBMS_3.png](/assets/img/2024-06-22-WhyUUID7isbetterthanUUID4asclusteredindexinRDBMS_3.png)\n\n\n<div class=\"content-ad\"></div>\n\n앞서 말한 대로, 비순서화된 ID가 성능에 어떤 영향을 미칠 수 있는지 짐작할 수 있게 되었습니다.\n\nUUID v4 ID는 서로 상관관계가 없어서, 완전히 무작위한 성격 때문에 인덱스 지역성이 떨어집니다. 따라서 새로 생성된 UUID v4가 이전 것보다 낮은 Hex 값일 수 있습니다. 클러스터 인덱스를 사용하고 있기 때문에, 원하는 순서를 유지하기 위해 새로 생성된 UUID v4를 이전 것보다 앞에 위치시키는 것이 필요합니다.\n\nUUID v7와 달리, 시간 기반 성격으로 내재적으로 정렬되어 있습니다. 이것은 값이 거의 순차적으로 생성되어 마지막 페이지 끝에 일관되게 삽입된다는 것을 의미합니다(모든 서버가 동기화되어 있다면). 이 특성은 인덱스 지역성 문제를 효과적으로 해결합니다.\n\n## 버퍼 풀:\n\n<div class=\"content-ad\"></div>\n\n만약 이 개념이 처음이라면 빠르게 소개해 드리겠습니다.\n데이터베이스 엔진은 우리의 기기에서 다른 실행 중인 프로세스와 마찬가지로 무한한 메모리를 갖고 있지 않습니다. 그들은 OS로부터 고정 크기의 메모리를 요청합니다. 데이터베이스 엔진은 쿼리 최적화, 레코드 구문 분석, 레코드 정렬, 레코드 조인 등 다양한 작업을 수행하는 데 사용됩니다. 하지만 중요한 것은 우리에게 있어서, 이 메모리 위치 중에는 저장소에서 읽은 페이지를 유지하거나 새 레코드를 삽입하기 위한 새 페이지를 생성하는 메모리 파티션인 \"버퍼 풀\"이 있습니다.\n\n이것은 읽기(선택) 작업에서 페이지를 저장하는 데만 사용되지 않습니다. 삽입, 업데이트 및 삭제 작업에도 사용됩니다. 데이터베이스 엔진은 대상 레코드가 존재하는 페이지를 가져오거나 삽입, 업데이트 또는 삭제해야 하는 페이지를 가져와야 합니다.\n\n우리 문제와 어떤 관련이 있을까요?\n\n<div class=\"content-ad\"></div>\n\nUUID v4의 병목 현상 핵심입니다. 문제는 ID가 매우 무작위이며 버퍼 풀이 빠르게 가득 차서 매번 레코드가 다른 페이지에 저장됩니다. 따라서 데이터베이스 엔진은 해당 레코드를 가져와야 하는데 버퍼 풀이 가득 찬 경우 몇 개의 페이지를 디스크로 다시 기록하여 공간을 확보해야 합니다. 그리고 바로 옆에 있는 다음 레코드가 방금 기록한 페이지와 다를 수도 있기 때문에 이 작업이 계속 반복됩니다.\n\n그러나 UUID v7 또는 Serial Integer의 경우에는 이러한 일이 발생하지 않습니다. 왜냐하면 레코드의 ID가 증가하는 순서로 부여되기 때문입니다. 따라서 페이지 제한에 도달하면 레코드가 마지막 페이지에 추가될 것이고 데이터베이스 엔진은 새 페이지를 만들게 됩니다. 이전 페이지를 디스크에 기록할지 여부는, 버퍼 풀이 가득 차기를 기다릴지 아니면 WAL에만 쓸지를 결정할 것입니다.\n\n# 마지막 질문은 왜 Serial이 UUID보다 빨랐을까요?\n\n이제 이 질문은 매우 쉽게 대답할 수 있는 질문입니다. 데이터베이스에 각 레코드가 페이지에 삽입되고 페이지의 기본 크기는 16 KByte (MySQL) 및 8 KByte (PostgreSQL)로 고정됩니다. INT ID의 경우 레코드 크기는 271 바이트(4 + 4 + 4 + 255 + 4)(INT, INT, INT, VARCHAR(255), TIMES...)입니다. 그러나 UUID의 경우 레코드 크기는 307 바이트(16 + 16 +16 + 255 + 4)입니다.\n페이지 당 더 많은 레코드가 포함될 수 있다는 가정하에, INT ID의 페이지에는 더 많은 레코드가 포함되어 있기 때문에 IO가 적고 속도가 더 빠릅니다.\n\n<div class=\"content-ad\"></div>\n\n한 가지 작은 참고사항을 드리자면 타임스탬프 GUID를 추가하는 아이디어는 새로운 것이 아닙니다. UUID v1이 이를 수행했지만 단점이 있었고, Instagram의 ShardingID, Shopify는 UUID v4 대신 ULID를 사용하며, MongoDB ObjectID도 비슷한 방식을 사용합니다.\n\n마지막으로, 이 기사를 즐겁게 읽으셨기를 바랍니다. 새로운 것을 배우셨다면 좋겠습니다. 더 개선할 부분이 있다면 언제든지 알려주세요.\n\n# 향후 작업:\n\n- Rust로 테스트해 보고 싶습니다.\n- 각 인덱스 유형별로 인덱스 B+ 트리의 크기를 확인하고 싶습니다.\n- 단일 연결 대신 데이터베이스 연결 풀을 사용하고 싶습니다.\n\n<div class=\"content-ad\"></div>\n\n# 참고 자료:\n\n- 비슷한 아이디어를 설명하는 멋진 동영상\n- UUID 버전 4 형식\n- UUID 고유성\n- UUID RFC\n- UUID와 ID에 대한 더 많은 정보\n- UUID v7\n- 잘못된 분할\n- 정수 작별. UUIDv7 안녕하세요! 훌륭한 기사.","ogImage":{"url":"/assets/img/2024-06-22-WhyUUID7isbetterthanUUID4asclusteredindexinRDBMS_0.png"},"coverImage":"/assets/img/2024-06-22-WhyUUID7isbetterthanUUID4asclusteredindexinRDBMS_0.png","tag":["Tech"],"readingTime":8}],"page":"20","totalPageCount":154,"totalPageGroupCount":8,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true}