{"pageProps":{"posts":[{"title":"잡음 저항 칼만 필터 이동 평균KMA 대 단순 이동 평균SMA 교차 알고 트레이딩 전략 BAC 쇼케이스","description":"","date":"2024-06-20 04:43","slug":"2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase","content":"\n\n- 대부분의 기술적거래지표(TTI)는 과거 주식 데이터에서 유래되며 미래 가격 흐름 반전을 예측하고 거래 결정을 내리는 데 거래자들에 의해 사용됩니다.\n- 금융 시장 예측은 시간에 따라 변하는 시장 소음 수준이 뒤틀리는 기본 트렌드와 계절적 주기의 이미지를 왜곡하기 때문에 매우 어려운 작업임이 널리 인정되고 있습니다.\n- 알고트레이딩에서 기술적 분석은 항상 패턴 및 신호를 식별하는 데 의존하지만 때로는 신뢰성 없는 것이 있을 수 있습니다. (신호/소음)`1.\n- 실제로, 가짜 가격 변동 및 오작동이 잘못된 TTI 신호를 초래하여 리스크-수익 최적화를 감소시키고 좋지 않은 거래 전략을 야기할 수 있습니다.\n- 본 게시물에서는 불확실하고 정확하지 않은 시계열 데이터에 기초한 숨겨진 변수의 소음이 적절한 확률 추정을 제공하는 칼만 필터(KF)를 사용하여 TTI의 상기한 단점을 다룰 것입니다.\n- KF는 선형 가우시안 상태 공간 모델에서 이론적으로 최적인 것으로 알려져 있으며, 추정된 오차 공분산을 최소화함으로써 베이지안 예측 및 수정의 최적의 재귀적 구현이라고 할 수 있습니다. \n- 여기서, 우리의 목적은 짧은 윈도우 칼만 필터 이동 평균(KMA)를 도입하여 SMA 크로스오버 거래 전략의 극심한 소음 민감성을 줄이는 것입니다.\n- 사례 예시로, BAC 주식의 예상 수익율을 비교하여 KMA, SMA 크로스오버 및 매수 & 보유 알고트레이딩 전략의 백테스트 분석을 수행할 것입니다.\n- 비즈니스적인 측면에서, 제안된 연구는 계속되는 알고트레이딩 SaaS R&D 노력을 촉진하여 BAC에 대한 거래 봇 및 백테스팅 결과를 업데이트합니다. 이러한 노력은 은행이 대량의 핀테크 데이터를 분석하고 신속하게 거래를 실행하여 이윤을 극대화하고 인적 오류를 최소화합니다.\n\n우리의 접근 방식을 구체적으로 살펴보겠습니다.\n\n## 기본 Imports 및 설정\n\n<div class=\"content-ad\"></div>\n\n- 현재 작업 디렉토리를 YOURPATH로 설정하기\n\n```python\nimport os\nos.chdir('YOURPATH')    # 작업 디렉토리 설정\nos.getcwd()\n```\n\n- Python 라이브러리 가져오고 설치하기\n\n```python\n!pip install yfinance, pykalman\n\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport requests\nimport math\nfrom termcolor import colored as cl \nimport numpy as np\nimport yfinance as yf\nimport matplotlib.pyplot as plt\nfrom pykalman import KalmanFilter\n\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = (12, 6)\n```\n\n<div class=\"content-ad\"></div>\n\n## 주식 데이터 입력 읽기\n\n- 야후 파이낸스에서 BAC의 과거 데이터 가져오기\n\n```js\ndata = yf.download('BAC', start='2023-01-01', end='2024-06-01')\n\ndf=data.drop(columns=['Open', 'High','Low','Adj Close','Volume'])\ndf.tail()\n\n           Close\nDate \n2024-05-24 39.700001\n2024-05-28 39.320000\n2024-05-29 38.720001\n2024-05-30 38.630001\n2024-05-31 39.990002\n```\n\n## KMA vs SMA40\n\n<div class=\"content-ad\"></div>\n\n- 파이칼만(pykalman)을 사용한 KF 구현 및 SMA40 계산하기\n\n```python\nkf = KalmanFilter(\n    transition_matrices=[1],\n    observation_matrices=[1],\n    initial_state_mean=0,\n    initial_state_covariance=1,\n    observation_covariance=1,\n    transition_covariance=0.01\n)\n\nstate_means, _ = kf.filter(df['Close'].values)\nstate_means = pd.Series(state_means.flatten(), index=df.index)\ndf['kma'] = state_means\ndf['sma'] = df['Close'].rolling(window=40).mean()\n\ndf.tail()\n\n           Close     kma       sma\nDate   \n2024-05-24 39.700001 38.568957 37.64750\n2024-05-28 39.320000 38.640400 37.69250\n2024-05-29 38.720001 38.647972 37.72800\n2024-05-30 38.630001 38.646262 37.75775\n2024-05-31 39.990002 38.774086 37.83450\n```\n\n- 여기에서 KF에 대해 더 알아보기.\n- KMA vs SMA40 그래프 그리기\n\n```python\nplt.figure(figsize=(12,6))\nplt.plot(df['Close'], label='BAC', linewidth=5, alpha=0.3)\nplt.plot(df['kma'], label='KMA')\nplt.plot(df['sma'], label='SMA40')\nplt.title('BAC KMA/SMA')\nplt.xlabel('Date')\nplt.ylabel('Close Price USD')\nplt.legend(loc='upper left')\nplt.show()\n```\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_1.png\" />\n\n## KMA vs SMA20\n\n- KMA와 20일 이동평균(SMA)을 비교\n\n```js\nmean30 = df['Close'].rolling(window=20).mean()\n\n#plt.figure(figsize=(12,6))\nplt.plot(state_means)\nplt.plot(df['Close'])\nplt.plot(mean30)\nplt.title('Kalman filter estimate of average', fontsize=20)\nplt.legend(['Kalman', 'Price', '20-day MA'], fontsize=20)\nplt.xlabel('Date')\nplt.ylabel('Close Price USD')\n```\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_2.png)\n\n## KMA-SMA40 Trading Strategy\n\n- `implement_sma_strategy` 함수를 사용하여 KMA-SMA40 트레이딩 전략 구현하기\n\n```python\ndef implement_sma_strategy(data, short_window, long_window):\n    sma1 = short_window\n    sma2 = long_window\n    buy_price = []\n    sell_price = []\n    sma_signal = []\n    signal = 0\n    \n    for i in range(len(data)):\n        if sma1.iloc[i] > sma2.iloc[i]:\n            if signal != 1:\n                buy_price.append(data.iloc[i])\n                sell_price.append(np.nan)\n                signal = 1\n                sma_signal.append(signal)\n            else:\n                buy_price.append(np.nan)\n                sell_price.append(np.nan)\n                sma_signal.append(0)\n        elif sma2.iloc[i] > sma1.iloc[i]:\n            if signal != -1:\n                buy_price.append(np.nan)\n                sell_price.append(data.iloc[i])\n                signal = -1\n                sma_signal.append(-1)\n            else:\n                buy_price.append(np.nan)\n                sell_price.append(np.nan)\n                sma_signal.append(0)\n        else:\n            buy_price.append(np.nan)\n            sell_price.append(np.nan)\n            sma_signal.append(0)\n            \n    return buy_price, sell_price, sma_signal\n\nsma_20 = df['kma']\nsma_50 = df['sma']\n\nbuy_price, sell_price, signal = implement_sma_strategy(df['Close'], sma_20, sma_50)\n```\n\n\n<div class=\"content-ad\"></div>\n\n- 우리 Position 생성하기\n\n```js\nposition = []\nfor i in range(len(signal)):\n    if signal[i] > 1:\n        position.append(0)\n    else:\n        position.append(1)\n        \nfor i in range(len(df['Close'])):\n    if signal[i] == 1:\n        position[i] = 1\n    elif signal[i] == -1:\n        position[i] = 0\n    else:\n        position[i] = position[i-1]\n\nsma_20 = pd.DataFrame(sma_20).rename(columns = {0:'sma_20'})\nsma_50 = pd.DataFrame(sma_50).rename(columns = {0:'sma_50'}) \nsignal = pd.DataFrame(signal).rename(columns = {0:'sma_signal'}).set_index(df.index)\nposition = pd.DataFrame(position).rename(columns = {0:'sma_position'}).set_index(df.index)\n\nframes = [sma_20, sma_50, signal, position]\nstrategy = pd.concat(frames, join = 'inner', axis = 1)\nstrategy = strategy.reset_index().drop('Date', axis = 1)\n\ndf_ret = pd.DataFrame(np.diff(df['Close'])).rename(columns = {0:'returns'})\nsma_strategy_ret = []\n\nfor i in range(len(df_ret)):\n    try:\n        returns = df_ret['returns'][i]*strategy['sma_position'][i]\n        sma_strategy_ret.append(returns)\n    except:\n        pass\n    \nsma_strategy_ret_df = pd.DataFrame(sma_strategy_ret).rename(columns = {0:'sma_returns'})\n```\n\n- BAC KMA/SMA 트레이딩 신호 플로팅\n\n```js\nplt.plot(df['Close'], alpha = 0.3, label = 'BAC')\nplt.plot(sma_20, alpha = 0.6, label = 'KMA')\nplt.plot(sma_50, alpha = 0.6, label = 'SMA40')\nplt.scatter(df.index, buy_price, marker = '^', s = 200, color = 'darkblue', label = '매수 신호')\nplt.scatter(df.index, sell_price, marker = 'v', s = 200, color = 'crimson', label = '매도 신호')\nplt.legend(loc = 'lower right')\nplt.xlabel('날짜')\nplt.ylabel('종가 USD')\nplt.title('BAC KMA/SMA 트레이딩 신호')\nplt.show()\n```\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_3.png)\n\n- 저희 전략의 백테스팅을 수행 중입니다.\n\n```python\nimport math\nfrom termcolor import colored as cl\n투자금 = 100000\n주식수 = math.floor(투자금 / df['Close'].iloc[1])\nsma_투자_수익 = []\n\nfor i in range(len(sma_strategy_ret_df['sma_returns'])):\n    수익 = 주식수 * sma_strategy_ret_df['sma_returns'].iloc[i]\n    sma_투자_수익.append(수익)\n\nsma_투자_수익_df = pd.DataFrame(sma_투자_수익).rename(columns = {0:'투자_수익'})\n총_투자_수익 = round(sum(sma_투자_수익_df['투자_수익']), 2)\nprint(cl('BAC에 10만 달러를 투자하여 전략으로 얻은 이익: ${}'.format(총_투자_수익), attrs = ['bold']))\n\nBAC에 10만 달러를 투자하여 전략으로 얻은 이익: $29026.39\n```\n\n## SMA 20–50 트레이딩 전략\n\n\n<div class=\"content-ad\"></div>\n\n- 표준 SMA 20-50 거래 전략 구현\n\n```python\ndef sma(data, n):\n    sma = data.rolling(window=n).mean()\n    return pd.DataFrame(sma)\n\nn = [20, 50]\nfor i in n:\n    df[f'sma_{i}'] = sma(df['Close'], i)\n\nClose       sma_20    sma_50         sma_40\nDate    \n2024-05-24 39.700001 38.3415 37.4868 37.64750\n2024-05-28 39.320000 38.4300 37.5650 37.69250\n2024-05-29 38.720001 38.5155 37.6192 37.72800\n2024-05-30 38.630001 38.5995 37.6712 37.75775\n2024-05-31 39.990002 38.7550 37.7360 37.83450\n```\n\n- SMA 20-50 플로팅\n\n```python\nplt.plot(df['Close'], label='BAC', linewidth=5, alpha=0.3)\nplt.plot(df['sma_20'], label='SMA 20')\nplt.plot(df['sma_50'], label='SMA 50')\nplt.title('BAC Simple Moving Averages (20, 50)')\nplt.legend(loc='upper left')\n\nplt.xlabel('Date')\nplt.ylabel('Close Price USD')\nplt.show()\n```\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_4.png\" />\n\n- implement_sma_strategy 함수를 사용하여 BAC SMA (20,50) 거래 신호를 생성합니다.\n\n```js\ndef implement_sma_strategy(data, short_window, long_window):\n    sma1 = short_window\n    sma2 = long_window\n    buy_price = []\n    sell_price = []\n    sma_signal = []\n    signal = 0\n    \n    for i in range(len(data)):\n        if sma1.iloc[i] > sma2.iloc[i]:\n            if signal != 1:\n                buy_price.append(data.iloc[i])\n                sell_price.append(np.nan)\n                signal = 1\n                sma_signal.append(signal)\n            else:\n                buy_price.append(np.nan)\n                sell_price.append(np.nan)\n                sma_signal.append(0)\n        elif sma2.iloc[i] > sma1.iloc[i]:\n            if signal != -1:\n                buy_price.append(np.nan)\n                sell_price.append(data.iloc[i])\n                signal = -1\n                sma_signal.append(-1)\n            else:\n                buy_price.append(np.nan)\n                sell_price.append(np.nan)\n                sma_signal.append(0)\n        else:\n            buy_price.append(np.nan)\n            sell_price.append(np.nan)\n            sma_signal.append(0)\n            \n    return buy_price, sell_price, sma_signal\n\nsma_20 = df['sma_20']\nsma_50 = df['sma_50']\n\nbuy_price, sell_price, signal = implement_sma_strategy(df['Close'], sma_20, sma_50)\n```\n\n- BAC SMA (20,50) 거래 신호를 플로팅합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\r\nplt.plot(df['Close'], alpha = 0.3, label = 'BAC')\nplt.plot(sma_20, alpha = 0.6, label = 'SMA 20')\nplt.plot(sma_50, alpha = 0.6, label = 'SMA 50')\nplt.scatter(df.index, buy_price, marker = '^', s = 200, color = 'darkblue', label = 'BUY SIGNAL')\nplt.scatter(df.index, sell_price, marker = 'v', s = 200, color = 'crimson', label = 'SELL SIGNAL')\nplt.legend(loc = 'upper left')\nplt.title('BAC SMA CROSSOVER TRADING SIGNALS')\nplt.xlabel('Date')\nplt.ylabel('Close Price USD')\nplt.show()\r\n```\n\n<img src=\"/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_5.png\" />\n\n- 포지션 생성\n\n```js\r\nposition = []\nfor i in range(len(signal)):\n    if signal[i] > 1:\n        position.append(0)\n    else:\n        position.append(1)\n        \nfor i in range(len(df['Close'])):\n    if signal[i] == 1:\n        position[i] = 1\n    elif signal[i] == -1:\n        position[i] = 0\n    else:\n        position[i] = position[i-1]\n\nsma_20 = pd.DataFrame(sma_20).rename(columns = {0:'sma_20'})\nsma_50 = pd.DataFrame(sma_50).rename(columns = {0:'sma_50'}) \nsignal = pd.DataFrame(signal).rename(columns = {0:'sma_signal'}).set_index(df.index)\nposition = pd.DataFrame(position).rename(columns = {0:'sma_position'}).set_index(df.index)\n\nframes = [sma_20, sma_50, signal, position]\nstrategy = pd.concat(frames, join = 'inner', axis = 1)\nstrategy = strategy.reset_index().drop('Date', axis = 1)\r\n```\n\n<div class=\"content-ad\"></div>\n\n- 우리 전략의 백테스팅을 수행중입니다\n\n```js\nmsft_ret = pd.DataFrame(np.diff(df['Close'])).rename(columns = {0:'returns'})\nsma_strategy_ret = []\n\nfor i in range(len(msft_ret)):\n    try:\n        returns = msft_ret['returns'].iloc[i]*strategy['sma_position'].iloc[i]\n        sma_strategy_ret.append(returns)\n    except:\n        pass\n\nsma_strategy_ret_df = pd.DataFrame(sma_strategy_ret).rename(columns = {0:'sma_returns'})\n\ninvestment_value = 100000\nnumber_of_stocks = math.floor(investment_value/df['Close'].iloc[1])\nsma_investment_ret = []\n\nfor i in range(len(sma_strategy_ret_df['sma_returns'])):\n    returns = number_of_stocks*sma_strategy_ret_df['sma_returns'].iloc[i]\n    sma_investment_ret.append(returns)\n\nsma_investment_ret_df = pd.DataFrame(sma_investment_ret).rename(columns = {0:'investment_returns'})\ntotal_investment_ret = round(sum(sma_investment_ret_df['investment_returns']), 2)\nprint(cl('장기 배당 수익 전략에 $100K 투자로 얻은 이익: ${}'.format(total_investment_ret), attrs = ['bold']))\n\n장기 배당 수익 전략에 $100K 투자로 얻은 이익: $13473.41\n```\n\n## 수동 매수 & 보유 전략\n\n- 일일 수익에 기반한 누적 수익률 계산 중\n\n<div class=\"content-ad\"></div>\n\n```js\ndf['daily_return'] = df['Close'].pct_change()\n# 누적 수익률 계산\ndf['cum_return'] = np.exp(np.log1p(df['daily_return']).cumsum())\n\n투자금 = 100000\n수익률=(df['cum_return'].iloc[-1]-1)*투자금\nprint(round(수익률,2))\n19337.52\n\n수익=round(수익률,2)\nprint(cl('BAC에 10만 달러를 투자하여 Buy & Hold 전략에서 얻은 수익: ${} '.format(수익), attrs = ['bold']))\n\nBAC에 10만 달러를 투자하여 Buy & Hold 전략에서 얻은 수익: $19337.52 \n```\n\n- 결과 그래프 그리기\n\n```js\ndf['cum_return'].plot()\nplt.title('BAC Buy-Hold 누적 수익률')\n```\n\n<img src=\"/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_6.png\" />\n\n\n<div class=\"content-ad\"></div>\n\n## 결론\n\n- 2023년 1월 3일부터 2024년 5월 31일까지의 백테스트 결과를 기반으로, KMA 알고 트레이딩 전략은 SMA 크로스오버 및 Buy & Hold 전략에 비해 매우 유망한 성과를 보여주었습니다.\n\n```js\nBAC에 10만 달러를 투자하여 KMA 전략으로 얻은 이익 : $29026.39\n\nBAC에 10만 달러를 투자하여 Buy & Hold 전략으로 얻은 이익 : $19337.52\n\nBAC에 10만 달러를 투자하여 SMA 크로스오버 전략으로 얻은 이익 : $13473.41\n```\n\n![이미지](/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_7.png)\n\n<div class=\"content-ad\"></div>\n\n- 우리는 KF가 TTI의 제한을 극복하고 algo-trading 전략의 성능을 향상시킬 수 있다는 것을 보여줬어요.\n- 비선형 시스템, 이상치 및 잡음을 효율적이고 견고하게 처리하면서 동시에 최적 부드량화와 자동 매개변수 추정이 가능한 KF 프레임워크는 모든 KF 수정사항과 이점을 함께 포함할 수 있게 해 줄 거에요.\n\n## 전체 Python 코드 및 입출력\n\n```js\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport yfinance as yf\nfrom pandas_datareader import data as web\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nfrom datetime import datetime as dt, timedelta as td\nfrom pykalman import KalmanFilter\nsns.set()\n\ndata = yf.download('BAC', start='2023-01-01', end='2024-06-01')\n\ndf=data.drop(columns=['Open', 'High','Low','Adj Close','Volume'])\ndf.tail()\n\nClose\nDate \n2024-05-24 39.700001\n2024-05-28 39.320000\n2024-05-29 38.720001\n2024-05-30 38.630001\n2024-05-31 39.990002\n\nimport matplotlib.pyplot as plt \nimport requests\nimport math\nfrom termcolor import colored as cl \n\nfrom pykalman import KalmanFilter\n\nplt.style.use('fivethirtyeight')\nplt.rcParams['figure.figsize'] = (15, 8)\n\nkf = KalmanFilter(\n    transition_matrices = [1],\n    observation_matrices = [1],\n    initial_state_mean = 0,\n    initial_state_covariance = 1,\n    observation_covariance=1,\n    transition_covariance=0.01\n)\nstate_means, _ = kf.filter(df.values)\nstate_means = pd.Series(state_means.flatten(), index=df.index)\n\n...\n\nprint(signal)\n[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 0, 0, ...\n\nposition = []\nfor i in range(len(signal)):\n    if signal[i] > 1:\n        position.append(0)\n    else:\n        position.append(1)\n        \nfor i in range(len(df['Close'])):\n    if signal[i] == 1:\n        position[i] = 1\n    elif signal[i] == -1:\n        position[i] = 0\n    else:\n        position[i] = position[i-1]\n\nsma_20 = pd.DataFrame(sma_20).rename(columns = {0:'sma_20'})\nsma_50 = pd.DataFrame(sma_50).rename(columns = {0:'sma_50'}) \nsignal = pd.DataFrame(signal).rename(columns = {0:'sma_signal'}).set_index(df.index)\nposition = pd.DataFrame(position).rename(columns = {0:'sma_position'}).set_index(df.index)\n\n...\n\nprint(cl('100K달러를 BAC에 투자하여 전략으로 얻은 이익 : ${}'.format(total_investment_ret), attrs = ['bold']))\n\n100K달러를 BAC에 투자하여 전략으로 얻은 이익 : $13473.41\r\n```\n\n## 더 알아보기\n\n<div class=\"content-ad\"></div>\n\n- 신호/잡음 비율이 낮은 칼만 필터 기반 객체 추적\n- 칼만 필터를 사용한 대상 궤적 추적 성능 QC 분석\n- 견고한 1차원 칼만 필터의 해부학\n- 칼만 필터를 사용한 주식 시장 변동성 예측\n\n## 참고 자료\n\n- 파이썬에서 SMA를 이용한 알고리즘 트레이딩\n- 금융 분야에서의 칼만 필터 (KF)\n- 칼만 필터를 기반으로 한 트레이딩 전략 구현\n- 파이썬에서 칼만 필터, 칼만 스무서, EM 알고리즘 구현\n- 칼만 필터를 활용한 주식 거래 마스터하기: 포괄적인 가이드\n- 파이썬에서 주식 가격 예측을 위한 칼만 필터 사용\n- 주식 거래에서의 칼만 필터\n- 시장 탁계를 탐색하는 주식 분석에서의 칼만 필터\n\n## 연락처\n\n<div class=\"content-ad\"></div>\n\n- 웹사이트\n- GitHub\n- X/트위터\n- 핀터레스트\n- 마스토돈\n- 텀블러","ogImage":{"url":"/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_0.png"},"coverImage":"/assets/img/2024-06-20-Noise-ResistantKalmanFilterMovingAverageKMAvsSMACrossoverAlgo-TradingStrategiesBACShowcase_0.png","tag":["Tech"],"readingTime":17},{"title":"오디오 데이터에 대한 대화형 감정 분석","description":"","date":"2024-06-20 04:41","slug":"2024-06-20-ConversationalSentimentAnalysisonAudioData","content":"\n\n<img src=\"/assets/img/2024-06-20-ConversationalSentimentAnalysisonAudioData_0.png\" />\n\n감성 분석 또는 의견 분석은 자연어 처리(NLP)에서 널리 사용되는 작업입니다. NLP 기술을 텍스트 데이터에 특히 적용하는 맥락에서, 주요 목표는 주어진 텍스트를 다양한 감성 클래스에 분류할 수 있는 모델을 훈련하는 것입니다. 감성 분류기의 고수준 개요는 아래 이미지에 나와 있습니다.\n\n<img src=\"/assets/img/2024-06-20-ConversationalSentimentAnalysisonAudioData_1.png\" />\n\n예를 들어, 세 가지 클래스 분류 문제의 클래스는 긍정적, 부정적 및 중립일 수 있습니다. 세 가지 클래스의 감성 분석 문제의 예는 인기 있는 Twitter 감성 분석 데이터 세트입니다. 이 데이터는 트위터 사용자들이 게시한 다국어 트윗에 대한 Entity-level 감성 분석 작업입니다.\n\n<div class=\"content-ad\"></div>\n\n과거의 자연어처리(NLP) 연구 및 개발 대부분은 주로 텍스트에 감성 분석을 적용하는 데 중점을 두었습니다. 그러나 최근에는 사용자들 사이에서 음성 기반 상호 작용 도구의 대규모 채택과 인기를 볼 수 있었으며, 이는 연구자들과 기관들을 음성 영역에서 감성 분류기를 구축하도록 이끕니다.\n\n따라서 이 게시물에서는 AssemblyAI API와 Python을 사용하여 대화 데이터에 감성 분석 시스템을 구축하는 방법을 보여줄 것입니다. 이 종단 간 시스템은 엄격한 고객 지원 및 피드백 평가와 관련이 있는 영역에서 광범위한 적용 가능성을 지니며, 특히 음성 도메인에서 중요하고 가치 있는 문제를 해결하는 데 도움이 됩니다. 마지막으로 얻은 결과물을 이해하기 쉽게 향상시키고 데이터에서 적절한 통찰을 얻기 위한 분석을 보여줄 것입니다.\n\n이 글의 코드는 여기에서 찾을 수 있습니다. 게시물의 주요 내용은 다음과 같습니다:\n\n- 대화형 오디오 데이터에 대한 감성 분석\n- 감성 분석 결과\n- 감성 분석 통찰력\n\n<div class=\"content-ad\"></div>\n\n# 대화 오디오 데이터에 대한 감정 분석\n\n이 섹션에서는, 녹음된 음성 대화 조각에서 개별 문장을 세 가지 감정 클래스로 분류하는 AssemblyAI API의 사용을 보여드리겠습니다: 긍정적, 부정적 및 중립적.\n\n![이미지](/assets/img/2024-06-20-ConversationalSentimentAnalysisonAudioData_2.png)\n\n## 단계 1: 요구 사항 설치\n\n<div class=\"content-ad\"></div>\n\n감정 분류기를 구축하는 데 필요한 요소가 매우 적습니다. Python 라이브러리 관점에서 requests 패키지만 필요합니다. 아래와 같이 수행할 수 있습니다:\n\n```js\npip install requests\n```\n\n## 단계 2: API 토큰 생성\n\n다음 단계는 AssemblyAI 웹사이트에 계정을 생성하는 것입니다. 이 과정은 무료로 진행할 수 있습니다. 계정을 생성하면 프라이빗 API 액세스 키를 받게 되는데, 이것을 사용하여 음성을 텍스트로 변환하는 모델에 접근할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n## 단계 3: 오디오 파일 업로드\n\n이 튜토리얼의 목적을 위해, 두 사람 간의 미리 녹음된 오디오 대화를 사용하여 감정 분석을 수행하겠습니다. API 키를 획득하셨다면, 미리 녹음된 오디오 파일에 대한 감정 분류 작업을 진행할 수 있습니다.\n\n그러나 그 전에, 오디오 파일을 업로드하여 URL을 통해 액세스할 수 있도록 해야 합니다. AWS S3 버킷에 업로드하거나 SoundCloud 또는 AssemblyAI의 셀프-호스팅 서비스와 같은 오디오 호스팅 서비스에 업로드하는 옵션이 있습니다. 저는 오디오 파일을 SoundCloud에 업로드하여 아래에서 액세스할 수 있도록 했습니다.\n\n만약 AssemblyAI의 호스팅 서비스에 오디오 파일을 직접 업로드하고 싶다면, 그것도 가능합니다. 저는 코드 블록 안에서 이 단계별 절차를 보여드렸습니다.\n\n<div class=\"content-ad\"></div>\n\n## 단계 3.1: 요구 사항 가져오기\n\n프로젝트에 필요한 요구 사항을 가져오는 것으로 시작합니다.\n\n## 단계 3.2: 파일 위치 및 API 키 지정\n\n다음으로, 로컬 컴퓨터에서 오디오 파일의 위치와 가입 후 얻은 API 키를 지정해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n## 단계 3.3: 업로드 엔드포인트 지정\n\n- 엔드포인트: 여기서 사용할 서비스인 \"upload\" 서비스를 지정합니다.\n- 헤더: API 키 및 콘텐츠 유형을 보유합니다.\n\n## 단계 3.4: 업로드 함수 정의\n\n오디오 파일은 한 번에 5 MB(5,242,880 바이트)까지만 업로드할 수 있습니다. 따라서 데이터를 청크 단위로 업로드해야 합니다. 이후에 서비스 엔드포인트에서 이들을 합칩니다. 따라서 많은 URL을 처리할 필요가 없어집니다.\n\n<div class=\"content-ad\"></div>\n\n## 단계 3.5: 업로드\n\n마지막 단계는 POST 요청을 호출하는 것입니다. POST 요청의 응답은 오디오 파일의 업로드 URL을 보유한 JSON입니다. 이 URL을 사용하여 오디오의 감정 분류를 실행하는 다음 단계에 사용할 것입니다.\n\n## 단계 4: 감정 분석\n\n이제 이 단계에서 오디오 파일에 대해 감정 분석 작업을 수행하기 위한 필요한 모든 전제조건을 충족했습니다. 이제 우리는 API를 호출하여 원하는 결과를 가져오는 것으로 계속할 수 있습니다. 이는 아래 소목록에서 설명되는 2단계 프로세스입니다.\n\n<div class=\"content-ad\"></div>\n\n## 단계 4.1: 전사용 파일 제출\n\n첫 번째 단계는 HTTP POST 요청을 호출하는 것입니다. 이는 기본으로 실행되는 AI 모델에 오디오 파일을 보내 전사를 위임하고, 전사된 텍스트에 대해 감정 분석을 수행하도록 지시하는 것입니다.\n\nPOST 요청에 전달되는 인수는 다음과 같습니다:\n\n- endpoint: 호출할 전사 서비스를 지정합니다.\n- json: 오디오 파일의 URL을 audio_url 키로 포함합니다. 대화 데이터에 대한 감정 분석을 수행하려면 sentiment_analysis 플래그와 speaker_labels를 True로 설정합니다.\n- headers: 허가 키와 콘텐츠 유형을 보유합니다.\n\n<div class=\"content-ad\"></div>\n\n포스트 요청의 현재 상태는 JSON 응답으로 받았을 때 대기 중인 상태입니다. 이는 현재 오디오가 변환 중임을 나타냅니다.\n\n또한, JSON 응답에서 sentiment_analysis 플래그도 True로 나와 있습니다. 그러나 sentiment_analysis_results 키에 해당하는 값은 상태가 대기 중이기 때문에 None입니다.\n\n## 단계 4.2: 변환 결과 가져오기\n\nPOST 요청의 상태를 확인하려면 위에서 받은 JSON 응답의 id 키를 사용하여 GET 요청을 해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n다음으로, 아래 코드 블록에 나와 있는 것처럼 GET 요청을 진행할 수 있습니다.\n\nGET 요청에 전달되는 인수는 다음과 같습니다:\n\n- endpoint: 이는 호출된 서비스를 지정하며 id 키를 사용하여 결정된 API 호출 식별자를 나타냅니다.\n- headers: 이는 귀하의 고유한 API 키를 보유합니다.\n\n여기서 중요한 점은 상태 키가 completed로 변경될 때까지 전사 결과가 준비되지 않는다는 것입니다. 전사에 걸리는 시간은 입력 오디오 파일의 길이에 따라 다릅니다. 따라서 전사 상태를 확인하기 위해 규칙적인 간격으로 반복적인 GET 요청을 수행해야 합니다. 이를 위한 간단한 방법을 아래 구현하였습니다:\n\n<div class=\"content-ad\"></div>\n\n# 감정 분석 결과\n\n일단 상태가 완료로 변경되면 아래와 유사한 응답을 받게 될 것입니다.\n\n- JSON 응답에서의 상태가 완료로 표시됩니다. 이는 오디오 전사에 오류가 없었음을 나타냅니다.\n- 텍스트 키에는 입력 오디오 대화의 전체 전사가 포함되어 있으며, 총 22개 문장이 포함됩니다.\n- 오디오 파일은 여러 화자로 구성되어 있기 때문에, 단어 키 내의 모든 화자 키를 Not Null로 볼 수 있습니다. 화자 키는 \"A\" 또는 \"B\"일 수 있습니다.\n- 모든 개별 단어와 전체 전사 텍스트에 대한 확신 점수를 볼 수 있습니다. 이 점수는 0부터 1까지 범위를 가지며, 0이 가장 낮고 1이 가장 높습니다.\n- 오디오의 각각 22개 문장에 대한 감정 분석 결과는 JSON 응답의 sentiment_analysis_results 키를 사용하여 액세스할 수 있습니다.\n- 각 문장에 대응하여, 4번 항목과 유사한 확신 점수를 얻을 수 있습니다.\n- 각 문장의 감정은 문장 사전의 sentiment 키를 사용하여 검색할 수 있습니다. 두 번째 문장에 대한 감정 분석 결과가 아래에 표시되어 있습니다:\n\n# 감정 분석 인사이트\n\n<div class=\"content-ad\"></div>\n\nJSON은 보통 읽고 해석하기 어렵습니다. 그래서 데이터를 시각적으로 보기 좋게 만들고 추가 분석을 수행하기 위해 위의 감정 분석 결과를 DataFrame으로 변환합시다. 우리는 문장의 텍스트, 지속 시간, 스피커, 그리고 문장의 감정을 저장할 것입니다. 이를 아래에서 구현하겠습니다:\n\n위 코드 스니펫으로 생성된 DataFrame은 아래 이미지에 표시됩니다. 여기서 대화 중 발화된 22개의 문장과 해당하는 스피커 레이블(\"A\"와 \"B\"), 문장의 지속 시간(초), 그리고 모델이 예측한 문장의 감정이 포함되어 있습니다.\n\n<img src=\"/assets/img/2024-06-20-ConversationalSentimentAnalysisonAudioData_3.png\" />\n\n## #1 스피커 분포\n\n<div class=\"content-ad\"></div>\n\n각 화자가 말한 문장 수는 아래와 같이 value_counts() 메소드를 사용하여 계산할 수 있습니다:\n\n화자들의 백분율 분포를 보려면 다음과 같이 value_counts() 메소드에 normalize = True를 전달할 수 있습니다:\n\n“A”와 “B” 두 화자 모두 문장 수 측면에서 대화에 동등하게 기여했습니다.\n\n## #2 화자 지속 시간 분포\n\n<div class=\"content-ad\"></div>\n\n다음으로 대화 참가자 각각의 기여도를 계산해 봅시다. 아래에서 확인할 수 있습니다:\n\ngroupby() 메서드를 사용하여 각 발화자의 발화 시간을 총합하여 계산했습니다. 발화 시간 측면에서 발화자 A가 우세한 발화자입니다.\n\n## #3 감정 분포\n\n대화 중 총 22문장 중 부정 감정으로 분류된 문장은 3개뿐이었습니다. 또한 양의 감정으로 분류된 문장은 없었습니다.\n\n<div class=\"content-ad\"></div>\n\n정규화된 분포는 다음과 같이 계산할 수 있습니다:\n\n## 스피커 레벨에서 #4 감정 분포\n\n마지막으로, 개별 스피커 간의 감정 분포를 계산해 봅시다. 여기서는 groupby() 메서드 대신 더 나은 시각화를 위해 crosstab()을 사용할 것입니다. 아래에서 이를 시연합니다:\n\n\"A\" 스피커가 한 부정적 문장의 비율이 \"B\" 스피커보다 더 많았습니다.\n\n<div class=\"content-ad\"></div>\n\n## #5 감정 수준별 평균 문장 지속 시간\n\n마지막으로, 우리는 개별 감정 클래스에 속하는 문장의 평균 지속 시간을 계산할 것입니다. 이는 아래의 groupby() 메서드를 사용하여 구현되었습니다:\n\n부정적인 문장의 평균 지속 시간은 중립 문장보다 작습니다.\n\n마무리로, 이 글에서는 AssemblyAI API의 특정 NLP 사용 사례에 대해 논의했습니다. 구체적으로, 여러 화자로 구성된 미리 녹음된 오디오 파일에서 감정 분류 모듈을 구축하는 방법을 살펴보았습니다. 마지막으로, 감정 분석 결과에 대해 철저한 분석을 수행했습니다. API로부터 얻은 결과는 입력 오디오 파일의 22개의 개별 문장의 감정을 강조했습니다.\n\n<div class=\"content-ad\"></div>\n\n이 글의 코드는 여기서 찾을 수 있어요.\n\n다음 게시물에서는 어셈블리 AI API의 더 많은 사용 사례에 대해 논의할 거예요. Entity Detection, Content Moderation 등 기술적, 실용적 관점에서 더 자세하게 다루겠습니다.\n\n다음에 또 봐요. 읽어 주셔서 감사해요.\n\n🚀 매일 뉴스레터를 구독하면 320개 이상의 글이 실린 데이터 과학 PDF(550페이지)를 무료로 받을 수 있어요:\n\n<div class=\"content-ad\"></div>\n\n<table>\n  <img src=\"https://miro.medium.com/v2/resize:fit:1400/0*QXJuDEr_pCNDtj4D.gif\" />\n</table>\n\nDDI 중간 게시글 바닥 링크(DDI)\n\nDataDrivenInvestor.com에서 방문하세요\n\nDDIntel을 여기에서 구독하세요.\n\n<div class=\"content-ad\"></div>\n\n주요 기사:\n\n여기서 우리의 창조자 생태계에 참여하세요.\n\nDDI 공식 텔레그램 채널: [https://t.me/+tafUp6ecEys4YjQ1](https://t.me/+tafUp6ecEys4YjQ1)\n\nLinkedIn, Twitter, YouTube, 그리고 Facebook에서 팔로우해보세요.","ogImage":{"url":"/assets/img/2024-06-20-ConversationalSentimentAnalysisonAudioData_0.png"},"coverImage":"/assets/img/2024-06-20-ConversationalSentimentAnalysisonAudioData_0.png","tag":["Tech"],"readingTime":7},{"title":"웹을 당신의 최고 친구 데이터 제공업체로 만들어 보세요","description":"","date":"2024-06-20 04:38","slug":"2024-06-20-MaketheWebyourbestfrienddataprovider","content":"\n\n<img src=\"/assets/img/2024-06-20-MaketheWebyourbestfrienddataprovider_0.png\" />\n\nLLM을 도구로 갖추는 아이디어는 그리 새로운 것은 아닙니다. LangChain과 Llamaindex와 같은 강력하고 잘 알려진 프레임워크는 몇 달 전에 이미 이를 실행했습니다.\n\n그들은 위험 부담에 대한 승리했어요!\n\n지금 완전히 열광 중인 AI 에이전트 혁명은 도구 패러다임을 충분히 활용하여 놀라운 결과를 얻고 있어요.\n\n<div class=\"content-ad\"></div>\n\n인공지능이 지금 새로운 벽을 맞이했습니다: 계산 요구 사항과 무료로 이용 가능한 데이터의 끝.\n\n이 기사에서는 이러한 도전 과제를 다루고, 우리의 LLM 애플리케이션을 새로운 관련 데이터로 무료로 풍부하게 만드는 방법을 배울 것입니다!\n\n```js\n# 목차\n- 중립적 LLM 방향\n- 검색 보강 생성: 여전히 최고의 도구\n- 웹 검색 및 NLP 뉴스는 도구입니다\n- 단락에서 문서까지\n- 그럼 이제 무엇을 해야 할까요? 직접 문서 저장소 만들기\n```\n\n# 중립적 LLM\n\n<div class=\"content-ad\"></div>\n\n기술 발전은 이미 지난 해의 많은 작업을 이미 완료했습니다. 새로운 하드웨어와 GPU 세트는 이제 더 빠르고 저렴하게 복잡한 신경망 계산을 처리할 수 있습니다.\n\n동시에 엣지-모바일 기기로의 명확한 이동이 있으며, 작은 언어 모델이 큰 모델과 경쟁할 수 있도록 하는 데 특별한 주의를 기울이고 있습니다. TinyLlama 프로젝트를 시작으로 목표는 모바일 전화 하드웨어에서 실행할만큼 충분히 작지만 환각하지 않고 유용한 모델을 만드는 것입니다.\n\n규모 법칙 이상으로, 우리는 LLM이 추상화하고 이성적으로 추론하는 능력을 잃는 한계를 이해해야 합니다. 데이터 없이 신경망을 구축할 수 없지만 동시에 우리는 새로운 위키피디아를 만들고 있지는 않습니다, 맞죠?\n\nAI 커뮤니티에서 진정한 권위자인 Cobus Greyling은 항상 이것을 강조합니다: 데이터 처리 및 데이터 처리를 LLM 응용 프로그램에서 분리하세요. 그에게는 LLM 응용 프로그램은 모델에 중립적이어야 하며 LLM을 유틸리티로 취급해야 한다 - 그러나 이는 신뢰할 수 있는 데이터, 좋은 소식 및 선별된 데이터 집합에 대해 작업해야 한다는 것을 의미합니다.\n\n<div class=\"content-ad\"></div>\n\n우수한 데이터를 이용하면 작은 모델(20억 파라미터 미만)이 탁월한 성과를 거둘 수 있어요!\n\n![image](/assets/img/2024-06-20-MaketheWebyourbestfrienddataprovider_1.png)\n\n## 검색 증강 생성: 여전히 최고의 도구\n\n좋은 말들이지만, 이를 어떻게 구현할까요?\n\n<div class=\"content-ad\"></div>\n\nRetrieval Augmented Generation (RAG)은 생성된 텍스트의 품질을 향상시키기 위해 자연어 처리에서 사용되는 기술입니다.\n\n마술은 없어요! 우리는 대규모 외부 지식 원본(데이터베이스나 문서 코퍼스 등)에서 관련 정보를 통합하여 LLM 프롬프트에 적용합니다. RAG에서는 쿼리나 프롬프트에 대한 응답을 생성할 때 모델이 매우 좋은 작업을 합니다:\n\n- 먼저 검색 메커니즘을 사용해 외부 지식 원본에서 관련 정보를 검색합니다.\n- 검색된 정보는 그 후 생성 모델로 투입되어 자신의 지식을 보완하고\n- 보다 정확하고 유익한 응답을 생성합니다.\n\n예를 들어, 특정 역사적 사건에 대한 질문을 하는 경우 RAG 모델은 먼저 역사 문서의 대규모 데이터베이스에서 해당 사건에 대한 정보를 검색하고, 그 정보를 사용하여 귀하의 질문에 대한 세부적이고 정확한 응답을 생성합니다.\n\n<div class=\"content-ad\"></div>\n\nRAG은 순수 생성 모델과 구체적인 사실 정보에 제한을 받을 수 있는 것을 합하고, 오직 검색 기반 모델과 창의적인 대답을 생성하는 데 어려움을 겪을 수 있는 것을 합하면서 이 둘 간의 간극을 좁히는 데 도움을 줍니다.\n\n그러니까 우리 수학 시간을 시작해 볼까요:\n\n- 좋은 이유를 제공하는 작은 LLM이 주어지면\n- 좋고 최신 정보를 위해 RAG 파이프라인을 설정하면\n\n... 전례 없는 그리고 의미 있는 문서 세트를 만드는 방법이 필요합니다.\n\n<div class=\"content-ad\"></div>\n\n# 웹 검색 및 NLP 뉴스는 도구들입니다\n\n이전 글에서 LangChain을 DuckDuckGo 웹 검색과 함께 사용하는 방법에 대해 설명했었습니다.\n\n최신 뉴스와 업데이트된 정보를 검색 엔진을 사용하여 가져오는 것은 어떤 반 데이터 모형으로 향하는 놀라운 방법입니다. 생성 모델의 마감일 한계가 우리가 필요한 모든 것과 외부 지식을 제공할 수 있기 때문에 우회됩니다.\n\n확인되고 진실한 정보가 있는 경우, 우리의 LLM 응용 프로그램은 좋은 RAG 전략을 사용함으로써보다 효과적 일 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n하지만 잘 알려진 웹 검색 도구에도 제한이 있습니다! 무료 Google Colab 노트북을 사용하여 확인해 보세요.\n\n```js\n%pip install --upgrade --quiet langchain langchain-community faiss-cpu \n%pip install tiktoken duckduckgo-search llama-cpp-agent newspaper3k\n```\n\nLangchain과 함께 duckduckgo-search와 newspaper3k(강력한 NLP 웹 HTML 문서 파서)를 설치합니다.\n\n먼저, 웹 검색의 출력이 무엇인지 살펴봅시다:\n\n<div class=\"content-ad\"></div>\n\n```js\nfrom langchain_community.utilities import DuckDuckGoSearchAPIWrapper\nwrapper = DuckDuckGoSearchAPIWrapper(region='us-en', \n                                   time=\"y\", \n                                   max_results=10) #time Options: d, w, m, y\n\nrawdb = wrapper.results('LLM Mixture of Agents',max_results=5)\r\n```\n\n여기서는 에이전트 도구가 아닌 wrapper 자체를 사용하여 \"LLM 혼합 에이전트\"에 대한 정보를 찾습니다. 결과를 출력하고 rawdb 변수에 저장하면 다음과 같은 내용이 나타납니다:\n\n```js\n[\n    {\n        'snippet': '대형 언어 모델(LM)의 최근 발전은 자연어 이해 및 생성 작업에서 상당한 성능을 보여줍니다. 증가하는 LLM의 수로 인해 여러 LLM의 집단적 전문지식을 어떻게 활용할지는 흥미로운 개방 방향입니다. 이 목표를 향해, 우리는 Mixture-of-Agents (MoA) 방법을 통해 여러 LLM의 집단적 강점을 활용하는 새로운 접근 방식을 제안합니다.',\n        'title': 'Mixture-of-Agents Enhances Large Language Model Capabilities',\n        'link': 'https://arxiv.org/abs/2406.04692'\n    },\n    {\n        'snippet': '첫째로, 우리는 답안 제공자들에 의해 생성된 답 중 하나를 선택하기 위해 집계 모델을 사용하는 LLM 기반 순위 결정기를 Mixture-of-Agents와 비교합니다. 쓰기 결과는 Figure 4에 나와 있으며 MoA 접근 방식이 LLM-순위 결정층 베이스라인을 크게 능가함을 관찰할 수 있습니다.',\n        'title': 'Mixture-of-Agents Enhances Large Language Model Capabilities - arXiv.org',\n        'link': 'https://arxiv.org/html/2406.04692v1'\n    },\n    {\n        'snippet': '우리는 여러 LLM의 집단적 강점을 활용하여 최첨단 품질을 향상시키기 위한 Mixture of Agents (MoA) 접근 방식을 소개합니다. 그리고 우리는 상태-of-the-art의 품질을 향상하기 위해 여러 오픈소스 LLM 에이전트들을 활용하는 참조 구현인 Together MoA을 제공합니다. Together MoA는 AlpacaEval 2.0에서 65.1%의 점수를 달성하여 이전 리더 GPT-4o (57.5%)를 능가합니다.',\n        'title': 'Together MoA — collective intelligence of open-source models pushing ...',\n        'link': 'https://www.together.ai/blog/together-moa'\n    },\n    {\n        'snippet': '이 목표를 향해, 여러 LLM의 집단적 강점을 Mixture-of-Agents (MoA) 방법론을 통해 활용하는 새로운 접근 방식을 제안합니다. 우리의 접근 방식에서는 각 층이 여러 LLM 에이전트로 이루어진 층화식 MoA 아키텍처를 구성합니다. 각 에이전트는 이전 층에서 생성된 모든 출력을 보조 정보로 받습니다.',\n        'title': 'Mixture-of-Agents Enhances Large Language Model Capabilities',\n        'link': 'https://huggingface.co/papers/2406.04692'\n    },\n    {\n        'snippet': 'Mixture of Agents (MoA)는 여러 LLM의 집단적 강점을 활용하여 성능을 향상시키는 혁신적인 접근 방식으로, 최첨단 결과를 달성합니다. 각 층이 여러 LLM 에이전트로 이루어진 층화 구조를 사용하여 MoA는 65.1%의 점수로 AlpacaEval 2.0에서 GPT-4 Omni의 57.5%를 크게 능가합니다.',\n        'title': 'GitHub - togethercomputer/MoA',\n        'link': 'https://github.com/togethercomputer/moa'\n    }\n]\r\n```\n\n결과가 정확히 5개인 것을 확인할 수 있습니다. 하지만 텍스트가 짧네요! 이 짧은 조각 텍스트는 구체적인 사실적 질문에 사용할 수는 있지만 새로운 지식 베이스를 구축하기에는 부족합니다!\n\n<div class=\"content-ad\"></div>\n\n좋은 점은 링크도 얻었다는 것이에요 🤣\n\n![image](/assets/img/2024-06-20-MaketheWebyourbestfrienddataprovider_2.png)\n\n# 스니펫에서 문서로\n\nGitHub 레포지토리를 하나씩 검색하면서 쉽고 완벽한 웹 검색을 찾고 있었는데, newspaper3k를 만나기 전까지요.\n\n<div class=\"content-ad\"></div>\n\n이 Python 라이브러리는 검색 엔진 결과에서 전체 텍스트를 얻기 위한 입구입니다. 그게 전부가 아닙니다!\n\nnltk 라이브러리도 함께 사용되기 때문에 키워드, 설명, 이미지 URL 및 요약과 같은 다양한 메타데이터로 정보를 보완할 수 있습니다!\n\nGoogle Colab에서 항상 살펴봅시다.\n\n```js\nfrom newspaper import Article\nimport nltk\nnltk.download('punkt')\n```\n\n<div class=\"content-ad\"></div>\n\n웹 페이지 텍스트 추출 함수들은 정말 쉽게 사용할 수 있어요. NLTK 기능을 포함하려면 우선 Punkt를 다운로드해야 해요.\n\nNLTK에서 Punkt는 문장 토큰화에 사용되는 비지도 학습 가능한 모델이에요. 이 모델은 문장을 단어로 나누어 문장 시작 단어, 전치사구, 약어에 대한 모델을 개발함으로써 문장을 분리해요.\n\n이제 우리가 작은 Neural toolkit를 준비했으니 웹 페이지에서 가능한 모든 것을 추출해 봅시다. 이전 DuckDuckGo 검색에서 추출된 링크 중 하나를 사용할 수 있어요: https://www.together.ai/blog/together-moa\n\n```js\nurl = 'https://www.together.ai/blog/together-moa'\narticle = Article(url) # payload requests를 불러와요\narticle.download()     # 로컬로 데이터와 메타데이터를 버퍼링해요\narticle.parse()        # 텍스트 추출\narticle.nlp()          # 키워드와 요약을 위해 nlp 도구 실행\n```\n\n<div class=\"content-ad\"></div>\n\n이제 모든 것이 처리되었으니 데이터를 살펴볼 수 있어요:\n\n```js\nprint(article.text)\n---\n우린 Mixture of Agents (MoA)를 소개합니다. 이는 여러 LLM들의 집합적인 강점을 활용하여 최신 기술 수준을 향상시키는 접근법입니다. 또한 우리는 몇몇 오픈 소스 LLM 에이전트를 이용하여 65.1%의 점수를 얻는 Together MoA라는 참조 구현을 제공합니다. 이로써 이전 리더인 GPT-4o (57.5%)를 능가했습니다.\\n\\n그림 1: 에이전트 혼합 구조의 그림. 이 예시 ...\n\n\nprint(article.authors)\n\nprint(article.keywords)\n---\n['에이전트', '20', '전선', '성능', '모델', 'qwen1510bchat', '응답', 'moa', 'llm', '집단', '오픈소스', 'alpacaeval', '제안자', '인텔리전스', 'gpt4o', '능력강화']\n\nprint(article.summary)\n---\n우리는 Mixture of Agents (MoA)를 소개합니다. 이는 여러 LLM들의 집단적인 강점을 활용하여 최신 기술 수준을 향상시키는 접근법입니다.\n개요: 새로운 방법인 Mixture of Agents (MoA)를 소개하게 되어 기쁩니다. 이는 여러 LLM들의 집단적인 강점을 활용하는 혁신적인 접근법입니다.\n우리의 참조 구현인 Together MoA는 오직 오픈 소스 모델을 사용하여 AlpacaEval 2.0에서 57.5%인 GPT-4o를 크게 능가하며 65.1%의 점수를 얻습니다.\n그림 2는 각 모델이 AlpacaEval 2.0에서 기존 점수를 크게 개선함을 보여줍니다. 특히, 오픈 소스 모델만을 사용하여 AlpacaEval 2.0에서 우리는 57.5% (GPT-4o)에서 65.1% (Together MoA)로 7.6%의 절대 향상을 이룩했습니다.\n\nprint(article.meta_description)\n\nprint(article.meta_img)\nhttps://cdn.prod.website-files.com/650c3b59079d92475f37b68f/6667e9c28da8569e846b4632_thumbnail.jpg\n\nprint(article.meta_keywords)\n['']\n```\n\n정말 멋지다고 생각해요!\n\n이 몇 줄의 코드로 전체 텍스트와 중요한 메타데이터를 검색했어요. 웹 리소스가 정말 좋은 경우 날짜와 주 이미지도 간단히 이렇게 얻을 수 있답니다:\n\n<div class=\"content-ad\"></div>\n\n\n```js\r\narticle.top_image\r\narticle.publish_date\r\n```\r\n\r\n![image](/assets/img/2024-06-20-MaketheWebyourbestfrienddataprovider_3.png)\r\n\r\n# 그럼 이제 어떻게 하죠? 자체 문서 저장소 만들기\r\n\r\n지금까지 말한 모든 것들은 데이터/정보가 생성 AI 애플리케이션에 있어 핵심이라는 것을 고려할 때에만 관련이 있습니다. LLM은 이제 NLP 작업을 뛰어나게 수행하므로 좋은 텍스트가 필요합니다.\r\n\n\n<div class=\"content-ad\"></div>\n\n여기서 더 나아가 봅시다! 웹 검색 쿼리를 입력하면 데이터를 풍부하게 모아서 표준 Langchain 형식으로 정리하는 파이프라인을 직접 만들 수 있습니다. 언제든지 사용할 준비가 완료되었어요!\n\n## Wrapper 실행\n\n```js\nfrom newspaper import Article\nimport pickle\nfrom rich.markdown import Markdown\nimport datetime\nfrom rich.console import Console\nfrom langchain.schema.document import Document\nconsole = Console(width=90)\nimport nltk\n# DuckDuckGo 검색 엔진 래퍼 준비\nfrom langchain_community.utilities import DuckDuckGoSearchAPIWrapper\nwrapper = DuckDuckGoSearchAPIWrapper(region='us-en', time=\"y\", max_results=10) #time parameter Options: d, w, m, y\n# 사용자 쿼리 요청\nconsole.print(f'[bold red1]무엇을 검색하시겠습니까?')\nresearch = console.input(f'[bright_green]> ')\nconsole.print(90*'=')\n# Wrapper 실행\nrawdb = wrapper.results(research,max_results=5)\n```\n\n저는 아이작 아시모프의 원자 폭탄에 대한 이야기를 찾아보겠습니다. 그런 다음 예상 출력 형식을 사용하여 데이터베이스를 구축할 거에요. 다시 설명드리자면, 예상 형식은 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n```js\n[\n  {\n    'snippet': '비디오 콜 - 아이작 아시모프 - 다양한 패운데이션 이야기 (1950년대+) 패운데이션 시리즈는 거대한 시간과 공간을 다룹니다. ... 원자폭탄 - H.G. 웰스 - The World Set Free (1914)',\n    'title': '과학 소설이 미래 기술을 예언한 10가지 시간 - 디스트로이드',\n    'link': 'https://www.destructoid.com/10-times-sci-fi-predicted-the-future-of-technology/'\n  },\n  {\n    'snippet': '밤바람과 다른 이야기들. 아이작 아시모프의 최고의 과학 소설. 전체...'\n  }\n]\n```\n\n여기에서 이미 황금 광산을 발견했어요: 우리는 DDG 검색 필드에서 제목, 스니펫 및 링크를 얻을 수 있어요.\n\n## 신문 NLP 도구와 Wrapper 결과 병합\n\n이제 rawdb 리스트를 반복하고 각 URL을 사용하여 newspaper3k를 실행할 수 있습니다. 더 똑똒하게 만들기 위해 반복 중 LangChain Document 객체를 만들어요.\n\n<div class=\"content-ad\"></div>\n\n```python\ndocdocs = []\nfor items in rawdb:\n    url = items[\"link\"]\n    try:  # 만약 URL에 접속할 수 없다면 유용합니다\n        article = Article(url)\n        article.download()\n        article.parse()\n        article.nlp()\n        kw = []\n        # NLTK 키워드와 메타 웹페이지 키워드를 병합합니다\n        for i in article.keywords + article.meta_keywords:\n            if i == '':  # 우리에게는 블랙 키워드가 없습니다\n                pass\n            else:\n                kw.append(i)\n        if article.text == '':  # 때로는 구문 분석할 텍스트가 없습니다. 그래서 스니펫을 사용합니다\n            docdocs.append(Document(page_content=items[\"snippet\"], metadata={\n                'source': items[\"link\"],\n                'title': items[\"title\"],\n                'snippet': items[\"snippet\"],\n                'author': article.authors,\n                'keywords': kw,\n                'meta_description': article.meta_description,\n                'meta_img': article.meta_img,\n                'top_image': article.top_image,\n                'publish_date': article.publish_date,\n                'summary': article.summary}))\n        else:\n            docdocs.append(Document(page_content=article.text.replace('\\n\\n', ''), metadata={\n                'source': items[\"link\"],\n                'title': items[\"title\"],\n                'snippet': items[\"snippet\"],\n                'author': article.authors,\n                'keywords': kw,\n                'meta_description': article.meta_description,\n                'meta_img': article.meta_img,\n                'top_image': article.top_image,\n                'publish_date': article.publish_date,\n                'summary': article.summary}))\n    except:\n        pass\n```\n\n이제 변수 docdocs에는 메타데이터가 풍부한 LangChain 문서 목록이 있습니다. 이를 FAISS와 같은 벡터 데이터베이스에서 직접 사용하거나 로컬 파일에 저장할 수 있습니다. 저는 두 번째 옵션을 선호합니다. 그 이유는 언제든지 이러한 문서를 나중에 병합할 수 있기 때문입니다.\n\n따라서 나는 이러한 문서를 저장하기 위해 피클 형식을 선택한 것입니다. pickle 모듈은 Python 표준 라이브러리에 포함되어 있습니다. Python 개체 구조를 직렬화하고 역 직렬화하기 위한 이진 프로토콜을 구현합니다.\n\n“Pickling”은 Python 개체 계층 구조를 바이트 스트림으로 변환하는 프로세스이며, “unpickling”은 그 반대 작업으로, 바이너리 파일 또는 바이트류 객체에서 바이트 스트림을 개체 계층 구조로 변환하는 작업입니다.\n\n\n<div class=\"content-ad\"></div>\n\n```js\n## 메타데이터와 함께 문서 세트를 pickle에 저장합니다.\nlcdfilename = research.replace(' ','_')+'.lcd'\noutput = open(lcdfilename, 'wb')\npickle.dump(docdocs, output)\noutput.close()\nconsole.print(Markdown(\"> LangChain 문서 데이터가 저장되었습니다...\"))\n```\n\n이제 LangChain 문서를 가지고 로컬 모델을 실행해 볼 수 있어요. 여기에 하나의 도전 과제가 있네요: 왜 llama-cpp-python만 사용해서 시도해 보지 않으세요?\n\n# 결론\n\nWeb 검색 및 자연어 처리(NLP) 도구를 이용하여 최신 및 관련 데이터로 언어 학습 모델(LLM)를 풍부하게 하는 혁신적인 접근 방식을 함께 탐색했습니다.\n\n<div class=\"content-ad\"></div>\n\n이와 같은 전략들은 계산 요구 사항과 무료 데이터의 부족으로 인한 제한을 극복하는 데 중요합니다.\n\n어고노스틱 LLM을 달성하기 위해, 외부 지식 소스를 통합하여 LLM 응답의 정확성과 신뢰도를 향상시키는 Retrieval Augmented Generation (RAG) 기술이 결정적인 기법으로 부상합니다.\n\n저희는 웹 검색 엔진과 newspaper3k와 같은 NLP 라이브러리를 도구로 사용하여 온라인 리소스로부터 전체 텍스트와 가치 있는 메타데이터를 추출하고, 간략한 스니펫을 포괄적인 문서로 변환했습니다.\n\n이 프로세스는 생성 모델의 잘라내기 날짜 제한을 우회하는 것뿐만 아니라 개인화된 문서 저장소를 생성하는 것을 용이하게 합니다.\n\n<div class=\"content-ad\"></div>\n\n무서워하지 마시고 실험해보세요. 하지만 항상 기억하세요, 도구는 좋거나 나쁘지 않습니다! 도구는 사용하는 사람만큼 좋습니다!\n\n만약 이 이야기가 가치 있었고 조금이라도 지원을 보내고 싶다면, 다음을 해볼 수 있습니다:\n\n- 이 이야기에 대해 많이 박수를 보내기\n- 기억할 가치가 있는 부분을 강조하기 (나중에 찾기가 쉽고, 나는 더 나은 기사를 쓸 수 있습니다)\n- '자체 AI 구축 방법 배우기, 이 무료 eBook 다운로드하기'\n- 내 링크를 통해 Medium 멤버십 가입하기 ($5/월로 무제한 Medium 이야기 읽기)\n- Medium에서 나를 팔로우하기\n- 내 최신 기사를 읽기: https://medium.com/@fabio.matricardi\n\n더 많은 내용을 보고 싶다면, 다음은 몇 가지 아이디어입니다:\n\n<div class=\"content-ad\"></div>\n\n구글 Colab 노트북이 있는 GitHub 저장소\n\n![GitHub Repository](/assets/img/2024-06-20-MaketheWebyourbestfrienddataprovider_4.png)\n\n이 이야기는 Generative AI에서 발행되었습니다. 최신 AI 이야기를 알고 싶다면 LinkedIn에서 저희와 연결하고 Zeniteq를 팔로우하세요.\n\n저희의 뉴스레터에 가입하여 최신 generative AI 뉴스와 업데이트를 받아보세요. 함께 AI의 미래를 함께 만들어 봅시다!\n\n<div class=\"content-ad\"></div>\n\n`![2024-06-20-MaketheWebyourbestfrienddataprovider_5.png](/assets/img/2024-06-20-MaketheWebyourbestfrienddataprovider_5.png)`","ogImage":{"url":"/assets/img/2024-06-20-MaketheWebyourbestfrienddataprovider_0.png"},"coverImage":"/assets/img/2024-06-20-MaketheWebyourbestfrienddataprovider_0.png","tag":["Tech"],"readingTime":14},{"title":"Vercel에 Nodejs 백엔드를 배포하는 방법 단계별 가이드","description":"","date":"2024-06-20 04:36","slug":"2024-06-20-HowtoDeployYourNodejsBackendonVercelAStep-by-StepGuide","content":"\n\n<img src=\"/assets/img/2024-06-20-HowtoDeployYourNodejsBackendonVercelAStep-by-StepGuide_0.png\" />\n\nVercel에 Node.js 백엔드를 배포하는 것은 업무를 간편화하면서 애플리케이션을 웹상에서 작동시킬 수 있는 프로세스입니다. 이 수정된 가이드에서는 가장 최신 방법을 사용하여 백엔드를 배포하는 방법을 안내해 드리겠습니다. 시작해 봅시다.\n\n# 1. Vercel 계정 생성\n\n먼저, vercel.com에서 Vercel 계정을 만들어주세요. GitHub, GitLab 또는 Bitbucket 중 선호하는 인증 방법을 선택할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 2. 간단한 Express API 만들기\n\n로컬 머신에 Node.js와 NPM이 설치되어 있는지 확인해주세요. 만약 없다면, https://nodejs.org/ 에서 다운로드할 수 있습니다.\n\n먼저, 새로운 프로젝트용 디렉토리를 만들고 해당 디렉토리로 이동한 후, 새로운 Node.js 프로젝트를 초기화하세요:\n\n```js\nmkdir my-express-api\ncd my-express-api\nnpm init -y\n```\n\n<div class=\"content-ad\"></div>\n\nExpress를 설치하고 index.js 파일을 만드세요:\n\n```js\nnpm install express touch index.js\n```\n\n선호하는 코드 편집기에서 index.js를 열고 기본 Express API를 만들기 위한 다음 코드를 추가하세요:\n\n```js\nconst express = require(\"express\");\nconst app = express();\napp.get(\"/\", (req, res) => {\n  res.send(\"Express on Vercel\");\n});\nconst PORT = process.env.PORT || 5000;\napp.listen(PORT, () => {\n  console.log(`서버가 포트 ${PORT}에서 실행 중입니다`);\n});\n```\n\n<div class=\"content-ad\"></div>\n\n# 3. Express API 내보내기\n\n원하는 위치에 있는 index.js 파일을 수정하여 Express 앱을 내보냅니다:\n\n```js\n// ... (이전 코드) module.exports = app; // Express 앱 내보내기\n```\n\n프로젝트 디렉토리에 vercel.json 파일을 생성하세요.\n\n<div class=\"content-ad\"></div>\n\n```js\ntouch vercel.json\n```\n\nvercel.json 파일 내용:\n\n```js\n{\n  \"version\": 2,\n  \"builds\": [\n    {\n      \"src\": \"index.js\",\n      \"use\": \"@vercel/node\"\n    }\n  ],\n  \"routes\": [\n    {\n      \"src\": \"/(.*)\",\n      \"dest\": \"index.js\"\n    }\n  ]\n}\n```\n\n# 5. Express API 배포하기\n\n<div class=\"content-ad\"></div>\n\n깃 레포지토리를 초기화하고 코드를 커밋한 후에 해당 코드를 소스 레포지토리에 푸시하세요. 이 레포지토리는 GitHub, GitLab 또는 다른 플랫폼에 있을 수 있습니다.\n\n배포가 완료되면 제공된 Vercel URL에서 API에 액세스하여 서비스가 제대로 작동하는지 확인해보세요. 예를 들면 your-app-name.vercel.app와 같이 접속할 수 있습니다.\n\n축하합니다! 이제 Node.js 백엔드가 서버리스 함수로 성공적으로 Vercel에 배포되었습니다. 프로젝트 구조와 요구사항에 맞게 가이드를 수정하여 원활한 배포 경험을 만들어보세요.\n\n원문은 https://kkupgrader.eu.org에서 확인할 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-20-HowtoDeployYourNodejsBackendonVercelAStep-by-StepGuide_0.png"},"coverImage":"/assets/img/2024-06-20-HowtoDeployYourNodejsBackendonVercelAStep-by-StepGuide_0.png","tag":["Tech"],"readingTime":2},{"title":"내가 원하는 테크 회사에 자동 이메일을 보내는 스크립트를 작성했어요 결과 포함","description":"","date":"2024-06-20 04:35","slug":"2024-06-20-IWroteAnAutomatedScripttoSendOutColdE-MailstotheTechCompaniesIWanttoWorkAtWithResults","content":"\n\n\n<img src=\"/assets/img/2024-06-20-IWroteAnAutomatedScripttoSendOutColdE-MailstotheTechCompaniesIWanttoWorkAtWithResults_0.png\" />\n\n'Cold e-mailing'은 오늘날 모든 구직자가 들어본 적이 있는 것입니다. 그러나 실제로 도움되고 쉬운 것일까요? 매번 이메일을 맞춤화하여 모든 채용 담당자 및 관리자들의 이메일을 검색하고 보내기는 귀찮은 일입니다. 굳이 그렇게 해야 하는가?\n\n어떻게하면 프로세스를 쉽게 만들 수 있을까요? LinkedIn에서 사람들에게 메시지를 보내는 것은 수백 명의 사람들이 이미 모든 채용 담당자와 리크루터에게 메시지를 보냈다는 점을 고려하면 불가능합니다 (아무도 무시하려는 것이 아닙니다. 현재는 정말 어려운 시기이며 모두 최선을 다하고 있습니다)\n\n# 생각\n\n\n<div class=\"content-ad\"></div>\n\n어떻게 하면 좋을까요? '회사 이름' 채용 담당자/리쿠르터의 LinkedIn을 온라인으로 검색하여 그들의 이름을 찾고, 직접적인 이메일을 보내는 스크립트를 작성한다면 어떨까요? 하지만 LinkedIn에서 이들의 이메일 주소를 어떻게 찾을까요? 각기 다른 회사에 맞춰 이메일을 어떻게 개인화할까요? 가장 중요한 것은, 이 모든 작업을 수작업으로 할 수는 없다는 것입니다.\n\n# 아이디어 발산\n\n처음에 생각한 것은, 스크립트를 작성하여 firstName+lastName@companywebsite.com의 모든 조합에 이메일을 보내는 것인데, 어떻게하면 유효한 이메일 주소인지 알 수 있을까요?\n\n이 문제는 꽤 간단하게 해결할 수 있었습니다. 유효하지 않은 이메일로 메일을 보내면 메일러 데몬(발신자와 수신자 사이의 중간 인터페이스)이 수신자의 이메일 주소가 유효하지 않아서 이메일을 보낼 수 없다는 경고를 통보해줍니다.\n\n<div class=\"content-ad\"></div>\n\n알겠어요. 이제 하나의 조합이 유효하다면 메일러 데몬으로부터 알림을 받지 않는다는 사실을 알게 되었어요. 이제 조합을 생성하는 것은 또 다른 작업이었지만, 제 경험상 회사 이메일은 일반적으로 다음과 같은 양식을 따른다는 것을 알고 있어요 -\n\n- jdoe@company.com\n- johnd@company.com\n- johndoe@company.com\n- j.doe@company.com\n- john.doe@company.com\n\n그러나 몇몇 회사 이메일을 알고 있는 것에 기반하여 스크립트에 추가적인 조합 몇 가지를 추가했어요. 따라서 여기서의 작업은 탐색 스크립트로부터 수집된 이름에서 조합을 생성하는 것이었습니다. 문자열 조작과 생성적 AI를 사용하여 이 작업은 꽤 간단한 일이었어요.\n\n# ‘맞춤’ 이메일\n\n<div class=\"content-ad\"></div>\n\n각 회사에 이메일을 맞춤화하는 것을 고려해야 하는 부분이었지만, 회사에 대한 내 흥미와 경력, 프로젝트, 학력을 언급한 일반적인 텍스트 조각을 만드는 것이 목표였어요. 또한, 이메일에 이력서를 첨부해야 했죠.\n\n내가 미리 설정한 이메일 샘플:\n\n```js\n\"안녕하세요, 제 이름은 Priyanshu입니다... 제 자격 및 성취는...\n...${companyName}에서 일하고 싶어하는 이유는...\n...SDE/풀스택 엔지니어와 같은 역할을 찾고 있습니다...\n...제 이력서를 첨부했습니다...\"\n```\n\n매우 간략한 형태로 이메일을 작성한 것을 볼 수 있어요. 회사 이름이 변수로 전달되는 것에 주목해주세요. 이 변수는 내가 최우선 순위로 둔 회사들의 배열에서 가져온 것이에요.\n\n<div class=\"content-ad\"></div>\n\n간단히 말씀드리면, 목록에서 각 회사에 대해 다음을 시도했습니다:\n\n- 구글 검색을 통해 회사에서 채용 담당자/리쿠르터/시니어 개발자를 찾기 위해 — Puppeteer.js를 사용한 웹 스크래핑\n- 스크랩된 텍스트에서 이름을 추출하기 위해 — 발생 모델 AI API 및 문자열 조작\n- 내 이력서와 함께 맞춤형 이메일을 모든 조합에게 보내기 — Nodemailer API\n- 이미 이메일을 보낸 주소를 저장하여 리쿠르터에게 스팸을 보내지 않도록 함 — MongoDB\n\n위의 모든 작업은 저가 Node.js를 사용하여 작성한 스크립트로 자동화했습니다.\n\n# 결과 및 결론\n\n<div class=\"content-ad\"></div>\n\n\n![1](/assets/img/2024-06-20-IWroteAnAutomatedScripttoSendOutColdE-MailstotheTechCompaniesIWanttoWorkAtWithResults_1.png)\n\n![2](/assets/img/2024-06-20-IWroteAnAutomatedScripttoSendOutColdE-MailstotheTechCompaniesIWanttoWorkAtWithResults_2.png)\n\n![3](/assets/img/2024-06-20-IWroteAnAutomatedScripttoSendOutColdE-MailstotheTechCompaniesIWanttoWorkAtWithResults_3.png)\n\n![4](/assets/img/2024-06-20-IWroteAnAutomatedScripttoSendOutColdE-MailstotheTechCompaniesIWanttoWorkAtWithResults_4.png)\n\n\n<div class=\"content-ad\"></div>\n\n많은 추가적인 이메일도 있어요.\n\n많은 긍정적인 응답을 받기는 했지만, 아직 후속 조치는 받지 못했어요. 현재 시장 상황과 후원 요건 때문에 조금 어려울지도 모르겠지만, 희망을 잃지 말아봐요!\n\n읽어주셔서 감사합니다!","ogImage":{"url":"/assets/img/2024-06-20-IWroteAnAutomatedScripttoSendOutColdE-MailstotheTechCompaniesIWanttoWorkAtWithResults_0.png"},"coverImage":"/assets/img/2024-06-20-IWroteAnAutomatedScripttoSendOutColdE-MailstotheTechCompaniesIWanttoWorkAtWithResults_0.png","tag":["Tech"],"readingTime":3},{"title":"NestJS에서 IoC 컨테이너에 접근하기 실용적인 로깅 라이브러리 예제","description":"","date":"2024-06-20 04:34","slug":"2024-06-20-AccessingtheIoCContainerinNestJSAPracticalLoggingLibraryExample","content":"\n\n![2024-06-20-AccessingtheIoCContainerinNestJSAPracticalLoggingLibraryExample_0.png](/assets/img/2024-06-20-AccessingtheIoCContainerinNestJSAPracticalLoggingLibraryExample_0.png)\n\n안녕하세요! 이 세부적인 자습서에서는 NestJS 프로젝트를 만들고 특정 메타데이터가 지정된 모든 프로바이더 및 컨트롤러의 메서드 호출을 동적으로 탐지하고 기록하는 로깅 라이브러리를 구축할 것입니다. 이 예제는 IoC(Inversion of Control) 컨테이너에 액세스하고 등록된 프로바이더 및 컨트롤러를 조사하며 사용자 정의 데코레이터를 사용하여 동적 동작을 적용하는 방법을 이해하는 데 도움이 될 것입니다.\n\n# IoC 컨테이너란?\n\nNestJS의 IoC 컨테이너는 애플리케이션 구성 요소의 생성, 설정 및 라이프사이클을 관리하여 의존성 주입을 가능하게 합니다. 이는 컨테이너가 필요한 클래스에 자동으로 의존성을 제공하는 의존성 주입을 허용합니다.\n\n<div class=\"content-ad\"></div>\n\n# IoC 컨테이너에 접근하는 이유\n\nIoC 컨테이너에 접근하는 것은 다음과 같은 이유로 매우 중요합니다:\n\n- 살펴보기: 등록된 제공자(Providers) 및 컨트롤러(Controllers)를 모두 검사하기 위해.\n- 동적 동작: 로깅, 모니터링 또는 메타데이터를 기반으로 동작을 수정하는 등 동적 동작을 적용하기 위해.\n- 일반 라이브러리: 다양한 응용프로그램 구성 요소와 동적으로 상호작용해야 하는 라이브러리를 구축하기 위해.\n\n# 단계별 안내\n\n<div class=\"content-ad\"></div>\n\nNestJS 프로젝트를 만들고 동적 로깅 라이브러리를 빌드하는 단계를 함께 진행해 보겠습니다.\n\n## 단계 1: NestJS 프로젝트 설정하기\n\n- NestJS CLI를 설치합니다:\n\n```js\nnpm install -g @nestjs/cli\n```\n\n<div class=\"content-ad\"></div>\n\n2. 새로운 NestJS 프로젝트 만들기:\n\n```js\nnest new logging-library\ncd logging-library\n```\n\n3. 필수 종속성 설치:\n\n```js\nnpm install @nestjs/core @nestjs/common @nestjs-plus/discovery\n```\n\n<div class=\"content-ad\"></div>\n\n## 단계 2: LoggerService 생성하기\n\nNestJS 라이프사이클 훅을 사용하여 메서드 호출 로깅을 동적으로 설정하고 지우는 LoggerService를 생성합니다.\n\n- LoggerService 생성하기:\n\n```js\nnest generate service logger\n```\n\n<div class=\"content-ad\"></div>\n\n2. LoggerService를 구현하세요:\n\n```js\n// src/logger/logger.service.ts\nimport { Injectable, OnApplicationBootstrap, OnApplicationShutdown } from '@nestjs/common';\nimport { DiscoveryService, Reflector, MetadataScanner } from '@nestjs/core';\n\n@Injectable()\nexport class LoggerService implements OnApplicationBootstrap, OnApplicationShutdown {\n  // 원본 메소드를 저장하고 종료 시 복원하기 위한 Map\n  private readonly originals: Map<any, any> = new Map();\n\n  constructor(\n    // DiscoveryService는 모든 프로바이더와 컨트롤러를 찾기 위해 사용됩니다.\n    private readonly discoveryService: DiscoveryService,\n    // Reflector는 클래스와 메소드에서 메타데이터를 읽기 위해 사용됩니다.\n    private readonly reflector: Reflector,\n    // MetadataScanner는 클래스 프로토타입을 메소드 이름으로 스캔하기 위해 사용됩니다.\n    private readonly metadataScanner: MetadataScanner\n  ) {}\n\n  // 모든 모듈이 초기화된 후에 실행되는 라이프사이클 훅\n  onApplicationBootstrap() {\n    // 애플리케이션에서 모든 프로바이더(컨트롤러 포함)를 가져옵니다.\n    const providers = this.discoveryService.getProviders();\n    providers.forEach((wrapper) => {\n      // 프로바이더의 인스턴스(실제 객체) 가져오기\n      const { instance } = wrapper;\n      // 프로바이더의 프로토타입(모든 인스턴스에서 공유되는 메소드와 속성) 가져오기\n      const prototype = instance && Object.getPrototypeOf(instance);\n      // 인스턴스나 프로토타입이 없는 경우 건너뜁니다.\n      if (!instance || !prototype) {\n        return;\n      }\n      // 클래스가 @Loggable로 표시되어 있는지 확인합니다.\n      const isLoggable = this.reflector.get('LOGGABLE_KEY', instance.constructor) ?? false;\n      if (!isLoggable) {\n        return;\n      }\n      // 클래스 프로토타입에서 모든 메소드 이름 가져오기\n      const methodKeys = this.metadataScanner.getAllMethodNames(prototype);\n      methodKeys.forEach((methodKey) => {\n        // 이름으로 메소드 가져오기\n        const method = instance[methodKey];\n        // 함수(메소드)인지 확인합니다.\n        if (typeof method === 'function') {\n          // 원본 메소드 저장\n          this.originals.set(method, method.bind(instance));\n          // 원본 메소드를 로깅 래퍼로 대체합니다.\n          instance[methodKey] = (...args: any[]) => {\n            console.log(`Calling ${methodKey} with args:`, args);\n            return this.originals.get(method)(...args);\n          };\n        }\n      });\n    });\n  }\n\n  // 애플리케이션이 종료되기 전에 실행되는 라이프사이클 훅\n  onApplicationShutdown(signal?: string) {\n    // 모든 원본 메소드를 복원합니다.\n    this.originals.forEach((original, method) => {\n      method = original;\n    });\n    // 원본 메소드 Map을 비웁니다.\n    this.originals.clear();\n  }\n}\n```\n\n- Instance: IoC 컨테이너에서 생성된 실제 객체입니다. 이는 응용프로그램에서 상호작용하는 실시간 객체입니다.\n- Prototype: 객체의 청사진입니다. 클래스의 모든 인스턴스간에 공유되는 메소드와 속성이 포함되어 있습니다. 프로토타입을 사용하면 클래스 메소드의 동적 조회 및 수정이 가능합니다.\n\n# 로깅 메소드의 상세 설명\n\n<div class=\"content-ad\"></div>\n\n코드의 일부를 더 깊이 파헤쳐 보겠습니다. 여기서는 로깅 기능을 가진 메소드를 동적으로 래핑하는 부분에 집중해 봅시다:\n\n```js\nmethodKeys.forEach((methodKey) => {\n  // 메소드 이름으로 메소드를 가져옵니다\n  const method = instance[methodKey];\n  // 속성이 함수(메소드)인지 확인합니다\n  if (typeof method === 'function') {\n    // 원본 메소드를 저장합니다\n    this.originals.set(method, method.bind(instance));\n    // 원본 메소드를 로깅 래퍼로 교체합니다\n    instance[methodKey] = (...args: any[]) => {\n      console.log(`${methodKey}를 인수와 함께 호출 중:`, args);\n      return this.originals.get(method)(...args);\n    };\n  }\n});\n```\n\n## 단계별 설명\n\n<div class=\"content-ad\"></div>\n\n```js\nmethodKeys.forEach((methodKey) => {\n```\n\n- methodKeys: 프로바이더의 프로토타입에 있는 모든 메서드 이름의 배열입니다.\n\n2. 이름으로 메서드 가져오기:\n\n```js\nconst method = instance[methodKey];\n```\n\n<div class=\"content-ad\"></div>\n\n- instance[methodKey]: 이름(key)으로 인스턴스의 메서드에 액세스합니다.\n- method: 실제 메서드 함수에 대한 참조를 보유합니다.\n\n3. 속성이 함수인지 확인합니다:\n\n```js\nif (typeof method === 'function') {\n```\n\n- 속성이 실제로 함수이고 다른 유형의 속성(예: 변수)이 아님을 보장합니다.\n\n<div class=\"content-ad\"></div>\n\n4. 원본 메소드 저장:\n\n```js\nthis.originals.set(method, method.bind(instance));\n```\n\n- this.originals: 원본 메소드 참조를 저장하는 Map 객체입니다.\n- set(method, method.bind(instance)): 해당 메소드를 인스턴스에 바인딩하여 저장하여 메소드가 호출될 때 올바른 컨텍스트(this)를 유지합니다.\n\n5. 원본 메소드를 로깅 래퍼로 대체하기:\n\n<div class=\"content-ad\"></div>\n\n```js\ninstance[methodKey] = (...args: any[]) => {\n  console.log(`Calling ${methodKey} with args:`, args);\n  return this.originals.get(method)(...args);\n};\n```\n\n- instance[methodKey]: 기존 메소드를 새 함수로 대체합니다.\n- (...args: any[]): '...'는 새 함수를 나타내며:\n- 메소드 호출과 인수를 기록합니다.\n- this.originals에 저장된 참조를 사용하여 원본 메소드를 호출합니다.\n\n# 실제 예시\n\ncreateUser 및 deleteUser 메소드를 갖는 UserService 클래스가 있다고 가정해보겠습니다:\n\n<div class=\"content-ad\"></div>\n\n```js\n@Loggable\n@Injectable()\nexport class UserService {\n  createUser(name: string) {\n    console.log(`User ${name} created.`);\n  }\n\n  deleteUser(id: number) {\n    console.log(`User with id ${id} deleted.`);\n  }\n}\n```\n\nLoggerService가 초기화될 때 다음을 합니다:\n\n- UserService 제공자를 탐색합니다.\n- UserService에 @Loggable이 표시되어 있는지 확인합니다.\n- UserService의 각 메서드(예: createUser 및 deleteUser)에 대해\n- 원본 메서드를 저장합니다.\n- 원본 메서드를 호출하기 전에 호출과 매개변수를 기록하는 새 함수로 메서드를 대체합니다\n\n## 단계 3: 사용자 정의 데코레이터 정의하기\n\n\n<div class=\"content-ad\"></div>\n\n클래스 및 메서드에 로깅을 위한 표시를 지정하기 위해 @Loggable 데코레이터를 정의합니다.\n\n데코레이터를 생성하세요:\n\n```js\n// src/logger/loggable.decorator.ts\nimport { SetMetadata } from '@nestjs/common';\n\n// loggable 메타데이터를 위한 키\nexport const LOGGABLE_KEY = 'LOGGABLE_KEY';\n// 로깅을 위해 클래스를 표시하는 Loggable 데코레이터\nexport const Loggable: ClassDecorator = SetMetadata(LOGGABLE_KEY, true);\n```\n\n## 스텝 4: 사용자 지정 데코레이터 사용하기\n\n<div class=\"content-ad\"></div>\n\n@Service 클래스에서 @Loggable 데코레이터를 사용하여 로깅해야 하는 메서드를 생성하세요.\n\n- 서비스 생성:\n\n```js\nnest generate service user\n```\n\n2. UserService를 구현하세요.\n\n<div class=\"content-ad\"></div>\n\n```js\n// src/user/user.service.ts\nimport { Injectable } from '@nestjs/common';\nimport { Loggable } from '../logger/loggable.decorator';\n\n// UserService 클래스를 로깅하기 위해 표시합니다\n@Loggable\n@Injectable()\nexport class UserService {\n  // 사용자 생성 메서드\n  createUser(name: string) {\n    console.log(`사용자 ${name}이(가) 생성되었습니다.`);\n  }\n\n  // 사용자 삭제 메서드\n  deleteUser(id: number) {\n    console.log(`ID가 ${id}인 사용자가 삭제되었습니다.`);\n  }\n}\n```\n\n3. 로깅을 테스트하기 위해 UserController를 생성합니다:\n\n```bash\nnest generate controller user\n```\n\n4. UserController를 구현합니다:\n\n<div class=\"content-ad\"></div>\n\n```js\n// src/user/user.controller.ts\nimport { Controller, Post, Body, Delete, Param } from '@nestjs/common';\nimport { UserService } from './user.service';\n\n@Controller('users')\nexport class UserController {\n  constructor(private readonly userService: UserService) {}\n\n  @Post()\n  createUser(@Body('name') name: string) {\n    return this.userService.createUser(name);\n  }\n\n  @Delete(':id')\n  deleteUser(@Param('id') id: number) {\n    return this.userService.deleteUser(id);\n  }\n}\n```\n\n5. Step 5: AppModule에서 LoggerService 통합\n\nLoggerService와 UserController가 응용 프로그램 모듈에 포함되어 있는지 확인하십시오.\n\nAppModule 업데이트:\n\n<div class=\"content-ad\"></div>\n\n```js\n// src/app.module.ts\nimport { Module } from '@nestjs/common';\nimport { DiscoveryModule } from '@nestjs/core';\nimport { LoggerService } from './logger/logger.service';\nimport { UserService } from './user/user.service';\nimport { UserController } from './user/user.controller';\n\n@Module({\n  imports: [DiscoveryModule],\n  providers: [LoggerService, UserService],\n  controllers: [UserController],\n})\nexport class AppModule {\n  // Inject LoggerService to initialize it on application start\n  constructor(private readonly loggerService: LoggerService) {}\n}\n```\n\n## 단계 6: 로깅 테스트\n\ncurl을 사용하여 엔드포인트를 테스트하고 로깅 기능을 확인할 수 있습니다.\n\n- 유저 생성:\n\n<div class=\"content-ad\"></div>\n\n```bash\n# 사용자 추가:\ncurl -X POST http://localhost:3000/users -H \"Content-Type: application/json\" -d '{\"name\": \"John Doe\"}'\n```\n\n2. 사용자 삭제:\n\n```bash\ncurl -X DELETE http://localhost:3000/users/1\n```\n\n# 결과\n\n<div class=\"content-ad\"></div>\n\n```js\ncreateUser을 다음과 같은 args와 함께 호출했습니다: ['John Doe']\n사용자 John Doe가 생성되었습니다.\ndeleteUser을 다음과 같은 args와 함께 호출했습니다: ['1']\nid가 1인 사용자가 삭제되었습니다.\n```\n\n# 요약\n\n이 지침을 따라 NestJS 프로젝트를 생성하고, 특정 메타데이터로 표시된 모든 프로바이더 및 컨트롤러에 대한 메서드 호출을 동적으로 기록하는 로깅 라이브러리를 구축했습니다. 이 튜토리얼은 NestJS의 IoC 컨테이너에 액세스하여 등록된 프로바이더 및 컨트롤러를 검사하고 동적 동작을 적용하는 방법을 보여주었습니다.\n\n사용자 지정 데코레이터와 메타데이터 반사를 활용하여 메서드 호출을 기록하는 유연한 시스템을 구축하여, NestJS의 강력한 IoC 컨테이너를 활용하여 고급 사용 사례에 대처하는 방법을 시연했습니다. 이 접근 방식은 NestJS 애플리케이션의 다른 부분과 동적으로 상호작용해야 하는 다양한 제네릭 및 통합 라이브러리를 구축하기 위해 확장할 수 있습니다.\n","ogImage":{"url":"/assets/img/2024-06-20-AccessingtheIoCContainerinNestJSAPracticalLoggingLibraryExample_0.png"},"coverImage":"/assets/img/2024-06-20-AccessingtheIoCContainerinNestJSAPracticalLoggingLibraryExample_0.png","tag":["Tech"],"readingTime":10},{"title":"Nodejs에서 SSLCOMMERZ 결제 게이트웨이 통합하기","description":"","date":"2024-06-20 04:32","slug":"2024-06-20-IntegratingSSLCOMMERZPaymentGatewayinNodejs","content":"\n\n이 블로그 포스트에서는 MongoDB를 사용하여 Node.js 애플리케이션에 SSLCommerz 결제 게이트웨이를 통합하는 과정을 안내하겠습니다. 이 안내서는 웹 애플리케이션을 위한 안전하고 효율적인 결제 처리 시스템을 설정하는 데 도움이 될 것입니다.\n\n![이미지](/assets/img/2024-06-20-IntegratingSSLCOMMERZPaymentGatewayinNodejs_0.png)\n\nSSLCOMMERZ는 SSL Wireless가 개발한 안전하고 인증된 온라인 결제 게이트웨이 플랫폼으로, 온라인 비즈니스 및 전자상거래 판매 업체의 최종 고객이 고객의 카드, 모바일 지갑 또는 은행 계좌로 안전한 거래를 수행할 수 있도록 하였습니다. SSLCOMMERZ의 주요 이점을 살펴보겠습니다.\n\n- 온라인 문서를 통한 빠른 활성화\n- 쉬운 통합\n- 방글라데시 중앙 은행이 PSO 라이선스 부여\n- 30개 이상의 결제 방식\n- 글로벌 결제 수락\n- 실시간 대시보드 보고\n- PCI DSS 규정을 준수한 고수준 보안\n\n<div class=\"content-ad\"></div>\n\n# 준비 사항\n\n시작하기 전에 다음 사항이 준비되어 있는지 확인하십시오:\n\n- Node.js: 컴퓨터에 Node.js가 설치되어 있는지 확인하십시오. nodejs.org에서 다운로드할 수 있습니다.\n- MongoDB: MongoDB가 설정되어 실행 중인지 확인하십시오.\n- SSLCommerz 계정: SSLCommerz 상인 계정이 필요합니다. sslcommerz.com에서 가입할 수 있습니다.\n\n# 단계 1: 프로젝트 설정하기\n\n<div class=\"content-ad\"></div>\n\n먼저, 새로운 Node.js 프로젝트를 생성하고 필요한 종속성을 설치하세요. 터미널을 열고 다음 명령을 실행해보세요:\n\n```js\nmkdir sslcommerz-integration\ncd sslcommerz-integration\nnpm init -y\nnpm install express body-parser dotenv sslcommerz-lts mongodb cors\n```\n\n# 단계 2: 환경 변수 설정\n\n프로젝트의 루트에 .env 파일을 생성하고 SSLCommerz 자격 증명을 추가하세요. 이러한 자격 증명은 SSLCommerz API와의 요청을 인증하는 데 사용될 것입니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nSTORE_ID=your_store_id\nSTORE_PASSWORD=your_store_password\nSERVER_API=http://localhost:3030\nMONGO_URI = \"mongodb+srv://username:password@cluster0.7ctc5qe.mongodb.net/?retryWrites=true&w=majority\"\n```\n\n상인 계정을 생성한 후 이메일로 STORE_ID 및 STORE_PASSWORD를 받게 됩니다. SERVER_API는 백엔드 API 주소이며, MONGO_URI는 MongoDB 대시보드에서 얻을 수 있습니다.\n\n# 단계 3: 익스프레스 서버 설정\n\n이제 익스프레스 서버를 설정하고 결제 작업을 처리하기 위한 필요한 라우트를 정의하세요. app.js 파일을 만들고 다음 코드를 추가하세요:\n\n\n<div class=\"content-ad\"></div>\n\n```js\nconst express = require('express');\nconst bodyParser = require('body-parser');\nconst SSLCommerzPayment = require('sslcommerz-lts');\nconst { MongoClient, ObjectId, ServerApiVersion } = require(\"mongodb\");\nconst cors = require(\"cors\");\nrequire('dotenv').config();\nconst mongoURI = process.env.MONGO_URI;\n\nconst app = express();\nconst port = process.env.PORT || 3030;\n\napp.use(bodyParser.json());\napp.use(bodyParser.urlencoded({ extended: true })); // SSLCommerz로부터 전송된 폼 데이터 처리를 위해\n\n// MongoDB 연결\nconst client = new MongoClient(mongoURI, {\n  serverApi: {\n    version: ServerApiVersion.v1,\n    strict: true,\n    deprecationErrors: true,\n  },\n});\n\n// CORS 및 JSON 파싱을 위한 미들웨어\napp.use(\n  cors({\n    origin: [\"http://localhost:5173\"],\n    credentials: true,\n  })\n);\napp.use(express.json());\n\n// SSLCommerz 구성\nconst store_id = process.env.STORE_ID;\nconst store_passwd = process.env.STORE_PASSWORD;\nconst is_live = false; // 라이브 모드: true, 샌드박스 모드: false\n\nconst run = async () => {\n  try {\n    // 데이터베이스 연결\n    await client.connect();\n\n    // 주문 저장을 위한 컬렉션\n    const ordersCollection = client.db(\"test\").collection(\"orders\");\n\n    // 결제 생성을 위한 POST 요청\n    app.post(\"/plans\", async (req, res) => {\n      // 클라이언트에서 보낸 플랜 세부 정보\n      const planDetails = req.body;\n\n      // 가격을 정수로 변환\n      const price = parseInt(planDetails.price);\n\n      // ObjectId를 사용하여 트랜잭션 ID 생성\n      const tran_id = new ObjectId().toString();\n\n      // SSLCommerz로 보낼 결제 데이터\n      const data = {\n        total_amount: price,\n        currency: \"BDT\",\n        tran_id: tran_id,\n        success_url: `${process.env.SERVER_API}/payment/success`,\n        fail_url: `${process.env.SERVER_API}/payment/fail`,\n        cancel_url: `${process.env.SERVER_API}/payment/cancel`,\n        ipn_url: `${process.env.SERVER_API}/payment/ipn`,\n        shipping_method: \"Courier\",\n        product_name: planDetails.plan,\n        product_category: \"Electronic\",\n        product_profile: \"general\",\n        cus_name: \"Customer Name\",\n        cus_email: planDetails.user_email,\n        cus_add1: \"Dhaka\",\n        cus_add2: \"Dhaka\",\n        cus_city: \"Dhaka\",\n        cus_state: \"Dhaka\",\n        cus_postcode: \"1000\",\n        cus_country: \"Bangladesh\",\n        cus_phone: \"01711111111\",\n        cus_fax: \"01711111111\",\n        ship_name: \"Customer Name\",\n        ship_add1: \"Dhaka\",\n        ship_add2: \"Dhaka\",\n        ship_city: \"Dhaka\",\n        ship_state: \"Dhaka\",\n        ship_postcode: 1000,\n        ship_country: \"Bangladesh\"\n      };\n\n      // SSLCommerz 결제 초기화\n      const sslcz = new SSLCommerzPayment(store_id, store_passwd, is_live);\n      sslcz.init(data).then((apiResponse) => {\n        // 결제 게이트웨이 URL 가져오기\n        let GatewayPageURL = apiResponse.GatewayPageURL;\n        res.send({ url: GatewayPageURL });\n\n        // 주문 세부 정보를 데이터베이스에 삽입\n        const order = { ...planDetails, tran_id, status: 'pending'};\n        const result = ordersCollection.insertOne(order);\n      });\n\n      // 성공한 결제 처리를 위한 POST 요청\n      app.post(\"/payment/success\", async (req, res) => {\n\n        // 데이터베이스에서 주문 상태를 성공으로 업데이트\n        const result = await ordersCollection.updateOne(\n          { tran_id },\n          { $set: { status: 'success'} }\n        );\n         // 클라이언트에 결제 성공 페이지로 리디렉션\n        res.redirect(\"http://localhost:5173/payment/success\");\n      });\n\n      // 실패한 결제 처리를 위한 POST 요청\n      app.post(\"/payment/fail\", async (req, res) => {\n\n        // 데이터베이스에서 주문 상태를 실패로 업데이트\n        const result = await ordersCollection.updateOne(\n          { tran_id },\n          { $set: { status: 'failed'} }\n        );\n       // 클라이언트에 결제 실패 페이지로 리디렉션\n        res.redirect(\"http://localhost:5173/payment/fail\");\n      });\n\n      // 취소된 결제 처리를 위한 POST 요청\n      app.post(\"/payment/cancel\", async (req, res) => {\n\n        // 데이터베이스에서 주문 상태를 취소됨으로 업데이트\n        const result = await ordersCollection.updateOne(\n          { tran_id },\n          { $set: { status: 'canceled'} }\n        );\n        // 클라이언트에 결제 취소 페이지로 리디렉션\n        res.redirect(\"http://localhost:5173/payment/cancel\");\n      });\n\n      // IPN(즉시 결제 알림) 처리를 위한 POST 요청\n      app.post(\"/payment/ipn\", async (req, res) => {\n\n        // IPN 알림에 따라 데이터베이스에서 주문 상태 업데이트\n        const result = await ordersCollection.updateOne(\n          { tran_id },\n          { $set: { status: status === \"VALID\" } }\n        );\n        res.send({ message: \"IPN received\" });\n      });\n    });\n  } finally {\n    // 서버가 계속 실행되도록 보장\n  }\n};\n\n// 서버 실행\nrun().catch(console.dir);\n\n// 서버 실행 상태 확인을 위한 간단한 루트\napp.get('/', async (req, res) => {\n  res.send({ server_status: \"Running\" });\n});\n\n// Express 서버 시작\napp.listen(port, () => {\n  console.log(`서버가 ${port} 포트에서 실행 중입니다.`);\n});\n```\n\n<div class=\"content-ad\"></div>\n\n프론트엔드에서 지불 프로세스를 트리거하기 위해 아래의 코드 스니펫을 사용할 수 있어요. 이 코드는 POST 요청을 /plans 엔드포인트로 보내고, 사용자를 SSLCommerz 지불 페이지로 리디렉션해요.\n\n```js\nconst handlePlans = async () => {\n  const { data } = await axios.post('/plans', {\n    user_email: user.email,\n    plan: plan,\n    price: price,\n    purchase_date: purchaseDate,\n    expiration_date: expirationDate,\n    currency: 'BDT',\n    payment_method: 'SSLCOMMERZ'\n  });\n  // 서버로부터 받은 URL로 리디렉션하기\n  window.location.replace(data.url);\n};\n```\n\n# 설명\n\n- handlePlans 함수: 해당 함수는 필요한 플랜 세부 정보와 함께 /plans 엔드포인트로 POST 요청을 보냅니다.\n- 리디렉션: 응답을 받은 후, 사용자는 window.location.replace를 사용하여 SSLCommerz 지불 페이지로 리디렉션됩니다.\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n이 블로그 포스트에서 우리는 SSLCommerz 결제 게이트웨이를 Node.js 어플리케이션에 성공적으로 통합하고 데이터베이스 작업에 대해 직접 MongoDB를 사용했습니다. 이 통합을 통해 안전하게 결제를 처리하고 데이터베이스를 업데이트할 수 있습니다.\n\n# 주요 포인트\n\n- SSLCommerz 설정: SSLCommerz와 상점 ID 및 비밀번호를 획득하기 위해 상인 계정을 사용합니다.\n- 환경 변수: 환경 변수에 자격 증명을 안전하게 저장합니다.\n- MongoDB 작업: 주문 추적 및 사용자 플랜 업데이트를 위해 데이터베이스 작업에 MongoDB를 사용합니다.\n\n<div class=\"content-ad\"></div>\n\n이 단계를 따라하면 Node.js 애플리케이션에 견고하고 안전한 결제 처리 시스템을 설정할 수 있어요. 코딩을 즐기세요!","ogImage":{"url":"/assets/img/2024-06-20-IntegratingSSLCOMMERZPaymentGatewayinNodejs_0.png"},"coverImage":"/assets/img/2024-06-20-IntegratingSSLCOMMERZPaymentGatewayinNodejs_0.png","tag":["Tech"],"readingTime":8},{"title":"AWS EC2에 수동으로 Nextjs 앱을 배포하는 방법 단계별 안내","description":"","date":"2024-06-20 04:31","slug":"2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide","content":"\n\n소개\n\n웹 개발의 끊임없이 진화하는 풍경에서 Next.js와 같은 현대적인 프레임워크가 사용자 인터페이스를 구축하는 방법을 혁신했습니다. Next.js는 React 프레임워크로, 서버 렌더링 및 정적으로 생성된 React 애플리케이션을 구축하는데 원활한 경험을 제공합니다. 성능, SEO 및 사용자 경험을 향상시킬 수 있는 능력은 개발자들에게 인기 있는 선택지입니다. 이 안내서에서는 Next.js 앱을 AWS EC2 인스턴스에 배포하는 과정을 안내해 드릴 것이며, 클라우드의 강력한 기능을 활용하여 애플리케이션을 전 세계에 제공할 수 있습니다.\n\nAWS 클라우드에서 Next.js 배포의 장점\n\n배포 프로세스에 들어가기 전에, AWS 클라우드에서 Next.js 앱을 호스팅하는 주요 이점을 강조해 보겠습니다:\n\n<div class=\"content-ad\"></div>\n\n- 확장성: AWS는 수요에 따라 EC2 인스턴스를 확장할 수 있는 유연성을 제공합니다. 이는 당신의 Next.js 앱이 성능을 희생하지 않고 트래픽 증가를 처리할 수 있음을 의미합니다.\n- 신뢰성: AWS는 SLA(서비스 레벨 계약)로 높은 신뢰성의 인프라를 제공하여 사용자가 필요로 할 때 응용 프로그램이 이용 가능하고 운영 중인지를 보장합니다.\n- 글로벌 네트워크: AWS에 배포하면 전 세계의 데이터 센터를 선택할 수 있어 지리적으로 다른 위치의 사용자에게 더 빠른 경험을 제공하고 지연 시간을 줄일 수 있습니다.\n- 보안: AWS는 방화벽, 암호화 및 아이디어 관리를 포함한 견고한 보안 조치를 제공하여 Next.js 앱과 사용자 데이터를 잘 보호합니다.\n- 비용 효율성: AWS EC2 인스턴스는 선택한 인스턴스 유형을 선택하고 필요에 따라 리소스를 확장함으로써 비용을 제어할 수 있는 요금 체계를 제공합니다.\n\nAWS EC2에 Next.js 앱을 배포하는 단계별 안내서\n\n이제 배포 과정에 대해 살펴봅시다. 원활한 경험을 보장하기 위해 관리 가능한 단계로 나누어 설명하겠습니다:\n\n# 전제 조건\n\n<div class=\"content-ad\"></div>\n\n- Github 계정\n- AWS 계정\n- Next.js 웹 애플리케이션\n\n단계 1: AWS 계정 설정하기\n\n- AWS Management Console에 로그인하거나 계정이 없는 경우 새로 만드세요.\n- 인스턴스를 생성하고 관리하기 위해 EC2 대시보드로 이동하세요.\n\n단계 2: EC2 인스턴스 시작하기\n\n<div class=\"content-ad\"></div>\n\n아마존 관리 콘솔에 로그인한 후 EC2 대시보드를 열고 인스턴스 시작 드롭다운 목록을 클릭한 후 아래 그림과 같이 '인스턴스 시작'을 클릭하세요:\n\n![Launch Instance](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_0.png)\n\n인스턴스 시작 창이 열리면 EC2 인스턴스의 이름을 입력해주세요:\n\n![Provide EC2 Instance Name](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_1.png)\n\n<div class=\"content-ad\"></div>\n\n이 데모에서는 무료 티어 자격이 있는 Ubuntu 22.04 LTS를 선택할 것입니다.\n\n![이미지](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_2.png)\n\n인스턴스 유형을 선택하세요. 여기서는 머신 유형, vCPU 수 및 원하는 메모리를 선택할 수 있습니다. 무료 티어 자격이 있는 t2.micro를 선택하세요.\n\n![이미지](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_3.png)\n\n<div class=\"content-ad\"></div>\n\n이 데모에서는 이미 존재하는 키페어를 선택할 것입니다. 키 쌍이 없는 경우에는 새로운 키페어를 만들 수 있습니다:\n\n![키페어 선택](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_4.png)\n\n이제 네트워크 설정에서 기본 VPC를 선택하고 공인 IP 자동 할당을 활성화하세요. 본 데모에서는 기존 보안 그룹을 선택하고, Devops-SG의 인바운드 규칙 아래에 HTTP 및 HTTPS 포트가 열려 있는지 확인할 것입니다. 진행하려면 규칙을 저장하세요.\n\n![보안 그룹 설정](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_5.png)\n\n<div class=\"content-ad\"></div>\n\n나머지 설정은 기본값으로 유지하고 \"인스턴스 시작\"을 클릭해주세요.\n\n![이미지](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_6.png)\n\n다음 화면에서 EC2 인스턴스가 성공적으로 생성되었다는 성공 메시지를 볼 수 있습니다. \"인스턴스에 연결\" 버튼을 클릭해주세요:\n\n![이미지](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_7.png)\n\n<div class=\"content-ad\"></div>\n\n이제 인스턴스 연결 마법사가 열립니다. SSH 클라이언트 탭으로 이동하고 제공된 chmod 및 SSH 명령을 복사하세요:\n\n![이미지](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_8.png)\n\n로컬 머신에서 SSH 클라이언트를 열어서 EC2 인스턴스의 공용 IP를 입력하여 pem 키를 추가하면 EC2 머신에 액세스할 수 있습니다.\n\n단계 3: EC2 인스턴스를 준비하고 다른 종속성 설치하기\n\n<div class=\"content-ad\"></div>\n\n시스템 패키지를 업데이트하세요: 최신 업데이트를 적용하려면 sudo apt update를 실행하십시오.\n\n![이미지](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_9.png)\n\nNode.js와 npm을 설치하세요. 이 튜토리얼에서 사용하는 Node.js 버전은 16 LTS입니다. 아래 명령어를 실행하세요:\n\n```js\ncurl -sL https://deb.nodesource.com/setup_16.x | sudo -E bash -\nsudo apt-get install -y nodejs\nnode -v\n```\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_10.png\" />\n\n가장 최신 버전의 NPM이 설치되어 있는지 확인하세요:\n\n```js\nsudo npm install -g npm@latest\nnpm -v\n```\n\n<img src=\"/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_11.png\" />\n\n<div class=\"content-ad\"></div>\n\nStep 4: GitHub에서 Nextjs 앱을 클론하세요.\n\n이 데모에서는 GitHub에서 공개된 Nextjs 프로젝트를 사용할 것입니다. EC2 인스턴스에서 해당 저장소를 클론하세요.\n\n```js\nhttps://github.com/warengonzaga/sample-nextjs-app.git\n```\n\n<img src=\"/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_12.png\" />\n\n<div class=\"content-ad\"></div>\n\n**단계 5: npm 설치**\n\n프로젝트 디렉토리/폴더로 이동하고, Next.js 웹 애플리케이션을 실행하는 데 필요한 종속성을 설치하기 위해 아래 명령어를 실행하세요.\n\n![이미지](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_13.png)\n\n**단계 6: npm 빌드**\n\n<div class=\"content-ad\"></div>\n\n프로덕션 단계에 애플리케이션을 준비하려면 자바스크립트 파일을 번들로 묶어야합니다. 이 작업은 다음 명령어를 실행하여 Next.js에서 처리됩니다:\n\nnpm run build 명령어의 출력은 참고용으로 제공됩니다.\n\n```js\nubuntu@ip-172-31-36-85:~/sample-nextjs-app$ npm run build\n\n> sample-next-app@0.1.0 build\n> next build\n\ninfo  - SWC minify release candidate enabled. https://nextjs.link/swcmin\n주의: Next.js는 이제 완전히 익명의 텔레메트리 데이터를 수집합니다. \n이 정보는 Next.js의 로드맵을 구성하고 기능을 우선 순위에 따라 결정하는 데 사용됩니다. \n이 익명의 프로그램에 참여하고 싶지 않다면 해당 URL을 방문하여 옵트아웃하는 방법을 비롯한 자세한 정보를 확인할 수 있습니다.\nhttps://nextjs.org/telemetry\n\ninfo  - Linting and checking validity of types\nBrowserslist: caniuse-lite is outdated. Please run:\n  npx browserslist@latest --update-db\n  Why you should do it regularly: https://github.com/browserslist/browserslist#browsers-data-updating\nBrowserslist: caniuse-lite is outdated. Please run:\n  npx browserslist@latest --update-db\n  Why you should do it regularly: https://github.com/browserslist/browserslist#browsers-data-updating\ninfo  - Creating an optimized production build\ninfo  - Compiled successfully\ninfo  - Collecting page data\ninfo  - Generating static pages (3/3)\ninfo  - Finalizing page optimization\n\nRoute (pages)                              Size     First Load JS\n┌ ○ /                                      689 B          78.6 kB\n├   └ css/ae0e3e027412e072.css             707 B\n├   /_app                                  0 B            77.9 kB\n├ ○ /404                                   186 B          78.1 kB\n└ λ /api/hello                             0 B            77.9 kB\n+ First Load JS shared by all              78.1 kB\n  ├ chunks/framework-db825bd0b4ae01ef.js   45.7 kB\n  ├ chunks/main-3123a443c688934f.js        30.9 kB\n  ├ chunks/pages/_app-0e6b46beaaa55ac1.js  498 B\n  ├ chunks/webpack-7ee66019f7f6d30f.js     755 B\n  └ css/ab44ce7add5c3d11.css               247 B\n\nλ  (서버)  서버 측에서 렌더링됩니다 (getInitialProps 또는 getServerSideProps 사용)\n○  (정적)  자동으로 정적 HTML로 렌더링됩니다 (초기 프로퍼티를 사용하지 않음)\n```\n\n6단계: PM2 설치\n\n<div class=\"content-ad\"></div>\n\nNext.js 프로세스를 처리하고 터미널을 닫아도 계속해서 백그라운드에서 실행되도록 하는 솔루션이 필요합니다. 이 요구사항을 충족시키기 위해 PM2가 프로세스 관리에 이상적인 도구로 사용됩니다.\n\n- 아래 명령어를 사용하여 PM2를 설치합니다:\n\n```js\nsudo npm install pm2 -g\n```\n\n- PM2 설치를 확인하려면 다음 명령어 pm2를 실행하고, 아래 스크린샷과 유사한 응답을 받게 됩니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_14.png\" />\n\n7단계: Next.js를 PM2를 사용하여 백그라운드에서 실행하기\n\n터미널을 닫은 후에도 Next.js 애플리케이션을 실행, 중지 및 재시작해야 합니다. 이를 PM2 도구를 사용하여 달성할 수 있습니다.\n\n다음 코드를 실행하여 PM2로 Next.js를 실행하세요:\n\n<div class=\"content-ad\"></div>\n\n```js\npm2 start npm --name nextjs-app -- run start -- -p 3000\n```\n\n![Screenshot](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_15.png)\n\n아래 명령어를 사용하여 nextjs-app의 상태도 확인할 수 있습니다:\n\n```js\npm2 list nextjs-app\n```\n\n<div class=\"content-ad\"></div>\n\n\n![Next.js app deployment](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_16.png)\n\nNext.js 애플리케이션의 기능을 확인하려면, 웹 브라우저에 EC2 인스턴스의 공용 IP와 포트 번호 3000을 입력하세요. 예를 들어, 다음 형식을 사용하세요: 0.0.0.0:3000\n\n![Next.js app deployment](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_17.png)\n\nnextjs-app 프로세스를 중지하려면, 아래 명령어를 사용하세요:\n\n\n<div class=\"content-ad\"></div>\n\n```js\npm2 stop nextjs-app\n```\n\n<img src=\"/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_18.png\" />\n\n다음 명령을 사용하여 nextjs-app 프로세스를 시작합니다:\n\n```js\npm2 start nextjs-app\n```\n\n<div class=\"content-ad\"></div>\n\n다음js-app 프로세스를 다시 시작하려면:\n\n```js\npm2 restart nextjs-app\n```\n\n다음js-app 프로세스를 삭제하려면:\n\n```js\npm2 delete nextjs-app\n```\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n마무리하면, 이 블로그에서는 수동 단계를 이용해 AWS EC2 인스턴스에 Next.js 앱을 성공적으로 배포하는 과정을 보여주었습니다. 이러한 단계들은 애플리케이션 배포를 위한 견고한 기반을 제공하지만, 컨테이너화와 지속적 통합/지속적 배포(CI/CD) 파이프라인을 통해 더욱 효율적이고 간소화된 접근 방식을 통해 더 많은 것을 이룰 수 있다는 점을 알아두는 것이 중요합니다.\n\n다가오는 포스트들에서는 컨테이너화의 세계에 대해 자세히 다루고, Docker와 Kubernetes 같은 도구 및 CI/CD 파이프라인을 활용하여 배포 프로세스를 자동화하고 확장 가능성을 향상시키며, Next.js 애플리케이션 관리를 더욱 최적화하는 방법을 살펴볼 것입니다. 이러한 고급 배포 전략에 대한 논의를 기대해 주세요.\n\n만약 이 블로그 포스트가 도움이 되었고 유익하게 느껴진다면, 박수로 감사를 표현해 주시길 초대합니다! 여러분의 지원은 저에게 지속적으로 가치 있는 콘텐츠를 공유할 동기를 부여합니다. 팔로우 버튼도 꼭 눌러주시고, 계속해서 연결되어 다가오는 포스트에 대한 업데이트를 받아보세요. 함께 이 여정에 참여하고 데브옵스 세계에서 더욱 흥미로운 통찰을 탐구해봅시다. 여러분의 참여를 진심으로 사랑합니다! 👏🔗","ogImage":{"url":"/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_0.png"},"coverImage":"/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_0.png","tag":["Tech"],"readingTime":9},{"title":"API 버전 관리 이해하기 왜 중요한 것인지","description":"","date":"2024-06-20 04:28","slug":"2024-06-20-UnderstandingAPIVersioningWhyItsImportant","content":"\n\nAPI(응용 프로그램 프로그래밍 인터페이스)는 현대 소프트웨어 개발의 중추로, 다른 시스템이 통신하고 데이터를 교환할 수 있게 합니다.\n\n소프트웨어가 발전함에 따라 API에 대한 변경은 불가피합니다. 이러한 변경은 새로운 기능을 도입하거나 성능을 개선하거나 버그를 수정할 수 있습니다.\n\n하지만, API의 변경은 API의 이전 버전에 의존하는 사용자들에게 기존 기능을 망가뜨릴 수도 있습니다. 이 때 API 버전 관리가 필요합니다.\n\n이 글에서는 API 버전 관리가 무엇인지, 왜 중요한지, 언제 사용해야 하는지, 그리고 Node.js를 사용한 실용적인 예제에 대해 탐구해 보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n# API 버전 관리란 무엇인가요?\n\nAPI 버전 관리는 API의 변경 사항을 관리하기 위해 API의 다른 상태에 다른 버전을 할당하는 것을 말합니다.\n\n![image](/assets/img/2024-06-20-UnderstandingAPIVersioningWhyItsImportant_0.png)\n\n이를 통해 개발자는 특정 API 버전에 의존하는 기존 사용자를 방해하지 않고 업데이트와 개선 사항을 적용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# API 버전 관리의 중요성\n\n다음은 API 버전 관리의 중요성을 강조하는 요점입니다.\n\n- 역호환성: API 버전 관리는 API의 변경 사항이 기존 응용 프로그램을 손상시키지 않도록 보장합니다. 클라이언트는 의존하는 버전을 계속 사용할 수 있으며, 동시에 새로운 클라이언트는 최신 기능을 활용할 수 있습니다.\n- 부드러운 전환: 이는 한 버전에서 다른 버전으로의 부드러운 전환을 허용하며, 개발자들이 코드를 새 버전과 호환되도록 업데이트하는 데 충분한 시간을 제공합니다.\n- 유지보수 향상: 버전 관리는 코드베이스를 유지하고 조직화하는 데 도움이 되어 API의 다양한 반복본을 관리하기가 쉬워집니다.\n- 명확한 의사 소통: 사용자들에게 그들이 사용 중인 버전과 향후 버전에서 기대할 수 있는 변경 사항에 대해 명확히 전달합니다.\n\n# API 버전 관리의 사용 시기\n\n<div class=\"content-ad\"></div>\n\n다음은 API 버전 관련 시기를 강조한 내용입니다.\n\n- 중단 변경사항: 엔드포인트를 제거하거나 응답 형식을 변경하거나 기존 엔드포인트의 동작을 변경하는 등과 같이 하위 호환성이 없는 변경 사항을 도입할 때.\n- 중요한 업데이트: 중요한 업데이트로, 상당한 새 기능을 추가하거나 기존 기능을 크게 변경하는 경우.\n- 사용 중단: 더 오래된 기능을 단계적으로 폐기할 계획이지만 이전 기능에 대한 지원을 제공해야 할 때.\n\n# API 버전 관리에 사용하지 말아야 할 때\n\n다음은 API 버전 관리를 사용하지 말아야 하는 경우를 강조한 내용입니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-UnderstandingAPIVersioningWhyItsImportant_1.png\" />\n\n- 작은 변경 사항: 작은, 하위 호환성 업데이트에는 새 엔드포인트 추가, 기존 엔드포인트에 비파괴적인 변경, 또는 버그 수정이 포함됩니다.\n- 내부 API: 조직 내부에서 사용되는 API로, 모든 클라이언트를 제어하고 API 변경 사항과 동시에 업데이트되도록 보장할 수 있는 경우입니다.\n\n# 다른 버전의 API로 클라이언트 요청\n\n<img src=\"/assets/img/2024-06-20-UnderstandingAPIVersioningWhyItsImportant_2.png\" />\n\n<div class=\"content-ad\"></div>\n\n- 클라이언트 요청: 클라이언트는 API에 요청을 보냅니다.\n- API 게이트웨이: API 게이트웨이는 이러한 요청을 받아들이고 요청 URL 또는 헤더에 지정된 버전에 따라 적절한 API 버전으로 라우팅합니다.\n- API 버전: API 게이트웨이는 요청을 적절한 API 버전(e.g., v1, v2 또는 v3)으로 전달합니다.\n- 응답: API는 요청을 처리하고 응답을 API 게이트웨이에 다시 보내며, 이후 게이트웨이가 클라이언트에게 전달합니다.\n\n# API 게이트웨이를 통한 API 버전 관리 구현\n\n위의 흐름을 설명하기 위해 URL을 기반으로 서로 다른 API 버전으로 요청을 라우팅하는 간단한 Node.js API 게이트웨이를 생성할 수 있습니다.\n\n## 단계 1: 프로젝트 설정하기\n\n<div class=\"content-ad\"></div>\n\n우선 새로운 Node.js 프로젝트를 만들고 Express를 설치하세요.\n\n```bash\nmkdir api-gateway-example\ncd api-gateway-example\nnpm init -y\nnpm install express\n```\n\n## 단계 2: 서버 및 API 게이트웨이 생성\n\ngateway.js라는 파일을 만들고 API 게이트웨이로 작동하는 기본 Express 서버를 설정하세요.\n\n<div class=\"content-ad\"></div>\n\n```javascript\nconst express = require('express');\nconst app = express();\nconst port = 3000;\n\n// API v1 route\napp.use('/api/v1', (req, res, next) => {\n    // Forward the request to the API v1 server\n    // Assuming the API v1 server is running on port 3001\n    const proxy = require('http-proxy').createProxyServer();\n    proxy.web(req, res, { target: 'http://localhost:3001' });\n});\n\n// API v2 route\napp.use('/api/v2', (req, res, next) => {\n    // Forward the request to the API v2 server\n    // Assuming the API v2 server is running on port 3002\n    const proxy = require('http-proxy').createProxyServer();\n    proxy.web(req, res, { target: 'http://localhost:3002' });\n});\n\napp.listen(port, () => {\n    console.log(`API Gateway is now running at http://localhost:${port}/`);\n});\n```\n\n## Step 3: API Version Creation\n\nCreate separate API servers for v1 and v2.\n\nStep 3.1: API v1 (port 3001):\n\n<div class=\"content-ad\"></div>\n\n```js\n// api-v1.js\nconst express = require('express');\nconst app = express();\nconst port = 3001;\n\napp.get('/users', (req, res) => {\n    res.json([\n        { id: 1, name: 'John Doe' },\n        { id: 2, name: 'Jane Smith' }\n    ]);\n});\n\napp.listen(port, () => {\n    console.log(`API v1 running at http://localhost:${port}/`);\n});\n```\n\n단계 3.2: API v2 (포트 3002):\n\n```js\n// api-v2.js\nconst express = require('express');\nconst app = express();\nconst port = 3002;\n\napp.get('/users', (req, res) => {\n    res.json([\n        { userId: 1, fullName: 'John Doe' },\n        { userId: 2, fullName: 'Jane Smith' },\n        { userId: 3, fullName: 'Jim Beam' }\n    ]);\n});\n\napp.listen(port, () => {\n    console.log(`API v2 running at http://localhost:${port}/`);\n});\n```\n\n## 단계 4: 서버 실행하기\n\n\n<div class=\"content-ad\"></div>\n\nAPI 게이트웨이와 두 개의 API 버전을 시작하세요:\n\n```js\nnode gateway.js\nnode api-v1.js\nnode api-v2.js\n```\n\n## 단계 5: 설정 테스트\n\n다른 버전에 요청을 보내어 API 게이트웨이를 테스트하세요.\n\n<div class=\"content-ad\"></div>\n\n\ncurl http://localhost:3000/api/v1/users\ncurl http://localhost:3000/api/v2/users\n\n\nAPI 게이트웨이 및 버전별 API를 Node.js에서 구현하여 클라이언트 요청을 적절한 API 버전으로 라우팅하고 관리할 수 있습니다.\n\n이 설정은 하위 호환성을 보장하고 API의 다른 버전 간에 원확한 전환을 가능하게 합니다.\n\n# 결론\n\n\n<div class=\"content-ad\"></div>\n\nAPI 버전 관리는 API 설계 및 개발의 중요한 측면이며, 기존 기능을 손상시키지 않고 변경 사항을 도입할 수 있도록 개발자들을 가능하게 합니다.\n\nAPI의 다양한 버전을 신중하게 관리함으로써 사용자들에게 원활한 전환을 보장하고 역호환성을 유지할 수 있습니다.\n\n제 글을 끝까지 읽어주셔서 진심으로 감사드립니다!\n\n도움이 되었거나 흥미로웠다면 박수 버튼을 클릭하여 응원해주시겠어요? 🎉\n\n<div class=\"content-ad\"></div>\n\n\n![image](https://miro.medium.com/v2/resize:fit:1400/0*4KabDY9ZImT3QdwF.gif)\n\nAnd hey, don’t miss out on more insightful content — hit that follow button to stay updated!\n\nGet email alerts for my latest Medium posts! Click here.\n\nLet’s learn and grow together. Happy Coding! 👏\n","ogImage":{"url":"/assets/img/2024-06-20-UnderstandingAPIVersioningWhyItsImportant_0.png"},"coverImage":"/assets/img/2024-06-20-UnderstandingAPIVersioningWhyItsImportant_0.png","tag":["Tech"],"readingTime":6},{"title":"IPC 만들기가 Execa 92로 쉬워졌어요","description":"","date":"2024-06-20 04:27","slug":"2024-06-20-IPCmadeeasywithExeca92","content":"\n\n<img src=\"/assets/img/2024-06-20-IPCmadeeasywithExeca92_0.png\" />\n\n# 프로세스 간 복잡성\n\n당신의 운영 체제가 어떤 기술적 경이로운 것들로 구축되어 있는지 잊기 쉽습니다. 터미널에서 다음 명령어를 입력하는 것만으로도 여러 추상화 계층이 관여됩니다.\n\n```js\nnpx open-cli \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\"\n```\n\n<div class=\"content-ad\"></div>\n\nnpx는 호출한 셸과 별도의 프로세스에서 실행되며, 그런 다음 open-cli를 위해 또 다른 서브프로세스를 생성합니다. 각 프로세스에는 실행 파일과 자원(메모리, CPU 상태, 파일 디스크립터 등)이 있습니다.\n\n프로세스는 서로 격리되어 있습니다. 이는 보안상의 이유로 좋은면도 있지만, 이로 인해 프로세스 간 통신(IPC)이 필요합니다.\n\n가장 일반적인 IPC 메커니즘은: 인수, 종료 코드, 환경 변수, 시그널, 표준 스트림(stdin, stdout, stderr), 파일 디스크립터, 파일, 공유 메모리, 그리고 네트워크 호출입니다.\n\n하지만 이러한 해결책들은 종종 너무 한정된 경우나 너무 복잡한 경우가 많습니다. 방금 출시된 Execa 9.2는 두 프로세스 모두 Node.js를 사용할 때 IPC를 간단하게 만드는 것을 목표로 합니다.\n\n<div class=\"content-ad\"></div>\n\n# 프로세스에 어떤 것이라도 전달하기\n\n대부분의 IPC 방법을 사용하면 문자열을 보내는 것이 간단합니다. 그러나 구조화된 데이터를 전송하려면 직렬화(serializing)하고 파싱(parsing)해야 합니다. 예를 들어, 일반 객체는 JSON을 사용할 수 있습니다.\n\nExeca에서는 ipcInput 옵션이 대부분의 유형을 자동으로 변환하므로 수동으로 직렬화하거나 파싱할 필요가 없습니다.\n\n이것은 구조화된 복제 알고리즘을 따릅니다. 요약하면, 거의 모든 JavaScript 값이 허용되지만 함수(클래스 인스턴스 메서드를 포함한)가 두드러진 예외입니다.\n\n<div class=\"content-ad\"></div>\n\n일반적으로 인수와 환경 변수의 크기 제한은 1MB 미만인 반면, ipcInput 옵션은 최대 2GB까지 처리할 수 있습니다.\n\n```js\n// main.js\nimport {execaNode} from 'execa';\n\nconst ipcInput = [\n  {\n    task: 'lint',\n    ignore: /test\\.js/,\n  },\n  {\n    task: 'copy',\n    files: new Set([\n      'main.js',\n      'index.js',\n    ]),\n  },\n];\nawait execaNode({ipcInput})`build.js`;\n```\n\n```js\n// build.js\nimport {getOneMessage} from 'execa';\n\nconst ipcInput = await getOneMessage();\nfor (const {task, ignore, files} of ipcInput) {\n  await runTask(task, {ignore, files});\n}\n```\n\n# 프로세스로부터 아무 것이나 반환\n\n<div class=\"content-ad\"></div>\n\n프로세스의 출력물에도 동일한 문제가 있습니다. stdout와 stderr은 어떤 내용이든 출력할 수 있지만 호출자는 이를 구문 분석해야 합니다.\n\nExeca를 사용하면 프로세스가 sendMessage(message)를 호출하여 거의 모든 데이터를 반환할 수 있습니다. 부모 프로세스는 결과.ipcOutput 배열을 사용하여 그대로 가져옵니다.\n\n```js\n// main.js\nimport {execaNode} from 'execa';\n\nconst {ipcOutput} = await execaNode`build.js`;\nconsole.log(ipcOutput[0]); // {kind: 'start', timestamp: date}\nconsole.log(ipcOutput[1]); // {kind: 'stop', timestamp: date}\n```\n\n```js\n// build.js\nimport {sendMessage} from 'execa';\n\nawait sendMessage({kind: 'start', timestamp: new Date()});\nawait runBuild();\nawait sendMessage({kind: 'stop', timestamp: new Date()});\n```\n\n<div class=\"content-ad\"></div>\n\n# 메시지 교환\n\n만약 프로세스가 실행 중일 때 출력을 검색해야 하는 경우 어떻게 할까요? 진행률 표시를 위해 예를 들면요? 또는 이미 시작된 프로세스 이후에 추가 입력을 제공해야 할 때는 어떻게 해야 할까요?\n\n일반적으로 이는 stdin, stdout, stderr를 스트리밍하거나 네트워크 호출을 수행하여 해결됩니다. 성능 조정 및 잠재적 I/O 오류 처리를 다룰 때 특히 어려울 수 있습니다.\n\nExeca는 메시지를 교환하기 위한 간단한 메서드 세트를 제공합니다: sendMessage(message)와 getOneMessage().\n\n<div class=\"content-ad\"></div>\n\n```js\n// parent.js\nimport {execaNode} from 'execa';\n\nconst subprocess = execaNode`child.js`;\nawait subprocess.sendMessage('Hello from parent');\nconst message = await subprocess.getOneMessage();\nconsole.log(message); // 'Hello from child'\nawait subprocess;\n```   \n\n```js\n// child.js\nimport {getOneMessage, sendMessage} from 'execa';\n\nconst message = await getOneMessage(); // 'Hello from parent'\nconst newMessage = message.replace('parent', 'child'); // 'Hello from child'\nawait sendMessage(newMessage);\n```\n\n# 메시지 수신\n\n또한 한 프로세스(또는 양쪽 모두)가 상대방에서 오는 요청을 처리하는 클라이언트/서버 모델을 따를 수 있습니다. 이것은 getEachMessage()를 사용하여 모든 수신 메시지를 수신함으로써 구현됩니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n// parent.js\nimport {execaNode} from 'execa';\n\nconst subprocess = execaNode`child.js`;\nawait subprocess.sendMessage(0);\n\n// This loop ends when the subprocess exits.\n// It throws if the subprocess fails.\nfor await (const message of subprocess.getEachMessage()) {\n  console.log(message); // 1, 3, 5, 7, 9\n  await subprocess.sendMessage(message + 1);\n}\n```\n\n```js\n// child.js\nimport {sendMessage, getEachMessage} from 'execa';\n\n// The subprocess exits when hitting `break`\nfor await (const message of getEachMessage()) {\n  if (message === 10) {\n    break;\n  }\n\n  console.log(message); // 0, 2, 4, 6, 8\n  await sendMessage(message + 1);\n}\n```\n\n# 메시지 필터링\n\n`getOneMessage()` 메서드에는 특정 메시지를 선택하는 필터 옵션이 있습니다. 이는 서로 다른 유형의 이벤트를 수신할 때 유용합니다.\n\n\n<div class=\"content-ad\"></div>\n\n```js\nimport {execaNode} from 'execa';\n\nconst subprocess = execaNode`build.js`;\nconst stopMessage = await subprocess.getOneMessage({\n  filter: message => message.type === 'stop',\n});\n```\n\n# 보장된 수신\n\nIPC는 본질적으로 상태를 가지며 시간에 민감하기 때문에 미묘한 레이스 컨디션 버그를 만들어낼 수 있습니다. 대부분의 네트워크 프로토콜은 메시지를 보낼 때 메시지가 제대로 수신되도록 보장하여 이를 예방합니다. 예를 들어, TCP는 ACK 번호를 사용합니다.\n\nExeca에서는 strict 옵션이 그 목적을 충족시킵니다. 활성화된 경우, 다른 프로세스가 메시지를 제대로 수신하는 것을 보장합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n// main.js\nimport {execaNode} from 'execa';\n\nconst subprocess = execaNode`build.js`;\n// `build` 메시지를 받음\nawait subprocess.sendMessage('build', {strict: true});\n// `lint` 메시지를 받지 못해 예외가 발생함\nawait subprocess.sendMessage('lint', {strict: true});\nawait subprocess; \n```\n\n```js\n// build.js\nimport {getOneMessage} from 'execa';\n\n// `build` 메시지를 받음\nconst task = await getOneMessage();\n// `runTask()`이 진행 중일 때 `lint` 메시지가 전송됨\n// 따라서 `lint` 메시지는 버려짐\nawait runTask(task);\n\n// `lint` 메시지를 받지 않음\n// `strict`이 없으면 영원히 대기할 것\nconst secondTask = await getOneMessage();\nawait runTask(secondTask);\n```\n\n# 프로세스를 멈추지 않기\n\n메시지를 보낸 쪽에서 보낸 모든 메시지가 다른 쪽에서 받도록 하려면, 메시지를 수신할 때 프로세스를 유지합니다.\n\n\n<div class=\"content-ad\"></div>\n\n그러나 메시지가 전송되었는지 여부를 확신할 수 없을 때는 이 방법이 잘 작동하지 않을 수 있습니다. 그렇게 되면 프로세스가 영원히 멈춰있는 상황이 발생할 수 있습니다. 이 문제는 reference: false 옵션을 사용하여 해결할 수 있습니다.\n\n```js\nimport {getEachMessage} from 'execa';\n\n// {type: 'gracefulExit'}가 가끔 수신되지만 항상 그렇지는 않습니다\nfor await (const message of getEachMessage({reference: false})) {\n  if (message.type === 'gracefulExit') {\n    gracefulExit();\n  }\n}\n```\n\n# 디버깅\n\n프로세스가 격리되어 있기 때문에 디버깅하기 어려운 블랙 박스가 될 수 있습니다. 이를 해결하기 위해 Execa 프로세스에서 보낸 모든 IPC 메시지는 오류 메시지와 상세 로그 모두 자동으로 출력됩니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n// build.js\nimport {execaNode} from 'execa';\n\nawait execaNode`npm run build`;\n```\n\n```js\n# 자세한 모드로 실행\n# 각 * 심볼이 있는 행은 IPC 메시지입니다\n\n$ NODE_DEBUG=execa node build.js\n[00:57:44.658] [0] $ npm run build\n[00:57:44.670] [0]   응용프로그램 빌드 중...\n[00:57:44.692] [0] * {name: 'start'}\n[00:57:44.701] [0] * {name: 'entrypoint', value: 'mispelled_index.js'} \n[00:57:44.740] [0]   오류: 입구점이 잘못되었습니다.\n[00:57:44.747] [0] ✘ 명령은 종료 코드 1로 실패했습니다: npm run build\n[00:57:44.747] [0] ✘ (89ms에 완료됨)\n```\n\n# 우아한 종료\n\n프로세스를 부드럽게 다루는 것은 쉽지 않습니다. 사실, 그들을 종료하는 것은 보통 꽤 무자비합니다. 표준 접근 방식은 SIGTERM과 같은 신호를 보내는 것입니다. 그러나 이러한 절차는 프로세스가 급작스럽게 종료되어 진행 중인 작업이 모두 종료된다는 점을 의미합니다. 이로 인해 파일 작성이 중간에 멈추거나, HTTP 요청이 멈추거나, 데이터가 손상될 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nUnix에서는 핸들러가 시그널을 가로채서 정리 작업을 실행할 수 있습니다. 하지만 윈도우에서는 작동하지 않습니다.\n\ngracefulCancel 옵션은 이 문제에 대한 크로스 플랫폼 솔루션을 제공합니다. 이는 IPC를 사용하여 프로세스와 해당 부모 프로세스 사이에서 AbortSignal을 공유합니다.\n\n```js\n// main.js\nimport {execaNode} from 'execa';\n\nconst controller = new AbortController();\nsetTimeout(() => {\n  controller.abort();\n}, 5000);\n\nconst cancelSignal = controller.signal;\nawait execaNode({cancelSignal, gracefulCancel: true})`build.js`;\n```\n\n```js\n// build.js\nimport {getCancelSignal} from 'execa';\n\nconst cancelSignal = await getCancelSignal();\nconst url = 'https://example.com/build/info';\nconst response = await fetch(url, {signal: cancelSignal});\n```\n\n<div class=\"content-ad\"></div>\n\n# 속내를 들여다보기\n\n우리는 이러한 기능들을 Node의 내장 IPC 위에 구축했습니다. 명명된 파이프는 프로세스 간 통신 채널로 사용됩니다. 메시지 페이로드는 V8로 직렬화됩니다.\n\nIPC는 고급 기능입니다. 95%의 경우, 필요하지 않을 것입니다. Execa는 이미 스크립트에서 파이핑 또는 스트리밍까지 보다 간단한 방법을 제공합니다. 그러나 더 복잡한 시나리오에서는 IPC가 시간 절약의 도구가 될 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-20-IPCmadeeasywithExeca92_0.png"},"coverImage":"/assets/img/2024-06-20-IPCmadeeasywithExeca92_0.png","tag":["Tech"],"readingTime":8}],"page":"38","totalPageCount":154,"totalPageGroupCount":8,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true}