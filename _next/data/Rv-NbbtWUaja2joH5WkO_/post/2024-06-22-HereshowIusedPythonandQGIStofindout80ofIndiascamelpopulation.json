{"pageProps":{"post":{"title":"파이썬과 QGIS로 인도의 낙타 80 찾는 방법","description":"","date":"2024-06-22 02:56","slug":"2024-06-22-HereshowIusedPythonandQGIStofindout80ofIndiascamelpopulation","content":"\n\n## 파이썬 자동화\n\n\"안녕 Aayush, 내가 인도의 저소득 농촌 여성들을 위한 낙타 기반 생계 개선에 집중해야 할 곳을 알고 싶어\", 라는 요구가 왔어요. 라자스탄 출신인 내 친구가 말했어요. 그녀는 라자스탄의 사막 지역이 정답일 것이라고 알고 있었지만, 직감을 뒷받침할 공식 자료가 필요했어요. 그래서 제가 나서서 이 정보를 찾기로 했어요. \n\n## 단계 1\n\n인도 정부의 데이터 제공 플랫폼인 data.gov.in 에서 2019년 20번째 가축 조사 자료 시트 제2020년 승업부와 가축전문부, 수산부, 가축전문부의 자료를 찾아보세요.\n\n<div class=\"content-ad\"></div>\n\n## 단계 2\n\n개발자 도구를 사용하여 한 번에 모든 파일에 액세스할 수 있는 URL을 얻는 cURL을 얻으세요. 이렇게 하지 않았다면 각 파일을 개별적으로 클릭하여 양식을 작성하고 캡차를 입력한 다음 CSV를 수동으로 다운로드해야 했을 것입니다. 이 방법으로 제게 많은 시간을 절약했어요.\n\n## Step 3\n\nPostman에 URL을 게시하고 해당하는 Python 요청 코드를 가져와서 응답을 구문 분석하세요.\n\n<div class=\"content-ad\"></div>\n\n## 단계 4\n\n저는 Python을 사용하여 응답을 구문 분석하고, 이 코드를 사용하여 모든 URL 링크를 가져왔어요.\n\n```js\nfrom pprint import pprint\nimport os\nimport pandas as pd\nimport requests\n\nurl = \"https://data.gov.in/backend/dmspublic/v1/resources?filters[catalog_reference]=6885101&offset=0&limit=35&sort[changed]=desc&filters[domain_visibility]=4\"\n\npayload = {}\nheaders = {\n  'Accept': 'application/json, text/plain, */*',\n  'Accept-Language': 'en-GB,en-US;q=0.9,en;q=0.8,de;q=0.7',\n  'Connection': 'keep-alive',\n  'Cookie': 'fontSize=67.5; citrix_ns_id=AAA7TRx1ZjuD0ksAAAAAADuMGtjGAxHPGX4gOzVglnj-t-2_KYp3QS5pOwB3wsrGOw==jyF1Zg==9zCLz_Tsia4CNE6H2-pAKy8Ou1w=; citrix_ns_id=AAA7TRx1ZjuD0ksAAAAAADuMGtjGAxHPGX4gOzVglnj-t-2_KYp3QS5pOwB3wsrGOw==uiR1Zg==JTC1HaNqvL2oNi2kwWYolcsi_TU=',\n  'Referer': 'https://data.gov.in/catalog/20th-livestock-census',\n  'Sec-Fetch-Dest': 'empty',\n  'Sec-Fetch-Mode': 'cors',\n  'Sec-Fetch-Site': 'same-origin',\n  'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',\n  'dnt': '1',\n  'sec-ch-ua': '\"Not/A)Brand\";v=\"8\", \"Chromium\";v=\"126\", \"Google Chrome\";v=\"126\"',\n  'sec-ch-ua-mobile': '?0',\n  'sec-ch-ua-platform': '\"macOS\"',\n  'sec-gpc': '1'\n}\n\nresponse = requests.request(\"GET\", url, headers=headers, data=payload)\n```\n\n```js\nrjson = response.json()\nrows = rjson['data']['rows']\nurls = []\nfor row in rows:\n    url = \"https://\"+row['datafile'][0]\n    print(url)\n    urls.append(url)\n```\n\n<div class=\"content-ad\"></div>\n\n최종 출력물은 CSV를 얻기 위해 구문 분석한 URL 목록입니다.\n\n![이미지](/assets/img/2024-06-22-HereshowIusedPythonandQGIStofindout80ofIndiascamelpopulation_0.png)\n\n## 단계 5\n\n모든 파일을 다운로드하여 연결하여 최종 데이터 프레임을 얻었습니다. 그 후에는 80%의 기준점을 사용하여 낙타 인구의 80%를 보유한 지역을 파악했습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\r\nsave_directory = './csv_files/'\n\nif not os.path.exists(save_directory):\n    os.makedirs(save_directory)\n\ndef download_file(url, save_directory):\n    try:\n        response = requests.get(url)\n        response.raise_for_status()  # 요청이 성공적인지 확인\n        file_name = os.path.join(save_directory, url.split('/')[-1])\n        with open(file_name, 'wb') as file:\n            file.write(response.content)\n        print(f\"다운로드 완료: {file_name}\")\n    except requests.exceptions.RequestException as e:\n        print(f\"{url}을(를) 다운로드하는 데 실패했습니다: {e}\")\n\nfor url in urls:\n    download_file(url, save_directory)\n\ncsv_directory = save_directory\n\ndataframes = []\n\nall_headers = set()\n\nfor filename in os.listdir(csv_directory):\n    if filename.endswith('.csv'):\n        file_path = os.path.join(csv_directory, filename)\n        df = pd.read_csv(file_path)\n        dataframes.append(df)\n        all_headers.update(df.columns)\n\n# 모든 데이터 프레임이 동일한 헤더를 갖고 있는지 확인\nheaders_match = all(len(df.columns.difference(all_headers)) == 0 for df in dataframes)\n\nif headers_match:\n    combined_df = pd.concat(dataframes, ignore_index=True)\nelse:\n    combined_df = pd.DataFrame(columns=all_headers)\n    for df in dataframes:\n        df = df.reindex(columns=all_headers)  # 모든 열이 존재하는지 확인\n        combined_df = pd.concat([combined_df, df], ignore_index=True)\n\ncombined_csv_path = os.path.join(csv_directory, 'combined.csv')\ncombined_df.to_csv(combined_csv_path, index=False)\n\nprint(f\"결합된 CSV가 저장되었습니다: {combined_csv_path}\")\r\n```\n\n```js\r\ndf['camel'] = pd.to_numeric(df['camel'], errors='coerce')\ndf_sorted = df.sort_values(by='camel', ascending=False).reset_index(drop=True)\ndf_sorted['cumulative_sum'] = df_sorted['camel'].cumsum()\ntotal_camels = df_sorted['camel'].sum()\nthreshold = 0.8 * total_camels\ndf_sorted['cumulative_percentage'] = df_sorted['cumulative_sum'] / total_camels\ndistricts_80_percent = df_sorted[df_sorted['cumulative_percentage'] <= 0.8]\nprint(districts_80_percent[['state_name','district_name', 'camel', 'cumulative_sum', 'cumulative_percentage']])\r\n```\n\n<img src=\"/assets/img/2024-06-22-HereshowIusedPythonandQGIStofindout80ofIndiascamelpopulation_1.png\" />\n\n## 단계 6\r\n\n\n<div class=\"content-ad\"></div>\n\n인도의 지구 행정 구역 geojson 파일을 받았어요. 이 파일을 이용하여 18개의 지구를 필터링하는 기능을 만들고, QGIS에서 이를 시각화하며 배경 레이어를 구글 위성 지도로 설정하여 최종 결과물을 얻었어요.\n\n만약 어떤 단계에 대해 더 알고 싶다면 언제든지 저에게 문의해주세요. 이것은 공개 데이터를 활용하여 결정을 내리는 데 있어 있는 가능성 중 하나의 작은 예시에 불과해요. 즐기세요!","ogImage":{"url":"/assets/img/2024-06-22-HereshowIusedPythonandQGIStofindout80ofIndiascamelpopulation_0.png"},"coverImage":"/assets/img/2024-06-22-HereshowIusedPythonandQGIStofindout80ofIndiascamelpopulation_0.png","tag":["Tech"],"readingTime":5},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<h2>파이썬 자동화</h2>\n<p>\"안녕 Aayush, 내가 인도의 저소득 농촌 여성들을 위한 낙타 기반 생계 개선에 집중해야 할 곳을 알고 싶어\", 라는 요구가 왔어요. 라자스탄 출신인 내 친구가 말했어요. 그녀는 라자스탄의 사막 지역이 정답일 것이라고 알고 있었지만, 직감을 뒷받침할 공식 자료가 필요했어요. 그래서 제가 나서서 이 정보를 찾기로 했어요.</p>\n<h2>단계 1</h2>\n<p>인도 정부의 데이터 제공 플랫폼인 data.gov.in 에서 2019년 20번째 가축 조사 자료 시트 제2020년 승업부와 가축전문부, 수산부, 가축전문부의 자료를 찾아보세요.</p>\n<div class=\"content-ad\"></div>\n<h2>단계 2</h2>\n<p>개발자 도구를 사용하여 한 번에 모든 파일에 액세스할 수 있는 URL을 얻는 cURL을 얻으세요. 이렇게 하지 않았다면 각 파일을 개별적으로 클릭하여 양식을 작성하고 캡차를 입력한 다음 CSV를 수동으로 다운로드해야 했을 것입니다. 이 방법으로 제게 많은 시간을 절약했어요.</p>\n<h2>Step 3</h2>\n<p>Postman에 URL을 게시하고 해당하는 Python 요청 코드를 가져와서 응답을 구문 분석하세요.</p>\n<div class=\"content-ad\"></div>\n<h2>단계 4</h2>\n<p>저는 Python을 사용하여 응답을 구문 분석하고, 이 코드를 사용하여 모든 URL 링크를 가져왔어요.</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">from</span> pprint <span class=\"hljs-keyword\">import</span> pprint\n<span class=\"hljs-keyword\">import</span> os\n<span class=\"hljs-keyword\">import</span> pandas <span class=\"hljs-keyword\">as</span> pd\n<span class=\"hljs-keyword\">import</span> requests\n\nurl = <span class=\"hljs-string\">\"https://data.gov.in/backend/dmspublic/v1/resources?filters[catalog_reference]=6885101&#x26;offset=0&#x26;limit=35&#x26;sort[changed]=desc&#x26;filters[domain_visibility]=4\"</span>\n\npayload = {}\nheaders = {\n  <span class=\"hljs-string\">'Accept'</span>: <span class=\"hljs-string\">'application/json, text/plain, */*'</span>,\n  <span class=\"hljs-string\">'Accept-Language'</span>: <span class=\"hljs-string\">'en-GB,en-US;q=0.9,en;q=0.8,de;q=0.7'</span>,\n  <span class=\"hljs-string\">'Connection'</span>: <span class=\"hljs-string\">'keep-alive'</span>,\n  <span class=\"hljs-string\">'Cookie'</span>: <span class=\"hljs-string\">'fontSize=67.5; citrix_ns_id=AAA7TRx1ZjuD0ksAAAAAADuMGtjGAxHPGX4gOzVglnj-t-2_KYp3QS5pOwB3wsrGOw==jyF1Zg==9zCLz_Tsia4CNE6H2-pAKy8Ou1w=; citrix_ns_id=AAA7TRx1ZjuD0ksAAAAAADuMGtjGAxHPGX4gOzVglnj-t-2_KYp3QS5pOwB3wsrGOw==uiR1Zg==JTC1HaNqvL2oNi2kwWYolcsi_TU='</span>,\n  <span class=\"hljs-string\">'Referer'</span>: <span class=\"hljs-string\">'https://data.gov.in/catalog/20th-livestock-census'</span>,\n  <span class=\"hljs-string\">'Sec-Fetch-Dest'</span>: <span class=\"hljs-string\">'empty'</span>,\n  <span class=\"hljs-string\">'Sec-Fetch-Mode'</span>: <span class=\"hljs-string\">'cors'</span>,\n  <span class=\"hljs-string\">'Sec-Fetch-Site'</span>: <span class=\"hljs-string\">'same-origin'</span>,\n  <span class=\"hljs-string\">'User-Agent'</span>: <span class=\"hljs-string\">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36'</span>,\n  <span class=\"hljs-string\">'dnt'</span>: <span class=\"hljs-string\">'1'</span>,\n  <span class=\"hljs-string\">'sec-ch-ua'</span>: <span class=\"hljs-string\">'\"Not/A)Brand\";v=\"8\", \"Chromium\";v=\"126\", \"Google Chrome\";v=\"126\"'</span>,\n  <span class=\"hljs-string\">'sec-ch-ua-mobile'</span>: <span class=\"hljs-string\">'?0'</span>,\n  <span class=\"hljs-string\">'sec-ch-ua-platform'</span>: <span class=\"hljs-string\">'\"macOS\"'</span>,\n  <span class=\"hljs-string\">'sec-gpc'</span>: <span class=\"hljs-string\">'1'</span>\n}\n\nresponse = requests.<span class=\"hljs-title function_\">request</span>(<span class=\"hljs-string\">\"GET\"</span>, url, headers=headers, data=payload)\n</code></pre>\n<pre><code class=\"hljs language-js\">rjson = response.<span class=\"hljs-title function_\">json</span>()\nrows = rjson[<span class=\"hljs-string\">'data'</span>][<span class=\"hljs-string\">'rows'</span>]\nurls = []\n<span class=\"hljs-keyword\">for</span> row <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">rows</span>:\n    url = <span class=\"hljs-string\">\"https://\"</span>+row[<span class=\"hljs-string\">'datafile'</span>][<span class=\"hljs-number\">0</span>]\n    <span class=\"hljs-title function_\">print</span>(url)\n    urls.<span class=\"hljs-title function_\">append</span>(url)\n</code></pre>\n<div class=\"content-ad\"></div>\n<p>최종 출력물은 CSV를 얻기 위해 구문 분석한 URL 목록입니다.</p>\n<p><img src=\"/assets/img/2024-06-22-HereshowIusedPythonandQGIStofindout80ofIndiascamelpopulation_0.png\" alt=\"이미지\"></p>\n<h2>단계 5</h2>\n<p>모든 파일을 다운로드하여 연결하여 최종 데이터 프레임을 얻었습니다. 그 후에는 80%의 기준점을 사용하여 낙타 인구의 80%를 보유한 지역을 파악했습니다.</p>\n<div class=\"content-ad\"></div>\n<pre><code class=\"hljs language-js\">save_directory = <span class=\"hljs-string\">'./csv_files/'</span>\n\n<span class=\"hljs-keyword\">if</span> not os.<span class=\"hljs-property\">path</span>.<span class=\"hljs-title function_\">exists</span>(save_directory):\n    os.<span class=\"hljs-title function_\">makedirs</span>(save_directory)\n\ndef <span class=\"hljs-title function_\">download_file</span>(url, save_directory):\n    <span class=\"hljs-attr\">try</span>:\n        response = requests.<span class=\"hljs-title function_\">get</span>(url)\n        response.<span class=\"hljs-title function_\">raise_for_status</span>()  # 요청이 성공적인지 확인\n        file_name = os.<span class=\"hljs-property\">path</span>.<span class=\"hljs-title function_\">join</span>(save_directory, url.<span class=\"hljs-title function_\">split</span>(<span class=\"hljs-string\">'/'</span>)[-<span class=\"hljs-number\">1</span>])\n        <span class=\"hljs-keyword\">with</span> <span class=\"hljs-title function_\">open</span>(file_name, <span class=\"hljs-string\">'wb'</span>) <span class=\"hljs-keyword\">as</span> <span class=\"hljs-attr\">file</span>:\n            file.<span class=\"hljs-title function_\">write</span>(response.<span class=\"hljs-property\">content</span>)\n        <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">\"다운로드 완료: {file_name}\"</span>)\n    except requests.<span class=\"hljs-property\">exceptions</span>.<span class=\"hljs-property\">RequestException</span> <span class=\"hljs-keyword\">as</span> <span class=\"hljs-attr\">e</span>:\n        <span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">\"{url}을(를) 다운로드하는 데 실패했습니다: {e}\"</span>)\n\n<span class=\"hljs-keyword\">for</span> url <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">urls</span>:\n    <span class=\"hljs-title function_\">download_file</span>(url, save_directory)\n\ncsv_directory = save_directory\n\ndataframes = []\n\nall_headers = <span class=\"hljs-title function_\">set</span>()\n\n<span class=\"hljs-keyword\">for</span> filename <span class=\"hljs-keyword\">in</span> os.<span class=\"hljs-title function_\">listdir</span>(csv_directory):\n    <span class=\"hljs-keyword\">if</span> filename.<span class=\"hljs-title function_\">endswith</span>(<span class=\"hljs-string\">'.csv'</span>):\n        file_path = os.<span class=\"hljs-property\">path</span>.<span class=\"hljs-title function_\">join</span>(csv_directory, filename)\n        df = pd.<span class=\"hljs-title function_\">read_csv</span>(file_path)\n        dataframes.<span class=\"hljs-title function_\">append</span>(df)\n        all_headers.<span class=\"hljs-title function_\">update</span>(df.<span class=\"hljs-property\">columns</span>)\n\n# 모든 데이터 프레임이 동일한 헤더를 갖고 있는지 확인\nheaders_match = <span class=\"hljs-title function_\">all</span>(<span class=\"hljs-title function_\">len</span>(df.<span class=\"hljs-property\">columns</span>.<span class=\"hljs-title function_\">difference</span>(all_headers)) == <span class=\"hljs-number\">0</span> <span class=\"hljs-keyword\">for</span> df <span class=\"hljs-keyword\">in</span> dataframes)\n\n<span class=\"hljs-keyword\">if</span> <span class=\"hljs-attr\">headers_match</span>:\n    combined_df = pd.<span class=\"hljs-title function_\">concat</span>(dataframes, ignore_index=<span class=\"hljs-title class_\">True</span>)\n<span class=\"hljs-attr\">else</span>:\n    combined_df = pd.<span class=\"hljs-title class_\">DataFrame</span>(columns=all_headers)\n    <span class=\"hljs-keyword\">for</span> df <span class=\"hljs-keyword\">in</span> <span class=\"hljs-attr\">dataframes</span>:\n        df = df.<span class=\"hljs-title function_\">reindex</span>(columns=all_headers)  # 모든 열이 존재하는지 확인\n        combined_df = pd.<span class=\"hljs-title function_\">concat</span>([combined_df, df], ignore_index=<span class=\"hljs-title class_\">True</span>)\n\ncombined_csv_path = os.<span class=\"hljs-property\">path</span>.<span class=\"hljs-title function_\">join</span>(csv_directory, <span class=\"hljs-string\">'combined.csv'</span>)\ncombined_df.<span class=\"hljs-title function_\">to_csv</span>(combined_csv_path, index=<span class=\"hljs-title class_\">False</span>)\n\n<span class=\"hljs-title function_\">print</span>(f<span class=\"hljs-string\">\"결합된 CSV가 저장되었습니다: {combined_csv_path}\"</span>)\n</code></pre>\n<pre><code class=\"hljs language-js\">df[<span class=\"hljs-string\">'camel'</span>] = pd.<span class=\"hljs-title function_\">to_numeric</span>(df[<span class=\"hljs-string\">'camel'</span>], errors=<span class=\"hljs-string\">'coerce'</span>)\ndf_sorted = df.<span class=\"hljs-title function_\">sort_values</span>(by=<span class=\"hljs-string\">'camel'</span>, ascending=<span class=\"hljs-title class_\">False</span>).<span class=\"hljs-title function_\">reset_index</span>(drop=<span class=\"hljs-title class_\">True</span>)\ndf_sorted[<span class=\"hljs-string\">'cumulative_sum'</span>] = df_sorted[<span class=\"hljs-string\">'camel'</span>].<span class=\"hljs-title function_\">cumsum</span>()\ntotal_camels = df_sorted[<span class=\"hljs-string\">'camel'</span>].<span class=\"hljs-title function_\">sum</span>()\nthreshold = <span class=\"hljs-number\">0.8</span> * total_camels\ndf_sorted[<span class=\"hljs-string\">'cumulative_percentage'</span>] = df_sorted[<span class=\"hljs-string\">'cumulative_sum'</span>] / total_camels\ndistricts_80_percent = df_sorted[df_sorted[<span class=\"hljs-string\">'cumulative_percentage'</span>] &#x3C;= <span class=\"hljs-number\">0.8</span>]\n<span class=\"hljs-title function_\">print</span>(districts_80_percent[[<span class=\"hljs-string\">'state_name'</span>,<span class=\"hljs-string\">'district_name'</span>, <span class=\"hljs-string\">'camel'</span>, <span class=\"hljs-string\">'cumulative_sum'</span>, <span class=\"hljs-string\">'cumulative_percentage'</span>]])\n</code></pre>\n<img src=\"/assets/img/2024-06-22-HereshowIusedPythonandQGIStofindout80ofIndiascamelpopulation_1.png\">\n<h2>단계 6</h2>\n<div class=\"content-ad\"></div>\n<p>인도의 지구 행정 구역 geojson 파일을 받았어요. 이 파일을 이용하여 18개의 지구를 필터링하는 기능을 만들고, QGIS에서 이를 시각화하며 배경 레이어를 구글 위성 지도로 설정하여 최종 결과물을 얻었어요.</p>\n<p>만약 어떤 단계에 대해 더 알고 싶다면 언제든지 저에게 문의해주세요. 이것은 공개 데이터를 활용하여 결정을 내리는 데 있어 있는 가능성 중 하나의 작은 예시에 불과해요. 즐기세요!</p>\n</body>\n</html>\n"},"__N_SSG":true}