{"pageProps":{"posts":[{"title":"Nodejs에서 SSLCOMMERZ 결제 게이트웨이 통합하기","description":"","date":"2024-06-20 04:32","slug":"2024-06-20-IntegratingSSLCOMMERZPaymentGatewayinNodejs","content":"\n\n이 블로그 포스트에서는 MongoDB를 사용하여 Node.js 애플리케이션에 SSLCommerz 결제 게이트웨이를 통합하는 과정을 안내하겠습니다. 이 안내서는 웹 애플리케이션을 위한 안전하고 효율적인 결제 처리 시스템을 설정하는 데 도움이 될 것입니다.\n\n![이미지](/assets/img/2024-06-20-IntegratingSSLCOMMERZPaymentGatewayinNodejs_0.png)\n\nSSLCOMMERZ는 SSL Wireless가 개발한 안전하고 인증된 온라인 결제 게이트웨이 플랫폼으로, 온라인 비즈니스 및 전자상거래 판매 업체의 최종 고객이 고객의 카드, 모바일 지갑 또는 은행 계좌로 안전한 거래를 수행할 수 있도록 하였습니다. SSLCOMMERZ의 주요 이점을 살펴보겠습니다.\n\n- 온라인 문서를 통한 빠른 활성화\n- 쉬운 통합\n- 방글라데시 중앙 은행이 PSO 라이선스 부여\n- 30개 이상의 결제 방식\n- 글로벌 결제 수락\n- 실시간 대시보드 보고\n- PCI DSS 규정을 준수한 고수준 보안\n\n<div class=\"content-ad\"></div>\n\n# 준비 사항\n\n시작하기 전에 다음 사항이 준비되어 있는지 확인하십시오:\n\n- Node.js: 컴퓨터에 Node.js가 설치되어 있는지 확인하십시오. nodejs.org에서 다운로드할 수 있습니다.\n- MongoDB: MongoDB가 설정되어 실행 중인지 확인하십시오.\n- SSLCommerz 계정: SSLCommerz 상인 계정이 필요합니다. sslcommerz.com에서 가입할 수 있습니다.\n\n# 단계 1: 프로젝트 설정하기\n\n<div class=\"content-ad\"></div>\n\n먼저, 새로운 Node.js 프로젝트를 생성하고 필요한 종속성을 설치하세요. 터미널을 열고 다음 명령을 실행해보세요:\n\n```js\nmkdir sslcommerz-integration\ncd sslcommerz-integration\nnpm init -y\nnpm install express body-parser dotenv sslcommerz-lts mongodb cors\n```\n\n# 단계 2: 환경 변수 설정\n\n프로젝트의 루트에 .env 파일을 생성하고 SSLCommerz 자격 증명을 추가하세요. 이러한 자격 증명은 SSLCommerz API와의 요청을 인증하는 데 사용될 것입니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nSTORE_ID=your_store_id\nSTORE_PASSWORD=your_store_password\nSERVER_API=http://localhost:3030\nMONGO_URI = \"mongodb+srv://username:password@cluster0.7ctc5qe.mongodb.net/?retryWrites=true&w=majority\"\n```\n\n상인 계정을 생성한 후 이메일로 STORE_ID 및 STORE_PASSWORD를 받게 됩니다. SERVER_API는 백엔드 API 주소이며, MONGO_URI는 MongoDB 대시보드에서 얻을 수 있습니다.\n\n# 단계 3: 익스프레스 서버 설정\n\n이제 익스프레스 서버를 설정하고 결제 작업을 처리하기 위한 필요한 라우트를 정의하세요. app.js 파일을 만들고 다음 코드를 추가하세요:\n\n\n<div class=\"content-ad\"></div>\n\n```js\nconst express = require('express');\nconst bodyParser = require('body-parser');\nconst SSLCommerzPayment = require('sslcommerz-lts');\nconst { MongoClient, ObjectId, ServerApiVersion } = require(\"mongodb\");\nconst cors = require(\"cors\");\nrequire('dotenv').config();\nconst mongoURI = process.env.MONGO_URI;\n\nconst app = express();\nconst port = process.env.PORT || 3030;\n\napp.use(bodyParser.json());\napp.use(bodyParser.urlencoded({ extended: true })); // SSLCommerz로부터 전송된 폼 데이터 처리를 위해\n\n// MongoDB 연결\nconst client = new MongoClient(mongoURI, {\n  serverApi: {\n    version: ServerApiVersion.v1,\n    strict: true,\n    deprecationErrors: true,\n  },\n});\n\n// CORS 및 JSON 파싱을 위한 미들웨어\napp.use(\n  cors({\n    origin: [\"http://localhost:5173\"],\n    credentials: true,\n  })\n);\napp.use(express.json());\n\n// SSLCommerz 구성\nconst store_id = process.env.STORE_ID;\nconst store_passwd = process.env.STORE_PASSWORD;\nconst is_live = false; // 라이브 모드: true, 샌드박스 모드: false\n\nconst run = async () => {\n  try {\n    // 데이터베이스 연결\n    await client.connect();\n\n    // 주문 저장을 위한 컬렉션\n    const ordersCollection = client.db(\"test\").collection(\"orders\");\n\n    // 결제 생성을 위한 POST 요청\n    app.post(\"/plans\", async (req, res) => {\n      // 클라이언트에서 보낸 플랜 세부 정보\n      const planDetails = req.body;\n\n      // 가격을 정수로 변환\n      const price = parseInt(planDetails.price);\n\n      // ObjectId를 사용하여 트랜잭션 ID 생성\n      const tran_id = new ObjectId().toString();\n\n      // SSLCommerz로 보낼 결제 데이터\n      const data = {\n        total_amount: price,\n        currency: \"BDT\",\n        tran_id: tran_id,\n        success_url: `${process.env.SERVER_API}/payment/success`,\n        fail_url: `${process.env.SERVER_API}/payment/fail`,\n        cancel_url: `${process.env.SERVER_API}/payment/cancel`,\n        ipn_url: `${process.env.SERVER_API}/payment/ipn`,\n        shipping_method: \"Courier\",\n        product_name: planDetails.plan,\n        product_category: \"Electronic\",\n        product_profile: \"general\",\n        cus_name: \"Customer Name\",\n        cus_email: planDetails.user_email,\n        cus_add1: \"Dhaka\",\n        cus_add2: \"Dhaka\",\n        cus_city: \"Dhaka\",\n        cus_state: \"Dhaka\",\n        cus_postcode: \"1000\",\n        cus_country: \"Bangladesh\",\n        cus_phone: \"01711111111\",\n        cus_fax: \"01711111111\",\n        ship_name: \"Customer Name\",\n        ship_add1: \"Dhaka\",\n        ship_add2: \"Dhaka\",\n        ship_city: \"Dhaka\",\n        ship_state: \"Dhaka\",\n        ship_postcode: 1000,\n        ship_country: \"Bangladesh\"\n      };\n\n      // SSLCommerz 결제 초기화\n      const sslcz = new SSLCommerzPayment(store_id, store_passwd, is_live);\n      sslcz.init(data).then((apiResponse) => {\n        // 결제 게이트웨이 URL 가져오기\n        let GatewayPageURL = apiResponse.GatewayPageURL;\n        res.send({ url: GatewayPageURL });\n\n        // 주문 세부 정보를 데이터베이스에 삽입\n        const order = { ...planDetails, tran_id, status: 'pending'};\n        const result = ordersCollection.insertOne(order);\n      });\n\n      // 성공한 결제 처리를 위한 POST 요청\n      app.post(\"/payment/success\", async (req, res) => {\n\n        // 데이터베이스에서 주문 상태를 성공으로 업데이트\n        const result = await ordersCollection.updateOne(\n          { tran_id },\n          { $set: { status: 'success'} }\n        );\n         // 클라이언트에 결제 성공 페이지로 리디렉션\n        res.redirect(\"http://localhost:5173/payment/success\");\n      });\n\n      // 실패한 결제 처리를 위한 POST 요청\n      app.post(\"/payment/fail\", async (req, res) => {\n\n        // 데이터베이스에서 주문 상태를 실패로 업데이트\n        const result = await ordersCollection.updateOne(\n          { tran_id },\n          { $set: { status: 'failed'} }\n        );\n       // 클라이언트에 결제 실패 페이지로 리디렉션\n        res.redirect(\"http://localhost:5173/payment/fail\");\n      });\n\n      // 취소된 결제 처리를 위한 POST 요청\n      app.post(\"/payment/cancel\", async (req, res) => {\n\n        // 데이터베이스에서 주문 상태를 취소됨으로 업데이트\n        const result = await ordersCollection.updateOne(\n          { tran_id },\n          { $set: { status: 'canceled'} }\n        );\n        // 클라이언트에 결제 취소 페이지로 리디렉션\n        res.redirect(\"http://localhost:5173/payment/cancel\");\n      });\n\n      // IPN(즉시 결제 알림) 처리를 위한 POST 요청\n      app.post(\"/payment/ipn\", async (req, res) => {\n\n        // IPN 알림에 따라 데이터베이스에서 주문 상태 업데이트\n        const result = await ordersCollection.updateOne(\n          { tran_id },\n          { $set: { status: status === \"VALID\" } }\n        );\n        res.send({ message: \"IPN received\" });\n      });\n    });\n  } finally {\n    // 서버가 계속 실행되도록 보장\n  }\n};\n\n// 서버 실행\nrun().catch(console.dir);\n\n// 서버 실행 상태 확인을 위한 간단한 루트\napp.get('/', async (req, res) => {\n  res.send({ server_status: \"Running\" });\n});\n\n// Express 서버 시작\napp.listen(port, () => {\n  console.log(`서버가 ${port} 포트에서 실행 중입니다.`);\n});\n```\n\n<div class=\"content-ad\"></div>\n\n프론트엔드에서 지불 프로세스를 트리거하기 위해 아래의 코드 스니펫을 사용할 수 있어요. 이 코드는 POST 요청을 /plans 엔드포인트로 보내고, 사용자를 SSLCommerz 지불 페이지로 리디렉션해요.\n\n```js\nconst handlePlans = async () => {\n  const { data } = await axios.post('/plans', {\n    user_email: user.email,\n    plan: plan,\n    price: price,\n    purchase_date: purchaseDate,\n    expiration_date: expirationDate,\n    currency: 'BDT',\n    payment_method: 'SSLCOMMERZ'\n  });\n  // 서버로부터 받은 URL로 리디렉션하기\n  window.location.replace(data.url);\n};\n```\n\n# 설명\n\n- handlePlans 함수: 해당 함수는 필요한 플랜 세부 정보와 함께 /plans 엔드포인트로 POST 요청을 보냅니다.\n- 리디렉션: 응답을 받은 후, 사용자는 window.location.replace를 사용하여 SSLCommerz 지불 페이지로 리디렉션됩니다.\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n이 블로그 포스트에서 우리는 SSLCommerz 결제 게이트웨이를 Node.js 어플리케이션에 성공적으로 통합하고 데이터베이스 작업에 대해 직접 MongoDB를 사용했습니다. 이 통합을 통해 안전하게 결제를 처리하고 데이터베이스를 업데이트할 수 있습니다.\n\n# 주요 포인트\n\n- SSLCommerz 설정: SSLCommerz와 상점 ID 및 비밀번호를 획득하기 위해 상인 계정을 사용합니다.\n- 환경 변수: 환경 변수에 자격 증명을 안전하게 저장합니다.\n- MongoDB 작업: 주문 추적 및 사용자 플랜 업데이트를 위해 데이터베이스 작업에 MongoDB를 사용합니다.\n\n<div class=\"content-ad\"></div>\n\n이 단계를 따라하면 Node.js 애플리케이션에 견고하고 안전한 결제 처리 시스템을 설정할 수 있어요. 코딩을 즐기세요!","ogImage":{"url":"/assets/img/2024-06-20-IntegratingSSLCOMMERZPaymentGatewayinNodejs_0.png"},"coverImage":"/assets/img/2024-06-20-IntegratingSSLCOMMERZPaymentGatewayinNodejs_0.png","tag":["Tech"],"readingTime":8},{"title":"AWS EC2에 수동으로 Nextjs 앱을 배포하는 방법 단계별 안내","description":"","date":"2024-06-20 04:31","slug":"2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide","content":"\n\n소개\n\n웹 개발의 끊임없이 진화하는 풍경에서 Next.js와 같은 현대적인 프레임워크가 사용자 인터페이스를 구축하는 방법을 혁신했습니다. Next.js는 React 프레임워크로, 서버 렌더링 및 정적으로 생성된 React 애플리케이션을 구축하는데 원활한 경험을 제공합니다. 성능, SEO 및 사용자 경험을 향상시킬 수 있는 능력은 개발자들에게 인기 있는 선택지입니다. 이 안내서에서는 Next.js 앱을 AWS EC2 인스턴스에 배포하는 과정을 안내해 드릴 것이며, 클라우드의 강력한 기능을 활용하여 애플리케이션을 전 세계에 제공할 수 있습니다.\n\nAWS 클라우드에서 Next.js 배포의 장점\n\n배포 프로세스에 들어가기 전에, AWS 클라우드에서 Next.js 앱을 호스팅하는 주요 이점을 강조해 보겠습니다:\n\n<div class=\"content-ad\"></div>\n\n- 확장성: AWS는 수요에 따라 EC2 인스턴스를 확장할 수 있는 유연성을 제공합니다. 이는 당신의 Next.js 앱이 성능을 희생하지 않고 트래픽 증가를 처리할 수 있음을 의미합니다.\n- 신뢰성: AWS는 SLA(서비스 레벨 계약)로 높은 신뢰성의 인프라를 제공하여 사용자가 필요로 할 때 응용 프로그램이 이용 가능하고 운영 중인지를 보장합니다.\n- 글로벌 네트워크: AWS에 배포하면 전 세계의 데이터 센터를 선택할 수 있어 지리적으로 다른 위치의 사용자에게 더 빠른 경험을 제공하고 지연 시간을 줄일 수 있습니다.\n- 보안: AWS는 방화벽, 암호화 및 아이디어 관리를 포함한 견고한 보안 조치를 제공하여 Next.js 앱과 사용자 데이터를 잘 보호합니다.\n- 비용 효율성: AWS EC2 인스턴스는 선택한 인스턴스 유형을 선택하고 필요에 따라 리소스를 확장함으로써 비용을 제어할 수 있는 요금 체계를 제공합니다.\n\nAWS EC2에 Next.js 앱을 배포하는 단계별 안내서\n\n이제 배포 과정에 대해 살펴봅시다. 원활한 경험을 보장하기 위해 관리 가능한 단계로 나누어 설명하겠습니다:\n\n# 전제 조건\n\n<div class=\"content-ad\"></div>\n\n- Github 계정\n- AWS 계정\n- Next.js 웹 애플리케이션\n\n단계 1: AWS 계정 설정하기\n\n- AWS Management Console에 로그인하거나 계정이 없는 경우 새로 만드세요.\n- 인스턴스를 생성하고 관리하기 위해 EC2 대시보드로 이동하세요.\n\n단계 2: EC2 인스턴스 시작하기\n\n<div class=\"content-ad\"></div>\n\n아마존 관리 콘솔에 로그인한 후 EC2 대시보드를 열고 인스턴스 시작 드롭다운 목록을 클릭한 후 아래 그림과 같이 '인스턴스 시작'을 클릭하세요:\n\n![Launch Instance](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_0.png)\n\n인스턴스 시작 창이 열리면 EC2 인스턴스의 이름을 입력해주세요:\n\n![Provide EC2 Instance Name](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_1.png)\n\n<div class=\"content-ad\"></div>\n\n이 데모에서는 무료 티어 자격이 있는 Ubuntu 22.04 LTS를 선택할 것입니다.\n\n![이미지](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_2.png)\n\n인스턴스 유형을 선택하세요. 여기서는 머신 유형, vCPU 수 및 원하는 메모리를 선택할 수 있습니다. 무료 티어 자격이 있는 t2.micro를 선택하세요.\n\n![이미지](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_3.png)\n\n<div class=\"content-ad\"></div>\n\n이 데모에서는 이미 존재하는 키페어를 선택할 것입니다. 키 쌍이 없는 경우에는 새로운 키페어를 만들 수 있습니다:\n\n![키페어 선택](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_4.png)\n\n이제 네트워크 설정에서 기본 VPC를 선택하고 공인 IP 자동 할당을 활성화하세요. 본 데모에서는 기존 보안 그룹을 선택하고, Devops-SG의 인바운드 규칙 아래에 HTTP 및 HTTPS 포트가 열려 있는지 확인할 것입니다. 진행하려면 규칙을 저장하세요.\n\n![보안 그룹 설정](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_5.png)\n\n<div class=\"content-ad\"></div>\n\n나머지 설정은 기본값으로 유지하고 \"인스턴스 시작\"을 클릭해주세요.\n\n![이미지](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_6.png)\n\n다음 화면에서 EC2 인스턴스가 성공적으로 생성되었다는 성공 메시지를 볼 수 있습니다. \"인스턴스에 연결\" 버튼을 클릭해주세요:\n\n![이미지](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_7.png)\n\n<div class=\"content-ad\"></div>\n\n이제 인스턴스 연결 마법사가 열립니다. SSH 클라이언트 탭으로 이동하고 제공된 chmod 및 SSH 명령을 복사하세요:\n\n![이미지](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_8.png)\n\n로컬 머신에서 SSH 클라이언트를 열어서 EC2 인스턴스의 공용 IP를 입력하여 pem 키를 추가하면 EC2 머신에 액세스할 수 있습니다.\n\n단계 3: EC2 인스턴스를 준비하고 다른 종속성 설치하기\n\n<div class=\"content-ad\"></div>\n\n시스템 패키지를 업데이트하세요: 최신 업데이트를 적용하려면 sudo apt update를 실행하십시오.\n\n![이미지](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_9.png)\n\nNode.js와 npm을 설치하세요. 이 튜토리얼에서 사용하는 Node.js 버전은 16 LTS입니다. 아래 명령어를 실행하세요:\n\n```js\ncurl -sL https://deb.nodesource.com/setup_16.x | sudo -E bash -\nsudo apt-get install -y nodejs\nnode -v\n```\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_10.png\" />\n\n가장 최신 버전의 NPM이 설치되어 있는지 확인하세요:\n\n```js\nsudo npm install -g npm@latest\nnpm -v\n```\n\n<img src=\"/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_11.png\" />\n\n<div class=\"content-ad\"></div>\n\nStep 4: GitHub에서 Nextjs 앱을 클론하세요.\n\n이 데모에서는 GitHub에서 공개된 Nextjs 프로젝트를 사용할 것입니다. EC2 인스턴스에서 해당 저장소를 클론하세요.\n\n```js\nhttps://github.com/warengonzaga/sample-nextjs-app.git\n```\n\n<img src=\"/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_12.png\" />\n\n<div class=\"content-ad\"></div>\n\n**단계 5: npm 설치**\n\n프로젝트 디렉토리/폴더로 이동하고, Next.js 웹 애플리케이션을 실행하는 데 필요한 종속성을 설치하기 위해 아래 명령어를 실행하세요.\n\n![이미지](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_13.png)\n\n**단계 6: npm 빌드**\n\n<div class=\"content-ad\"></div>\n\n프로덕션 단계에 애플리케이션을 준비하려면 자바스크립트 파일을 번들로 묶어야합니다. 이 작업은 다음 명령어를 실행하여 Next.js에서 처리됩니다:\n\nnpm run build 명령어의 출력은 참고용으로 제공됩니다.\n\n```js\nubuntu@ip-172-31-36-85:~/sample-nextjs-app$ npm run build\n\n> sample-next-app@0.1.0 build\n> next build\n\ninfo  - SWC minify release candidate enabled. https://nextjs.link/swcmin\n주의: Next.js는 이제 완전히 익명의 텔레메트리 데이터를 수집합니다. \n이 정보는 Next.js의 로드맵을 구성하고 기능을 우선 순위에 따라 결정하는 데 사용됩니다. \n이 익명의 프로그램에 참여하고 싶지 않다면 해당 URL을 방문하여 옵트아웃하는 방법을 비롯한 자세한 정보를 확인할 수 있습니다.\nhttps://nextjs.org/telemetry\n\ninfo  - Linting and checking validity of types\nBrowserslist: caniuse-lite is outdated. Please run:\n  npx browserslist@latest --update-db\n  Why you should do it regularly: https://github.com/browserslist/browserslist#browsers-data-updating\nBrowserslist: caniuse-lite is outdated. Please run:\n  npx browserslist@latest --update-db\n  Why you should do it regularly: https://github.com/browserslist/browserslist#browsers-data-updating\ninfo  - Creating an optimized production build\ninfo  - Compiled successfully\ninfo  - Collecting page data\ninfo  - Generating static pages (3/3)\ninfo  - Finalizing page optimization\n\nRoute (pages)                              Size     First Load JS\n┌ ○ /                                      689 B          78.6 kB\n├   └ css/ae0e3e027412e072.css             707 B\n├   /_app                                  0 B            77.9 kB\n├ ○ /404                                   186 B          78.1 kB\n└ λ /api/hello                             0 B            77.9 kB\n+ First Load JS shared by all              78.1 kB\n  ├ chunks/framework-db825bd0b4ae01ef.js   45.7 kB\n  ├ chunks/main-3123a443c688934f.js        30.9 kB\n  ├ chunks/pages/_app-0e6b46beaaa55ac1.js  498 B\n  ├ chunks/webpack-7ee66019f7f6d30f.js     755 B\n  └ css/ab44ce7add5c3d11.css               247 B\n\nλ  (서버)  서버 측에서 렌더링됩니다 (getInitialProps 또는 getServerSideProps 사용)\n○  (정적)  자동으로 정적 HTML로 렌더링됩니다 (초기 프로퍼티를 사용하지 않음)\n```\n\n6단계: PM2 설치\n\n<div class=\"content-ad\"></div>\n\nNext.js 프로세스를 처리하고 터미널을 닫아도 계속해서 백그라운드에서 실행되도록 하는 솔루션이 필요합니다. 이 요구사항을 충족시키기 위해 PM2가 프로세스 관리에 이상적인 도구로 사용됩니다.\n\n- 아래 명령어를 사용하여 PM2를 설치합니다:\n\n```js\nsudo npm install pm2 -g\n```\n\n- PM2 설치를 확인하려면 다음 명령어 pm2를 실행하고, 아래 스크린샷과 유사한 응답을 받게 됩니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_14.png\" />\n\n7단계: Next.js를 PM2를 사용하여 백그라운드에서 실행하기\n\n터미널을 닫은 후에도 Next.js 애플리케이션을 실행, 중지 및 재시작해야 합니다. 이를 PM2 도구를 사용하여 달성할 수 있습니다.\n\n다음 코드를 실행하여 PM2로 Next.js를 실행하세요:\n\n<div class=\"content-ad\"></div>\n\n```js\npm2 start npm --name nextjs-app -- run start -- -p 3000\n```\n\n![Screenshot](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_15.png)\n\n아래 명령어를 사용하여 nextjs-app의 상태도 확인할 수 있습니다:\n\n```js\npm2 list nextjs-app\n```\n\n<div class=\"content-ad\"></div>\n\n\n![Next.js app deployment](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_16.png)\n\nNext.js 애플리케이션의 기능을 확인하려면, 웹 브라우저에 EC2 인스턴스의 공용 IP와 포트 번호 3000을 입력하세요. 예를 들어, 다음 형식을 사용하세요: 0.0.0.0:3000\n\n![Next.js app deployment](/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_17.png)\n\nnextjs-app 프로세스를 중지하려면, 아래 명령어를 사용하세요:\n\n\n<div class=\"content-ad\"></div>\n\n```js\npm2 stop nextjs-app\n```\n\n<img src=\"/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_18.png\" />\n\n다음 명령을 사용하여 nextjs-app 프로세스를 시작합니다:\n\n```js\npm2 start nextjs-app\n```\n\n<div class=\"content-ad\"></div>\n\n다음js-app 프로세스를 다시 시작하려면:\n\n```js\npm2 restart nextjs-app\n```\n\n다음js-app 프로세스를 삭제하려면:\n\n```js\npm2 delete nextjs-app\n```\n\n<div class=\"content-ad\"></div>\n\n# 결론\n\n마무리하면, 이 블로그에서는 수동 단계를 이용해 AWS EC2 인스턴스에 Next.js 앱을 성공적으로 배포하는 과정을 보여주었습니다. 이러한 단계들은 애플리케이션 배포를 위한 견고한 기반을 제공하지만, 컨테이너화와 지속적 통합/지속적 배포(CI/CD) 파이프라인을 통해 더욱 효율적이고 간소화된 접근 방식을 통해 더 많은 것을 이룰 수 있다는 점을 알아두는 것이 중요합니다.\n\n다가오는 포스트들에서는 컨테이너화의 세계에 대해 자세히 다루고, Docker와 Kubernetes 같은 도구 및 CI/CD 파이프라인을 활용하여 배포 프로세스를 자동화하고 확장 가능성을 향상시키며, Next.js 애플리케이션 관리를 더욱 최적화하는 방법을 살펴볼 것입니다. 이러한 고급 배포 전략에 대한 논의를 기대해 주세요.\n\n만약 이 블로그 포스트가 도움이 되었고 유익하게 느껴진다면, 박수로 감사를 표현해 주시길 초대합니다! 여러분의 지원은 저에게 지속적으로 가치 있는 콘텐츠를 공유할 동기를 부여합니다. 팔로우 버튼도 꼭 눌러주시고, 계속해서 연결되어 다가오는 포스트에 대한 업데이트를 받아보세요. 함께 이 여정에 참여하고 데브옵스 세계에서 더욱 흥미로운 통찰을 탐구해봅시다. 여러분의 참여를 진심으로 사랑합니다! 👏🔗","ogImage":{"url":"/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_0.png"},"coverImage":"/assets/img/2024-06-20-DeployingaNextjsAppmanuallyonAWSEC2AStep-by-StepGuide_0.png","tag":["Tech"],"readingTime":9},{"title":"API 버전 관리 이해하기 왜 중요한 것인지","description":"","date":"2024-06-20 04:28","slug":"2024-06-20-UnderstandingAPIVersioningWhyItsImportant","content":"\n\nAPI(응용 프로그램 프로그래밍 인터페이스)는 현대 소프트웨어 개발의 중추로, 다른 시스템이 통신하고 데이터를 교환할 수 있게 합니다.\n\n소프트웨어가 발전함에 따라 API에 대한 변경은 불가피합니다. 이러한 변경은 새로운 기능을 도입하거나 성능을 개선하거나 버그를 수정할 수 있습니다.\n\n하지만, API의 변경은 API의 이전 버전에 의존하는 사용자들에게 기존 기능을 망가뜨릴 수도 있습니다. 이 때 API 버전 관리가 필요합니다.\n\n이 글에서는 API 버전 관리가 무엇인지, 왜 중요한지, 언제 사용해야 하는지, 그리고 Node.js를 사용한 실용적인 예제에 대해 탐구해 보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n# API 버전 관리란 무엇인가요?\n\nAPI 버전 관리는 API의 변경 사항을 관리하기 위해 API의 다른 상태에 다른 버전을 할당하는 것을 말합니다.\n\n![image](/assets/img/2024-06-20-UnderstandingAPIVersioningWhyItsImportant_0.png)\n\n이를 통해 개발자는 특정 API 버전에 의존하는 기존 사용자를 방해하지 않고 업데이트와 개선 사항을 적용할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# API 버전 관리의 중요성\n\n다음은 API 버전 관리의 중요성을 강조하는 요점입니다.\n\n- 역호환성: API 버전 관리는 API의 변경 사항이 기존 응용 프로그램을 손상시키지 않도록 보장합니다. 클라이언트는 의존하는 버전을 계속 사용할 수 있으며, 동시에 새로운 클라이언트는 최신 기능을 활용할 수 있습니다.\n- 부드러운 전환: 이는 한 버전에서 다른 버전으로의 부드러운 전환을 허용하며, 개발자들이 코드를 새 버전과 호환되도록 업데이트하는 데 충분한 시간을 제공합니다.\n- 유지보수 향상: 버전 관리는 코드베이스를 유지하고 조직화하는 데 도움이 되어 API의 다양한 반복본을 관리하기가 쉬워집니다.\n- 명확한 의사 소통: 사용자들에게 그들이 사용 중인 버전과 향후 버전에서 기대할 수 있는 변경 사항에 대해 명확히 전달합니다.\n\n# API 버전 관리의 사용 시기\n\n<div class=\"content-ad\"></div>\n\n다음은 API 버전 관련 시기를 강조한 내용입니다.\n\n- 중단 변경사항: 엔드포인트를 제거하거나 응답 형식을 변경하거나 기존 엔드포인트의 동작을 변경하는 등과 같이 하위 호환성이 없는 변경 사항을 도입할 때.\n- 중요한 업데이트: 중요한 업데이트로, 상당한 새 기능을 추가하거나 기존 기능을 크게 변경하는 경우.\n- 사용 중단: 더 오래된 기능을 단계적으로 폐기할 계획이지만 이전 기능에 대한 지원을 제공해야 할 때.\n\n# API 버전 관리에 사용하지 말아야 할 때\n\n다음은 API 버전 관리를 사용하지 말아야 하는 경우를 강조한 내용입니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-UnderstandingAPIVersioningWhyItsImportant_1.png\" />\n\n- 작은 변경 사항: 작은, 하위 호환성 업데이트에는 새 엔드포인트 추가, 기존 엔드포인트에 비파괴적인 변경, 또는 버그 수정이 포함됩니다.\n- 내부 API: 조직 내부에서 사용되는 API로, 모든 클라이언트를 제어하고 API 변경 사항과 동시에 업데이트되도록 보장할 수 있는 경우입니다.\n\n# 다른 버전의 API로 클라이언트 요청\n\n<img src=\"/assets/img/2024-06-20-UnderstandingAPIVersioningWhyItsImportant_2.png\" />\n\n<div class=\"content-ad\"></div>\n\n- 클라이언트 요청: 클라이언트는 API에 요청을 보냅니다.\n- API 게이트웨이: API 게이트웨이는 이러한 요청을 받아들이고 요청 URL 또는 헤더에 지정된 버전에 따라 적절한 API 버전으로 라우팅합니다.\n- API 버전: API 게이트웨이는 요청을 적절한 API 버전(e.g., v1, v2 또는 v3)으로 전달합니다.\n- 응답: API는 요청을 처리하고 응답을 API 게이트웨이에 다시 보내며, 이후 게이트웨이가 클라이언트에게 전달합니다.\n\n# API 게이트웨이를 통한 API 버전 관리 구현\n\n위의 흐름을 설명하기 위해 URL을 기반으로 서로 다른 API 버전으로 요청을 라우팅하는 간단한 Node.js API 게이트웨이를 생성할 수 있습니다.\n\n## 단계 1: 프로젝트 설정하기\n\n<div class=\"content-ad\"></div>\n\n우선 새로운 Node.js 프로젝트를 만들고 Express를 설치하세요.\n\n```bash\nmkdir api-gateway-example\ncd api-gateway-example\nnpm init -y\nnpm install express\n```\n\n## 단계 2: 서버 및 API 게이트웨이 생성\n\ngateway.js라는 파일을 만들고 API 게이트웨이로 작동하는 기본 Express 서버를 설정하세요.\n\n<div class=\"content-ad\"></div>\n\n```javascript\nconst express = require('express');\nconst app = express();\nconst port = 3000;\n\n// API v1 route\napp.use('/api/v1', (req, res, next) => {\n    // Forward the request to the API v1 server\n    // Assuming the API v1 server is running on port 3001\n    const proxy = require('http-proxy').createProxyServer();\n    proxy.web(req, res, { target: 'http://localhost:3001' });\n});\n\n// API v2 route\napp.use('/api/v2', (req, res, next) => {\n    // Forward the request to the API v2 server\n    // Assuming the API v2 server is running on port 3002\n    const proxy = require('http-proxy').createProxyServer();\n    proxy.web(req, res, { target: 'http://localhost:3002' });\n});\n\napp.listen(port, () => {\n    console.log(`API Gateway is now running at http://localhost:${port}/`);\n});\n```\n\n## Step 3: API Version Creation\n\nCreate separate API servers for v1 and v2.\n\nStep 3.1: API v1 (port 3001):\n\n<div class=\"content-ad\"></div>\n\n```js\n// api-v1.js\nconst express = require('express');\nconst app = express();\nconst port = 3001;\n\napp.get('/users', (req, res) => {\n    res.json([\n        { id: 1, name: 'John Doe' },\n        { id: 2, name: 'Jane Smith' }\n    ]);\n});\n\napp.listen(port, () => {\n    console.log(`API v1 running at http://localhost:${port}/`);\n});\n```\n\n단계 3.2: API v2 (포트 3002):\n\n```js\n// api-v2.js\nconst express = require('express');\nconst app = express();\nconst port = 3002;\n\napp.get('/users', (req, res) => {\n    res.json([\n        { userId: 1, fullName: 'John Doe' },\n        { userId: 2, fullName: 'Jane Smith' },\n        { userId: 3, fullName: 'Jim Beam' }\n    ]);\n});\n\napp.listen(port, () => {\n    console.log(`API v2 running at http://localhost:${port}/`);\n});\n```\n\n## 단계 4: 서버 실행하기\n\n\n<div class=\"content-ad\"></div>\n\nAPI 게이트웨이와 두 개의 API 버전을 시작하세요:\n\n```js\nnode gateway.js\nnode api-v1.js\nnode api-v2.js\n```\n\n## 단계 5: 설정 테스트\n\n다른 버전에 요청을 보내어 API 게이트웨이를 테스트하세요.\n\n<div class=\"content-ad\"></div>\n\n\ncurl http://localhost:3000/api/v1/users\ncurl http://localhost:3000/api/v2/users\n\n\nAPI 게이트웨이 및 버전별 API를 Node.js에서 구현하여 클라이언트 요청을 적절한 API 버전으로 라우팅하고 관리할 수 있습니다.\n\n이 설정은 하위 호환성을 보장하고 API의 다른 버전 간에 원확한 전환을 가능하게 합니다.\n\n# 결론\n\n\n<div class=\"content-ad\"></div>\n\nAPI 버전 관리는 API 설계 및 개발의 중요한 측면이며, 기존 기능을 손상시키지 않고 변경 사항을 도입할 수 있도록 개발자들을 가능하게 합니다.\n\nAPI의 다양한 버전을 신중하게 관리함으로써 사용자들에게 원활한 전환을 보장하고 역호환성을 유지할 수 있습니다.\n\n제 글을 끝까지 읽어주셔서 진심으로 감사드립니다!\n\n도움이 되었거나 흥미로웠다면 박수 버튼을 클릭하여 응원해주시겠어요? 🎉\n\n<div class=\"content-ad\"></div>\n\n\n![image](https://miro.medium.com/v2/resize:fit:1400/0*4KabDY9ZImT3QdwF.gif)\n\nAnd hey, don’t miss out on more insightful content — hit that follow button to stay updated!\n\nGet email alerts for my latest Medium posts! Click here.\n\nLet’s learn and grow together. Happy Coding! 👏\n","ogImage":{"url":"/assets/img/2024-06-20-UnderstandingAPIVersioningWhyItsImportant_0.png"},"coverImage":"/assets/img/2024-06-20-UnderstandingAPIVersioningWhyItsImportant_0.png","tag":["Tech"],"readingTime":6},{"title":"IPC 만들기가 Execa 92로 쉬워졌어요","description":"","date":"2024-06-20 04:27","slug":"2024-06-20-IPCmadeeasywithExeca92","content":"\n\n<img src=\"/assets/img/2024-06-20-IPCmadeeasywithExeca92_0.png\" />\n\n# 프로세스 간 복잡성\n\n당신의 운영 체제가 어떤 기술적 경이로운 것들로 구축되어 있는지 잊기 쉽습니다. 터미널에서 다음 명령어를 입력하는 것만으로도 여러 추상화 계층이 관여됩니다.\n\n```js\nnpx open-cli \"https://www.youtube.com/watch?v=dQw4w9WgXcQ\"\n```\n\n<div class=\"content-ad\"></div>\n\nnpx는 호출한 셸과 별도의 프로세스에서 실행되며, 그런 다음 open-cli를 위해 또 다른 서브프로세스를 생성합니다. 각 프로세스에는 실행 파일과 자원(메모리, CPU 상태, 파일 디스크립터 등)이 있습니다.\n\n프로세스는 서로 격리되어 있습니다. 이는 보안상의 이유로 좋은면도 있지만, 이로 인해 프로세스 간 통신(IPC)이 필요합니다.\n\n가장 일반적인 IPC 메커니즘은: 인수, 종료 코드, 환경 변수, 시그널, 표준 스트림(stdin, stdout, stderr), 파일 디스크립터, 파일, 공유 메모리, 그리고 네트워크 호출입니다.\n\n하지만 이러한 해결책들은 종종 너무 한정된 경우나 너무 복잡한 경우가 많습니다. 방금 출시된 Execa 9.2는 두 프로세스 모두 Node.js를 사용할 때 IPC를 간단하게 만드는 것을 목표로 합니다.\n\n<div class=\"content-ad\"></div>\n\n# 프로세스에 어떤 것이라도 전달하기\n\n대부분의 IPC 방법을 사용하면 문자열을 보내는 것이 간단합니다. 그러나 구조화된 데이터를 전송하려면 직렬화(serializing)하고 파싱(parsing)해야 합니다. 예를 들어, 일반 객체는 JSON을 사용할 수 있습니다.\n\nExeca에서는 ipcInput 옵션이 대부분의 유형을 자동으로 변환하므로 수동으로 직렬화하거나 파싱할 필요가 없습니다.\n\n이것은 구조화된 복제 알고리즘을 따릅니다. 요약하면, 거의 모든 JavaScript 값이 허용되지만 함수(클래스 인스턴스 메서드를 포함한)가 두드러진 예외입니다.\n\n<div class=\"content-ad\"></div>\n\n일반적으로 인수와 환경 변수의 크기 제한은 1MB 미만인 반면, ipcInput 옵션은 최대 2GB까지 처리할 수 있습니다.\n\n```js\n// main.js\nimport {execaNode} from 'execa';\n\nconst ipcInput = [\n  {\n    task: 'lint',\n    ignore: /test\\.js/,\n  },\n  {\n    task: 'copy',\n    files: new Set([\n      'main.js',\n      'index.js',\n    ]),\n  },\n];\nawait execaNode({ipcInput})`build.js`;\n```\n\n```js\n// build.js\nimport {getOneMessage} from 'execa';\n\nconst ipcInput = await getOneMessage();\nfor (const {task, ignore, files} of ipcInput) {\n  await runTask(task, {ignore, files});\n}\n```\n\n# 프로세스로부터 아무 것이나 반환\n\n<div class=\"content-ad\"></div>\n\n프로세스의 출력물에도 동일한 문제가 있습니다. stdout와 stderr은 어떤 내용이든 출력할 수 있지만 호출자는 이를 구문 분석해야 합니다.\n\nExeca를 사용하면 프로세스가 sendMessage(message)를 호출하여 거의 모든 데이터를 반환할 수 있습니다. 부모 프로세스는 결과.ipcOutput 배열을 사용하여 그대로 가져옵니다.\n\n```js\n// main.js\nimport {execaNode} from 'execa';\n\nconst {ipcOutput} = await execaNode`build.js`;\nconsole.log(ipcOutput[0]); // {kind: 'start', timestamp: date}\nconsole.log(ipcOutput[1]); // {kind: 'stop', timestamp: date}\n```\n\n```js\n// build.js\nimport {sendMessage} from 'execa';\n\nawait sendMessage({kind: 'start', timestamp: new Date()});\nawait runBuild();\nawait sendMessage({kind: 'stop', timestamp: new Date()});\n```\n\n<div class=\"content-ad\"></div>\n\n# 메시지 교환\n\n만약 프로세스가 실행 중일 때 출력을 검색해야 하는 경우 어떻게 할까요? 진행률 표시를 위해 예를 들면요? 또는 이미 시작된 프로세스 이후에 추가 입력을 제공해야 할 때는 어떻게 해야 할까요?\n\n일반적으로 이는 stdin, stdout, stderr를 스트리밍하거나 네트워크 호출을 수행하여 해결됩니다. 성능 조정 및 잠재적 I/O 오류 처리를 다룰 때 특히 어려울 수 있습니다.\n\nExeca는 메시지를 교환하기 위한 간단한 메서드 세트를 제공합니다: sendMessage(message)와 getOneMessage().\n\n<div class=\"content-ad\"></div>\n\n```js\n// parent.js\nimport {execaNode} from 'execa';\n\nconst subprocess = execaNode`child.js`;\nawait subprocess.sendMessage('Hello from parent');\nconst message = await subprocess.getOneMessage();\nconsole.log(message); // 'Hello from child'\nawait subprocess;\n```   \n\n```js\n// child.js\nimport {getOneMessage, sendMessage} from 'execa';\n\nconst message = await getOneMessage(); // 'Hello from parent'\nconst newMessage = message.replace('parent', 'child'); // 'Hello from child'\nawait sendMessage(newMessage);\n```\n\n# 메시지 수신\n\n또한 한 프로세스(또는 양쪽 모두)가 상대방에서 오는 요청을 처리하는 클라이언트/서버 모델을 따를 수 있습니다. 이것은 getEachMessage()를 사용하여 모든 수신 메시지를 수신함으로써 구현됩니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n// parent.js\nimport {execaNode} from 'execa';\n\nconst subprocess = execaNode`child.js`;\nawait subprocess.sendMessage(0);\n\n// This loop ends when the subprocess exits.\n// It throws if the subprocess fails.\nfor await (const message of subprocess.getEachMessage()) {\n  console.log(message); // 1, 3, 5, 7, 9\n  await subprocess.sendMessage(message + 1);\n}\n```\n\n```js\n// child.js\nimport {sendMessage, getEachMessage} from 'execa';\n\n// The subprocess exits when hitting `break`\nfor await (const message of getEachMessage()) {\n  if (message === 10) {\n    break;\n  }\n\n  console.log(message); // 0, 2, 4, 6, 8\n  await sendMessage(message + 1);\n}\n```\n\n# 메시지 필터링\n\n`getOneMessage()` 메서드에는 특정 메시지를 선택하는 필터 옵션이 있습니다. 이는 서로 다른 유형의 이벤트를 수신할 때 유용합니다.\n\n\n<div class=\"content-ad\"></div>\n\n```js\nimport {execaNode} from 'execa';\n\nconst subprocess = execaNode`build.js`;\nconst stopMessage = await subprocess.getOneMessage({\n  filter: message => message.type === 'stop',\n});\n```\n\n# 보장된 수신\n\nIPC는 본질적으로 상태를 가지며 시간에 민감하기 때문에 미묘한 레이스 컨디션 버그를 만들어낼 수 있습니다. 대부분의 네트워크 프로토콜은 메시지를 보낼 때 메시지가 제대로 수신되도록 보장하여 이를 예방합니다. 예를 들어, TCP는 ACK 번호를 사용합니다.\n\nExeca에서는 strict 옵션이 그 목적을 충족시킵니다. 활성화된 경우, 다른 프로세스가 메시지를 제대로 수신하는 것을 보장합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n// main.js\nimport {execaNode} from 'execa';\n\nconst subprocess = execaNode`build.js`;\n// `build` 메시지를 받음\nawait subprocess.sendMessage('build', {strict: true});\n// `lint` 메시지를 받지 못해 예외가 발생함\nawait subprocess.sendMessage('lint', {strict: true});\nawait subprocess; \n```\n\n```js\n// build.js\nimport {getOneMessage} from 'execa';\n\n// `build` 메시지를 받음\nconst task = await getOneMessage();\n// `runTask()`이 진행 중일 때 `lint` 메시지가 전송됨\n// 따라서 `lint` 메시지는 버려짐\nawait runTask(task);\n\n// `lint` 메시지를 받지 않음\n// `strict`이 없으면 영원히 대기할 것\nconst secondTask = await getOneMessage();\nawait runTask(secondTask);\n```\n\n# 프로세스를 멈추지 않기\n\n메시지를 보낸 쪽에서 보낸 모든 메시지가 다른 쪽에서 받도록 하려면, 메시지를 수신할 때 프로세스를 유지합니다.\n\n\n<div class=\"content-ad\"></div>\n\n그러나 메시지가 전송되었는지 여부를 확신할 수 없을 때는 이 방법이 잘 작동하지 않을 수 있습니다. 그렇게 되면 프로세스가 영원히 멈춰있는 상황이 발생할 수 있습니다. 이 문제는 reference: false 옵션을 사용하여 해결할 수 있습니다.\n\n```js\nimport {getEachMessage} from 'execa';\n\n// {type: 'gracefulExit'}가 가끔 수신되지만 항상 그렇지는 않습니다\nfor await (const message of getEachMessage({reference: false})) {\n  if (message.type === 'gracefulExit') {\n    gracefulExit();\n  }\n}\n```\n\n# 디버깅\n\n프로세스가 격리되어 있기 때문에 디버깅하기 어려운 블랙 박스가 될 수 있습니다. 이를 해결하기 위해 Execa 프로세스에서 보낸 모든 IPC 메시지는 오류 메시지와 상세 로그 모두 자동으로 출력됩니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n// build.js\nimport {execaNode} from 'execa';\n\nawait execaNode`npm run build`;\n```\n\n```js\n# 자세한 모드로 실행\n# 각 * 심볼이 있는 행은 IPC 메시지입니다\n\n$ NODE_DEBUG=execa node build.js\n[00:57:44.658] [0] $ npm run build\n[00:57:44.670] [0]   응용프로그램 빌드 중...\n[00:57:44.692] [0] * {name: 'start'}\n[00:57:44.701] [0] * {name: 'entrypoint', value: 'mispelled_index.js'} \n[00:57:44.740] [0]   오류: 입구점이 잘못되었습니다.\n[00:57:44.747] [0] ✘ 명령은 종료 코드 1로 실패했습니다: npm run build\n[00:57:44.747] [0] ✘ (89ms에 완료됨)\n```\n\n# 우아한 종료\n\n프로세스를 부드럽게 다루는 것은 쉽지 않습니다. 사실, 그들을 종료하는 것은 보통 꽤 무자비합니다. 표준 접근 방식은 SIGTERM과 같은 신호를 보내는 것입니다. 그러나 이러한 절차는 프로세스가 급작스럽게 종료되어 진행 중인 작업이 모두 종료된다는 점을 의미합니다. 이로 인해 파일 작성이 중간에 멈추거나, HTTP 요청이 멈추거나, 데이터가 손상될 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nUnix에서는 핸들러가 시그널을 가로채서 정리 작업을 실행할 수 있습니다. 하지만 윈도우에서는 작동하지 않습니다.\n\ngracefulCancel 옵션은 이 문제에 대한 크로스 플랫폼 솔루션을 제공합니다. 이는 IPC를 사용하여 프로세스와 해당 부모 프로세스 사이에서 AbortSignal을 공유합니다.\n\n```js\n// main.js\nimport {execaNode} from 'execa';\n\nconst controller = new AbortController();\nsetTimeout(() => {\n  controller.abort();\n}, 5000);\n\nconst cancelSignal = controller.signal;\nawait execaNode({cancelSignal, gracefulCancel: true})`build.js`;\n```\n\n```js\n// build.js\nimport {getCancelSignal} from 'execa';\n\nconst cancelSignal = await getCancelSignal();\nconst url = 'https://example.com/build/info';\nconst response = await fetch(url, {signal: cancelSignal});\n```\n\n<div class=\"content-ad\"></div>\n\n# 속내를 들여다보기\n\n우리는 이러한 기능들을 Node의 내장 IPC 위에 구축했습니다. 명명된 파이프는 프로세스 간 통신 채널로 사용됩니다. 메시지 페이로드는 V8로 직렬화됩니다.\n\nIPC는 고급 기능입니다. 95%의 경우, 필요하지 않을 것입니다. Execa는 이미 스크립트에서 파이핑 또는 스트리밍까지 보다 간단한 방법을 제공합니다. 그러나 더 복잡한 시나리오에서는 IPC가 시간 절약의 도구가 될 수 있습니다.","ogImage":{"url":"/assets/img/2024-06-20-IPCmadeeasywithExeca92_0.png"},"coverImage":"/assets/img/2024-06-20-IPCmadeeasywithExeca92_0.png","tag":["Tech"],"readingTime":8},{"title":"HTTPS 성능 최적화를 위한 몇 가지 방법","description":"","date":"2024-06-20 04:25","slug":"2024-06-20-SomeMethodsforOptimizingHTTPSPerformance","content":"\n\n예상대로 HTTPS 연결이 느리다고 말하는 사람들을 들어본 적이 있을 것입니다. 이 \"느림\"의 이유는 무엇일까요?\n\nHTTPS 연결은 대략 두 부분으로 나눌 수 있습니다. 연결 설정 중에 대칭 암호화 핸드셰이크와 핸드셰이크 후의 대칭 암호화 메시지 전송입니다.\n\n인기 있는 알고리즘인 AES와 ChaCha20 같은 우수한 성능을 가지고 있고, 하드웨어 최적화로 메시지 전송의 성능 오버헤드는 무시할 정도로 미미할 수 있습니다. 따라서 사람들이 \"느린 HTTPS 연결\"에 대해 이야기할 때 주로 말하는 것은 초기 연결 설정 단계입니다.\n\n<div class=\"content-ad\"></div>\n\nTCP 연결이 설정되어 있는 상태에서 실제 데이터 전송이 이루어지기 전에 HTTPS는 최대 2개의 메시지 왕복 루트 또는 2-RTT가 소요될 수 있는 TLS 핸드셰이크 단계를 추가합니다. 핸드셰이크 메시지의 네트워크 시간 외에도 다음과 같은 \"보이지 않는\" 비용이 추가로 발생합니다:\n\n- 키 교환을 위한 임시 공개-개인 키 쌍(ECDHE) 생성\n- CRL 또는 OCSP를 위해 CA에 액세스하여 인증서 확인\n- \"Pre-Master\" 비밀에 대한 비대칭 암호화 및 복호화 처리\n\n최악의 경우, 최적화 조치를 취하지 않은 경우 HTTPS 연결 설정은 HTTP보다 수백 밀리초에서 몇 초 더 오래 걸릴 수 있습니다. 이는 네트워크 및 계산 비용을 포함하여 \"HTTPS 웹 사이트 열기가 느린 것처럼 느껴질 수 있습니다.\"\n\n그러나 위에서 설명한 상황은 이미 지나간 얘기입니다. 지금은 많은 효과적인 HTTPS 최적화 방법이 사용 가능하며, 적절히 사용하면 추가 연결 시간을 수십 밀리초로 줄이거나 완전히 \"제로\"로 만들 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nTLS 핸드셰이크 과정 중 성능에 영향을 미치는 부분을 강조한 다이어그램을 만들었습니다. 이 다이어그램을 참고하여 HTTPS를 효과적으로 최적화할 수 있어요.\n\n![다이어그램](/assets/img/2024-06-20-SomeMethodsforOptimizingHTTPSPerformance_1.png)\n\n# 하드웨어 최적화\n\n컴퓨터 세계에서 \"최적화\"는 \"하드웨어 최적화\"와 \"소프트웨어 최적화\" 두 가지 유형으로 나뉩니다. 먼저 하드웨어 방법을 살펴보겠습니다.\n\n<div class=\"content-ad\"></div>\n\n하드웨어 최적화는 본질적으로 \"돈을 지출하는 것\"입니다. 그러나 돈을 쓰는 것도 기술이 필요합니다. 돈을 낭비하는 대신에 가장 중요한 곳에 투자해야 합니다.\n\nHTTPS 연결은 입출력보다는 계산 집약적입니다. 따라서 비싼 네트워크 카드, 대역폭 또는 SSD 저장 공간을 사는 것은 성능을 최적화하지 않습니다.\n\n최적화를 위해 어떤 하드웨어를 사용해야 할까요?\n\n먼저, AES 최적화가 내장된 더 빠른 CPU를 선택할 수 있습니다. 이는 핸드셰이크와 전송을 가속화할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n둘째, CPU로 부터 비대칭 암호화 및 복호화를 줄여주는 \"SSL 가속기 카드\"를 선택할 수도 있어요! \n\n하지만, \"SSL 가속기 카드\"는 소프트웨어 업그레이드가 느리고, 제한된 알고리즘을 지원하며 사용자 정의의 유연성이 부족한 등 몇 가지 단점이 있답니다.\n\n그래서 세 번째 하드웨어 가속 방법인 \"SSL 가속기 서버\"가 개발되었어요! 이 방법은 TLS 핸드셰이크 중에 암호화 및 복호화 계산을 완전히 오프로드하는 전용 서버 클러스터를 사용하여, 간단한 \"가속기 카드\"보다 훨씬 높은 성능을 제공해요!\n\n# 소프트웨어 최적화\n\n<div class=\"content-ad\"></div>\n\n그러나 CPU를 업그레이드하는 것 외에 다른 하드웨어 최적화 방법들은 돈을 쓰면 간단히 달성되지 않는 경우가 많습니다. 이것들은 어떤 개발과 적응 작업이 필요하며, 이는 매우 도전적일 수 있습니다. 예를 들어, \"가속화 서버\"의 중요한 측면 중 하나는 통신이 \"비동기적\"이어야 한다는 것이며, 그렇지 않으면 가속화는 무의미해질 수 있습니다.\n\n따라서 소프트웨어 최적화는 상대적으로 더 실현 가능하고, 비용 효율적이며, 적은 돈으로 더 많은 것을 이룰 수 있습니다.\n\n소프트웨어 최적화는 소프트웨어 업그레이드와 프로토콜 최적화 두 부분으로 나눌 수 있습니다.\n\n소프트웨어 업그레이드는 상대적으로 간단한데, 가능한 한 최신 버전의 소프트웨어로 업그레이드하는 것을 포함합니다. 예를 들어, Linux 커널을 2.x에서 4.x로, Nginx를 1.6에서 1.16로, OpenSSL을 1.0.1에서 1.1.0/1.1.1로 업그레이드하는 것 등이 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이러한 소프트웨어 업데이트는 성능 최적화와 버그 수정을 포함하므로, 만약 작업이 적극적으로 협력할 수 있다면 이 최적화를 달성하는 것은 비교적 쉬운 일입니다.\n\n그러나 많은 대규모 및 중소기업에 대해 하드웨어 및 소프트웨어 업그레이드는 어려운 문제입니다. 여러 데이터 센터에 분산된 수백 대의 다양한 모델의 기계들이 있기 때문에 하나씩 업그레이드하는 과정에는 많은 인력이 필요하며 정상적인 온라인 서비스에 영향을 미칠 위험이 큽니다.\n\n그러므로 하드웨어나 소프트웨어 업그레이드가 불가능할 때, 가장 일반적인 최적화 방법은 기존 환경 내에서 프로토콜 자체의 잠재력을 탐색하는 것입니다.\n\n# 프로토콜 최적화\n\n<div class=\"content-ad\"></div>\n\nTLS 핸드셰이크 프로세스에서 키 교환은 성능에 큰 영향을 미치는 중요한 요소입니다. 프로토콜 최적화는 핵심 키 교환 프로세스부터 시작해야 합니다.\n\n가능하다면 TLS 1.3을 사용하는 것이 좋습니다. TLS 1.3은 핸드셰이크 프로세스를 크게 간소화하여 완전한 핸드셰이크를 위해 단 하나의 왕복 시간(1-RTT)만 필요하며 보안을 향상시킵니다.\n\nTLS 1.3로 업그레이드하는 것이 아직 불가능하고 TLS 1.2를 사용해야 할 때, 핸드셰이크를 위해 선택되는 키 교환 프로토콜은 가능한 ECDHE(Elliptic Curve Diffie-Hellman Ephemeral) 알고리즘을 사용하는 것이 좋습니다. ECDHE는 연산이 빠르고 안전성이 높을 뿐만 아니라 \"False Start\"를 지원하여 핸드셰이크에 필요한 왕복 시간을 2-RTT에서 1-RTT로 줄여 TLS 1.3과 유사한 효과를 얻을 수 있습니다.\n\n게다가, 타원 곡선의 경우 고성능 곡선을 선택해야 합니다. x25519를 선호하는 선택지로 하고 P-256을 대체 옵션으로 고려해야 합니다. 대칭 암호화 알고리즘으로는 \"AES_256_GCM\"보다 약간 성능이 빠른 \"AES_128_GCM\"을 선택할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n엔진엑스에서는 \"ssl_ciphers\" 및 \"ssl_ecdh_curve\"와 같은 지시문을 사용하여 서버의 암호 스위트 및 타원 곡선을 구성할 수 있습니다. 이를 통해 선호하는 옵션을 우선순위로 설정할 수 있습니다. 예를 들어:\n\n```js\nssl_ciphers   TLS13-AES-256-GCM-SHA384:TLS13-CHACHA20-POLY1305-SHA256:EECDH+CHACHA20；\nssl_ecdh_curve              X25519:P-256;\n```\n\n# 인증서 최적화\n\n키 교환에 추가로 핸드쉐이크 과정 중에 인증서 유효성 검사도 상대적으로 시간이 많이 소요되는 작업입니다. 서버는 클라이언트에게 자체 전체 인증서 체인을 보내야 하며, 그러면 클라이언트는 각 인증서를 확인해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n여기에는 인증서 전송과 인증서 유효성 검증이 두 가지 최적화 포인트가 있습니다.\n\n서버의 인증서의 경우 RSA 인증서 대신 타원 곡선(ECDSA) 인증서를 선택할 수 있습니다. 224비트 ECC는 2048비트 RSA와 동등하며, 타원 곡선 인증서는 RSA 인증서보다 훨씬 작은 \"크기\"를 가지고 있어 대역폭을 절약하고 클라이언트의 계산 부담을 줄여 \"한 방에 두 마리 토끼를 잡는\" 효과를 얻을 수 있습니다.\n\n클라이언트 인증서 유효성 검증은 실제로 복잡한 작업입니다. 공개 키로 여러 개의 인증서 서명을 해독하고 확인하는 것 외에도, 인증서가 취소될 수 있기 때문에 클라이언트는 때로는 CA에 액세스하여 CRL 또는 OCSP 데이터를 다운로드해야 할 수도 있습니다. 이는 DNS 쿼리, 연결 설정 및 데이터 교환과 같은 일련의 네트워크 통신을 필요로 하며, 추가적인 RTT가 발생할 수 있습니다.\n\nCA에 의해 주기적으로 발급되는 CRL (인증서 폐기 목록)은 모든 폐기된 인증서의 일련 번호를 포함하고 있습니다. 이 목록을 확인하여 인증서가 유효한지 결정할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n하지만, CRL은 \"주기적\"으로 발행되는 것으로 인해 보안 위험이 있으며, 폐기된 인증서의 수가 증가할수록 목록도 커져 종종 메가바이트에 이를 정도로 커집니다. 웹사이트에 연결할 때마다 몇 메가바이트의 \"무의미한 데이터\"를 사전에 다운로드해야 한다고 상상해보세요. 이것은 간단히 말해 실용적이지 않습니다.\n\n그래서 CRL은 이제 거의 사용되지 않으며, OCSP(온라인 인증서 상태 프로토콜)가 대신하게 되었습니다. OCSP는 인증 기관에 쿼리 요청을 보내어 인증서의 유효성 상태를 얻습니다.\n\n그러나 OCSP도 추가적인 네트워크 요청 오버헤드를 발생시키고, 인증 기관 서버에 의존합니다. 인증 기관 서버가 바쁘면 응답 지연이 용납할 수 없을 수 있습니다.\n\n이 문제를 해결하기 위해 OCSP 스테이플링이라는 \"패치\"가 있습니다. 이 방법을 사용하면 서버가 CA로부터 사전에 OCSP 응답을 미리 가져와서 핸드셰이크 중에 인증서와 함께 보내어 클라이언트가 쿼리를 위해 CA 서버에 연결할 필요가 없도록 합니다.\n\n<div class=\"content-ad\"></div>\n\n# TLS 세션 재개\n\n지금까지 네 가지 HTTPS 최적화 방법 (하드웨어 최적화, 소프트웨어 최적화, 프로토콜 최적화, 그리고 인증서 최적화) 에 대해 이야기했습니다. 또 다른 더 나은 방법이 있을까요?\n\nHTTPS 연결 설정 과정을 다시 살펴보겠습니다: 먼저 TCP 쓰이-와이 핸드셰이크, 그리고 TLS 핸드셰이크가 이어집니다. 후자의 핸드셰이크의 핵심은 \"마스터 시크릿\" 키를 계산하는 것인데, 이는 각 연결마다 재계산되어야 합니다. 이는 조금 낭비적으로 보입니다. 만약 수고끈한 마스터 시크릿 키를 캐시하여 재사용할 수 있다면, 핸드셰이크와 계산 비용을 제거할 수 있지 않을까요?\n\n이 접근 방법은 \"TLS 세션 재개\" 라고 불리며, HTTP 캐시와 마찬가지로 HTTPS 성능을 향상시키는 \"큰 무기\"이며 브라우저와 서버에서 널리 사용됩니다.\n\n<div class=\"content-ad\"></div>\n\n세션 재개에는 두 가지 형태가 있습니다. 첫 번째는 \"세션 ID\"로, 클라이언트와 서버가 처음 연결 후 세션 ID를 저장하여 메모리에 Master Secret 키 및 다른 관련 정보를 저장합니다. 클라이언트가 다시 연결할 때 ID를 보내면 서버는 메모리에서 해당 ID를 찾아 세션 상태를 바로 복원하여 Master Secret 키를 사용하여 인증서 확인 및 키 교환을 건너뛰고 안전한 통신을 한 번의 메시지 교환으로 설정합니다.\"\n\n패킷을 캡처하면 서버가 \"ServerHello\" 메시지 이후에 바로 \"Change Cipher Spec\" 및 \"Finished\" 메시지를 보내 세션 재개를 위해 핸드셰이크를 완료하는 것을 볼 수 있습니다.\n\n![이미지](/assets/img/2024-06-20-SomeMethodsforOptimizingHTTPSPerformance_2.png)\n\n# 세션 티켓\n\n<div class=\"content-ad\"></div>\n\n세션 ID는 가장 초기의 세션 재개 기술이었으며 가장 널리 사용되는 기술입니다. 그러나 이에는 단점이 있습니다. 서버는 각 클라이언트의 세션 데이터를 저장해야 하므로, 수백만 또는 수천만 사용자를 가진 웹사이트의 경우 서버의 부하가 증가하는 중요한 문제가 됩니다.\n\n그래서 두 번째 \"세션 티켓\" 방식이 도입되었습니다.\n\n이 방식은 HTTP 쿠키와 약간 유사하여, 저장 책임을 서버에서 클라이언트로 전환합니다. 서버는 세션 정보를 암호화하고 저장을 위해 클라이언트에게 \"새 세션 티켓\" 메시지를 전송합니다.\n\n재연결할 때 클라이언트는 \"세션 ID\" 대신 \"세션 티켓\"을 사용하여 \"session_ticket\" 확장을 통해 \"티켓\"을 전송합니다. 서버는 티켓의 만료일을 해독하고 확인하여 세션을 재개하고 암호화 통신을 시작할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n그러나 \"세션 티켓\" 방식은 Ticket을 암호화하기 위해 고정 키 파일 (ticket_key)의 사용을 필요로 합니다. 키가 노출되는 것을 방지하고 전방 비밀 보장을 확보하기 위해 키 파일은 정기적으로 회전되어야 합니다. 예를 들어 매 시간 또는 매일마다 회전해야 합니다.\n\n# 사전 공유 키 (PSK)\n\n\"False Start\", \"세션 ID\" 및 \"세션 티켓\"은 1-RTT만 달성할 수 있지만, TLS 1.3는 \"0-RTT\"를 달성하기 위해 더 나아갑니다. 원리는 \"세션 티켓\"과 유사하지만 Ticket과 함께 응용 프로그램 데이터 (이른 데이터)를 포함하여 1.2의 서버 확인 단계를 제거합니다. 이 방법은 \"사전 공유 키\" 또는 \"PSK\"로 불립니다.\n\n![이미지](/assets/img/2024-06-20-SomeMethodsforOptimizingHTTPSPerformance_3.png)\n\n<div class=\"content-ad\"></div>\n\n그러나 \"PSK\"는 완벽하지 않습니다. 보안을 약간 희생하여 효율성을 높였기 때문에 \"재생 공격\"에 취약해집니다. 해커들이 \"PSK\" 데이터를 가로채 서버로 반복적으로 보낼 수 있습니다. 이는 재생 장치를 사용하는 것과 유사합니다.\n\n해결책은 안전한 GET/HEAD 메서드만 허용하거나 메시지에 타임스탬프 또는 \"nonce\" 검증을 추가하거나 \"일회용 티켓\"을 사용하여 재생 공격을 제한하는 것입니다.\n\n# 결론\n\n- 네트워크 및 연산 오버헤드를 감소시키는 하드웨어 및 소프트웨어 접근 방식이 여러 가지 있어 HTTPS를 HTTP만큼 빠르게 만들 수 있습니다. 가장 실행 가능한 방법은 소프트웨어 최적화입니다.\n- 가능한 경우 ECDHE 타원 곡선 암호 스위트를 사용하는 것이 좋습니다. 대역폭과 연산을 절약할 수 있으며 \"False Start\"도 가능합니다.\n- 서버는 \"OCSP Stapling\"을 활성화하여 클라이언트가 CA에 인증서를 유효성 검사하기 위해 접근하지 않도록 해야 합니다.\n- 세션 재개는 캐싱과 유사합니다. 클라이언트가 이전에 연결을 성공적으로 설정했다고 가정하면 \"세션 ID\"나 \"세션 티켓\"과 같은 자격 증명을 사용하여 키 교환 및 인증서 유효성 검사 단계를 우회하고 암호화 통신을 직접 시작할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n![2024-06-20-SomeMethodsforOptimizingHTTPSPerformance_4.png](/assets/img/2024-06-20-SomeMethodsforOptimizingHTTPSPerformance_4.png)\n","ogImage":{"url":"/assets/img/2024-06-20-SomeMethodsforOptimizingHTTPSPerformance_0.png"},"coverImage":"/assets/img/2024-06-20-SomeMethodsforOptimizingHTTPSPerformance_0.png","tag":["Tech"],"readingTime":8},{"title":"NodeJS의 이벤트 루프","description":"","date":"2024-06-20 04:22","slug":"2024-06-20-EventLoopinNodeJS","content":"\n\n## Node.js 내부 심층 분석 (블로킹, 논블로킹 IO, 이벤트 루프, nextTick, 프로미스)\n\n![NodeJS Event Loop](/assets/img/2024-06-20-EventLoopinNodeJS_0.png)\n\n안녕하세요! 이 글은 저의 고급 NodeJS 기술자를 위한 시리즈의 세 번째 글입니다. 이 글에서는 노드JS의 이벤트 루프가 무엇이며, 왜 그리고 어떻게 작동하는지에 대해 자세히 설명하고 있습니다. 아래에서 고급 NodeJS 기술자 시리즈의 다른 글들을 찾아볼 수 있어요:\n\n\n글 시리즈 로드맵\n\n* V8 JavaScript 엔진\n* NodeJS에서의 비동기 IO\n* NodeJS의 이벤트 루프 (이 글)\n* Worker Threads: NodeJS에서의 멀티태스킹\n* 자식 프로세스: NodeJS에서의 멀티태스킹\n* 클러스터링과 PM2: NodeJS에서의 멀티태스킹\n* 흔한 NodeJS 오해들을 해소\n\n\n<div class=\"content-ad\"></div>\n\n\n차례\n\n- Node.js에서의 이벤트 루프\n- process.nextTick 및 프로미스 콜백\n- I/O 폴링\n- 실습 예제\n  - setTimeout\n  - 0초 후의 setTimeout\n  - 0초의 setTimeout이지만 다른 호출이 차단 중\n  - setTimeout 및 setImmediate\n  - fs 콜백 내의 setTimeout 및 setImmediate\n  - process.nextTick 및 Promise\n  - process.nextTick 중첩\n  - process.nextTick 프로미스 및 setTimeout\n  - IO, process.nextTick 프로미스 및 setTimeout setImmediate\n\n\n이 글에서는 Event Loop에 대해 깊이 설명하겠습니다. 따라서 초보자라도 이해하기 쉽게 했습니다. 자바스크립트를 배우기 시작할 때 이벤트 루프는 매우 추상적이며 이러한 개념들로 Node.js로 넘어가면 오해하기 쉬울 수 있습니다. 게다가 인터넷에는 많은 잘못된 다이어그램이 있습니다.\n\n# Node.js에서의 이벤트 루프\n\n![Event Loop in Nodejs](https://miro.medium.com/v2/resize:fit:1080/1*17w5J0pMc9Ae49wztRWHhw.gif)\n\n\n<div class=\"content-ad\"></div>\n\n이벤트 루프는 종종 \"반 무한 루프\"라고 불리며, 이벤트 처리할 것이 없을 때까지 실행되며 루프가 살아 있으면 종료되지 않습니다. 활성 핸들이 있거나 활성 요청이 있을 경우도 마찬가지입니다.\n\n![NodeJS Event Loop](/assets/img/2024-06-20-EventLoopinNodeJS_1.png)\n\n- 각 루프 반복의 시작에서 이벤트 루프는 현재 시간(now)을 계산하고 전체 반복에 대한 참조로 저장합니다. 계산된 시간은 시스템 호출 빈도를 줄이기 위해 캐시됩니다.\n- UV_RUN_DEFAULT로 루프가 실행된 경우 타이머가 실행됩니다. 이 시점에서 setTimeout 또는 setInterval과 같은 함수를 통해 실행할 콜백들이 예약된 별도의 큐가 있습니다.\n- 루프가 살아 있는지 확인하려면 참조된 핸들, 활성 요청 또는 닫힌 핸들이 있는지 확인합니다.\n- 대기 중인 콜백이 호출됩니다. 대부분의 I/O 콜백은 I/O 확인 후 즉시 호출됩니다. 그러나 이전 반복에서 콜백 호출이 연기된 경우 다음 루프 반복에서 실행됩니다.\n- 아이들 핸들 콜백이 호출됩니다. 불행한 이름에도 불구하고, 아이들 핸들은 활성 상태일 때마다 각 루프 반복에서 실행됩니다. 이 콜백은 이벤트 루프가 시간 중요한 작업으로 바쁘지 않을 때 저 우선 순위 작업을 수행하는 데 사용됩니다. 아이들 핸들은 정기적으로 실행이 필요하지만 특정 이벤트에 대해 즉각적인 조치 또는 응답을 요구하지 않는 작업에 유용합니다.\n- I/O 점검 전에 준비 핸들 콜백이 실행되어 데이터 구조 또는 설정과 같은 필요한 작업을 수행합니다.\n- I/O 블로킹 전에 폴링 시간이 계산됩니다. 폴링 시간을 계산하는 규칙은 다음과 같습니다:\n- UV_RUN_NOWAIT 플래그가 포함된 루프가 실행되었거나 루프가 중지될 예정이고(유비트 스탑()이 호출됨), 활성 핸들이나 요청이 없거나 아이들 핸들이 활성 상태거나 닫힐 핸들이 대기 중이면 타임아웃은 0입니다.\n- 위의 경우 중 하나도 일치하지 않으면 타임아웃이 가장 가까운 타이머의 지속 시간으로 설정됩니다. 활성 타이머가 없는 경우 무한대로 설정됩니다.\n- 루프가 I/O를 위해 블로킹됩니다. 이 시점에서 루프는 이전 단계에서 계산된 시간만큼 I/O가 블로킹됩니다. 특정 파일 디스크립터의 읽기 또는 쓰기 작업을 모니터링하던 모든 I/O 관련 핸들은 이 시점에 콜백이 실행됩니다.\n- I/O 폴링 후에 즉시 핸들 콜백이 실행되어 setImmediate 콜백을 처리합니다.\n- 닫기 콜백이 실행됩니다. 이 콜백들은 libuv가 활성 핸들을 처분할 때 실행되도록 예약됩니다.\n- '지금'의 루프 개념이 업데이트됩니다.\n- 반복이 종료됩니다.\n\n따라서 이러한 단계들은 때로는 단계 또는 큐로 축소될 수 있습니다. 각 상자를 이벤트 루프의 \"단계\"로 참조할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-06-20-EventLoopinNodeJS_2.png\" />\n\n# process.nextTick과 프로미스 콜백\n\n이제 매크로 태스크에 대해 이야기했는데, process.nextTick() 및 프로미스 콜백 같은 마이크로 태스크는 어떻게 되나요? process.nextTick()이 다이어그램에 표시되지 않은 이유는 process.nextTick()이 기술적으로 이벤트 루프의 일부가 아니기 때문입니다. 대신, nextTickQueue는 현재 작업이 완료된 후에 처리될 것이며, 이는 이벤트 루프의 현재 단계에 관계없이입니다. 여기서 작업이란 기본 C/C++ 핸들러에서 JavaScript를 처리하고 실행해야 하는 것까지의 전환을 의미합니다.\n\nprocess.nextTick()은 현재 작업이 완료된 후, 이벤트 루프가 다음 단계로 진행하기 전에 즉시 콜백 함수를 실행할 수 있게 하는 함수입니다. 이는 재귀적으로 process.nextTick() 호출을 통해 I/O를 \"굶게\" 만들고 폴링 단계에 도달하지 못하게 하는 나쁜 상황을 만들 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nprocess.nextTick()를 사용해야 하는 때:\n\n- process.nextTick()의 주요 용도는 시간에 민감하거나 우선순위가 높은 작업으로, 다른 대기 중인 작업을 기다리지 않고 즉각적인 실행이 필요한 경우에 사용합니다.\n- 사용자가 오류를 처리하도록 허용하거나 필요 없는 자원을 정리하거나, 이벤트 루프가 계속되기 전에 요청을 다시 시도할 수 있도록 합니다.\n- 때로는 콜백이 콜 스택이 풀린 후에 실행되도록 하지만, 이벤트 루프가 계속되기 전에 실행을 허용해야 하는 경우가 있습니다.\n\n출력 순서에 관한 면에서 process.nextTick() 콜백은 항상 Promise 콜백보다 먼저 실행됩니다.\n\n- process.nextTick()은 즉시 동일한 단계에서 발생합니다.\n- setImmediate()는 이벤트 루프의 다음 반복이나 `tick`에서 발생합니다.\n\n<div class=\"content-ad\"></div>\n\n개념도는 다음과 같이 나타날 것입니다\n\n![Conceptual Diagram](/assets/img/2024-06-20-EventLoopinNodeJS_3.png)\n\n## I/O 폴링\n\n몇 가지 예시를 살펴봅시다.\n\n<div class=\"content-ad\"></div>\n\n예시 1)\n\n```js\nconst fs = require('fs')\n\nsetTimeout(() => {\n  console.log('hello');\n}, 0);\nfs.readFile('./AWS Migration.txt', () => {\n  console.log('world');\n});\nsetImmediate(() => {\n  console.log('immediate');\n});\n\nfor (let index = 0; index > 2000000000; index++) {}\n```\n\n```js\nhello\nimmediate\nworld\n```\n\n세계가 먼저 출력될 것으로 예상했겠죠? 단계별로 살펴봅시다.\n\n<div class=\"content-ad\"></div>\n\n- 먼저 \"sync user code\"를 실행합니다. 즉, for 루프가 실행됩니다.\n- EventLoop는 타이머 콜백을 실행하고 타이머가 완료되고 실행 준비가 된 것을 발견합니다. 결과적으로 타이머인 setTimeout이 실행됩니다. 콘솔에는 \"hello\"가 표시됩니다.\n- 이후 EventLoop는 I/O 콜백 단계로 이동합니다. 이 시점에서 파일 읽기 프로세스는 완료되었지만 콜백은 아직 실행 대기 중이며, 이는 IO 콜백이 IO polling 단계에서만 대기열에 들어가기 때문입니다. 즉, 파일 읽기가 완료되어도 이벤트 루프가 IO polling 단계에 도달할 때까지 콜백이 IO 대기열에 추가되지 않습니다. 이 때, readFile() 콜백 이벤트가 수집되어 I/O 대기열에 추가되었지만 아직 실행되지 않습니다. 실행 준비가 되어 있지만 EventLoop는 다음 사이클에서 실행합니다.\n- 다음 단계로 넘어가면, EventLoop가 setImmediate() 콜백을 실행합니다. 콘솔에는 \"immediate\"가 표시됩니다.\n- 그런 다음, EventLoop가 다시 시작됩니다. 실행할 타이머가 없으므로 \"Call pending callback stage\"로 이동하고, readFile() 콜백을 마칩니다. 콘솔에는 \"world\"가 표시됩니다.\n\n예시 2)\n\n```js\nconst fs = require('fs')\nconst now = Date.now();\nsetTimeout(() => {\n  console.log('hello');\n}, 50);\nfs.readFile(__filename, () => {\n  console.log('world');\n});\nsetImmediate(() => {\n  console.log('immediate');\n});\nwhile(Date.now() - now < 2000) {} // 2초간 블록\n```\n\n세 가지 작업을 수행합니다: setTimeot, readFile 및 setImmediate. 그 후에는 스레드를 2초 동안 차단하는 while 루프가 있습니다. 이 기간 동안 세 가지 이벤트가 각각의 대기열에 추가되어야 합니다. 따라서 while 루프가 종료될 때, EventLoop는 모든 세 가지 이벤트를 동일한 사이클에서 처리하고 다이어그램에 표시된 순서대로 콜백을 실행합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n안녕\n즉시\n세계\n```\n\n하지만 실제 결과는 이렇게 보입니다:\n\n```js\n안녕\n세계\n즉시\n```\n\n그 이유는 I/O 폴링이라는 추가적인 과정이 있기 때문입니다.\n\n<div class=\"content-ad\"></div>\n\nI/O 이벤트는 다른 유형의 이벤트와는 달리 특정 시점에 대기열에 추가됩니다. 그래서 setImmediate()의 콜백이 readFile()의 콜백보다 먼저 실행됩니다. 둘 다 while 루프가 끝날 때 준비가 된 상태입니다.\n\n문제는 EventLoop의 I/O 대기열 확인 단계에서 이미 이벤트 대기열에 있는 콜백만을 실행한다는 점입니다. 이들은 완료된 시점에 자동으로 이벤트 대기열에 추가되지 않습니다. 대신, I/O 폴링 단계 중에 나중에 이벤트 대기열에 추가됩니다.\n\nwhile 루프가 끝난 후 2초가 지난 후 일어나는 일은 다음과 같습니다.\n\n- EventLoop은 타이머 콜백을 실행하고 타이머가 완료되어 실행 가능한 상태임을 알게 됩니다. 따라서 타이머를 실행합니다. 콘솔에 \"hello\" 메시지가 출력됩니다.\n- 그 후, EventLoop은 I/O 콜백 단계로 진행합니다. 이 시점에서 파일 읽기 프로세스는 완료되었지만 해당 콜백은 아직 실행 대상이 아닙니다. 이후에 실행 대상으로 표시됩니다. EventLoop는 여러 단계를 거치고 I/O 폴링 단계에 도달합니다. 이때 readFile() 콜백 이벤트가 수집되고 I/O 대기열에 추가되지만 아직 실행되지 않습니다. 실행 준비가 된 상태이지만 EventLoop는 다음 사이클에서 실행합니다.\n- 다음 단계로 진행하여 EventLoop는 setImmediate() 콜백을 실행합니다. 콘솔에 \"immediate\"가 표시됩니다.\n- 이후 EventLoop는 다시 시작합니다. 실행할 타이머가 없으므로 I/O 콜백 단계로 이동하고 마침내 readFile() 콜백을 찾아 실행합니다. 콘솔에 \"world\"가 나타납니다.\n\n<div class=\"content-ad\"></div>\n\n이 예제는 이해하기 약간 어려울 수 있지만, I/O 폴링 프로세스에 대한 유용한 통찰력을 제공합니다. 2초짜리 while 루프를 제거하면 다른 결과를 볼 수 있을 것입니다.\n\n```js\n즉시\n월드\n안녕\n```\n\nsetImmediate()는 setTimeout이나 파일 시스템 프로세스 중 하나도 완료되지 않았을 때 EventLoop의 첫 번째 사이클에서 작동합니다. 일정 기간이 지나면 타임아웃이 끝나고 EventLoop은 해당 콜백을 실행할 것입니다. 나중에 파일이 읽히면 EventLoop은 readFile의 콜백을 실행할 것입니다.\n\n모든 것은 타임아웃의 지연 시간과 파일의 크기에 따라 달라집니다. 파일이 크면 읽기 프로세스가 완료되는 데 더 오래 걸릴 것입니다. 마찬가지로 타임아웃이 길면 파일 읽기 프로세스가 타임아웃 이전에 완료될 수 있습니다. 그러나 setImmediate() 콜백은 고정되어 있으며 V8이 실행하는 즉시 항상 이벤트 큐에 등록됩니다.\n\n<div class=\"content-ad\"></div>\n\n# 실습 예시\n\n## 예시 1) setTimeout\n\n```js\nconsole.log('첫번째');\nsetTimeout(() => { console.log('두번째') }, 10);\nconsole.log('세번째');\n```\n\n```js\n첫번째\n세번째\n두번째\n```\n\n<div class=\"content-ad\"></div>\n\n테이블 태그를 Markdown 형식으로 변경하세요.\n\n<div class=\"content-ad\"></div>\n\n하지만 왜 결과가 비슷한 걸까요? 네, 이유는 실행 시간이 0밀리초이지만 비동기 함수이기 때문에 여전히 타이머 큐에 들어가서 실행됩니다. 그래서 시간이 걸립니다.\n\n## 예시 3) setTimeout은 0이지만 다른 호출이 블로킹됩니다\n\n만약 세 번째 호출이 루프를 3초 동안 차단하면 우리가 0 밀리초로 설정했던 두 번째 호출이 될까요?\n\n```js\nconsole.log('first');\nsetTimeout(() => { console.log('second') }, 0);\nconst startTime = new Date()\nconst endTime = new Date(startTime.getTime() + 3000)\nwhile (new Date() < endTime) {\n}\nconsole.log('third');\n```\n\n<div class=\"content-ad\"></div>\n\n\n첫 번째\n세 번째\n두 번째\n\n세 번째 이후에도 여전히 두 번째가 출력됩니다. 0밀리초 타임아웃이 지정되었지만 사용자 코드가 우선시되기 때문에 0초가 보장되지 않습니다. 사용자 동기 코드가 이벤트 루프를 차단하면 타이머가 굶주리게 될 수 있으므로 이벤트 루프를 차단하지 말아야 한다고 말합니다.\n\n## 예제 4) setTimeout & setImmediate\n\n```js\nsetTimeout(() => {\n  console.log('setTimeout');\n}, 0);\n\nsetImmediate(() => {\n  console.log('setImmediate');\n});\n```\n\n<div class=\"content-ad\"></div>\n\n가끔 프로세스가 실행하는 데 더 오랜 시간이 걸릴 수 있어(밀리초 기준) 타이머 대기열이 비어 있을 때 이벤트 루프가 지나가는 경우가 있습니다. 또는 이벤트 루프가 너무 빨리 작동하여 다중화기가 이벤트를 제때 이벤트 큐에 등록하지 못할 수도 있습니다. 결과적으로 이 예제를 여러 번 실행하면 각 시간마다 다른 결과를 얻을 수 있습니다.\n\n## 예제 4) fs 콜백 내부의 setTimeout & setImmediate\n\n```js\nconst fs  = require('fs');\n\nfs.readFile(__filename, () => {\n  setTimeout(() => {\n    console.log('setTimeout');\n  }, 0);\n  \n  setImmediate(() => {\n    console.log('setImmediate');\n  });\n});\n```\n\n<div class=\"content-ad\"></div>\n\n```js\nsetImmediate\nsetTimeout\n```\n\nsetTimeout와 setImmediate는 readFile 함수 내부에 작성되어 있으므로, 콜백이 실행될 때 이벤트 루프가 I/O 단계에 있음을 알 수 있습니다. 따라서, 다음으로 진행되는 것은 setImmediate 대기열입니다. setImmediate가 즉시 대기열에 등록되므로 항상 이 순서로 로그가 표시되는 것은 놀라운 일이 아닙니다.\n\n## 예제 5) process.nextTick 및 Promise\n\n```js\nconsole.log('first');\n\nprocess.nextTick(() => {\n  console.log('nextTick');\n});\n\nPromise.resolve()\n  .then(() => {\n    console.log('Promise');\n  });\n\nconsole.log('second');\n```\n\n<div class=\"content-ad\"></div>\n\n\n```js\n첫 번째\n두 번째\n다음 실행\n프로미스\n```\n\n## 예제 5) process.nextTick 중첩\n\n```js\nprocess.nextTick(() => {\n  console.log('다음 실행 1');\n\n  process.nextTick(() => {\n    console.log('다음 실행 2');\n\n    process.nextTick(() => console.log('다음 실행 3'));\n    process.nextTick(() => console.log('다음 실행 4'));\n  });\n\n  process.nextTick(() => {\n    console.log('다음 실행 5');\n\n    process.nextTick(() => console.log('다음 실행 6'));\n    process.nextTick(() => console.log('다음 실행 7'));\n  });\n  \n});\n```\n\n```js\n다음 실행 1\n다음 실행 2\n다음 실행 5\n다음 실행 3\n다음 실행 4\n다음 실행 6\n다음 실행 7\n```\n\n<div class=\"content-ad\"></div>\n\n위 설명 드릴게요:\n이 코드를 실행하면 중첩된 process.nextTick 콜백들이 일련의 일정에 맞게 예약됩니다.\n\n- 처음의 process.nextTick 콜백이 가장 먼저 실행되어 콘솔에 `nextTick 1`을 로깅합니다.\n- 이 콜백 내에서 두 개의 process.nextTick 콜백이 더 예약됩니다: 하나는 `nextTick 2`를 로깅하고 다른 하나는 `nextTick 5`를 로깅합니다.\n- 'nextTick 2'로 로깅된 콜백이 다음에 실행되어 콘솔에 'nextTick 2'를 로깅합니다.\n- 이 콜백 내에서 두 개의 process.nextTick 콜백이 더 예약됩니다: 하나는 `nextTick 3`를 로깅하고 다른 하나는 `nextTick 4`를 로깅합니다.\n- 'nextTick 5'로 로깅된 콜백은 'nextTick 2' 이후에 실행되어 콘솔에 'nextTick 5'를 로깅합니다.\n- 이 콜백 내에서 두 개의 process.nextTick 콜백이 더 예약됩니다: 하나는 `nextTick 6`을 로깅하고 다른 하나는 `nextTick 7`을 로깅합니다.\n- 마지막으로, 남은 process.nextTick 콜백들이 예약된 순서대로 실행되어 콘솔에 `nextTick 3`, `nextTick 4`, `nextTick 6`, `nextTick 7`을 로깅합니다.\n\n아래는 실행 중에 대기열이 어떻게 구성될지에 대한 개요입니다.\n\n```js\nProcess started: [ nT1 ]\nnT1 executed: [ nT2, nT5 ]\nnT2 executed: [ nT5, nT3, nT4 ]\nnT5 executed: [ nT3, nT4, nT6, nT7 ]\n// ...\n```\n\n<div class=\"content-ad\"></div>\n\n## 예제 6) process.nextTick promises 및 setTimeouts\n\n```js\nprocess.nextTick(() => {\n  console.log('nextTick');\n});\n\nPromise.resolve()\n  .then(() => {\n    console.log('Promise');\n  });\n\nsetTimeout(() => {\n  console.log('setTimeout');\n}, 0);\n\nsetImmediate(() => {\n  console.log('setImmediate');\n});\n```\n\n```js\nnextTick\nPromise\nsetTimeout\nsetImmediate\n```\n\n## 예제 7) IO, process.nextTick promises와 setTimeouts setImmediate\n\n<div class=\"content-ad\"></div>\n\n```js\nconst fs  = require('fs');\n\nfs.readFile(__filename, () => {\n  process.nextTick(() => {\n    console.log('nextTick in fs');\n  });\n\n  setTimeout(() => {\n    console.log('setTimeout');\n\n    process.nextTick(() => {\n      console.log('nextTick in setTimeout');\n    });\n  }, 0);\n  \n  setImmediate(() => {\n    console.log('setImmediate');\n\n    process.nextTick(() => {\n      console.log('nextTick in setImmediate');\n\n      Promise.resolve()\n        .then(() => {\n          console.log('Promise in setImmediate');\n        });\n    });\n  });  \n});\n```\n\n```js\nnextTick in fs\nsetImmediate\nnextTick in setImmediate\nPromise in setImmediate\nsetTimeout\nnextTick in setTimeout\n```\n\nV8이 코드를 실행할 때, 처음에는 fs.readFile() 하나의 작업만 있습니다. 이 작업이 처리되는 동안 Event Loop가 각 큐를 확인하며 작업을 계속합니다. 계속해서 카운터가 0이 되어 Event Loop는 프로세스를 종료할 때까지 큐를 확인합니다.\n\n결국 파일 시스템 읽기 작업이 완료되고, Event Loop는 I/O 큐를 확인하면서 이를 감지합니다. 콜백 함수 내에는 nextTick, setTimeout, 그리고 setImmediate와 같이 세 가지 새로운 작업이 있습니다.\n\n<div class=\"content-ad\"></div>\n\n자 이제 우선순위에 대해 생각해보세요.\n\n매크로태스크 큐를 모두 실행한 후에는 마이크로태스크가 실행됩니다. 이는 “fs에 있는 nextTick”이 기록될 것이라는 것을 의미합니다. 그리고 마이크로태스크 큐가 비어 있으면 이벤트 루프가 계속 진행됩니다. 다음 단계는 즉시 실행 큐입니다. 그래서 “setImmediate”가 기록될 것입니다. 게다가, 다음 nextTick 큐에 이벤트도 등록됩니다.\n\n이제 즉시 실행할 이벤트가 남아있지 않으면 JavaScript는 마이크로태스크 큐를 확인하기 시작합니다. 결과적으로 “setImmediate 내부의 nextTick”이 기록되고 동시에 프로미스 큐에 이벤트가 추가됩니다. 이제 nextTick 큐가 비어 있으므로 JavaScript는 프로미스 큐를 확인하여 새로 등록된 이벤트로 인해 “setImmediate 내부의 Promise”가 기록됩니다.\n\n이 시점에서 모든 마이크로태스크 큐가 비어 있으므로 이벤트 루프가 계속 진행하고 다음으로 타이머 큐 안에 이벤트를 발견합니다.\n이제 마지막으로 “setTimeout”과 “setTimeout 내부의 nextTick”이 우리가 논의한 로직과 동일한 방식으로 기록됩니다.\n\n<div class=\"content-ad\"></div>\n\n## 예제 8) IO, process.nextTick promises 및 setTimeouts setImmediate\n\n```js\nsetTimeout(() => console.log('Timeout 1'));\nsetTimeout(() => {\n    console.log('Timeout 2');\n    Promise.resolve().then(() => console.log('promise resolve'));\n});\nsetTimeout(() => console.log('Timeout 3'));\n```\n\n```js\nTimeout 1\nTimeout 2\npromise resolve\nTimeout 3\n```\n\n## 참고문헌\n\n<div class=\"content-ad\"></div>\n\n- 노드 JS 내부 아키텍처 | Ignition, Turbofan, Libuv\n- 노드.js가 확장하는 이유는? Libuv 및 epoll 및 fcntl\n- 노드.js 자습서 — 42 — 이벤트 루프\n- 노드 js 이벤트 루프의 심층 탐구 — Tyler Hawkins\n- 이벤트 루프와 전체 그림 — NodeJS 이벤트 루프 파트 1\n- https://blog.bitsrc.io/you-dont-know-node-js-eventloop-8ee16831767\n- 노드.js 이벤트 루프 이해하기\n- 노드.js 이벤트 루프에 대한 실제 상황과 오해: 진실 밝혀내기\n\n# 가기 전에!\n\n- 더 많은 통찰력을 기대해주세요! 팔로우하고 구독하세요.\n- 👏 버튼을 클릭하고 누르고 있을 때 발생하는 일을 보셨나요?","ogImage":{"url":"/assets/img/2024-06-20-EventLoopinNodeJS_0.png"},"coverImage":"/assets/img/2024-06-20-EventLoopinNodeJS_0.png","tag":["Tech"],"readingTime":14},{"title":"API에 대한 동시 요청 처리하기 Nodejs, AWS","description":"","date":"2024-06-20 04:20","slug":"2024-06-20-HandlingConcurrentRequeststoanAPINodejsAWS","content":"\n\n동시에 여러 입찰을 처리하고 실시간 입찰 시스템에서 우승자를 결정하는 것은 데이터 일관성과 공정성을 보장할 때 특히 어려울 수 있습니다. diff database를 사용할 수도 있어요.\n\n단계\n\n## Node.js 서버 설정\n\nExpress 및 Mongoose가 포함된 기본 Node.js 서버를 설정하세요.\n\n<div class=\"content-ad\"></div>\n\n```js\nnpm init -y\nnpm install express mongoose body-parser\n```\n\n```js\nsaas-bidding/\n│\n├── models/\n│   ├── bid.js\n│   └── auction.js\n│\n├── routes/\n│   ├── bids.js\n│   └── auctions.js\n│\n├── app.js\n└── config.js\n```\n\nconfig.js\n\n```js\n// config.js\nmodule.exports = {\n  mongoURI: 'mongodb://localhost:27017/saasbidding',\n  port: 3000\n};\n```\n\n<div class=\"content-ad\"></div>\n\n더하기 기호 뒤에 해당 값을 입력하세요:\n\nMongoose 모델 생성\n\n경매 모델 (models/auction.js)\n\n```js\n// models/auction.js\nconst mongoose = require('mongoose');\n\nconst AuctionSchema = new mongoose.Schema({\n  product: { type: String, required: true },\n  startingPrice: { type: Number, required: true },\n  currentHighestBid: { type: Number, default: 0 },\n  highestBidder: { type: mongoose.Schema.Types.ObjectId, ref: 'Bidder' },\n  endTime: { type: Date, required: true }\n});\n\nmodule.exports = mongoose.model('Auction', AuctionSchema);\n```\n\n<div class=\"content-ad\"></div>\n\n```js\n// models/bid.js\nconst mongoose = require('mongoose');\n\nconst BidSchema = new mongoose.Schema({\n  auctionId: { type: mongoose.Schema.Types.ObjectId, ref: 'Auction', required: true },\n  bidderId: { type: mongoose.Schema.Types.ObjectId, ref: 'Bidder', required: true },\n  bidAmount: { type: Number, required: true },\n  timestamp: { type: Date, default: Date.now }\n});\n\nmodule.exports = mongoose.model('Bid', BidSchema);\n```\n\n## Express and Mongoose (app.js)\n\n```js\n// app.js\nconst express = require('express');\nconst mongoose = require('mongoose');\nconst bodyParser = require('body-parser');\nconst config = require('./config');\n\nconst app = express();\n\nmongoose.connect(config.mongoURI, { useNewUrlParser: true, useUnifiedTopology: true });\n\napp.use(bodyParser.json());\n\n// Routes\napp.use('/bids', require('./routes/bids'));\napp.use('/auctions', require('./routes/auctions'));\n\napp.listen(config.port, () => {\n  console.log(`Server is running on port ${config.port}`);\n});\n```\n\nBids 및 Auctions에 대한 라우팅\n\n<div class=\"content-ad\"></div>\n\n경매 라우트(Auction Routes)는 다음과 같습니다(routes/auctions.js)\n\n```js\n// routes/auctions.js\nconst express = require('express');\nconst Auction = require('../models/auction');\nconst router = express.Router();\n\n// 새 경매 생성\nrouter.post('/', async (req, res) => {\n  const { product, startingPrice, endTime } = req.body;\n  const auction = new Auction({ product, startingPrice, endTime });\n  await auction.save();\n  res.status(201).send(auction);\n});\n\n// 경매 세부 정보 가져오기\nrouter.get('/:id', async (req, res) => {\n  const { id } = req.params;\n  const auction = await Auction.findById(id).populate('highestBidder');\n  res.send(auction);\n});\n\nmodule.exports = router;\n```\n\n입찰 라우트(Bid Routes)는 다음과 같습니다(routes/bids.js)\n\n```js\n// routes/bids.js\nconst express = require('express');\nconst mongoose = require('mongoose');\nconst Bid = require('../models/bid');\nconst Auction = require('../models/auction');\nconst router = express.Router();\n\n// 입찰하기\nrouter.post('/', async (req, res) => {\n  const session = await mongoose.startSession();\n  session.startTransaction();\n  try {\n    const { auctionId, bidderId, bidAmount } = req.body;\n\n    // 경매 찾기\n    const auction = await Auction.findById(auctionId).session(session);\n    if (!auction) {\n      throw new Error('경매를 찾을 수 없습니다');\n    }\n\n    // 입찰이 현재 최고 입찰보다 높은지 확인\n    if (bidAmount <= auction.currentHighestBid) {\n      throw new Error('입찰 금액은 현재 최고 입찰보다 높아야 합니다');\n    }\n\n    // 새로운 입찰 생성\n    const bid = new Bid({ auctionId, bidderId, bidAmount });\n    await bid.save({ session });\n\n    // 경매에 새로운 최고 입찰로 업데이트\n    auction.currentHighestBid = bidAmount;\n    auction.highestBidder = bidderId;\n    await auction.save({ session });\n\n    await session.commitTransaction();\n    session.endSession();\n    res.status(201).send(bid);\n  } catch (error) {\n    await session.abortTransaction();\n    session.endSession();\n    res.status(400).send({ error: error.message });\n  }\n});\n\n// 특정 경매에 대한 모든 입찰 가져오기\nrouter.get('/:auctionId', async (req, res) => {\n  const { auctionId } = req.params;\n  const bids = await Bid.find({ auctionId }).sort({ timestamp: -1 });\n  res.send(bids);\n});\n\nmodule.exports = router;\n```\n\n<div class=\"content-ad\"></div>\n\n# 동시에 발생하는 입찰 처리\n\n동시에 발생하는 입찰을 효율적으로 처리하기 위해 MongoDB의 세션과 트랜잭션 기능을 사용하여 원자성을 보장합니다. 주요 단계는 다음과 같습니다:\n\n- 세션 및 트랜잭션 시작: 세션을 시작하여 세션 내의 작업이 원자적으로 실행되도록 합니다.\n- 경매 유효성 검사: 경매가 존재하고 유효한지 확인합니다.\n- 입찰 유효성 검사: 현재 가장 높은 입찰가보다 입찰이 높은지 확인합니다.\n- 경매 업데이트: 입찰이 유효한 경우 새로운 최고 입찰가로 경매를 업데이트합니다.\n- 트랜잭션 커밋: 변경 사항을 영구적으로 만들기 위해 트랜잭션을 커밋합니다.\n- 오류 처리: 오류 발생 시 트랜잭션을 중단하여 데이터 일관성을 보장합니다.\n\n# AWS 및 자동 스케일링을 활용하여 더 최적화해봅시다.\n\n<div class=\"content-ad\"></div>\n\n# 주요 구성 요소\n\n- Node.js 어플리케이션: API 요청을 처리합니다.\n- 부하 분산 장치: 여러 인스턴스에 들어오는 트래픽을 분산합니다.\n- 자동 확장: 트래픽에 기반하여 인스턴스 수를 자동으로 조정합니다.\n- 메시지 큐: 입찰 요청을 비동기적으로 처리합니다.\n- 데이터베이스: 동시에 발생하는 쓰기 및 읽기 작업을 효율적으로 처리합니다.\n- 캐시: 읽기 작업을 가속화하고 데이터베이스에 가해지는 부하를 감소시킵니다.\n- 마이크로서비스 아키텍처: 구성요소를 분리하고 특정 작업을 효율적으로 처리합니다.\n\n# AWS 아키텍처\n\n- 탄력적 부하 분산기 (ELB): 입찰 요청을 분산합니다.\n- 자동 확장 그룹: 응용프로그램 인스턴스가 부하를 처리할 수 있는지 확인합니다.\n- Amazon SQS (Simple Queue Service): 입찰 요청 큐를 관리합니다.\n- Amazon RDS/DynamoDB: 경매 및 입찰 데이터를 저장합니다.\n- Amazon ElastiCache (Redis): 빈번하게 액세스되는 데이터를 캐싱합니다.\n- Worker 노드: 큐에서 입찰 요청을 처리합니다.\n- Amazon CloudWatch: 인프라를 모니터링하고 확장합니다.\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-20-HandlingConcurrentRequeststoanAPINodejsAWS_0.png)\n\n단계\n\nnode.js\n\n```js\nnpm init -y\nnpm install express body-parser aws-sdk\n```\n\n<div class=\"content-ad\"></div>\n\nconfig.js\n\n```js\nmodule.exports = {\n  awsRegion: 'us-east-1',\n  sqsQueueUrl: 'YOUR_SQS_QUEUE_URL',\n  mongoURI: 'mongodb://localhost:27017/saasbidding',\n  port: 3000\n};\n```\n\napp.js\n\n```js\nconst express = require('express');\nconst bodyParser = require('body-parser');\nconst AWS = require('aws-sdk');\nconst config = require('./config');\n\nconst app = express();\napp.use(bodyParser.json());\n\nAWS.config.update({ region: config.awsRegion });\n\nconst sqs = new AWS.SQS();\n\napp.post('/bid', async (req, res) => {\n  const { auctionId, bidderId, bidAmount } = req.body;\n\n  const params = {\n    MessageBody: JSON.stringify({ auctionId, bidderId, bidAmount }),\n    QueueUrl: config.sqsQueueUrl\n  };\n\n  try {\n    await sqs.sendMessage(params).promise();\n    res.status(200).send({ message: 'Bid received' });\n  } catch (error) {\n    res.status(500).send({ error: 'Failed to process bid' });\n  }\n});\n\napp.listen(config.port, () => {\n  console.log(`Server is running on port ${config.port}`);\n});\n```\n\n<div class=\"content-ad\"></div>\n\nWorker.js 파일 — 이 파일은 SQS에서 메시지를 처리하고 데이터베이스를 업데이트합니다.\n\n```js\nconst AWS = require('aws-sdk');\nconst mongoose = require('mongoose');\nconst Auction = require('./models/auction');\nconst Bid = require('./models/bid');\nconst config = require('./config');\n\nAWS.config.update({ region: config.awsRegion });\n\nconst sqs = new AWS.SQS();\nconst queueUrl = config.sqsQueueUrl;\n\nmongoose.connect(config.mongoURI, { useNewUrlParser: true, useUnifiedTopology: true });\n\nconst processBid = async (message) => {\n  const { auctionId, bidderId, bidAmount } = JSON.parse(message.Body);\n\n  const session = await mongoose.startSession();\n  session.startTransaction();\n  try {\n    const auction = await Auction.findById(auctionId).session(session);\n    if (bidAmount <= auction.currentHighestBid) {\n      throw new Error('Bid amount must be higher than the current highest bid');\n    }\n\n    const bid = new Bid({ auctionId, bidderId, bidAmount });\n    await bid.save({ session });\n\n    auction.currentHighestBid = bidAmount;\n    auction.highestBidder = bidderId;\n    await auction.save({ session });\n\n    await session.commitTransaction();\n    session.endSession();\n  } catch (error) {\n    await session.abortTransaction();\n    session.endSession();\n    throw error;\n  }\n};\n\nconst pollQueue = async () => {\n  const params = {\n    QueueUrl: queueUrl,\n    MaxNumberOfMessages: 10,\n    WaitTimeSeconds: 20\n  };\n\n  try {\n    const data = await sqs.receiveMessage(params).promise();\n    if (data.Messages) {\n      for (const message of data.Messages) {\n        try {\n          await processBid(message);\n          await sqs.deleteMessage({ QueueUrl: queueUrl, ReceiptHandle: message.ReceiptHandle }).promise();\n        } catch (error) {\n          console.error('Failed to process bid', error);\n        }\n      }\n    }\n  } catch (error) {\n    console.error('Failed to receive messages', error);\n  }\n\n  setImmediate(pollQueue);\n};\n\npollQueue();\r\n```\n\n## AWS 리소스 구성\n\n- Elastic Load Balancer: ELB를 설정하여 여러 EC2 인스턴스 간에 들어오는 트래픽을 분산합니다.\n- Auto Scaling 그룹: 트래픽 패턴에 따라 EC2 인스턴스를 추가하거나 제거할 수 있도록 자동 스케일링을 구성합니다.\n- Amazon SQS: 수신된 입찰 요청을 관리하기 위한 SQS 대기열을 생성합니다.\n- Amazon RDS/DynamoDB: 경매 및 입찰 데이터를 처리할 데이터베이스를 설정합니다.\n- Amazon ElastiCache (Redis): 자주 액세스되는 데이터를 캐싱하여 데이터베이스 부하를 줄이기 위해 Redis를 사용합니다.\n- Amazon CloudWatch: 인프라를 모니터링하고 스케일링 이벤트를 트리거할 알림을 설정합니다.\n\n\n<div class=\"content-ad\"></div>\n\n주의 : 이 코드는 샘플입니다. 조심해서 사용해주세요.","ogImage":{"url":"/assets/img/2024-06-20-HandlingConcurrentRequeststoanAPINodejsAWS_0.png"},"coverImage":"/assets/img/2024-06-20-HandlingConcurrentRequeststoanAPINodejsAWS_0.png","tag":["Tech"],"readingTime":9},{"title":"Agora 라이브 비디오 스트림에 실시간 3D 아바타 추가하기","description":"","date":"2024-06-20 04:18","slug":"2024-06-20-AddRealtime3DAvatarstoAgoraLiveVideoStreams","content":"\n\n현재 급속히 변화하는 디지털 환경에서 라이브 스트림 비디오가 주도를 차지하고 있어요. 사용자들은 이제 더 몰입적이고 맞춤형 스트리밍 옵션을 기대하고 있어요. 콘텐츠 크리에이터들은 점점 더 창의적인 방법으로 스트리밍을 하기 위해 노력하고 있어요. 이로 인해 자신의 움직임과 표현을 반영하는 동적 3D 아바타에 대한 수요가 늘어나고 있어요.\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*dbCqUb7N3awHxQP4xj3ZXA.gif)\n\n실시간 가상 아바타는 전통적으로 복잡한 모션 캡처 장비와 정교한 소프트웨어가 필요했기 때문에 보통 일반 사용자나 독립적인 크리에이터들에게는 접근하기 어려웠어요. 그러나 이 역시 인공지능이 상황을 바꾸는 분야 중 하나에요. 컴퓨터 비전의 발전으로 장치에서 정교한 AI 알고리즘을 실행해서 인간의 얼굴 제스처를 실시간으로 정확하게 캡처하고 디지털 형태로 번역할 수 있게 된 거예요.\n\n이 가이드에서는 MediaPipe와 ReadyPlayerMe의 3D 아바타를 사용해 Agora 라이브 스트림에 3D 가상 아바타를 통합하는 방법을 살펴볼 거예요. 관객 참여도를 높이거나 앱의 비디오 통화/라이브 방송에 창의적 요소를 추가하는 것이 목표라면, 이 안내서는 3D 가상 페르소나를 구현하는 데 필요한 단계를 제공할 거예요.\n\n<div class=\"content-ad\"></div>\n\n# 전제 조건\n\n- Node.JS\n- Agora 개발자 계정\n- HTML/CSS/JS의 기본 지식\n- ThreeJS의 기본 이해\n- Agora - Web QuickStart의 기본 이해\n- 코드 편집기 (저는 VSCode를 사용합니다)\n- ReadyPlayerMe에서 3D 아바타\n\n# Agora + MediaPipe 프로젝트\n\n이 안내서를 간결하게 유지하기 위해 Agora Video SDK를 웹 앱에 구현하는 방법을 이해한다고 가정합니다. 알지 못한다면, 'Building a Group Video Chat Web App' 안내서를 확인해보세요.\n\n<div class=\"content-ad\"></div>\n\n시작하려면 데모 프로젝트를 다운로드하세요. 코드를 다운로드한 후 터미널에서 프로젝트 폴더로 이동하여 npm을 사용하여 노드 패키지를 설치하십시오.\n\n```js\ngit clone git@github.com:digitallysavvy/agora-mediapipe-readyplayerme.git\ncd agora-mediapipe-readyplayerme\nnpm i\n```\n\n# 핵심 구조 (HTML)\n\nindex.html의 HTML 구조에서 시작해보겠습니다. 본문에서 \"call\" UI 요소가 있는 맨 위에, 원격 비디오를 담을 컨테이너, 로컬 사용자를 담을 컨테이너(음소거 및 음소거 해제를 위한 버튼 포함), 채팅에서 떠나기 위한 버튼이 포함되어 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n<!doctype html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"UTF-8\" />\n    <link rel=\"icon\" type=\"image/svg+xml\" href=\"/agora-box-logo.svg\" />\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"style.css\" />\n    <title>Agora Live Video Demo</title>\n  </head>\n  <body>\n    <div id=\"container\"></div>\n    <div id=\"local-user-container\"></div>\n    <div id=\"local-media-controls\">\n      <button id=\"mic-toggle\" class=\"media-active\">Mic</button>\n      <button id=\"video-toggle\" class=\"media-active\">Video</button>\n      <button id=\"leave-channel\" class=\"media-active\">Leave</button>\n    </div>\n    <div id=\"overlay\" class=\"modal\">\n      <div id=\"form-container\">\n        <h1 id=\"form-header\">Avatar Video Chat</h1>\n        <form id=\"join-channel-form\">\n          <div id=\"form-body\">\n            <div class=\"form-group\">\n              <label for=\"form-rpm-url\">Ready Player Me URL</label>\n              <input type=\"text\" id=\"form-rpm-url\" placeholder=\"http://models.readyplayer.me/<MODEL-ID>.glb\" class=\"form-control\">\n            </div>\n            <div id=\"form-footer\">\n              <button type=\"submit\" id=\"join-channel-btn\">Join Channel</button>\n            </div>\n          </div>\n        </form>\n      </div>\n    </div>\n    <script type=\"module\" src=\"/main.js\"></script>\n  </body>\n</html>\n\n\n투사 UI 외에도 사용자가 아바타 URL을 입력할 수 있는 오버레이 화면과 채널에 참여하는 버튼이 필요합니다.\n\n# Agora Client 및 데이터 저장소\n\nmain.js에 우리는 Agora 클라이언트를 생성하여 Agora의 SDK를 사용하고 로컬 미디어를 사용하여 오디오, 비디오 및 캔버스 트랙과 활성 상태에 대한 참조를 유지합니다. MediPipe의 컴퓨터 비전에서 얻은 데이터를 저장하기 위해 headRotation과 blendShapes가 필요합니다.\n\n\n<div class=\"content-ad\"></div>\n\n```js\n// Agora 클라이언트 생성\nconst client = AgoraRTC.createClient({ \n  codec: 'vp9',\n  mode: 'live',\n  role: 'host'\n})\n\nconst localMedia = {\n  audio: {\n    track: null,\n    isActive: false\n  },\n  video: {\n    track: null,\n    isActive: false\n  },\n  canvas: {\n    track: null,\n    isActive: false\n  },\n}\n\n// 원격 스트림을 저장할 컨테이너\nlet remoteUsers = {}                \n\n// 얼굴 특징점 데이터 저장\nlet headRotation\nlet blendShapes\n```\n\n# DOMContentLoaded 및 이벤트 리스너\n\n페이지가 로드될 때, Agora 이벤트, 미디어 컨트롤, 그리고 폼 제출을 위한 리스너를 추가합니다. 리스너가 준비되면, 오버레이 폼을 보여줄 준비가 되었습니다.\n\n```js\n// DOM이 로드될 때까지 기다립니다\ndocument.addEventListener('DOMContentLoaded', async () => {\n  // Agora 이벤트 리스너 추가\n  addAgoraEventListeners()\n  // 로컬 미디어 버튼에 대한 리스너 추가\n  addLocalMediaControlListeners()\n  // 채널 참여 폼 가져오기 & 폼 제출 처리\n  const joinform = document.getElementById('join-channel-form')\n  joinform.addEventListener('submit', handleJoin)\n  // 오버레이 폼 보이기\n  showOverlayForm(true) \n})\n```\n\n<div class=\"content-ad\"></div>\n\n# 3D & 아바타 설정\n\n이 가이드의 선행 요건 중 하나는 ReadyPlayerMe의 3D 아바타입니다. ReadyPlayerMe는 Apple의 ARKit ARFaceAnchor 위치에 대한 이름 규칙을 준수하는 3D 파일을 제공합니다. 이러한 정의는 산업 표준이며 MediaPipe의 출력과 일치합니다.\n\n코드로 돌아와서, 사용자가 \"참가\" 버튼을 클릭하면 ThreeJS 씬을 초기화하고 `canvas`를 localUserContainer에 추가합니다.\n\n```js\n// 로컬 사용자 컨테이너 div 가져오기\nconst localUserContainer = document.getElementById('local-user-container')\n\n// 씬을 만들고 canvas를 localUserContainer에 추가\nconst { scene, camera, renderer } = await initScene(localUserContainer)\n```\n\n<div class=\"content-ad\"></div>\n\n새로 생성된 씬을 사용하여 glbURL을 통해 사용자의 ReadyPlayerMe 아바타를 로드하세요. glbURL에는 URL 매개변수가 추가됩니다. 이는 blend shapes가 ReadyPlayerMe에서 제공하는 기본 .glb 파일의 일부가 아니기 때문입니다. 이러한 매개변수는 ReadyPlayerMe RESTful API의 일부이며, 아바타용입니다.\n\n3D 아바타를 로드한 후, 해당 씬 그래프를 탐색하고 모든 노드를 사용하여 빠르게 headMesh에 액세스할 수 있는 객체를 생성합니다.\n\n```js\n// glb url에 url 매개변수 추가 - morphTargets를 사용하여 ReadyPlayerMe 아바타 로드\nconst rpmMorphTargetsURL = glbURL + '?morphTargets=ARKit&textureAtlas=1024'\nlet nodes\n// morph targets가 포함된 GLB 로드\nconst loader = new GLTFLoader()\nloader.load(rpmMorphTargetsURL, \n  async (gltf) => {\n  const avatar = gltf.scene\n  // 아바타 노드 그래프 작성\n  nodes =  await getGraph(avatar)\n  const headMesh = nodes['Wolf3D_Avatar']\n  // 위치 조정\n  avatar.position.y = -1.65\n  avatar.position.z = 1\n  \n  // 씬에 아바타 추가\n  scene.add(avatar)\n},\n(event) => {\n  // 로딩 세부 정보 출력\n  console.log(event)\n})\n```\n\n씬이 초기화되는 시점과 3D 아바타가 로드되는 시점 간의 지연 시간을 고려하기 위해, 3D 아바타가 씬에 추가되기 전에 모델이 로드 중임을 사용자에게 알리기 위해 로딩 애니메이션을 표시하는 것이 좋은 실천법입니다.\n\n<div class=\"content-ad\"></div>\n\n```js\n// 로딩 애니메이션 표시\nconst loadingDiv = document.createElement('div')\nloadingDiv.classList.add('lds-ripple')\nloadingDiv.append(document.createElement('div'))\nlocalUserContainer.append(loadingDiv)\n\n/* loader.load - 성공 시 콜백 */\nloadingDiv.remove() // 로딩 스피너 삭제\n```\n\n# Agora로 비디오 엘리먼트 초기화\n\n<img src=\"/assets/img/2024-06-20-AddRealtime3DAvatarstoAgoraLiveVideoStreams_0.png\" />\n\n카메라 액세스를 받고 비디오 및 오디오 트랙을 만드는 데 Agora를 사용합니다. 비디오 엘리먼트의 소스로 카메라의 비디오 트랙을 사용할 것입니다. 더 자세한 설명이 필요하면 Agora를 사용하여 사용자 정의 비디오 엘리먼트를 사용하는 방법에 대한 내 안내서를 확인해주세요. \n\n\n<div class=\"content-ad\"></div>\n\n```js\n// 로컬 마이크와 카메라 초기화\nawait initDevices('music_standard', '1080_3')\n// 비디오 요소 생성\nconst video = document.createElement('video')\nvideo.setAttribute('webkit-playsinline', 'webkit-playsinline');\nvideo.setAttribute('playsinline', 'playsinline');\n// 카메라 트랙을 사용하여 새 MediaStream 생성하고 비디오의 소스로 설정\nvideo.srcObject = new MediaStream([localMedia.video.track.getMediaStreamTrack()])\n```\n\n# 미디어파이프 설정\n\n얼굴과 제스처를 인식하기 전에, 미디어파이프의 컴퓨터 비전 기술을 위한 최신 웹어셈블리(WASM) 파일을 먼저 다운로드해야 합니다. 이 파일들은 FaceLandmarker 작업을 설정하는 데 필수적입니다. FaceLandmarker는 비디오 스트림에서 사용자 얼굴의 특정 \"관심 지점\"을 식별하는 컴퓨터 비전 알고리즘입니다. 이 정밀도는 인공지능이 얼굴 특징을 효과적으로 추적할 수 있게 합니다.\n\n컴퓨터 비전에서 작업을 실행하는 것은 AI에 요청을 보내고, AI가 자신감 수준인 예측을 반환하는 것을 의미합니다. 우리는 각 비디오 프레임에 대해 이 작업을 계속 반복적으로 실행할 것이며, 이를 predictionLoop이라고 이름 붙였습니다.\n\n\n<div class=\"content-ad\"></div>\n\n얼굴 랜드마크 구성에서는 FaceLandmarker를 설정하여 두 가지 중요한 데이터 유형을 생성합니다: outputFacialTransformationMatrixes와 outputFaceBlendshapes: true. outputFacialTransformationMatrixes는 얼굴 위치, 회전 및 크기의 추정을 제공하여 머리 움직임을 추적하는 데 필수적입니다. 반면 outputFaceBlendshapes는 즉시 명확하지 않을 수 있습니다. 이는 블렌드 모양 또는 모양 키프라는 3D 모델링 기술을 포함합니다. 이를 통해 3D 메시가 \"닫힘\" (0으로 표시)에서 \"열림\" (1로 표시)으로 부드럽게 전환할 수 있습니다. 이 방법은 모든 가능한 얼굴 움직임을 모델링하는 것을 피할 수 있어 효율적입니다. 대신 렌더링 엔진이 이러한 상태를 보간합니다.\n\n이러한 설정은 머리 회전 및 위치를 모니터링하기 위해 변환 행렬을 사용하고, 블렌드 모양 예측은 ARKit 표준 블렌드 모양에 대해 0에서 1 범위를 제공하여 52가지 다른 얼굴 움직임을 다룹니다.\n\n```js\n// 미디어파이프 비전 작업 초기화\nconst faceLandmarker = await initVision()\n\n// 미디어파이프 비전 초기화\nconst initVision = async () => {\n  // 최신 비전 WASM 파일 로드\n  const vision = await FilesetResolver.forVisionTasks('https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm')\n  // 얼굴 랜드마크 트래커 구성\n  const faceLandmarker = await FaceLandmarker.createFromOptions(\n    vision, { \n      baseOptions: {\n        modelAssetPath: `https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task`,\n      },\n      outputFaceBlendshapes: true,\n      outputFacialTransformationMatrixes: true,\n      runningMode: 'VIDEO'\n    })\n  return faceLandmarker\n}\n```\n\n# 컴퓨터 비전 예측 루프\n\n<div class=\"content-ad\"></div>\n\nfaceLandmarker와 `video/`을 설정하고 나면, 우리는 모든 비디오 프레임에 MediaPipe의 컴퓨터 비전 작업을 실행하는 예측 루프를 시작할 수 있습니다. 예측 결과를 반환하면 facialTransformationMatrixes에 접근할 수 있어 headRotation을 계산할 수 있게 됩니다. 또한, 예측 결과는 얼굴 메시의 블렌드 형태에 대한 추정 가중치를 제공합니다.\n\n```js\nvideo.addEventListener(\"loadeddata\", () => {\n  video.play()                            // 비디오 재생 시작\n  initPredictLoop(faceLandmarker, video)  // 얼굴 랜드마킹 예측 루프 시작\n})\n\nconst initPredictLoop = (faceLandmarker, video) => {\n  // 스트림 재생 시간을 추적하는 플래그\n  let lastVideoTime = -1\n  // 예측 루프\n  const predict = () => {\n    // 타임스탬프 생성\n    const timeInMs = Date.now()\n    // 비디오 재생 중일 때\n    if (lastVideoTime !== video.currentTime) {\n      lastVideoTime = video.currentTime\n      // 비디오 프레임에서 얼굴을 감지하는 비전 작업 실행\n      const result = faceLandmarker.detectForVideo(video, timeInMs)\n      // 얼굴 1에 대한 얼굴 매트릭스 변환 정보 가져오기\n      const faceMatrix = result.facialTransformationMatrixes\n      if (faceMatrix && faceMatrix.length > 0) {\n        const matrix = new THREE.Matrix4().fromArray(faceMatrix[0].data)\n        headRotation =  new THREE.Euler().setFromRotationMatrix(matrix)\n      }\n      // 얼굴 1에 대한 블렌드 형태 예측 가져오기\n      const blendShapePredictions = result.faceBlendshapes\n      if (blendShapePredictions && blendShapePredictions.length > 0){\n        blendShapes = blendShapePredictions[0].categories\n      }\n    }\n    // 모든 프레임 업데이트에서 예측하기\n    requestAnimationFrame(predict)\n  }\n  // 루프 시작\n  requestAnimationFrame(predict)\n}\n```\n\n# 컴퓨터 비전 + 3D 아바타\n\nThreeJS 씬을 렌더링하려면 렌더 루프를 사용합니다. 렌더 루프를 초기화할 때, 예측 루프의 결과를 사용하여 머리 회전과 블렌드 형태 강도를 업데이트하는 함수를 전달할 것입니다.\n\n<div class=\"content-ad\"></div>\n\n```js\r\n// 렌더 루프 만들기\nconst initRenderLoop = (scene, camera, renderer, sceneUpdates) => {\n  const render = (time) => {\n    // 씬 업데이트하기\n    sceneUpdates(time)\n    // 카메라를 사용하여 씬 렌더링\n    renderer.render(scene, camera)\n    // 렌더를 호출 스택에 추가\n    requestAnimationFrame(render)\n  }\n  // 렌더 루프 시작\n  requestAnimationFrame(render)\n}\n\ninitRenderLoop(scene, camera, renderer, (time) => {\n  // 노드 또는 헤드 회전이 null이면 빨리 반환하기\n  if(!nodes || !headRotation) return\n  // 헤드, 목, 어깨 본에 회전 데이터 적용하기\n  nodes.Head.rotation.set(headRotation.x, headRotation.y, headRotation.z)\n  nodes.Neck.rotation.set(headRotation.x/2, headRotation.y/2, headRotation.z/2)\n  nodes.Spine1.rotation.set(headRotation.x/3, headRotation.y/3, headRotation.z/3)\n  // 블렌드 쉐이프 반복하기\n  blendShapes.forEach(blendShape => {\n    const headMesh = nodes.Wolf3D_Avatar\n    const blendShapeIndex = headMesh.morphTargetDictionary[blendShape.categoryName]\n    if (blendShapeIndex >= 0) {\n      headMesh.morphTargetInfluences[blendShapeIndex] = blendShape.score\n    }\n  })\n})\r\n```\n\n기본적으로 입 움직임이 표정을 과장할 때만 보입니다. 말할 때 사람 얼굴이 일반적으로 움직이는 방식은 아닙니다. 이를 보상하기 위해 블렌드 쉐이프 점수를 과장하여 아바타의 입이 더 반응적으로 보이도록 할 수 있습니다.\n\n타겟으로 정할 모든 블렌드 쉐이프를 나열하고 기본 점수에 대한 배수를 설정합시다. 입이 움직이지 말아야 할 때나 과장해서 나타내지 않도록, 상한선과 하한선을 설정해보겠습니다.\n\n```js\r\n// 입 블렌드 쉐이프\nconst mouthBlendShapes = [\n  'mouthSmile_L', 'mouthSmile_R', 'mouthFrown_L','mouthFrown_R',\n  'mouthOpen', 'mouthPucker','mouthWide','mouthShrugUpper','mouthShrugLower',\n]\n// 입 움직임 강조를 위한 배수\nconst exagerationMultiplier = 1.5\nconst threshold ={ min: 0.25, max: 0.6}\r\n```\n\n<div class=\"content-ad\"></div>\n\n멀티플라이어를 적용하려면 mouthBlendShapes 목록에서 특정 키를 확인해야 합니다. 이 작업은 점수를 적용하는 루프 내에서 처리할 수 있습니다. mouth 블렌드 모양을 식별할 때 동시에 그것들이 임계값 내에 있는지도 확인할 것입니다.\n\n```js\n// 블렌드 모양 반복\nblendShapes.forEach(blendShape => {\n  const headMesh = nodes.Wolf3D_Avatar\n  const blendShapeIndex = headMesh.morphTargetDictionary[blendShape.categoryName]\n  if (blendShapeIndex >= 0) {\n    // mouth 블렌드 모양에 대한 점수를 과장\n    if (mouthBlendShapes.includes[blendShape.categoryName] && blendShape.score > threshold.min && blendShape.score < threshold.max) {\n      blendShape.score *= exagerationMultiplier\n    }\n    headMesh.morphTargetInfluences[blendShapeIndex] = blendShape.score\n  }\n})\n```\n\n# ThreeJS에서 Agora 비디오 스트림으로\n\n![이미지](/assets/img/2024-06-20-AddRealtime3DAvatarstoAgoraLiveVideoStreams_1.png)\n\n<div class=\"content-ad\"></div>\n\n렌더 루프는 3D 씬을 캔버스에 렌더링합니다. `canvas`에서 Agora로 씬을 전송하려면 captureStream을 생성하고 비디오 트랙을 사용하여 사용자 지정 비디오 트랙을 초기화하십시오.\n\n더 자세한 설명이 필요하시다면 캔버스 엘리먼트를 사용하여 Agora 비디오 트랙을 생성하는 방법을 안내하는 내 안내서를 확인해보세요.\n\n```js\n// 캔버스 가져오기\nconst canvas = renderer.domElement\n// 프레임 속도 설정\nconst fps = 30\n// captureStream 생성\nconst canvasStream = canvas.captureStream(fps)\n// 캔버스 스트림으로부터 비디오 트랙 가져오기\nconst canvasVideoTrack = canvasStream.getVideoTracks()[0]\n// canvasVideoTrack을 사용하여 사용자 지정 Agora 비디오 트랙 생성\nconst customAgoraVideoTrack = AgoraRTC.createCustomVideoTrack({\n  mediaStreamTrack: canvasVideoTrack,\n  frameRate: fps\n})\nlocalMedia.canvas.track = customAgoraVideoTrack\nlocalMedia.canvas.isActive = true\n// 캔버스 트랙을 채널에 게시\nawait client.publish([localMedia.audio.track, localMedia.canvas.track])\n```\n\n로컬 클라이언트가 채널에 참여하면, 이전에 설정한 이벤트 리스너가 동작합니다. 사용자가 채널에 참여할 때마다 그들의 비디오 스트림이 #container에 표시됩니다.\n\n<div class=\"content-ad\"></div>\n\n# 테스트\n\nVite를 사용하고 있으므로 로컬에서 테스트하기 쉽습니다. 터미널에서 프로젝트 폴더로 이동하고 npm을 사용하여 코드를 실행하세요.\n\n```js\nnpm run dev\n```\n\n로컬 서버가 실행되면 코드를 테스트할 시간입니다. ReadyPlayer.Me로 이동하여 아바타의 URL을 복사하세요. URL을 양식에 붙여넣고 \"가입\"을 클릭하세요.\n\n<div class=\"content-ad\"></div>\n\n채널에서 여러 사용자를 시뮬레이션하려면 첫 번째 탭에서 URL을 복사한 다음 다른 브라우저 창을 열고 URL을 붙여넣으세요. URL을 복사하는 것은 동일한 채널에 참여할 수 있도록 돕습니다. 두 창을 사용하면 각 캔버스가 보이게 됩니다. 이는 브라우저가 웹사이트의 탭이 초점을 잃으면 AnimationFrame 요청을 일시 중지하기 때문에 중요합니다.\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*TVz9rtnQHNU4yDco9nH6BQ.gif)\n\n여러 기기로 테스트하려면 프로젝트를 안전한 https 연결로 실행해야 합니다. 이를 설정하려면 두 가지 옵션이 있습니다: 로컬 장치에 사용자 정의 SSL 인증서를 구성하거나 ngrok와 같은 서비스를 사용하여 로컬 기기에서 나가는 터널을 생성하고 https URL을 제공합니다.\n\n# 끝.\n\n<div class=\"content-ad\"></div>\n\n여기에 Agora의 Video SDK를 사용하여 MediaPipe의 컴퓨터 비전을 활용하여 사용자 정의 3D 아바타를 만드는 방법이 있습니다. 웨비나, 대화형 교육 플랫폼 또는 라이브 비디오가 핵심 역할을 하는 다른 어플리케이션을 위해 이 예시는 훌륭한 기반입니다. 이 코드를 조정하고 사용하여 현실을 확장하는 더 복잡한 AI 기반 기능을 만들어 보세요.\n\n이 안내서는 Agora의 Raw Video와 Custom Video와 같은 두 가지 고급 비디오 주제를 다룹니다. Agora Video for Web 문서에서 고급 비디오 주제를 더 깊이 파고들어 보세요.","ogImage":{"url":"/assets/img/2024-06-20-AddRealtime3DAvatarstoAgoraLiveVideoStreams_0.png"},"coverImage":"/assets/img/2024-06-20-AddRealtime3DAvatarstoAgoraLiveVideoStreams_0.png","tag":["Tech"],"readingTime":15},{"title":"지금 언급한 콘텐츠와 관련하여 다음과 같이 번역할 수 있습니다 아주 똑똑하지만 노력을 하지 않는 개발자 대처 방법어떻게 하면 좋을까요 이제 한번 살펴보겠습니다","description":"","date":"2024-06-20 04:17","slug":"2024-06-20-HowDoYouDealwithaVerySmartDeveloperWhoIsntWorkingHard","content":"\n\n## 프로그래밍 의견\n\n![이미지](/assets/img/2024-06-20-HowDoYouDealwithaVerySmartDeveloperWhoIsntWorkingHard_0.png)\n\n만약 텔레비전을 조립하는 조선라인에 있다고 상상해보세요. 예를 들어, 누군가가 몇 분동안 자신의 작업을 멈추면 곧바로 제품 생산량이 줄어들게 됩니다. 이는 돈으로 환산하면 제품 제작 비용이 증가하는 것을 의미합니다.\n\n불행히도, 이러한 관리 방식으로 소프트웨어 개발자도 관리하려고 합니다. 그리고 이때 이러한 종류의 질문들이 나오게 됩니다. 소프트웨어 개발자의 작업은 더 많은 숙련이 필요한데, 모든 종류의 숙련된 작업에서는 좋은 것을 만들어내는 능력이 항상 시간과 경험에 의존적입니다.\n\n<div class=\"content-ad\"></div>\n\n경험이 적을수록 품질이 좋은 것을 만드는 데 걸리는 시간이 더 오래 걸리고, 경험이 많을수록 품질이 좋은 것을 만드는 데 걸리는 시간이 덜 걸립니다. 이것을 조각을 만드는 것에 비유할 수 있겠네요. 이에 자질을 비교해보면, 보스나 관리자로서 결과물을 평가하는 것이 더 중요합니다. 빠르게 행동한다면, 1시간이건 1일이건 상관없죠.\n\n그것은 비용과 대조되는데, 우리가 예산을 갖고 있다면 일정 시간보다 더 오래 걸리게 허용할 수 없죠. 하지만 그것은 개발자가 하는 것이 아니라 관리자의 역할입니다. 개발자는 문제나 작업을 받아서 얼마나 걸리는지 말하고 그 시간 안에 작업이 완료될 것을 확약해야 합니다. 관리자가 그것이 실행 가능한지 여부를 결정하는 사람입니다.\n\n프로젝트 리더 직책에 대한 면접에서, 어떻게 일할 것인지에 대해 물어보았습니다. 제 경우, 프로세스를 실행하고 인프라를 구축하며 소프트웨어 개발자와 제 자신의 삶을 더 쉽게 만들기 위해 훈련합니다.\n\n인터뷰어는 나의 의도를 완벽하게 요약하고 이해한 것을 알려주었지만 한 가지 문제가 있었습니다. 언젠가 내일은 모양새가 되고 노력이 줄어들 것이라고 깨달았다고 합니다.\n\n<div class=\"content-ad\"></div>\n\n일단 그를 웃게 했다. 정확히 그의 말대로, 그 프로세스를 실행한 후, 하루 중 대부분의 시간을 아무것도 하지 않게 될 것이라고 한다. 하루 중 대부분을 아무것도 안 하게 되는 것이 문제라고 했다. 비록 현재의 팀보다 4배 더 효율적이고 생산적인 팀을 만들어낼 것이라고 해도 말이다.\n\n노력보다 생산성을 중요시하는 것이 문제다. 상사들은 늦게까지 남아 있는 사람, 주말에 출근하는 사람, 자녀의 생일을 놓치는 사람, 병원에 어머니와 같이 출근하는 사람, 5년간 휴가를 안 낸 사람들을 더욱 높이 평가하는 경향이 있다. 8시에서 5시에 출퇴근하는 사람을 아주 추하게 여기는 것이다.\n\n생산성이 전부다. 그러한 재능 있는 사람을 갖게 되면, 진짜 생산성을 기준으로 측정하는 법을 배워야 한다: 얼마나 빨리 작업을 끝내는지, 코드에서 버그가 얼마나 생기는지, QA가 티켓을 얼마나 자주 반납하는지 등을 통해.\n\n반대 특성을 가진 사람을 가지고 있는 것은 매우 비용이 많이 든다. 그들이 일을 많이 하고 있을지도 모르지만, 제품을 계속 실패 없이 전달할 수 없다면, 고객이 요청하지 않은 것을 하게 된다. 천 번을 설명해야 할지도 모른다. 그렇다, 비용이 많이 들고, 이것은 팀이 가진 문제다.\n\n<div class=\"content-ad\"></div>\n\n물론, 그렇다고 해서 당신이 질서 정연하거나 규칙을 어기는 허락을 받지 않아야 한다는 뜻은 아닙니다. 대신 그 대신, 그의 생산성을 유지하는 방법을 찾는 것이 여러분의 역할이 될 것입니다 (바쁘다는 것과는 다릅니다).\n\n# Stackademic 🎓\n\n마지막까지 읽어주셔서 감사합니다. 떠나시기 전에:\n\n- 박수를 보내고 작성자를 팔로우 해주세요! 👏\n- 저희를 팔로우하세요 X | LinkedIn | YouTube | Discord\n- 다른 플랫폼 방문하기: In Plain English | CoFeed | Differ\n- Stackademic.com에서 더 많은 콘텐츠를 확인하세요","ogImage":{"url":"/assets/img/2024-06-20-HowDoYouDealwithaVerySmartDeveloperWhoIsntWorkingHard_0.png"},"coverImage":"/assets/img/2024-06-20-HowDoYouDealwithaVerySmartDeveloperWhoIsntWorkingHard_0.png","tag":["Tech"],"readingTime":2},{"title":"Astro 기반 문서에 다중 버전 지원 추가하기","description":"","date":"2024-06-20 04:15","slug":"2024-06-20-AddingMulti-VersionSupporttoYourAstro-basedDocumentation","content":"\n\n## 같은 문서 안에 여러 버전을 가질 수 있는 방법은 무엇인가요?\n\n![Image](/assets/img/2024-06-20-AddingMulti-VersionSupporttoYourAstro-basedDocumentation_0.png)\n\n현재 Astro는 매우 인기가 높습니다. 저에게 물어봐도 마찬가지에요. 이 프레임워크를 사용하면 개발자들이 유연하고 강력한 정적 웹사이트를 만들 수 있습니다.\n\n다른 곳에서 이주할 때 여러 렌더링 라이브러리를 통합할 수 있는 능력은 채택을 도와 줍니다.\n\n<div class=\"content-ad\"></div>\n\n그리고 문서 사이트를 만드는 것은 아마도 지금 이 시점에서는 사소한 문제일지 모르지만, 최근에 해결해야 했던 문제인 문서 사이트에 다중 버전 지원을 추가하는 방법에 대해 다루고 싶었습니다.\n\n그러니 시작해 봅시다.\n\n# 문제\n\n문서 사이트를 구축하는 것은 많은 페이지로 이루어진 정적 사이트를 구축하는 것 이상을 의미하지 않습니다.\n\n<div class=\"content-ad\"></div>\n\n용하기 쉬우면 Astro를 사용하면 간단합니다.\n\n그러나 제품 버전이 변경될 때 페이지가 변경되면 어떻게 됩니까?\n\n그럴 때 해결해야할 두 가지 주요 문제가 있습니다:\n\n- 쉬운 문제: 라우팅 프로세스에 버전을 추가합니다. 버전 간에 전환할 수 있어야하며, Astro는 파일 경로 기반의 라우팅을 사용하므로 각 버전에 대한 폴더를 만들어야 합니다.\n- 어려운 문제: 현재 버전에 맞게 모든 상대적 링크를 처리하고 내부 탐색을 일관되게 유지해야 합니다 (현재 선택된 버전에 따라 동일한 링크가 다른 버전으로 리디렉트되어야 합니다).\n\n<div class=\"content-ad\"></div>\n\n이 문제들은 사소해 보일 수 있지만 쉽게 해결되지 않습니다.\n\n두 기능을 모두 구현하는 방법을 살펴보겠습니다.\n\n# 문제 해결\n\n해결해야 할 문제는 두 가지이므로 한 가지씩 해결해 봅시다.\n\n<div class=\"content-ad\"></div>\n\n## 라우팅 프로세스에 버전 추가하기\n\n가장 쉬운 방법은 /docs/getting-started와 같은 경로에서 /docs/1.1.0/getting-started로 이동하는 것을 확인하는 것입니다.\n\n이렇게 하면 해당 페이지의 내용으로 사용할 getting-started.mdx 파일을 여전히 참조할 수 있고, 해당 파일에 접근하려면 1.1.0이라는 폴더 안에 넣어야 합니다.\n\n이것은 단순한 것으로 보이네요. 해야 할 일은 폴더 구조를 변경하는 것뿐입니다. 따라서 이렇게 변경해야 합니다:\n\n<div class=\"content-ad\"></div>\n\n```js\n/\n |_ docs\n     |_ v1.0.0\n     |  |_ getting-started.mdx\n     |\n     |_ v2.0.0\n        |_ getting-started.mdx\n```\n\n위와 같이 변경해 주세요. 변경 후에 Astro가 콘텐츠를 찾을 수 있도록 알려주었으며, 이제 Astro는 제대로 동작할 것입니다. 이제 npm run build를 실행하면 모든 것이 제대로 빌드되지만 새로운 폴더에 생성될 것입니다.\n\n<div class=\"content-ad\"></div>\n\n하지만 아직 끝나지 않았어요. 이것은 1단계의 반만이에요. 우리는 아직 버전 지원의 중요한 부분을 놓치고 있어요. 바로 버전 전환기에요.\n\n사용자가 버전을 변경할 수 있는 방법을 추가해야 해요. 그래서 그 코드를 살펴보도록 해요:\n\n원하는 곳에 추가할 수 있는 간단한 컴포넌트에요. 저는 대개 문서 사이트에 추가하는 헤더에 추가하는 것을 좋아해요. 하지만 당신이 원하는 대로 사용할 수 있어요.\n\n코드를 보면, 컴포넌트는 VERSIONS 배열 내에 나열된 버전을 기반으로 버전 드롭다운을 그려줄 거에요. 거기서 표시할 레이블과 경로를 가져올 거에요.\n\n<div class=\"content-ad\"></div>\n\n최신 버전에서는 경로가 없다는 것을 주목해주세요. 이렇게 하면 최신 버전을 루트 폴더 아래의 docs 폴더에 유지하고, 버전이 명시된 경우에만 버전 폴더를 사용할 수 있게 됩니다.\n\n그런 다음 JavaScript 코드의 일부로 selectCurrentVersion 함수가 실행됩니다. 이 함수는 URL에서 버전 번호를 가져와 올바른 옵션 요소를 선택합니다.\n\n마지막으로 드롭다운에서 onChange 이벤트가 발생하면 updateLocation 함수를 호출합니다. 이 함수는 선택한 버전으로 현재 경로 내의 현재 버전을 덮어씁니다. 그런 다음 사용자를 새 URL로 리디렉션합니다.\n\n그런데 잠깐, 이제 새 버전을 릴리스할 때마다 문서 링크를 모두 확인하고 사용자가 버전 간을 이동하는 것을 방지하기 위해 내부 링크를 업데이트해야 한다는 말인가요?\n\n<div class=\"content-ad\"></div>\n\n그렇게하면 정말 귀찮을 텐데, 특히 문서가 충분히 큰 경우 말이죠. 그래서 이에 대해 처리할 방법을 찾아보겠습니다.\n\n## 모든 상대 링크 처리\n\n문서에 추가하는 하드코딩된 경로에 실제 문서 버전을 유지하는 것을 피할 방법을 찾아야 합니다.\n\n왜냐하면 그렇게 한다면 각 새 버전을 릴리스할 때마다 최신 버전의 문서를 복제해야 하기 때문에 매번 검색 및 교체 프로세스를 실행해야 합니다.\n\n<div class=\"content-ad\"></div>\n\n그리고 우리가 그것을 잊어버리거나 어떠한 이유로 인해, 검색 패턴이 모든 URL을 포착하지 못하면, 결함이 있는 문서 사이트가 공개될 수 있습니다.\n\n우리는 항상 현재 버전을 생각하고, 대안 버전의 문서가 없는 것처럼 다른 섹션에 링크를 걸어야 한다는 방법을 찾아야 합니다.\n\n내가 생각해낸 해결책은 브라우저에서 URL을 직접 수정하는 스크립트를 추가하는 것이었습니다:\n\n그 스크립트를 내 메인 레이아웃 파일의 하단에 넣었습니다. 그렇게 하면 컨텐츠가 로드될 때 스크립트가 실행됩니다.\n\n<div class=\"content-ad\"></div>\n\n해당 코드는 모든 링크를 실행하고, 사이트 도메인 내의 장소로 리디렉션하는 링크를 찾습니다 (이상적으로 \"docs.yourdomain.com\"과 같은 것) 그 중에서만 현재 버전이 있는 새 링크로 변경합니다.\n\n다시 말해, /docs/getting-started와 같은 상대적 링크를 가져와 현재 선택된 버전에 맞게 /docs/v1.0.0/getting-started로 동적으로 변환합니다. 이렇게하면 모든 상대적 링크 (내비게이션에 사용되는 링크)가 현재 선택된 버전에 자동으로 맞춰집니다.\n\n그게 전부에요. Astro는 정적 사이트에 JavaScript를 추가하고 컴포넌트를 만들 때 매우 유연성을 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n이 예제들은 두 가지 다른 사용 사례를 보여줍니다. 하나는 동적 부분이 있는 컴포넌트가 생성될 때이며, 서버에서 드롭다운이 렌더링되더라도 여전히 작동하도록하기 위해 추가적인 JS 코드를 추가해야 합니다.\n\n다른 한편으로, 모든 서버 사이드 렌더링된 링크는 동적으로 업데이트되어야 합니다(사실 내부 네비게이션만 해당됩니다), 그래서 해당 작업을 수행하는 스크립트를 페이지에 추가했습니다. 우리는 다른 UI 라이브러리를 사용할 필요가 없었습니다.\n\n이러한 유형의 문제를 이전에 마주쳤나요? 그 문제를 어떻게 해결했나요?\n\n# 레고처럼 재사용 가능한 컴포넌트로 앱을 개발하세요\n\n<div class=\"content-ad\"></div>\n\n\n![image](/assets/img/2024-06-20-AddingMulti-VersionSupporttoYourAstro-basedDocumentation_1.png)\n\nBit’s open-source tool helps over 250,000 developers build apps with components.\n\nEasily turn any UI, feature, or page into a reusable component — and share it across your applications. Collaborate more efficiently and build faster.\n\n→ Learn more\n\n\n<div class=\"content-ad\"></div>\n\n앱을 컴포넌트로 분리하여 앱 개발을 쉽게 만들고, 원하는 작업을 위한 최상의 경험을 즐기세요:\n\n## → 마이크로 프론트엔드\n\n## → 디자인 시스템\n\n## → 코드 공유 및 재사용\n\n<div class=\"content-ad\"></div>\n\n## → Monorepo\n\n# Learn more","ogImage":{"url":"/assets/img/2024-06-20-AddingMulti-VersionSupporttoYourAstro-basedDocumentation_0.png"},"coverImage":"/assets/img/2024-06-20-AddingMulti-VersionSupporttoYourAstro-basedDocumentation_0.png","tag":["Tech"],"readingTime":5}],"page":"38","totalPageCount":154,"totalPageGroupCount":8,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true}