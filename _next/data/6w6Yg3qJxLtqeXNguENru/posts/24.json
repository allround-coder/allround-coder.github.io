{"pageProps":{"posts":[{"title":"JavaScript Promise 제대로 이해하고 넘어가자","description":"","date":"2024-05-17 03:20","slug":"2024-05-17-JavaScriptPromisesDemystifiedTheOnlyGuideYoullNeedPart1","content":"\n\n\n![이미지](/assets/img/2024-05-17-JavaScriptPromisesDemystifiedTheOnlyGuideYoullNeedPart1_0.png)\n\n자바스크립트를 사용하면 언젠가는 프로미스에 직면하게 될 것입니다. 프로미스는 자바스크립트에서 비동기 프로그래밍의 핵심입니다. 실시간 데이터는 모두 프로미스를 사용하여 처리됩니다. 프론트엔드 개발자든 백엔드 개발자든, 이 개념을 이해하는 것은 원활한 자바스크립트 애플리케이션을 만드는 데 중요합니다. 이 블로그 포스트에서는 프로미스에 대해 깊게 들어가보고 다른 곳을 찾아볼 필요가 없도록 이해해보겠습니다.\n\nMDN 웹 문서에는 다음과 같이 설명되어 있습니다:\n\n'프로미스 객체는 비동기 작업의 최종 완료(또는 실패)와 그 결과 값의 대기 시간을 나타냅니다.'\n\n\n<div class=\"content-ad\"></div>\n\n상기 문장을 더 잘 이해하기 위해 두 친구의 예를 들어보겠습니다. 첫 번째 친구가 두 번째 친구에게 돈을 빌려주고, 두 번째 친구는 한 달 후에 돈을 돌려줄 것을 약속합니다. 이제 두 가지 경우의 수가 있습니다. 두 번째 친구가 약속대로 돈을 돌려주거나, 두 번째 친구가 돈을 돌려주기를 거절할 수 있습니다.\n\n어떤 경우에도 한 달 후에는 결과가 나올 것입니다. 그 점은 확실합니다. 이것이 JavaScript에서 약속이 작동하는 방식입니다. 약속은 응답을 보장합니다: 성공 또는 실패 중 하나가 될 것이지만, 반드시 응답을 받을 수 있습니다.\n\n약속에 따라, 성공적인 해결에 대해 '이행(resolve)'이라고 하고, 실패한 해결에 대해 '거부(rejected)'라고 합니다. 따라서 총 세 가지 상태로 약속을 나타낼 수 있습니다:\n\n- pending: 초기 상태, 이행되지도 거절되지도 않은 상태.\n- fulfilled: 작업이 성공적으로 완료된 상태.\n- rejected: 작업이 실패한 상태.\n\n<div class=\"content-ad\"></div>\n\n약속을 어떻게 만들 수 있는지 살펴봅시다.\n\n```js\nconst myPromise = new Promise((resolve, reject) => {\n  let a = true; // 여기서 일반적으로 일부 외부 호출을 수행합니다.\n  if (a) {\n      setTimeout(() => {\n      resolve(\"foo\");\n    }, 1000);\n  } else {\n    setTimeout(() => {\n        reject(\"foo\");\n      }, 1000);\n  }\n});\n```\n\n기본적인 약속은 이렇게 보입니다. 외부 호출을 시뮬레이션하기 위해 setTimeout 함수를 사용했는데, 여기에 호출에 1초의 지연이 추가됩니다. 조건이 성공하면 resolve가 반환되고 실패하면 reject가 반환됩니다.\n\n약속에 대해 추가 조치를 취하려면 연결된 세 가지 메서드가 있습니다.\n\n<div class=\"content-ad\"></div>\n\n- then: 이 방법은 성공적인 처리의 응답을 받기 위해 프로미스에서 사용됩니다.\n- catch: 이 방법은 거절된 경우 프로미스에서 오류를 받기 위해 사용됩니다.\n- finally: 응답에 관계없이 어떤 작업을 수행하고 싶다면, 이를 사용합니다.\n\n이러한 방법은 모두 프로미스를 반환하며, 데이터를 계속 전달하고 체이닝할 수 있습니다.\n\n```js\nmyPromise\n .then((response) => {\n   // 성공한 경우에 대한 작업 수행\n  })\n  .catch((error) => {\n   // 거절된 경우에 대한 작업 수행\n  })\n  .finally(() => {\n   // 각각의 작업 후에 수행할 작업 수행\n  })\n```\n\n이제 프로미스가 더 이상 시작할 때보다 훨씬 더 의미가 있길 바랍니다. 다가오는 블로그에서 여러 프로미스를 호출하고 그러한 상황을 처리하는 방법, 콜백 지옥이 뭔지 그리고 어떻게 벗어날 수 있는지, 여러 프로미스를 처리하는 데 사용할 수 있는 방법 등을 알아볼 것입니다.\n\n<div class=\"content-ad\"></div>\n\n이 블로그 시리즈를 마치면 약속을 사용하는 데 훨씬 더 편안해지고 무엇이 일어나고 있는지 깊이 이해할 수 있을 거예요.\n\n끝까지 읽어 주셔서 감사합니다. 친구들과 함께 좋아요를 눌러 주시고 댓글을 남겨 주시고 공유해 주세요. 그래야 그들도 능숙해질 수 있으니까요. 함께 배우는 건 훨씬 더 재미있어요.\n\n좋은 하루 되세요!","ogImage":{"url":"/assets/img/2024-05-17-JavaScriptPromisesDemystifiedTheOnlyGuideYoullNeedPart1_0.png"},"coverImage":"/assets/img/2024-05-17-JavaScriptPromisesDemystifiedTheOnlyGuideYoullNeedPart1_0.png","tag":["Tech"],"readingTime":3},{"title":"2024년에 가장 인기 있는 최고의 자바 프로파일러 9가지","description":"","date":"2024-05-17 03:16","slug":"2024-05-17-9BestJavaProfilerstoUsein2024","content":"\n\n<img src=\"/assets/img/2024-05-17-9BestJavaProfilerstoUsein2024_0.png\" />\n\n요즘에는 제가 써오던 서드파티 리눅스 애플리케이션에서 내 애플리케이션이 메모리 누수를 일으켰을 것으로 생각되는 경우가 발생하여 메모리 부족 예외를 계속 받게 되었어요.\n\n그래서 서드파티 애플리케이션을 모니터링하기 위해 프로파일러를 시작하기로 결정했어요. 이 아이디어는 실행 중인 Java 프로세스에 프로파일러를 연결하고 할당 호출 트리 보기를 사용하여 호출되는 메서드 및 관련 클래스를 기록하는 것이었죠.\n\n도와줄 Java 프로파일러를 찾기 시작했을 때 여러 가지가 있음을 깨달았고, 그 중 YourKit을 시도하기로 결정했어요. YourKit은 인기 있는 강력한 프리미엄 Java 프로파일러로 Java 애플리케이션을 위해 설계되었답니다. 프로파일러 설정은 그동안 들었던 소문과는 달리 꽤 쉬웠어요.\n\n<div class=\"content-ad\"></div>\n\n프로파일러를 시작하여 어떤 애플리케이션이 내 앱을 느리게 만드는지 알아보려고 했어요. 도구가 정말 잠재력이 있는 것을 깨달았지만 문제가 어디인지 실제로 정확히 파악하는 데 많은 시간이 걸리고 정말 어렵다는 걸 깨달았어요. 데이터를 받은 후에는 호출 트리를 직접 살펴보고 결론을 내려야 해서 분석하기가 어려웠어요.\n\n![image](/assets/img/2024-05-17-9BestJavaProfilerstoUsein2024_1.png)\n\n최적화된 SQL 쿼리에 대한 이 글을 읽은 후 새로운 멋진 도구를 발견했다는 걸 기억했어요. 이 도구는 전통적인 의미의 프로파일러는 아니지만 관측 가능한 데이터를 분석할 수 있어 프로파일링 노력에 도움이 될 것 같았어요. Digma Continuous Feedback 도구가 프로파일러 결과를 분석하여 결론에 도달하고 프로파일러에서 무엇을 찾아야 하는지 도와줄 수 있을 것 같아요. 그래서 YourKit 프로파일러와 함께 Digma를 열었어요.\n\n이 블로그에서는 왜 프로파일러를 시작하기로 결정했는지, 자바 앱을 프로파일링하기에 적합한 프로파일러 목록, 그리고 Digma Continuous Feedback이 프로파일러의 데이터를 분석하고 결론을 도출하는 데 어떻게 도움이 되었는지를 공유할 거예요.\n\n<div class=\"content-ad\"></div>\n\n# 자바 프로파일러란?\n\n자바 프로파일러는 자바 애플리케이션의 성능을 측정하고 분석하는 도구입니다. 각 함수의 소요 시간, 메모리 사용량 및 함수 호출 빈도를 포함하여 프로그램 실행에 대한 데이터를 수집합니다.\n\n자바 프로파일링은 소프트웨어 애플리케이션에서 성능 병목 현상을 찾는 데 유용합니다. 프로파일러가 수집한 데이터를 분석하면, 코드에서 가장 주목할 만한 지연 또는 자원 소비에 책임 있는 부분을 식별할 수 있습니다. 이 데이터는 코드를 개선하고 성능을 향상시키며 자원 소비를 감소시킬 수 있습니다.\n\n그러므로 자바 프로파일러는 JVM 수준에서 자바 바이트 코드 구조와 작업을 확인하는 도구입니다. 이 프로그래밍 구조와 작업에는 객체 생성, 프로세스 반복(재귀적 함수 호출 포함), 메소드 실행, 스레드 실행 및 가비지 수집이 포함됩니다.\n\n<div class=\"content-ad\"></div>\n\n# Java Profiler 종류\n\n- 샘플링 프로파일러: 이러한 프로파일러는 주기적으로 실행 중인 프로그램의 스냅샷을 찍고 콜 스택을 분석하여 핫스팟을 식별합니다.\n\n- Instrumentation 프로파일러: 이러한 프로파일러는 프로그램의 코드를 수정하여 좀 더 자세한 성능 데이터를 수집합니다.\n\n# Java 프로파일러의 사용 사례\n\n<div class=\"content-ad\"></div>\n\nJava 프로파일링 도구는 기본적으로 세 가지 방법으로 사용할 수 있어요:\n\n성능 최적화: 개발자들은 Java 프로파일러를 사용하여 성능 문제를 일으키는 코드 부분을 파악할 수 있어요. 예를 들어 느린 함수 호출이나 높은 메모리 사용량 등이 있어요. 이 데이터를 활용하여 코드를 개선하여 성능을 향상시킬 수 있어요.\n\n메모리 관리: Java 프로파일러는 메모리 누수를 감지하는 데 도움이 될 수 있어요. 프로그램이 사용하지 않는 메모리를 해제하지 못할 때 발생하는 메모리 누수가 있어요. 이러한 누수로 인해 메모리가 부족해져 프로그램이 다운될 수 있어요. 개발자들은 메모리 누수를 파악하여 더 이상 필요하지 않은 메모리를 해제하도록 코드를 수정할 수 있어요.\n\n테스트: Java 프로파일러는 다양한 시나리오에서 프로그램 성능을 평가할 수 있어요. 예를 들어 다양한 입력 크기나 사용자 수를 고려한 테스트에 사용할 수 있어요. 이를 통해 프로그램이 출시되기 전에 잠재적인 성능 문제를 인식할 수 있어요.\n\n<div class=\"content-ad\"></div>\n\n# 자바 프로파일러는 어떻게 작동하나요?\n\nJVM은 자바 개발자가 실행 중인 JVM(Java Virtual Machine)에 에이전트를 연결할 수 있도록 합니다. 개발자가 JVM에 에이전트를 연결하면, JVM은 에이전트에게 클래스를 로드하기 전에 클래스를 제공합니다. 그런 다음, 에이전트는 클래스를 변환합니다. 에이전트는 어떤 클래스의 코드를 변경할 수 있습니다.\n\n자바 프로파일러는 기본적으로 에이전트입니다. 그들은 메소드의 시작과 끝에 계측 코드를 추가하여 해당 작업 시간을 추적합니다. 또한 모든 클래스의 생성자와 종료 메소드에 코드를 추가하여 사용된 메모리량을 추적합니다.\n\n자바에서 코드 프로파일링은 내장 도구와 제3자 도구를 포함한 다양한 도구를 통해 달성할 수 있습니다. 애석하게도 인기 있는 일부 도구는 다음과 같습니다:\n\n<div class=\"content-ad\"></div>\n\n- JVM 도구\n- Digma\n- VisualVM\n- YourKit\n- JProfiler\n- NetBeans Profiler\n- IntelliJ Profiler\n- Async Profiler\n- Arthas\n\nOpenTelemetry와 Java Flight Recorder (JFR)는 대부분의 경우를 커버합니다. 자동으로 instrumentation을 원하는 경우 OpenTelemetry Java 에이전트를 사용하거나 직접 instrumentation을 수행하려면 API만 사용하십시오.\n\n# 1. JVM 도구\n\n이 Java 프로파일링 도구는 표준 JDK와 함께 제공되어 별도의 설치나 설정이 필요하지 않습니다. 대략 다섯 가지가 있습니다: jstat, jmap, jcmp, jhat 및 hprof.\n\n<div class=\"content-ad\"></div>\n\na. jstat\n이 내장 명령줄 도구는 표준 JDK와 함께 제공되며 설치나 설정이 필요하지 않습니다. 명령줄을 통해 JVM 메모리, 힙 크기, 그리고 가비지 수집 활동을 모니터링하는 것은 매우 유익합니다.\n\n이 도구는 JVM의 기본으로 활성화된 내장 계측을 활용하여 JVM을 시작하는 데 특별한 명령이 필요하지 않은 가상 머신 식별자 (VMID)를 통해 대상 Java 프로세스를 식별합니다.\n\n다음은 jstat을 사용하는 세 가지 방법입니다:\n\n미리 정의된 성능 제약 조건을 사용하여 Java 프로그램을 실행합니다.\n\n<div class=\"content-ad\"></div>\n\n```js\njava -Xmx125m -Xms25m -Xmn15m -XX:PermSize=30m -XX:MaxPermSize=30m -XX:+UseSerialGC HelloWorld\n```\n\n아래 명령어를 사용하여 프로세스 ID를 얻을 수 있습니다.\n\n```js\nps aux | grep java\n```\n\nJVM Heap Memory 사용량을 모니터링하려면 터미널에서 jstat을 -gc 옵션과 함께 실행하세요.```\n\n<div class=\"content-ad\"></div>\n\n```js\njstat -gc 98132 17527\n```\n\n![이미지](/assets/img/2024-05-17-9BestJavaProfilerstoUsein2024_2.png)\n\nb. jmap\n\n이 명령줄 도구는 표준 JDK에 포함되어 있습니다. 라이브 VM 또는 코어 파일에 대한 메모리 관련 데이터(heap summary, java object heap histogram, class loader stats, finalization queue info, dump of Java heap in hprof binary format)를 표시합니다.\n\n<div class=\"content-ad\"></div>\n\n기본 구성 및 알고리즘을 분석하는 것은 특히 유익합니다.\n\n성능을 향상시키고 진단을 개선하기 위해 JDK 8부터 사용할 수 있는 새로운 유틸리티인 jcmd를 jmap 유틸리티 대신 사용하는 것을 제안합니다.\n\n터미널에서 jmap을 사용하는 방법은 다음과 같습니다.\n\njhsdb jmap –-heap `JAVA_PID`\n\n<div class=\"content-ad\"></div>\n\n해당 명령을 사용하여 힙 덤프(heap dump)를 생성할 수도 있어요.\n\njhsdb jmap — -dump:file=`FILE` `JAVA_PID`\n\nc. jcmp\n이 명령행 도구는 표준 JDK와 함께 제공되며 별도의 설치나 설정 절차가 필요하지 않아요. JVM에 진단 명령을 보내는 데 사용됩니다.\n\n<div class=\"content-ad\"></div>\n\njcmd `JAVA_PID` GC.heap_dump filename=`FILE`\n\n- jhat\n\n이 명령줄 도구는 표준 JDK에 미리 설치되어 있으며 설치나 설정이 필요하지 않습니다. 힙 스냅샷(또는 힙 덤프)의 객체 구조를 탐색하는 데 사용됩니다.\n\n이 도구는 Heap Analysis Tool (HAT)을 대신합니다. jcmd에 의해 생성된 힙 덤프와 같은 이진 형식의 힙 덤프를 처리합니다.\n\n<div class=\"content-ad\"></div>\n\n이 도구는 Java의 메모리 누수와 유사한 의도하지 않은 객체 연결을 식별하는 데도 도움을 줄 수 있습니다. (루트셋에서 참조되어 있는 객체)\n\n예를 들어, hprof\n\n이 기본 명령줄 도구는 표준 JDK와 함께 제공됩니다. 힙 및 CPU 프로파일링, 락 경합, 메모리 누수 및 기타 문제를 분석하여 성능을 조사합니다. JVMTI(JVM 도구 인터페이스)를 통해 JVM과 통신하는 동적 링크 라이브러리(DLL)입니다.\n\n프로파일링 데이터를 파일이나 소켓을 통해 ASCII 또는 이진 형식으로 기록합니다. 힙 할당 통계, 힙 덤프, CPU 사용량, JVM 내의 모든 모니터 및 스레드의 상태, 경합 프로필에 대한 정보를 제공할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\njava –agentlib:hprof HelloWorld\n```\n\n아래 명령을 사용하여 hprof를 사용하여 힙 할당 프로필을 얻을 수 있습니다.\n\n```js\njavac –J-agentlib:hprof=heap=sites HelloWorld.java\n```\n\n아래 명령을 사용하여 힙 덤프를 생성할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n\n```js\njavac -J-agentlib:hprof=heap=dump HelloWorld.java\n```\n\n# 2. Digma Continuous Feedback\n\nDigma는 OTEL을 사용하여 자동으로 수집한 관측 데이터에 의존합니다. 다른 프로파일링 도구와 마찬가지로 코드가 런타임에서 어떻게 작동하는지 분석하고 문제점을 찾는 것이 목적입니다. 유일한 차이점은 Digma가 자체적으로 이러한 문제점을 계속해서 찾는다는 것입니다.\n\n몇 가지 예시를 살펴보겠습니다:\n\n\n<div class=\"content-ad\"></div>\n\n- 앱에 가장 많은 영향을 미치는 코드/쿼리를 찾아보세요(성능 영향).\n\na. 가장 성능에 영향을 많이 주는 코드를 찾으려면 자산 탭에서 \"Performance Impact\"로 정렬할 수 있습니다:\n\n![이미지](/assets/img/2024-05-17-9BestJavaProfilerstoUsein2024_3.png)\n\n이 뷰는 개발자에게 가치 있는 정보를 제공합니다. 성능 문제로 최적화가 필요할 수 있는 엔드포인트를 빠르게 파악할 수 있습니다. 실행 시간과 성능 영향의 조합을 통해 문제 해결에 우선순위를 두고 개발에 집중할 수 있어 전체 애플리케이션의 성능과 신뢰성을 향상시킬 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nb. 또는 대시보드를 여시고, 클라이언트 스팬 성능 영향 위젯을 사용해보세요:\n\n![위젯](/assets/img/2024-05-17-9BestJavaProfilerstoUsein2024_4.png)\n\n이 위젯은 개발자들이 애플리케이션의 어떤 부분이 성능 문제에 기여할 수 있는지 빠르게 식별할 수 있게 해줍니다. 성능에 미치는 영향이 큰 엔드포인트부터 시작해 디버깅과 최적화 노력을 우선 순위에 따라 할 수 있습니다.\n\n2. 최근 커밋에서 성능 저하 식별하기 ― 지속 시간의 변화\n\n<div class=\"content-ad\"></div>\n\n![Image](/assets/img/2024-05-17-9BestJavaProfilerstoUsein2024_5.png)\n\n코드 성능의 최근 변경 사항을 추적하는 또 다른 방법은 기간 통찰력입니다. 이는 특정 범위의 호출 기간 분포를 시각적으로 나타냅니다.\n\n최근 호출 성능: 위젯은 가장 최근 호출의 기간을 보여줍니다(91.95밀리초), 이를 일반적인 성능과 즉시 비교하여 예상 범위 내인지 아니면 이상값인지 확인할 수 있습니다.\n\n중앙값 기간: 중앙값 기간이 최근 변경되었습니다(16.19밀리초 증가). 빨간색은 최근 변경 사항을 나타내며, 이는 성능의 저하 또는 개선을 나타낼 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n성능 분포: 히스토그램 자체는 호출 지속 시간의 빈도를 표시하여 개발자가 다양한 성능 시간의 공통성을 빠르게 파악할 수 있습니다. 특정 호출 지속 시간 범위가 얼마나 자주 발생하는지 보여줍니다.\n\n가장 느린 5%: 호출의 가장 느린 5%를 나타내는 히스토그램의 부분이 강조됩니다. 이는 평균이나 중앙값 통계로는 명백하지 않은 장기적인 성능 문제를 식별하는 데 중요합니다.\n\n이 통찰력을 활용하여 개발자는 코드의 성능을 시간이 지남에 따라 추적할 수 있습니다. 시각화는 증가하는 지연과 같은 트렌드를 식별하는 데 도움이 되며, 이는 메모리 누수, 비효율적인 데이터베이스 쿼리 또는 다른 리소스 충돌 문제와 같은 잠재적인 문제를 나타낼 수 있습니다. 최근 변경 사항을 나타내는 빨간 블록은 최근 코드 변경이나 배포 업데이트와 성능 변화를 상관시켜 주어 더 즉각적인 조사를 유도하는 데 특히 유용합니다.\n\n3. 스케일링 문제 찾기를 위한 프로파일링 - 스케일링 통찰력\nDigma는 코드의 확장성에 대한 통찰력을 제공하여, 응용프로그램의 확장 가능성을 방해할 수 있는 잠재적인 문제를 식별합니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Java Profiler](/assets/img/2024-05-17-9BestJavaProfilerstoUsein2024_6.png)\n\n예를 들어, 스케일링 문제 통찰력을 통해 개발자는 동시성 처리 및 요청 처리 시간과 관련된 성능 병목 현상을 빠르게 파악할 수 있습니다.\n\n성능 저하 메트릭은 성능이 하락하는 부하 수준을 식별하는 데 도움이 됩니다. 이 메트릭은 이러한 트랜잭션 중에 실행된 코드 경로를 확인하여 비효율성이나 리소스 경합을 찾도록 개발자를 안내할 수 있습니다.\n\n동시성 정보는 시스템이 동시적인 프로세스나 스레드를 처리할 때 문제가 발생하는 것을 개발자에게 알립니다. 이는 응용프로그램이 병렬 처리를 처리하거나 응용프로그램이 이 수준의 동시성에서 최적으로 작동하도록 필요한 리소스가 할당되지 않는 문제를 시사할 수 있습니다.\n\n\n<div class=\"content-ad\"></div>\n\n시간 소요: 넓은 범위는 일부 조건에서 응답 시간이 크게 증가할 수 있는 것을 시사합니다. 이는 처리 병목, 비효율적인 알고리즘, 데이터베이스 쿼리 성능 또는 다른 시스템 제약 때문일 수 있습니다.\n\n이 정보를 종합함으로써, 개발자는 주의를 요하는 응용 프로그램 요소로 유도되고 비효율적인 코드, 데이터베이스 병목 현상, 부적절한 하드웨어 자원 또는 최적화되지 않은 아키텍처 결정과 같은 문제의 원인을 가정하기 시작할 수 있습니다. 목표는 이러한 영역을 조사하고 개선하여 응용 프로그램의 확장성을 향상시키는 것입니다.\n\n# 3. VisualVM\n\n이 도구는 Java Development Kit (JDK)의 일부였지만 JDK 8에서 제거되었으며, 현재는 별도의 도구로 제공됩니다.\n\n<div class=\"content-ad\"></div>\n\n이 Java 프로파일러는 CPU 샘플링, 메모리 샘플링, 가비지 수집 실행, 힙 오류 분석, 스냅샷 촬영 및 그래픽 사용자 인터페이스를 위해 편리합니다.\n\n이 Java 프로파일러는 로컬 및 원격 프로파일링을 지원하지만 SSH 터널링을 통한 프로파일링은 지원하지 않습니다. 원격 프로파일링을 위해 JMX 포트를 구성해야 합니다.\n\nVisualVM은 프로파일링 세션의 스냅샷을 나중에 분석할 수 있도록 촬영하는 기능을 제공합니다.\n\nVisualVM은 JConsole, jstat, jinfo, jstack 및 jmap과 같은 JDK와 함께 제공되는 독립적인 도구에 의존합니다.\n\n<div class=\"content-ad\"></div>\n\n\n![VisualVM](/assets/img/2024-05-17-9BestJavaProfilerstoUsein2024_7.png)\n\n다음은 VisualVM을 사용하는 세 가지 방법입니다:\n\n1. 미리 정의된 성능 제약 조건을 사용하여 Java 프로그램 실행하기\n\n```bash\njava -Xmx125m -Xms25m -Xmn15m -XX:PermSize=30m -XX:MaxPermSize=30m -XX:+UseSerialGC HelloWorld\n```\n\n<div class=\"content-ad\"></div>\n\n터미널에서 jvisualvm을 실행하여 JVM 힙 메모리 사용량을 모니터링해보세요.\n\n\njvisualvm\n\n\n다음으로, Java VisualVM 프로그램이 실행됩니다. Tools > Plugins로 이동하여 Visual GC 플러그인을 다운로드하세요. (다른 플러그인들도 표시될 것입니다. 필요한 것들을 사용할 수 있습니다.)\n\n# 4. Yourkit\n\n<div class=\"content-ad\"></div>\n\nYourKit Java Profiler은 다양한 플랫폼과 호환되며 Windows, MacOS, Linux, Solaris 및 FreeBSD와 같은 각 지원 운영 체제에 대한 구별된 설치를 제공합니다.\n\nJProfiler와 마찬가지로 YourKit에는 스레드, 가비지 수집, 메모리 사용량 및 메모리 누수를 표시하는 핵심 기능이 포함되어 있습니다. SSH 터널링을 통해 로컬 및 원격 프로파일링을 지원합니다.\n\n당신의 계획은 비즈니스 목적을 위한 유료 라이선스를 제공하며, 무료 평가판 및 개인 사용을 위한 할인된 또는 무료 허가권을 포함합니다.\n\n![](/assets/img/2024-05-17-9BestJavaProfilerstoUsein2024_8.png)\n\n<div class=\"content-ad\"></div>\n\n당신의 킷은 발생한 예외를 분석하는 데도 유용합니다. 발생한 예외를 식별하고 빈도를 파악하는 것은 간단합니다.\n\n당신의 킷은 특정 부분인 메서드나 스레드 내의 브랜치와 같은 코드에 초점을 맞춘 독특한 CPU 프로파일링 기능을 제공합니다. 이 기능은 조건부 프로파일링을 가능하게 함으로써 유용합니다.\n\n당신의 킷은 SQL 및 NoSQL 데이터베이스 호출을 프로파일링할 수도 있습니다.\n\n# 5. JProfiler\n\n<div class=\"content-ad\"></div>\n\nMarkdown 형식은 JProfiler을 사용하여 Java 애플리케이션의 프로파일링을 수행할 수 있는 ej-technologies의 도구입니다. JProfiler에는 메모리 사용량, 시스템 성능, 잠재적인 메모리 누수, 그리고 스레드 프로파일링을 모니터링하기 위한 인터페이스가 제공되며 사용자 친화적인 사용자 인터페이스를 통해 제공됩니다.\n\n이 정보를 통해 시스템의 기초에서 최적화, 제거 또는 수정할 부분을 쉽게 식별할 수 있습니다.\n\nJProfiler은 Java 애플리케이션의 프로파일링 도구이며 ej-technologies가 개발했습니다. JProfiler은 메모리 사용량, 시스템 성능, 잠재적인 메모리 누수, 그리고 스레드 프로파일링을 모니터링하기 위한 인터페이스가 제공되며 사용자 친화적인 사용자 인터페이스를 통해 제공됩니다.\n\n이 정보를 통해 시스템의 기초에서 최적화, 제거 또는 수정할 부분을 쉽게 식별할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-17-9BestJavaProfilerstoUsein2024_9.png\" />\n\n이 Java Profiler는 라이선스를 구매해야하지만 무료 평가판을 제공합니다. 주요 초점은 네 가지 핵심 영역을 다룹니다:\n\n- 메서드 호출: 메서드 호출을 분석하면 응용 프로그램의 기능에 대한 통찰력을 제공하고 전반적인 성능을 향상시킬 수 있습니다.\n- 할당: 힙에 저장된 항목, 참조 연결 및 쓰레기 수집 관리를 조사함으로써 메모리 누수를 해결하고 메모리 효율성을 향상할 수 있습니다.\n- 스레드 및 락: JProfiler는 다양한 스레드 및 락 분석 관점을 제공하여 멀티스레딩 문제를 식별하는 데 도움을 줍니다.\n- 고급 서브시스템: 고급 의미 수준에서 다양한 성능 문제가 발생합니다. Java 데이터베이스 연결(JDBC)의 JDBC 호출에서 가장 느린 SQL 문을 식별하는 것이 중요합니다. JProfiler를 사용하면 이러한 서브시스템을 통합적으로 조사할 수 있습니다.\n\nJProfiler는 IntelliJ IDEA, 이클립스, NetBeans와 같은 잘 알려진 IDE와 통합될 수 있습니다. 사용자는 스냅샷에서 실제 소스 코드로 이동할 수도 있습니다.\n\n<div class=\"content-ad\"></div>\n\n# 6. NetBeans Profiler\n\n넷빈스는 주로 우수한 디버깅 기능으로 알려져 있지만, 놀랍게도 최고의 자바 프로파일러 중 하나로 부상합니다. 오라클의 오픈 소스 넷빈스 IDE에는 NetBeans Profiler가 번들의 일부로 포함되어 있습니다. 쉬운 개발과 프로파일링에 대한 우수한 선택지이기도 합니다.\n\n![이미지](/assets/img/2024-05-17-9BestJavaProfilerstoUsein2024_10.png)\n\n프로파일러와 디버거의 기능을 결합하면 코드 실행 시간 및 런타임 동작을 모니터링하고 멀티스레딩과 같은 디버깅 방법의 효율을 향상시킬 수 있습니다. 넷빈스 프로파일러는 응용 프로그램의 속도를 향상시키고 메모리 효율성을 향상시킵니다. 무료로 해당 웹사이트에서 다운로드할 수 있다는 것이 멋집니다.\n\n<div class=\"content-ad\"></div>\n\nJava VisualVM과 Netbeans Profiler은 기능 면에서 유사하며 둘 다 무료입니다. 그러나 Netbeans는 IDE와 함께 모든 기능을 제공하는 번들 프로그램으로 더 뛰어납니다.\n\n# 7. IntelliJ Profiler\n\nIntelliJ Profiler는 CPU 및 메모리 할당 프로파일링을 위한 간편하면서도 강력한 도구입니다. 두 가지 잘 알려진 Java 프로파일러인 JFR과 Async 프로파일러의 기능을 통합합니다.\n\n일부 고급 기능이 제공되지만, 기본적으로 간편함에 중점을 둡니다. IntelliJ Profiler는 설치 없이 쉽게 시작할 수 있는 간단한 방법을 제공하며 일상적인 개발 작업에 유용한 도구를 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n\n![Java Profiler](/assets/img/2024-05-17-9BestJavaProfilerstoUsein2024_11.png)\n\nIntelliJ IDEA Ultimate에서 IntelliJ Profiler를 Java 프로세스에 쉽게 연결할 수 있어요. 스냅숏과 소스 코드 사이를 쉽게 이동할 수 있어서 매끄럽게 작업할 수 있어요. 독특한 flame graph와 같은 다른 측면을 통해 시각적으로 다양한 메소드의 효과를 평가하고 런타임 프로세스를 신속하고 효과적으로 이해할 수 있어요.\n\n# 8. Async Profiler\n\n이 Java 프로파일링 도구는 최소한의 오버헤드가 있으며 Safepoint 편견 문제를 회피할 수 있어요. HotSpot을 위한 스택 추적 및 메모리 할당 모니터링을 위한 특정 API가 포함되어 있어요. 이 프로파일러는 HotSpot JVM을 사용하는 OpenJDK 및 다른 Java 런타임과 호환되어요.\n\n\n<div class=\"content-ad\"></div>\n\nasync-profiler은 다양한 유형의 이벤트를 모니터링할 수 있습니다.\n\n- 중앙 처리 장치 작업\n- 캐시 미스, 브랜치 미스, 페이지 폴트 및 컨텍스트 전환과 같은 성능 카운터를 통해 하드웨어 및 소프트웨어 성능을 모니터링합니다.\n- Java 힙 내의 메모리 분배\n- Java 객체 모니터 및 ReentrantLocks의 locked contention 등의 locked contention 실험\n\n현재 Async Profiler는 Linux 및 Mac 운영 체제만 지원합니다. IntelliJ IDEA를 사용한다면 별도로 설치할 필요가 없습니다. 통합 기능이 미리 설치되어 있으며 다음을 포함합니다.\n\n- 프로파일링 세션 시작 및 종료\n- 이미 진행 중인 프로세스에 연결\n- 프로파일 평가 검사\n\n<div class=\"content-ad\"></div>\n\n![image](/assets/img/2024-05-17-9BestJavaProfilerstoUsein2024_12.png)\n\n# 9. Arthas\n\n앨리바바 아르타스는 Java 애플리케이션을 진단하는 데 사용되는 도구로, 문제를 추적, 분석 및 해결할 수 있는 기능을 제공합니다. Arthas를 활용하는 주요 장점은 코드를 수정하거나 모니터링 중인 Java 서비스를 다시 시작할 필요가 없다는 것입니다.\n\n![image](/assets/img/2024-05-17-9BestJavaProfilerstoUsein2024_13.png)\n\n<div class=\"content-ad\"></div>\n\n# 다른 실력 있는 자바 프로파일러\n\n일부 주목할 만한 프로파일러로는 Java Mission Control, New Relic, Glowroot, JMH, Arthas, XRebel/JRebel, JProbe, Pinpoint 및 Stackify Prefix가 있습니다. 시장 점유율은 낮지만 분명 인정받을 가치가 있습니다.\n\nDigna Continuous Feedback 다운로드: 여기\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\n그래서, YourKit과 Digma를 결합하는 것이 최상의 최적화 결과를 가져옵니다. Grafana는 애플리케이션 로그를 시각화하기 위해 사용되며, YourKit은 잠재적인 병목 현상을 찾기 위해 애플리케이션을 프로파일링하고, Digma는 잠재적인 문제가 있는 코드 조각에 대한 원활한 통찰력을 제공합니다.\n\n# 자주 묻는 질문:\n\nJProfiler는 자바 프로파일러인가요?\n\nJProfiler는 강력한 프리미엄 자바 프로파일러로, Java 응용 프로그램용으로 설계되었습니다. 10일간의 완전한 평가판을 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n자바 메모리 프로파일러란 무엇인가요?\n자바 메모리 프로파일러는 자바 애플리케이션이 어떻게 메모리를 활용하는지를 분석하여 성능 문제를 확인하고 메모리 누수를 수정하는 데 도움을 줍니다.\n\n자바에서 CPU 프로파일링이란 무엇인가요?\n\nCPU 프로파일링은 CPU 사용량을 분석함으로써 애플리케이션의 효율성을 평가하고 개선하는 방법입니다. 이는 코드 내의 핫스팟, 병목 현상 및 효율성 문제를 식별하여 CPU 사용량의 증가나 부적절한 성능으로 이어질 수 있는 문제를 해결하는 데 도움이 됩니다.","ogImage":{"url":"/assets/img/2024-05-17-9BestJavaProfilerstoUsein2024_0.png"},"coverImage":"/assets/img/2024-05-17-9BestJavaProfilerstoUsein2024_0.png","tag":["Tech"],"readingTime":14},{"title":"2부 미디어 무결성 기반 보호하기","description":"","date":"2024-05-16 17:45","slug":"2024-05-16-Part2SecuringtheFoundationsofMediaIntegrity","content":"\n\n![이미지](/assets/img/2024-05-16-Part2SecuringtheFoundationsofMediaIntegrity_0.png)\n\n소셜 미디어의 광범위한 영향은 개인 데이터에 대한 상당량의 접근성을 가능케 하여, 다양한 기관들이 알고리즘 추천을 향상시키고 사용자 참여를 촉진하며 수익화 노력을 촉진하도록 했습니다. 이 비즈니스 모델은 지속적인 참여와 성장 및 확장을 위해 데이터 수집 전략에 의존합니다. 이제 소셜 미디어가 일상생활에 깊이 뿌리내린 상황에서, 그 구조화된 아키텍처는 연결성 도구뿐만 아니라 악의적인 주체들에 의해 조작되는 수단으로 작용합니다. 이들 기관은 영향 작전부터 스파이 행위 및 사이버 범죄까지 목적에 따라 플랫폼 설계를 악용할 수 있습니다.\n\n소셜 미디어 플랫폼의 엄청난 데이터 수집 및 조작 능력은 정보 작전 및 사회 공학적 공격에 있어 강력한 도구로 작용하며, 심리 전쟁 및 다양한 분야 작전에서 중요한 요소입니다. 악의적인 주체들, 특히 전략적인 사이버 목표를 가진 외국 기관과 연관된 주체들에 의해 소셜 미디어의 오용 가능성이 큽니다. 지역정치의 긴장 속에서 적 대국과 연관된 플랫폼들이 언국가 안보에 미치는 위협을 이해하는 것이 중요합니다.\n\n미군은 종종 적에 대비해 응답 속도가 늦어지는 것에 대해 걱정을 표명했습니다. 이에 대응하기 위해 군은 방어작전에 대한 미디어 접근을 제공하는 정책을 시행했습니다. 군사 부대에 기자를 배치하는 것은 주로 작전 보안을 보호하면서 뉴스의 적시성과 상세 설명을 크게 희생시키지 않도록 하는 것을 목표로 합니다. 이에 대해 언론 조작 가능성에 대한 비판이 있지만, 이것은 주로 작전 보안을 보호하는 데 목적이 있습니다.\n\n<div class=\"content-ad\"></div>\n\n더 많은 접근 및 투명한 정보 공유는 언론이 더 많은 정보와 포괄적인 보도를 생산할 수 있도록 돕습니다. 그러나 뉴스 산업은 수익 창출을 위한 노력과 감소하는 수익과 광고 베이스로 인한 압력 등, 이러한 최선의 실천 방안을 방해할 수 있는 압력에 직면합니다. 뉴스 수집 자원의 중대한 감소와 경험이 적은 계약 직원에 대한 의존도 증가는 추가적인 도전을 제기합니다. 더불어 미디어 플랫폼들의 증가로 지속적인 콘텐츠 업데이트가 요구되는데, 이는 종종 덜 비용이 드는 코멘터리로 채워지며 정보의 품질과 정확성을 희석시킬 수 있습니다.\n\n주류 미디어의 영향력은 크며, 국가적 논쟁을 결정하고 보안 문제에 대한 대중 의견을 형성합니다. 미디어가 고수해야 할 전문적인 기준을 준수하는 것은 중요합니다. 이를 하지 못하면 신뢰도와 사회 기능이 퇴색될 우려가 있습니다. 이러한 환경에서 정보원의 출처 및 진위를 보장하는 것이 중요합니다. 정보의 안전하고 검증 가능한 출처를 확립함으로써 미디어 콘텐츠의 질을 보호하고, 결과적으로 왜곡된 오보의 영향으로부터 사회적 대화와 개인 인식을 보호할 수 있습니다.\n\n![The Security of Our Minds](/assets/img/2024-05-16-Part2SecuringtheFoundationsofMediaIntegrity_1.png)\n\n<div class=\"content-ad\"></div>\n\n인간의 정신을 교란하는 숨겨진 영향으로부터 방어하기 위한 여정에서, 우리의 집단 책임은 단순한 경계를 초월하여 깊은 이해를 필요로 합니다; 진실과 거짓이 우리의 사고의 전장을 어떻게 형성하는지를 깊이 파악해야 합니다. 미디어의 무결성은 정보 보안의 중추일 뿐만 아니라 정신적 자율성의 수호자가 되는 것입니다. 사회적 상호작용 속에서, 미디어는 대중 담론의 풍경을 형성하는 통로로서 존재합니다. 이 흐름이 오보와 프로파간다의 오염물질로 오염된다면, 인간 인식의 본질 자체가 훼손됩니다.\n\n이 영향의 깊이를 이해하려면, 우리가 소비하는 각 정보 조각이 현실에 대한 우리의 지각을 섬세하게 조정하는 것을 인정해야 합니다. 거짓된 스토리가 번식하는 환경에서, 특히 순진한 이나 교육받지 못한 사람들을 겨냥하는 경우, 마음의 방어 기제는 준비되지 않아 조작에 취약해질 수 있습니다. 이러한 조건은 파시스트 정권에게 우월한 위치를 제공하는데, 그들은 진실을 숨기고 무지를 부추기며 권력을 유지하려는 수법을 통해 이야기를 통제하는 데 착취합니다.\n\n조작된 사실과 꼬인 진실의 해로운 영향은 단순한 속임수를 넘어서 사람들의 동의를 의도적으로 조작하고 사회적 의지를 형성합니다. 개인이 세상을 바라보는 렌즈를 왜곡함으로써 악의적인 세력은 사회적 규범과 가치를 다시 조작하며 인류를 깨달음 있는 담론에서 더 어두운, 더 분열된 목적으로 이끌 수 있습니다. 이 심리적 조작이 방치된다면, 공공을 유도하는 주자들의 권력을 더욱 굳히면서 공공을 오인시키는 오보의 사이클을 촉발시킵니다.\n\n이것으로서 뉴스 이야기의 권을 그 중요한 방패로 드러납니다. 정보의 성질을 보호하고, 그로부터 확장된 인간 정신의 자율성을 보호하는 수단으로 나타납니다. 미디어의 신뢰성을 보장하기 위해 암호화와 견고한 사이버 보안 조치가 배치되는 데에는 쌍둥이 목적이 있습니다. 먼저, 정보의 부패를 막는 방어선으로 작용하여 뉴스의 원본과 무결성이 창조부터 소비까지 보존되도록 합니다. 둘째, 참된 것을 접근하고 검증할 수 있는 환경을 육성하여 개인을 에워싸는 정보 영역을 견고하게 하여 진실이 접근 가능하고 확인 가능한 환경이 유지되도록 합니다.\n\n<div class=\"content-ad\"></div>\n\n미디어 소스의 신뢰성은 기술적 보호를 통해 확보되며, 이는 개인들이 진실을 추출할 수 있는 기반을 제공합니다. 이 진실은 다시 말해, 잘 통찰하고 판단력 있는 결정을 내릴 수 있는 기초가 되며, 시민들이 건강하고 지속 가능한 사회를 유지하고 육성하는 길을 선택할 수 있게 합니다. 미디어의 역할은 정보를 제공하는 데 그치는 것이 아니라, 인간 발전의 드라마에서 핵심적인 주역이 되어 현실의 관리자이자 대중의 지성을 지키는 역할을 합니다.\n\n미디어의 성실성은 잘 기능하는 사회의 특징뿐만 아니라 자유와 민주주의를 보존하는 것의 전제조건입니다. 우리가 소비하는 각 이야기가 현실의 반영이 되고 왜곡된 정보가 아닌 현실에 입각한 것임을 보장함으로써, 우리는 개별적인 마음 뿐만 아니라 문명의 집단 의식을 지키게 됩니다. 이 관점에서 미디어 성실성을 향상시키는 모든 노력은 사회의 인지적 저항력 향상에 투자하는 것이며, 우리 집단적 수평선을 흐려지게 하려는 그림자에 대항하여 지키는 것입니다.\n\n![미디어 성취의 중요성](/assets/img/2024-05-16-Part2SecuringtheFoundationsofMediaIntegrity_2.png)\n\n- 미디어 출처의 중요성\n\n<div class=\"content-ad\"></div>\n\n뉴스의 출처와 신뢰성은 그저 운영 상세사항에 그치는 것이 아니라, 언론이 사회에서 발하는 역할에 있어 중요한 요소입니다. 이는 언론이 공익의 수호자로서, 권력에 대항하는 감시자로서, 진실을 추구하는 신뢰할 만한 횃불로서의 역할을 수행할 수 있도록 보장합니다. 이에 따라 뉴스 보도의 출처와 신뢰성을 강화하기 위한 노력은 정보 제공, 공정성, 민주적 사회 형성에 있어서 언론의 영향력과 효과를 유지하는 데 중요합니다. 뉴스 보도에서의 출처와 신뢰성의 중요성은 널리 강조되어야 합니다. 특히 오늘날의 디지털 시대에는 정보가 신속하게 생성되고 수정되며 세계적으로 퍼져나가는 환경에서 그 중요성이 더욱 커집니다. 뉴스 기사에 대한 명확하고 검증 가능한 가계보를 수립하는 것은 여러 가지 핵심적인 이유로 필수적입니다:\n\n1. 대중 신뢰 유지\n\n신뢰는 어떤 관계의 기반입니다. 대중과 미디어 사이의 관계 역시 예외는 아닙니다. 뉴스 매체가 정보에 대한 투명하고 검증 가능한 출처를 제공할 때, 그들은 청중과의 신뢰를 구축하고 유지합니다. 이 신뢰는 미디어 매체의 신뢰성 뿐만 아니라 그 실천하는 언론의 효과성을 위해 필수적입니다. 위기나 혼란의 시기에는 믿을 만한 미디어가 신뢰할만한 실질적인 정보의 공급원입니다.\n\n2. 정보화된 시민 유도\n\n<div class=\"content-ad\"></div>\n\n정보에 정통한 대중은 기능하는 민주주의의 기반이 됩니다. 시민들은 정확하고 진실한 보도에 의존하여 행정, 정책 및 지역 사회 참여에 대한 결정을 내립니다. 뉴스의 출처가 명확하고 검증 가능하면 이를 통해 이러한 결정에 사용되는 정보가 정확함이 보장되어 시민이 현실에 기반한 시민 생활에 참여할 수 있도록 지원됩니다.\n\n3. 오보와 조작 정보 대응\n\n디지털 정보가 신속하게 퍼지는 시대에, 오보(의도치 않게 부정확한 정보)와 조작 정보(고의적으로 속이는 정보)의 위험이 크게 증가했습니다. 뉴스의 신뢰성을 보장함으로써 언론 기관은 이러한 위협에 맞서게 됩니다. 신뢰성은 거짓된 내러티브의 풍조에 대항하여 사회 불안, 대중 혼란, 심지어 공중보건 및 안전 위협에 이르는 것을 막아줍니다.\n\n4. 저널리즘의 정직한 유지\n\n<div class=\"content-ad\"></div>\n\n저널리즘적 신뢰도는 정확성, 공정성 및 중립성을 준수하는 윤리적 기준에 의지합니다. Provenance는 정보 원본으로의 추적 가능한 경로를 제공함으로써 이러한 원칙을 지원하며, 저널리즘이 매력적인 이야기 전달 도구뿐만 아니라 신뢰할 수 있고 윤리적인 공중정보 제공자가 되도록 보장합니다.\n\n5. 법적 및 평판적 위험으로부터 보호\n\n실용적인 관점에서 뉴스 기관은 잘못된 내용이나 표절 콘텐츠의 배포로 인한 법적 결과로부터 자신을 보호해야 합니다. 검증 가능한 출처 정보를 통해 이러한 기관들은 보도 과정에서의 노력을 입증함으로써 중상 소송 및 기타 법적 도전에 대비할 수 있습니다. 게다가 신뢰성을 강조하는 평판은 뉴스 기관이 갖는 가장 가치 있는 자산 중 하나가 될 수 있습니다.\n\n6. 책임과 투명성 지원\n\n<div class=\"content-ad\"></div>\n\n정보의 원본이 명확히 문서화되고 접근할 수 있는 경우, 이는 언론과 그 대상에 대한 책임을 지지합니다. 이 투명성은 공개 인물과 기관이 행동에 대해 책임을 져야 함을 보장하며, 그들의 발언과 정보가 검증된 사실과 출처와 대조될 수 있도록 돕습니다.\n\n미디어와 뉴스에서 제공되는 오리진, 신뢰성, 그리고 정보의 정직성을 보장하는 핵심적인 수용 — 현대 언론과 정보 전파 아키텍처의 기반적인 기둥으로 기능합니다. 현실의 질서가 디지털 조작과 거짓된 이야기를 통해 왜곡될 수 있는 시대에, 뉴스 기사에 대한 검증 가능한 계보를 수립하는 것은 공중의 신뢰와 정보화된 시민성을 유지하는 데 중요합니다. 미디어에서의 오리진 보증은 흥미로운 내용을 그 소스와 맥락에 고정시키는 진리의 수호자 역할을 효과적으로 합니다. 각 뉴스 항목의 기원과 발전을 추적할 수 있는 강력한 메커니즘을 내장함으로써 소비자들은 신뢰성을 확인할 도구를 갖출 수 있습니다. 이것은 미술이나 고고학의 출처 프로토콜과 유사하여, 유물의 기원과 역사가 그 평가된 가치와 정토성에 중요한 역할을 합니다.\n\n```\n![Part2SecuringtheFoundationsofMediaIntegrity_3](/assets/img/2024-05-16-Part2SecuringtheFoundationsofMediaIntegrity_3.png)\n```\n\n블록체인과 디지털 워터마킹과 같은 기술들은 이 분야에서 중추적인 역할을 할 수 있습니다. 블록체인은 변경할 수 없는 장부 능력을 이용하여 뉴스 아이템의 수명주기를 기록하는 방법을 제공합니다. 각 단계는 타임 스탬프가 찍히고 생성자에게 연결될 수 있어, 어떤 수정 또는 추가 사항이 투명하고 책임 있게 할 수 있습니다. 반면 디지털 워터마킹은 디지털 콘텐츠에 직접 정보를 삽입하여 생성자의 신원과 콘텐츠의 정직성을 확인할 수 있게 하여, 어떤 조작이 감지될 수 있도록 합니다. 이러한 워터마크는 이동하는 콘텐츠와 함께 유지되어, 기원지로의 지속적이고 눈에 띄지 않는 연결을 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n위 제안된 실제 실현 가능성에는 몇 가지 난관이 있을 수 있지만, 섭왜성을 보장하기 위한 이 이론적인 프레임워크는 진보적으로 보일 수도 있습니다. 첫째로, 기존 미디어 생산 및 배포 워크플로우에 이러한 시스템을 통합하는 기술적인 어려움이 있습니다. 이를 해결하면서 언론에게 중요한 속도와 효율을 해치지 않아야 합니다. 둘째로, 언론사, 기자, 그리고 궁극적으로 대중이 받아들이고 채택해야 하는 보다 넓은 문제가 있습니다. 궁극적으로 성공적으로 기능하기 위해서는 섭왜성 시스템이 산업 내에서 일반적으로 받아들여지고 신뢰돼야 합니다.\n\n게다가, 미디어에서의 섭왜성은 윤리적, 법적 고려 사항에도 영향을 미칩니다. 예를 들어, 민감한 뉴스 이야기에서의 언론 소스 보호는 콘텐츠 생성의 투명성이 필요한 필요와 균형을 이루어야 합니다. 마찬가지로, 뉴스 콘텐츠의 발전을 추적하고 기록하는 시스템을 개발할 때는 뉴스 이야기에 나오는 개인 및 조직의 사생활 권리를 고려해야 합니다.\n\n미디어에서 섭왜성을 보장하는 시스템의 사회적 영향은 깊습니다. 정보의 명확하고 검증 가능한 계보를 제공함으로써, 이러한 시스템은 가짜 정보와 오도전의 확산을 현저히 줄일 수 있습니다. 전통적인 미디어에 대한 신뢰가 침식되는 현대에는, 섭왜성이 신뢰를 회복하고 소비자들이 신뢰할 수 있는, 투명한 뉴스 소스를 기반으로 교육된 결정을 내릴 수 있도록 할 수 있습니다.\n\n미디어와 뉴스에서 섭왜성을 실현하는 것은 기술적인 문제뿐만 아니라 건강한 사회를 위한 필수 문화적 요구입니다. 점점 복잡해지는 정보의 풍경을 고려할 때, 뉴스의 근원 및 진위를 확인하는 능력은 부가적인 기능에 그치는 것이 아닌 자유롭고 정보화되고 민주적인 사회를 지키기 위한 필수 조건입니다. 궁극적으로, 미디어에서의 섭왜성 채택은 정보가 얼마나 가치 있고 신뢰되는지에 대한 철학적 전환이 요구됩니다. 이는 정보 소비가 함께 중요한 것이라는 콘텐츠 자체와 동등한 중요도를 갖게 하여, 보다 미래를 밝게 하는 공개적인 대화를 이끌 수 있습니다. 공개적인 대화는 진실과 투명성에 대한 공유된 약속을 바탕으로 한 더 현명한 공공 토론으로 이어질 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\nPart 1: 매체에서의 진실\n\nPart 3: 매체 소스 기록 제안","ogImage":{"url":"/assets/img/2024-05-16-Part2SecuringtheFoundationsofMediaIntegrity_0.png"},"coverImage":"/assets/img/2024-05-16-Part2SecuringtheFoundationsofMediaIntegrity_0.png","tag":["Tech"],"readingTime":7},{"title":"위협 인텔리전스를 멋지다고 생각하시나요","description":"","date":"2024-05-16 17:43","slug":"2024-05-16-DoyouthinkThreatIntelligenceiscool","content":"\n\n\n![이미지](/assets/img/2024-05-16-DoyouthinkThreatIntelligenceiscool_0.png)\n\n# 위협 인텔리전스란 무엇인가요?\n\n요약하자면, 위협 인텔은 다양한 위협 행위자와 캠페인에 대한 정보를 수집할 수 있는 활동의 집합입니다.\n\n## 위협 인텔리전스 활동\n\n\n<div class=\"content-ad\"></div>\n\n많은 사람들(아마도 당신도)이 생각하는 것:\n\n위협 인텔리전스 = 침해 표시\n\n이는 그 이상입니다!\n\n위협 인텔리전스 활동의 다른 예시를 소개해 드릴게요:\n\n<div class=\"content-ad\"></div>\n\n- 위협 모델링: 조직에 특정한 위협을 매핑합니다. 예를 들어, 은행은 TV 온라인 채널보다 다른 위협을 대상으로 합니다.\n\n![이미지](/assets/img/2024-05-16-DoyouthinkThreatIntelligenceiscool_1.png)\n\n그럼 이게 왜 중요할까요?\n\n두 가지 예를 들어볼게요:\n\n<div class=\"content-ad\"></div>\n\n- 비즈니스 결정: 귀하의 조직에 특화된 위협 모델을 정의하면 비즈니스는 귀하의 요구에 맞게 특정 투자 결정을 내릴 수 있습니다. 제 나라에 곰이 없다면 왜 스스로를 곰으로부터 방어해야 하는 걸까요? 같은 개념이 여기에도 적용됩니다.\n- 레드팀: 위협 모델을 사용하여 레드팀은 귀하의 조직을 대상으로 하는 위협 그룹들이 사용하는 기술, 전술 및 절차(Techniques, Tactics, and Procedures, TTPs)를 모의할 수 있습니다.\n\n- OSINT: \"오픈소스 인텔리전스\"의 약자입니다. 기본적으로 인터넷을 활용하여 위협 가해자에 대한 정보를 수집할 수 있습니다. 서로 다른 플랫폼을 사용하여 캠페인이나 위협 그룹 뒤에 숨은 사람들의 실제 신원을 파악할 수 있습니다.\n\n이미지:\n<img src=\"/assets/img/2024년-05월-16일-도유희감위협인텔리전스잘하는거시아이쿨_2.png\" />\n\n또한, OSINT를 통해 사이버범죄 포럼에서 정보를 수집할 수 있습니다. 아래에서 확인할 수 있는 몇 가지 예시를 찾아보세요:\n\n<div class=\"content-ad\"></div>\n\n```js\nxss[.]in\nExploit[.]in\nCracked[.]io\nNulled[.]to\nInfinity[.]ink\nBreachForums[.]st\nWww-club[.]link\n```\n\n- **HUMINT**: 사람 지능을 나타내는 HUMINT는 정보를 사람의 소스로부터 수집하는 과정을 나타냅니다. 위협 인텔리전스에서 HUMINT는 사람을 통해 위협 그룹과 내부 연결을 설정하는 데 사용될 수 있습니다. 예를 들어, 해킹 그룹의 미래 목표에 대한 소중한 정보를 얻고 이를 사용하여 고객/희생자의 보안을 강화할 수 있습니다.\n- **Compromise Monitoring**: 포럼, 해킹 커뮤니티 및 텔레그램 채널을 적극적으로 모니터링하여 귀하나 귀하의 고객과 관련된 게시물을 확인하는 스크레이핑 도구를 만드는 것을 권장합니다.\n\n<img src=\"/assets/img/2024-05-16-DoyouthinkThreatIntelligenceiscool_3.png\" />\n\n- **Puppet Master**: 네, 정말로 그렇습니다! 당신은 꼭두각시 주인이 될 수 있습니다... 하지만 위협 인텔리전스 분야에서요.```\n\n<div class=\"content-ad\"></div>\n\n\n![Image](/assets/img/2024-05-16-DoyouthinkThreatIntelligenceiscool_4.png)\n\n위협 인텔리전스의 퍼펫 마스터는 해킹 커뮤니티 내에서 자신의 페르소나의 신뢰도를 구축하고 보호하고 있어요.\n\nHUMINT와 퍼펫 마스터링의 차이는 무엇인가요? — HUMINT는 외부 소스를 다루는 반면, 퍼펫 마스터는 자체 가짜 \"위협 요소\"를 보유하고 사이버 범죄 집단에 침투하여 정보를 수집해요.\n\n이 주제에 관한 정말 좋은 책인 “Securing Online Personas” by deadlock (온라인에서 찾을 수 있어요)를 공부할 수 있어요.\n\n\n<div class=\"content-ad\"></div>\n\n그리고 위에 나열된 것 외에도 수행할 수 있는 많은 위협 인텔 활동이 있습니다.\n\n## 데이터, 정보 및 인텔리전스\n\n이 세 용어의 차이점을 알고 계신가요?\n\n\"This is an IP address\" - `데이터`\n\n<div class=\"content-ad\"></div>\n\n\"이 IP 주소는 명령 및 제어에 사용됩니다\" -` 정보\n\n\"이 IP 주소는 우리의 인프라를 대상으로하여 민감한 문서를 추출하기 위한 경제 스파이 활동을 목적으로 하는 명령 및 제어에 사용된 주소입니다\" -` 인텔리전스\n\n## 용어 및 참조\n\n위협 인텔리전스 산업에서 사용되는 용어 예시 중 일부를 아래에서 찾을 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n소스 = 지능을 제공하는 모든 제공자 또는 채널을 가리킵니다. 보고서에서 사람들은 정보를 어떻게 또는 누구로부터 얻었는지 언급하지 않습니다. 대신, 매우 자주 \"우리의 소스가 우리에게 XYZ를 알려주었다\"고 언급됩니다.\n\n페르소나 = 주로 위협 요소 또는 그룹과 관련된 생성된 신원입니다. 일반적으로 사용자 이름에 의해 정의됩니다.\n\n작전 보안 (OPSEC) = 실제 신원을 추적으로부터 활동 및 페르소나를 보호하는 데 적용하는 방법입니다.\n\n침해 지표 (IoC) = 시스템이 침입되었거나 침해당했다는 것을 시사하는 증거 또는 유물입니다. 이는 악성 파일 해시, IP 주소, 도메인 이름, URL, 이메일 주소, 레지스트리 키, 파일 경로, 사용자 에이전트 문자열 등을 포함할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n**기술, 전술 및 절차(TTPs)** = 위협 행위자가 목표를 달성하는 데 사용하는 구체적인 방법 또는 접근법입니다. MITRE ATT&CK 페이지에서 포괄적인 목록을 찾을 수 있습니다.\n\n![이미지](/assets/img/2024-05-16-DoyouthinkThreatIntelligenceiscool_5.png)\n\n**YARA 규칙** = \"Yet Another Recursive Acronym\"의 약자로 악의적 파일을 식별하는 데 사용할 수 있는 규칙을 생성하고 공유하기 위해 주로 설계된 오픈 소스 도구입니다. 잠재적으로 위험한 파일의 정적 분석에 기반을 두고 있습니다. 참조: [https://github.com/VirusTotal/yara](https://github.com/VirusTotal/yara)\n\n![이미지](/assets/img/2024-05-16-DoyouthinkThreatIntelligenceiscool_6.png)\n\n<div class=\"content-ad\"></div>\n\n적 정보 = 위협 주체의 신원과 온라인 존재에 관한 정보\n\n작업 정보 = 위협 주체와 관련된 캠페인 및 TTP(Tactics, Techniques, Procedures)에 대한 정보\n\n초기 접근 중개자 (IAB) = 초기 접근을 판매하는 위협 주체 (침해된 VPN, RDP, SSH 또는 다른 원격 액세스 계정)\n\n위협 모형 = 조직의 잠재적 위협을 평가하기 위한 구조화된 접근 방식\n\n<div class=\"content-ad\"></div>\n\nMISP는 \"악성 소프트웨어 정보 공유 플랫폼 및 위협 공유\"로, 조직이 보안 위협에 대한 정보를 수집, 공유 및 분석할 수 있게 해주는 오픈 소스 위협 인텔리전스 플랫폼입니다.\n\n![Do you think Threat Intelligence is cool](/assets/img/2024-05-16-DoyouthinkThreatIntelligenceiscool_7.png)\n\n# 정보의 품질을 어떻게 평가할 수 있을까요?\n\n얻은 위협 인텔리전스는 NATO 해군 시스템을 사용하여 분류할 수 있으며, 이를 사용하여 정보의 신뢰성 및 유효성을 분류할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n`<img src=\"/assets/img/2024-05-16-DoyouthinkThreatIntelligenceiscool_8.png\" />`\n\n`<img src=\"/assets/img/2024-05-16-DoyouthinkThreatIntelligenceiscool_9.png\" />`\n\n# Is it dangerous? OPSec Considerations\n\nDefinitely YES!\n\n<div class=\"content-ad\"></div>\n\n많은 갱단, 깡패, 범죄 조직 및 테러 조직이 사이버 위협 가해자들과 관련되어 있음을 고려해야 합니다. 그들은 돈, 무기 및 영향력을 갖고 있습니다.\n\n그래서 좋은 OPSec을 갖추는 것이 매우 중요합니다. 몇 가지 조언은 다음과 같습니다:\n\n- VPN 및 프록시 사용\n- 포런 및 기타 플랫폼에 계정을 등록할 때 Proton Email 또는 YOPMail 사용\n- 브라우저의 사용자 에이전트를 소유하지 않는 기기를 모방하도록 설정\n- 브라우저에서 쿠키 추적 비활성화\n- 기기의 로컬 시간을 다른 시간대로 변경\n- 수집한 정보에 “필요한 정보만” 원칙 적용\n- 개인성 사용자 이름을 실제 신원의 사용자 이름과 연결하지 마세요\n- 포럼 계정 및 개성에 무작위 시간에 로그인하여 자신의 가능한 시간대를 드러내지 않도록 함\n- 거짓말하는 법을 배우세요! 예를 들어, 리소스와 날씨에 대한 토론 중에 만난 경우, 반대의 것에 대해 불평하세요 (그리고 전하는 거짓말을 추적하세요). 현실: 귀하는 국가에서 눈이 옵니다. 당신이 할 말: “아이고 여기 너무 덥네요”. 실생활 취미와는 1%도 관련이 없는 개성에 대한 취미를 개발하세요. 이해하셨으면 좋겠네요 ;)\n\n매우 유심히 읽어주셔서 감사하며 건강하세요!","ogImage":{"url":"/assets/img/2024-05-16-DoyouthinkThreatIntelligenceiscool_0.png"},"coverImage":"/assets/img/2024-05-16-DoyouthinkThreatIntelligenceiscool_0.png","tag":["Tech"],"readingTime":5},{"title":"선명한 오리진 스토리","description":"","date":"2024-05-16 17:41","slug":"2024-05-16-VIVIDOriginStory","content":"\n\n![VIVID Gallery](/assets/img/2024-05-16-VIVIDOriginStory_0.png)\n\n안녕하세요! VIVID 갤러리가 재디자인한 웹사이트를 공개하게 되어 매우 기쁩니다. 우리는 예술가와 수집가에 대한 약속을 가슴 깊이 간직하고 있으며, 최신 업데이트에서는 예술가와 수집가 모두의 경험을 향상시키기 위한 여정을 강화하고자 합니다. VIVID의 정체성을 조금이나마 소개하며, 당신과 함께 하는 미션과 목표를 나누는 것에 흥분합니다. 오늘의 우리를 이끄는 기원 이야기를 다시 들려주면서 새로운 미학을 축하하고자 합니다. 당신과 함께 손잡고 계속해서 성장해 나가는 것을 기대합니다.\n\nVIVID는 플랫폼 이상의 것을 구축하려 애썼습니다; 창작자와 예술 애호가 모두에게 필요한 완벽한 경험을 조성하기 위한 목표를 세웠습니다. 우리의 야망은 예술가들에게 견고한 기술적, 예술적 지원을 제공하여 그들의 창의적 꿈을 현실로 이끌어 주는 것이었습니다. 동시에 우리는 디지털 아트의 열렬한 후원자인, 열정을 가진 수집가들의 단단한 공동체를 짜기를 희망했습니다.\n\n그 초기 시절에는 비트코인으로 창작, 기록, 수집하는 것은 중요한 인프라가 없어 지각이 된 큰 과업처럼 보였습니다.\n\n<div class=\"content-ad\"></div>\n\n이 안전하고 탈중앙화된, 변경 불가능한 생태계는 모든 디지털 작품이 원래의 블록체인처럼 영원히 존속할 수 있는 안식처를 제공했습니다.\n\n수집가들의 여정을 높이기 위해 우리는 이례적이고 프리미엄한 경험을 상상했습니다 — 기존의 오더널이나 인기 있는 NFT 마켓플레이스에서 만나볼 수 있는 비인간적인 거래와는 대조적인 경험입니다. 우리의 목표는 전통적이고 개인적인 미술 수집 경험을 재도입하여 진지한 미술 애호가들이 예술가와 VIVID의 창립자들과 직접 소통하며 디지털 시대에서 종종 잃어버린 개인적 연결을 유도하는 것이었습니다.\n\n2023년의 곰 시장에서 데뷔한 VIVID는 Ordinals의 매력에 대해 거의 무감각한 세상을 뚫고 나아갔습니다. 우리의 첫 번째 컬렉션인 \"Rising Echoes\"는 2023년 7월 빛을 보았습니다. 판매를 매듭짓는 길은 Magic Eden 런치패드에서 출시 후 몇 일 동안의 도전 끝에 이르렀습니다 — NFT 세계의 순발력 지배 문화 속에서의 인내심 대결로, 디지털 미술 세계에서 기대하는 즉각적인 만족감과의 시험이기도 했습니다. 마침내, Rising Echoes는 완판되었고 이 경로를 계속해서 나아갈 수 있도록 우리에게 격려를 주었습니다.\n\n급변하는 환경에서 선구자로 남아, 우리는 예술과 기술의 교차로에 서 있으며, 가상 경계를 초월하는 연결을 구축하고 있습니다. 지루한 미래의 아름다움과 블록체인 기술의 무한한 잠재력을 믿음으로, VIVID는 새로운 영역을 개척하며 모든 화소와 대화로 새로운 길을 개척하고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n전통 예술계를 모태로 한 VIVID는 예술가들이 번성하고 수집가들이 고품질 디지털 예술을 발견하고 투자할 수 있는 육성 환경을 제공합니다. 하르토의 Floraforms와 같은 혁신적인 프로젝트의 도입은 VIVID의 혁신적 접근과 기술적 능력을 강조하며 Ordinals 공간 내 생성적 예술에 대한 새로운 가능성을 열어줍니다.\n\n![이미지](/assets/img/2024-05-16-VIVIDOriginStory_1.png)\n\n2024년 발렌타인 데이에 빈의 명문 Belvedere 박물관은 VIP들을 위해 호화로운 파티를 개최하여 FloraForms 콜렉션을 론칭하고 발행하는 독특한 기회를 제공했습니다. 이 이벤트는 즉시 FloraForms Ordinals 콜렉션의 매진을 보았으며, 역사적인 예술 기관과 혁신적인 예술가의 협업으로 전세계적으로 전복적인 생성적 예술 계획으로 자리 잡았습니다. 이 협력은 박물관의 깊은 유산과 구스타프 클림트 시대를 존중함과 함께 예술가, 철학자, 사상가들의 혁신적이고 변혁적인 기여를 찬양하는 시기를 기념하였습니다.\n\n![이미지](/assets/img/2024-05-16-VIVIDOriginStory_2.png)\n\n<div class=\"content-ad\"></div>\n\n벨베데레 미술관과 협력하여 Gustav Klimt의 상징인 작품에 경의를 표하며 FloraForms를 통해 전통적인 예술과 디지털 예술 영역 사이의 간극을 좁히는 VIVID의 야망을 보여줍니다. 이는 과거와 현재 예술적 움직임 사이의 대화를 시작함으로써 디지털 예술 컬렉션의 문화적 의미를 풍부하게 하고 예술 커뮤니티 내 참여와 소유의 독특한 기회를 제공합니다.\n\nFloraForms의 성공적인 출시 이후, VIVID는 CyberSea의 Deus Ex Machina, Moodsoup의 Mitosis, 그리고 Medusa의 Artifakt와 같은 명망 높은 아티스트들과의 협업을 공개했습니다. 각 컬렉션은 상당한 사전 판매 관심을 보이며 출시 즉시 완판되었습니다.\n\n![이미지1](/assets/img/2024-05-16-VIVIDOriginStory_3.png)\n\n![이미지2](/assets/img/2024-05-16-VIVIDOriginStory_4.png)\n\n<div class=\"content-ad\"></div>\n\n\n![VIVIDOriginStory_5](/assets/img/2024-05-16-VIVIDOriginStory_5.png)\n\n아티스트와 그들의 컬렉터 사이의 동적인 연결을 유지하기 위해 Discord를 통해 제공하며, 컬렉터들에게 아티스트에 대한 이전에 없던 접근권한을 제공합니다. 이러한 가까운 상호작용은 컬렉터들이 아티스트와 깊게 상호작용할 수 있도록 하여 VIVID 컬렉션 경험의 중요한 요소로 남아 있습니다.\n\nDiscord에서 아티스트와 컬렉터들의 커뮤니티에 가입하세요.\n\n앞으로도 Shaderism, Manuel Larino 및 Dario Lanza와 같은 비전있는 아티스트들과의 미래 프로젝트를 발표하는 것에 흥분하며, 이들은 모두 VIVID의 탁월함에 대한 약속을 담고 있으며, VIVID 애호가들의 컬렉션을 풍부하게 하는 훌륭한 작품을 제공할 것입니다.\n\n\n<div class=\"content-ad\"></div>\n\n창립자들의 공유된 비전과 커뮤니티의 적극적인 참여는 미술의 풍부한 유산을 존중하면서 혁신적인 플랫폼을 형성하는 데 중요한 역할을 합니다. VIVID는 고품질 생성 미술 작품의 창작과 획득의 무한한 잠재력을 발견할 수 있는 예술가와 수집가들이 함께 모여 커뮤니티를 구축하며 발전할 것입니다.","ogImage":{"url":"/assets/img/2024-05-16-VIVIDOriginStory_0.png"},"coverImage":"/assets/img/2024-05-16-VIVIDOriginStory_0.png","tag":["Tech"],"readingTime":4},{"title":"점들로부터 평면까지 Vision-Language Subspace Prompting","description":"","date":"2024-05-16 17:39","slug":"2024-05-16-FromPointstoPlanesVision-LanguageSubspacePrompting","content":"\n\n\n![lecture image](/assets/img/2024-05-16-FromPointstoPlanesVision-LanguageSubspacePrompting_0.png)\n\n최근에 고급 컴퓨터 비전 수업인 Dr. 이 제가 이끄는 Dr. 송 이제의 흥미로운 게스트 강연을 듣게 되었습니다. Dr. Li는 삼성 AI의 연구 과학자로, 도메인 일반화, 연합 학습 및 PEFT 방법과 같은 인공 지능의 중요 주제를 다루었습니다. 특히, 그의 최신 연구인 \"Vision-Language Sub Space Prompting\"에 초점을 맞춘 프레젠테이션은 정보 전달 뿐만 아니라 유사성 검색과 같은 작업에서 진화하는 방법론을 구체화하는 데 있어서 흥미롭고 사유를 제공했습니다. 그의 통찰력에 영감을 받아, 저는 그의 최신 연구 작업에 대한 직관에 대한 생각을 이 블로그를 통해 공유할 필요성을 느꼈습니다.\n\nSub-space prompting의 복잡성에 뛰어들기 전에, 대규모 언어 모델(LLMs)과 시각-언어 모델(VLMs)의 영역에서 우리를 이 시점으로 이끌어 온 혁신의 역사를 잠깐 돌아봅시다. 여러분, 정말 대단한 여정이었습니다!\n\nLLMs의 초기 발전은 Word2Vec 및 GloVe와 같은 모델의 등장으로 시작되었고, 이 모델은 단어의 밀도 있는 벡터 표현을 생성했습니다. 이 임베딩은 단어 간 의미와 관계를 포착해, 더 정교한 모델을 위한 기초를 마련했습니다. 이는 예전 페이스북에서 누군가가 우리를 \"찌르다\"라는 말만 들어도 정말 즐거웠던 소셜 미디어 초기 시절과 닮았네요.\n\n\n<div class=\"content-ad\"></div>\n\n그 다음에는 트랜스포머의 시대가 도래했습니다. 특히 2017년 Vaswani 등이 소개한 트랜스포머 아키텍처는 해당 분야를 완전히 혁신했습니다. 트랜스포머는 셀프 어텐션 메커니즘을 활용하여 모델이 문장이나 문서 전체를 병렬로 처리하고 맥락적 관계를 더 효과적으로 포착할 수 있게 했습니다.\n\n이어서 BERT(Bidirectional Encoder Representations from Transformers)와 GPT(Generative Pre-trained Transformer)가 등장했습니다. BERT는 모델이 양방향으로 컨텍스트를 학습하는 이중향 교육 개념을 소개했고, GPT는 비지도 학습과 자기회귀 언어 생성의 힘을 보여줌으로써 언어 모델링 분야에서 새로운 기준을 세웠습니다. GPT가 마치 AI 세계를 황홀한 롤러코스터 여행에 초대하며 기록을 깨고 모두를 감탄시켰다고 상상해보세요.\n\n한편 VLM(Visual Language Models)도 주목을 받고 있었습니다. VisualBERT와 ViLBERT와 같은 모델은 시각적 및 텍스트 데이터를 결합하여 이미지 캡션 달기, 시각적 질문 응답 등 양쪽 모드를 이해해야 하는 작업을 가능하게 했습니다. AI의 동적인 듀오로 생각해보세요. 함께 세계를 보고 설명하며 복잡한 퍼즐을 해결합니다.\n\n이어서 OpenAI의 CLIP(Contrastive Language–Image Pre-training)이 등장합니다. CLIP은 대규모 이미지-텍스트 쌍 데이터셋에서 훈련하여 이미지와 텍스트를 연관시키는 방법을 학습함으로써 제로샷 분류 작업에서 놀라운 성능을 달성했습니다. CLIP은 마치 AI 파티에 등장해 파티 분위기를 살려 이미지와 텍스트를 완벽하게 이해하는 능력으로 모든 이들을 감탄시켰다고 생각해보세요.\n\n<div class=\"content-ad\"></div>\n\n서브스페이스 프롬프팅의 구체적인 내용을 살펴보면, 기술의 진화를 이해하는 것이 매우 중요합니다. 각 혁신은 이전 성공과 교훈을 기반으로 구축되어 오늘날 우리가 보는 정교한 모델과 방법론으로 이어졌습니다.\n\n# 비전-언어 모델 이해: CLIP 사례\n\n![이미지](/assets/img/2024-05-16-FromPointstoPlanesVision-LanguageSubspacePrompting_1.png)\n\n비전-언어 모델(VLM)에 대해 생각할 때, 그것들을 AI 세계의 스위스 아미 나이프로 상상해보세요. 다재다능하고 소형이면서 예상치 못하게 강력합니다. 이 분야에서 빛나는 별 한 개는 OpenAI가 개발한 CLIP입니다. 수백만 개의 세심하게 레이블이 붙은 이미지를 사탕 가게에서 사탕을 먹는 아이처럼 먹이는 전통적 모델들이 있는 세계에서, CLIP은 자가 감독 학습 방식으로 젠의 접근을 취합니다. 이 방법은 대조 손실 함수를 사용하여 멋지기만 한 것이 아니라 놀랍도록 효과적으로 작동하여 CLIP이 많은 지도 학습 모델들을 앞설 수 있게 합니다.\n\n<div class=\"content-ad\"></div>\n\nCLIP은 그냥 어떤 모델이 아닙니다. 그것은 다양한 작업을 동시에 수행하는 마에스트로입니다. 이 모델은 우수한 특성 표현을 만들어내는데, 이는 단순히 좋을 뿐만 아니라 수많은 하위 작업들을 해결하는 금빛 열쇠 같습니다. 예를 들어, CLIP에서 임베딩을 사용하면 순식간에 이미지 또는 텍스트 분류 시스템을 만들 수 있습니다. 또는 이 임베딩을 사용하여 텍스트와 이미지를 결합한 가장 가까운 이웃 검색을 수행할 수 있습니다. 마치 화가가 캔버스에 색을 섞는 것처럼요.\n\n# 프롬프트 엔지니어링의 진화\n\n훌륭한 임베딩이면 큰 책임도 따라옵니다. 즉, 그것들을 효과적으로 활용하는 방법을 알아내야 합니다. 이것이바로 프롬프트 엔지니어링, 모델로부터 최상의 답변을 도출하기 위해 완벽한 질문을 만드는 예술입니다. 이는 데이터를 위한 매치메이킹과 같습니다. 이를 통해 질문과 모델이 완벽히 맞는지를 확인합니다. 연구자들은 구문을 다듬어 순수한 요청인 \"'CLASS'의 사진.\"과 같은 것을 \"새 종류 중 'CLASS'의 사진.\"과 같이 더 화려하게 변환하여 결과물을 향상시키고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n그러나 수동으로 이러한 프롬프트를 제작하는 것은 설명서 없이 가구를 조립하는 것만큼 지루합니다. 이에 프롬프트 학습 분야가 등장해 밝은 기사갑옷을 입은 기사처럼 나타났습니다. 이는 강한, 수동으로 만들어진 프롬프트를 더 유연한 것으로 대체합니다 — Coop 및 CoCoOp과 같은 작품에서 나타나는 학습 가능한 임베딩, 즉 컨텍스트 최적화(즉, 소프트 프롬프팅이나 소프트 프롬프터라고도 함). 이러한 동적 임베딩은 특정 작업의 맛을 향상시킬 수 있도록 맞춤형 양념 조합과 같습니다. 예를 들어, 정의된 일련의 범주를 분류하는 것과 같은 특정 작업에 더욱 특화된 작업에 특화된 작업에 대한 임베딩입니다.\n\n# Vision-Language Sub Space Prompting\n\n<img src=\"/assets/img/2024-05-16-FromPointstoPlanesVision-LanguageSubspacePrompting_3.png\" />\n\n그들의 논문인 “Vision-Language Sub Space Prompting”에서 컨텍스트 최적화의 일반적인 문제점들이 지적됩니다. 일반적으로 학습 가능한 소프트 프롬프트는 너무 열정적인 학생들처럼 작용합니다 — 익숙한 주제에서 뛰어나지만 새로운 자료에 직면할 때 성능이 떨어지며 새로운 클래스에 마주했을 때 성능이 떨어집니다. 전통적으로 해결책은 수동으로 만들어진 프롬프트 조미료를 약간 뿌리는 것이었지만, 이는 모델이 초기에 학습한 작업에 대해 빛나던 빛깔을 둔화시키는 경우가 많았습니다. 이는 주로 여기서 특징 공간에서 2개의 점 간 거리가 계산되고 점 단독이 항상 수업의 충분한 의미를 포착할 수 없기 때문입니다.\n\n<div class=\"content-ad\"></div>\n\n이를 해결하기 위해 SuPr (Subspace Prompting) 개념이 제안되었습니다. 클래스를 하나의 공간 점으로 나타내는 대신 전체 하위 공간으로 나타내는 새로운 차원으로의 건너뛰기와 같다고 생각해보세요. 일반적인 소프트 프롬프트 세트를 더 짧은 길이로 분할하여 파라미터 수를 증가시키지 않고도 앙상블을 유지할 수 있습니다. 각 세트는 토큰 시퀀스를 생성하여 텍스트 인코더에 공급하여 임베딩의 꽃다발을 만들어내는 하위 공간을 생성합니다 - 그들은 이를 하위 공간의 지원 지점이라고 부릅니다.\n\n![image alt text](/assets/img/2024-05-16-FromPointstoPlanesVision-LanguageSubspacePrompting_4.png)\n\n기존의 유클리드 메트릭을 뒤바꾸는 포인트-서브스페이스 거리를 사용하여 (누가 평범한 유클리드를 좋아할까요?). 이 방법은 단순히 새로운 레이어를 추가하는 것이 아니라 하위 공간이 VLM(비전-언어 모델)과 상호 작용하는 방식을 변경하여 시각적 의미의 더 풍부한 스펙트럼을 포괄할 수 있는 지평을 넓힙니다.\n\n![image alt text](/assets/img/2024-05-16-FromPointstoPlanesVision-LanguageSubspacePrompting_5.png)\n\n<div class=\"content-ad\"></div>\n\n이 방법론을 통해 다른 다중 모달에 적용할 수 있는 가능성이 있으며, 여러 기본 모델에 기반을 둔 차별적인 방식으로 공동 내재 표현이 학습될 것으로 예상됩니다.\n\n참고문헌","ogImage":{"url":"/assets/img/2024-05-16-FromPointstoPlanesVision-LanguageSubspacePrompting_0.png"},"coverImage":"/assets/img/2024-05-16-FromPointstoPlanesVision-LanguageSubspacePrompting_0.png","tag":["Tech"],"readingTime":5},{"title":"RWKV-6 주목할 필요 없이 최신 기술을 활용한 7B LLM","description":"","date":"2024-05-16 17:38","slug":"2024-05-16-RWKV-6Attention-freeandState-of-the-art7BLLM","content":"\n\nRWKV 신경 구조는 주의를 사용하지 않습니다. 이는 시퀀스 길이에 대해 제곱으로 증가하는 어텐션 계산 비용을 갖는 트랜스포머 아키텍처보다 추론에서 훨씬 더 효율적입니다. 이 글에서 RWKV를 설명하고 사용하는 방법을 보여드렸어요:\n\nRWKV를 개발한 팀은 주기적으로 아키텍처를 개선하고 새로운 모델을 출시합니다. 현재 RWKV의 여섯 번째 버전이 출시되었으며 Hugging Face Hub에서 7B RWKV-6이 공개되었습니다:\n\n- BlinkDL/rwkv-6-world (Apache 2.0 라이선스)\n\n이 모델은 100개 이상의 언어를 지원하며 2.5T 토큰에 대해 사전 훈련되었습니다. 이 사이즈의 LLM 중 비영어권 언어에 대해 최고의 성능을 보여준다고 하네요. 저희 자체 평가에 따르면요:\n\n<div class=\"content-ad\"></div>\n\n![2024-05-16-RWKV-6Attention-freeandState-of-the-art7BLLM_0.png](/assets/img/2024-05-16-RWKV-6Attention-freeandState-of-the-art7BLLM_0.png)\n\nLlama 3 8B보다 더 좋아 보입니다. 또한 RWKV-5보다 현저히 더 좋습니다. 그러나 영어 작업에 대해서는 Mistral 7B와 Llama 3 8B 대부분의 벤치마크에서 성과가 낮습니다. 아마도 아키텍처 때문이 아니라 단순히 영어 토큰을 훨씬 적게 학습했기 때문일 것입니다.\n\n제 작업을 지원하려면 AI의 최근 발전에 대한 더 많은 기사/튜토리얼을 제공하는 뉴스레터를 구독해 주시기 바랍니다.","ogImage":{"url":"/assets/img/2024-05-16-RWKV-6Attention-freeandState-of-the-art7BLLM_0.png"},"coverImage":"/assets/img/2024-05-16-RWKV-6Attention-freeandState-of-the-art7BLLM_0.png","tag":["Tech"],"readingTime":1},{"title":"GPT-4o가 정말 엔드투엔드 멀티모달 모델인가요 공포, 당황, 암울에 빠진 당신을 떤들어드릴게요","description":"","date":"2024-05-16 17:36","slug":"2024-05-16-TerrifiedMortifiedPetrifiedIsGPT-4oTrulyanEnd-to-EndMulti-ModalModel","content":"\n\n\n![GPT-4 Omni](/assets/img/2024-05-16-TerrifiedMortifiedPetrifiedIsGPT-4oTrulyanEnd-to-EndMulti-ModalModel_0.png)\n\nOpenAI가 강력하고 다재다능한 AI 모델인 GPT-4 옴니를 소개했습니다. 다양한 입력 및 출력 형식을 처리하는 능력이 탁월하지만, 기술 전문가와 연구자들이 GPT-4 옴니가 엔드 투 엔드 다중 모달 모델인지 아닌지를 이해하는 것은 매우 중요합니다. 이 구별은 다양한 영역에서의 응용에 대한 적절한 기대 설정 및 기능을 올바르게 활용하는 데 중요합니다.\n\n다중 모달 모델 이해하기: 다중 모달 모델은 텍스트, 이미지, 오디오, 비디오 등 여러 유형의 데이터를 처리하고 생성하는 AI 시스템입니다. 이러한 모델은 다양한 입력의 종합적인 이해가 필요한 작업을 수행하기 위해 여러 모달리티의 정보를 통합합니다. 특히 엔드 투 엔드 다중 모달 모델은 각 모달리티에 대해 별도의 모델을 사용하지 않고 원시 데이터 입력(예: 음성, 이미지)을 직접 처리하여 출력(예: 텍스트, 생성된 이미지)을 생성합니다.\n\n엔드 투 엔드 모델 이해하기: 머신 러닝에서 \"엔드 투 엔드\"란 작업을 분리되지 않고 단일하고 일관된 프로세스에서 시작부터 끝까지 수행하는 모델을 가리킵니다. 그러나 GPT-4 옴니는 전달 방식을 사용하여 각각 다른 유형의 데이터 및 작업을 독립적으로 처리하는 전문 컴포넌트를 포함합니다.\n\n\n<div class=\"content-ad\"></div>\n\n지켜보면서도 놀라운 발전을 지켜봤어요. 태스크에 특화된 NLP 모델에서부터 BERT와 GPT-3 같은 조기 단계의 사전 훈련된 LLM까지, 마침내 일반적이고 생산적인 ChatGPT로 이어졌습니다. 이러한 모델들은 세상의 지식, 상식적 지식, 심지어 도메인 특정 지식과 추론을 표현하는 데 놀라운 능력을 보여주었답니다. 이러한 발전에도 불구하고 연구자들은 여전히 이러한 신생 능력을 설명할 수 있는 탄탄한 이론을 개발하는 데 어려움을 겪고 있습니다.\n\n텍스트 전용 modalities에서의 종단 간 훈련에 대한 확장 법칙은 어느 정도 이해하기 쉽습니다. 그러나 다중 모달 데이터에 대해 단일 신경망을 최적화하는 종단 간 방식은 정말 놀라운 것이죠. 많은 질문이 떠오르는데요:\n\n<div class=\"content-ad\"></div>\n\n- 서로 다른 데이터 모달리티를 어떻게 정렬할까요? 각 모달리티(텍스트, 비전, 오디오)는 고유한 특성과 표현 요구사항이 있습니다. 이를 하나의 모델에 정렬하는 것은 복잡한 도전입니다.\n- 최적의 학습 매개변수: 각 모달리티가 자체 최적의 학습률, 손실 함수 및 훈련 일정이 필요할까요? 이러한 매개변수를 한 모델에서 균형있게 맞추는 것은 매우 어려울 수 있습니다.\n- 계산 리소스: 이러한 모델을 훈련하는 데 얼마나 많은 계산 리소스가 필요할까요? 다중 모달 데이터의 규모와 복잡성은 계산 파워와 시간에 대한 수요를 크게 증가시킵니다.\n\nEnd-to-End인가 아닌가? 다중 모달 데이터에서 GPT-4o를 훈련하는 것에 대한 탐구 OpenAI의 GPT-4와는 달리 GPT-4 Omni에 대한 포괄적인 기술적 문서가 제공되지 않습니다. 내부 문서가 GPT-4o의 신원을 인식하는 데 도움이 되었을 수 있다고 믿어, 직접 GPT-4o로부터 답을 찾기로 결정했습니다.\n\n![이미지1](/assets/img/2024-05-16-TerrifiedMortifiedPetrifiedIsGPT-4oTrulyanEnd-to-EndMulti-ModalModel_1.png)\n\n![이미지2](/assets/img/2024-05-16-TerrifiedMortifiedPetrifiedIsGPT-4oTrulyanEnd-to-EndMulti-ModalModel_2.png)\n\n<div class=\"content-ad\"></div>\n\n📝 참고: GPT-4o에서 자체적으로 엔드 투 엔드 훈련을 거부하고 다단계 파이프라인을 주장한 후 질문을 한 것으로, 제 개인적인 편견을 피하기 위해 정확한 정보를 확인하려고 노력했습니다.\n\n# 가능한 다단계 파이프라인은 무엇인가요?\n\nGPT-4o와의 대화를 통해 \"모듈식\" 및 \"분리된\" 구성 요소에 대한 세부 정보에 대해 요약했습니다. (이것은 FAKE NEWS일 수도 있습니다)\n\nGPT-4 Omni은 다양한 유형의 입력과 출력을 수용하고 생성할 수 있는 능력을 가지지만, 엔드 투 엔드 구조 대신 모듈식 접근 방식을 따릅니다.\n\n<div class=\"content-ad\"></div>\n\n모든 비텍스트 입력은 처리되기 전에 먼저 텍스트로 변환되어야 합니다: GPT-4 Omni의 핵심은 GPT-4 언어 모델이며, 이 모델은 텍스트 입력을 처리하고 텍스트 응답을 생성합니다. 이 모델은 방대한 텍스트 데이터 코퍼스에서 훈련되어 제공된 문맥을 기반으로 인간과 유사한 텍스트를 이해하고 생성할 수 있습니다.\n\n다음은 이 작업 흐름의 자세한 내용입니다:\n\n- 음성인식 (음성 입력): GPT-4 Omni는 음성 인식 시스템을 사용하여 말로 된 언어를 텍스트로 변환합니다. 이 시스템은 일반적으로 Google의 Speech-to-Text와 같은 고급 모델을 기반으로 합니다. 음성 인식 구성 요소는 음성 단어를 정확하게 전사하기 위해 오디오 데이터와 해당 텍스트 전사본의 방대한 데이터 세트에서 독립적으로 훈련됩니다.\n- 이미지 인식 및 처리: 이미지 입력의 경우 GPT-4 Omni는 외부 이미지 인식 및 처리 시스템에 의존하여 시각 데이터를 언어 모델이 해석할 수 있는 형식으로 변환합니다. 즉, 밀집 벡터(임베딩) 또는 문구 텍스트입니다. 이 두 형식은 모델이 해석할 수 있지만 각각 다른 목적과 영향을 가지고 있습니다. 밀집 벡터 또는 임베딩은 시각 데이터의 숫자 표현입니다. 임베딩은 이미지 분류, 유사성 검색, 특정 유형의 이미지 기반 질문에 대한 답변과 같이 이미지의 추상적인 특징을 이해하고 응답 생성하는 작업에 유용합니다. 이 문구화 과정은 이미지 내용을 자연어 설명으로 번역하여 언어 모델이 직접 해석하고 응답할 수 있도록 합니다. 이 기술은 이미지 내용의 자연어 이해가 필요한 작업에 유용하며, 캡션 생성, 상세한 설명 제공, 이미지의 특정 측면에 대한 질문에 대답하는 등의 작업에 활용됩니다.\n- 텍스트 음성 변환: 출력이 발화형태로 전달되어야 할 경우 GPT-4 Omni는 텍스트-음성(TTS) 시스템을 사용합니다. 이 시스템은 생성된 텍스트 응답을 다시 음성으로 변환합니다. TTS 구성 요소는 텍스트와 해당 발화 형태의 쌍으로 훈련되어 자연스러운 발화 합성을 보장합니다.\n\n# 결론\n\n<div class=\"content-ad\"></div>\n\nGPT-4o의 기술 세부 정보가 공개되길 열심히 기다리고 있습니다. 멀티모달 모델에 대해 전문가가 아니기 때문에 더 알아보기 위해 계획 중입니다. 저와 같이 인간과 비슷한 지능을 모방하려는 연구자들에게 이 정보가 큰 영향을 줄 것으로 믿습니다.","ogImage":{"url":"/assets/img/2024-05-16-TerrifiedMortifiedPetrifiedIsGPT-4oTrulyanEnd-to-EndMulti-ModalModel_0.png"},"coverImage":"/assets/img/2024-05-16-TerrifiedMortifiedPetrifiedIsGPT-4oTrulyanEnd-to-EndMulti-ModalModel_0.png","tag":["Tech"],"readingTime":4},{"title":"Google Colab에서 GPT-4o로 시작하기 단계별 안내","description":"","date":"2024-05-16 17:34","slug":"2024-05-16-GettingStartedwithGPT-4oonGoogleColabAStep-by-StepGuide","content":"\n\n<img src=\"/assets/img/2024-05-16-GettingStartedwithGPT-4oonGoogleColabAStep-by-StepGuide_0.png\" />\n\n2024년 5월 13일에 OpenAI는 최신 AI 모델인 GPT-4o를 선보였습니다. 이 모델은 텍스트와 이미지 모두와의 고급 음성 상호작용 능력을 보여주었습니다. 인공지능(AI)은 다양한 산업을 변화시키고 있으며, OpenAI의 GPT-4o 모델은 이 혁명의 선두주자입니다.\n\n<img src=\"/assets/img/2024-05-16-GettingStartedwithGPT-4oonGoogleColabAStep-by-StepGuide_1.png\" />\n\n본 안내서는 Google Colab에서 GPT-4o를 설정하고 사용하는 방법을 안내해 드립니다. 간단한 수학 문제를 해결하거나 복잡한 텍스트를 생성하거나 이미지를 분석하려는 경우, 이 튜토리얼을 통해 시작할 수 있을 것입니다.\n\n<div class=\"content-ad\"></div>\n\n![image](https://miro.medium.com/v2/resize:fit:1400/0*Ob6Fa-AKD9ZTpBsW.gif)\n\n# 1. 설정\n\n코딩을 시작하기 전에 Google Colab 계정과 OpenAI의 GPT-4o API에 액세스할 수 있는지 확인해주세요. GPT-4o의 환경 설정 및 몇 가지 흥미로운 기능을 탐색하는 단계별 안내서가 여기 있습니다.\n\n## 단계 1: OpenAI Python 패키지 설치\n\n<div class=\"content-ad\"></div>\n\n먼저 OpenAI Python 패키지를 설치해야 합니다. 새로운 Colab 노트북을 열고 다음 명령을 실행하세요:\n\n```js\n!pip install --upgrade openai --quiet\n```\n\n## 단계 2: 라이브러리 가져오기 및 API 키 설정\n\n그 다음으로 필요한 라이브러리를 가져오고 API 키를 설정하세요. Google Colab의 userdata 모듈을 사용하여 API 키를 안전하게 저장할 수 있습니다.\n\n<div class=\"content-ad\"></div>\n\n```js\nimport json\nfrom openai import OpenAI\nimport os\nfrom google.colab import userdata\n\nMODEL = \"gpt-4o\"\n\nclient = OpenAI(api_key=userdata.get('openai'))\n```\n\n## 단계 3: 첫 번째 완성물 생성\n\nGPT-4o가 어떻게 작동하는지 감을 잡기 위해 간단한 완성물을 만들어 봅시다. 모델에 간단한 수학 문제를 해결하도록 요청하겠습니다.\n\n```js\ncompletion = client.chat.completions.create(\n  model=MODEL,\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a helpful assistant. Help me with my math homework!\"},\n    {\"role\": \"user\", \"content\": \"Hello! Could you solve 4+5?\"}\n  ]\n)\n\nprint(\"Assistant: \" + completion.choices[0].message.content)\n```\n\n<div class=\"content-ad\"></div>\n\n## 단계 4: 더 복잡한 질문하기\n\nGPT-4o에게 더 복잡한 질문을 하여 기능을 더 잘 이해할 수 있습니다. 예를 들어, 모델의 기원 및 훈련 세부 정보에 대해 질문할 수 있습니다.\n\n```js\ncompletion = client.chat.completions.create(\n  model=MODEL,\n  messages=[\n    {\"role\": \"user\", \"content\": \"당신의 이름은 무엇이며 누가 만들었나요? 훈련의 종료일은 언제인가요?\"}\n  ]\n)\n\nprint(\"Assistant: \" + completion.choices[0].message.content)\n```\n\n## 2. 함수 호출을 위한 JSON 모드\n\n<div class=\"content-ad\"></div>\n\nGPT-4는 JSON 응답을 생성할 수 있어서 구조화된 데이터와 함수 호출에 유용합니다.\n\n![image](https://miro.medium.com/v2/resize:fit:1400/0*TyQQvSdTlOenI5YY.gif)\n\n## 단계 1: JSON 응답 생성\n\n주간 운동 루틴을 생성하기 위해 JSON 응답을 만들어 봅시다.\n\n<div class=\"content-ad\"></div>\n\n```js\ncompletion = client.chat.completions.create(\n  model=MODEL,\n  response_format={\"type\": \"json_object\"},\n  messages=[\n    {\"role\": \"system\", \"content\": \"You are a trainer who always responds in JSON\"},\n    {\"role\": \"user\", \"content\": \"Create a weekly workout routine for me\"}\n  ]\n)\n\nprint(completion.choices[0].message)\njson.loads(completion.choices[0].message.content)\n```\n\n# 3. Image Understanding\n\nGPT-4o can also understand and process images. We’ll explore how to work with images by encoding them in base64.\n\n![Image](https://miro.medium.com/v2/resize:fit:1080/0*pYZ8nvgtWiL55IhN.gif)\n\n<div class=\"content-ad\"></div>\n\n## 단계 1: 이미지 인코딩\n\n먼저 이미지를 base64로 인코딩하세요.\n\n```js\nfrom IPython.display import Image, display\nimport base64\n\nIMAGE_PATH = \"/content/IMG-20240118-WA0023.jpg\"\n\ndef encode_image(image_path):\n    with open(image_path, \"rb\") as image_file:\n        return base64.b64encode(image_file.read()).decode(\"utf-8\")\n\nbase64_image = encode_image(IMAGE_PATH)\ndisplay(Image(IMAGE_PATH))\n```\n\n## 단계 2: 이미지 분석\n\n<div class=\"content-ad\"></div>\n\n```js\nresponse = client.chat.completions.create(\n    model=MODEL,\n    messages=[\n        {\"role\": \"system\", \"content\": \"당신은 친절하고 마크다운으로 응답하는 도우미입니다. 수학 숙제를 도와주세요!\"},\n        {\"role\": \"user\", \"content\": [\n            {\"type\": \"text\", \"text\": \"꽃의 색깔은 무엇인가요?\"},\n            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n        ]}\n    ],\n    temperature=0.0,\n)\n\nprint(response.choices[0].message.content)\n```\n\n## 단계 3: URL 이미지 분석\n\nURL에서 직접 이미지를 분석할 수도 있습니다.```\n\n<div class=\"content-ad\"></div>\n\n```js\nresponse = client.chat.completions.create(\n    model=MODEL,\n    messages=[\n        {\"role\": \"system\", \"content\": \"마크다운으로 응답하는 도움이 되는 도우미에요. 수학 숙제를 도와줄게요!\"},\n        {\"role\": \"user\", \"content\": [\n            {\"type\": \"text\", \"text\": \"꽃의 색깔은 무엇인가요?\"},\n            {\"type\": \"image_url\", \"image_url\": {\"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Ranunculus_repens_1_%28cropped%29.JPG/192px-Ranunculus_repens_1_%28cropped%29.JPG\"}\n        ]}\n    ],\n    temperature=0.0,\n)\n\nprint(response.choices[0].message.content)\n```\n\n# 4. Function Calling\n\nGPT-4o는 사용자 입력에 기반하여 미리 정의된 함수를 호출할 수 있어요. 외부 데이터 소스나 서비스를 통합하는 데 특히 유용합니다.\n\n<img src=\"https://miro.medium.com/v2/resize:fit:1200/0*YKVvRxnSDMQEWPqb.gif\" />\n\n\n<div class=\"content-ad\"></div>\n\n## 단계 1: 함수 정의\n\nNBA 경기의 현재 점수를 가져오는 함수를 정의하세요.\n\n```js\ndef get_nba_game_score(team):\n    if \"lakers\" in team.lower():\n        return json.dumps({\"team\": \"레이커스\", \"score\": \"102\", \"opponent\": \"워리어스\", \"opponent_score\": \"98\"})\n    elif \"bulls\" in team.lower():\n        return json.dumps({\"team\": \"불스\", \"score\": \"89\", \"opponent\": \"셀틱스\", \"opponent_score\": \"95\"})\n    else:\n        return json.dumps({\"team\": team, \"score\": \"N/A\", \"opponent\": \"N/A\", \"opponent_score\": \"N/A\"})\n```\n\n## 단계 2: 대화 초기화 및 함수 호출\n\n<div class=\"content-ad\"></div>\n\n모델이 이 함수를 호출할 수 있는 대화를 만들어보세요.\n\n```js\ndef function_calling():\n    messages = [{\"role\": \"user\", \"content\": \"레이커스 게임 점수가 어떻게 되나요?\"}]\n\n    tools = [\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"get_nba_game_score\",\n                \"description\": \"주어진 팀의 NBA 게임의 현재 점수를 가져옵니다.\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"team\": {\"type\": \"string\", \"description\": \"NBA 팀의 이름, 예: 레이커스, 불스\"},\n                    },\n                    \"required\": [\"team\"],\n                },\n            },\n        }\n    ]\n\n    response = client.chat.completions.create(\n        model=MODEL,\n        messages=messages,\n        tools=tools,\n        tool_choice=\"auto\",\n    )\n\n    response_message = response.choices[0].message\n    tool_calls = response_message.tool_calls\n\n    if tool_calls:\n        available_functions = {\"get_nba_game_score\": get_nba_game_score}\n        messages.append(response_message)\n\n        for tool_call in tool_calls:\n            function_name = tool_call.function.name\n            function_to_call = available_functions[function_name]\n            function_args = json.loads(tool_call.function.arguments)\n\n            function_response = function_to_call(team=function_args.get(\"team\"))\n\n            messages.append(\n                {\"tool_call_id\": tool_call.id, \"role\": \"tool\", \"name\": function_name, \"content\": function_response}\n            )\n\n        second_response = client.chat.completions.create(\n            model=MODEL,\n            messages=messages,\n        )\n\n        return second_response\n\nprint(function_calling())\n```\n\n축하합니다!\n\n이제 Google Colab에서 GPT-4o를 설정하고 사용하는 방법을 배웠습니다. 이 가이드는 기본 텍스트 완성, JSON 응답, 이미지 처리 및 함수 호출 내용을 다루었습니다. 이러한 기능을 확장하여 다양한 분야의 정교한 AI 응용프로그램을 구축할 수 있습니다. 즐거운 코딩하세요!\n\n<div class=\"content-ad\"></div>\n\n\n![Image](https://miro.medium.com/v2/resize:fit:1400/0*e35njv6_nLGt-8QY.gif)\n","ogImage":{"url":"/assets/img/2024-05-16-GettingStartedwithGPT-4oonGoogleColabAStep-by-StepGuide_0.png"},"coverImage":"/assets/img/2024-05-16-GettingStartedwithGPT-4oonGoogleColabAStep-by-StepGuide_0.png","tag":["Tech"],"readingTime":8},{"title":"전문 블로그 포스트 스타일로 해석하면 다음과 같습니다 최고의 전투  LLama 3, Claude 3, GPT4 옴니, Gemini 15 Pro-Light 등","description":"","date":"2024-05-16 17:33","slug":"2024-05-16-BattleoftheTOPLLama3Claude3GPT4OmniGemini15Pro-Lightandmore","content":"\n\n모든 것이 적어도 다음 순간까지 조용해 보였으니, 최신 TOP 모델들을 다중 모달리티, 능력, 맥락, 성능 및 가격을 고려하여 비교해봅시다.\n\n## 다중 모달리티\n\n![다중 모달리티 이미지](/assets/img/2024-05-16-BattleoftheTOPLLama3Claude3GPT4OmniGemini15Pro-Lightandmore_0.png)\n\n지금은 이미지가 상용 모델에서 흔하지만 LLama 3를 제외한 모든 모델이 이미지를 가지고 있습니다 (META는 올해 후반에 다중 모달 런치를 약속했습니다).\n\n<div class=\"content-ad\"></div>\n\n금니 1.5 버전과 GPT 4 Omni는 오디오 및 비디오(어떤 면에서는 그 스냅샷)를 처리할 수 있는 기능으로 눈에 띕니다.\n\n그리고 지금은 GPT 4 Omni만이 이러한 모달리티의 모든 기능을 갖췄지만, api에서는 오늘날 사용할 수 없으며 올해 후반에 가능할 예정입니다.\n\n# 문맥 길이\n\n![이미지](/assets/img/2024-05-16-BattleoftheTOPLLama3Claude3GPT4OmniGemini15Pro-Lightandmore_1.png)\n\n<div class=\"content-ad\"></div>\n\n이제 우리는 베타 테스팅을 위해 2M 토큰을 갖춘 Gemini와 나중에 전체 릴리즈를 위한 큰 컨텍스트 창을 갖추었습니다. Claude 3는 1M으로 따르며, GPT 4는 128K로 진행했고, LLama는 8K로 증가했습니다.\n\n실제 사용은 우리가 한계에 도달했을 때 이 컨텍스트 중 얼마나 사용되는지를 알려주는 논문 RULER에 기반한 점수를 보여줍니다. Llama 3이 더 작은 창을 갖고 있지만 매우 최적화된 사용을 보여주는 것이 흥미로운데요.\n\n# 벤치마크\n\n## 텍스트\n\n<div class=\"content-ad\"></div>\n\n<img src=\"/assets/img/2024-05-16-BattleoftheTOPLLama3Claude3GPT4OmniGemini15Pro-Lightandmore_2.png\" />\n\n모든 점수를 분석해 보면 모두 동일한 수준에 있다는 것을 알 수 있습니다. 이제 GPT4o와 Gemini 1.5 Flash가 모든 추가 기능을 가지고 있음에도 불구하고 매우 빠르게 응답한다는 것은 상당히 인상적입니다. 이는 다른 제품들의 응답 속도에 지연이 발생하는 반면에 잘 작동합니다.\n\n물론, LLama 3도 크기와 비교했을 때 매우 인상적하며 매우 양호한 점수를 얻고 있습니다.\n\n## 비전\n\n<div class=\"content-ad\"></div>\n\n아래는 테이블로 변환된 내용입니다.\n\n\n![](/assets/img/2024-05-16-BattleoftheTOPLLama3Claude3GPT4OmniGemini15Pro-Lightandmore_3.png)\n\n여전히 모두 같은 범위에 있는 것 같아요.\n\n# 가격\n\n![](/assets/img/2024-05-16-BattleoftheTOPLLama3Claude3GPT4OmniGemini15Pro-Lightandmore_4.png)\n\n\n<div class=\"content-ad\"></div>\n\n이 목록은 이러한 모델들의 가격을 나타냅니다. 오늘날 GPT4 Omni는 다른 모델들과 비교하여 독특한 능력을 갖고 있지 않지만 GPT 4 Turbo보다 빠른 버전으로, 시각에 대해서는 Gemini 1.5 및 Claude 3의 대안이 있고 텍스트에 대해서는 해당하는 모든 것이 있습니다.\n\nGPT 4 Omni는 아직 매우 비싸다는 것을 알 수 있습니다. 단지 Claude 3 Opus에 밀리는 것 뿐입니다.\n\n마지막으로 LLama 3, Claude 3 Haiku 및 Gemini 1.5 Flash는 가장 좋은 성능 대비 비용을 가지고 있으며, 중간/간단한 작업을 대부분 수행할 수 있기 때문입니다.\n\n이 데이터 컴필레이션이 솔루션에 대해 더 나은 성능 대비 비용 모델을 선택하는 데 도움이 되기를 바랍니다.\n\n<div class=\"content-ad\"></div>\n\n최근 오픈 소스 모델의 벤치마크를 비교할 계획입니다.\n\n참고: GPT4 Omni의 기술 보고서에 대한 접근이 아직 없어 오디오 및 비디오의 벤치마크를 수행하지 않았습니다. 해당 보고서가 공개되면 분석할 예정입니다.","ogImage":{"url":"/assets/img/2024-05-16-BattleoftheTOPLLama3Claude3GPT4OmniGemini15Pro-Lightandmore_0.png"},"coverImage":"/assets/img/2024-05-16-BattleoftheTOPLLama3Claude3GPT4OmniGemini15Pro-Lightandmore_0.png","tag":["Tech"],"readingTime":3}],"page":"24","totalPageCount":99,"totalPageGroupCount":5,"lastPageGroup":20,"currentPageGroup":1},"__N_SSG":true}