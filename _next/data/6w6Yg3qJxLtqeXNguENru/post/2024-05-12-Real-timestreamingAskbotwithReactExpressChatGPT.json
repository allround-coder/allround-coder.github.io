{"pageProps":{"post":{"title":"리얼타임 스트리밍 Askbot을 React, Express, ChatGPT로 개발하기","description":"","date":"2024-05-12 20:32","slug":"2024-05-12-Real-timestreamingAskbotwithReactExpressChatGPT","content":"\n\n![이미지](https://miro.medium.com/v2/resize:fit:1244/1*pgF3zoeDTN7tEbUP67AzaA.gif)\n\n이 블로그는 React를 사용하여 ChatGPT 앱을 안전하게 설정하는 데 초점을 맞춥니다.\n\nOpenAI는 클라이언트 라이브러리를 제공하여 React 앱에서 ChatGPT를 직접 사용할 수 있지만, 라이브러리 자체가 경고하는 대로:\n\n그러므로 이상적인 방법은 서버가 ChatGPT와 통신하여 원하는 응답을 받은 다음 해당 응답을 다시 React 앱으로 전달하는 것입니다.\n\n\n\n하지만 위 스크린샷에 나와 있는 것처럼 ChatGPT와 같은 스트리밍 응답을 어떻게 구현할 수 있을까요?\n\n이를 달성하기 위한 세 가지 단계는 다음과 같습니다:\n\n- NodeJS-Express 서버 설정\n- OpenAI 및 스트리밍 응답 설정\n- React 앱에서 작동시키기\n\n# NodeJS-Express 서버 설정\n\n\n\n첫 번째로, React 앱과 OpenAI ChatGPT API 사이에서 중계 역할을 하는 Express 서버를 만들어야 합니다. 이 서버는 OpenAI로의 API 호출을 처리하고 응답을 React 앱으로 스트리밍합니다.\n\n먼저 Node.js와 npm이 설치되어 있는지 확인하세요. 그런 다음 프로젝트 디렉토리에서 다음 명령을 실행하세요:\n\n```js\nnpm install express cors body-parser\n```\n\n아래 코드를 사용하여 app.js에 빠른 Express 서버 설정을해보세요:\n\n\n\n```js\nimport express from \"express\";\nimport bodyParser from \"body-parser\";\nimport cors from \"cors\";\n\nconst app = express();\nconst port = 2000;\napp.use(bodyParser.json());\napp.use(bodyParser.urlencoded({ extended: false }));\napp.use(cors());\n\napp.get(\"/\", (req, res) => {\n  return res.json({ data: \"success\" });\n});\n\n\napp.listen(port, () => {\n  console.log(`Example app listening on port ${port}`);\n});\n```\n\n다음 명령어를 사용하여 서버를 실행하세요:\n\n```js\nnode app.js\n```\n\n팁: 언제든지 변경 사항을 만들 때마다 Express 서버를 다시로드하려면 nodemon을 사용할 수 있습니다.\n\n\n\n# OpenAI 및 스트리밍 응답 설정\n\n## OpenAI 설정하기\n\n오픈에이아이 라이브러리를 설치하고 시작하세요!\n\n```js\nimport OpenAI from \"openai\";\n\nconst client = new OpenAI({\n  apiKey: 'YOUR_OPENAI_API_KEY',\n});\n\nconst systemMessage = {\n  role: \"system\",\n  content:\n    \"You are a Askbot. You are supposed to answer the questions asked by the users. Validate the prompts to be a question and it should not in approprite. Give funky responses\",\n};\n\nexport const getStreamingCompletion = async ({ userPrompt }) => {\n  return client.chat.completions.create({\n    model: \"gpt-3.5-turbo\",\n    messages: [systemMessage, { role: \"user\", content: userPrompt }],\n    stream: true,\n  });\n};\n```\n\n\n\nOpenAI 웹사이트에서 실제 OpenAI API 키를 얻을 수 있습니다.\n\n작성 시점에서 현재 안정 버전인 openai 라이브러리(3.3.0)에서는 스트리밍이 제대로 작동하지 않습니다. 여기에 설명된 대로.\n\n라이브러리의 곧 출시될 v4 버전에서는 이를 지원할 것입니다. 베타 버전을 통해 이미 사용 가능합니다. 그럼 설치해봅시다:\nnpm install openai@4.0.0-beta.6 . 코드는 그대로 유지됩니다.\n\n## ChatGPT에서 스트리밍 패치 설정\n\n\n\n스트리밍 응답의 큰 장점은 응답이 도착하는 대로 표시될 수 있어 사용자가 완전한 응답을 기다릴 필요가 없다는 것입니다. 이것은 프롬프트에 따라 시간이 오래 소요될 수 있기 때문에 중요합니다.\n\n스트리밍 응답을 소비하려면 아래 코드를 확인해보세요:\n\n```js\nlet starttime = Date.now();\nconst stream = await getStreamingCompletion({ userPrompt: userPrompt });\n for await (const part of stream) {\n    const chunkTime = (Date.now() - starttime) / 1000;\n    process.stdout.write(JSON.stringify(part.choices[0]?.delta || \"\"));\n    console.log(\" chunk time:\", chunkTime);\n}\n```\n\n해보세요. 델타와 해당 델타가 표시되기까지 걸린 시간을 볼 수 있어야 합니다. 델타는 결과에서 다음 토큰입니다. 사용자가 \"안녕\"이라는 프롬프트를 제시하면 다음과 유사한 응답을 받게 될 것입니다:\n\n\n\n\n![이미지](/assets/img/2024-05-12-Real-timestreamingAskbotwithReactExpressChatGPT_0.png)\n\n## Express API로부터의 스트리밍 응답\n\nExpress에는 응답을 스트림으로 반환하는 API가 이미 준비되어 있습니다.\n\n아래는 Express 서버의 전체 코드입니다:\n\n\n\n```js\nimport express from \"express\";\nimport bodyParser from \"body-parser\";\nimport cors from \"cors\";\nimport { getStreamingCompletion } from \"./src/modules/openai/index.js\";\n\nconst app = express();\nconst port = 2000;\napp.use(bodyParser.json());\napp.use(bodyParser.urlencoded({ extended: false }));\napp.use(cors());\n\napp.get(\"/\", (req, res) => {\n  return res.json({ data: \"success\" });\n});\n\napp.post(\"/aiCompletion\", async (req, res) => {\n  const data = req.body;\n  let starttime = Date.now();\n  const stream = await getStreamingCompletion({ userPrompt: data?.userPrompt });\n  for await (const part of stream) {\n    // here express will stream the response\n    res.write(part.choices[0]?.delta.content || \"\");\n  }\n  // here express sends the closing/done/end signal for the stream consumer\n  res.end();\n});\n\napp.listen(port, () => {\n  console.log(`Example app listening on port ${port}`);\n});\n```\n# 리액트 앱에서 작동시키는 방법\n\n프론트 엔드를 설정해 봅시다. 나는 React SPA를 사용하고 있어요. 왜 SPA를 사용하냐고요? Next나 Remix가 제공하는 풀 스택 기능이 필요하지 않기 때문에 ExpressJS 기반의 백엔드를 이미 사용하고 있어요.\n\nVite를 사용해서 빠르게 설정해 보세요 (당연한 이유로 CRA는 사용하지 않는 것이 좋아요).\n\n\n\n스트리밍 데이터를 읽기 위해 응답으로부터 리더를 사용해야 하며, 그 데이터를 바이트 스트림에서 문자열로 변환하기 위해 디코딩해야 합니다. 아래는 그에 대한 샘플 코드입니다:\n\n```js\n  // 사용자 프롬프트에 기반한 서버 응답 가져오기\n  const response = await fetch(\"http://localhost:2000/aiCompletion\", {\n    method: \"post\",\n    headers: {\n      Accept: \"application/json, text/plain, */*\",\n      \"Content-Type\": \"application/json\",\n    },\n    body: JSON.stringify({ userPrompt: prompt }),\n  });\n  if (!response.ok || !response.body) {\n    throw response.statusText;\n  }\n\n  // 여기서 스트리밍 응답 준비를 시작합니다\n  const reader = response.body.getReader();\n  const decoder = new TextDecoder();\n  const loopRunner = true;\n\n  while (loopRunner) {\n    // 여기서 스트림을 읽기 시작합니다. 완료될 때까지.\n    const { value, done } = await reader.read();\n    if (done) {\n      break;\n    }\n    const decodedChunk = decoder.decode(value, { stream: true });\n    setAnswer(answer => answer + decodedChunk); // 새 청크로 상태 업데이트\n  }\n```\n\nReact에서 useState를 사용하여 decodedChunk를 추가해 실시간 스트리밍 응답을 형성할 수 있습니다.\n\n이 예제는 ReactJS, Express, 그리고 OpenAI ChatGPT API를 사용하여 스트리밍 채팅 응답을 구현하는 기본적인 예제를 보여줍니다. 사용 사례 및 요구 사항에 따라 오류 처리를 개선하거나 스타일을 추가하고 대화 흐름을 세밀하게 조정해야 할 수 있습니다.\n\n\n\n당신은 이 레포지토리를 사용하여 직접 askbot을 실행하고 실험해볼 수 있어요.","ogImage":{"url":"/assets/img/2024-05-12-Real-timestreamingAskbotwithReactExpressChatGPT_0.png"},"coverImage":"/assets/img/2024-05-12-Real-timestreamingAskbotwithReactExpressChatGPT_0.png","tag":["Tech"],"readingTime":6},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p><img src=\"https://miro.medium.com/v2/resize:fit:1244/1*pgF3zoeDTN7tEbUP67AzaA.gif\" alt=\"이미지\"></p>\n<p>이 블로그는 React를 사용하여 ChatGPT 앱을 안전하게 설정하는 데 초점을 맞춥니다.</p>\n<p>OpenAI는 클라이언트 라이브러리를 제공하여 React 앱에서 ChatGPT를 직접 사용할 수 있지만, 라이브러리 자체가 경고하는 대로:</p>\n<p>그러므로 이상적인 방법은 서버가 ChatGPT와 통신하여 원하는 응답을 받은 다음 해당 응답을 다시 React 앱으로 전달하는 것입니다.</p>\n<p>하지만 위 스크린샷에 나와 있는 것처럼 ChatGPT와 같은 스트리밍 응답을 어떻게 구현할 수 있을까요?</p>\n<p>이를 달성하기 위한 세 가지 단계는 다음과 같습니다:</p>\n<ul>\n<li>NodeJS-Express 서버 설정</li>\n<li>OpenAI 및 스트리밍 응답 설정</li>\n<li>React 앱에서 작동시키기</li>\n</ul>\n<h1>NodeJS-Express 서버 설정</h1>\n<p>첫 번째로, React 앱과 OpenAI ChatGPT API 사이에서 중계 역할을 하는 Express 서버를 만들어야 합니다. 이 서버는 OpenAI로의 API 호출을 처리하고 응답을 React 앱으로 스트리밍합니다.</p>\n<p>먼저 Node.js와 npm이 설치되어 있는지 확인하세요. 그런 다음 프로젝트 디렉토리에서 다음 명령을 실행하세요:</p>\n<pre><code class=\"hljs language-js\">npm install express cors body-parser\n</code></pre>\n<p>아래 코드를 사용하여 app.js에 빠른 Express 서버 설정을해보세요:</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">import</span> express <span class=\"hljs-keyword\">from</span> <span class=\"hljs-string\">\"express\"</span>;\n<span class=\"hljs-keyword\">import</span> bodyParser <span class=\"hljs-keyword\">from</span> <span class=\"hljs-string\">\"body-parser\"</span>;\n<span class=\"hljs-keyword\">import</span> cors <span class=\"hljs-keyword\">from</span> <span class=\"hljs-string\">\"cors\"</span>;\n\n<span class=\"hljs-keyword\">const</span> app = <span class=\"hljs-title function_\">express</span>();\n<span class=\"hljs-keyword\">const</span> port = <span class=\"hljs-number\">2000</span>;\napp.<span class=\"hljs-title function_\">use</span>(bodyParser.<span class=\"hljs-title function_\">json</span>());\napp.<span class=\"hljs-title function_\">use</span>(bodyParser.<span class=\"hljs-title function_\">urlencoded</span>({ <span class=\"hljs-attr\">extended</span>: <span class=\"hljs-literal\">false</span> }));\napp.<span class=\"hljs-title function_\">use</span>(<span class=\"hljs-title function_\">cors</span>());\n\napp.<span class=\"hljs-title function_\">get</span>(<span class=\"hljs-string\">\"/\"</span>, <span class=\"hljs-function\">(<span class=\"hljs-params\">req, res</span>) =></span> {\n  <span class=\"hljs-keyword\">return</span> res.<span class=\"hljs-title function_\">json</span>({ <span class=\"hljs-attr\">data</span>: <span class=\"hljs-string\">\"success\"</span> });\n});\n\n\napp.<span class=\"hljs-title function_\">listen</span>(port, <span class=\"hljs-function\">() =></span> {\n  <span class=\"hljs-variable language_\">console</span>.<span class=\"hljs-title function_\">log</span>(<span class=\"hljs-string\">`Example app listening on port <span class=\"hljs-subst\">${port}</span>`</span>);\n});\n</code></pre>\n<p>다음 명령어를 사용하여 서버를 실행하세요:</p>\n<pre><code class=\"hljs language-js\">node app.<span class=\"hljs-property\">js</span>\n</code></pre>\n<p>팁: 언제든지 변경 사항을 만들 때마다 Express 서버를 다시로드하려면 nodemon을 사용할 수 있습니다.</p>\n<h1>OpenAI 및 스트리밍 응답 설정</h1>\n<h2>OpenAI 설정하기</h2>\n<p>오픈에이아이 라이브러리를 설치하고 시작하세요!</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">import</span> <span class=\"hljs-title class_\">OpenAI</span> <span class=\"hljs-keyword\">from</span> <span class=\"hljs-string\">\"openai\"</span>;\n\n<span class=\"hljs-keyword\">const</span> client = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">OpenAI</span>({\n  <span class=\"hljs-attr\">apiKey</span>: <span class=\"hljs-string\">'YOUR_OPENAI_API_KEY'</span>,\n});\n\n<span class=\"hljs-keyword\">const</span> systemMessage = {\n  <span class=\"hljs-attr\">role</span>: <span class=\"hljs-string\">\"system\"</span>,\n  <span class=\"hljs-attr\">content</span>:\n    <span class=\"hljs-string\">\"You are a Askbot. You are supposed to answer the questions asked by the users. Validate the prompts to be a question and it should not in approprite. Give funky responses\"</span>,\n};\n\n<span class=\"hljs-keyword\">export</span> <span class=\"hljs-keyword\">const</span> <span class=\"hljs-title function_\">getStreamingCompletion</span> = <span class=\"hljs-keyword\">async</span> (<span class=\"hljs-params\">{ userPrompt }</span>) => {\n  <span class=\"hljs-keyword\">return</span> client.<span class=\"hljs-property\">chat</span>.<span class=\"hljs-property\">completions</span>.<span class=\"hljs-title function_\">create</span>({\n    <span class=\"hljs-attr\">model</span>: <span class=\"hljs-string\">\"gpt-3.5-turbo\"</span>,\n    <span class=\"hljs-attr\">messages</span>: [systemMessage, { <span class=\"hljs-attr\">role</span>: <span class=\"hljs-string\">\"user\"</span>, <span class=\"hljs-attr\">content</span>: userPrompt }],\n    <span class=\"hljs-attr\">stream</span>: <span class=\"hljs-literal\">true</span>,\n  });\n};\n</code></pre>\n<p>OpenAI 웹사이트에서 실제 OpenAI API 키를 얻을 수 있습니다.</p>\n<p>작성 시점에서 현재 안정 버전인 openai 라이브러리(3.3.0)에서는 스트리밍이 제대로 작동하지 않습니다. 여기에 설명된 대로.</p>\n<p>라이브러리의 곧 출시될 v4 버전에서는 이를 지원할 것입니다. 베타 버전을 통해 이미 사용 가능합니다. 그럼 설치해봅시다:\nnpm install openai@4.0.0-beta.6 . 코드는 그대로 유지됩니다.</p>\n<h2>ChatGPT에서 스트리밍 패치 설정</h2>\n<p>스트리밍 응답의 큰 장점은 응답이 도착하는 대로 표시될 수 있어 사용자가 완전한 응답을 기다릴 필요가 없다는 것입니다. 이것은 프롬프트에 따라 시간이 오래 소요될 수 있기 때문에 중요합니다.</p>\n<p>스트리밍 응답을 소비하려면 아래 코드를 확인해보세요:</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">let</span> starttime = <span class=\"hljs-title class_\">Date</span>.<span class=\"hljs-title function_\">now</span>();\n<span class=\"hljs-keyword\">const</span> stream = <span class=\"hljs-keyword\">await</span> <span class=\"hljs-title function_\">getStreamingCompletion</span>({ <span class=\"hljs-attr\">userPrompt</span>: userPrompt });\n <span class=\"hljs-keyword\">for</span> <span class=\"hljs-keyword\">await</span> (<span class=\"hljs-keyword\">const</span> part <span class=\"hljs-keyword\">of</span> stream) {\n    <span class=\"hljs-keyword\">const</span> chunkTime = (<span class=\"hljs-title class_\">Date</span>.<span class=\"hljs-title function_\">now</span>() - starttime) / <span class=\"hljs-number\">1000</span>;\n    process.<span class=\"hljs-property\">stdout</span>.<span class=\"hljs-title function_\">write</span>(<span class=\"hljs-title class_\">JSON</span>.<span class=\"hljs-title function_\">stringify</span>(part.<span class=\"hljs-property\">choices</span>[<span class=\"hljs-number\">0</span>]?.<span class=\"hljs-property\">delta</span> || <span class=\"hljs-string\">\"\"</span>));\n    <span class=\"hljs-variable language_\">console</span>.<span class=\"hljs-title function_\">log</span>(<span class=\"hljs-string\">\" chunk time:\"</span>, chunkTime);\n}\n</code></pre>\n<p>해보세요. 델타와 해당 델타가 표시되기까지 걸린 시간을 볼 수 있어야 합니다. 델타는 결과에서 다음 토큰입니다. 사용자가 \"안녕\"이라는 프롬프트를 제시하면 다음과 유사한 응답을 받게 될 것입니다:</p>\n<p><img src=\"/assets/img/2024-05-12-Real-timestreamingAskbotwithReactExpressChatGPT_0.png\" alt=\"이미지\"></p>\n<h2>Express API로부터의 스트리밍 응답</h2>\n<p>Express에는 응답을 스트림으로 반환하는 API가 이미 준비되어 있습니다.</p>\n<p>아래는 Express 서버의 전체 코드입니다:</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">import</span> express <span class=\"hljs-keyword\">from</span> <span class=\"hljs-string\">\"express\"</span>;\n<span class=\"hljs-keyword\">import</span> bodyParser <span class=\"hljs-keyword\">from</span> <span class=\"hljs-string\">\"body-parser\"</span>;\n<span class=\"hljs-keyword\">import</span> cors <span class=\"hljs-keyword\">from</span> <span class=\"hljs-string\">\"cors\"</span>;\n<span class=\"hljs-keyword\">import</span> { getStreamingCompletion } <span class=\"hljs-keyword\">from</span> <span class=\"hljs-string\">\"./src/modules/openai/index.js\"</span>;\n\n<span class=\"hljs-keyword\">const</span> app = <span class=\"hljs-title function_\">express</span>();\n<span class=\"hljs-keyword\">const</span> port = <span class=\"hljs-number\">2000</span>;\napp.<span class=\"hljs-title function_\">use</span>(bodyParser.<span class=\"hljs-title function_\">json</span>());\napp.<span class=\"hljs-title function_\">use</span>(bodyParser.<span class=\"hljs-title function_\">urlencoded</span>({ <span class=\"hljs-attr\">extended</span>: <span class=\"hljs-literal\">false</span> }));\napp.<span class=\"hljs-title function_\">use</span>(<span class=\"hljs-title function_\">cors</span>());\n\napp.<span class=\"hljs-title function_\">get</span>(<span class=\"hljs-string\">\"/\"</span>, <span class=\"hljs-function\">(<span class=\"hljs-params\">req, res</span>) =></span> {\n  <span class=\"hljs-keyword\">return</span> res.<span class=\"hljs-title function_\">json</span>({ <span class=\"hljs-attr\">data</span>: <span class=\"hljs-string\">\"success\"</span> });\n});\n\napp.<span class=\"hljs-title function_\">post</span>(<span class=\"hljs-string\">\"/aiCompletion\"</span>, <span class=\"hljs-keyword\">async</span> (req, res) => {\n  <span class=\"hljs-keyword\">const</span> data = req.<span class=\"hljs-property\">body</span>;\n  <span class=\"hljs-keyword\">let</span> starttime = <span class=\"hljs-title class_\">Date</span>.<span class=\"hljs-title function_\">now</span>();\n  <span class=\"hljs-keyword\">const</span> stream = <span class=\"hljs-keyword\">await</span> <span class=\"hljs-title function_\">getStreamingCompletion</span>({ <span class=\"hljs-attr\">userPrompt</span>: data?.<span class=\"hljs-property\">userPrompt</span> });\n  <span class=\"hljs-keyword\">for</span> <span class=\"hljs-keyword\">await</span> (<span class=\"hljs-keyword\">const</span> part <span class=\"hljs-keyword\">of</span> stream) {\n    <span class=\"hljs-comment\">// here express will stream the response</span>\n    res.<span class=\"hljs-title function_\">write</span>(part.<span class=\"hljs-property\">choices</span>[<span class=\"hljs-number\">0</span>]?.<span class=\"hljs-property\">delta</span>.<span class=\"hljs-property\">content</span> || <span class=\"hljs-string\">\"\"</span>);\n  }\n  <span class=\"hljs-comment\">// here express sends the closing/done/end signal for the stream consumer</span>\n  res.<span class=\"hljs-title function_\">end</span>();\n});\n\napp.<span class=\"hljs-title function_\">listen</span>(port, <span class=\"hljs-function\">() =></span> {\n  <span class=\"hljs-variable language_\">console</span>.<span class=\"hljs-title function_\">log</span>(<span class=\"hljs-string\">`Example app listening on port <span class=\"hljs-subst\">${port}</span>`</span>);\n});\n</code></pre>\n<h1>리액트 앱에서 작동시키는 방법</h1>\n<p>프론트 엔드를 설정해 봅시다. 나는 React SPA를 사용하고 있어요. 왜 SPA를 사용하냐고요? Next나 Remix가 제공하는 풀 스택 기능이 필요하지 않기 때문에 ExpressJS 기반의 백엔드를 이미 사용하고 있어요.</p>\n<p>Vite를 사용해서 빠르게 설정해 보세요 (당연한 이유로 CRA는 사용하지 않는 것이 좋아요).</p>\n<p>스트리밍 데이터를 읽기 위해 응답으로부터 리더를 사용해야 하며, 그 데이터를 바이트 스트림에서 문자열로 변환하기 위해 디코딩해야 합니다. 아래는 그에 대한 샘플 코드입니다:</p>\n<pre><code class=\"hljs language-js\">  <span class=\"hljs-comment\">// 사용자 프롬프트에 기반한 서버 응답 가져오기</span>\n  <span class=\"hljs-keyword\">const</span> response = <span class=\"hljs-keyword\">await</span> <span class=\"hljs-title function_\">fetch</span>(<span class=\"hljs-string\">\"http://localhost:2000/aiCompletion\"</span>, {\n    <span class=\"hljs-attr\">method</span>: <span class=\"hljs-string\">\"post\"</span>,\n    <span class=\"hljs-attr\">headers</span>: {\n      <span class=\"hljs-title class_\">Accept</span>: <span class=\"hljs-string\">\"application/json, text/plain, */*\"</span>,\n      <span class=\"hljs-string\">\"Content-Type\"</span>: <span class=\"hljs-string\">\"application/json\"</span>,\n    },\n    <span class=\"hljs-attr\">body</span>: <span class=\"hljs-title class_\">JSON</span>.<span class=\"hljs-title function_\">stringify</span>({ <span class=\"hljs-attr\">userPrompt</span>: prompt }),\n  });\n  <span class=\"hljs-keyword\">if</span> (!response.<span class=\"hljs-property\">ok</span> || !response.<span class=\"hljs-property\">body</span>) {\n    <span class=\"hljs-keyword\">throw</span> response.<span class=\"hljs-property\">statusText</span>;\n  }\n\n  <span class=\"hljs-comment\">// 여기서 스트리밍 응답 준비를 시작합니다</span>\n  <span class=\"hljs-keyword\">const</span> reader = response.<span class=\"hljs-property\">body</span>.<span class=\"hljs-title function_\">getReader</span>();\n  <span class=\"hljs-keyword\">const</span> decoder = <span class=\"hljs-keyword\">new</span> <span class=\"hljs-title class_\">TextDecoder</span>();\n  <span class=\"hljs-keyword\">const</span> loopRunner = <span class=\"hljs-literal\">true</span>;\n\n  <span class=\"hljs-keyword\">while</span> (loopRunner) {\n    <span class=\"hljs-comment\">// 여기서 스트림을 읽기 시작합니다. 완료될 때까지.</span>\n    <span class=\"hljs-keyword\">const</span> { value, done } = <span class=\"hljs-keyword\">await</span> reader.<span class=\"hljs-title function_\">read</span>();\n    <span class=\"hljs-keyword\">if</span> (done) {\n      <span class=\"hljs-keyword\">break</span>;\n    }\n    <span class=\"hljs-keyword\">const</span> decodedChunk = decoder.<span class=\"hljs-title function_\">decode</span>(value, { <span class=\"hljs-attr\">stream</span>: <span class=\"hljs-literal\">true</span> });\n    <span class=\"hljs-title function_\">setAnswer</span>(<span class=\"hljs-function\"><span class=\"hljs-params\">answer</span> =></span> answer + decodedChunk); <span class=\"hljs-comment\">// 새 청크로 상태 업데이트</span>\n  }\n</code></pre>\n<p>React에서 useState를 사용하여 decodedChunk를 추가해 실시간 스트리밍 응답을 형성할 수 있습니다.</p>\n<p>이 예제는 ReactJS, Express, 그리고 OpenAI ChatGPT API를 사용하여 스트리밍 채팅 응답을 구현하는 기본적인 예제를 보여줍니다. 사용 사례 및 요구 사항에 따라 오류 처리를 개선하거나 스타일을 추가하고 대화 흐름을 세밀하게 조정해야 할 수 있습니다.</p>\n<p>당신은 이 레포지토리를 사용하여 직접 askbot을 실행하고 실험해볼 수 있어요.</p>\n</body>\n</html>\n"},"__N_SSG":true}