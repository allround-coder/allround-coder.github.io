{"pageProps":{"post":{"title":"파이스파크 인터뷰 질문 by COFORGE","description":"","date":"2024-06-20 01:48","slug":"2024-06-20-PySparkInterviewQuestionbyCOFORGE","content":"\n\n이 글에서는 고객 거래 데이터 세트를 사용하여 PySpark를 사용하여 데이터 변환 및 분석을 수행하는 방법을 살펴보겠습니다.\n\n문제 명시:\n\n-PySpark 코드를 작성하여 $10,000보다 큰 고객 거래를 필터링하고, 고객 이름을 첫 글자는 대문자로 변환하고 나머지는 소문자로 변환하고, 각 제품 카테고리별 평균 거래 금액을 계산하십시오.\n\n해결책:\n\n<div class=\"content-ad\"></div>\n\nPySpark 스크립트는 네 가지 주요 단계에서 다음 작업을 수행합니다:\n\n1. **데이터 수집 및 변환:**\n- 샘플 고객 거래 데이터를 Spark DataFrame으로 읽어옵니다.\n- 고객 이름을 `initcap` 형식으로 변환합니다 (첫 글자를 대문자로 변환하고 나머지는 소문자로 변환).\n\n2. **데이터 필터링:**\n- 거래를 10,000 이상인 것만 포함하도록 필터링합니다.\n\n3. **집계:**\n- 각 제품 카테고리별 평균 거래 금액을 계산합니다.\n\n<div class=\"content-ad\"></div>\n\n4. **결과 표시:**\n- 제품 카테고리별 평균 거래액과 함께 변환된 고객 데이터를 표시합니다.\n\n```python\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col, avg, initcap\n\n# SparkSession 생성\nspark = SparkSession.builder \\\n    .appName(\"CustomerTransactionAnalysis\") \\\n    .getOrCreate()\n\n# 대문자로 된 고객 이름이 포함된 고객 거래의 샘플 데이터\ndata = [\n    (1, \"ALICE\", 12000, \"전자제품\"),\n    (2, \"BOB\", 9000, \"가전제품\"),\n    (3, \"CHARLIE\", 15000, \"패션\"),\n    (4, \"DANIEL\", 8000, \"전자제품\"),\n    (5, \"EMMA\", 11000, \"패션\"),\n    (6, \"FRANK\", 13000, \"가전제품\"),\n    (7, \"GINA\", 10000, \"전자제품\"),\n    (8, \"HENRY\", 14000, \"패션\"),\n    (9, \"ISABELLA\", 9500, \"가전제품\"),\n    (10, \"JACK\", 10500, \"전자제품\")\n]\n\n# 샘플 데이터로부터 DataFrame 생성\ncustomer_df = spark.createDataFrame(data, [\"customer_id\", \"customer_name\", \"transaction\", \"product_category\"])\n\n# 초기 데이터 표시\nprint(\"초기 데이터:\")\ncustomer_df.show()\n\n# 고객 이름을 initcap 형식으로 변환\ntransformed_df = customer_df.withColumn(\"customer_name_transformed\", initcap(col(\"customer_name\")))\n\n# 10,000보다 큰 고객 거래 필터링\nfiltered_transactions = transformed_df.filter(col(\"transaction\") > 10000)\n\n# 각 제품 카테고리별 평균 거래액 계산\navg_transaction_by_category = filtered_transactions.groupBy(\"product_category\") \\\n    .agg(avg(\"transaction\").alias(\"avg_transaction\"))\n\n# 평균과 함께 변환된 데이터 표시\nprint(\"\\n평균이 포함된 변환된 데이터:\")\nresult = filtered_transactions.select(\"customer_name_transformed\", \"product_category\", \"transaction\") \\\n    .join(avg_transaction_by_category, \"product_category\") \\\n    .orderBy(\"product_category\")\n\nresult.show(truncate=False)\n\n# SparkSession 중지\nspark.stop()\n```\n\n출력:\n\n<img src=\"/assets/img/2024-06-20-PySparkInterviewQuestionbyCOFORGE_0.png\" />","ogImage":{"url":"/assets/img/2024-06-20-PySparkInterviewQuestionbyCOFORGE_0.png"},"coverImage":"/assets/img/2024-06-20-PySparkInterviewQuestionbyCOFORGE_0.png","tag":["Tech"],"readingTime":3},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<p>이 글에서는 고객 거래 데이터 세트를 사용하여 PySpark를 사용하여 데이터 변환 및 분석을 수행하는 방법을 살펴보겠습니다.</p>\n<p>문제 명시:</p>\n<p>-PySpark 코드를 작성하여 $10,000보다 큰 고객 거래를 필터링하고, 고객 이름을 첫 글자는 대문자로 변환하고 나머지는 소문자로 변환하고, 각 제품 카테고리별 평균 거래 금액을 계산하십시오.</p>\n<p>해결책:</p>\n<p>PySpark 스크립트는 네 가지 주요 단계에서 다음 작업을 수행합니다:</p>\n<ol>\n<li><strong>데이터 수집 및 변환:</strong></li>\n</ol>\n<ul>\n<li>샘플 고객 거래 데이터를 Spark DataFrame으로 읽어옵니다.</li>\n<li>고객 이름을 <code>initcap</code> 형식으로 변환합니다 (첫 글자를 대문자로 변환하고 나머지는 소문자로 변환).</li>\n</ul>\n<ol start=\"2\">\n<li><strong>데이터 필터링:</strong></li>\n</ol>\n<ul>\n<li>거래를 10,000 이상인 것만 포함하도록 필터링합니다.</li>\n</ul>\n<ol start=\"3\">\n<li><strong>집계:</strong></li>\n</ol>\n<ul>\n<li>각 제품 카테고리별 평균 거래 금액을 계산합니다.</li>\n</ul>\n<ol start=\"4\">\n<li><strong>결과 표시:</strong></li>\n</ol>\n<ul>\n<li>제품 카테고리별 평균 거래액과 함께 변환된 고객 데이터를 표시합니다.</li>\n</ul>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">from</span> pyspark.sql <span class=\"hljs-keyword\">import</span> SparkSession\n<span class=\"hljs-keyword\">from</span> pyspark.sql.functions <span class=\"hljs-keyword\">import</span> col, avg, initcap\n\n<span class=\"hljs-comment\"># SparkSession 생성</span>\nspark = SparkSession.builder \\\n    .appName(<span class=\"hljs-string\">\"CustomerTransactionAnalysis\"</span>) \\\n    .getOrCreate()\n\n<span class=\"hljs-comment\"># 대문자로 된 고객 이름이 포함된 고객 거래의 샘플 데이터</span>\ndata = [\n    (<span class=\"hljs-number\">1</span>, <span class=\"hljs-string\">\"ALICE\"</span>, <span class=\"hljs-number\">12000</span>, <span class=\"hljs-string\">\"전자제품\"</span>),\n    (<span class=\"hljs-number\">2</span>, <span class=\"hljs-string\">\"BOB\"</span>, <span class=\"hljs-number\">9000</span>, <span class=\"hljs-string\">\"가전제품\"</span>),\n    (<span class=\"hljs-number\">3</span>, <span class=\"hljs-string\">\"CHARLIE\"</span>, <span class=\"hljs-number\">15000</span>, <span class=\"hljs-string\">\"패션\"</span>),\n    (<span class=\"hljs-number\">4</span>, <span class=\"hljs-string\">\"DANIEL\"</span>, <span class=\"hljs-number\">8000</span>, <span class=\"hljs-string\">\"전자제품\"</span>),\n    (<span class=\"hljs-number\">5</span>, <span class=\"hljs-string\">\"EMMA\"</span>, <span class=\"hljs-number\">11000</span>, <span class=\"hljs-string\">\"패션\"</span>),\n    (<span class=\"hljs-number\">6</span>, <span class=\"hljs-string\">\"FRANK\"</span>, <span class=\"hljs-number\">13000</span>, <span class=\"hljs-string\">\"가전제품\"</span>),\n    (<span class=\"hljs-number\">7</span>, <span class=\"hljs-string\">\"GINA\"</span>, <span class=\"hljs-number\">10000</span>, <span class=\"hljs-string\">\"전자제품\"</span>),\n    (<span class=\"hljs-number\">8</span>, <span class=\"hljs-string\">\"HENRY\"</span>, <span class=\"hljs-number\">14000</span>, <span class=\"hljs-string\">\"패션\"</span>),\n    (<span class=\"hljs-number\">9</span>, <span class=\"hljs-string\">\"ISABELLA\"</span>, <span class=\"hljs-number\">9500</span>, <span class=\"hljs-string\">\"가전제품\"</span>),\n    (<span class=\"hljs-number\">10</span>, <span class=\"hljs-string\">\"JACK\"</span>, <span class=\"hljs-number\">10500</span>, <span class=\"hljs-string\">\"전자제품\"</span>)\n]\n\n<span class=\"hljs-comment\"># 샘플 데이터로부터 DataFrame 생성</span>\ncustomer_df = spark.createDataFrame(data, [<span class=\"hljs-string\">\"customer_id\"</span>, <span class=\"hljs-string\">\"customer_name\"</span>, <span class=\"hljs-string\">\"transaction\"</span>, <span class=\"hljs-string\">\"product_category\"</span>])\n\n<span class=\"hljs-comment\"># 초기 데이터 표시</span>\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"초기 데이터:\"</span>)\ncustomer_df.show()\n\n<span class=\"hljs-comment\"># 고객 이름을 initcap 형식으로 변환</span>\ntransformed_df = customer_df.withColumn(<span class=\"hljs-string\">\"customer_name_transformed\"</span>, initcap(col(<span class=\"hljs-string\">\"customer_name\"</span>)))\n\n<span class=\"hljs-comment\"># 10,000보다 큰 고객 거래 필터링</span>\nfiltered_transactions = transformed_df.<span class=\"hljs-built_in\">filter</span>(col(<span class=\"hljs-string\">\"transaction\"</span>) > <span class=\"hljs-number\">10000</span>)\n\n<span class=\"hljs-comment\"># 각 제품 카테고리별 평균 거래액 계산</span>\navg_transaction_by_category = filtered_transactions.groupBy(<span class=\"hljs-string\">\"product_category\"</span>) \\\n    .agg(avg(<span class=\"hljs-string\">\"transaction\"</span>).alias(<span class=\"hljs-string\">\"avg_transaction\"</span>))\n\n<span class=\"hljs-comment\"># 평균과 함께 변환된 데이터 표시</span>\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">\"\\n평균이 포함된 변환된 데이터:\"</span>)\nresult = filtered_transactions.select(<span class=\"hljs-string\">\"customer_name_transformed\"</span>, <span class=\"hljs-string\">\"product_category\"</span>, <span class=\"hljs-string\">\"transaction\"</span>) \\\n    .join(avg_transaction_by_category, <span class=\"hljs-string\">\"product_category\"</span>) \\\n    .orderBy(<span class=\"hljs-string\">\"product_category\"</span>)\n\nresult.show(truncate=<span class=\"hljs-literal\">False</span>)\n\n<span class=\"hljs-comment\"># SparkSession 중지</span>\nspark.stop()\n</code></pre>\n<p>출력:</p>\n</body>\n</html>\n"},"__N_SSG":true}