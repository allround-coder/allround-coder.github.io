{"pageProps":{"posts":[{"title":"Angular 18  새로운 주요 기능 및 개선사항TOP","description":"","date":"2024-05-15 10:42","slug":"2024-05-15-Angular18Topnewfeaturesandimprovements","content":"\n\n<img src=\"/assets/img/2024-05-15-Angular18Topnewfeaturesandimprovements_0.png\" />\n\n앵귤러 18의 릴리스 날짜가 금방 오다가 예상 데뷔일인 2024년 5월 20일에 기대감이 커지고 있습니다. 새로운 기능과 개선 사항이 무엇을 가져올지 기대되는 가운데, 앵귤러는 지속적으로 발전하여 개발자들의 요구 사항과 문제를 해결하고 각 업데이트마다 혁신, 최적화 및 개선을 제공합니다. 앵귤러 18에서 기대되는 새로운 기능들을 알아보겠습니다:\n\n# 함수를 사용한 라우트 리다이렉트\n\n앵귤러 18에서는 문자열 대신 함수를 사용하여 리디렉트를 관리할 수 있는 새로운 기능이 소개됩니다. 이 개선으로 라우팅에서 더 많은 유연성을 제공하고 새로운 가능성을 엽니다. 예를 들면:\n\n\n\n테이블 태그를 Markdown 형식으로 변경하면 다음과 같습니다.\n\n\nThe function can access an object with information about the URL, allowing for more dynamic redirection.\n\n## Default Content in ng-content\n\nDefault content is now allowed within the ng-content tag. This logical extension will enable developers to include default content directly in the tag itself:\n\n## New RedirectCommand class\n\n\n\n\n리다이렉트 명령 클래스인 RedirectCommand클래스를 도입하기 전에, Guards 및 Resolvers는 새로운 경로를 나타내는 UrlTree를 반환하여 네비게이션을 리다이렉트할 수 있었습니다. 그러나 이 방법은 NavigationExtras를 사용한 네비게이션 리다이렉션을 허용하지 않습니다. 예를 들어:\n\n이 문제를 해결하기 위해 Angular 18에서는 가드 및 리졸버에서 네비게이션 리다이렉션을 처리하는 NavigationExtras를 허용하는 새 RedirectCommand클래스를 소개했습니다.\n\n이 개선으로 Angular 애플리케이션에서 복잡한 네비게이션 패턴을 다루는 것이 더 쉬워지며 유지보수성과 유연성이 향상됩니다.\n\n# 새 ng-template API\n\n\n\nAngular 18은 ng-template API를 더 강력하고 유연하게 만들 수 있는 기능을 도입할 수도 있습니다.\n\n# 향상된 Forms API\n\nForms API는 몇 가지 향상을 받아서 더 강력하고 개발자 친화적입니다:\n\n- 좀 더 쉬운 Form 객체 정의: 이를 통해 폼 모델을 더 적은 보일러플레이트 코드로 작성할 수 있어 가독성과 유지 보수성을 향상시킵니다.\n- 간단한 유효성 검사 규칙: API는 대부분의 유효성 검사 시나리오에 대한 더 나은 추상화를 제공하여 필수 필드, 최소/최대 값, 패턴 및 사용자 정의 유효성 검사를 더 쉽게 관리할 수 있습니다.\n- 복잡한 유효성 검사 시나리오 관리: 교차 필드 유효성 검사나 동적 유효성 규칙 등에 대한 Angular 18의 기능을 통해 복잡한 경우를 더 잘 관리할 수 있습니다.\n- 세밀한 제어: 폼 유효성 검사에 대해 더 많은 제어를 제공하여 오류 메시지를 사용자 정의하고 비동기적 유효성 검사를 처리하며 사용자 입력에 효과적으로 반응할 수 있습니다.\n\n\n\n# Zoneless Applications\n\nAngular 18은 응용 프로그램에 신호를 통합하여 zone.js에 의존하지 않고 작동하도록 합니다. 이 최적화는 성능과 응답 시간을 향상시킵니다.\n\nMatthieu Riegler와 Enea Jahollari는 각각이 주제에 관한 기사를 게시했습니다.\n\nMatthieu의 기사는 새로운 하이브리드 변경 감지 시스템에 깊이 들어가며 Signal 변경 또는 markForCheck를 호출하는 비동기(pipe)와 같은 작업이 zone.js 외부에서도 자동으로 변경 감지를 트리거할 수 있다는 것을 강조합니다.\n\n\n\n한편, Enea의 기사는 zone.js를 완전히 비활성화하고 이러한 새로운 트리거 메커니즘에 완전히 의존하여 애플리케이션 상태 변경을 관리하는 데 초점을 맞추고 있습니다.\n\n# TypeScript 4.7 지원\n\nAngular 18은 TypeScript 4.7의 기능을 최대한 활용합니다. 이 강력한 JavaScript의 슈퍼셋은 빠른 컴파일 시간과 간소화된 빌드 절차, 향상된 Readonly 지원, 새로운 import 유형 및 템플릿 리터럴 유형과 같은 다양한 성능 향상을 소개합니다. 이러한 개선 사항으로 더 원활한 개발 경험과 잠재적으로 더 빠른 애플리케이션 실행이 가능해집니다.\n\n중요한 점은 Angular 18에서 TypeScript 5.4 이전 버전의 지원을 중단한다는 것입니다. 따라서 TypeScript 버전을 업데이트하면 이러한 진보를 활용할 수 있습니다.\n\n\n\n# Ivy를 통한 성능 개선\n\nAngular의 새로운 렌더링 엔진 인 Ivy는 Angular 18에서 성능을 향상시키고 번들 크기를 줄이며 트리 쉐이킹 능력을 향상시킴으로써 계속 발전하고 있습니다.\n\n# 개선된 디버깅 도구\n\nAngular 18에서는 디버깅 도구에 여러 가지 개선 사항이 도입될 예정입니다. 이러한 개선 사항은 Angular 애플리케이션의 디버깅 과정을 단순화하고 응용 프로그램 상태에 대한 더 깊은 통찰을 제공하기 위해 목표로 합니다.\n\n\n\n- 디버깅 시 소스 맵 활용\n- 컴포넌트 트리 및 데이터 바인딩 시각화\n\n# Angular 18: 반응성을 위한 새 시대\n\nAngular 18이 다가오고 있습니다. 개발자들을 위한 흥미로운 변화를 약속하며, 단순함, 개선된 컴포넌트 및 향상된 도구에 초점을 맞춰 이번 버전은 개발 경험을 더욱 높이고 있습니다. 릴리즈를 열망하며 우리의 개발 경험이 어떻게 진화되는지 기대하고 있습니다.\n\n# 읽어 주셔서 감사합니다!\n\n\n\n만약 이 내용이 유익했다면, 댓글을 남기거나 박수를 보내주시거나 제 팔로우를 눌러주세요. 공유는 사랑입니다, 따라서 여러분의 기술 열정이 넘치는 친구들과 커뮤니티에 전달해 보세요. 그리고 LinkedIn에서 저와 연락을 유지해주시는 걸 잊지 마세요 — 언제나 열정을 가진 열광적인 분들과 소통하는 것을 기대하고 있습니다! 👏\n\n기억해 주세요, 우리의 기술 커뮤니티는 협력과 지식 공유에 의해 번영합니다. 대화를 이어나가 봅시다! 😊🚀","ogImage":{"url":"/assets/img/2024-05-15-Angular18Topnewfeaturesandimprovements_0.png"},"coverImage":"/assets/img/2024-05-15-Angular18Topnewfeaturesandimprovements_0.png","tag":["Tech"],"readingTime":4},{"title":"빠른 BDD UI 테스트 프레임워크 with Playwright","description":"","date":"2024-05-15 10:41","slug":"2024-05-15-QuickBDDUITestFrameworkwithPlaywright","content":"\n\n<img src=\"/assets/img/2024-05-15-QuickBDDUITestFrameworkwithPlaywright_0.png\" />\n\n```javascript\n// Playwright에서 Type Script와 Cucumber로 UI 테스트 프레임워크를 시작하는 빠른 가이드입니다.\n\n// 주의 사항:-\n// 이것은 테스트 자동화를 시작하기 위해 의도적으로 매우 기본적인 프레임워크 설정입니다.\n// 요구 사항에 맞게 향상시킬 수 있습니다.\n```\n\n# 필요한 것\n\n- Node 및 NPM 설치가 되어 있어야 합니다.\n- Visual Studio Code\n- Cucumber 익스텐션\n\n\n\n# 프로젝트 설정하기\n\n명령줄로 이동하여 다음을 실행하세요 (프로젝트 설정 및 종속성 설치):\n\n```js\n> mkdir playwright-bdd-project\n> cd playwright-bdd-project\n> npm init // 모든 기본 값 선택, 이렇게 하면 새 노드 프로젝트가 초기화되고 package.json이 생성됩니다\n> npm i @cucumber/cucumber -D // cucumber // -D 플래그는 이 설치를 package.json의 개발용 종속성으로 추가합니다\n> npm i @playwright/test -D // Playwright\n> npm i @types/node -D // Node용 Type Script\n> npm i ts-node -D // Node 실행 환경에서 Type Script 파일을 실행하기 위함\n> code . // 이 새롭게 설정한 프로젝트를 Visual Studio Code로 엽니다\n```\n\n<img src=\"/assets/img/2024-05-15-QuickBDDUITestFrameworkwithPlaywright_1.png\" />\n\n\n\n# 프로젝트 구조\n\n다음과 같이 프로젝트에서 디렉터리 구조를 설정해주세요:\n\n```js\nroot \\ src \\ test \\ features // 여기에는 피쳐 파일이 위치합니다\nroot \\src \\ test \\steps // 여기에는 스텝 정의 파일이 위치합니다\nroot \\ reports // 여기에는 테스트 보고서가 생성됩니다\nroot \\ src \\ test \\ utils // 여기에는 유틸리티 코드를 유지합니다\n```\n\n![예시 이미지](/assets/img/2024-05-15-QuickBDDUITestFrameworkwithPlaywright_2.png)\n\n\n\n# 이 프레임워크의 핵심 — cucumber.json\n\n프로젝트 루트에 cucumber.json 파일을 생성하세요.\n\n루트 `cucumber.json\n\n```js\n{\n    \"default\": {\n        \"paths\": [\n            \"src/test/features/*.feature\" // 피처 파일의 위치\n        ],\n        \"dryRun\": false,\n        \"formatOptions\": {\n            \"snippetInterface\": \"async-await\" // async-await 형식으로 스텝 정의를 자동 생성하기 위함\n        },\n        \"require\": [\n            \"src/test/steps/*.ts\" // 피처 파일의 위치\n        ],\n        \"requireModule\": [\n            \"ts-node/register\" // 타입스크립트 파일에서 import를 사용할 수 있도록, node 실행 환경에서 이를 인식할 수 있게 함\n        ],\n        \"format\": [\n            [\"html\", \"reports/cucumber-report.html\"] // 테스트 실행 보고서가 여기에 생성됩니다\n        ]\n    }\n}\n```\n\n\n\n# Cucumber Extension 설정.json 파일에 Feature 파일 및 Step Definitions 경로 업데이트\n\n이를 통해 Cucumber 확장 프로그램이 Feature 및 해당하는 Step Definitions 파일을 매핑하는 데 도움이 됩니다.\n\n```json\n// 참고:-\n// 아래에 표시된 것과 다를 수 있는 경우가 있습니다.\n\n{\n    \"workbench.colorTheme\": \"Quiet Light\",\n    \"files.autoSave\": \"afterDelay\",\n    \"workbench.iconTheme\": \"vscode-icons\",\n    \"playwright.reuseBrowser\": false,\n    \"playwright.showTrace\": false,\n    \"cucumber.features\": [\n        \"src/test/features/*.feature\" // Feature 파일의 위치\n    ],\n    \"cucumber.glue\": [\n        \"src/test/steps/*.ts\" // Step Definition 파일의 위치\n    ],\n    \"aws.telemetry\": false,\n    \"amazonQ.telemetry\": false,\n    \"explorer.confirmDelete\": false,\n    \"javascript.updateImportsOnFileMove.enabled\": \"always\"\n}\n```\n\n# Feature 파일\n\n\n\n\"root \\ src \\ test \\ features \\ search.feature\" 경로에 다음 기능 파일을 추가해 주세요.\n\n```js\nFeature: Basic search using google engine\n\n  Scenario: Search for a term\n    Given I am on the google search page\n    When I search for \"cucumber\"\n    Then the search results page should contain \"cucumber\"\n```\n\n# 단계 정의\n\n\"root \\ src \\ test \\ steps \\ search.ts\" 경로에 다음 단계 정의 파일을 추가해 주세요.\n\n\n\n\n```js\nimport { Given, When, Then } from '@cucumber/cucumber';\nimport { expect } from '@playwright/test';\nimport { page } from './hooks';\n\nGiven('I am on the google search page', async function () {\n    console.log('I am on the google search page');\n});\n\nWhen('I search for {string}', async function (string) {\n    console.log('I search for ' + string);\n    await page.getByLabel('Search', { exact: true }).click();\n    await page.getByLabel('Search', { exact: true }).fill(string);\n    await page.getByLabel('Google Search').first().click();\n\n});\n\nThen('the search results page should contain {string}', async function (string) {\n    console.log('the search results page should contain ' + string);\n    await page.getByRole('link', { name: 'Cucumber: BDD Testing &' }).click();\n    expect(page.url()).toContain('cucumber.io');\n});\n``` \n\n## Hooks\n\nAdd the following hooks file under: root \\ src \\ test \\ steps \\ hooks.ts\n\n```js\nimport { Before, After, AfterStep, BeforeStep, World } from \"@cucumber/cucumber\";\nimport { chromium, Page, Browser } from '@playwright/test';\nimport { addCommentToReport, addScreenshotToReport } from \"../utils/reporting\";\n\nlet browser : Browser;\nlet page : Page;\n\nBefore(async function () { // SETUP (Runs Before Every Test Scenario) \n    console.log('Before hook');\n    browser = await chromium.launch({headless: false});\n    page = await browser.newPage();\n    await page.goto('https://www.google.com');\n});\n\nAfter(async function () { // TEARDOWN (Runs After Every Test Scenario)\n    console.log('After hook');\n    await browser.close();\n});\n\n// RUNS BEFORE EVERY STEP\n// We are taking screenshop before every step and adding it to the test report\nBeforeStep(async function({pickle, pickleStep, gherkinDocument, testCaseStartedId, testStepId}) {\n    await addScreenshotToReport.call(this);\n    await addCommentToReport.call(this, 'BeforeStep hook: ' + pickleStep.text);\n})\n\n// RUNS AFTER EVERY STEP\n// We are taking screenshop after every step and adding it to the test report\nAfterStep(async function({pickle, pickleStep, gherkinDocument, result, testCaseStartedId, testStepId}) {\n    await addScreenshotToReport.call(this);\n    await addCommentToReport.call(this, 'AfterStep hook: ' + pickleStep.text + ' - ' + result.status);\n})\n\nexport { browser, page };\n```   \n  \n\n\n\n# 유틸리티\n\n아래의 유틸리티 파일을 다음 경로에 추가하세요: root \\ src \\ test \\ utils\\ reporting.ts\n\n```js\nimport { World } from \"@cucumber/cucumber\";\nimport { page } from \"../steps/hooks\";\n\n// 테스트 리포트에 스크린샷을 추가하는 함수\nexport async function addScreenshotToReport(this: World) {\n    this.attach(await page.screenshot({ fullPage: true }), 'image/png');\n}\n\n// 테스트 리포트에 코멘트를 추가하는 함수\nexport async function addCommentToReport(this: World, comment: string) {\n    this.attach(comment, 'text/plain');\n}\n```\n\n# 최종 설정은 이렇게 될 것입니다:\n\n\n\n\n![이미지](/assets/img/2024-05-15-QuickBDDUITestFrameworkwithPlaywright_3.png)\n\n# 테스트 실행\n\npackage.json에서 test 필드 값을 \"cucumber-js test\"로 설정하세요.\n\n```js\n \"scripts\": {\n    \"test\": \"cucumber-js test\"\n  },\n```\n\n\n\n터미널을 열고 (CTRL + J) `npm test`를 실행해주세요.\n\n이 명령을 통해 테스트가 실행됩니다.\n\n![이미지](/assets/img/2024-05-15-QuickBDDUITestFrameworkwithPlaywright_4.png)\n\n# 실행 보고서 유효성 검사\n\n\n\n루트 / 보고서 / 로 이동하셔서\n\n여기에서 최신 테스트 실행 보고서를 찾으실 수 있습니다.\n\n![보고서 이미지](/assets/img/2024-05-15-QuickBDDUITestFrameworkwithPlaywright_5.png)","ogImage":{"url":"/assets/img/2024-05-15-QuickBDDUITestFrameworkwithPlaywright_0.png"},"coverImage":"/assets/img/2024-05-15-QuickBDDUITestFrameworkwithPlaywright_0.png","tag":["Tech"],"readingTime":7},{"title":"루비 온 레일즈 앱을 커피스트라노Capistrano를 사용하여 로컬로동일 PC에서 다른 사용자에게 배포하기","description":"","date":"2024-05-15 10:39","slug":"2024-05-15-DeploymentofRubyonRailsappusingCapistranoLocallyFromoneusertoanotheronthesamePC","content":"\n\n<img src=\"/assets/img/2024-05-15-DeploymentofRubyonRailsappusingCapistranoLocallyFromoneusertoanotheronthesamePC_0.png\" />\n\n# 소개\n\n소프트웨어 개발에서 애플리케이션을 배포하는 것은 사용자가 이용할 수 있도록 하는 중요한 단계입니다. Capistrano는 배포 프로세스를 자동화하여 효율적이고 신뢰성있게 만드는 인기 있는 도구입니다.\n\n이 안내서에서는 Capistrano를 사용하여 로컬에서 Ruby on Rails 애플리케이션을 배포하는 단계를 안내합니다. 레일즈 앱 배포 방법을 배우면서 수행한 내용이며, 이런 단계를 따랐습니다.\n\n\n\n# 전제 조건\n\n시작하기 전에 다음 전제 조건을 확인하세요:\n\n- Ubuntu 터미널과 Capistrano 파일 구조에 대한 기본 지식.\n- Ruby on Rails가 PC에 올바르게 설정되어 있어야 합니다.\n- 두 사용자가 Rails 앱 디렉토리에 액세스하고 명령을 실행할 필요한 권한을 갖고 있어야 합니다.\n- SSH 키가 올바르게 설정되어 있어야 합니다.\n- Ubuntu에서 사용자 및 SSH 키 설정에 익숙해야 합니다.\n\n# 사용자 생성 및 SSH 설정\n\n\n\n- 새 사용자를 만드세요:\n\n```js\nsudo adduser newuser\n```\n\n- 사용자를 만든 후, 해당 사용자로 전환하세요\n\n```js\nsudo su - newuser\n```\n\n\n\n새 사용자에게 .ssh 디렉토리를 만들어야 합니다. Rails 앱을 배포하기 위해 ssh 키가 필요합니다.\n\n```js\n mkdir -p ~/.ssh\n```\n\n- 기존 사용자의 SSH 인증 키를 새 사용자의 .ssh 디렉토리로 복사해야 합니다. 여기서 ssh는 두 사용자 간 통신에 사용됩니다.\n\n```js\nsudo cp /home/existing-user/.ssh/authorized_keys /home/newuser/.ssh\n```\n\n\n\n- 또한, 새 사용자에게 소유권을 부여해 주세요\n\n```js\nsudo chown -R newuser:newuser /home/newuser/.ssh\n```\n\n- 새로운 사용자에게 sudo 권한을 부여하세요(관리자 권한을 가진 사용자로 로그인해야 함)\n\n```js\nsudo usermod -aG sudo newuser\n```\n\n\n\n- 이제 새 사용자로 전환할 수 있어요\n\n```js\nsu - newuser\n```\n\n- 이제 새 사용자의 SSH 구성 여부를 확인할 수 있어요\n\n```js\nssh localhost\n```\n\n\n\n- 만약 ssh가 연결되어 있다면 이제 다음과 같이 표시됩니다 :\n\n![Deployment of Ruby on Rails app using Capistrano Locally From one user to another on the same PC](/assets/img/2024-05-15-DeploymentofRubyonRailsappusingCapistranoLocallyFromoneusertoanotheronthesamePC_1.png)\n\n- 이제 배포 프로세스를 시작해봅시다. 레일즈 앱을 배포하려는 사용자를 엽니다 :\n\n# Gemfile 설정\n\n\n\n- 먼저 레일즈에서 Capistrano 젬을 설정하는 것이 첫 번째 단계입니다.\n\n다음을 개발 그룹 아래 Gemfile에 추가하십시오.\n\n```js\ngem \"capistrano\", \"~> 3.10\", require: false\ngem \"capistrano-rails\", \"~> 1.6\", require: false \ngem 'capistrano-rbenv', require: false   \ngem 'capistrano-puma', require: false\n```\n\n- 이제 다음 명령을 명령 줄에서 실행하여 추가 번들을 설치하십시오\n\n\n\n```js\n번들 설치\n```\n\n- 생성기를 실행하여 기본 구성 파일 세트를 만듭니다.\n\n```js\n번들 실행 cap 설치\n```\n\n# Capfile 구성\n\n\n\n- 루트 디렉토리에 있는 Capfile에서 다음 플러그인들을 주석처리 해제하세요.\n\n```js\nrequire \"capistrano/rbenv\" \nrequire \"capistrano/bundler\"\nrequire \"capistrano/rails/assets\"\nrequire \"capistrano/rails/migrations\" \nrequire \"capistrano/rails\" \nrequire \"capistrano/bundler\"\nrequire \"capistrano/puma\"\n```\n\n- 참고: 위의 플러그인은 앱의 요구 사항에 따라 다를 수 있습니다. 예를 들어, 여기서 패신저를 사용하는 경우 require \"capistrano/passenger\"를 추가해야합니다. 저는 사용하지 않기 때문에 추가하지 않아도 됩니다.\n\n# 설정 파일\n\n\n\n- `config/deploy.rb` 파일을 적절한 값으로 업데이트해주세요. 여기서는 cap loc 버전 3.18.0을 사용하며 `staging.rb`를 사용하여 배포하고 있습니다.\n- 프로젝트 요구 사항에 따라 구성을 사용자 정의해주시기 바랍니다.\n\n```js\nlock \"~> 3.18.0\"\nset :stage, :staging \nset :rails_env, 'test' \nset :application, '{앱 이름}' \nset :repo_url, 'git@github.com:당신의/github/url.git' \nset :deploy_to, '/home/{로컬 사용자명}/{배포할 애플리케이션 이름}' \nset :branch, '{배포하려는 브랜치}' \nset :rbenv_ruby, '2.7.7' \nset :default_env, { 'PATH' => \"#{fetch(:rbenv_path)}/shims:#{fetch(:rbenv_path)}/bin:$PATH\", 'RBENV_VERSION' => fetch(:rbenv_ruby) }\n```\n\n# 배포\n\n- `staging.rb` 파일에 로컬 호스트 IP를 추가하세요.\n\n\n\n```js\n서버 'localhost', 사용자: '{귀하의 로컬 사용자 이름}', 역할: %w{app db web}\n```\n\n- 이제 다음 명령을 사용하여 API를 로컬로 배포할 수 있습니다.\n\n```js\ncap staging deploy\n```\n\n- 이제 루비 온 레일 API가 로컬로 배포되었고 앱 폴더로 이동하여 버전을 확인할 수 있습니다. 현재 디렉토리로 이동한 후에 아래 명령을 실행할 수 있습니다.\n\n\n\n```js\nbin/rails s\n```\n\n- 특정 젬 설치 오류가 발생하면 ruby와 rails 간 버전 간의 충돌이 없는지 확인해보세요.\n\n이제 파일 구조가 다음과 같이 보일 것입니다 :\n\n![image](/assets/img/2024-05-15-DeploymentofRubyonRailsappusingCapistranoLocallyFromoneusertoanotheronthesamePC_2.png)\n\n\n\n\n# 결론\n\n축하합니다! Capistrano를 사용하여 로컬에 Ruby on Rails 애플리케이션을 성공적으로 배포했습니다. 이제 Rails 서버를 실행하고 애플리케이션에 액세스할 수 있습니다.\n\n# 팁\n\n- 배포 명령을 실행하기 전에 배포 구성을 항상 확인해보세요.\n- 배포 중 발생하는 오류를 해결하려면 로그와 구성을 확인하세요.\n- 프로젝트의 요구에 맞게 Capistrano 구성을 사용자 정의하세요.","ogImage":{"url":"/assets/img/2024-05-15-DeploymentofRubyonRailsappusingCapistranoLocallyFromoneusertoanotheronthesamePC_0.png"},"coverImage":"/assets/img/2024-05-15-DeploymentofRubyonRailsappusingCapistranoLocallyFromoneusertoanotheronthesamePC_0.png","tag":["Tech"],"readingTime":4},{"title":"Vite와 함께 하는 동적 모듈 연맹","description":"","date":"2024-05-15 10:38","slug":"2024-05-15-DynamicModuleFederationwithVite","content":"\n\n<img src=\"/assets/img/2024-05-15-DynamicModuleFederationwithVite_0.png\" />\n\n요즘은 Vite를 통해 React 마이크로 프론트엔드를 빌드하는 작업을 맡게 되었어요. 이 솔루션은 런타임에서 원격 모듈 URL을 동적으로 결정해야 했어요. 컴파일 시간이 아니라요.\n\n동적 모듈 연합은 새로운 도전이 아니에요. 웹팩으로 여러 번 구현되어 왔기 때문에 Vite로도 이를 하는 것이 더 쉬울 것이라고 생각했어요. 그러나 이 기능이 지원되지 않거나 문서화되지 않았다는 것에 놀랐어요.\n\n몇 일 동안 검색한 끝에 좋은 긴 GitHub 토론을 발견했는데 막다른 곳처럼 보였어요. 그렇지만 흥미로워서 계속 읽다가 어쩌면 해결책이 있어요.\n\n\n\n다이내믹 모듈 연합이 도움이 되는 여러 시나리오가 있습니다. 예를 들어, A/B 테스팅입니다. 집단에 영향을 주지 않고 일부 사용자를 위한 새 레이아웃을 테스트하고 싶은 경우를 상상해보세요. 이 작업을 수행하는 React 앱을 만들어 봅시다. 앞서 진행하고 싶은 사람들을 위해 작동하는 예제가 여기 있어요. https://github.com/lestersconyers/react-apps/tree/main/dynamic-module-federation\n\n## 설정\n\n이 예제에서는 호스트 앱과 A와 B의 2개의 원격 앱을 갖게 됩니다. 사용자가 사이트를 방문할 때, 어떤 원격 앱 콘텐츠를 표시할지 결정하기 위해 일부 최상급 로직을 사용할 것입니다.\n\n- 보통처럼 원격 앱 모듈 연합을 설정합니다. Vite와 함께의 표준 모듈 연합은 상당히 잘 문서화되어 있으므로 인터넷을 중복하지는 않겠습니다. 다만 여기에 설정 파일이 있어요.\n\n\n\n2. 호스트 앱의 App.tsx 파일에서 __federation__ 모듈에서 함수를 가져와주세요. 여기에서 마법이 일어납니다!\n\n3. setRemote를 사용하여 url을 반환하는 프로미스를 만들고, getRemote를 사용하여 해당 프로미스를 반환하세요. 이 프로미스는 런타임 시에 해결됩니다.\n\n4. 동적 원격 앱을 사용하세요.\n\n5. 마지막으로 호스트 앱의 vite.config.ts 파일에 더미 원격 항목을 추가하여 런타임 오류를 피하세요.\n\n\n\n모두 완료했습니다!","ogImage":{"url":"/assets/img/2024-05-15-DynamicModuleFederationwithVite_0.png"},"coverImage":"/assets/img/2024-05-15-DynamicModuleFederationwithVite_0.png","tag":["Tech"],"readingTime":2},{"title":"파이토치를 처음부터 다시 만들어보기 GPU 지원 및 자동 미분 기능 포함","description":"","date":"2024-05-15 10:33","slug":"2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation","content":"\n\n## C/C++, CUDA, 및 Python을 기반으로 한 고유의 딥 러닝 프레임워크를 구축해 보세요. GPU 지원과 자동 미분을 제공합니다\n\n![image](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_0.png)\n\n# 소개\n\n여러 해 동안 PyTorch를 사용하여 딥 러닝 모델을 구축하고 훈련해 왔습니다. 그럼에도 불구하고, 그 문법과 규칙을 익히고도, 제 궁금증을 자극하던 것이 있었습니다: 이러한 작업 중에 내부에서 어떤 일이 일어나고 있는 걸까요? 이 모든 것이 어떻게 작동할까요?\n\n\n\n여기까지 오셨다면, 아마도 비슷한 질문을 가지고 계실 것입니다. 파이토치(PyTorch)에서 모델을 생성하고 훈련하는 방법을 물어본다면 아마도 아래 코드와 비슷한 것을 생각해볼 것입니다:\n\n```js\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.fc1 = nn.Linear(1, 10)\n        self.sigmoid = nn.Sigmoid()\n        self.fc2 = nn.Linear(10, 1)\n\n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.sigmoid(out)\n        out = self.fc2(out)\n        \n        return out\n\n...\n\nmodel = MyModel().to(device)\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\nfor epoch in range(epochs):\n    for x, y in ...\n        \n        x = x.to(device)\n        y = y.to(device)\n\n        outputs = model(x)\n        loss = criterion(outputs, y)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n```\n\n하지만 이번에 역전파(backward) 단계가 어떻게 작동하는지 물어본다면 어떨까요? 또는 예를 들어, 텐서를 재구성할 때 무슨 일이 일어나는지 궁금하시다면요? 내부에서 데이터가 재배치되나요? 그런 일이 어떻게 일어나나요? 왜 PyTorch는 빠른가요? PyTorch가 GPU 연산을 어떻게 처리하는지요? 이런 질문들이 항상 저를 호기심 가득하게 만들었고, 여러분도 마찬가지로 호기심이 드실 것이라고 상상합니다. 그래서 이러한 개념을 더 잘 이해하기 위해 스스로 텐서 라이브러리를 처음부터 구축해보는 것이 무엇보다 좋을까요? 이 글에서 여러분이 배우게 될 것이 바로 그겁니다!\n\n## #1 — 텐서\n\n\n\n텐서 라이브러리를 구축하기 위해 가장 먼저 알아야 할 개념은 무엇이 텐서인지에 대한 명백한 개념입니다.\n\n텐서는 몇 가지 숫자를 포함하는 n차원 데이터 구조의 수학적 개념이라는 직관적인 생각을 가지고 있을 수 있습니다. 그러나 여기서는 이 데이터 구조를 계산적 관점에서 어떻게 모델링할지 이해해야 합니다. 텐서는 데이터 자체뿐만 아니라 모양이나 텐서가 있는 장치(예: CPU 메모리, GPU 메모리)와 같은 측면을 설명하는 메타데이터로 구성된다고 생각할 수 있습니다.\n\n텐서의 내부를 이해하는 데 매우 중요한 개념인 stride라는 잘 알려지지 않은 메타데이터도 있습니다. 따라서 텐서 데이터 재배열의 내부를 이해하기 위해 약간 더 이에 대해 논의해야 합니다.\n\n\n\n2-D 텐서의 모양이 [4, 8]인 경우를 상상해보세요.\n\n![텐서](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_2.png)\n\n텐서의 데이터(즉, 부동 소수점 수)는 실제로 메모리에 1차원 배열로 저장됩니다.\n\n![데이터](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_3.png)\n\n\n\n그러면 이 1차원 배열을 N차원 텐서로 나타내려면 스트라이드를 사용합니다. 기본 아이디어는 다음과 같습니다:\n\n4행 8열의 행렬이 있습니다. 그 행렬의 모든 원소가 1차원 배열의 행에 의해 구성되어 있다고 가정할 때, 위치 [2, 3]의 값을 액세스하려면 2행(각 행에 8개의 요소)을 횡단해야 하며 추가로 3개의 위치를 지나야 합니다. 수학적으로 표현하면 1차원 배열에서 3 + 2 * 8 요소를 횡단해야 합니다.\n\n따라서, '8'은 두 번째 차원의 스트라이드입니다. 이 경우, 배열에서 다른 위치로 \"점프\"하기 위해 몇 개의 요소를 횡단해야 하는지를 나타내는 정보입니다.\n\n\n\n따라서, 모양이 [shape_0, shape_1]인 2차원 텐서의 요소 [i, j]에 액세스하려면, 기본적으로 j + i * shape_1 위치에 있는 요소에 액세스해야 합니다.\n\n이제 3차원 텐서를 상상해보겠습니다:\n\n![image](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_5.png)\n\n이 3차원 텐서를 행렬의 시퀀스로 생각할 수 있습니다. 예를 들어, 이 [5, 4, 8] 텐서를 [4, 8] 모양의 5개 행렬로 생각할 수 있습니다.\n\n\n\n이제 [1, 3, 7] 위치에 있는 요소에 액세스하기 위해 [4,8] 형태의 행렬을 1개 완전히 횡단하고, [8] 형태의 행을 2개, [1] 형태의 열을 7개 횡단해야 합니다. 따라서 1차원 배열에서 (1 * 4 * 8) + (2 * 8) + (7 * 1) 위치를 횡단해야 합니다.\n\n![image](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_6.png)\n\n따라서, [shape_0, shape_1, shape_2] 모양의 3차원 텐서에서 1차원 데이터 배열에서 [i][j][k] 요소에 액세스하는 방법은 다음과 같습니다:\n\n![image](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_7.png)\n\n\n\n이 shape_1 * shape_2가 첫 번째 차원의 stride이고, shape_2는 두 번째 차원의 stride이며 1은 세 번째 차원의 stride입니다.\n\n그런 다음, 일반화하기 위해서는:\n\n![image](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_8.png)\n\n각 차원의 stride는 다음 차원 텐서 모양의 곱을 사용하여 계산할 수 있습니다:\n\n\n\n<img src=\"/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_9.png\" />\n\n그런 다음 stride[n-1] = 1로 설정합니다.\n\n우리의 형태의 텐서 예제 [5, 4, 8]에서 strides = [4*8, 8, 1] = [32, 8, 1]일 것입니다.\n\n여러분들도 직접 테스트할 수 있어요:\n\n\n\n```js\nimport torch\n\ntorch.rand([5, 4, 8]).stride()\n#(32, 8, 1)\n```\n\n알겠어요, 그런데 왜 모양과 스트라이드가 필요한 건가요? N차원 텐서의 요소에 접근하는 것을 넘어, 이 개념은 텐서 배열을 매우 쉽게 조작하는 데 사용될 수 있어요.\n\n예를 들어, 텐서를 재구성하려면 새로운 모양을 설정하고 새로운 스트라이드를 계산하면 됩니다! (새로운 모양은 동일한 요소 수를 보장하므로)\n\n```js\nimport torch\n\nt = torch.rand([5, 4, 8])\n\nprint(t.shape)\n# [5, 4, 8]\n\nprint(t.stride())\n# [32, 8, 1]\n\nnew_t = t.reshape([4, 5, 2, 2, 2])\n\nprint(new_t.shape)\n# [4, 5, 2, 2, 2]\n\nprint(new_t.stride())\n# [40, 8, 4, 2, 1]\n``` \n\n\n\n\n텐서 내부에서는 여전히 동일한 1차원 배열로 저장됩니다. reshape 메서드는 배열 내 요소의 순서를 변경하지 않았습니다! 대단하지 않나요? 😁\n\n다음 함수를 사용하여 PyTorch에서 내부 1차원 배열에 액세스하는 함수를 사용하여 직접 확인할 수 있습니다:\n\n```js\nimport ctypes\n\ndef print_internal(t: torch.Tensor):\n    print(\n        torch.frombuffer(\n            ctypes.string_at(t.data_ptr(), t.storage().nbytes()), dtype=t.dtype\n        )\n    )\n\nprint_internal(t)\n# [0.0752, 0.5898, 0.3930, 0.9577, 0.2276, 0.9786, 0.1009, 0.138, ...\n\nprint_internal(new_t)\n# [0.0752, 0.5898, 0.3930, 0.9577, 0.2276, 0.9786, 0.1009, 0.138, ...\n```\n\n예를 들어 두 축을 전치하려면 내부적으로 해당 스트라이드를 단순히 바꾸어 주면 됩니다!\n\n\n\n```js\nt = torch.arange(0, 24).reshape(2, 3, 4)\nprint(t)\n# [[[ 0,  1,  2,  3],\n#   [ 4,  5,  6,  7],\n#   [ 8,  9, 10, 11]],\n \n#  [[12, 13, 14, 15],\n#   [16, 17, 18, 19],\n#   [20, 21, 22, 23]]]\n\nprint(t.shape)\n# [2, 3, 4]\n\nprint(t.stride())\n# [12, 4, 1]\n\nnew_t = t.transpose(0, 1)\nprint(new_t)\n# [[[ 0,  1,  2,  3],\n#   [12, 13, 14, 15]],\n\n#  [[ 4,  5,  6,  7],\n#   [16, 17, 18, 19]],\n\n#  [[ 8,  9, 10, 11],\n#   [20, 21, 22, 23]]]\n\nprint(new_t.shape)\n# [3, 2, 4]\n\nprint(new_t.stride())\n# [4, 12, 1]\n```\n\n내부 배열을 출력하면 두 값 모두 동일합니다:\n\n```js\nprint_internal(t)\n# [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n\nprint_internal(new_t)\n# [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n```\n\n그러나 new_t의 스트라이드는 이제 위의 식과 일치하지 않습니다. 이것은 텐서가 이제 연속적이지 않기 때문에 발생합니다. 즉, 내부 배열은 동일하지만 메모리 내의 값의 순서가 텐서의 실제 순서와 일치하지 않는다는 것을 의미합니다.\n\n\n\n```js\nt.is_contiguous()\n# True\n\nnew_t.is_contiguous()\n# False\n```\n\n이는 연속되지 않는 요소에 연속적으로 액세스하는 것이 효율적이지 않다는 것을 의미합니다 (실제 텐서 요소는 메모리 상에서 순서대로 정렬되어 있지 않기 때문입니다). 이를 해결하기 위해 다음을 수행할 수 있습니다:\n\n```js\nnew_t_contiguous = new_t.contiguous()\n\nprint(new_t_contiguous.is_contiguous())\n# True\n```\n\n내부 배열을 분석하면 이제 순서가 실제 텐서 순서와 일치하여 더 나은 메모리 액세스 효율을 제공할 수 있습니다:\n\n\n\n```js\nprint(new_t)\n# [[[ 0,  1,  2,  3],\n#   [12, 13, 14, 15]],\n\n#  [[ 4,  5,  6,  7],\n#   [16, 17, 18, 19]],\n\n#  [[ 8,  9, 10, 11],\n#   [20, 21, 22, 23]]]\n\nprint_internal(new_t)\n# [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n\nprint_internal(new_t_contiguous)\n# [ 0,  1,  2,  3, 12, 13, 14, 15,  4,  5,  6,  7, 16, 17, 18, 19,  8,  9, 10, 11, 20, 21, 22, 23]\n```\n\n이제 우리는 텐서가 어떻게 모델링되는지 이해했으니, 라이브러리 생성을 시작해 봅시다!\n\n내가 만들 라이브러리 이름은 Norch입니다. PyTorch가 아닌 (NOT PyTorch)을 의미하며, 성(Nogueira)을 암시하기도 합니다. 😁\n\n첫 번째로 알아야 할 것은 PyTorch가 Python을 통해 사용되지만 내부적으로는 C/C++로 실행된다는 것입니다. 그래서 먼저 내부 C/C++ 함수를 만들 것입니다.\n\n\n\n\n먼저 텐서를 데이터와 메타데이터를 저장하는 구조체로 정의하고 이를 만들기 위한 함수를 생성할 수 있습니다:\n\n```js\n//norch/csrc/tensor.cpp\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n\ntypedef struct {\n    float* data;\n    int* strides;\n    int* shape;\n    int ndim;\n    int size;\n    char* device;\n} Tensor;\n\nTensor* create_tensor(float* data, int* shape, int ndim) {\n    \n    Tensor* tensor = (Tensor*)malloc(sizeof(Tensor));\n    if (tensor == NULL) {\n        fprintf(stderr, \"메모리 할당 실패\\n\");\n        exit(1);\n    }\n    tensor->data = data;\n    tensor->shape = shape;\n    tensor->ndim = ndim;\n\n    tensor->size = 1;\n    for (int i = 0; i < ndim; i++) {\n        tensor->size *= shape[i];\n    }\n\n    tensor->strides = (int*)malloc(ndim * sizeof(int));\n    if (tensor->strides == NULL) {\n        fprintf(stderr, \"메모리 할당 실패\\n\");\n        exit(1);\n    }\n    int stride = 1;\n    for (int i = ndim - 1; i >= 0; i--) {\n        tensor->strides[i] = stride;\n        stride *= shape[i];\n    }\n    \n    return tensor;\n}\n```\n\n일부 요소에 접근하기 위해서는 앞서 배웠던 스트라이드(strides)를 활용할 수 있습니다:\n\n```js\n//norch/csrc/tensor.cpp\n\nfloat get_item(Tensor* tensor, int* indices) {\n    int index = 0;\n    for (int i = 0; i < tensor->ndim; i++) {\n        index += indices[i] * tensor->strides[i];\n    }\n\n    float result;\n    result = tensor->data[index];\n\n    return result;\n}\n```\n\n\n\n이제 텐서 작업을 만들 수 있습니다. 몇 가지 예제를 보여드리겠고, 이 글 끝에 링크된 저장소에서 완전한 버전을 찾을 수 있습니다.\n\n```js\n//norch/csrc/cpu.cpp\n\nvoid add_tensor_cpu(Tensor* tensor1, Tensor* tensor2, float* result_data) {\n    \n    for (int i = 0; i < tensor1->size; i++) {\n        result_data[i] = tensor1->data[i] + tensor2->data[i];\n    }\n}\n\nvoid sub_tensor_cpu(Tensor* tensor1, Tensor* tensor2, float* result_data) {\n    \n    for (int i = 0; i < tensor1->size; i++) {\n        result_data[i] = tensor1->data[i] - tensor2->data[i];\n    }\n}\n\nvoid elementwise_mul_tensor_cpu(Tensor* tensor1, Tensor* tensor2, float* result_data) {\n    \n    for (int i = 0; i < tensor1->size; i++) {\n        result_data[i] = tensor1->data[i] * tensor2->data[i];\n    }\n}\n\nvoid assign_tensor_cpu(Tensor* tensor, float* result_data) {\n\n    for (int i = 0; i < tensor->size; i++) {\n        result_data[i] = tensor->data[i];\n    }\n}\n\n...\n```\n\n그 다음에, 이러한 작업들을 호출할 텐서 다른 함수를 만들 수 있습니다.\n\n```js\n//norch/csrc/tensor.cpp\n\nTensor* add_tensor(Tensor* tensor1, Tensor* tensor2) {\n    if (tensor1->ndim != tensor2->ndim) {\n        fprintf(stderr, \"덧셈을 위해서 텐서는 동일한 차원 수여야 합니다 %d 와 %d\\n\", tensor1->ndim, tensor2->ndim);\n        exit(1);\n    }\n\n    int ndim = tensor1->ndim;\n    int* shape = (int*)malloc(ndim * sizeof(int));\n    if (shape == NULL) {\n        fprintf(stderr, \"메모리 할당 실패\\n\");\n        exit(1);\n    }\n\n    for (int i = 0; i < ndim; i++) {\n        if (tensor1->shape[i] != tensor2->shape[i]) {\n            fprintf(stderr, \"덧셈을 위해서 텐서는 동일한 모양이어야 합니다 %d 와 %d 인덱스 %d에서\\n\", tensor1->shape[i], tensor2->shape[i], i);\n            exit(1);\n        }\n        shape[i] = tensor1->shape[i];\n    }        \n    float* result_data = (float*)malloc(tensor1->size * sizeof(float));\n    if (result_data == NULL) {\n        fprintf(stderr, \"메모리 할당 실패\\n\");\n        exit(1);\n    }\n    add_tensor_cpu(tensor1, tensor2, result_data);\n    \n    return create_tensor(result_data, shape, ndim, device);\n}\n```\n\n\n\n이전에 언급한 대로, 텐서 재구성은 내부 데이터 배열을 수정하지 않습니다.\n\n```js\n//norch/csrc/tensor.cpp\n\nTensor* reshape_tensor(Tensor* tensor, int* new_shape, int new_ndim) {\n\n    int ndim = new_ndim;\n    int* shape = (int*)malloc(ndim * sizeof(int));\n    if (shape == NULL) {\n        fprintf(stderr, \"메모리 할당 실패\\n\");\n        exit(1);\n    }\n\n    for (int i = 0; i < ndim; i++) {\n        shape[i] = new_shape[i];\n    }\n\n    // 새 모양의 요소 총 수 계산\n    int size = 1;\n    for (int i = 0; i < new_ndim; i++) {\n        size *= shape[i];\n    }\n\n    // 총 요소 수가 현재 텐서의 크기와 일치하는지 확인\n    if (size != tensor->size) {\n        fprintf(stderr, \"텐서를 재구성할 수 없습니다. 새 모양의 요소 총 수가 현재 텐서의 크기와 일치하지 않습니다.\\n\");\n        exit(1);\n    }\n\n    float* result_data = (float*)malloc(tensor->size * sizeof(float));\n    if (result_data == NULL) {\n        fprintf(stderr, \"메모리 할당 실패\\n\");\n        exit(1);\n    }\n    assign_tensor_cpu(tensor, result_data);\n    return create_tensor(result_data, shape, ndim, device);\n}\n```\n\n이제 일부 텐서 작업을 수행할 수 있지만, 누구나 C/C++을 사용하여 실행해야 하는 것은 아닙니다. 이제 Python 래퍼를 만들어 봅시다!\n\nPython을 사용하여 C/C++ 코드를 실행할 수 있는 다양한 옵션이 있습니다. Pybind11과 Cython 등이 있습니다. 이 예시에서는 ctypes를 사용할 것입니다.\n\n\n\n아래는 ctypes의 기본적인 구조입니다:\n\n```js\n//C 코드\n#include <stdio.h>\n\nfloat add_floats(float a, float b) {\n    return a + b;\n}\n```\n\n```js\n# 컴파일\ngcc -shared -o add_floats.so -fPIC add_floats.c\n```\n\n```js\n# Python 코드\nimport ctypes\n\n# 공유 라이브러리 로드\nlib = ctypes.CDLL('./add_floats.so')\n\n# 함수의 인자와 반환 유형 정의\nlib.add_floats.argtypes = [ctypes.c_float, ctypes.c_float]\nlib.add_floats.restype = ctypes.c_float\n\n# 파이썬 float 값을 c_float 유형으로 변환\na = ctypes.c_float(3.5)\nb = ctypes.c_float(2.2)\n\n# C 함수 호출\nresult = lib.add_floats(a, b)\nprint(result)\n# 5.7\n```\n\n\n\n보시다시피 매우 직관적입니다. C/C++ 코드를 컴파일한 후 Python에서 ctypes를 사용하면 매우 쉽게 사용할 수 있습니다. 함수의 매개변수 및 반환 c_types를 정의하고, 변수를 해당 c_types로 변환하고 함수를 호출하기만 하면 됩니다. 배열(부동 소수점 목록)과 같은 보다 복잡한 유형의 경우 포인터를 사용할 수 있습니다.\n\n```js\ndata = [1.0, 2.0, 3.0]\ndata_ctype = (ctypes.c_float * len(data))(*data)\n\nlib.some_array_func.argstypes = [ctypes.POINTER(ctypes.c_float)]\n\n...\n\nlib.some_array_func(data)\n```\n\n그리고 구조체 유형의 경우 직접 c_type을 만들 수 있습니다.\n\n```js\nclass CustomType(ctypes.Structure):\n    _fields_ = [\n        ('field1', ctypes.POINTER(ctypes.c_float)),\n        ('field2', ctypes.POINTER(ctypes.c_int)),\n        ('field3', ctypes.c_int),\n    ]\n\n# ctypes.POINTER(CustomType)로 사용할 수 있습니다.\n```\n\n\n\n간단히 설명하고, 텐서 C/C++ 라이브러리를 위한 Python 래퍼를 만들어 보겠습니다!\n\n```js\n# norch/tensor.py\n\nimport ctypes\n\nclass CTensor(ctypes.Structure):\n    _fields_ = [\n        ('data', ctypes.POINTER(ctypes.c_float)),\n        ('strides', ctypes.POINTER(ctypes.c_int)),\n        ('shape', ctypes.POINTER(ctypes.c_int)),\n        ('ndim', ctypes.c_int),\n        ('size', ctypes.c_int),\n    ]\n\nclass Tensor:\n    os.path.abspath(os.curdir)\n    _C = ctypes.CDLL(\"COMPILED_LIB.so\")\n\n    def __init__(self):\n        \n        data, shape = self.flatten(data)\n        self.data_ctype = (ctypes.c_float * len(data))(*data)\n        self.shape_ctype = (ctypes.c_int * len(shape))(*shape)\n        self.ndim_ctype = ctypes.c_int(len(shape))\n       \n        self.shape = shape\n        self.ndim = len(shape)\n\n        Tensor._C.create_tensor.argtypes = [ctypes.POINTER(ctypes.c_float), ctypes.POINTER(ctypes.c_int), ctypes.c_int]\n        Tensor._C.create_tensor.restype = ctypes.POINTER(CTensor)\n\n        self.tensor = Tensor._C.create_tensor(\n            self.data_ctype,\n            self.shape_ctype,\n            self.ndim_ctype,\n        )\n        \n    def flatten(self, nested_list):\n        \"\"\"\n        This method simply convert a list type tensor to a flatten tensor with its shape\n        \n        Example:\n        \n        Arguments:  \n            nested_list: [[1, 2, 3], [-5, 2, 0]]\n        Return:\n            flat_data: [1, 2, 3, -5, 2, 0]\n            shape: [2, 3]\n        \"\"\"\n        def flatten_recursively(nested_list):\n            flat_data = []\n            shape = []\n            if isinstance(nested_list, list):\n                for sublist in nested_list:\n                    inner_data, inner_shape = flatten_recursively(sublist)\n                    flat_data.extend(inner_data)\n                shape.append(len(nested_list))\n                shape.extend(inner_shape)\n            else:\n                flat_data.append(nested_list)\n            return flat_data, shape\n        \n        flat_data, shape = flatten_recursively(nested_list)\n        return flat_data, shape\n```\n\n이제 Python 텐서 작업을 포함하여 C/C++ 작업을 호출할 수 있습니다.\n\n```js\n# norch/tensor.py\n\ndef __getitem__(self, indices):\n    \"\"\"\n    index 텐서를 사용하여 텐서에 액세스 tensor[i, j, k...]\n    \"\"\"\n\n    if len(indices) != self.ndim:\n        raise ValueError(\"인덱스 수가 차원 수와 일치해야 함\")\n    \n    Tensor._C.get_item.argtypes = [ctypes.POINTER(CTensor), ctypes.POINTER(ctypes.c_int)]\n    Tensor._C.get_item.restype = ctypes.c_float\n                                       \n    indices = (ctypes.c_int * len(indices))(*indices)\n    value = Tensor._C.get_item(self.tensor, indices)  \n    \n    return value\n\ndef reshape(self, new_shape):\n    \"\"\"\n    텐서를 재구성합니다\n    result = tensor.reshape([1,2])\n    \"\"\"\n    new_shape_ctype = (ctypes.c_int * len(new_shape))(*new_shape)\n    new_ndim_ctype = ctypes.c_int(len(new_shape))\n    \n    Tensor._C.reshape_tensor.argtypes = [ctypes.POINTER(CTensor), ctypes.POINTER(ctypes.c_int), ctypes.c_int]\n    Tensor._C.reshape_tensor.restype = ctypes.POINTER(CTensor)\n    result_tensor_ptr = Tensor._C.reshape_tensor(self.tensor, new_shape_ctype, new_ndim_ctype)   \n\n    result_data = Tensor()\n    result_data.tensor = result_tensor_ptr\n    result_data.shape = new_shape.copy()\n    result_data.ndim = len(new_shape)\n    result_data.device = self.device\n\n    return result_data\n\ndef __add__(self, other):\n    \"\"\"\n    텐서를 더합니다\n    result = tensor1 + tensor2\n    \"\"\"\n  \n    if self.shape != other.shape:\n        raise ValueError(\"덧셈을 위해서 텐서들은 동일한 모양이어야 함\")\n    \n    Tensor._C.add_tensor.argtypes = [ctypes.POINTER(CTensor), ctypes.POINTER(CTensor)]\n    Tensor._C.add_tensor.restype = ctypes.POINTER(CTensor)\n\n    result_tensor_ptr = Tensor._C.add_tensor(self.tensor, other.tensor)\n\n    result_data = Tensor()\n    result_data.tensor = result_tensor_ptr\n    result_data.shape = self.shape.copy()\n    result_data.ndim = self.ndim\n    result_data.device = self.device\n\n    return result_data\n\n# 기타 연산 포함:\n# __str__\n# __sub__ (-)\n# __mul__ (*)\n# __matmul__ (@)\n# __pow__ (**)\n# __truediv__ (/)\n# log\n# ...\n```\n\n\n\n여기까지 오신 것을 환영합니다! 이제 코드를 실행하고 텐서 작업을 시작할 수 있는 능력이 생겼습니다!\n\n```js\nimport norch\n\ntensor1 = norch.Tensor([[1, 2, 3], [3, 2, 1]])\ntensor2 = norch.Tensor([[3, 2, 1], [1, 2, 3]])\n\nresult = tensor1 + tensor2\nprint(result[0, 0])\n# 4 \n```\n\n# #2 — GPU 지원\n\n우리 라이브러리의 기본 구조를 만든 후, 이제 새로운 수준으로 끌어올릴 것입니다. 데이터를 GPU로 전송하고 수학 연산을 빠르게 실행하기 위해 `.to(\"cuda\")`를 호출할 수 있다는 것은 잘 알려져 있습니다. CUDA가 어떻게 작동하는지 기본 지식이 있을 것으로 가정하겠습니다만, 그렇지 않은 경우 다른 기사인 'CUDA 튜토리얼'을 읽어볼 수 있습니다. 여기서 기다릴게요. 😊\n\n\n\n...\n\n급한 사람들을 위해, 간단한 소개가 여기 있어요:\n\n기본적으로, 지금까지의 모든 코드는 CPU 메모리에서 실행되고 있어요. 하나의 작업에 대해서는 CPU가 빠르지만, GPU의 장점은 병렬화 능력에 있어요. CPU 디자인은 연산(스레드)을 빠르게 실행하도록 목표를 한 반면, GPU 디자인은 수백만 개의 연산을 병렬로 실행하도록 목표를 해요 (개별 스레드의 성능을 희생하며).\n\n그래서 우리는 이 능력을 활용하여 병렬 연산을 수행할 수 있어요. 예를 들어, 백만 개의 요소로 구성된 텐서를 추가할 때, 반복문 내에서 각 색인의 요소를 순차적으로 추가하는 대신, GPU를 사용하여 한꺼번에 모두를 병렬로 추가할 수 있어요. 이를 위해 NVIDIA에서 개발한 개발자들이 GPU 지원을 소프트웨어 애플리케이션에 통합할 수 있게 하는 플랫폼인 CUDA를 사용할 수 있어요.\n\n\n\n그걸 하려면, 특정 GPU 작업(예: CPU 메모리에서 GPU 메모리로 데이터 복사)을 실행하기 위해 설계된 간단한 C/C++ 기반 인터페이스 인 CUDA C/C++를 사용할 수 있습니다.\n\n아래 코드는 기본적으로 CPU에서 GPU로 데이터를 복사하고 배열의 각 요소를 추가하는 AddTwoArrays 함수(커널이라고도 함)를 N개의 GPU 스레드에서 병렬로 실행하는 몇 가지 CUDA C/C++ 함수를 사용합니다.\n\n```c\n#include <stdio.h>\n\n// CPU 버전(비교용)\nvoid AddTwoArrays_CPU(flaot A[], float B[], float C[]) {\n    for (int i = 0; i < N; i++) {\n        C[i] = A[i] + B[i];\n    }\n}\n\n// 커널 정의\n__global__ void AddTwoArrays_GPU(float A[], float B[], float C[]) {\n    int i = threadIdx.x;\n    C[i] = A[i] + B[i];\n}\n\nint main() {\n\n    int N = 1000; // 배열 크기\n    float A[N], B[N], C[N]; // 배열 A, B, C\n\n    ...\n\n    float *d_A, *d_B, *d_C; // 배열 A, B, C의 장치 포인터\n\n    // 배열 A, B, C에 대한 장치에서의 메모리 할당\n    cudaMalloc((void **)&d_A, N * sizeof(float));\n    cudaMalloc((void **)&d_B, N * sizeof(float));\n    cudaMalloc((void **)&d_C, N * sizeof(float));\n\n    // 호스트에서 장치로 배열 A 및 B 복사\n    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n\n    // N개의 스레드를 사용하여 커널 호출\n    AddTwoArrays_GPU<<<1, N>>>(d_A, d_B, d_C);\n    \n    // 장치에서 호스트로 벡터 C 복사\n    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n}\n```\n\n주목할 점은 각 요소 쌍을 각각 추가하는 대신 모든 덧셈 작업을 병렬로 실행하여 루프 명령을 제거한 것입니다.\n\n\n\n간단한 소개 이후에, 텐서 라이브러리로 돌아갈 수 있어요.\n\n첫 번째 단계는 CPU에서 GPU로 텐서 데이터를 보내는 함수를 만드는 것입니다.\n\n```js\n//norch/csrc/tensor.cpp\n\nvoid to_device(Tensor* tensor, char* target_device) {\n    if ((strcmp(target_device, \"cuda\") == 0) && (strcmp(tensor->device, \"cpu\") == 0)) {\n        cpu_to_cuda(tensor);\n    }\n\n    else if ((strcmp(target_device, \"cpu\") == 0) && (strcmp(tensor->device, \"cuda\") == 0)) {\n        cuda_to_cpu(tensor);\n    }\n}\n```\n\n```js\n//norch/csrc/cuda.cu\n\n__host__ void cpu_to_cuda(Tensor* tensor) {\n    \n    float* data_tmp;\n    cudaMalloc((void **)&data_tmp, tensor->size * sizeof(float));\n    cudaMemcpy(data_tmp, tensor->data, tensor->size * sizeof(float), cudaMemcpyHostToDevice);\n\n    tensor->data = data_tmp;\n\n    const char* device_str = \"cuda\";\n    tensor->device = (char*)malloc(strlen(device_str) + 1);\n    strcpy(tensor->device, device_str); \n\n    printf(\"텐서가 성공적으로 %s로 전송되었습니다.\\n\", tensor->device);\n}\n\n__host__ void cuda_to_cpu(Tensor* tensor) {\n    float* data_tmp = (float*)malloc(tensor->size * sizeof(float));\n\n    cudaMemcpy(data_tmp, tensor->data, tensor->size * sizeof(float), cudaMemcpyDeviceToHost);\n    cudaFree(tensor->data);\n\n    tensor->data = data_tmp;\n\n    const char* device_str = \"cpu\";\n    tensor->device = (char*)malloc(strlen(device_str) + 1);\n    strcpy(tensor->device, device_str); \n\n    printf(\"텐서가 성공적으로 %s로 전송되었습니다.\\n\", tensor->device);\n}\n```\n\n\n\n파이썬으로 구현된 래퍼:\n\n```js\n# norch/tensor.py\n\ndef to(self, device):\n    self.device = device\n    self.device_ctype = self.device.encode('utf-8')\n  \n    Tensor._C.to_device.argtypes = [ctypes.POINTER(CTensor), ctypes.c_char_p]\n    Tensor._C.to_device.restype = None\n    Tensor._C.to_device(self.tensor, self.device_ctype)\n  \n    return self\n```\n\n다음으로, 모든 텐서 연산에 대해 GPU 버전을 생성합니다. 덧셈과 뺄셈에 대한 예제를 작성하겠습니다:\n\n```js\n//norch/csrc/cuda.cu\n\n#define THREADS_PER_BLOCK 128\n\n__global__ void add_tensor_cuda_kernel(float* data1, float* data2, float* result_data, int size) {\n    \n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < size) {\n        result_data[i] = data1[i] + data2[i];\n    }\n}\n\n__host__ void add_tensor_cuda(Tensor* tensor1, Tensor* tensor2, float* result_data) {\n    \n    int number_of_blocks = (tensor1->size + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;\n    add_tensor_cuda_kernel<<<number_of_blocks, THREADS_PER_BLOCK>>>(tensor1->data, tensor2->data, result_data, tensor1->size);\n\n    cudaError_t error = cudaGetLastError();\n    if (error != cudaSuccess) {\n        printf(\"CUDA error: %s\\n\", cudaGetErrorString(error));\n        exit(-1);\n    }\n\n    cudaDeviceSynchronize();\n}\n\n__global__ void sub_tensor_cuda_kernel(float* data1, float* data2, float* result_data, int size) {\n   \n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < size) {\n        result_data[i] = data1[i] - data2[i];\n    }\n}\n\n__host__ void sub_tensor_cuda(Tensor* tensor1, Tensor* tensor2, float* result_data) {\n    \n    int number_of_blocks = (tensor1->size + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;\n    sub_tensor_cuda_kernel<<<number_of_blocks, THREADS_PER_BLOCK>>>(tensor1->data, tensor2->data, result_data, tensor1->size);\n\n    cudaError_t error = cudaGetLastError();\n    if (error != cudaSuccess) {\n        printf(\"CUDA error: %s\\n\", cudaGetErrorString(error));\n        exit(-1);\n    }\n\n    cudaDeviceSynchronize();\n}\n\n...\n```\n\n\n\n그런 다음, 텐서.cpp에 새로운 텐서 속성 char* device를 추가하고 작업을 실행할 위치(CPU 또는 GPU)를 선택하는 데 사용할 수 있습니다:\n\n```js\n//norch/csrc/tensor.cpp\n\nTensor* add_tensor(Tensor* tensor1, Tensor* tensor2) {\n    if (tensor1->ndim != tensor2->ndim) {\n        fprintf(stderr, \"덧셈을 위해 텐서가 동일한 차원 수여야 합니다 %d and %d\\n\", tensor1->ndim, tensor2->ndim);\n        exit(1);\n    }\n\n    if (strcmp(tensor1->device, tensor2->device) != 0) {\n        fprintf(stderr, \"텐서는 동일한 장치에 있어야 합니다: %s and %s\\n\", tensor1->device, tensor2->device);\n        exit(1);\n    }\n\n    char* device = (char*)malloc(strlen(tensor1->device) + 1);\n    if (device != NULL) {\n        strcpy(device, tensor1->device);\n    } else {\n        fprintf(stderr, \"메모리 할당 실패\\n\");\n        exit(-1);\n    }\n    int ndim = tensor1->ndim;\n    int* shape = (int*)malloc(ndim * sizeof(int));\n    if (shape == NULL) {\n        fprintf(stderr, \"메모리 할당 실패\\n\");\n        exit(1);\n    }\n\n    for (int i = 0; i < ndim; i++) {\n        if (tensor1->shape[i] != tensor2->shape[i]) {\n            fprintf(stderr, \"덧셈을 위해 텐서들은 색인 %d에서 동일한 형태여야 합니다 %d and %d\\n\", i, tensor1->shape[i], tensor2->shape[i]);\n            exit(1);\n        }\n        shape[i] = tensor1->shape[i];\n    }        \n\n    if (strcmp(tensor1->device, \"cuda\") == 0) {\n\n        float* result_data;\n        cudaMalloc((void **)&result_data, tensor1->size * sizeof(float));\n        add_tensor_cuda(tensor1, tensor2, result_data);\n        return create_tensor(result_data, shape, ndim, device);\n    } \n    else {\n        float* result_data = (float*)malloc(tensor1->size * sizeof(float));\n        if (result_data == NULL) {\n            fprintf(stderr, \"메모리 할당 실패\\n\");\n            exit(1);\n        }\n        add_tensor_cpu(tensor1, tensor2, result_data);\n        return create_tensor(result_data, shape, ndim, device);\n    }     \n}\n```\n\n이제 라이브러리가 GPU 지원을 제공합니다!\n\n```js\nimport norch\n\ntensor1 = norch.Tensor([[1, 2, 3], [3, 2, 1]]).to(\"cuda\")\ntensor2 = norch.Tensor([[3, 2, 1], [1, 2, 3]]).to(\"cuda\")\n\nresult = tensor1 + tensor2\n```\n\n\n\n# #3 — Automatic Differentiation (Autograd)\n\n파이토치가 인기를 얻게 된 주요 이유 중 하나는 Autograd 모듈 때문입니다. Autograd 모듈은 자동 미분을 수행하여 기울기를 계산할 수 있게 해주는 핵심 구성 요소입니다 (경사 하강법과 같은 최적화 알고리즘을 사용하여 모델을 훈련하는 데 중요합니다). .backward()라는 단일 메서드 호출로 이전 텐서 연산에서 모든 기울기를 계산합니다:\n\n```js\nx = torch.tensor([[1., 2, 3], [3., 2, 1]], requires_grad=True)\n# [[1,  2,  3],\n#  [3,  2., 1]]\n\ny = torch.tensor([[3., 2, 1], [1., 2, 3]], requires_grad=True)\n# [[3,  2, 1],\n#  [1,  2, 3]]\n\nL = ((x - y) ** 3).sum()\n\nL.backward()\n\n# x와 y의 기울기에 접근할 수 있습니다\nprint(x.grad)\n# [[12, 0, 12],\n#  [12, 0, 12]]\n\nprint(y.grad)\n# [[-12, 0, -12],\n#  [-12, 0, -12]]\n\n# z를 최소화하기 위해서는 경사 하강법에 사용할 수 있습니다:\n# x = x - 학습률 * x.grad\n# y = y - 학습률 * y.grad\n```\n\n무슨 일이 일어나고 있는지 이해하기 위해 동일한 절차를 수동으로 복제해보겠습니다:\n\n\n\n<img src=\"/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_10.png\" />\n\n우선 계산해 봅시다:\n\n<img src=\"/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_11.png\" />\n\nx가 행렬이라는 것에 유의해야 합니다. 따라서 각 요소에 대한 L의 미분을 개별적으로 계산해야 합니다. 게다가, L은 모든 요소에 대한 합이지만 각 요소에 대한 미분에서 다른 요소들은 중요한 영향을 미치지 않는다는 것을 기억하는 것이 중요합니다. 따라서 우리는 다음과 같은 항을 얻습니다:\n\n\n\n\n![이미지](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_12.png)\n\n각 항에 대해 연쇄 법칙을 적용하여 외부 함수를 미분하고 내부 함수를 미분한 값을 곱합니다:\n\n![이미지](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_13.png)\n\nWhere:\n\n\n\n\n마침내:\n\n![이미지](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_14.png)\n\n그러므로, x에 관한 L의 미분을 계산하는 최종 방정식은 다음과 같습니다:\n\n\n\n아래는 Markdown 형식으로 변경된 내용입니다.\n\n\n![Image 1](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_16.png)\n\nSubstituting the values into the equation:\n\n![Image 2](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_17.png)\n\nCalculating the result, we get the same values we obtained with PyTorch:\n\n\n\n\n\n![image](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_18.png)\n\nNow, let’s analyze what we just did:\n\nBasically, we observed all the operations involved in reverse order: a summation, a power of 3, and a subtraction. Then, we applied the chain rule, calculating the derivative of each operation and recursively calculated the derivative for the next operation. So, first we need an implementation of the derivative for different math operations:\n\nFor addition:\n\n\n\n\n\n![Image](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_19.png)\n\n```js\n# norch/autograd/functions.py\n\nclass AddBackward:\n    def __init__(self, x, y):\n        self.input = [x, y]\n\n    def backward(self, gradient):\n        return [gradient, gradient]\n```\n\nFor sin:\n\n![Image](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_20.png)\n\n\n\n\n```js\n# norch/autograd/functions.py\n\nclass SinBackward:\n    def __init__(self, x):\n        self.input = [x]\n\n    def backward(self, gradient):\n        x = self.input[0]\n        return [x.cos() * gradient]\n```\n\n코사인에 대해:\n\n![2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_21](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_21.png)\n\n```js\n# norch/autograd/functions.py\n\nclass CosBackward:\n    def __init__(self, x):\n        self.input = [x]\n\n    def backward(self, gradient):\n        x = self.input[0]\n        return [- x.sin() * gradient]\n```\n\n\n\n요소별 곱셈에 대한 자세한 내용을 확인해보세요:\n\n![element-wise multiplication](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_22.png)\n\n```python\n# norch/autograd/functions.py\n\nclass ElementwiseMulBackward:\n    def __init__(self, x, y):\n        self.input = [x, y]\n\n    def backward(self, gradient):\n        x = self.input[0]\n        y = self.input[1]\n        return [y * gradient, x * gradient]\n```\n\n합산에 대해서:\n\n\n\n\n# norch/autograd/functions.py\n\n```python\nclass SumBackward:\n    def __init__(self, x):\n        self.input = [x]\n\n    def backward(self, gradient):\n        # sum 함수는 텐서를 스칼라로 줄이므로 기울기를 일치시키기 위해 브로드캐스트됩니다.\n        return [float(gradient.tensor.contents.data[0]) * self.input[0].ones_like()]\n```\n\n다른 연산을 살펴볼 수 있는 GitHub 저장소 링크도 확인할 수 있습니다.\n\n이제 각 작업에 대한 도함수 식을 가졌으니, 재귀적으로 역전파 체인 규칙을 구현할 수 있습니다. 텐서에 requires_grad 인자를 설정하여 이 텐서의 기울기를 저장하려는 것을 나타낼 수 있습니다. True이면 각 텐서 작업의 기울기를 저장합니다. 예를 들어:\n\n```python\n# norch/tensor.py\n\ndef __add__(self, other):\n\n  if self.shape != other.shape:\n      raise ValueError(\"덧셈을 위해 텐서는 동일한 모양이어야 합니다.\")\n  \n  Tensor._C.add_tensor.argtypes = [ctypes.POINTER(CTensor), ctypes.POINTER(CTensor)]\n  Tensor._C.add_tensor.restype = ctypes.POINTER(CTensor)\n  \n  result_tensor_ptr = Tensor._C.add_tensor(self.tensor, other.tensor)\n  \n  result_data = Tensor()\n  result_data.tensor = result_tensor_ptr\n  result_data.shape = self.shape.copy()\n  result_data.ndim = self.ndim\n  result_data.device = self.device\n  \n  result_data.requires_grad = self.requires_grad or other.requires_grad\n  if result_data.requires_grad:\n      result_data.grad_fn = AddBackward(self, other)\n```\n\n\n\n그럼, `.backward()` 메서드를 구현해보세요:\n\n```python\n# norch/tensor.py\n\ndef backward(self, gradient=None):\n    if not self.requires_grad:\n        return\n    \n    if gradient is None:\n        if self.shape == [1]:\n            gradient = Tensor([1]) # dx/dx = 1 case\n        else:\n            raise RuntimeError(\"Gradient argument must be specified for non-scalar tensors.\")\n\n    if self.grad is None:\n        self.grad = gradient\n\n    else:\n        self.grad += gradient\n\n    if self.grad_fn is not None: # not a leaf\n        grads = self.grad_fn.backward(gradient) # call the operation backward\n        for tensor, grad in zip(self.grad_fn.input, grads):\n            if isinstance(tensor, Tensor):\n                tensor.backward(grad) # recursively call the backward again for the gradient expression (chain rule)\n```\n\n마지막으로, 텐서의 그래디언트를 제로화하는 `.zero_grad()`와 텐서의 오토그래드 히스토리를 제거하는 `.detach()`를 구현해주세요:\n\n```python\n# norch/tensor.py\n\ndef zero_grad(self):\n    self.grad = None\n\ndef detach(self):\n    self.grad = None\n    self.grad_fn = None\n```\n\n\n\n축하합니다! GPU 지원 및 자동 미분 기능이 있는 완전한 텐서 라이브러리를 만드셨군요! 이제 nn 및 optim 모듈을 만들어 몇 가지 딥 러닝 모델을 더 쉽게 훈련시킬 수 있습니다.\n\n## #4 — nn 및 optim 모듈\n\nnn은 신경망 및 딥 러닝 모델을 구축하기 위한 모듈이며, optim은 이러한 모델을 훈련시키기 위한 최적화 알고리즘과 관련이 있습니다. 이들을 재현하기 위한 첫 번째 단계는 Parameter를 구현하는 것입니다. Parameter는 간단히 말해 항상 True로 설정된 requires_grad 속성을 갖는 훈련 가능한 텐서로, 일부 임의의 초기화 기법을 사용해 같은 연산을 수행합니다.\n\n```js\n# norch/nn/parameter.py\n\nfrom norch.tensor import Tensor\nfrom norch.utils import utils\nimport random\n\nclass Parameter(Tensor):\n    \"\"\"\n    A parameter is a trainable tensor.\n    \"\"\"\n    def __init__(self, shape):\n        data = utils.generate_random_list(shape=shape)\n        super().__init__(data, requires_grad=True)\n```\n\n\n\n```js\n# norch/utisl/utils.py\n\ndef generate_random_list(shape):\n    \"\"\"\n    랜덤한 숫자로 이루어진 'shape' 형태의 리스트를 생성합니다\n    [4, 2] --> [[rand1, rand2], [rand3, rand4], [rand5, rand6], [rand7, rand8]]\n    \"\"\"\n    if len(shape) == 0:\n        return []\n    else:\n        inner_shape = shape[1:]\n        if len(inner_shape) == 0:\n            return [random.uniform(-1, 1) for _ in range(shape[0])]\n        else:\n            return [generate_random_list(inner_shape) for _ in range(shape[0])]\n```\n\n파라미터를 활용하면 모듈을 구성할 수 있습니다:\n\n```js\n# norch/nn/module.py\n\nfrom .parameter import Parameter\nfrom collections import OrderedDict\nfrom abc import ABC\nimport inspect\n\nclass Module(ABC):\n    \"\"\"\n    모듈을 위한 추상 클래스\n    \"\"\"\n    def __init__(self):\n        self._modules = OrderedDict()\n        self._params = OrderedDict()\n        self._grads = OrderedDict()\n        self.training = True\n\n    def forward(self, *inputs, **kwargs):\n        raise NotImplementedError\n\n    def __call__(self, *inputs, **kwargs):\n        return self.forward(*inputs, **kwargs)\n\n    def train(self):\n        self.training = True\n        for param in self.parameters():\n            param.requires_grad = True\n\n    def eval(self):\n        self.training = False\n        for param in self.parameters():\n            param.requires_grad = False\n\n    def parameters(self):\n        for name, value in inspect.getmembers(self):\n            if isinstance(value, Parameter):\n                yield self, name, value\n            elif isinstance(value, Module):\n                yield from value.parameters()\n\n    def modules(self):\n        yield from self._modules.values()\n\n    def gradients(self):\n        for module in self.modules():\n            yield module._grads\n\n    def zero_grad(self):\n        for _, _, parameter in self.parameters():\n            parameter.zero_grad()\n\n    def to(self, device):\n        for _, _, parameter in self.parameters():\n            parameter.to(device)\n\n        return self\n    \n    def inner_repr(self):\n        return \"\"\n\n    def __repr__(self):\n        string = f\"{self.get_name()}(\"\n        tab = \"   \"\n        modules = self._modules\n        if modules == {}:\n            string += f'\\n{tab}(parameters): {self.inner_repr()}'\n        else:\n            for key, module in modules.items():\n                string += f\"\\n{tab}({key}): {module.get_name()}({module.inner_repr()})\"\n        return f'{string}\\n)'\n    \n    def get_name(self):\n        return self.__class__.__name__\n    \n    def __setattr__(self, key, value):\n        self.__dict__[key] = value\n\n        if isinstance(value, Module):\n            self._modules[key] = value\n        elif isinstance(value, Parameter):\n            self._params[key] = value\n```\n\n예를 들어, nn.Module을 상속하여 사용자 정의 모듈을 만들거나, 이전에 생성된 모듈 중 하나인 선형 모듈을 사용하여 y = Wx + b 작업을 구현할 수 있습니다.\n\n\n\n\n```js\n# norch/nn/modules/linear.py\n\nfrom ..module import Module\nfrom ..parameter import Parameter\n\nclass Linear(Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.weight = Parameter(shape=[self.output_dim, self.input_dim])\n        self.bias = Parameter(shape=[self.output_dim, 1])\n\n    def forward(self, x):\n        z = self.weight @ x + self.bias\n        return z\n\n    def inner_repr(self):\n        return f\"input_dim={self.input_dim}, output_dim={self.output_dim}, \" \\\n               f\"bias={True if self.bias is not None else False}\"\n```\n\n이제 몇 가지 손실 및 활성화 함수를 구현할 수 있습니다. 예를 들어, 평균 제곱 오차 손실 및 시그모이드 함수:\n\n```js\n# norch/nn/loss.py\n\nfrom .module import Module\n \nclass MSELoss(Module):\n    def __init__(self):\n      pass\n\n    def forward(self, predictions, labels):\n        assert labels.shape == predictions.shape, \\\n            \"Labels and predictions shape does not match: {} and {}\".format(labels.shape, predictions.shape)\n        \n        return ((predictions - labels) ** 2).sum() / predictions.numel\n\n    def __call__(self, *inputs):\n        return self.forward(*inputs)\n```\n\n```js\n# norch/nn/activation.py\n\nfrom .module import Module\nimport math\n\nclass Sigmoid(Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        return 1.0 / (1.0 + (math.e) ** (-x)) \n```\n\n\n\n마지막으로 옵티마이저를 만들어봅시다. 예시로 확률적 경사 하강법(Stochastic Gradient Descent) 알고리즘을 구현하겠습니다:\n\n```js\n# norch/optim/optimizer.py\n\nfrom abc import ABC\nfrom norch.tensor import Tensor\n\nclass Optimizer(ABC):\n    \"\"\"\n    옵티마이저를 위한 추상 클래스\n    \"\"\"\n\n    def __init__(self, parameters):\n        if isinstance(parameters, Tensor):\n            raise TypeError(\"parameters는 반복 가능한 객체이어야 하지만 {} 타입이 입력되었습니다\".format(type(parameters)))\n        elif isinstance(parameters, dict):\n            parameters = parameters.values()\n\n        self.parameters = list(parameters)\n\n    def step(self):\n        raise NotImplementedError\n    \n    def zero_grad(self):\n        for module, name, parameter in self.parameters:\n            parameter.zero_grad()\n\n\nclass SGD(Optimizer):\n    def __init__(self, parameters, lr=1e-1, momentum=0):\n        super().__init__(parameters)\n        self.lr = lr\n        self.momentum = momentum\n        self._cache = {'velocity': [p.zeros_like() for (_, _, p) in self.parameters]}\n\n    def step(self):\n        for i, (module, name, _) in enumerate(self.parameters):\n            parameter = getattr(module, name)\n\n            velocity = self._cache['velocity'][i]\n\n            velocity = self.momentum * velocity - self.lr * parameter.grad\n\n            updated_parameter = parameter + velocity\n\n            setattr(module, name, updated_parameter)\n\n            self._cache['velocity'][i] = velocity\n\n            parameter.detach()\n            velocity.detach()\n```\n\n그리고 여기까지입니다! 이제 우리만의 딥러닝 프레임워크를 만들었어요! 🥳\n\n이제 학습을 시작해봅시다:\n\n\n\n```js\nimport norch\nimport norch.nn as nn\nimport norch.optim as optim\nimport random\nimport math\n\nrandom.seed(1)\n\nclass MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.fc1 = nn.Linear(1, 10)\n        self.sigmoid = nn.Sigmoid()\n        self.fc2 = nn.Linear(10, 1)\n\n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.sigmoid(out)\n        out = self.fc2(out)\n        \n        return out\n\ndevice = \"cuda\"\nepochs = 10\n\nmodel = MyModel().to(device)\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001)\nloss_list = []\n\nx_values = [0. ,  0.4,  0.8,  1.2,  1.6,  2. ,  2.4,  2.8,  3.2,  3.6,  4. ,\n        4.4,  4.8,  5.2,  5.6,  6. ,  6.4,  6.8,  7.2,  7.6,  8. ,  8.4,\n        8.8,  9.2,  9.6, 10. , 10.4, 10.8, 11.2, 11.6, 12. , 12.4, 12.8,\n       13.2, 13.6, 14. , 14.4, 14.8, 15.2, 15.6, 16. , 16.4, 16.8, 17.2,\n       17.6, 18. , 18.4, 18.8, 19.2, 19.6, 20.]\n\ny_true = []\nfor x in x_values:\n    y_true.append(math.pow(math.sin(x), 2))\n\n\nfor epoch in range(epochs):\n    for x, target in zip(x_values, y_true):\n        x = norch.Tensor([[x]]).T\n        target = norch.Tensor([[target]]).T\n\n        x = x.to(device)\n        target = target.to(device)\n\n        outputs = model(x)\n        loss = criterion(outputs, target)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss[0]:.4f}')\n    loss_list.append(loss[0])\n\n# Epoch [1/10], Loss: 1.7035\n# Epoch [2/10], Loss: 0.7193\n# Epoch [3/10], Loss: 0.3068\n# Epoch [4/10], Loss: 0.1742\n# Epoch [5/10], Loss: 0.1342\n# Epoch [6/10], Loss: 0.1232\n# Epoch [7/10], Loss: 0.1220\n# Epoch [8/10], Loss: 0.1241\n# Epoch [9/10], Loss: 0.1270\n# Epoch [10/10], Loss: 0.1297\n```\n\n<img src=\"/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_23.png\" />\n\n성공적으로 모델이 생성되고 사용자 정의 딥러닝 프레임워크를 사용하여 훈련되었습니다!\n\n전체 코드는 여기에서 확인할 수 있습니다.\n\n\n\n# 결론\n\n이 게시물에서는 텐서와 같은 기본 개념, 어떻게 모델링되는지, CUDA 및 Autograd와 같은 고급 주제 등을 다루었습니다. 우리는 GPU 지원 및 자동 미분이 가능한 딥 러닝 프레임워크를 성공적으로 만들었습니다. 이 게시물이 여러분이 PyTorch가 어떻게 작동하는지 간략히 이해하는 데 도움이 되었으면 좋겠습니다.\n\n앞으로의 게시물에서는 분산 훈련(다중 노드/다중 GPU) 및 메모리 관리와 같은 고급 주제를 다루려고 할 것입니다. 의견이 있거나 다음에 어떤 내용을 다루길 원하시는지 댓글로 알려주세요! 읽어 주셔서 정말 감사합니다! 😊\n\n또한 최신 기사를 받아보기 위해 여기와 제 LinkedIn 프로필에서 팔로우해 주세요!\n\n\n\n# 참고 자료\n\n- [PyNorch](https://github.com) - 이 프로젝트의 GitHub 저장소 \n- [CUDA 튜토리얼](https://www.example.com/tutorial-cuda) - CUDA 작동 방식에 대한 간단한 소개\n- [PyTorch](https://pytorch.org/docs) - PyTorch 문서\n\n\n\n# MartinLwx's 블로그 - 스트라이드에 관한 튜토리얼.\n\n# 스트라이드 튜토리얼 - 스트라이드에 관한 또 다른 튜토리얼.\n\n# PyTorch 내부 구조 - PyTorch 구조에 대한 가이드.\n\n# 네츠 - NumPy를 사용한 PyTorch 재구현.\n\n\n\nMarkdown으로 표 태그를 변경하십시오.","ogImage":{"url":"/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_0.png"},"coverImage":"/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_0.png","tag":["Tech"],"readingTime":40},{"title":"2024년을 위한 무료 프론트엔드 및 백엔드 개발 강좌 TOP 10","description":"","date":"2024-05-15 10:30","slug":"2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024","content":"\n\n## 초보자와 중급 개발자를 위한 내가 좋아하는 무료 웹 개발 강좌\n\n![image](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_0.png)\n\n안녕하세요 여러분, 여러분이 2024년에 프론트엔드와 백엔드 개발을 배우고 무료 온라인 강좌, 튜토리얼, 그리고 책과 같은 최고의 무료 자료를 찾고 있다면 제가 맞는 장소에 오신 것을 환영합니다.\n\n이전에는 HTML, CSS, JavaScript, React, Angular, 그리고 Node.js를 배우기 위한 최고의 웹 개발 온라인 강좌를 공유한 적이 있으며, 이번 기사에서는 웹 개발을 배우기 위한 최고의 무료 온라인 강좌를 공유하려고 합니다.\n\n\n\n이 기사에는 Udemy 및 Coursera와 같은 사이트에서 무료로 가입할 수있는 무료 웹 개발 과정이 포함되어 있습니다. 이를 통해 누구나 2024년에 웹 개발에 필요한 기본 기술을 배울 수 있습니다.\n\n하지만, 먼저 프론트엔드와 백엔드를 모두 다루는 웹 개발에 대해 알려주는 최고의 무료 온라인 과정 10개로 넘어가기 전에요.\n\n웹 개발이란 인터넷에 호스팅되는 웹사이트를 개발하는 데 관련된 모든 작업을 정의하는 데 사용됩니다. 웹사이트를 개발하는 과정에는 웹 디자인, 웹 콘텐츠 개발, 서버 측 스크립팅 및 네트워크 보안 구성이 포함될 수 있습니다.\n\n웹 개발은 또한 웹사이트를 생성, 유지 관리 및 관리하기 위해 필요한 모든 다양한 작업, 작업 및 업데이트를 의미할 수도 있습니다. 좋은 웹 개발자는 최적의 성능, 속도 및 사용자 경험을 확보해야 합니다.\n\n\n\n# 2024년 초보자를 위한 최고의 무료 웹 개발 강좌 10선\n\n여기서는 7개의 최고의 무료 웹 개발 강좌 목록을 모았습니다. 계속 읽어보세요.\n\n## 1. 웹 개발자를 위한 웹 디자인: 아름다운 웹사이트 만들기\n\n이 강좌는 몇 가지 빠른 단계로 흥미로운 멋진 웹사이트를 만드는 방법을 가르치는 좋은 무료 강좌입니다. HTML과 주석 기반 의존성 주입을 효율적으로 사용할 수 있게 될 것입니다.\n\n\n\n이제 여러 웹 사이트에 대한 외부 맞춤 속성 및 빈을 구성할 수 있을 것입니다. 다양한 기능을 활용하여 올바른 방법으로 흥미로운 이메일을 보내는 방법을 배우게 될 것입니다.\n\n수업 기간: 2 시간\n\n수업 평점: 5점 중 4.4점\n\n강사: Jonas Schmeldtmann\n\n\n\n코스 비용: 무료\n\n![이미지](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_1.png)\n\n## 2. JavaScript Essentials [Udemy]\n\n이 멋진 코스에서는 JavaScript를 사용하여 아름다운 웹사이트를 구성하고 만드는 방법을 배울 수 있습니다. 또한 JavaScript를 사용하여 웹 애플리케이션을 만들 수도 있습니다. 또한 JPA와 Hibernate를 사용하여 데이터베이스에서 데이터를 저장 및 업데이트하는 방법도 배울 수 있습니다.\n\n\n\n강의 기간: 6 시간\n\n강의 평가: 5점 만점에 4.1점\n\n강사: Lawrence Turton\n\n수강료: 무료\n\n\n\n![Course Image](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_2.png)\n\n## 3. Practical PHP: Master The Basics And Code Dynamic Websites\n\n이 흥미로운 강의를 통해 PHP와 JavaScript를 사용하여 놀라운 웹 사이트를 만들 수 있습니다. HTTP 요청을 처리하는 웹 서비스 엔드포인트를 만드는 방법을 배울 것입니다. 또한 URL 쿼리 문자열 요청 매개변수를 읽고 삭제할 수도 있을 것입니다.\n\n강의 기간: 3 시간\n\n\n\n코스 평점: 5점 만점에 4.4점\n\n코스 강사: 브래드 허시와 코드 컬리지\n\n코스 가격: 무료\n\n![이미지](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_3.png)\n\n\n\n## 4. 웹 개발 체험하기: 처음부터 배우는 HTML과 CSS\n\n이 강좌는 웹 개발을 다뤄봄으로서 개발부터 배포까지 완벽한 안내서 역할을 해 줄 것입니다. HTML과 CSS를 이용해 다양한 기술로 애플리케이션을 구축하는 방법을 배울 수 있을 것입니다.\n\n수강 시간: 3 시간\n\n수강 평점: 5점 만점 중 4점\n\n\n\n강좌 강사: Bradley Berger\n\n강좌 가격: 무료\n\n![이미지](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_4.png)\n\n## 5. HTML5 및 CSS 3로 일주일 안에 첫 번째 웹사이트 만들기\n\n\n\n이 멋진 강좌를 통해 1주일만에 아름답고 기능적인 웹사이트를 만드는 방법을 배울 수 있습니다. 또한 포트폴리오에 표시할 새로운 프로젝트를 만들 수도 있습니다.\n\nSpring Data JPA를 활용하여 데이터를 저장하고 받는 방법을 배우게 될 것이며, Thymeleaf를 사용하여 데이터베이스에서 웹페이지로 데이터를 표시할 수도 있습니다.\n\n강좌 소요 시간: 3시간\n\n강좌 평가: 5점 만점 중 4.2점\n\n\n\n강좌 강사: Ryan Bernhardt\n\n강좌 가격: 무료\n\n![이미지](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_5.png)\n\n## 6. 프론트엔드 웹 개발 기초 [Udemy]\n\n\n\n이것은 웹 디자인과 웹 개발에 대해 알아야 할 모든 것을 가르쳐주는 훌륭한 무료 강좌입니다. 웹 사이트와 그 뒤에있는 데이터베이스 간의 통신 라인을 어떻게 구축할 수 있는지 배우게 될 것입니다.\n\n먼저 웹 사이트를 위한 간단한 첫 페이지를 만드는 방법을 배우게 됩니다. 게다가 웹 사이트에 도움이 될 기능적인 데이터베이스도 만들 수 있을 겁니다.\n\n강좌 기간: 1 시간\n\n강좌 평점: 5점 중 4.5점\n\n\n\n강의 강사: Davide Molin\n\n강의 가격: 무료\n\n![Course Image](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_6.png)\n\n## 7. 스프링 부트와 스프링 클라우드로 스프링 마이크로서비스 마스터하기\n\n\n\n이 코스는 Spring Cloud를 사용하여 Spring Boot Microservices를 마스터하는 데 도움이 되는 훌륭한 코스입니다. 이 코스를 통해 Java로 마이크로서비스를 만들기 위해 필요한 Spring 및 Spring Boot에 대해 모든 것을 배울 수 있습니다.\n\n코스 기간: 2 시간\n\n코스 평가: 5점 만점 중 4.4점\n\n코스 강사: Karthikeya T\n\n\n\n수업 가격: 무료\n\n![image](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_7.png)\n\n## 8. DevTools Pro: Chrome 개발자 도구 기초 [Udemy]\n\n이 강의에서는 이력서를 향상시키고 포트폴리오를 자랑하기 위해 아름다운 창조적인 웹사이트를 만드는 방법을 가르쳐줍니다. 구글 크롬 애플리케이션을 위한 간단한 웹사이트를 만드는 방법을 배울 수 있습니다. 또한 리소스를 저장하기 위해 계층적인 크롬 웹사이트를 만드는 방법도 배울 수 있습니다.\n\n\n\n강의 기간: 1시간\n\n강의 평점: 5점 만점 중 4.6점\n\n강의 강사: Rocco Balsamo\n\n강의 가격: 무료\n\n\n\n![이미지](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_8.png)\n\n## 9. 초보자를 위한 스프링 프레임워크와 의존성 주입\n\n이것은 몇 가지빠른 단계로 흥미로운 스프링 애플리케이션을 만드는 방법을 가르쳐주는 좋은 무료 강좌입니다. Java와 주석 기반의 의존성 주입을 효과적으로 사용할 수 있게 될 것입니다.\n\n다양한 환경에 대한 외부 사용자 정의 속성 및 빈을 구성할 수 있을 것입니다. 또한 Spring Boot를 사용하여 SMTP 메일을 올바른 방식으로 보내는 방법을 배우게 될 것입니다.\n\n\n\n코스 기간: 2시간\n\n코스 평점: 5점 만점에 4.4점\n\n강사: 산제이 파텔\n\n코스 가격: 무료\n\n\n\n<img src=\"/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_9.png\" />\n\n## 10. 초보자를 위한 Node JS API 개발 [무료]\n\n온라인에서 얻을 수 있는 최고의 Node JS 초보자 과정 중 하나입니다. 이 과정에서는 Node JS API 개발을 처음부터 배우게 됩니다.\n\n이 과정은 완전한 초보자들에게 게시된 가이드와 같습니다. Node JS가 무엇이며 왜 node.js를 배워야 하는지부터 시작해서, node js 개발 환경 설치 방법 및 브라우저 및 비브라우저 배경에서 JavaScript가 어떻게 실행되는지 이해할 수 있습니다.\n\n이 과정에서는 Modern JavaScript, Node JS 이벤트 루프, 비동기 프로그래밍, 노드 모듈, npm 모듈 및 직접 모듈 만들기, 서버 만들기, 데이터베이스에 연결하고 json 응답을 보내는 방법을 배울 수 있습니다.\n\n이 과정은 이론과 실습의 아주 좋은 조화를 갖추고 있어 무료 강좌로는 매우 어려운 것입니다.\n\n\n\n이 무료 강의에 참여할 수 있는 링크입니다 - Node JS API 개발\n\n![Node JS API Development](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_10.png)\n\n2024년에 참여할 수 있는 최고의 10개 무료 웹 개발 강좌에 대해 알아보았습니다. JavaScript, PHP 및 Java 개발자를 위한 무료 웹 개발 강좌를 모두 포함했습니다. 프론트엔드 개발과 백엔드 개발 강좌 모두를 조화롭게 섞어 웹 개발을 깊이 있게 학습하고 풀스택 개발자로 거듭날 수 있도록 노력했습니다.\n\n이 10개의 최고의 무료 웹 개발 강좌 목록이 마음에 드신다면 친구나 가족과 자유롭게 공유해보세요.\n\n\n\n웹 개발 분야에 의문이 생기면 언제든지 댓글을 달아주세요. 저희가 즉시 답변해 드릴 거에요. 이 강좌들은 몇 주 만에 완전 초보자에서 숙련된 웹 개발자로 변신할 수 있을 거라고 확신해요.\n\n다른 웹 개발자를 위한 리소스:\n\n- 웹 개발을 배우기 위한 최고 5개 강좌\n- React 프레임워크를 학습하기 위한 최고 5개 강좌\n- 2024년 웹 개발자로 거듭나는 방법\n- 초보자를 위한 Node.js 학습을 위한 최상의 10개 강좌\n- 풀 스택 개발자가 되기 위한 최상의 10개 강좌\n- 초보자를 위한 Angular 학습을 위한 10개의 무료 강좌\n- 2024년 React 개발자 로드맵\n- 웹 개발 배우기에 늦은 게 아냐\n- 2024년 React 학습을 위한 10개의 무료 강좌\n- 웹 개발자 로드맵 (프론트엔드 + 백엔드)\n- 웹 개발자를 위한 5개의 HTML 및 CSS 무료 강좌\n- 프로그래머를 위한 Java 및 웹 개발 강좌 10개\n- 모든 소프트웨어 엔지니어가 배워야 할 10가지\n- 2024년에 Java 및 웹 개발자가 배울 수 있는 10가지 프레임워크\n\n이 글을 읽어 주셔서 감사해요. 만약 이러한 최고의 무료 프론트엔드 및 백엔드 개발 강좌를 좋아하신다면, 친구들과 동료들과 공유해 주세요. 궁금한 점이나 피드백이 있으면 남겨주세요.\n\n참고 - Node.js와 같이 가치 있는 것을 배우기 위해 약간의 돈을 지불해도 된다면, Udemy의 Andrew Mead나 Rob Percival과 같은 전문가들의 Node.js 강좌 목록도 확인해 보시기를 권유합니다.","ogImage":{"url":"/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_0.png"},"coverImage":"/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_0.png","tag":["Tech"],"readingTime":6},{"title":"자바스크립트에서 1, 5, 11mapparseInt가 1, NaN, 3을 반환하는 이유","description":"","date":"2024-05-15 10:28","slug":"2024-05-15-Why1511mapparseIntreturns1NaN3inJavascript","content":"\n\n\n<img src=\"/assets/img/2024-05-15-Why1511mapparseIntreturns1NaN3inJavascript_0.png\" />\n\n다음에 그가 본 것은 그를 깊이 충격을 받게 했다:\n\n<img src=\"/assets/img/2024-05-15-Why1511mapparseIntreturns1NaN3inJavascript_1.png\" />\n\n이게 어떻게 가능할까? parseInt가 고장 났나? map()에 버그가 있나요?\n\n\n\n\n그는 절망적으로 올려다보았고, 제이크로부터 날카롭고 불안한 웃음소리를 듣게 되었다.\n\n코딩 실력 자랑꾼인 알렉스는 빠른 해킹과 짧은 코드를 자랑했다.\n\n산업에 아주 새로운 신입사원임에도 불구하고, 그는 항상 팀의 나머지보다 우월하다고 생각했으며, 자신이 원하는 대로 고집스럽게 행동했다. 그들의 선의로운 조언은 씌어지지 않았다.\n\n그러나 알렉스는 곧 충격적인 파멸과 마주하게 될 것이다. 그는 결코 잊지 못할 고통스럽고 겸손한 경험을 할 것이다.\n\n\n\n모든 것은 Alex와 Cody가 프로젝트 과제를 맡게 된 순간부터 시작되었습니다. 팀이 작업 중이던 전자상거래 웹 사이트의 제품을 사용자들이 볼 수 있도록 하기로 했죠.\n\n아직 스타트업 단계였기 때문에 모든 데이터는 CSV 파일에 저장되고 업데이트되었어요.\n\n제품 이름, 가격, 수량... 아마존과 같은 사이트에서 볼 수 있는 모든 일반적인 정보였죠.\n\nAlex는 협업 계획을 알게 되자 거만하게 비웃었습니다.\n\n\n\n\"누구하고 일을 한다는 건 전혀 필요하지 않아, 알았지?\" 그가 자신의 PC에서 타이핑을 하면서 웃었다. 엔지니어링 부서장인 온순한 제이크를 쳐다보았다. \"DB에서 가져와 JSX에 표시하는 거 뿐이야.\"\n\n\"알렉스, 타인과 협력하는 법 배워야 해. 계속 말하는데, 맞지?\", 제이크는 인내를 가지고 웃으며 대답했다. 그는 이 자의 자기 중심적인 짓궂음에 익숙했다.\n\n\"누구와 협력할 필요도 없어, 나 혼자서도 할 수 있어. 코디가 그 모호한 '가독성 좋은 코드' 얘기로 나를 방해할 뿐이야.\"\n\n\"코디는 최고 중 하나고, 시간을 들이는 게 그만한 이유가 있어. 코드를 빠르게 작성하고 간결하게 하는 게 전부가 아니라고 말했던 걸 계속 말하는데…\"\n\n\n\n\"너는 항상 내게 말을 하지만, 전혀 내 말을 듣지 않아. 이번에는 제게 혼자서 작업하게 해주세요, 알았죠?\"라며, 알렉스가 덧붙였어요. 너무 무례하게 들리지 않게 하려고 빠르게 말했죠 — 물론 그 스노비한 미소는 계속 유지하고 있었어요.\n\n제이크가 한숨을 쉬었어요.\n\n\"알았어요, 너 혼자서 작업할 수 있다면 이 문자열 배열을 숫자 배열로 변환해봐\", 그가 가까이 있는 종이에 노트하기 전에 말했어요.\n\n알렉스는 믿을 수가 없었어요. 종이에는 간단한 배열이 적혀 있었답니다.\n\n\n\n<img src=\"/assets/img/2024-05-15-Why1511mapparseIntreturns1NaN3inJavascript_2.png\" />\n\n이건 반드시 속임수 문제였다. 그는 의심스럽게 제이크를 쳐다봤다.\n\n\"진지하니? 이걸 파싱할 수 없을 정도로 얼마나 어리석다고 생각해?\"\n\n\"해보세요, 한 번의 기회밖에 없어요.\" 제이크는 이 소년에 대한 놀라운 인내심에 자기 제어력 메달을 받을 자격이 있다.\n\n\n\n심쿵 낀 표정을 지은 알렉스는 새로운 VS Code 터미널을 열고 오만한 표정으로 Node에서 보이는 당연한 솔루션을 타이핑했습니다:\n\n![image](/assets/img/2024-05-15-Why1511mapparseIntreturns1NaN3inJavascript_3.png)\n\n자신만만한 듯 웃음을 지었지만, 자크가 알렉스에게 짓는 알아차릴 수밖에 없는 미소를 보자 순식간에 균형을 잃어버렸습니다.\n\n\"확실하단말씀이신가요, 알렉스? 엔터 키를 눌러 최종 배열이 어떻게 되는지 한번 보죠.\"\n\n\n\n본인에게 약간 의심스러운 마음이 들어, 최종 순간이 오기 전에 제공된 짧은 CLI 코드를 확실하게 확인하기로 했습니다.\n\n다음에 보여진 것은 그를 깊이 깨우치게 했습니다.\n\n<img src=\"/assets/img/2024-05-15-Why1511mapparseIntreturns1NaN3inJavascript_4.png\" />\n\n어떻게 이런 일이 가능한 걸까요? parseInt가 제대로 작동하지 않는 걸까요? 또는 map()에 버그가 있는 걸까요?\n\n\n\n허나, 처자는 상담을 시작했다.\n\n\n\n알렉스의 실패는 map과 parseInt를 이해하지 못해 일어난 것이 아니었습니다 - 그러나 그것이 도움이 될 수도 있었습니다.\n\n알렉스의 문제는 가독성과 명확성을 희생하면서 코드를 가능한 짧게 만드는 집착이었어요...\n\n사실 99%의 경우에는 우리가 map과 parseInt를 사용하는 방식이 이런 식입니다\n\n<img src=\"/assets/img/2024-05-15-Why1511mapparseIntreturns1NaN3inJavascript_5.png\" />\n\n\n\n하지만 console.log를 사용하여 맵을 사용할 때 무슨 일이 벌어지는지 알면 놀랄 지도 모릅니다:\n\n![이미지](/assets/img/2024-05-15-Why1511mapparseIntreturns1NaN3inJavascript_6.png)\n\n각 항목에 대해 숫자 쌍이 3개씩 로깅됩니다!\n\n![이미지](/assets/img/2024-05-15-Why1511mapparseIntreturns1NaN3inJavascript_7.png)\n\n\n\n그 이유는 map() 콜백이 실제로 3개의 인수를 가져오기 때문입니다:\n\n\n<img src=\"/assets/img/2024-05-15-Why1511mapparseIntreturns1NaN3inJavascript_8.png\" />\n\n\n따라서 실제로 3개의 인수로 parseInt를 호출하게 됩니다:\n\n\n<img src=\"/assets/img/2024-05-15-Why1511mapparseIntreturns1NaN3inJavascript_9.png\" />\n  \n\n\n\n알렉스는 절대 parseInt가 1 또는 2개의 인수를 가져야 하며 각각에 대해 다르게 동작한다는 것을 몰랐습니다:\n\n두 번째 인수가 있는 경우 첫 번째 숫자 인수의 기수로 설정됩니다:\n\n![image](/assets/img/2024-05-15-Why1511mapparseIntreturns1NaN3inJavascript_10.png)\n\n맵(map) 및 parseInt에 대한 평균 지식을 갖고 있지만, 명시적으로 표현하는 것으로 이 모든 것을 피할 수 있었을 텐데요:\n\n\n\n![image](/assets/img/2024-05-15-Why1511mapparseIntreturns1NaN3inJavascript_11.png)\n\n코드를 줄이는 것은 혼란을 줄일 수 있는 좋은 방법이지만 항상 명확하고 가독성이 좋은 코드를 우선시해야 합니다.\n\n특히 길이가 그리 큰 문제가 아닌 경우에는 더욱 그렇죠?\n\n![image](/assets/img/2024-05-15-Why1511mapparseIntreturns1NaN3inJavascript_12.png)","ogImage":{"url":"/assets/img/2024-05-15-Why1511mapparseIntreturns1NaN3inJavascript_0.png"},"coverImage":"/assets/img/2024-05-15-Why1511mapparseIntreturns1NaN3inJavascript_0.png","tag":["Tech"],"readingTime":4},{"title":"코틀린 함수가 일등 시민인 이유","description":"","date":"2024-05-15 10:25","slug":"2024-05-15-KotlinFunctionsasFirstClassCitizens","content":"\n\n코틀린에서 함수 구성 이해하기\n\n![코틀린 함수](/assets/img/2024-05-15-KotlinFunctionsasFirstClassCitizens_0.png)\n\n코틀린에서 함수는 일등 시민으로 취급되어 변수처럼 다룰 수 있습니다. 즉, 함수는 변수에 할당되거나 다른 함수에 매개변수로 전달되거나 함수에서 반환될 수 있습니다.\n\n이를 통해 함수를 다양한 방식으로 결합하여 코드를 간소화하고 함수형 프로그래밍 패러다임을 사용할 수 있습니다.\n\n\n\n자, 우리가 얻을 수 있는 몇 가지 기능들을 살펴봅시다!\n\n## 변수에 값 할당하기 📝\n\n이것에 대한 예시는 다음과 같습니다:\n\n```js\n// 선언\nval foo : () -> Unit = {\n    println(\"안녕 함수!\")\n}\n\n// 사용\nfoo()\n\n// 결과\n안녕 함수!\n```\n\n\n\n참고: 네, 당신은 보통 또는 선언적으로 할 수 있습니다. 여기서는 함수 합성에 대해 이야기하고 있으므로 주석 섹션에서 소리치지 않아도 됩니다.\n\n이 방법의 장점:\n\n- 재사용성\n\n변수에 저장해 두었기 때문에 코드베이스의 여러 곳에서 재사용할 수 있습니다.\n\n\n\n```kotlin\n// 현재 시간 계산\nval currentTime: () -> Unit = {\n    val currentTime = LocalTime.now()\n    val formatter = DateTimeFormatter.ofPattern(\"HH:mm:ss\")\n    val formattedTime = currentTime.format(formatter)\n    println(\"현재 시간은: $formattedTime\")\n}\n\n// 보통은 호출하여 사용\ncurrentTime()\n\n// 또는 일정 간격으로\n\nsuspend fun repeatInterval(block: () -> Unit, delay: Long) {\n    while (true) {\n        delay(delay)\n        block.invoke()\n    }\n}\n\nfun main(){\n    runBlocking {\n        launch {\n            // 매개변수로 전달하는 사용법\n            repeatInterval(currentTime, 1000)\n        }\n    }\n}\n```\n\n2. 가독성\n\n익명 함수 대신 변수 이름을 전달하여 더 명확하게 만들 수 있습니다. 그렇지 않으면 전체 함수 블록을 읽어야 이해할 수 있습니다. 예시 :\n\n```kotlin\nrepeatInterval({\n  val currentTime = LocalTime.now()\n  val formatter = DateTimeFormatter.ofPattern(\"HH:mm:ss\")\n  val formattedTime = currentTime.format(formatter)\n  println(\"현재 시간은: $formattedTime\")\n  // 이것을 이해하려면 전체를 읽어야 합니다\n }, 1000)\n\n// 대비\n\nval currentTime: () -> Unit = {\n    val currentTime = LocalTime.now()\n    val formatter = DateTimeFormatter.ofPattern(\"HH:mm:ss\")\n    val formattedTime = currentTime.format(formatter)\n    println(\"현재 시간은: $formattedTime\")\n}\n\nrepeatInterval(currentTime, 1000)\n```\n\n\n\n## 함수를 인수로 전달할 수 있어요 🔀\n\n가장 흔한 사용 사례는 악명 높은 콜백 함수입니다. 예를 들어,\n\n```js\n// count complete callback\nval countCompleteCallback : () -> Unit = {\n    println(\"카운팅이 완료되었습니다!\")\n}\n\n// 콜백을 인수로 전달\nfun count10(callback:() -> Unit){\n    (1..10).toList().joinToString().also(::println)\n    callback.invoke()\n}\n\n// 트리거\ncount10(countCompleteCallback)\n\n// 결과\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10\n카운팅이 완료되었습니다!\n```\n\n하지만 우리가 가장 흔히 하는 일은 무엇인지 되돌아보자\n\n\n\n```js\n(1..10).map { it -> it * it }.also(::println)\n```\n\n여기서 map 함수는 구문 설탕을 추가하고 있지만 실제 코드는 다음과 같습니다.\n\n```js\n(1..10).map ({ it -> it * it }).also(::println)\n\n// 또는 \n\nval double = { it -> it * it }\n(1..10).map(double).also(::println)\n```\n\n맵 작업에서는 함수를 매개변수로 전달하고 있습니다. 이 방식은 모듈화되어 있고 집중적이어서 좋은 접근 방식입니다.\n\n\n\n## 다른 함수에서 함수를 반환할 수 있어요 🔙\n\n이것은 많은 사람들에게 이해하기 어려운 내용이지만, 이것을 기반으로 한 가장 유용한 팩토리 함수가 있어요. 예시를 보겠습니다:\n\n```js\nenum class Language {\n    ENGLISH,\n    FRENCH,\n    HINDI\n}\n\nfun greet(language: Language, name: String) {\n    val greetings = when (language) {\n        Language.ENGLISH -> \"Hello, $name!\"\n        Language.FRENCH -> \"Bonjour, $name!\"\n        Language.HINDI -> \"नमस्ते, $name!\"\n    }\n    println(greetings)\n}\n\ngreet(Language.HINDI, \"Chetan\") // नमस्ते, Chetan!\ngreet(Language.ENGLISH, \"Chetan\") // Hello, Chetan!\ngreet(Language.FRENCH, \"Chetan\") // Bonjour, Chetan!\n```\n\n이 프로그램은 언어와 이름을 인수로 사용하여 인사말을 출력합니다. 또는 이렇게도 할 수 있어요:\n\n\n\n```js\nenum class Language {\n    ENGLISH,\n    FRENCH,\n    HINDI\n}\n\nfun greetFactory(language: Language): (String) -> Unit {\n    // function within function\n    val greetTo = { name: String ->\n        val greetings = when(language){\n            Language.ENGLISH -> \"Hello, $name!\"\n            Language.FRENCH -> \"Bonjour, $name!\"\n            Language.HINDI -> \"नमस्ते, $name!\"\n        }\n        println(greetings)\n    }\n\n    // returning function\n    return greetTo\n}\n\n// mini function factories which are reusable\nval englishGreeting = greetFactory(Language.ENGLISH)\nval frenchGreeting = greetFactory(Language.FRENCH)\nval hindiGreeting = greetFactory(Language.HINDI)\n\n// use them separately \nhindiGreeting(\"Chetan\") // नमस्ते, Chetan!\nenglishGreeting(\"Chetan\") // Hello, Chetan!\nfrenchGreeting(\"Chetan\") // Bonjour, Chetan!\n```\n\n추후에 좋아하는 경우에 우리가 다양한 함수 조합 방법을 알고 있다는 것을 걱정하지 마십시오.\n\n## 커링 함수: 부분 실행 🥘\n\n커링 함수 또는 부분 실행 함수는 함수를 반환하는 함수의 부작용입니다. 이를 사용하여 함수의 일부분만 실행할 수 있지만 모두 실행하는 것은 아닙니다. 한 예를 살펴보겠습니다 :\n\n\n\n```kotlin\n// 두 숫자를 더하는 커링된 함수를 정의했습니다\nfun curriedAdd(firstNumber: Int): (Int) -> Int {\n    val sumWith = { secondNumber: Int ->\n        val sum = firstNumber + secondNumber\n        sum\n    }\n    return sumWith\n}\n\n// 커링을 사용하여 부분적으로 적용된 함수를 생성합니다\nval partialResult = curriedAdd(2) // 이 함수는 첫 번째 인수를 2로 고정합니다\n\n// 이제 addTwo는 인수에 2를 더하는 함수입니다\nval result1 = partialResult(3) \nval result2 = partialResult(10) \n\nprintln(\"Result1: $result1\") // 결과: 2 + 3 = 5\nprintln(\"Result2: $result2\") // 결과: 2 + 10 = 12\n```\n\n여기서 `curriedAdd` 함수는 값 2로 부분 실행되며, 3이 전달될 때 완전 실행되어 결과를 반환합니다. 계산된 값들을 매개변수로 사용하는 경우 뒤에 계산을 완료한 값을로드할 수 있어 매우 편리합니다.\n\n## 클로저 👯\n\n클로저는 외부 함수 범위에 있는 변수에 접근할 수 있도록 내부 함수를 통해 제공합니다. 아래 예제를 참조하세요:\n\n\n\n\n```js\nfun countWithClosure(): () -> Unit {\n    var counter = 0 // 외부 스코프에서 정의된 변수\n    val innerFunction = {\n        counter++ // 외부 스코프의 변수에 접근 및 수정\n        println(\"Counter: $counter\")\n    }\n    return innerFunction\n}\n\nval increment = countWithClosure()\n\nincrement() // 출력: Counter: 1\nincrement() // 출력: Counter: 2\nincrement() // 출력: Counter: 3\n```\n\n기본적으로 두 개의 함수인 외부 함수와 내부 함수가 역할에 관여하며, 내부 함수는 외부 함수 스코프에 접근할 수 있으며 내부 함수 스코프를 사용하여 외부 스코프의 값을 변경할 수 있습니다.\n\nReact에서 매우 인기 있는 기능으로 사용자 정의 후크를 만드는 데 사용되며, Kotlin에서 Jetpack Compose에서도 사용할 수 있습니다.\n\n```js\nval leakyClosure: () -> Unit = {\n    // 여기서 컨텍스트나 다른 Composable에 액세스하면 메모리 누수가 발생할 수 있습니다.\n}\n```\n\n\n\n## 함수는 데이터 구조에 저장될 수 있어요 💾\n\n함수를 컬렉션/데이터 구조에 저장할 수 있어요:\n\n```js\nfun greet() {println(\"hello world!\")}\nfun farewell() {println(\"bye bye world!\")}\n\nval functions : List<()->Unit> = listOf(::greet, ::farewell)\n\n// 리스트를 반복하며 각 함수를 호출해요\nfunctions.onEach { it.invoke() }\n\n// 결과\nhello world!\nbye bye world!\n```\n\n런타임에서 코드 동작을 조작할 수 있어요. 저는 지난 회사에서 실시간 매개 변수 값을 가져와 서버에 기록하기 위해 분석을 구축하는 데 사용했어요. 예를 들어:\n\n\n\n```kotlin\nfun logOnUserClicked () : Map<String,Any> { \n  ...\n  return mapOf(\n    \"이메일\" to datastore.userEmail,\n    \"안드로이드 버전\" to BuildConfig.Version\n  )\n}\n\nfun logOnBackPress () : Map<String,Any> { ...}\n\nval events : List<()->Unit> = listOf(::logOnUserClicked, ::logOnBackPress)\n\nevents.forEach { event ->\n  loggingSdk.log(event())\n}\n```\n\n만약 지금 분석 시스템을 설계하는 방법에 대한 자세한 가이드가 필요하다면, 기사에 댓글을 달아주세요. 다음에 그에 맞는 내용을 만들어 보겠습니다.\n\n함수를 객체에 저장할 수도 있습니다. 예를들어:\n\n```kotlin\ndata class Calculator(\n    val addition: (Int, Int) -> Int = { num1, num2 -> num1 + num2 },\n    val subtraction: (Int, Int) -> Int = { num1, num2 -> num1 - num2 },\n    val multiplication: (Int, Int) -> Int = { num1, num2 -> num1 * num2 },\n)\n\nval calculator = Calculator()\n\nval result1 = calculator.addition(5, 3) // 결과: 8\nval result2 = calculator.subtraction(10, 4) // 결과: 6\nval result3 = calculator.multiplication(6, 2) // 결과: 12\n```\n\n\n\n객체 내에 함수를 저장하면 코드 구조를 더 잘 정의하고 강력하고 다재다능한 프로그래밍 기술을 구현할 수 있습니다.\n\n## 익명 함수 🕵🏽‍♂️\n\n일시적이거나 일회성 함수에 매우 유용합니다. 이름을 부여하지 않은 함수들이기 때문에 당연히 인라인 함수라고도 불립니다 — 그렇지 않았다면 왜 익명인지요?\n\n이미 알고 계신 예시:\n\n\n\n```js\n(1..10).map { it -> it * it }.also(::println) // 결과: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n(1..10).filter { it -> it % 2 == 0 }.also(::println) // 결과: [2, 4, 6, 8, 10]\n```\n\n여기까지입니다. 읽어주셔서 감사합니다!\n\n## - 삶 속에서의 업데이트 -\n\n안녕하세요 👋! 저는 코틀린과 안드로이드 개발에서 7년 이상의 실무 경험을 보유하고 있습니다. 새로운 흥미로운 기회를 찾고 있습니다! 제 포트폴리오와 GitHub 기여를 살펴보시고, 회사에서 경험 많은 안드로이드 개발자가 필요하다면 chetan.garg36@gmail.com으로 연락해주세요. 또한 WhatsApp 번호 +91 8368928213로 연락하거나 LinkedIn에서 저와 연결할 수도 있습니다. 제 전문성을 귀하의 팀에 어떻게 가져다줄 수 있는지 이야기해 보겠습니다!","ogImage":{"url":"/assets/img/2024-05-15-KotlinFunctionsasFirstClassCitizens_0.png"},"coverImage":"/assets/img/2024-05-15-KotlinFunctionsasFirstClassCitizens_0.png","tag":["Tech"],"readingTime":8},{"title":"자바스크립트에서의 Call, Apply 및 Bind 함수들 - 깊게 들어가보기","description":"","date":"2024-05-15 10:12","slug":"2024-05-15-CallApplyandBindFunctionsinJavascriptDeepDive","content":"\n\n이 게시물에서는 JavaScript에서 호출, 적용 및 바인드 함수의 개념을 더 깊게 탐구하여 혼란을 해소하기 위해 노력할 것입니다. 우리는 이러한 함수를 포괄적인 예제를 통해 탐구하여 명확한 이해를 제공할 것입니다.\n\n# 차이점\n\n- call()은 지정된 this 값과 개별 인수로 함수를 호출합니다.\n- apply()은 배열로 제공된 인수와 함께 지정된 this 값으로 함수를 호출합니다. 이것은 전달된 인수를 제외하고는 call() 함수와 유사합니다.\n- bind()는 지정된 this 값과 초기 인수를 가진 새로운 함수를 반환하여 나중에 호출할 수 있도록 합니다.\n\nJavaScript의 세 가지 함수 각각에 대해 더 자세히 살펴보고 JavaScript의 미묘한 차이를 경험하여 더 나은 이해를 얻어봅시다.\n\n\n\n# 더 깊게 파보기\n\n실제 시나리오에서 두 명의 개인, person1과 person2를 고려해보겠습니다. 각각 JavaScript 객체로 표현되며 이름과 나이와 같은 속성을 갖습니다. introduce() 함수를 사용하면 call() 메서드를 사용하여 각 객체 컨텍스트로 함수를 호출하여 개인 속성을 기반으로 한 개인화된 소개를 할 수 있습니다.\n\n```js\n// person1 객체 정의\nconst person1 = {\n    name: '히만슈',\n    age: 25\n};\n\n// person2 객체 정의\nconst person2 = {\n    name: '알록',\n    age: 35\n};\n\n// 소개 함수\nfunction introduce(state, city) {\n    console.log(`안녕, 나는 ${this.name}이고, ${this.age}살이야. ${state}, ${city}에 사는 중이야`);\n}\n\n// person1 소개\nintroduce.call(person1, '서벵갈', '콜카타');\n\n// person2 소개\nintroduce.call(person2, '자르크핸드', '란치');\n```\n\n이 예제에서:\n\n\n\n- 서로 다른 이름과 나이를 가진 두 person 객체인 person1과 person2를 정의합니다.\n- this 컨텍스트의 속성을 사용하여 메시지를 출력하는 introduce() 함수가 있습니다.\n- call()을 사용하여 각 person 객체를 this 컨텍스트로 사용하여 introduce() 함수를 호출합니다. 이를 통해 각 person을 적절한 이름과 나이로 개별적으로 소개할 수 있습니다.\n\nperson1과 person2의 같은 시나리오를 살펴봅시다\n\n```js\n// Define person1 object\nconst person1 = {\n    name: 'Himanshu',\n    age: 25\n};\n\n// Define person2 object\nconst person2 = {\n    name: 'Alok',\n    age: 35\n};\n\n// Introduce function\nfunction introduce(state, city) {\n    console.log(`Hi, I'm ${this.name} and I'm ${this.age} years old. I live in ${state}, ${city}`);\n}\n\n// Introduce person1\nintroduce.apply(person1, ['West Bengal', 'Kolkata']);\n\n// Introduce person2\nintroduce.apply(person2, ['Jharkhand', 'Ranchi']);\n```\n\n이 예시에서:\n\n\n\n- 동일한 person1, person2 객체를 사용하여 함수를 소개합니다.\n- person1과 person2 객체 컨텍스트 및 상태와 도시를 포함하는 인수 배열을 전달하여 각 사람을 개별적으로 소개하기 위해 apply()를 사용합니다.\n\n참고: call과 apply에서 어떻게 인수가 전달되는지 살펴보세요. 이 두 가지 사이에 차이가 있습니다.\n\n```js\n// person1 객체 정의\nconst person1 = {\n    name: '히만수',\n    age: 25\n};\n\n// person2 객체 정의\nconst person2 = {\n    name: '알록',\n    age: 35\n};\n\n// 소개 함수\nfunction introduce(state, city) {\n    console.log(`안녕, 저는 ${this.name}이고 ${this.age}살 입니다. 저는 ${state}, ${city}에 살고 있어요.`);\n}\n\n// introduce 함수를 person1에 바인딩\nconst introducePerson1 = introduce.bind(person1, '서부 벵갈', '콜카타');\n\n// introduce 함수를 person2에 바인딩\nconst introducePerson2 = introduce.bind(person2, '자르크핸드', '란치');\n\n// person1 소개\nintroducePerson1();\n\n// person2 소개\nintroducePerson2();\n```\n\n이 예시에서:\n\n\n\n- 동일한 person1과 person2 객체를 사용하고 함수를 소개했습니다.\n- bind()를 사용하여 this를 각각 person1과 person2에 영구적으로 바인딩하고 state 및 city 인수를 미리 지정한 introducePerson1 및 introducePerson2 새 함수를 만듭니다.\n- 그런 다음 introducePerson1() 및 introducePerson2()를 호출하여 각 인물을 해당하는 state 및 city와 함께 소개하여 나중에 미리 지정된 컨텍스트와 인수로 이러한 소개를 나중에 호출할 수 있는 능력을 보여주었습니다.\n\n# bind()에 대해 더 알아보기\n\n더 깊이 이해하고 흥미를 느낄 수 있는 몇 가지 고급 예제로 bind()를 자세히 살펴보겠습니다.\n\n```js\nconst person = {\n  age: 42,\n  getDetails: function() {\n    return this.age;\n  }\n};\n\nconst unboundGetDetails = person.getDetails;\nconsole.log(unboundGetDetails()); // 함수는 window 객체인 전역 범위에서 호출됩니다.\n// 예상 출력: undefined\n```\n\n\n\n여기서 explicit context없이 unboundGetDetails()가 호출됩니다. 결과적으로 getDetails 함수 내에서 this는 기본적으로 전역 객체(window)를 참조합니다. 전역 객체에 age가 정의되어 있지 않기 때문에, this.age는 undefined로 평가되어 결과가 undefined로 표시됩니다.\n\n이를 해결하고 getDetails 함수 내에서 this가 person 객체를 참조하도록 하려면 bind() 메소드를 사용합니다:\n\n```js\nconst boundGetDetails = unboundGetDetails.bind(person);\nconsole.log(boundGetDetails());\n// 예상 출력: 42\n```\n\n# 팁:\n\n\n\n만약 person.getDetails()가 42를 반환하고 unboundGetDetails()가 정의되지 않았다는 이유에 대해 궁금해하고 있다면, 혼란을 해소해보겠습니다.\n\n제공된 코드 스니펫에서 person.getDetails()와 unboundGetDetails() 간의 출력 차이는 this 키워드가 처리되는 방식 때문입니다.\n\n1. person.getDetails():\n\n여기서 getDetails() 메소드는 person 객체에 직접 호출됩니다. 메소드가 점 표기법 (object.method())을 사용하여 호출될 때, 마침표 왼쪽의 객체가 메소드 내에서 컨텍스트(this)로 설정됩니다. 따라서 getDetails() 내부의 this.age는 person.age를 가리키며, 이 값은 42입니다.\n\n\n\n2. unboundGetDetails():\n\n이 경우 getDetails() 메서드는 어떤 컨텍스트 없이 unboundGetDetails 변수에 할당됩니다. 이와 같이 메서드가 변수에 할당되면 해당 메서드는 원래의 컨텍스트를 잃게 됩니다. 따라서 unboundGetDetails()가 호출될 때 getDetails() 내부의 this.age는 더 이상 person.age를 참조하지 않습니다. 대신에 전역 객체 (또는 엄격 모드에서는 정의되지 않음)로 기본 설정되어 age가 정의되지 않은 곳으로 인식됩니다. 따라서 출력은 undefined가 됩니다.\n\n읽어 주셔서 감사합니다! 본 게시물이 도움이 되었다면 다른 사람들과 함께 공유해 주세요. 더 유익한 콘텐츠를 기대해 주세요!","ogImage":{"url":"/assets/img/2024-05-15-CallApplyandBindFunctionsinJavascriptDeepDive_0.png"},"coverImage":"/assets/img/2024-05-15-CallApplyandBindFunctionsinJavascriptDeepDive_0.png","tag":["Tech"],"readingTime":5},{"title":"파이썬 초보자를 위한 안내 프로처럼 설정하기","description":"","date":"2024-05-15 10:10","slug":"2024-05-15-ABeginnersGuidetoPythonGettingSetUpLikeAPro","content":"\n\n이것은 '파이썬 초보자를 위한 가이드' 시리즈의 첫 번째 기사로, 여러분의 파이썬 여행을 시작하는 데 도움이 될 것입니다.\n\n그래서 여러분은 열정 넘치게 코딩을 시작하려고 합니다, 하지만 어디서부터 시작해야 할 지 모르겠죠?\n\n![Python 설치](/assets/img/2024-05-15-ABeginnersGuidetoPythonGettingSetUpLikeAPro_0.png)\n\n# 1. 파이썬 설치\n\n\n\n먼저, 프로그래밍 언어 자체인 Python을 다운로드하고 설치해야 합니다.\n\n이 작업이 필요한 이유는 무엇일까요? 여러분이 기기 설정을 변경하여 현재 기기를 스페인어로 작동하도록 설정했다고 상상해보세요. 대부분의 기기는 여러 언어 옵션을 미리 설치하여 손쉽게 변경할 수 있지만, 스와힐리어로 바꾸고 싶다면 어떻게 해야 할까요? 이 설정이 쉽게 사용 가능하지 않을 수도 있지만, 언어 팩을 다운로드하고 설치함으로써 여전히 기기를 스와힐리어로 실행할 수 있습니다. Python을 다운로드하는 것도 같은 방식으로 작동합니다. Python 코드를 이해하고 실행할 수 있도록 기기를 활성화합니다.\n\nmacOS 및 Linux 시스템에는 Python이 미리 설치되어 있을 수도 있지만, 가장 최신 버전이 아닐 수도 있습니다.\n\n# 2. 코드 편집기 또는 통합 개발 환경 설치\n\n\n\n다음으로는 코드 편집기 또는 통합 개발 환경(IDE)이 필요합니다. 이 소프트웨어는 코드를 작성하고 편집할 작업 공간을 제공합니다. 인기 있는 옵션으로는 Visual Studio Code (VS Code), PyCharm, Jupyter Notebook 등이 있습니다.\n\n이미 혼란스러우신가요? 저도 그랬어요. 파이썬이 이미 설치되어 있는데 또 다른 도구가 필요한 이유가 뭘까요? 익숙한 비유를 통해 이해하는 것은 쉽습니다. 스와힐리어 언어 팩이 장치에 새로운 언어를 해석할 수 있게 해 주는 것처럼, Word, 메모장, Google 문서와 같은 애플리케이션은 실제로 텍스트를 작성하고 편집할 수 있는 작업 공간 역할을 합니다. 텍스트를 작성하기 위한 다양한 텍스트 편집기가 있는 것처럼, 코드를 작성할 수 있는 여러 옵션이 있습니다.\n\n이를 한 발짝 더 나아가면, 메모장을 Word나 Google 문서의 가벼운 대응체로 생각해볼 수 있습니다. 모두 동일한 기본 기능을 제공하지만 Word나 Google 문서는 서식 설정, 맞춤법 검사, 협업 편집과 같은 추가 기능을 제공합니다. 마찬가지로, 코드 편집기는 IDE의 가벼운 대응체입니다. 둘 다 코드를 읽고, 쓰고, 실행할 수 있지만, IDE는 전체 소프트웨어 개발 수명주기를 위한 고급 기능과 포괄적인 도구 세트를 제공합니다. 그래서, 어떤 것을 선택해야 할까요?\n\n답은 대부분 중요하지 않습니다.\n\n\n\n마찬가지로 워드와 구글 문서로 동일한 텍스트 블록을 작성할 수 있는 것처럼, VS Code 또는 PyCharm으로도 동일한 코드 블록을 작성할 수 있습니다. 궁극적으로는 각 도구에 대한 익숙함과 능숙함이 생산성을 결정할 것입니다. 그러나 산업 표준을 선택하는 것에는 이점이 있습니다. 온라인이나 동료로부터 도움을 받기 쉽고, 고용주들도 선호할 수 있습니다. VS Code는 일반적으로 산업 내에서 인기가 많으며, 데이터 과학과 머신 러닝 분야에서 인기 있는 Jupyter Notebook도 있습니다.\n\n당신이 찾던 단호한 대답은 아니죠? 제가 동의합니다.\n\nJupyter Notebook부터 시작해보세요; 학습 곡선이 그리 가파르지 않습니다. Python에 빠르게 익숙해지는 것이 목표라면, 이 방법이 더 빠르게 달성할 수 있을 겁니다.\n\n\n# 3. 가상 환경 설정\n\n\n\n\n이 부분은 코딩을 시작하기에 필수적이지는 않아요. 그러나 이점을 따르는 것이 좋은 습관을 형성하는 데 도움이 될 거예요. 이를 염두에 두고, 먼저 '가상 환경'이 무엇인지에 대해 이야기해볼게요.\n\n가상 환경은 Python에서 프로젝트 간의 의존성을 분리하는 방식입니다.\n\n걱정 마세요. 아직이 개념을 이해하지 못할 것으로 기대하지는 않아요. 대신 예를 들어 설명해 드릴게요. 예를 들어 PyGame 라이브러리를 사용하여 새 게임을 개발하려고 한다고 상상해 보세요. 가장 최신 버전인 PyGame 1.7.10을 설치하고 'Pixelator'를 개발하는 데 1년을 보내게 됩니다.\n\nPixelator가 대성공을 거두어 투자자들이 이제 'Pixelator II'에 참여해 달라고 요청합니다. 그때에는 PyGame의 새로운 버전, PyGame 2.1.0이 출시되었다는 사실을 알게 되지만 이번에 추가된 많은 새로운 기능을 사용해 보고 싶어할 거예요. 최신 버전을 다운로드하고 설치한 후, 열심히 작업한 끝에 Pixelator II를 출시할 준비가 되는 거죠.\n\n\n\n하지만 기다려봐요. 이제 특별판 릴리스를 위해 원래 Pixelator를 조정해야 합니다. PyGame 1.7.10을 2.1.0으로 업그레이드하는 과정에서 원래 게임을 실수로 망가뜨렸다는 것을 깨달았습니다. 1.7.10에서 사용한 일부 기능이 폐기되었을 수도 있고, PyGame의 이전 버전과 함께 작동했던 다른 패키지가 새 버전과 함께 작동하도록 업데이트되지 않았을 수도 있습니다. 그럼 어떻게 해야 할까요? Pixelator II가 망가지지 않도록 PyGame의 이전 버전으로 다운그레이드할 수는 없습니다. 이것은 의존성 악몽에 빠진 상황입니다.\n\n이것이 가상 환경이 해결해주는 정확한 문제입니다.\n\nPixelator를 위한 가상 환경(에 PyGame 1.7.10 설치)과 Pixelator II를 위한 다른 가상 환경(에 PyGame 2.1.0 설치)을 만들면 이제 의존성 충돌 없이 두 프로젝트에 모두 작업할 수 있습니다.\n\n각 가상 환경은 해당 가상 환경에 설치된 Python 버전(예: Python 3.12.3)과 라이브러리를 저장하는 폴더로 작동합니다. 이를 통해 컴퓨터에 다른 Python 버전을 실행하고 동일한 라이브러리의 다른 버전을 설치할 수 있게 됩니다. 협업하고 싶으세요? 문제 없어요. 가상 환경은 쉽게 내보내고 공유할 수 있어서 코드가 모든 컴퓨터에서 작동하도록 보장합니다.\n\n\n\n요약하면, 가상 환경은 다음을 제공합니다:\n\n- 의존성 격리: 가상 환경은 프로젝트 의존성을 격리시켜 서로 다른 프로젝트가 동일한 라이브러리의 다른 버전을 요구할 때 충돌을 방지합니다.\n- 이식성: 가상 환경은 쉽게 공유하고 다른 기계에 복제할 수 있으며 일관된 개발 환경을 유지합니다.\n\n그 결론은? 각 프로젝트마다 새로운 가상 환경을 만드세요. 이렇게 하면 필요에 따라 쉽게 환경을 전환할 수 있습니다.\n\n그리고 여기까지입니다. Python을 다운로드하세요. Jupyter Notebook을 설치하세요. 가상 환경을 설정하세요. 이제 첫 번째 Python 프로그램을 작성할 준비가 모두 끝났습니다!\n\n\n\n만약 읽은 내용이 마음에 들었다면, 다음 시리즈 \"제로베이스부터 파이썬 배우기\"도 기대해주세요.\n\n# 읽어 주셔서 감사합니다\n\n설정하는 데 문제가 있으신가요? 댓글에서 도와드릴게요!","ogImage":{"url":"/assets/img/2024-05-15-ABeginnersGuidetoPythonGettingSetUpLikeAPro_0.png"},"coverImage":"/assets/img/2024-05-15-ABeginnersGuidetoPythonGettingSetUpLikeAPro_0.png","tag":["Tech"],"readingTime":4}],"page":"93","totalPageCount":151,"totalPageGroupCount":8,"lastPageGroup":20,"currentPageGroup":4},"__N_SSG":true}