{"pageProps":{"posts":[{"title":"잠금된 유동성 스테이킹","description":"","date":"2024-05-15 10:48","slug":"2024-05-15-LockedliquidityStaking","content":"\n\n\n![Locked Liquidity Staking](/assets/img/2024-05-15-LockedliquidityStaking_0.png)\n\n## 소개:\n\n토큰이 소각되거나 스테이킹되면 가격이 대부분 상승합니다. 문제는 USTC 홀더들이 토큰을 소각하도록 어떻게 인센티브를 제공할지입니다. 아마도 소각의 명백하고 돌이킬 수 없는 특성을 없애면서도 생태계 전반에 이익을 주는 대안 솔루션을 찾아야 할 것입니다. LUNC와 USTC가 커뮤니티 토큰이라면, 우리는 모두가 성공할 수 있도록 공동으로 행동할 수 있는 기회가 있습니다.\n\n# 잠긴 유동성 스테이킹:\n\n\n\n\nUSTC를 위탁/잠그면 순환 공급에서 제외됩니다. USTC 토큰은 가격이 설정된 페그보다 높을 때만 점차 잠금이 해제됩니다. 먼저 USTC를 위탁하시면 페그를 초과할 때 잠금이 해제된 다음 홀딩이 방출됩니다. 거래는 처음부터 순서대로 점진적으로 처리되므로 처음으로 위탁한 사람이 자동화된 프로세스에서 처음으로 잠금 해제됩니다. 여기서는 1달러의 예시를 들겠습니다. 가격이 1달러 이상으로 올라간다면, 먼저 USTC를 위탁한 사람이 자신의 잠금 홀딩이 페그를 안정화하고 1달러 가격을 유지하기 위해 점진적으로 방출/처리되는 첫 번째 대상이 됩니다. 가격이 1달러 이상으로 올라가면, USTC는 소액 이익을 위해 자동으로 잠금 해제되어 달러 가격을 다시 내리는 노력을 합니다. 자산을 잠그면 가격이 올라가는데, 페그를 넘으면 USTC가 해제되어 다음으로 USTC를 받을 대상에게 할당됩니다. 사용자들이 자산을 위탁/잠그도록 독려하기 위해, 위탁자들은 오라클 보상 풀에서 USTC로 보상받게 되며 이는 언제든지 사용 가능합니다. 이 노력을 통해 순환 공급을 낮추는 사람에게 보상이 주어지며, 보상/연간 이자율은 USTC가 페그 아래일 때 위탁하고 잠그도록 사용자들을 독려하는 방향으로 조정됩니다.\n\n다른 커뮤니티 회원의 제안에 따라 프로토콜을 보완하기 위해, 해제될 때 일부 USTC의 비율에 대한 소각이 설정됩니다. 하지만 이는 얻을 수 있는 이익에 기반합니다. 예를 들어, 페그가 1달러이고 가격이 1.20달러로 올라간 경우, 20%의 이익 중 10% 비율로 설정된 0.02달러가 소각됩니다. 이 투자자는 CEX 또는 DEX에서 판매하면 0.18달러의 이익을 얻게 됩니다. 상황에 따라 출금 지수를 더 높일 수도 있습니다.\n\n균형은 중요하며 유동성을 잠그는 것이 자산 가격을 안정시키는 데 도움이 될 수 있습니다. 토큰에 대한 신뢰가 높아진다면, 우리 생태계로 새로운 유동성이 들어오면 빠르게 새로운 수준을 달성할 수 있습니다. 훌륭한 커뮤니티 노력으로 USTC는 궁극적으로 유틸리티, 지위 및 신뢰를 되찾을 수 있습니다.\n\n\n\n\n![이미지](/assets/img/2024-05-15-LockedliquidityStaking_2.png)\n\n# USTC Staking 활성화:\n\nUSTC 스테이킹은 프로토콜의 주요 구성 요소 중 하나이므로 구현해야 합니다. 오라클 풀 내의 USTC는 USTC 스테이커들에게 전용되어야 하므로 USTC 스테이킹은 USTC 스테이커들에게만 USTC 보상을 제공할 것입니다. 따라서 USTC는 더 이상 Lunc 스테이커들에게 보상으로 제공되지 않을 것입니다. 이것은 일시적인 조치로 USTC를 재고정하기 위한 노력입니다.\n\n![이미지](/assets/img/2024-05-15-LockedliquidityStaking_3.png)\n\n\n\n\n이것은 초안임을 안내드립니다. 모든 것이 여전히 변동 사항이 많습니다. 이 제안서와 다음 부분은 커뮤니티에서 논의되어야 합니다.\n\n## 조기 언스테이킹을 허용하는 옵션:\n\n이겪에 대해 여전히 논의 중이지만, 락인된 USTC를 비정상적으로 언스테이킹할 수 있는 방법을 고려해왔습니다. 예를 들어, 스테이커들이 자동 언스테이킹 이전에 원한다면 언스테이킹할 수 있는 옵션을 제공할 수 있습니다. 그러나 이 경우 비용이 발생합니다. 이를 위해 20%의 세금이 부과됩니다. 10%는 소각되며, 10%는 오라클 보상 풀에 할당됩니다. 나머지 80%는 21일 후에 언스테이킹됩니다. 소각 및 오라클 보상 풀의 보충은 가격과 스테이킹 보상에 긍정적인 영향을 미칠 수 있습니다.\n\n## 프로토콜이 성공하지 못할 경우:\n\n\n\n현재 상태로 다시 돌아갑니다.\n\n모든 스테이크된 Ustc는 언스테이크되며 보유자들이 자산을 회수합니다.","ogImage":{"url":"/assets/img/2024-05-15-LockedliquidityStaking_0.png"},"coverImage":"/assets/img/2024-05-15-LockedliquidityStaking_0.png","tag":["Tech"],"readingTime":3},{"title":"코틀린에서의 DRY 원칙 코드 품질과 유지보수성 향상","description":"","date":"2024-05-15 10:46","slug":"2024-05-15-TheDRYPrincipleinKotlinEnhancingCodeQualityandMaintainability","content":"\n\n![image](/assets/img/2024-05-15-TheDRYPrincipleinKotlinEnhancingCodeQualityandMaintainability_0.png)\n\nDRY(반복하지 말 것) 원칙은 코드 중복을 피하고 코드 재사용을 촉진하는 소프트웨어 개발의 기본 개념입니다. 이 원칙은 시스템 내의 모든 지식 요소가 단일하고 명확한 표현을 가져야 한다고 주장합니다. 간단히 말하면, 동일한 논리 또는 정보가 코드베이스의 여러 위치에 중복되어 나타나지 않아야 한다는 것을 의미합니다.\n\nDRY 원칙은 공통 기능을 함수, 클래스 또는 모듈과 같은 재사용 가능한 구성 요소로 추상화하는 것을 개발자에게 권장합니다. 이렇게 함으로써, 개발자는 변경이나 업데이트를 한 곳에서만 수행하면 되므로 유지보수가 쉬운 코드를 작성할 수 있습니다. 이는 일관성과 오류 발생 가능성을 감소시키면서 코드의 가독성과 이해도를 향상시킵니다.\n\nDRY 원칙을 준수하면 모듈성, 캡슐화, 추상화와 같은 더 나은 소프트웨어 디자인 관행을 촉진합니다. 이는 유지보수와 확장, 디버그 및 협업이 쉬운 더 깔끔하고 관리하기 쉬운 코드베이스를 만드는 데 도움이 됩니다.\n\n\n\n## DRY 원칙이 필요한 이유는 무엇인가요?\n\n- 코드 유지보수성: 코드 중복은 유지보수 부담을 증가시킵니다. 동일한 코드 논리가 여러 곳에 복사되면 해당 논리를 수정하거나 업데이트해야 하는 경우 여러 위치에서 변경이 필요하며, 일관성 및 오류 발생 위험이 증가합니다. Kotlin에서 DRY 원칙을 준수하면 변경 사항을 하나의 위치에서만 수행해야 하므로 코드 유지보수가 더 쉬워집니다.\n- 버그와 오류 감소: 중복된 코드는 버그와 오류 발생 가능성을 증가시킵니다. 중복된 코드의 한 부분에서 버그가 수정되지만 다른 곳에서는 수정되지 않으면 일관성 문제가 발생하여 예기치 않은 동작을 야기할 수 있습니다. Kotlin 코드에서 DRY 원칙을 준수하면 코드 논리를 중앙 집중화하여 일관성 문제로 인한 버그 발생 가능성을 최소화합니다.\n- 가독성 및 이해도 향상: 중복된 코드는 코드의 가독성과 이해도를 저해합니다. 동일한 논리가 코드베이스 전체에 흩어져 있으면 시스템의 전반적인 기능과 목적을 파악하기가 어려워집니다. DRY 원칙을 따르고 논리를 통합함으로써 Kotlin 코드를 더 읽기 쉽고 이해하기 쉽게 만듭니다.\n- 모듈성과 재사용성 촉진: DRY 원칙을 준수하면 모듈화되고 재사용 가능한 구성 요소를 생성하는 것을 촉진합니다. 동일한 논리를 여러 곳에 반복하는 대신 Kotlin 개발자들은 공통 기능을 별도의 모듈, 함수 또는 클래스로 추출하도록 권장받습니다. 이는 구성 요소가 코드베이스 전반에서 재사용될 수 있는 모듈화 아키텍처를 촉진합니다.\n\n## Kotlin에서 DRY 원칙 적용 예:\n\n1. 공통 기능을 함수나 확장 함수로 추출하기\n\n\n\n```kotlin\n// DRY 원칙 없이: 특정 모양에 대한 함수\nfun calculateCircleArea(radius: Double): Double {\n    return Math.PI * radius * radius\n}\n\nfun calculateRectangleArea(width: Double, height: Double): Double {\n    return width * height\n}\n\n// DRY 원칙을 적용한 경우: 면적을 계산하는 일반적인 함수\nfun calculateArea(shape: Shape): Double {\n    return when (shape) {\n        is Circle -> Math.PI * shape.radius * shape.radius\n        is Rectangle -> shape.width * shape.height\n    }\n}\n```\n\n서로 다른 모양의 면적을 계산하기 위해 별도의 함수를 갖는 대신, 입력으로 Shape 객체를 받아 해당 형태의 면적을 계산하는 calculateArea라는 단일 함수를 생성합니다. 이 접근 방식은 코드 중복을 제거하고 재사용성을 증진시킵니다.\n\n2. 고차 함수 활용:\n\n```kotlin\n// DRY 원칙 없이\nfun applyOperationTwice(value: Int, operation: (Int) -> Int): Int {\n    return operation(operation(value))\n}\n\n// DRY 원칙을 적용한 경우\nfun applyOperationTwice(value: Int, operation: (Int) -> Int): Int {\n    return operation(value).let(operation)\n}\n```\n\n\n\napplyOperationTwice 함수에서는 DRY 원칙을 사용하여 let 함수를 사용하여 처음 호출 결과에 작업을 호출합니다. 이 접근법은 가독성을 향상시키고 작업이 적용되는 방식을 일관성있게 유지합니다.\n\n3. 상수 공유:\n\n```js\n// DRY 원칙 미적용: 전역으로 상수 선언\nconst val MAX_RETRIES = 3\nconst val TIMEOUT = 5000\n\n// DRY 원칙 적용: 상수를 객체에 그룹화\nobject Constants {\n    const val MAX_RETRIES = 3\n    const val TIMEOUT = 5000\n}\n```\n\n전역으로 상수를 선언하는 대신, 관련 있는 상수를 객체 내에 그룹화하여 DRY 원칙을 적용합니다. 이 접근법은 상수를 논리적으로 구성하고 네임스페이스 오염을 방지합니다.\n\n\n\n4. 재사용 가능한 데이터 구조:\n\n```js\n// DRY 원칙 없이: 각 모양에 대한 별도의 클래스\nclass Rectangle(val width: Double, val height: Double)\n\nclass Circle(val radius: Double)\n\n// DRY 원칙을 적용한 경우: 공유된 베이스 클래스와 데이터 클래스\nsealed class Shape\n\ndata class Rectangle(val width: Double, val height: Double) : Shape()\n\ndata class Circle(val radius: Double) : Shape()\n```\n\n공유된 베이스 클래스 Shape를 정의하고 이를 기반으로 Rectangle 및 Circle과 같은 특정 모양을 파생시킴으로써 DRY 원칙이 적용됩니다. 이 접근 방식은 코드 재사용을 촉진하고 모양이 어떻게 표현되는지에 일관성을 유지합니다.\n\n5. 비즈니스 로직 공유:\n\n\n\n```js\n// DRY 원칙을 적용한 예시: 공통 구현 로직을 캡슐화한 베이스 매니저 클래스\nclass BaseManager<T>(private val repository: BaseRepository<T>) {\n    fun addItem(item: T) {\n        if (repository.getItemById(item.id) == null) {\n            repository.addItem(item)\n        }\n    }\n}\n\n// UserManager과 ProductService와 같은 특정 매니저 클래스들은 BaseManager를 상속하여 이 공통 로직을 재사용하며, 코드 중복을 줄이고 일관성을 유지합니다.\n\n# DRY 사용 시 고려할 점:\n\n- 너르 도구 되기 전에: 코드 중복과 추상화 사이의 균형을 맞추는 것이 중요합니다. 때때로 일반 로직을 너무 이르게 추출하면 이해하기 어렵고 유지보수하기 어려운 지나치게 복잡한 추상화로 이어질 수 있습니다. 진정으로 재사용 가능한 경우에만 코드를 추상화해야 합니다.\n- 의미 있는 명명: 재사용 가능한 구성요소로 코드를 추출할 때, 함수, 클래스 또는 모듈에 서술적이고 의미 있는 이름을 선택해야 합니다. 명확한 명명은 다른 개발자가 코드의 의도와 목적을 이해하기 쉽도록 도와줍니다.\n- 함수 일관성 유지: 재사용 가능한 함수 또는 클래스를 작성할 때, 단일 책임을 갖고 명확한 작업을 수행하는지 확인해야 합니다. 하나의 함수 또는 클래스에 관련 없는 기능을 섞는 것은 혼란을 초래하고 단일 책임 원칙(SRP)을 위반할 수 있습니다.\n- 트레이드오프 고려: 중복을 줄이는 것은 일반적으로 유익하지만, 때로는 더 명확하고 유지보수가 쉬운 코드를 만들기 위해 약간의 중복이 허용될 수 있습니다. DRY성과 단순성 및 명료성과 같은 다른 소프트웨어 설계 원칙 간의 트레이드오프를 고려해야 합니다.\n- 문서화와 주석: 재사용 가능한 구성 요소의 목적과 사용법을 문서화하여 다른 개발자가 올바르게 사용하는 데 도움을 줄 수 있습니다. 또한 코드 내 복잡하거나 명확하지 않은 로직을 설명하는 주석을 제공해야 합니다.\n```\n\n\n\n# Stackademic 🎓\n\n끝까지 읽어주셔서 감사합니다. 떠나시기 전에:\n\n- 작가를 칭찬하고 팔로우해주시면 좋겠어요! 👏\n- 저희를 팔로우해주세요 X | 링크드인 | 유튜브 | 디스코드\n- 다른 플랫폼도 방문해보세요: In Plain English | CoFeed | Venture | Cubed\n- 알고리즘적 콘텐츠를 다루어야 하는 블로깅 플랫폼에 지쳤나요? Differ를 시도해보세요\n- Stackademic.com에서 더 많은 콘텐츠를 만나보세요","ogImage":{"url":"/assets/img/2024-05-15-TheDRYPrincipleinKotlinEnhancingCodeQualityandMaintainability_0.png"},"coverImage":"/assets/img/2024-05-15-TheDRYPrincipleinKotlinEnhancingCodeQualityandMaintainability_0.png","tag":["Tech"],"readingTime":5},{"title":"안녕하세요 HTML 안녕하세요","description":"","date":"2024-05-15 10:45","slug":"2024-05-15-ripHTMLrip","content":"\n\n## JavaScriptUI — DevBlog #2\n\n얼마 전에 미친 아이디어가 떠올랐어요: HTML 없이 웹사이트를 만들 수 있을까?\n\n아니요, 제가 말하는 것은 새로운 브라우저 엔진을 만드는 것이나 캔버스를 사용하여 콘텐츠를 표시하는 것이 아닙니다. 또한 WebAssembly나 HTML로 컴파일된 새 언어를 사용하는 것이 아닙니다. 제가 말하는 것은 오늘날 어떤 브라우저에서도 즉시 실행되는 완전히 기능적인 웹사이트를 작성하는 방법입니다. 그것도 HTML 한 줄을 작성하지 않고요.\n\n실은 가능합니다. 그리고 지금 바로 수행하기 까다롭지도 않아요. 우리는 그저 JavaScript의 DOM API를 맹공하면 되는 것 뿐입니다. 확실히 여전히 브라우저 안에서 약간의 HTML을 생성하지만 그건 당장 무시해도 되는 구현 세부사항입니다. 필요한 건 DOM 뿐이에요. 그러니 JavaScript로 생성된 웹사이트의 세계로 뛰어들어 모든 최선의 방법을 위반해 보죠.\n\n\n\n## Views 및 View 트리\n\n어떤 것을 만들기 위해서는 객체가 필요합니다. 기본 옵션은 document.createElement()을 사용하여 HTML 요소를 만들고, Element.prototype.append() 또는 Node.prototype.appendChild()를 사용하여 이후에 DOM에 추가하는 것입니다. 꽤 기본적인 방법이지만 불편하고 지저분하며 혼란스럽습니다. 더 나은 방법이 있습니다.\n\n그 대신, Image, Text 및 Stack과 같은 선언적 생성자를 정의하고 이를 Views(뷰)라고 부르겠습니다. 이들은 여전히 DOM API에 의존하지만 더 나은 선언적 구문을 제공할 수 있습니다. 예를 살펴보세요:\n\n```js\nStack(\n  Text(\"Hello World!\"),\n  Stack(\n    Text(\"Everyone has a plumbus in their home.\"),\n    Image(\"plumbus.jpeg\")\n  )\n);\n```\n\n\n\n이 점이 아름다운 이유입니다. 이는 유효한 JavaScript입니다. 우리는 단순히 일부 View 생성자를 호출하고 그들의 자식들을 인수로 제공합니다. 결국 어떤 View 트리도 우리가 사용하는 언어와는 무관하게 중첩된 목록일 뿐입니다.\n\n다른 이점은 사용자 정의 된 Views를 생성할 수 있으므로 Safari가 사용자 지정 내장 요소를 구현하기 위해 또 하나의 10년을 기다릴 필요가 없습니다. 또는 의미를 잃어버린 것에 분개하고 있다면, 적절한 HTML 요소에 매핑되는 Views를 생성할 수도 있습니다:\n\n```js\nDiv(\n  Div(\n    Div(\n      Div(),\n      Div(),\n      Div()\n    )\n  )\n);\n```\n\n## 절대 \"new(er)\" 라고 말하지 마세요\n\n\n\n새로운 키워드를 View 생성자 앞에 사용하지 않은 이유는 두 가지 있어요. 첫째, 나무들이 아주 빠르게 아주 커질 수 있기 때문에, 더 짧은 구문을 사용하면 가독성이 향상됩니다. 둘째, JavaScript에는 이미 Image나 Text와 같은 생성자들이 있어서, 이러한 이름들이 필요합니다. 다행히도, 대부분의 내장 생성자들은 new 키워드와 함께만 작동하므로, 이론적으로 자체 작성한 기능을 추가하면서도 이 기능을 유지할 수 있습니다.\n\n```js\nnew Image(width, height); // HTMLImageElement을 생성합니다 (기본 동작)\nImage(url); // Image View를 생성합니다 (JavaScriptUI)\n```\n\n## 논리의 마법\n\n이제 진정한 재미가 시작되는 부분이죠. 우리는 JavaScript에서 HTML을 그대로 따르는 것이 아니라, 그 이상의 기능을 구현할 수 있어요. 이제 우리는 진정한 프로그래밍 언어의 영역에 들어왔으니 변수, 연산자, 조건문, 반복문, 일급 함수 등을 활용하여 원하는 것을 무엇이든 만들 수 있습니다. 심지어 조건적 할당처럼 간단한 기능조차 HTML의 능력을 크게 뛰어넘는 것이죠:\n\n\n\n```js\nStack(\n  yourChoice ? Text(\"red pill\") : Text(\"blue pill\")\n);\n```\n\n이제, FizzBuzz가 일부 불행한 CSS 애호가들에게 상처를 줄 수 있다는 것을 이해했어요. 하지만 함수, 연산자, 반복문 및 조건문은 매우 간단하고 범용적이며 강력한 빌딩 블록으로, 더 나아가게 하는 데 도움이 되는 것들이에요. 간단한 콜백 함수로 다음과 같은 작업들을 수행할 수 있어요:\n\n```js\nStack(function* () {\n\n  let i = 1;\n  while (i <= 100) {\n\n    if ((i % 15) === 0) {\n      yield Text(\"FizzBuzz\");\n\n    } else if ((i % 3) === 0) {\n      yield Text(\"Fizz\");\n\n    } else if ((i % 5) === 0) {\n      yield Text(\"Buzz\");\n\n    } else {\n      yield Text(i);\n    }\n\n    i += 1;\n  }\n});\n```\n\n제너레이터 구문에 대해 걱정하지 마세요. 여기서는 함수에서 여러 값을 선언적으로 반환하기 위해 사용했어요. View 생성자에서 약간의 속임수를 사용하여 일반 함수로도 동일한 작업을 수행할 수 있지만, 이제 이 콜백이 바닐라 JavaScript에서 기대하는 것과 약간 다르게 작동한다는 점에 주의해야 해요:\n\n\n\n```js\nStack(() => {\n\n  let i = 1;\n  while (i <= 100) {\n\n    if ((i % 15) === 0) {\n      Text(\"FizzBuzz\"); // Stack에 추가\n\n    } else if ((i % 3) === 0) {\n      Text(\"Fizz\"); // Stack에 추가\n\n    } else if ((i % 5) === 0) {\n      Text(\"Buzz\"); // Stack에 추가\n\n    } else {\n      Text(i); // Stack에 추가\n    }\n\n    i += 1;\n  }\n});\n```\n\n또는 블록 없이 조건문을 사용하기를 원하신다면, 이렇게 써도 돼요:\n\n```js\nStack(() => {\n\n  let i = 1;\n  while (i <= 100) {\n\n    if (i % 15 === 0) Text(\"FizzBuzz\");\n    else if (i % 3 === 0) Text(\"Fizz\");\n    else if (i % 5 === 0) Text(\"Buzz\");\n    else Text(i);\n\n    i += 1;\n  }\n});\n```\n\n더 이상 선언적으로 할 수 있는 게 없네요.\n\n\n\n\n하지만 더 나아가면 더 나아갑니다. View 생성자는 콜백에 인수를 제공하거나 this 컨텍스트를 자체로 설정하거나 UI 구축의 여러 불편한 측면을 추상화하기 위해 반응 시스템을 구현할 수도 있습니다. 현재 가능한 것과 불가능한 것에 대한 간단한 개요입니다.\n\n```js\nStack((argument) => {\n\n  this; //상위 항목에 접근 가능\n\n  argument; //인수 작동(View 생성자 내에서 미리 정의됨)\n  \n  //myView; //뷰 참조는 작동하지 않음\n  \n  Text(\"foo\"); //일반적인 자식 추가는 작동함\n  \n  let view = Text(\"temp\"); //변수 할당은 작동하지만 새로 생성된 뷰는 자동으로 부모에 추가됨\n  \n  evaluate ? Text(\"foo\") : Text(\"bar\"); //삼항 연산자는 작동함\n  \n  if (\n      evaluate //조건문도 작동\n  ) {\n      Text(\"foo\");\n  } else {\n      Text(\"bar\");\n  }\n  \n  let i = 0;\n  while (i < 5) {\n      Text(\"foo\"); //루프 작동\n      i += 1;\n  }\n});\n```\n\n## 이것이 JavaScriptUI입니다.\n\n이것이 JavaScriptUI의 기초입니다. 내 목표는 HTML 및 CSS의 모든 기능을 직접 JavaScript로 이관하여 기본 브라우저 API 및 일반 목적 프로그래밍 언어의 방대한 기능을 활용하는 것입니다.\n\n\n\n매주 새로운 글을 게시해 여러분을 최신 정보로 업데이트하고 제 진전을 공유하려 합니다 (아무도 안 읽어준다면 제 자신을 위로하기 위한 글이겠지요 😄). 곧 여러분께 작동하는 코드 몇 줄을 보여드릴 수 있기를 희망하며, 여러분도 관심이 있으시다면 함께 즐기시길 바랍니다.\n\n그동안 제 글을 즐겨주신다면 박수쳐 주시고, 의견을 남기고 DevBlog를 관심 있는 사람들과 공유해 주세요.\n\n감사합니다! 그리고 계속해서 기대해 주세요.\n\n⬅️ 자바스크립트UI — DevBlog #1, HTML과 CSS 없이 새로운 웹 페이지","ogImage":{"url":"/assets/img/2024-05-15-ripHTMLrip_0.png"},"coverImage":"/assets/img/2024-05-15-ripHTMLrip_0.png","tag":["Tech"],"readingTime":5},{"title":"자바스크립트 UI - HTML 및 CSS 없이 새 웹을 만나보세요","description":"","date":"2024-05-15 10:44","slug":"2024-05-15-JavaScriptUIanewwebwithoutHTMLandCSS","content":"\n\n## 자바스크립트 UI — 개발 블로그 #1\n\n👋 안녕하세요, 웹 열정가 여러분!\n\n새로운 웹에 대한 개념에 대해 쓴 지 꽤 오래됐죠. 그러나 약속했던 대로, 저는 여러분을 새로운 개발 블로그에 초대하고 싶어요. 여기서는 제가 지난 6년 동안 언급해 온 것을 실제로 구축하는 여정을 문서화할 거에요.\n\n그래서 정확히 무엇일까요?\n\n\n\n웹, 특히 프론트 엔드가 점점 더 번잡해져서 웹 개발에 입문하는 많은 사람들을 두렵게 만들고 있다고 느껴요. 백 엔드 프로그래머, 그래픽 디자이너 또는 새로운 입문자들이 수많은 프레임워크, 도구, 라이브러리, 심지어 기본적인 HTML과 CSS조차 혼란스럽고 어설퍼 느껴 이를 포기하는 이야기를 많이 들었어요. 그렇다고 해서 포기하지 마세요. 제가 해결책이 있다고 믿어요.\n\n그렇다면 당신의 해결책은 뭐에요, 똑똑이?\n\n음, 그렇고 말고요.\n\n가장 좋은 해결책은 쓰레기를 처리하고 핵심 웹 언어가 어떻게 작동하는지 재설계하는 것이겠지만, 이미 얼마나 복잡하고 중요한지 알려져 있기 때문에 이를 제안하는 사람이 없을 거예요. 그래서 다음으로 좋은 방법을 선택하겠어요: 작은 JavaScript 라이브러리(원할 경우 폴리필로도 사용 가능)를 작성해서 프론트 엔드 개발이 얼마나 더 효율적일 수 있는지 보여줄 거에요. 이 라이브러리를 사용하면 누구나, 심지어 초보자도 HTML 또는 CSS 지식 없이도 웹사이트를 완전히 사용자 정의하여 구축할 수 있습니다. 또한 추가 도구, 프레임워크, 컴파일러, 트랜스파일러, 번들러 또는 어떠한 종속성도 없이 진행될 거에요. 딱 한 가지 라이브러리와 순수한 JavaScript만으로 가능합니다.\n\n\n\n매주 다른 프론트엔드 개념을 분석하고, 현재 구현의 문제점을 설명하며, 인간의 직관과 이미 잘 알려진 문제 해결을 기반으로 더 나은 해결책을 시범하는 것이 목표입니다. 제가 뭔가를 추가한다면 이미 넘치는 혼돈의 더미 위에 또 다른 추상화 층이 쌓이는 것을 피하기 위해 뭔가를 제거합니다.\n\n이 라이브러리는 이미 존재하는 많은 프론트엔드 개발자들에게 엄청난 가치를 제공할 수 있다고 생각하지만, 이를 구축하는 것 또한 방대한 작업이 될 것입니다. 제 작품에 흥미를 느끼셨다면, 박수를 보내주시고, 댓글을 달아주시고, 관심 있는 사람들과 함께 내 DevBlog를 공유해주시면 정말 고맙겠습니다.\n\n아 그리고 한 가지 더, 이것은 소개일 뿐이니까 두 번째 기사도 올려두었습니다. 이번에는 좀 더 기술적인 내용이 담겨 있습니다. 여기서 읽을 수 있습니다.\n\n감사합니다. 즐겁게 읽으시길 바랍니다.\n\n\n\nJavaScriptUI — DevBlog #2, HTML 태그 ➡️","ogImage":{"url":"/assets/img/2024-05-15-JavaScriptUIanewwebwithoutHTMLandCSS_0.png"},"coverImage":"/assets/img/2024-05-15-JavaScriptUIanewwebwithoutHTMLandCSS_0.png","tag":["Tech"],"readingTime":2},{"title":"Angular 18  새로운 주요 기능 및 개선사항TOP","description":"","date":"2024-05-15 10:42","slug":"2024-05-15-Angular18Topnewfeaturesandimprovements","content":"\n\n<img src=\"/assets/img/2024-05-15-Angular18Topnewfeaturesandimprovements_0.png\" />\n\n앵귤러 18의 릴리스 날짜가 금방 오다가 예상 데뷔일인 2024년 5월 20일에 기대감이 커지고 있습니다. 새로운 기능과 개선 사항이 무엇을 가져올지 기대되는 가운데, 앵귤러는 지속적으로 발전하여 개발자들의 요구 사항과 문제를 해결하고 각 업데이트마다 혁신, 최적화 및 개선을 제공합니다. 앵귤러 18에서 기대되는 새로운 기능들을 알아보겠습니다:\n\n# 함수를 사용한 라우트 리다이렉트\n\n앵귤러 18에서는 문자열 대신 함수를 사용하여 리디렉트를 관리할 수 있는 새로운 기능이 소개됩니다. 이 개선으로 라우팅에서 더 많은 유연성을 제공하고 새로운 가능성을 엽니다. 예를 들면:\n\n\n\n테이블 태그를 Markdown 형식으로 변경하면 다음과 같습니다.\n\n\nThe function can access an object with information about the URL, allowing for more dynamic redirection.\n\n## Default Content in ng-content\n\nDefault content is now allowed within the ng-content tag. This logical extension will enable developers to include default content directly in the tag itself:\n\n## New RedirectCommand class\n\n\n\n\n리다이렉트 명령 클래스인 RedirectCommand클래스를 도입하기 전에, Guards 및 Resolvers는 새로운 경로를 나타내는 UrlTree를 반환하여 네비게이션을 리다이렉트할 수 있었습니다. 그러나 이 방법은 NavigationExtras를 사용한 네비게이션 리다이렉션을 허용하지 않습니다. 예를 들어:\n\n이 문제를 해결하기 위해 Angular 18에서는 가드 및 리졸버에서 네비게이션 리다이렉션을 처리하는 NavigationExtras를 허용하는 새 RedirectCommand클래스를 소개했습니다.\n\n이 개선으로 Angular 애플리케이션에서 복잡한 네비게이션 패턴을 다루는 것이 더 쉬워지며 유지보수성과 유연성이 향상됩니다.\n\n# 새 ng-template API\n\n\n\nAngular 18은 ng-template API를 더 강력하고 유연하게 만들 수 있는 기능을 도입할 수도 있습니다.\n\n# 향상된 Forms API\n\nForms API는 몇 가지 향상을 받아서 더 강력하고 개발자 친화적입니다:\n\n- 좀 더 쉬운 Form 객체 정의: 이를 통해 폼 모델을 더 적은 보일러플레이트 코드로 작성할 수 있어 가독성과 유지 보수성을 향상시킵니다.\n- 간단한 유효성 검사 규칙: API는 대부분의 유효성 검사 시나리오에 대한 더 나은 추상화를 제공하여 필수 필드, 최소/최대 값, 패턴 및 사용자 정의 유효성 검사를 더 쉽게 관리할 수 있습니다.\n- 복잡한 유효성 검사 시나리오 관리: 교차 필드 유효성 검사나 동적 유효성 규칙 등에 대한 Angular 18의 기능을 통해 복잡한 경우를 더 잘 관리할 수 있습니다.\n- 세밀한 제어: 폼 유효성 검사에 대해 더 많은 제어를 제공하여 오류 메시지를 사용자 정의하고 비동기적 유효성 검사를 처리하며 사용자 입력에 효과적으로 반응할 수 있습니다.\n\n\n\n# Zoneless Applications\n\nAngular 18은 응용 프로그램에 신호를 통합하여 zone.js에 의존하지 않고 작동하도록 합니다. 이 최적화는 성능과 응답 시간을 향상시킵니다.\n\nMatthieu Riegler와 Enea Jahollari는 각각이 주제에 관한 기사를 게시했습니다.\n\nMatthieu의 기사는 새로운 하이브리드 변경 감지 시스템에 깊이 들어가며 Signal 변경 또는 markForCheck를 호출하는 비동기(pipe)와 같은 작업이 zone.js 외부에서도 자동으로 변경 감지를 트리거할 수 있다는 것을 강조합니다.\n\n\n\n한편, Enea의 기사는 zone.js를 완전히 비활성화하고 이러한 새로운 트리거 메커니즘에 완전히 의존하여 애플리케이션 상태 변경을 관리하는 데 초점을 맞추고 있습니다.\n\n# TypeScript 4.7 지원\n\nAngular 18은 TypeScript 4.7의 기능을 최대한 활용합니다. 이 강력한 JavaScript의 슈퍼셋은 빠른 컴파일 시간과 간소화된 빌드 절차, 향상된 Readonly 지원, 새로운 import 유형 및 템플릿 리터럴 유형과 같은 다양한 성능 향상을 소개합니다. 이러한 개선 사항으로 더 원활한 개발 경험과 잠재적으로 더 빠른 애플리케이션 실행이 가능해집니다.\n\n중요한 점은 Angular 18에서 TypeScript 5.4 이전 버전의 지원을 중단한다는 것입니다. 따라서 TypeScript 버전을 업데이트하면 이러한 진보를 활용할 수 있습니다.\n\n\n\n# Ivy를 통한 성능 개선\n\nAngular의 새로운 렌더링 엔진 인 Ivy는 Angular 18에서 성능을 향상시키고 번들 크기를 줄이며 트리 쉐이킹 능력을 향상시킴으로써 계속 발전하고 있습니다.\n\n# 개선된 디버깅 도구\n\nAngular 18에서는 디버깅 도구에 여러 가지 개선 사항이 도입될 예정입니다. 이러한 개선 사항은 Angular 애플리케이션의 디버깅 과정을 단순화하고 응용 프로그램 상태에 대한 더 깊은 통찰을 제공하기 위해 목표로 합니다.\n\n\n\n- 디버깅 시 소스 맵 활용\n- 컴포넌트 트리 및 데이터 바인딩 시각화\n\n# Angular 18: 반응성을 위한 새 시대\n\nAngular 18이 다가오고 있습니다. 개발자들을 위한 흥미로운 변화를 약속하며, 단순함, 개선된 컴포넌트 및 향상된 도구에 초점을 맞춰 이번 버전은 개발 경험을 더욱 높이고 있습니다. 릴리즈를 열망하며 우리의 개발 경험이 어떻게 진화되는지 기대하고 있습니다.\n\n# 읽어 주셔서 감사합니다!\n\n\n\n만약 이 내용이 유익했다면, 댓글을 남기거나 박수를 보내주시거나 제 팔로우를 눌러주세요. 공유는 사랑입니다, 따라서 여러분의 기술 열정이 넘치는 친구들과 커뮤니티에 전달해 보세요. 그리고 LinkedIn에서 저와 연락을 유지해주시는 걸 잊지 마세요 — 언제나 열정을 가진 열광적인 분들과 소통하는 것을 기대하고 있습니다! 👏\n\n기억해 주세요, 우리의 기술 커뮤니티는 협력과 지식 공유에 의해 번영합니다. 대화를 이어나가 봅시다! 😊🚀","ogImage":{"url":"/assets/img/2024-05-15-Angular18Topnewfeaturesandimprovements_0.png"},"coverImage":"/assets/img/2024-05-15-Angular18Topnewfeaturesandimprovements_0.png","tag":["Tech"],"readingTime":4},{"title":"빠른 BDD UI 테스트 프레임워크 with Playwright","description":"","date":"2024-05-15 10:41","slug":"2024-05-15-QuickBDDUITestFrameworkwithPlaywright","content":"\n\n<img src=\"/assets/img/2024-05-15-QuickBDDUITestFrameworkwithPlaywright_0.png\" />\n\n```javascript\n// Playwright에서 Type Script와 Cucumber로 UI 테스트 프레임워크를 시작하는 빠른 가이드입니다.\n\n// 주의 사항:-\n// 이것은 테스트 자동화를 시작하기 위해 의도적으로 매우 기본적인 프레임워크 설정입니다.\n// 요구 사항에 맞게 향상시킬 수 있습니다.\n```\n\n# 필요한 것\n\n- Node 및 NPM 설치가 되어 있어야 합니다.\n- Visual Studio Code\n- Cucumber 익스텐션\n\n\n\n# 프로젝트 설정하기\n\n명령줄로 이동하여 다음을 실행하세요 (프로젝트 설정 및 종속성 설치):\n\n```js\n> mkdir playwright-bdd-project\n> cd playwright-bdd-project\n> npm init // 모든 기본 값 선택, 이렇게 하면 새 노드 프로젝트가 초기화되고 package.json이 생성됩니다\n> npm i @cucumber/cucumber -D // cucumber // -D 플래그는 이 설치를 package.json의 개발용 종속성으로 추가합니다\n> npm i @playwright/test -D // Playwright\n> npm i @types/node -D // Node용 Type Script\n> npm i ts-node -D // Node 실행 환경에서 Type Script 파일을 실행하기 위함\n> code . // 이 새롭게 설정한 프로젝트를 Visual Studio Code로 엽니다\n```\n\n<img src=\"/assets/img/2024-05-15-QuickBDDUITestFrameworkwithPlaywright_1.png\" />\n\n\n\n# 프로젝트 구조\n\n다음과 같이 프로젝트에서 디렉터리 구조를 설정해주세요:\n\n```js\nroot \\ src \\ test \\ features // 여기에는 피쳐 파일이 위치합니다\nroot \\src \\ test \\steps // 여기에는 스텝 정의 파일이 위치합니다\nroot \\ reports // 여기에는 테스트 보고서가 생성됩니다\nroot \\ src \\ test \\ utils // 여기에는 유틸리티 코드를 유지합니다\n```\n\n![예시 이미지](/assets/img/2024-05-15-QuickBDDUITestFrameworkwithPlaywright_2.png)\n\n\n\n# 이 프레임워크의 핵심 — cucumber.json\n\n프로젝트 루트에 cucumber.json 파일을 생성하세요.\n\n루트 `cucumber.json\n\n```js\n{\n    \"default\": {\n        \"paths\": [\n            \"src/test/features/*.feature\" // 피처 파일의 위치\n        ],\n        \"dryRun\": false,\n        \"formatOptions\": {\n            \"snippetInterface\": \"async-await\" // async-await 형식으로 스텝 정의를 자동 생성하기 위함\n        },\n        \"require\": [\n            \"src/test/steps/*.ts\" // 피처 파일의 위치\n        ],\n        \"requireModule\": [\n            \"ts-node/register\" // 타입스크립트 파일에서 import를 사용할 수 있도록, node 실행 환경에서 이를 인식할 수 있게 함\n        ],\n        \"format\": [\n            [\"html\", \"reports/cucumber-report.html\"] // 테스트 실행 보고서가 여기에 생성됩니다\n        ]\n    }\n}\n```\n\n\n\n# Cucumber Extension 설정.json 파일에 Feature 파일 및 Step Definitions 경로 업데이트\n\n이를 통해 Cucumber 확장 프로그램이 Feature 및 해당하는 Step Definitions 파일을 매핑하는 데 도움이 됩니다.\n\n```json\n// 참고:-\n// 아래에 표시된 것과 다를 수 있는 경우가 있습니다.\n\n{\n    \"workbench.colorTheme\": \"Quiet Light\",\n    \"files.autoSave\": \"afterDelay\",\n    \"workbench.iconTheme\": \"vscode-icons\",\n    \"playwright.reuseBrowser\": false,\n    \"playwright.showTrace\": false,\n    \"cucumber.features\": [\n        \"src/test/features/*.feature\" // Feature 파일의 위치\n    ],\n    \"cucumber.glue\": [\n        \"src/test/steps/*.ts\" // Step Definition 파일의 위치\n    ],\n    \"aws.telemetry\": false,\n    \"amazonQ.telemetry\": false,\n    \"explorer.confirmDelete\": false,\n    \"javascript.updateImportsOnFileMove.enabled\": \"always\"\n}\n```\n\n# Feature 파일\n\n\n\n\"root \\ src \\ test \\ features \\ search.feature\" 경로에 다음 기능 파일을 추가해 주세요.\n\n```js\nFeature: Basic search using google engine\n\n  Scenario: Search for a term\n    Given I am on the google search page\n    When I search for \"cucumber\"\n    Then the search results page should contain \"cucumber\"\n```\n\n# 단계 정의\n\n\"root \\ src \\ test \\ steps \\ search.ts\" 경로에 다음 단계 정의 파일을 추가해 주세요.\n\n\n\n\n```js\nimport { Given, When, Then } from '@cucumber/cucumber';\nimport { expect } from '@playwright/test';\nimport { page } from './hooks';\n\nGiven('I am on the google search page', async function () {\n    console.log('I am on the google search page');\n});\n\nWhen('I search for {string}', async function (string) {\n    console.log('I search for ' + string);\n    await page.getByLabel('Search', { exact: true }).click();\n    await page.getByLabel('Search', { exact: true }).fill(string);\n    await page.getByLabel('Google Search').first().click();\n\n});\n\nThen('the search results page should contain {string}', async function (string) {\n    console.log('the search results page should contain ' + string);\n    await page.getByRole('link', { name: 'Cucumber: BDD Testing &' }).click();\n    expect(page.url()).toContain('cucumber.io');\n});\n``` \n\n## Hooks\n\nAdd the following hooks file under: root \\ src \\ test \\ steps \\ hooks.ts\n\n```js\nimport { Before, After, AfterStep, BeforeStep, World } from \"@cucumber/cucumber\";\nimport { chromium, Page, Browser } from '@playwright/test';\nimport { addCommentToReport, addScreenshotToReport } from \"../utils/reporting\";\n\nlet browser : Browser;\nlet page : Page;\n\nBefore(async function () { // SETUP (Runs Before Every Test Scenario) \n    console.log('Before hook');\n    browser = await chromium.launch({headless: false});\n    page = await browser.newPage();\n    await page.goto('https://www.google.com');\n});\n\nAfter(async function () { // TEARDOWN (Runs After Every Test Scenario)\n    console.log('After hook');\n    await browser.close();\n});\n\n// RUNS BEFORE EVERY STEP\n// We are taking screenshop before every step and adding it to the test report\nBeforeStep(async function({pickle, pickleStep, gherkinDocument, testCaseStartedId, testStepId}) {\n    await addScreenshotToReport.call(this);\n    await addCommentToReport.call(this, 'BeforeStep hook: ' + pickleStep.text);\n})\n\n// RUNS AFTER EVERY STEP\n// We are taking screenshop after every step and adding it to the test report\nAfterStep(async function({pickle, pickleStep, gherkinDocument, result, testCaseStartedId, testStepId}) {\n    await addScreenshotToReport.call(this);\n    await addCommentToReport.call(this, 'AfterStep hook: ' + pickleStep.text + ' - ' + result.status);\n})\n\nexport { browser, page };\n```   \n  \n\n\n\n# 유틸리티\n\n아래의 유틸리티 파일을 다음 경로에 추가하세요: root \\ src \\ test \\ utils\\ reporting.ts\n\n```js\nimport { World } from \"@cucumber/cucumber\";\nimport { page } from \"../steps/hooks\";\n\n// 테스트 리포트에 스크린샷을 추가하는 함수\nexport async function addScreenshotToReport(this: World) {\n    this.attach(await page.screenshot({ fullPage: true }), 'image/png');\n}\n\n// 테스트 리포트에 코멘트를 추가하는 함수\nexport async function addCommentToReport(this: World, comment: string) {\n    this.attach(comment, 'text/plain');\n}\n```\n\n# 최종 설정은 이렇게 될 것입니다:\n\n\n\n\n![이미지](/assets/img/2024-05-15-QuickBDDUITestFrameworkwithPlaywright_3.png)\n\n# 테스트 실행\n\npackage.json에서 test 필드 값을 \"cucumber-js test\"로 설정하세요.\n\n```js\n \"scripts\": {\n    \"test\": \"cucumber-js test\"\n  },\n```\n\n\n\n터미널을 열고 (CTRL + J) `npm test`를 실행해주세요.\n\n이 명령을 통해 테스트가 실행됩니다.\n\n![이미지](/assets/img/2024-05-15-QuickBDDUITestFrameworkwithPlaywright_4.png)\n\n# 실행 보고서 유효성 검사\n\n\n\n루트 / 보고서 / 로 이동하셔서\n\n여기에서 최신 테스트 실행 보고서를 찾으실 수 있습니다.\n\n![보고서 이미지](/assets/img/2024-05-15-QuickBDDUITestFrameworkwithPlaywright_5.png)","ogImage":{"url":"/assets/img/2024-05-15-QuickBDDUITestFrameworkwithPlaywright_0.png"},"coverImage":"/assets/img/2024-05-15-QuickBDDUITestFrameworkwithPlaywright_0.png","tag":["Tech"],"readingTime":7},{"title":"루비 온 레일즈 앱을 커피스트라노Capistrano를 사용하여 로컬로동일 PC에서 다른 사용자에게 배포하기","description":"","date":"2024-05-15 10:39","slug":"2024-05-15-DeploymentofRubyonRailsappusingCapistranoLocallyFromoneusertoanotheronthesamePC","content":"\n\n<img src=\"/assets/img/2024-05-15-DeploymentofRubyonRailsappusingCapistranoLocallyFromoneusertoanotheronthesamePC_0.png\" />\n\n# 소개\n\n소프트웨어 개발에서 애플리케이션을 배포하는 것은 사용자가 이용할 수 있도록 하는 중요한 단계입니다. Capistrano는 배포 프로세스를 자동화하여 효율적이고 신뢰성있게 만드는 인기 있는 도구입니다.\n\n이 안내서에서는 Capistrano를 사용하여 로컬에서 Ruby on Rails 애플리케이션을 배포하는 단계를 안내합니다. 레일즈 앱 배포 방법을 배우면서 수행한 내용이며, 이런 단계를 따랐습니다.\n\n\n\n# 전제 조건\n\n시작하기 전에 다음 전제 조건을 확인하세요:\n\n- Ubuntu 터미널과 Capistrano 파일 구조에 대한 기본 지식.\n- Ruby on Rails가 PC에 올바르게 설정되어 있어야 합니다.\n- 두 사용자가 Rails 앱 디렉토리에 액세스하고 명령을 실행할 필요한 권한을 갖고 있어야 합니다.\n- SSH 키가 올바르게 설정되어 있어야 합니다.\n- Ubuntu에서 사용자 및 SSH 키 설정에 익숙해야 합니다.\n\n# 사용자 생성 및 SSH 설정\n\n\n\n- 새 사용자를 만드세요:\n\n```js\nsudo adduser newuser\n```\n\n- 사용자를 만든 후, 해당 사용자로 전환하세요\n\n```js\nsudo su - newuser\n```\n\n\n\n새 사용자에게 .ssh 디렉토리를 만들어야 합니다. Rails 앱을 배포하기 위해 ssh 키가 필요합니다.\n\n```js\n mkdir -p ~/.ssh\n```\n\n- 기존 사용자의 SSH 인증 키를 새 사용자의 .ssh 디렉토리로 복사해야 합니다. 여기서 ssh는 두 사용자 간 통신에 사용됩니다.\n\n```js\nsudo cp /home/existing-user/.ssh/authorized_keys /home/newuser/.ssh\n```\n\n\n\n- 또한, 새 사용자에게 소유권을 부여해 주세요\n\n```js\nsudo chown -R newuser:newuser /home/newuser/.ssh\n```\n\n- 새로운 사용자에게 sudo 권한을 부여하세요(관리자 권한을 가진 사용자로 로그인해야 함)\n\n```js\nsudo usermod -aG sudo newuser\n```\n\n\n\n- 이제 새 사용자로 전환할 수 있어요\n\n```js\nsu - newuser\n```\n\n- 이제 새 사용자의 SSH 구성 여부를 확인할 수 있어요\n\n```js\nssh localhost\n```\n\n\n\n- 만약 ssh가 연결되어 있다면 이제 다음과 같이 표시됩니다 :\n\n![Deployment of Ruby on Rails app using Capistrano Locally From one user to another on the same PC](/assets/img/2024-05-15-DeploymentofRubyonRailsappusingCapistranoLocallyFromoneusertoanotheronthesamePC_1.png)\n\n- 이제 배포 프로세스를 시작해봅시다. 레일즈 앱을 배포하려는 사용자를 엽니다 :\n\n# Gemfile 설정\n\n\n\n- 먼저 레일즈에서 Capistrano 젬을 설정하는 것이 첫 번째 단계입니다.\n\n다음을 개발 그룹 아래 Gemfile에 추가하십시오.\n\n```js\ngem \"capistrano\", \"~> 3.10\", require: false\ngem \"capistrano-rails\", \"~> 1.6\", require: false \ngem 'capistrano-rbenv', require: false   \ngem 'capistrano-puma', require: false\n```\n\n- 이제 다음 명령을 명령 줄에서 실행하여 추가 번들을 설치하십시오\n\n\n\n```js\n번들 설치\n```\n\n- 생성기를 실행하여 기본 구성 파일 세트를 만듭니다.\n\n```js\n번들 실행 cap 설치\n```\n\n# Capfile 구성\n\n\n\n- 루트 디렉토리에 있는 Capfile에서 다음 플러그인들을 주석처리 해제하세요.\n\n```js\nrequire \"capistrano/rbenv\" \nrequire \"capistrano/bundler\"\nrequire \"capistrano/rails/assets\"\nrequire \"capistrano/rails/migrations\" \nrequire \"capistrano/rails\" \nrequire \"capistrano/bundler\"\nrequire \"capistrano/puma\"\n```\n\n- 참고: 위의 플러그인은 앱의 요구 사항에 따라 다를 수 있습니다. 예를 들어, 여기서 패신저를 사용하는 경우 require \"capistrano/passenger\"를 추가해야합니다. 저는 사용하지 않기 때문에 추가하지 않아도 됩니다.\n\n# 설정 파일\n\n\n\n- `config/deploy.rb` 파일을 적절한 값으로 업데이트해주세요. 여기서는 cap loc 버전 3.18.0을 사용하며 `staging.rb`를 사용하여 배포하고 있습니다.\n- 프로젝트 요구 사항에 따라 구성을 사용자 정의해주시기 바랍니다.\n\n```js\nlock \"~> 3.18.0\"\nset :stage, :staging \nset :rails_env, 'test' \nset :application, '{앱 이름}' \nset :repo_url, 'git@github.com:당신의/github/url.git' \nset :deploy_to, '/home/{로컬 사용자명}/{배포할 애플리케이션 이름}' \nset :branch, '{배포하려는 브랜치}' \nset :rbenv_ruby, '2.7.7' \nset :default_env, { 'PATH' => \"#{fetch(:rbenv_path)}/shims:#{fetch(:rbenv_path)}/bin:$PATH\", 'RBENV_VERSION' => fetch(:rbenv_ruby) }\n```\n\n# 배포\n\n- `staging.rb` 파일에 로컬 호스트 IP를 추가하세요.\n\n\n\n```js\n서버 'localhost', 사용자: '{귀하의 로컬 사용자 이름}', 역할: %w{app db web}\n```\n\n- 이제 다음 명령을 사용하여 API를 로컬로 배포할 수 있습니다.\n\n```js\ncap staging deploy\n```\n\n- 이제 루비 온 레일 API가 로컬로 배포되었고 앱 폴더로 이동하여 버전을 확인할 수 있습니다. 현재 디렉토리로 이동한 후에 아래 명령을 실행할 수 있습니다.\n\n\n\n```js\nbin/rails s\n```\n\n- 특정 젬 설치 오류가 발생하면 ruby와 rails 간 버전 간의 충돌이 없는지 확인해보세요.\n\n이제 파일 구조가 다음과 같이 보일 것입니다 :\n\n![image](/assets/img/2024-05-15-DeploymentofRubyonRailsappusingCapistranoLocallyFromoneusertoanotheronthesamePC_2.png)\n\n\n\n\n# 결론\n\n축하합니다! Capistrano를 사용하여 로컬에 Ruby on Rails 애플리케이션을 성공적으로 배포했습니다. 이제 Rails 서버를 실행하고 애플리케이션에 액세스할 수 있습니다.\n\n# 팁\n\n- 배포 명령을 실행하기 전에 배포 구성을 항상 확인해보세요.\n- 배포 중 발생하는 오류를 해결하려면 로그와 구성을 확인하세요.\n- 프로젝트의 요구에 맞게 Capistrano 구성을 사용자 정의하세요.","ogImage":{"url":"/assets/img/2024-05-15-DeploymentofRubyonRailsappusingCapistranoLocallyFromoneusertoanotheronthesamePC_0.png"},"coverImage":"/assets/img/2024-05-15-DeploymentofRubyonRailsappusingCapistranoLocallyFromoneusertoanotheronthesamePC_0.png","tag":["Tech"],"readingTime":4},{"title":"Vite와 함께 하는 동적 모듈 연맹","description":"","date":"2024-05-15 10:38","slug":"2024-05-15-DynamicModuleFederationwithVite","content":"\n\n<img src=\"/assets/img/2024-05-15-DynamicModuleFederationwithVite_0.png\" />\n\n요즘은 Vite를 통해 React 마이크로 프론트엔드를 빌드하는 작업을 맡게 되었어요. 이 솔루션은 런타임에서 원격 모듈 URL을 동적으로 결정해야 했어요. 컴파일 시간이 아니라요.\n\n동적 모듈 연합은 새로운 도전이 아니에요. 웹팩으로 여러 번 구현되어 왔기 때문에 Vite로도 이를 하는 것이 더 쉬울 것이라고 생각했어요. 그러나 이 기능이 지원되지 않거나 문서화되지 않았다는 것에 놀랐어요.\n\n몇 일 동안 검색한 끝에 좋은 긴 GitHub 토론을 발견했는데 막다른 곳처럼 보였어요. 그렇지만 흥미로워서 계속 읽다가 어쩌면 해결책이 있어요.\n\n\n\n다이내믹 모듈 연합이 도움이 되는 여러 시나리오가 있습니다. 예를 들어, A/B 테스팅입니다. 집단에 영향을 주지 않고 일부 사용자를 위한 새 레이아웃을 테스트하고 싶은 경우를 상상해보세요. 이 작업을 수행하는 React 앱을 만들어 봅시다. 앞서 진행하고 싶은 사람들을 위해 작동하는 예제가 여기 있어요. https://github.com/lestersconyers/react-apps/tree/main/dynamic-module-federation\n\n## 설정\n\n이 예제에서는 호스트 앱과 A와 B의 2개의 원격 앱을 갖게 됩니다. 사용자가 사이트를 방문할 때, 어떤 원격 앱 콘텐츠를 표시할지 결정하기 위해 일부 최상급 로직을 사용할 것입니다.\n\n- 보통처럼 원격 앱 모듈 연합을 설정합니다. Vite와 함께의 표준 모듈 연합은 상당히 잘 문서화되어 있으므로 인터넷을 중복하지는 않겠습니다. 다만 여기에 설정 파일이 있어요.\n\n\n\n2. 호스트 앱의 App.tsx 파일에서 __federation__ 모듈에서 함수를 가져와주세요. 여기에서 마법이 일어납니다!\n\n3. setRemote를 사용하여 url을 반환하는 프로미스를 만들고, getRemote를 사용하여 해당 프로미스를 반환하세요. 이 프로미스는 런타임 시에 해결됩니다.\n\n4. 동적 원격 앱을 사용하세요.\n\n5. 마지막으로 호스트 앱의 vite.config.ts 파일에 더미 원격 항목을 추가하여 런타임 오류를 피하세요.\n\n\n\n모두 완료했습니다!","ogImage":{"url":"/assets/img/2024-05-15-DynamicModuleFederationwithVite_0.png"},"coverImage":"/assets/img/2024-05-15-DynamicModuleFederationwithVite_0.png","tag":["Tech"],"readingTime":2},{"title":"파이토치를 처음부터 다시 만들어보기 GPU 지원 및 자동 미분 기능 포함","description":"","date":"2024-05-15 10:33","slug":"2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation","content":"\n\n## C/C++, CUDA, 및 Python을 기반으로 한 고유의 딥 러닝 프레임워크를 구축해 보세요. GPU 지원과 자동 미분을 제공합니다\n\n![image](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_0.png)\n\n# 소개\n\n여러 해 동안 PyTorch를 사용하여 딥 러닝 모델을 구축하고 훈련해 왔습니다. 그럼에도 불구하고, 그 문법과 규칙을 익히고도, 제 궁금증을 자극하던 것이 있었습니다: 이러한 작업 중에 내부에서 어떤 일이 일어나고 있는 걸까요? 이 모든 것이 어떻게 작동할까요?\n\n\n\n여기까지 오셨다면, 아마도 비슷한 질문을 가지고 계실 것입니다. 파이토치(PyTorch)에서 모델을 생성하고 훈련하는 방법을 물어본다면 아마도 아래 코드와 비슷한 것을 생각해볼 것입니다:\n\n```js\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\n\nclass MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.fc1 = nn.Linear(1, 10)\n        self.sigmoid = nn.Sigmoid()\n        self.fc2 = nn.Linear(10, 1)\n\n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.sigmoid(out)\n        out = self.fc2(out)\n        \n        return out\n\n...\n\nmodel = MyModel().to(device)\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001)\n\nfor epoch in range(epochs):\n    for x, y in ...\n        \n        x = x.to(device)\n        y = y.to(device)\n\n        outputs = model(x)\n        loss = criterion(outputs, y)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n```\n\n하지만 이번에 역전파(backward) 단계가 어떻게 작동하는지 물어본다면 어떨까요? 또는 예를 들어, 텐서를 재구성할 때 무슨 일이 일어나는지 궁금하시다면요? 내부에서 데이터가 재배치되나요? 그런 일이 어떻게 일어나나요? 왜 PyTorch는 빠른가요? PyTorch가 GPU 연산을 어떻게 처리하는지요? 이런 질문들이 항상 저를 호기심 가득하게 만들었고, 여러분도 마찬가지로 호기심이 드실 것이라고 상상합니다. 그래서 이러한 개념을 더 잘 이해하기 위해 스스로 텐서 라이브러리를 처음부터 구축해보는 것이 무엇보다 좋을까요? 이 글에서 여러분이 배우게 될 것이 바로 그겁니다!\n\n## #1 — 텐서\n\n\n\n텐서 라이브러리를 구축하기 위해 가장 먼저 알아야 할 개념은 무엇이 텐서인지에 대한 명백한 개념입니다.\n\n텐서는 몇 가지 숫자를 포함하는 n차원 데이터 구조의 수학적 개념이라는 직관적인 생각을 가지고 있을 수 있습니다. 그러나 여기서는 이 데이터 구조를 계산적 관점에서 어떻게 모델링할지 이해해야 합니다. 텐서는 데이터 자체뿐만 아니라 모양이나 텐서가 있는 장치(예: CPU 메모리, GPU 메모리)와 같은 측면을 설명하는 메타데이터로 구성된다고 생각할 수 있습니다.\n\n텐서의 내부를 이해하는 데 매우 중요한 개념인 stride라는 잘 알려지지 않은 메타데이터도 있습니다. 따라서 텐서 데이터 재배열의 내부를 이해하기 위해 약간 더 이에 대해 논의해야 합니다.\n\n\n\n2-D 텐서의 모양이 [4, 8]인 경우를 상상해보세요.\n\n![텐서](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_2.png)\n\n텐서의 데이터(즉, 부동 소수점 수)는 실제로 메모리에 1차원 배열로 저장됩니다.\n\n![데이터](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_3.png)\n\n\n\n그러면 이 1차원 배열을 N차원 텐서로 나타내려면 스트라이드를 사용합니다. 기본 아이디어는 다음과 같습니다:\n\n4행 8열의 행렬이 있습니다. 그 행렬의 모든 원소가 1차원 배열의 행에 의해 구성되어 있다고 가정할 때, 위치 [2, 3]의 값을 액세스하려면 2행(각 행에 8개의 요소)을 횡단해야 하며 추가로 3개의 위치를 지나야 합니다. 수학적으로 표현하면 1차원 배열에서 3 + 2 * 8 요소를 횡단해야 합니다.\n\n따라서, '8'은 두 번째 차원의 스트라이드입니다. 이 경우, 배열에서 다른 위치로 \"점프\"하기 위해 몇 개의 요소를 횡단해야 하는지를 나타내는 정보입니다.\n\n\n\n따라서, 모양이 [shape_0, shape_1]인 2차원 텐서의 요소 [i, j]에 액세스하려면, 기본적으로 j + i * shape_1 위치에 있는 요소에 액세스해야 합니다.\n\n이제 3차원 텐서를 상상해보겠습니다:\n\n![image](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_5.png)\n\n이 3차원 텐서를 행렬의 시퀀스로 생각할 수 있습니다. 예를 들어, 이 [5, 4, 8] 텐서를 [4, 8] 모양의 5개 행렬로 생각할 수 있습니다.\n\n\n\n이제 [1, 3, 7] 위치에 있는 요소에 액세스하기 위해 [4,8] 형태의 행렬을 1개 완전히 횡단하고, [8] 형태의 행을 2개, [1] 형태의 열을 7개 횡단해야 합니다. 따라서 1차원 배열에서 (1 * 4 * 8) + (2 * 8) + (7 * 1) 위치를 횡단해야 합니다.\n\n![image](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_6.png)\n\n따라서, [shape_0, shape_1, shape_2] 모양의 3차원 텐서에서 1차원 데이터 배열에서 [i][j][k] 요소에 액세스하는 방법은 다음과 같습니다:\n\n![image](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_7.png)\n\n\n\n이 shape_1 * shape_2가 첫 번째 차원의 stride이고, shape_2는 두 번째 차원의 stride이며 1은 세 번째 차원의 stride입니다.\n\n그런 다음, 일반화하기 위해서는:\n\n![image](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_8.png)\n\n각 차원의 stride는 다음 차원 텐서 모양의 곱을 사용하여 계산할 수 있습니다:\n\n\n\n<img src=\"/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_9.png\" />\n\n그런 다음 stride[n-1] = 1로 설정합니다.\n\n우리의 형태의 텐서 예제 [5, 4, 8]에서 strides = [4*8, 8, 1] = [32, 8, 1]일 것입니다.\n\n여러분들도 직접 테스트할 수 있어요:\n\n\n\n```js\nimport torch\n\ntorch.rand([5, 4, 8]).stride()\n#(32, 8, 1)\n```\n\n알겠어요, 그런데 왜 모양과 스트라이드가 필요한 건가요? N차원 텐서의 요소에 접근하는 것을 넘어, 이 개념은 텐서 배열을 매우 쉽게 조작하는 데 사용될 수 있어요.\n\n예를 들어, 텐서를 재구성하려면 새로운 모양을 설정하고 새로운 스트라이드를 계산하면 됩니다! (새로운 모양은 동일한 요소 수를 보장하므로)\n\n```js\nimport torch\n\nt = torch.rand([5, 4, 8])\n\nprint(t.shape)\n# [5, 4, 8]\n\nprint(t.stride())\n# [32, 8, 1]\n\nnew_t = t.reshape([4, 5, 2, 2, 2])\n\nprint(new_t.shape)\n# [4, 5, 2, 2, 2]\n\nprint(new_t.stride())\n# [40, 8, 4, 2, 1]\n``` \n\n\n\n\n텐서 내부에서는 여전히 동일한 1차원 배열로 저장됩니다. reshape 메서드는 배열 내 요소의 순서를 변경하지 않았습니다! 대단하지 않나요? 😁\n\n다음 함수를 사용하여 PyTorch에서 내부 1차원 배열에 액세스하는 함수를 사용하여 직접 확인할 수 있습니다:\n\n```js\nimport ctypes\n\ndef print_internal(t: torch.Tensor):\n    print(\n        torch.frombuffer(\n            ctypes.string_at(t.data_ptr(), t.storage().nbytes()), dtype=t.dtype\n        )\n    )\n\nprint_internal(t)\n# [0.0752, 0.5898, 0.3930, 0.9577, 0.2276, 0.9786, 0.1009, 0.138, ...\n\nprint_internal(new_t)\n# [0.0752, 0.5898, 0.3930, 0.9577, 0.2276, 0.9786, 0.1009, 0.138, ...\n```\n\n예를 들어 두 축을 전치하려면 내부적으로 해당 스트라이드를 단순히 바꾸어 주면 됩니다!\n\n\n\n```js\nt = torch.arange(0, 24).reshape(2, 3, 4)\nprint(t)\n# [[[ 0,  1,  2,  3],\n#   [ 4,  5,  6,  7],\n#   [ 8,  9, 10, 11]],\n \n#  [[12, 13, 14, 15],\n#   [16, 17, 18, 19],\n#   [20, 21, 22, 23]]]\n\nprint(t.shape)\n# [2, 3, 4]\n\nprint(t.stride())\n# [12, 4, 1]\n\nnew_t = t.transpose(0, 1)\nprint(new_t)\n# [[[ 0,  1,  2,  3],\n#   [12, 13, 14, 15]],\n\n#  [[ 4,  5,  6,  7],\n#   [16, 17, 18, 19]],\n\n#  [[ 8,  9, 10, 11],\n#   [20, 21, 22, 23]]]\n\nprint(new_t.shape)\n# [3, 2, 4]\n\nprint(new_t.stride())\n# [4, 12, 1]\n```\n\n내부 배열을 출력하면 두 값 모두 동일합니다:\n\n```js\nprint_internal(t)\n# [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n\nprint_internal(new_t)\n# [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n```\n\n그러나 new_t의 스트라이드는 이제 위의 식과 일치하지 않습니다. 이것은 텐서가 이제 연속적이지 않기 때문에 발생합니다. 즉, 내부 배열은 동일하지만 메모리 내의 값의 순서가 텐서의 실제 순서와 일치하지 않는다는 것을 의미합니다.\n\n\n\n```js\nt.is_contiguous()\n# True\n\nnew_t.is_contiguous()\n# False\n```\n\n이는 연속되지 않는 요소에 연속적으로 액세스하는 것이 효율적이지 않다는 것을 의미합니다 (실제 텐서 요소는 메모리 상에서 순서대로 정렬되어 있지 않기 때문입니다). 이를 해결하기 위해 다음을 수행할 수 있습니다:\n\n```js\nnew_t_contiguous = new_t.contiguous()\n\nprint(new_t_contiguous.is_contiguous())\n# True\n```\n\n내부 배열을 분석하면 이제 순서가 실제 텐서 순서와 일치하여 더 나은 메모리 액세스 효율을 제공할 수 있습니다:\n\n\n\n```js\nprint(new_t)\n# [[[ 0,  1,  2,  3],\n#   [12, 13, 14, 15]],\n\n#  [[ 4,  5,  6,  7],\n#   [16, 17, 18, 19]],\n\n#  [[ 8,  9, 10, 11],\n#   [20, 21, 22, 23]]]\n\nprint_internal(new_t)\n# [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n\nprint_internal(new_t_contiguous)\n# [ 0,  1,  2,  3, 12, 13, 14, 15,  4,  5,  6,  7, 16, 17, 18, 19,  8,  9, 10, 11, 20, 21, 22, 23]\n```\n\n이제 우리는 텐서가 어떻게 모델링되는지 이해했으니, 라이브러리 생성을 시작해 봅시다!\n\n내가 만들 라이브러리 이름은 Norch입니다. PyTorch가 아닌 (NOT PyTorch)을 의미하며, 성(Nogueira)을 암시하기도 합니다. 😁\n\n첫 번째로 알아야 할 것은 PyTorch가 Python을 통해 사용되지만 내부적으로는 C/C++로 실행된다는 것입니다. 그래서 먼저 내부 C/C++ 함수를 만들 것입니다.\n\n\n\n\n먼저 텐서를 데이터와 메타데이터를 저장하는 구조체로 정의하고 이를 만들기 위한 함수를 생성할 수 있습니다:\n\n```js\n//norch/csrc/tensor.cpp\n\n#include <stdio.h>\n#include <stdlib.h>\n#include <string.h>\n#include <math.h>\n\ntypedef struct {\n    float* data;\n    int* strides;\n    int* shape;\n    int ndim;\n    int size;\n    char* device;\n} Tensor;\n\nTensor* create_tensor(float* data, int* shape, int ndim) {\n    \n    Tensor* tensor = (Tensor*)malloc(sizeof(Tensor));\n    if (tensor == NULL) {\n        fprintf(stderr, \"메모리 할당 실패\\n\");\n        exit(1);\n    }\n    tensor->data = data;\n    tensor->shape = shape;\n    tensor->ndim = ndim;\n\n    tensor->size = 1;\n    for (int i = 0; i < ndim; i++) {\n        tensor->size *= shape[i];\n    }\n\n    tensor->strides = (int*)malloc(ndim * sizeof(int));\n    if (tensor->strides == NULL) {\n        fprintf(stderr, \"메모리 할당 실패\\n\");\n        exit(1);\n    }\n    int stride = 1;\n    for (int i = ndim - 1; i >= 0; i--) {\n        tensor->strides[i] = stride;\n        stride *= shape[i];\n    }\n    \n    return tensor;\n}\n```\n\n일부 요소에 접근하기 위해서는 앞서 배웠던 스트라이드(strides)를 활용할 수 있습니다:\n\n```js\n//norch/csrc/tensor.cpp\n\nfloat get_item(Tensor* tensor, int* indices) {\n    int index = 0;\n    for (int i = 0; i < tensor->ndim; i++) {\n        index += indices[i] * tensor->strides[i];\n    }\n\n    float result;\n    result = tensor->data[index];\n\n    return result;\n}\n```\n\n\n\n이제 텐서 작업을 만들 수 있습니다. 몇 가지 예제를 보여드리겠고, 이 글 끝에 링크된 저장소에서 완전한 버전을 찾을 수 있습니다.\n\n```js\n//norch/csrc/cpu.cpp\n\nvoid add_tensor_cpu(Tensor* tensor1, Tensor* tensor2, float* result_data) {\n    \n    for (int i = 0; i < tensor1->size; i++) {\n        result_data[i] = tensor1->data[i] + tensor2->data[i];\n    }\n}\n\nvoid sub_tensor_cpu(Tensor* tensor1, Tensor* tensor2, float* result_data) {\n    \n    for (int i = 0; i < tensor1->size; i++) {\n        result_data[i] = tensor1->data[i] - tensor2->data[i];\n    }\n}\n\nvoid elementwise_mul_tensor_cpu(Tensor* tensor1, Tensor* tensor2, float* result_data) {\n    \n    for (int i = 0; i < tensor1->size; i++) {\n        result_data[i] = tensor1->data[i] * tensor2->data[i];\n    }\n}\n\nvoid assign_tensor_cpu(Tensor* tensor, float* result_data) {\n\n    for (int i = 0; i < tensor->size; i++) {\n        result_data[i] = tensor->data[i];\n    }\n}\n\n...\n```\n\n그 다음에, 이러한 작업들을 호출할 텐서 다른 함수를 만들 수 있습니다.\n\n```js\n//norch/csrc/tensor.cpp\n\nTensor* add_tensor(Tensor* tensor1, Tensor* tensor2) {\n    if (tensor1->ndim != tensor2->ndim) {\n        fprintf(stderr, \"덧셈을 위해서 텐서는 동일한 차원 수여야 합니다 %d 와 %d\\n\", tensor1->ndim, tensor2->ndim);\n        exit(1);\n    }\n\n    int ndim = tensor1->ndim;\n    int* shape = (int*)malloc(ndim * sizeof(int));\n    if (shape == NULL) {\n        fprintf(stderr, \"메모리 할당 실패\\n\");\n        exit(1);\n    }\n\n    for (int i = 0; i < ndim; i++) {\n        if (tensor1->shape[i] != tensor2->shape[i]) {\n            fprintf(stderr, \"덧셈을 위해서 텐서는 동일한 모양이어야 합니다 %d 와 %d 인덱스 %d에서\\n\", tensor1->shape[i], tensor2->shape[i], i);\n            exit(1);\n        }\n        shape[i] = tensor1->shape[i];\n    }        \n    float* result_data = (float*)malloc(tensor1->size * sizeof(float));\n    if (result_data == NULL) {\n        fprintf(stderr, \"메모리 할당 실패\\n\");\n        exit(1);\n    }\n    add_tensor_cpu(tensor1, tensor2, result_data);\n    \n    return create_tensor(result_data, shape, ndim, device);\n}\n```\n\n\n\n이전에 언급한 대로, 텐서 재구성은 내부 데이터 배열을 수정하지 않습니다.\n\n```js\n//norch/csrc/tensor.cpp\n\nTensor* reshape_tensor(Tensor* tensor, int* new_shape, int new_ndim) {\n\n    int ndim = new_ndim;\n    int* shape = (int*)malloc(ndim * sizeof(int));\n    if (shape == NULL) {\n        fprintf(stderr, \"메모리 할당 실패\\n\");\n        exit(1);\n    }\n\n    for (int i = 0; i < ndim; i++) {\n        shape[i] = new_shape[i];\n    }\n\n    // 새 모양의 요소 총 수 계산\n    int size = 1;\n    for (int i = 0; i < new_ndim; i++) {\n        size *= shape[i];\n    }\n\n    // 총 요소 수가 현재 텐서의 크기와 일치하는지 확인\n    if (size != tensor->size) {\n        fprintf(stderr, \"텐서를 재구성할 수 없습니다. 새 모양의 요소 총 수가 현재 텐서의 크기와 일치하지 않습니다.\\n\");\n        exit(1);\n    }\n\n    float* result_data = (float*)malloc(tensor->size * sizeof(float));\n    if (result_data == NULL) {\n        fprintf(stderr, \"메모리 할당 실패\\n\");\n        exit(1);\n    }\n    assign_tensor_cpu(tensor, result_data);\n    return create_tensor(result_data, shape, ndim, device);\n}\n```\n\n이제 일부 텐서 작업을 수행할 수 있지만, 누구나 C/C++을 사용하여 실행해야 하는 것은 아닙니다. 이제 Python 래퍼를 만들어 봅시다!\n\nPython을 사용하여 C/C++ 코드를 실행할 수 있는 다양한 옵션이 있습니다. Pybind11과 Cython 등이 있습니다. 이 예시에서는 ctypes를 사용할 것입니다.\n\n\n\n아래는 ctypes의 기본적인 구조입니다:\n\n```js\n//C 코드\n#include <stdio.h>\n\nfloat add_floats(float a, float b) {\n    return a + b;\n}\n```\n\n```js\n# 컴파일\ngcc -shared -o add_floats.so -fPIC add_floats.c\n```\n\n```js\n# Python 코드\nimport ctypes\n\n# 공유 라이브러리 로드\nlib = ctypes.CDLL('./add_floats.so')\n\n# 함수의 인자와 반환 유형 정의\nlib.add_floats.argtypes = [ctypes.c_float, ctypes.c_float]\nlib.add_floats.restype = ctypes.c_float\n\n# 파이썬 float 값을 c_float 유형으로 변환\na = ctypes.c_float(3.5)\nb = ctypes.c_float(2.2)\n\n# C 함수 호출\nresult = lib.add_floats(a, b)\nprint(result)\n# 5.7\n```\n\n\n\n보시다시피 매우 직관적입니다. C/C++ 코드를 컴파일한 후 Python에서 ctypes를 사용하면 매우 쉽게 사용할 수 있습니다. 함수의 매개변수 및 반환 c_types를 정의하고, 변수를 해당 c_types로 변환하고 함수를 호출하기만 하면 됩니다. 배열(부동 소수점 목록)과 같은 보다 복잡한 유형의 경우 포인터를 사용할 수 있습니다.\n\n```js\ndata = [1.0, 2.0, 3.0]\ndata_ctype = (ctypes.c_float * len(data))(*data)\n\nlib.some_array_func.argstypes = [ctypes.POINTER(ctypes.c_float)]\n\n...\n\nlib.some_array_func(data)\n```\n\n그리고 구조체 유형의 경우 직접 c_type을 만들 수 있습니다.\n\n```js\nclass CustomType(ctypes.Structure):\n    _fields_ = [\n        ('field1', ctypes.POINTER(ctypes.c_float)),\n        ('field2', ctypes.POINTER(ctypes.c_int)),\n        ('field3', ctypes.c_int),\n    ]\n\n# ctypes.POINTER(CustomType)로 사용할 수 있습니다.\n```\n\n\n\n간단히 설명하고, 텐서 C/C++ 라이브러리를 위한 Python 래퍼를 만들어 보겠습니다!\n\n```js\n# norch/tensor.py\n\nimport ctypes\n\nclass CTensor(ctypes.Structure):\n    _fields_ = [\n        ('data', ctypes.POINTER(ctypes.c_float)),\n        ('strides', ctypes.POINTER(ctypes.c_int)),\n        ('shape', ctypes.POINTER(ctypes.c_int)),\n        ('ndim', ctypes.c_int),\n        ('size', ctypes.c_int),\n    ]\n\nclass Tensor:\n    os.path.abspath(os.curdir)\n    _C = ctypes.CDLL(\"COMPILED_LIB.so\")\n\n    def __init__(self):\n        \n        data, shape = self.flatten(data)\n        self.data_ctype = (ctypes.c_float * len(data))(*data)\n        self.shape_ctype = (ctypes.c_int * len(shape))(*shape)\n        self.ndim_ctype = ctypes.c_int(len(shape))\n       \n        self.shape = shape\n        self.ndim = len(shape)\n\n        Tensor._C.create_tensor.argtypes = [ctypes.POINTER(ctypes.c_float), ctypes.POINTER(ctypes.c_int), ctypes.c_int]\n        Tensor._C.create_tensor.restype = ctypes.POINTER(CTensor)\n\n        self.tensor = Tensor._C.create_tensor(\n            self.data_ctype,\n            self.shape_ctype,\n            self.ndim_ctype,\n        )\n        \n    def flatten(self, nested_list):\n        \"\"\"\n        This method simply convert a list type tensor to a flatten tensor with its shape\n        \n        Example:\n        \n        Arguments:  \n            nested_list: [[1, 2, 3], [-5, 2, 0]]\n        Return:\n            flat_data: [1, 2, 3, -5, 2, 0]\n            shape: [2, 3]\n        \"\"\"\n        def flatten_recursively(nested_list):\n            flat_data = []\n            shape = []\n            if isinstance(nested_list, list):\n                for sublist in nested_list:\n                    inner_data, inner_shape = flatten_recursively(sublist)\n                    flat_data.extend(inner_data)\n                shape.append(len(nested_list))\n                shape.extend(inner_shape)\n            else:\n                flat_data.append(nested_list)\n            return flat_data, shape\n        \n        flat_data, shape = flatten_recursively(nested_list)\n        return flat_data, shape\n```\n\n이제 Python 텐서 작업을 포함하여 C/C++ 작업을 호출할 수 있습니다.\n\n```js\n# norch/tensor.py\n\ndef __getitem__(self, indices):\n    \"\"\"\n    index 텐서를 사용하여 텐서에 액세스 tensor[i, j, k...]\n    \"\"\"\n\n    if len(indices) != self.ndim:\n        raise ValueError(\"인덱스 수가 차원 수와 일치해야 함\")\n    \n    Tensor._C.get_item.argtypes = [ctypes.POINTER(CTensor), ctypes.POINTER(ctypes.c_int)]\n    Tensor._C.get_item.restype = ctypes.c_float\n                                       \n    indices = (ctypes.c_int * len(indices))(*indices)\n    value = Tensor._C.get_item(self.tensor, indices)  \n    \n    return value\n\ndef reshape(self, new_shape):\n    \"\"\"\n    텐서를 재구성합니다\n    result = tensor.reshape([1,2])\n    \"\"\"\n    new_shape_ctype = (ctypes.c_int * len(new_shape))(*new_shape)\n    new_ndim_ctype = ctypes.c_int(len(new_shape))\n    \n    Tensor._C.reshape_tensor.argtypes = [ctypes.POINTER(CTensor), ctypes.POINTER(ctypes.c_int), ctypes.c_int]\n    Tensor._C.reshape_tensor.restype = ctypes.POINTER(CTensor)\n    result_tensor_ptr = Tensor._C.reshape_tensor(self.tensor, new_shape_ctype, new_ndim_ctype)   \n\n    result_data = Tensor()\n    result_data.tensor = result_tensor_ptr\n    result_data.shape = new_shape.copy()\n    result_data.ndim = len(new_shape)\n    result_data.device = self.device\n\n    return result_data\n\ndef __add__(self, other):\n    \"\"\"\n    텐서를 더합니다\n    result = tensor1 + tensor2\n    \"\"\"\n  \n    if self.shape != other.shape:\n        raise ValueError(\"덧셈을 위해서 텐서들은 동일한 모양이어야 함\")\n    \n    Tensor._C.add_tensor.argtypes = [ctypes.POINTER(CTensor), ctypes.POINTER(CTensor)]\n    Tensor._C.add_tensor.restype = ctypes.POINTER(CTensor)\n\n    result_tensor_ptr = Tensor._C.add_tensor(self.tensor, other.tensor)\n\n    result_data = Tensor()\n    result_data.tensor = result_tensor_ptr\n    result_data.shape = self.shape.copy()\n    result_data.ndim = self.ndim\n    result_data.device = self.device\n\n    return result_data\n\n# 기타 연산 포함:\n# __str__\n# __sub__ (-)\n# __mul__ (*)\n# __matmul__ (@)\n# __pow__ (**)\n# __truediv__ (/)\n# log\n# ...\n```\n\n\n\n여기까지 오신 것을 환영합니다! 이제 코드를 실행하고 텐서 작업을 시작할 수 있는 능력이 생겼습니다!\n\n```js\nimport norch\n\ntensor1 = norch.Tensor([[1, 2, 3], [3, 2, 1]])\ntensor2 = norch.Tensor([[3, 2, 1], [1, 2, 3]])\n\nresult = tensor1 + tensor2\nprint(result[0, 0])\n# 4 \n```\n\n# #2 — GPU 지원\n\n우리 라이브러리의 기본 구조를 만든 후, 이제 새로운 수준으로 끌어올릴 것입니다. 데이터를 GPU로 전송하고 수학 연산을 빠르게 실행하기 위해 `.to(\"cuda\")`를 호출할 수 있다는 것은 잘 알려져 있습니다. CUDA가 어떻게 작동하는지 기본 지식이 있을 것으로 가정하겠습니다만, 그렇지 않은 경우 다른 기사인 'CUDA 튜토리얼'을 읽어볼 수 있습니다. 여기서 기다릴게요. 😊\n\n\n\n...\n\n급한 사람들을 위해, 간단한 소개가 여기 있어요:\n\n기본적으로, 지금까지의 모든 코드는 CPU 메모리에서 실행되고 있어요. 하나의 작업에 대해서는 CPU가 빠르지만, GPU의 장점은 병렬화 능력에 있어요. CPU 디자인은 연산(스레드)을 빠르게 실행하도록 목표를 한 반면, GPU 디자인은 수백만 개의 연산을 병렬로 실행하도록 목표를 해요 (개별 스레드의 성능을 희생하며).\n\n그래서 우리는 이 능력을 활용하여 병렬 연산을 수행할 수 있어요. 예를 들어, 백만 개의 요소로 구성된 텐서를 추가할 때, 반복문 내에서 각 색인의 요소를 순차적으로 추가하는 대신, GPU를 사용하여 한꺼번에 모두를 병렬로 추가할 수 있어요. 이를 위해 NVIDIA에서 개발한 개발자들이 GPU 지원을 소프트웨어 애플리케이션에 통합할 수 있게 하는 플랫폼인 CUDA를 사용할 수 있어요.\n\n\n\n그걸 하려면, 특정 GPU 작업(예: CPU 메모리에서 GPU 메모리로 데이터 복사)을 실행하기 위해 설계된 간단한 C/C++ 기반 인터페이스 인 CUDA C/C++를 사용할 수 있습니다.\n\n아래 코드는 기본적으로 CPU에서 GPU로 데이터를 복사하고 배열의 각 요소를 추가하는 AddTwoArrays 함수(커널이라고도 함)를 N개의 GPU 스레드에서 병렬로 실행하는 몇 가지 CUDA C/C++ 함수를 사용합니다.\n\n```c\n#include <stdio.h>\n\n// CPU 버전(비교용)\nvoid AddTwoArrays_CPU(flaot A[], float B[], float C[]) {\n    for (int i = 0; i < N; i++) {\n        C[i] = A[i] + B[i];\n    }\n}\n\n// 커널 정의\n__global__ void AddTwoArrays_GPU(float A[], float B[], float C[]) {\n    int i = threadIdx.x;\n    C[i] = A[i] + B[i];\n}\n\nint main() {\n\n    int N = 1000; // 배열 크기\n    float A[N], B[N], C[N]; // 배열 A, B, C\n\n    ...\n\n    float *d_A, *d_B, *d_C; // 배열 A, B, C의 장치 포인터\n\n    // 배열 A, B, C에 대한 장치에서의 메모리 할당\n    cudaMalloc((void **)&d_A, N * sizeof(float));\n    cudaMalloc((void **)&d_B, N * sizeof(float));\n    cudaMalloc((void **)&d_C, N * sizeof(float));\n\n    // 호스트에서 장치로 배열 A 및 B 복사\n    cudaMemcpy(d_A, A, N * sizeof(float), cudaMemcpyHostToDevice);\n    cudaMemcpy(d_B, B, N * sizeof(float), cudaMemcpyHostToDevice);\n\n    // N개의 스레드를 사용하여 커널 호출\n    AddTwoArrays_GPU<<<1, N>>>(d_A, d_B, d_C);\n    \n    // 장치에서 호스트로 벡터 C 복사\n    cudaMemcpy(C, d_C, N * sizeof(float), cudaMemcpyDeviceToHost);\n\n}\n```\n\n주목할 점은 각 요소 쌍을 각각 추가하는 대신 모든 덧셈 작업을 병렬로 실행하여 루프 명령을 제거한 것입니다.\n\n\n\n간단한 소개 이후에, 텐서 라이브러리로 돌아갈 수 있어요.\n\n첫 번째 단계는 CPU에서 GPU로 텐서 데이터를 보내는 함수를 만드는 것입니다.\n\n```js\n//norch/csrc/tensor.cpp\n\nvoid to_device(Tensor* tensor, char* target_device) {\n    if ((strcmp(target_device, \"cuda\") == 0) && (strcmp(tensor->device, \"cpu\") == 0)) {\n        cpu_to_cuda(tensor);\n    }\n\n    else if ((strcmp(target_device, \"cpu\") == 0) && (strcmp(tensor->device, \"cuda\") == 0)) {\n        cuda_to_cpu(tensor);\n    }\n}\n```\n\n```js\n//norch/csrc/cuda.cu\n\n__host__ void cpu_to_cuda(Tensor* tensor) {\n    \n    float* data_tmp;\n    cudaMalloc((void **)&data_tmp, tensor->size * sizeof(float));\n    cudaMemcpy(data_tmp, tensor->data, tensor->size * sizeof(float), cudaMemcpyHostToDevice);\n\n    tensor->data = data_tmp;\n\n    const char* device_str = \"cuda\";\n    tensor->device = (char*)malloc(strlen(device_str) + 1);\n    strcpy(tensor->device, device_str); \n\n    printf(\"텐서가 성공적으로 %s로 전송되었습니다.\\n\", tensor->device);\n}\n\n__host__ void cuda_to_cpu(Tensor* tensor) {\n    float* data_tmp = (float*)malloc(tensor->size * sizeof(float));\n\n    cudaMemcpy(data_tmp, tensor->data, tensor->size * sizeof(float), cudaMemcpyDeviceToHost);\n    cudaFree(tensor->data);\n\n    tensor->data = data_tmp;\n\n    const char* device_str = \"cpu\";\n    tensor->device = (char*)malloc(strlen(device_str) + 1);\n    strcpy(tensor->device, device_str); \n\n    printf(\"텐서가 성공적으로 %s로 전송되었습니다.\\n\", tensor->device);\n}\n```\n\n\n\n파이썬으로 구현된 래퍼:\n\n```js\n# norch/tensor.py\n\ndef to(self, device):\n    self.device = device\n    self.device_ctype = self.device.encode('utf-8')\n  \n    Tensor._C.to_device.argtypes = [ctypes.POINTER(CTensor), ctypes.c_char_p]\n    Tensor._C.to_device.restype = None\n    Tensor._C.to_device(self.tensor, self.device_ctype)\n  \n    return self\n```\n\n다음으로, 모든 텐서 연산에 대해 GPU 버전을 생성합니다. 덧셈과 뺄셈에 대한 예제를 작성하겠습니다:\n\n```js\n//norch/csrc/cuda.cu\n\n#define THREADS_PER_BLOCK 128\n\n__global__ void add_tensor_cuda_kernel(float* data1, float* data2, float* result_data, int size) {\n    \n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < size) {\n        result_data[i] = data1[i] + data2[i];\n    }\n}\n\n__host__ void add_tensor_cuda(Tensor* tensor1, Tensor* tensor2, float* result_data) {\n    \n    int number_of_blocks = (tensor1->size + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;\n    add_tensor_cuda_kernel<<<number_of_blocks, THREADS_PER_BLOCK>>>(tensor1->data, tensor2->data, result_data, tensor1->size);\n\n    cudaError_t error = cudaGetLastError();\n    if (error != cudaSuccess) {\n        printf(\"CUDA error: %s\\n\", cudaGetErrorString(error));\n        exit(-1);\n    }\n\n    cudaDeviceSynchronize();\n}\n\n__global__ void sub_tensor_cuda_kernel(float* data1, float* data2, float* result_data, int size) {\n   \n    int i = blockIdx.x * blockDim.x + threadIdx.x;\n    if (i < size) {\n        result_data[i] = data1[i] - data2[i];\n    }\n}\n\n__host__ void sub_tensor_cuda(Tensor* tensor1, Tensor* tensor2, float* result_data) {\n    \n    int number_of_blocks = (tensor1->size + THREADS_PER_BLOCK - 1) / THREADS_PER_BLOCK;\n    sub_tensor_cuda_kernel<<<number_of_blocks, THREADS_PER_BLOCK>>>(tensor1->data, tensor2->data, result_data, tensor1->size);\n\n    cudaError_t error = cudaGetLastError();\n    if (error != cudaSuccess) {\n        printf(\"CUDA error: %s\\n\", cudaGetErrorString(error));\n        exit(-1);\n    }\n\n    cudaDeviceSynchronize();\n}\n\n...\n```\n\n\n\n그런 다음, 텐서.cpp에 새로운 텐서 속성 char* device를 추가하고 작업을 실행할 위치(CPU 또는 GPU)를 선택하는 데 사용할 수 있습니다:\n\n```js\n//norch/csrc/tensor.cpp\n\nTensor* add_tensor(Tensor* tensor1, Tensor* tensor2) {\n    if (tensor1->ndim != tensor2->ndim) {\n        fprintf(stderr, \"덧셈을 위해 텐서가 동일한 차원 수여야 합니다 %d and %d\\n\", tensor1->ndim, tensor2->ndim);\n        exit(1);\n    }\n\n    if (strcmp(tensor1->device, tensor2->device) != 0) {\n        fprintf(stderr, \"텐서는 동일한 장치에 있어야 합니다: %s and %s\\n\", tensor1->device, tensor2->device);\n        exit(1);\n    }\n\n    char* device = (char*)malloc(strlen(tensor1->device) + 1);\n    if (device != NULL) {\n        strcpy(device, tensor1->device);\n    } else {\n        fprintf(stderr, \"메모리 할당 실패\\n\");\n        exit(-1);\n    }\n    int ndim = tensor1->ndim;\n    int* shape = (int*)malloc(ndim * sizeof(int));\n    if (shape == NULL) {\n        fprintf(stderr, \"메모리 할당 실패\\n\");\n        exit(1);\n    }\n\n    for (int i = 0; i < ndim; i++) {\n        if (tensor1->shape[i] != tensor2->shape[i]) {\n            fprintf(stderr, \"덧셈을 위해 텐서들은 색인 %d에서 동일한 형태여야 합니다 %d and %d\\n\", i, tensor1->shape[i], tensor2->shape[i]);\n            exit(1);\n        }\n        shape[i] = tensor1->shape[i];\n    }        \n\n    if (strcmp(tensor1->device, \"cuda\") == 0) {\n\n        float* result_data;\n        cudaMalloc((void **)&result_data, tensor1->size * sizeof(float));\n        add_tensor_cuda(tensor1, tensor2, result_data);\n        return create_tensor(result_data, shape, ndim, device);\n    } \n    else {\n        float* result_data = (float*)malloc(tensor1->size * sizeof(float));\n        if (result_data == NULL) {\n            fprintf(stderr, \"메모리 할당 실패\\n\");\n            exit(1);\n        }\n        add_tensor_cpu(tensor1, tensor2, result_data);\n        return create_tensor(result_data, shape, ndim, device);\n    }     \n}\n```\n\n이제 라이브러리가 GPU 지원을 제공합니다!\n\n```js\nimport norch\n\ntensor1 = norch.Tensor([[1, 2, 3], [3, 2, 1]]).to(\"cuda\")\ntensor2 = norch.Tensor([[3, 2, 1], [1, 2, 3]]).to(\"cuda\")\n\nresult = tensor1 + tensor2\n```\n\n\n\n# #3 — Automatic Differentiation (Autograd)\n\n파이토치가 인기를 얻게 된 주요 이유 중 하나는 Autograd 모듈 때문입니다. Autograd 모듈은 자동 미분을 수행하여 기울기를 계산할 수 있게 해주는 핵심 구성 요소입니다 (경사 하강법과 같은 최적화 알고리즘을 사용하여 모델을 훈련하는 데 중요합니다). .backward()라는 단일 메서드 호출로 이전 텐서 연산에서 모든 기울기를 계산합니다:\n\n```js\nx = torch.tensor([[1., 2, 3], [3., 2, 1]], requires_grad=True)\n# [[1,  2,  3],\n#  [3,  2., 1]]\n\ny = torch.tensor([[3., 2, 1], [1., 2, 3]], requires_grad=True)\n# [[3,  2, 1],\n#  [1,  2, 3]]\n\nL = ((x - y) ** 3).sum()\n\nL.backward()\n\n# x와 y의 기울기에 접근할 수 있습니다\nprint(x.grad)\n# [[12, 0, 12],\n#  [12, 0, 12]]\n\nprint(y.grad)\n# [[-12, 0, -12],\n#  [-12, 0, -12]]\n\n# z를 최소화하기 위해서는 경사 하강법에 사용할 수 있습니다:\n# x = x - 학습률 * x.grad\n# y = y - 학습률 * y.grad\n```\n\n무슨 일이 일어나고 있는지 이해하기 위해 동일한 절차를 수동으로 복제해보겠습니다:\n\n\n\n<img src=\"/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_10.png\" />\n\n우선 계산해 봅시다:\n\n<img src=\"/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_11.png\" />\n\nx가 행렬이라는 것에 유의해야 합니다. 따라서 각 요소에 대한 L의 미분을 개별적으로 계산해야 합니다. 게다가, L은 모든 요소에 대한 합이지만 각 요소에 대한 미분에서 다른 요소들은 중요한 영향을 미치지 않는다는 것을 기억하는 것이 중요합니다. 따라서 우리는 다음과 같은 항을 얻습니다:\n\n\n\n\n![이미지](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_12.png)\n\n각 항에 대해 연쇄 법칙을 적용하여 외부 함수를 미분하고 내부 함수를 미분한 값을 곱합니다:\n\n![이미지](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_13.png)\n\nWhere:\n\n\n\n\n마침내:\n\n![이미지](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_14.png)\n\n그러므로, x에 관한 L의 미분을 계산하는 최종 방정식은 다음과 같습니다:\n\n\n\n아래는 Markdown 형식으로 변경된 내용입니다.\n\n\n![Image 1](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_16.png)\n\nSubstituting the values into the equation:\n\n![Image 2](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_17.png)\n\nCalculating the result, we get the same values we obtained with PyTorch:\n\n\n\n\n\n![image](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_18.png)\n\nNow, let’s analyze what we just did:\n\nBasically, we observed all the operations involved in reverse order: a summation, a power of 3, and a subtraction. Then, we applied the chain rule, calculating the derivative of each operation and recursively calculated the derivative for the next operation. So, first we need an implementation of the derivative for different math operations:\n\nFor addition:\n\n\n\n\n\n![Image](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_19.png)\n\n```js\n# norch/autograd/functions.py\n\nclass AddBackward:\n    def __init__(self, x, y):\n        self.input = [x, y]\n\n    def backward(self, gradient):\n        return [gradient, gradient]\n```\n\nFor sin:\n\n![Image](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_20.png)\n\n\n\n\n```js\n# norch/autograd/functions.py\n\nclass SinBackward:\n    def __init__(self, x):\n        self.input = [x]\n\n    def backward(self, gradient):\n        x = self.input[0]\n        return [x.cos() * gradient]\n```\n\n코사인에 대해:\n\n![2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_21](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_21.png)\n\n```js\n# norch/autograd/functions.py\n\nclass CosBackward:\n    def __init__(self, x):\n        self.input = [x]\n\n    def backward(self, gradient):\n        x = self.input[0]\n        return [- x.sin() * gradient]\n```\n\n\n\n요소별 곱셈에 대한 자세한 내용을 확인해보세요:\n\n![element-wise multiplication](/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_22.png)\n\n```python\n# norch/autograd/functions.py\n\nclass ElementwiseMulBackward:\n    def __init__(self, x, y):\n        self.input = [x, y]\n\n    def backward(self, gradient):\n        x = self.input[0]\n        y = self.input[1]\n        return [y * gradient, x * gradient]\n```\n\n합산에 대해서:\n\n\n\n\n# norch/autograd/functions.py\n\n```python\nclass SumBackward:\n    def __init__(self, x):\n        self.input = [x]\n\n    def backward(self, gradient):\n        # sum 함수는 텐서를 스칼라로 줄이므로 기울기를 일치시키기 위해 브로드캐스트됩니다.\n        return [float(gradient.tensor.contents.data[0]) * self.input[0].ones_like()]\n```\n\n다른 연산을 살펴볼 수 있는 GitHub 저장소 링크도 확인할 수 있습니다.\n\n이제 각 작업에 대한 도함수 식을 가졌으니, 재귀적으로 역전파 체인 규칙을 구현할 수 있습니다. 텐서에 requires_grad 인자를 설정하여 이 텐서의 기울기를 저장하려는 것을 나타낼 수 있습니다. True이면 각 텐서 작업의 기울기를 저장합니다. 예를 들어:\n\n```python\n# norch/tensor.py\n\ndef __add__(self, other):\n\n  if self.shape != other.shape:\n      raise ValueError(\"덧셈을 위해 텐서는 동일한 모양이어야 합니다.\")\n  \n  Tensor._C.add_tensor.argtypes = [ctypes.POINTER(CTensor), ctypes.POINTER(CTensor)]\n  Tensor._C.add_tensor.restype = ctypes.POINTER(CTensor)\n  \n  result_tensor_ptr = Tensor._C.add_tensor(self.tensor, other.tensor)\n  \n  result_data = Tensor()\n  result_data.tensor = result_tensor_ptr\n  result_data.shape = self.shape.copy()\n  result_data.ndim = self.ndim\n  result_data.device = self.device\n  \n  result_data.requires_grad = self.requires_grad or other.requires_grad\n  if result_data.requires_grad:\n      result_data.grad_fn = AddBackward(self, other)\n```\n\n\n\n그럼, `.backward()` 메서드를 구현해보세요:\n\n```python\n# norch/tensor.py\n\ndef backward(self, gradient=None):\n    if not self.requires_grad:\n        return\n    \n    if gradient is None:\n        if self.shape == [1]:\n            gradient = Tensor([1]) # dx/dx = 1 case\n        else:\n            raise RuntimeError(\"Gradient argument must be specified for non-scalar tensors.\")\n\n    if self.grad is None:\n        self.grad = gradient\n\n    else:\n        self.grad += gradient\n\n    if self.grad_fn is not None: # not a leaf\n        grads = self.grad_fn.backward(gradient) # call the operation backward\n        for tensor, grad in zip(self.grad_fn.input, grads):\n            if isinstance(tensor, Tensor):\n                tensor.backward(grad) # recursively call the backward again for the gradient expression (chain rule)\n```\n\n마지막으로, 텐서의 그래디언트를 제로화하는 `.zero_grad()`와 텐서의 오토그래드 히스토리를 제거하는 `.detach()`를 구현해주세요:\n\n```python\n# norch/tensor.py\n\ndef zero_grad(self):\n    self.grad = None\n\ndef detach(self):\n    self.grad = None\n    self.grad_fn = None\n```\n\n\n\n축하합니다! GPU 지원 및 자동 미분 기능이 있는 완전한 텐서 라이브러리를 만드셨군요! 이제 nn 및 optim 모듈을 만들어 몇 가지 딥 러닝 모델을 더 쉽게 훈련시킬 수 있습니다.\n\n## #4 — nn 및 optim 모듈\n\nnn은 신경망 및 딥 러닝 모델을 구축하기 위한 모듈이며, optim은 이러한 모델을 훈련시키기 위한 최적화 알고리즘과 관련이 있습니다. 이들을 재현하기 위한 첫 번째 단계는 Parameter를 구현하는 것입니다. Parameter는 간단히 말해 항상 True로 설정된 requires_grad 속성을 갖는 훈련 가능한 텐서로, 일부 임의의 초기화 기법을 사용해 같은 연산을 수행합니다.\n\n```js\n# norch/nn/parameter.py\n\nfrom norch.tensor import Tensor\nfrom norch.utils import utils\nimport random\n\nclass Parameter(Tensor):\n    \"\"\"\n    A parameter is a trainable tensor.\n    \"\"\"\n    def __init__(self, shape):\n        data = utils.generate_random_list(shape=shape)\n        super().__init__(data, requires_grad=True)\n```\n\n\n\n```js\n# norch/utisl/utils.py\n\ndef generate_random_list(shape):\n    \"\"\"\n    랜덤한 숫자로 이루어진 'shape' 형태의 리스트를 생성합니다\n    [4, 2] --> [[rand1, rand2], [rand3, rand4], [rand5, rand6], [rand7, rand8]]\n    \"\"\"\n    if len(shape) == 0:\n        return []\n    else:\n        inner_shape = shape[1:]\n        if len(inner_shape) == 0:\n            return [random.uniform(-1, 1) for _ in range(shape[0])]\n        else:\n            return [generate_random_list(inner_shape) for _ in range(shape[0])]\n```\n\n파라미터를 활용하면 모듈을 구성할 수 있습니다:\n\n```js\n# norch/nn/module.py\n\nfrom .parameter import Parameter\nfrom collections import OrderedDict\nfrom abc import ABC\nimport inspect\n\nclass Module(ABC):\n    \"\"\"\n    모듈을 위한 추상 클래스\n    \"\"\"\n    def __init__(self):\n        self._modules = OrderedDict()\n        self._params = OrderedDict()\n        self._grads = OrderedDict()\n        self.training = True\n\n    def forward(self, *inputs, **kwargs):\n        raise NotImplementedError\n\n    def __call__(self, *inputs, **kwargs):\n        return self.forward(*inputs, **kwargs)\n\n    def train(self):\n        self.training = True\n        for param in self.parameters():\n            param.requires_grad = True\n\n    def eval(self):\n        self.training = False\n        for param in self.parameters():\n            param.requires_grad = False\n\n    def parameters(self):\n        for name, value in inspect.getmembers(self):\n            if isinstance(value, Parameter):\n                yield self, name, value\n            elif isinstance(value, Module):\n                yield from value.parameters()\n\n    def modules(self):\n        yield from self._modules.values()\n\n    def gradients(self):\n        for module in self.modules():\n            yield module._grads\n\n    def zero_grad(self):\n        for _, _, parameter in self.parameters():\n            parameter.zero_grad()\n\n    def to(self, device):\n        for _, _, parameter in self.parameters():\n            parameter.to(device)\n\n        return self\n    \n    def inner_repr(self):\n        return \"\"\n\n    def __repr__(self):\n        string = f\"{self.get_name()}(\"\n        tab = \"   \"\n        modules = self._modules\n        if modules == {}:\n            string += f'\\n{tab}(parameters): {self.inner_repr()}'\n        else:\n            for key, module in modules.items():\n                string += f\"\\n{tab}({key}): {module.get_name()}({module.inner_repr()})\"\n        return f'{string}\\n)'\n    \n    def get_name(self):\n        return self.__class__.__name__\n    \n    def __setattr__(self, key, value):\n        self.__dict__[key] = value\n\n        if isinstance(value, Module):\n            self._modules[key] = value\n        elif isinstance(value, Parameter):\n            self._params[key] = value\n```\n\n예를 들어, nn.Module을 상속하여 사용자 정의 모듈을 만들거나, 이전에 생성된 모듈 중 하나인 선형 모듈을 사용하여 y = Wx + b 작업을 구현할 수 있습니다.\n\n\n\n\n```js\n# norch/nn/modules/linear.py\n\nfrom ..module import Module\nfrom ..parameter import Parameter\n\nclass Linear(Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n        self.input_dim = input_dim\n        self.output_dim = output_dim\n        self.weight = Parameter(shape=[self.output_dim, self.input_dim])\n        self.bias = Parameter(shape=[self.output_dim, 1])\n\n    def forward(self, x):\n        z = self.weight @ x + self.bias\n        return z\n\n    def inner_repr(self):\n        return f\"input_dim={self.input_dim}, output_dim={self.output_dim}, \" \\\n               f\"bias={True if self.bias is not None else False}\"\n```\n\n이제 몇 가지 손실 및 활성화 함수를 구현할 수 있습니다. 예를 들어, 평균 제곱 오차 손실 및 시그모이드 함수:\n\n```js\n# norch/nn/loss.py\n\nfrom .module import Module\n \nclass MSELoss(Module):\n    def __init__(self):\n      pass\n\n    def forward(self, predictions, labels):\n        assert labels.shape == predictions.shape, \\\n            \"Labels and predictions shape does not match: {} and {}\".format(labels.shape, predictions.shape)\n        \n        return ((predictions - labels) ** 2).sum() / predictions.numel\n\n    def __call__(self, *inputs):\n        return self.forward(*inputs)\n```\n\n```js\n# norch/nn/activation.py\n\nfrom .module import Module\nimport math\n\nclass Sigmoid(Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, x):\n        return 1.0 / (1.0 + (math.e) ** (-x)) \n```\n\n\n\n마지막으로 옵티마이저를 만들어봅시다. 예시로 확률적 경사 하강법(Stochastic Gradient Descent) 알고리즘을 구현하겠습니다:\n\n```js\n# norch/optim/optimizer.py\n\nfrom abc import ABC\nfrom norch.tensor import Tensor\n\nclass Optimizer(ABC):\n    \"\"\"\n    옵티마이저를 위한 추상 클래스\n    \"\"\"\n\n    def __init__(self, parameters):\n        if isinstance(parameters, Tensor):\n            raise TypeError(\"parameters는 반복 가능한 객체이어야 하지만 {} 타입이 입력되었습니다\".format(type(parameters)))\n        elif isinstance(parameters, dict):\n            parameters = parameters.values()\n\n        self.parameters = list(parameters)\n\n    def step(self):\n        raise NotImplementedError\n    \n    def zero_grad(self):\n        for module, name, parameter in self.parameters:\n            parameter.zero_grad()\n\n\nclass SGD(Optimizer):\n    def __init__(self, parameters, lr=1e-1, momentum=0):\n        super().__init__(parameters)\n        self.lr = lr\n        self.momentum = momentum\n        self._cache = {'velocity': [p.zeros_like() for (_, _, p) in self.parameters]}\n\n    def step(self):\n        for i, (module, name, _) in enumerate(self.parameters):\n            parameter = getattr(module, name)\n\n            velocity = self._cache['velocity'][i]\n\n            velocity = self.momentum * velocity - self.lr * parameter.grad\n\n            updated_parameter = parameter + velocity\n\n            setattr(module, name, updated_parameter)\n\n            self._cache['velocity'][i] = velocity\n\n            parameter.detach()\n            velocity.detach()\n```\n\n그리고 여기까지입니다! 이제 우리만의 딥러닝 프레임워크를 만들었어요! 🥳\n\n이제 학습을 시작해봅시다:\n\n\n\n```js\nimport norch\nimport norch.nn as nn\nimport norch.optim as optim\nimport random\nimport math\n\nrandom.seed(1)\n\nclass MyModel(nn.Module):\n    def __init__(self):\n        super(MyModel, self).__init__()\n        self.fc1 = nn.Linear(1, 10)\n        self.sigmoid = nn.Sigmoid()\n        self.fc2 = nn.Linear(10, 1)\n\n    def forward(self, x):\n        out = self.fc1(x)\n        out = self.sigmoid(out)\n        out = self.fc2(out)\n        \n        return out\n\ndevice = \"cuda\"\nepochs = 10\n\nmodel = MyModel().to(device)\ncriterion = nn.MSELoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001)\nloss_list = []\n\nx_values = [0. ,  0.4,  0.8,  1.2,  1.6,  2. ,  2.4,  2.8,  3.2,  3.6,  4. ,\n        4.4,  4.8,  5.2,  5.6,  6. ,  6.4,  6.8,  7.2,  7.6,  8. ,  8.4,\n        8.8,  9.2,  9.6, 10. , 10.4, 10.8, 11.2, 11.6, 12. , 12.4, 12.8,\n       13.2, 13.6, 14. , 14.4, 14.8, 15.2, 15.6, 16. , 16.4, 16.8, 17.2,\n       17.6, 18. , 18.4, 18.8, 19.2, 19.6, 20.]\n\ny_true = []\nfor x in x_values:\n    y_true.append(math.pow(math.sin(x), 2))\n\n\nfor epoch in range(epochs):\n    for x, target in zip(x_values, y_true):\n        x = norch.Tensor([[x]]).T\n        target = norch.Tensor([[target]]).T\n\n        x = x.to(device)\n        target = target.to(device)\n\n        outputs = model(x)\n        loss = criterion(outputs, target)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss[0]:.4f}')\n    loss_list.append(loss[0])\n\n# Epoch [1/10], Loss: 1.7035\n# Epoch [2/10], Loss: 0.7193\n# Epoch [3/10], Loss: 0.3068\n# Epoch [4/10], Loss: 0.1742\n# Epoch [5/10], Loss: 0.1342\n# Epoch [6/10], Loss: 0.1232\n# Epoch [7/10], Loss: 0.1220\n# Epoch [8/10], Loss: 0.1241\n# Epoch [9/10], Loss: 0.1270\n# Epoch [10/10], Loss: 0.1297\n```\n\n<img src=\"/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_23.png\" />\n\n성공적으로 모델이 생성되고 사용자 정의 딥러닝 프레임워크를 사용하여 훈련되었습니다!\n\n전체 코드는 여기에서 확인할 수 있습니다.\n\n\n\n# 결론\n\n이 게시물에서는 텐서와 같은 기본 개념, 어떻게 모델링되는지, CUDA 및 Autograd와 같은 고급 주제 등을 다루었습니다. 우리는 GPU 지원 및 자동 미분이 가능한 딥 러닝 프레임워크를 성공적으로 만들었습니다. 이 게시물이 여러분이 PyTorch가 어떻게 작동하는지 간략히 이해하는 데 도움이 되었으면 좋겠습니다.\n\n앞으로의 게시물에서는 분산 훈련(다중 노드/다중 GPU) 및 메모리 관리와 같은 고급 주제를 다루려고 할 것입니다. 의견이 있거나 다음에 어떤 내용을 다루길 원하시는지 댓글로 알려주세요! 읽어 주셔서 정말 감사합니다! 😊\n\n또한 최신 기사를 받아보기 위해 여기와 제 LinkedIn 프로필에서 팔로우해 주세요!\n\n\n\n# 참고 자료\n\n- [PyNorch](https://github.com) - 이 프로젝트의 GitHub 저장소 \n- [CUDA 튜토리얼](https://www.example.com/tutorial-cuda) - CUDA 작동 방식에 대한 간단한 소개\n- [PyTorch](https://pytorch.org/docs) - PyTorch 문서\n\n\n\n# MartinLwx's 블로그 - 스트라이드에 관한 튜토리얼.\n\n# 스트라이드 튜토리얼 - 스트라이드에 관한 또 다른 튜토리얼.\n\n# PyTorch 내부 구조 - PyTorch 구조에 대한 가이드.\n\n# 네츠 - NumPy를 사용한 PyTorch 재구현.\n\n\n\nMarkdown으로 표 태그를 변경하십시오.","ogImage":{"url":"/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_0.png"},"coverImage":"/assets/img/2024-05-15-RecreatingPyTorchfromScratchwithGPUSupportandAutomaticDifferentiation_0.png","tag":["Tech"],"readingTime":40},{"title":"2024년을 위한 무료 프론트엔드 및 백엔드 개발 강좌 TOP 10","description":"","date":"2024-05-15 10:30","slug":"2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024","content":"\n\n## 초보자와 중급 개발자를 위한 내가 좋아하는 무료 웹 개발 강좌\n\n![image](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_0.png)\n\n안녕하세요 여러분, 여러분이 2024년에 프론트엔드와 백엔드 개발을 배우고 무료 온라인 강좌, 튜토리얼, 그리고 책과 같은 최고의 무료 자료를 찾고 있다면 제가 맞는 장소에 오신 것을 환영합니다.\n\n이전에는 HTML, CSS, JavaScript, React, Angular, 그리고 Node.js를 배우기 위한 최고의 웹 개발 온라인 강좌를 공유한 적이 있으며, 이번 기사에서는 웹 개발을 배우기 위한 최고의 무료 온라인 강좌를 공유하려고 합니다.\n\n\n\n이 기사에는 Udemy 및 Coursera와 같은 사이트에서 무료로 가입할 수있는 무료 웹 개발 과정이 포함되어 있습니다. 이를 통해 누구나 2024년에 웹 개발에 필요한 기본 기술을 배울 수 있습니다.\n\n하지만, 먼저 프론트엔드와 백엔드를 모두 다루는 웹 개발에 대해 알려주는 최고의 무료 온라인 과정 10개로 넘어가기 전에요.\n\n웹 개발이란 인터넷에 호스팅되는 웹사이트를 개발하는 데 관련된 모든 작업을 정의하는 데 사용됩니다. 웹사이트를 개발하는 과정에는 웹 디자인, 웹 콘텐츠 개발, 서버 측 스크립팅 및 네트워크 보안 구성이 포함될 수 있습니다.\n\n웹 개발은 또한 웹사이트를 생성, 유지 관리 및 관리하기 위해 필요한 모든 다양한 작업, 작업 및 업데이트를 의미할 수도 있습니다. 좋은 웹 개발자는 최적의 성능, 속도 및 사용자 경험을 확보해야 합니다.\n\n\n\n# 2024년 초보자를 위한 최고의 무료 웹 개발 강좌 10선\n\n여기서는 7개의 최고의 무료 웹 개발 강좌 목록을 모았습니다. 계속 읽어보세요.\n\n## 1. 웹 개발자를 위한 웹 디자인: 아름다운 웹사이트 만들기\n\n이 강좌는 몇 가지 빠른 단계로 흥미로운 멋진 웹사이트를 만드는 방법을 가르치는 좋은 무료 강좌입니다. HTML과 주석 기반 의존성 주입을 효율적으로 사용할 수 있게 될 것입니다.\n\n\n\n이제 여러 웹 사이트에 대한 외부 맞춤 속성 및 빈을 구성할 수 있을 것입니다. 다양한 기능을 활용하여 올바른 방법으로 흥미로운 이메일을 보내는 방법을 배우게 될 것입니다.\n\n수업 기간: 2 시간\n\n수업 평점: 5점 중 4.4점\n\n강사: Jonas Schmeldtmann\n\n\n\n코스 비용: 무료\n\n![이미지](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_1.png)\n\n## 2. JavaScript Essentials [Udemy]\n\n이 멋진 코스에서는 JavaScript를 사용하여 아름다운 웹사이트를 구성하고 만드는 방법을 배울 수 있습니다. 또한 JavaScript를 사용하여 웹 애플리케이션을 만들 수도 있습니다. 또한 JPA와 Hibernate를 사용하여 데이터베이스에서 데이터를 저장 및 업데이트하는 방법도 배울 수 있습니다.\n\n\n\n강의 기간: 6 시간\n\n강의 평가: 5점 만점에 4.1점\n\n강사: Lawrence Turton\n\n수강료: 무료\n\n\n\n![Course Image](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_2.png)\n\n## 3. Practical PHP: Master The Basics And Code Dynamic Websites\n\n이 흥미로운 강의를 통해 PHP와 JavaScript를 사용하여 놀라운 웹 사이트를 만들 수 있습니다. HTTP 요청을 처리하는 웹 서비스 엔드포인트를 만드는 방법을 배울 것입니다. 또한 URL 쿼리 문자열 요청 매개변수를 읽고 삭제할 수도 있을 것입니다.\n\n강의 기간: 3 시간\n\n\n\n코스 평점: 5점 만점에 4.4점\n\n코스 강사: 브래드 허시와 코드 컬리지\n\n코스 가격: 무료\n\n![이미지](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_3.png)\n\n\n\n## 4. 웹 개발 체험하기: 처음부터 배우는 HTML과 CSS\n\n이 강좌는 웹 개발을 다뤄봄으로서 개발부터 배포까지 완벽한 안내서 역할을 해 줄 것입니다. HTML과 CSS를 이용해 다양한 기술로 애플리케이션을 구축하는 방법을 배울 수 있을 것입니다.\n\n수강 시간: 3 시간\n\n수강 평점: 5점 만점 중 4점\n\n\n\n강좌 강사: Bradley Berger\n\n강좌 가격: 무료\n\n![이미지](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_4.png)\n\n## 5. HTML5 및 CSS 3로 일주일 안에 첫 번째 웹사이트 만들기\n\n\n\n이 멋진 강좌를 통해 1주일만에 아름답고 기능적인 웹사이트를 만드는 방법을 배울 수 있습니다. 또한 포트폴리오에 표시할 새로운 프로젝트를 만들 수도 있습니다.\n\nSpring Data JPA를 활용하여 데이터를 저장하고 받는 방법을 배우게 될 것이며, Thymeleaf를 사용하여 데이터베이스에서 웹페이지로 데이터를 표시할 수도 있습니다.\n\n강좌 소요 시간: 3시간\n\n강좌 평가: 5점 만점 중 4.2점\n\n\n\n강좌 강사: Ryan Bernhardt\n\n강좌 가격: 무료\n\n![이미지](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_5.png)\n\n## 6. 프론트엔드 웹 개발 기초 [Udemy]\n\n\n\n이것은 웹 디자인과 웹 개발에 대해 알아야 할 모든 것을 가르쳐주는 훌륭한 무료 강좌입니다. 웹 사이트와 그 뒤에있는 데이터베이스 간의 통신 라인을 어떻게 구축할 수 있는지 배우게 될 것입니다.\n\n먼저 웹 사이트를 위한 간단한 첫 페이지를 만드는 방법을 배우게 됩니다. 게다가 웹 사이트에 도움이 될 기능적인 데이터베이스도 만들 수 있을 겁니다.\n\n강좌 기간: 1 시간\n\n강좌 평점: 5점 중 4.5점\n\n\n\n강의 강사: Davide Molin\n\n강의 가격: 무료\n\n![Course Image](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_6.png)\n\n## 7. 스프링 부트와 스프링 클라우드로 스프링 마이크로서비스 마스터하기\n\n\n\n이 코스는 Spring Cloud를 사용하여 Spring Boot Microservices를 마스터하는 데 도움이 되는 훌륭한 코스입니다. 이 코스를 통해 Java로 마이크로서비스를 만들기 위해 필요한 Spring 및 Spring Boot에 대해 모든 것을 배울 수 있습니다.\n\n코스 기간: 2 시간\n\n코스 평가: 5점 만점 중 4.4점\n\n코스 강사: Karthikeya T\n\n\n\n수업 가격: 무료\n\n![image](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_7.png)\n\n## 8. DevTools Pro: Chrome 개발자 도구 기초 [Udemy]\n\n이 강의에서는 이력서를 향상시키고 포트폴리오를 자랑하기 위해 아름다운 창조적인 웹사이트를 만드는 방법을 가르쳐줍니다. 구글 크롬 애플리케이션을 위한 간단한 웹사이트를 만드는 방법을 배울 수 있습니다. 또한 리소스를 저장하기 위해 계층적인 크롬 웹사이트를 만드는 방법도 배울 수 있습니다.\n\n\n\n강의 기간: 1시간\n\n강의 평점: 5점 만점 중 4.6점\n\n강의 강사: Rocco Balsamo\n\n강의 가격: 무료\n\n\n\n![이미지](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_8.png)\n\n## 9. 초보자를 위한 스프링 프레임워크와 의존성 주입\n\n이것은 몇 가지빠른 단계로 흥미로운 스프링 애플리케이션을 만드는 방법을 가르쳐주는 좋은 무료 강좌입니다. Java와 주석 기반의 의존성 주입을 효과적으로 사용할 수 있게 될 것입니다.\n\n다양한 환경에 대한 외부 사용자 정의 속성 및 빈을 구성할 수 있을 것입니다. 또한 Spring Boot를 사용하여 SMTP 메일을 올바른 방식으로 보내는 방법을 배우게 될 것입니다.\n\n\n\n코스 기간: 2시간\n\n코스 평점: 5점 만점에 4.4점\n\n강사: 산제이 파텔\n\n코스 가격: 무료\n\n\n\n<img src=\"/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_9.png\" />\n\n## 10. 초보자를 위한 Node JS API 개발 [무료]\n\n온라인에서 얻을 수 있는 최고의 Node JS 초보자 과정 중 하나입니다. 이 과정에서는 Node JS API 개발을 처음부터 배우게 됩니다.\n\n이 과정은 완전한 초보자들에게 게시된 가이드와 같습니다. Node JS가 무엇이며 왜 node.js를 배워야 하는지부터 시작해서, node js 개발 환경 설치 방법 및 브라우저 및 비브라우저 배경에서 JavaScript가 어떻게 실행되는지 이해할 수 있습니다.\n\n이 과정에서는 Modern JavaScript, Node JS 이벤트 루프, 비동기 프로그래밍, 노드 모듈, npm 모듈 및 직접 모듈 만들기, 서버 만들기, 데이터베이스에 연결하고 json 응답을 보내는 방법을 배울 수 있습니다.\n\n이 과정은 이론과 실습의 아주 좋은 조화를 갖추고 있어 무료 강좌로는 매우 어려운 것입니다.\n\n\n\n이 무료 강의에 참여할 수 있는 링크입니다 - Node JS API 개발\n\n![Node JS API Development](/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_10.png)\n\n2024년에 참여할 수 있는 최고의 10개 무료 웹 개발 강좌에 대해 알아보았습니다. JavaScript, PHP 및 Java 개발자를 위한 무료 웹 개발 강좌를 모두 포함했습니다. 프론트엔드 개발과 백엔드 개발 강좌 모두를 조화롭게 섞어 웹 개발을 깊이 있게 학습하고 풀스택 개발자로 거듭날 수 있도록 노력했습니다.\n\n이 10개의 최고의 무료 웹 개발 강좌 목록이 마음에 드신다면 친구나 가족과 자유롭게 공유해보세요.\n\n\n\n웹 개발 분야에 의문이 생기면 언제든지 댓글을 달아주세요. 저희가 즉시 답변해 드릴 거에요. 이 강좌들은 몇 주 만에 완전 초보자에서 숙련된 웹 개발자로 변신할 수 있을 거라고 확신해요.\n\n다른 웹 개발자를 위한 리소스:\n\n- 웹 개발을 배우기 위한 최고 5개 강좌\n- React 프레임워크를 학습하기 위한 최고 5개 강좌\n- 2024년 웹 개발자로 거듭나는 방법\n- 초보자를 위한 Node.js 학습을 위한 최상의 10개 강좌\n- 풀 스택 개발자가 되기 위한 최상의 10개 강좌\n- 초보자를 위한 Angular 학습을 위한 10개의 무료 강좌\n- 2024년 React 개발자 로드맵\n- 웹 개발 배우기에 늦은 게 아냐\n- 2024년 React 학습을 위한 10개의 무료 강좌\n- 웹 개발자 로드맵 (프론트엔드 + 백엔드)\n- 웹 개발자를 위한 5개의 HTML 및 CSS 무료 강좌\n- 프로그래머를 위한 Java 및 웹 개발 강좌 10개\n- 모든 소프트웨어 엔지니어가 배워야 할 10가지\n- 2024년에 Java 및 웹 개발자가 배울 수 있는 10가지 프레임워크\n\n이 글을 읽어 주셔서 감사해요. 만약 이러한 최고의 무료 프론트엔드 및 백엔드 개발 강좌를 좋아하신다면, 친구들과 동료들과 공유해 주세요. 궁금한 점이나 피드백이 있으면 남겨주세요.\n\n참고 - Node.js와 같이 가치 있는 것을 배우기 위해 약간의 돈을 지불해도 된다면, Udemy의 Andrew Mead나 Rob Percival과 같은 전문가들의 Node.js 강좌 목록도 확인해 보시기를 권유합니다.","ogImage":{"url":"/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_0.png"},"coverImage":"/assets/img/2024-05-15-Top10FreeFrontendandBackendDevelopmentCoursesin2024_0.png","tag":["Tech"],"readingTime":6}],"page":"98","totalPageCount":156,"totalPageGroupCount":8,"lastPageGroup":20,"currentPageGroup":4},"__N_SSG":true}