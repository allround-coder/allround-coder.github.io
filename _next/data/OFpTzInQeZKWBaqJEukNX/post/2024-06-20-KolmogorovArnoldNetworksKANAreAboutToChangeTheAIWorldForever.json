{"pageProps":{"post":{"title":"콜모고로프-아놀드 네트워크KAN가 인공지능 세계를 영원히 바꿀 것입니다","description":"","date":"2024-06-20 04:51","slug":"2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever","content":"\n\n## 신경망에 대해 알고 있던 모든 것을 잊어버리세요, KAN이 규칙을 다시 쓸 예정입니다\n\n![image](/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_0.png)\n\n# 소개:\n\n머신 러닝의 계속 변화하는 풍경 속에서 최근 발표된 \"KAN: Kolmogorov-Arnold Network\"라는 연구 논문은 열광적인 열기를 불러일으켰습니다. 이 혁신적인 접근 방식은 다층 퍼셉트론(MLP)의 전통적인 지혜에 도전하여 신경망 구조에 대한 새로운 시각을 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n# 콜모고로프-아놀드 네트워크 (KAN's)란 무엇인가요:\n\n이 혁신적인 개념의 핵심에는 Vladimir Arnold와 Andrey Kolmogorov가 개발한 수학 이론인 콜모고로프-아놀드 표현 정리가 있습니다. 이 정리는 복잡한 다변수 함수를 보다 간단한 일차원 함수로 분해할 수 있음을 주장하여 KAN의 독특한 구조의 기초를 제공합니다.\n\n![이미지](/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_1.png)\n\n이제 당연한 질문은 이 \"더 간단한 일차원 함수\"가 무엇인가요. 수학 또는 컴퓨터 그래픽을 조금 알고 있는 사람이라면, 우리가 말하는 것은 옛날부터 신뢰받는 조각별 다항식인 Spline입니다.\n\n<div class=\"content-ad\"></div>\n\n\n![image](https://miro.medium.com/v2/resize:fit:1400/1*1VcxJSh_CYAPc9-0os2-pA.gif)\n\n# KAN의 시크릿 소스, 스플라인!\n\n스플라인은 연속 점들을 연결하여 부드러운 곡선을 생성할 수 있는 수학적 함수입니다. 스플라인은 인접 세그먼트 사이의 연속성과 부드러움을 보장하면서 곡선의 모양을 조절하는 유연성을 제공합니다.\n\n스플라인을 생성하기 위해 일반적으로 곡선의 경로를 정의하는 일련의 제어점을 시작점으로 삼습니다. 그런 다음, B-스플라인이나 베지에 곡선과 같은 기저 함수를 사용하여 이러한 제어점 사이의 경로를 보간하거나 근사합니다.\n\n\n<div class=\"content-ad\"></div>\n\n![이미지](https://miro.medium.com/v2/resize:fit:1400/1*B1MXmHF8xD_WP3GJNwbfDQ.gif)\n\n기본적으로 스플라인은 복잡한 곡선이나 표면을 정밀하고 유연하게 표현하는 다재다능한 도구를 제공하여 다양한 분야에서 귀중하게 활용됩니다.\n\n하지만, KAN 아키텍처에서 이러한 스플라인을 어떻게 사용하고 적용할까요?\n\n# KAN 작동 방식을 이해하는 가장 간단한 방법\n\n<div class=\"content-ad\"></div>\n\n전통적인 MLP들과 달리 KAN은 고정된 활성화 함수를 학습 가능한 기능(B-Splines)으로 대체하여 네트워크의 가장자리를 따라 작동합니다.\n\n이 적응형 아키텍처를 통해 KAN은 복잡한 함수를 효과적으로 모델링하면서 해석 가능성을 유지하고 필요한 매개변수의 수를 줄일 수 있습니다.\n\n![image](https://miro.medium.com/v2/resize:fit:1200/1*5hfRk7kjl-CZvyhpbfKlsw.gif)\n\nMLP의 경우 신호를 전달하는 수동적인 수단으로 기능하는 것과 달리, KAN의 뉴런들은 학습 프로세스의 적극적인 참여자로서 동적으로 동작을 조정하여 마주치는 데이터에 대응합니다.\n\n<div class=\"content-ad\"></div>\n\n네트워크의 가장자리에 배치된 학습 가능한 활성화 함수를 도입하여 가능해진 이 혁신적인 전환은, 네트워크의 에지에 배치된 학습 가능한 활성화 함수를 통해 가능케 되었습니다.\n\n![이미지](/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_2.png)\n\nB-스플라인의 표현력을 이용하여, 이러한 함수들은 KAN에 무궁무진한 유연성과 적응성을 부여하여, 복잡한 데이터 환경을 쉽게 탐색할 수 있게 만들어줍니다.\n\n# KAN의 주요 장점:\n\n<div class=\"content-ad\"></div>\n\n## 향상된 확장성\n\nKAN은 특히 고차원 데이터 시나리오에서 MLP에 비해 우수한 확장성을 보여줍니다. 복잡한 함수를 간단한 구성 요소로 분해하는 능력으로 대용량 데이터를 효율적으로 처리할 수 있어서 방대한 양의 정보가 포함된 작업에 이상적입니다.\n\n## 향상된 정확성\n\n더 적은 매개변수를 사용하더라도 KAN은 다양한 작업에 걸쳐 전통적인 MLP보다 더 높은 정확도와 낮은 손실을 달성합니다. 이는 데이터 내에서 관계를 적응적으로 모델링하는 능력 때문에, 보다 정확한 예측과 보다 잘 일반화된 결과를 얻을 수 있다고 이해됩니다.\n\n<div class=\"content-ad\"></div>\n\n## 해석 가능한 모델\n\nKAN의 구조는 해석 가능성을 용이하게 하여 연구자들이 학습된 패턴을 효과적으로 나타내는 상징적인 공식을 도출할 수 있게 합니다. 블랙박스 모델과는 달리, KAN은 입력 특성이 네트워크 전반에 걸쳐 어떻게 변환되는지에 대한 통찰을 제공하여 투명성과 이해를 높입니다.\n\n이제 KAN이 무엇이며 왜 인공지능 분야에서 큰 문제인지를 알게 되었지만, 세상은 이론과 논문에서 멋져 보이는 모델로만 움직이는 것이 아닙니다.\n\n하지만 KAN의 가장 좋은 점은 새로운 Python 라이브러리 \"PyKAN\"을 사용하여 자신의 데이터 과학 문제에 쉽고 간단하게 적용할 수 있다는 것입니다.\n\n<div class=\"content-ad\"></div>\n\n위의 텍스트를 친근한 어조로 한국어로 번역하겠습니다.\n\n우리의 토론을 파이썬으로 이 아키텍처를 어떻게 구현할 수 있는지 예제와 함께 마무리해봅시다.\n\n# Python에서 KAN의 구현 (PyKAN):\n\n우리의 데모를 위해 분류 문제를 사용해봅시다.\n\n## 데이터셋 생성\n\n<div class=\"content-ad\"></div>\n\nsklearn 라이브러리의 \"make_moons\" 함수를 사용하여 합성 데이터 세트를 생성할 예정이에요.\n\n```js\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import make_moons\nimport torch\nimport numpy as np\n\ndataset = {}\ntrain_input, train_label = make_moons(n_samples=1000, shuffle=True, noise=0.1, random_state=None)\ntest_input, test_label = make_moons(n_samples=1000, shuffle=True, noise=0.1, random_state=None)\n\ndataset['train_input'] = torch.from_numpy(train_input)\ndataset['test_input'] = torch.from_numpy(test_input)\ndataset['train_label'] = torch.from_numpy(train_label)\ndataset['test_label'] = torch.from_numpy(test_label)\n\nX = dataset['train_input']\ny = dataset['train_label']\nplt.scatter(X[:,0], X[:,1], c=y[:])\n```\n\n## 결과 (시각화된 데이터셋)\n\n<img src=\"/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_3.png\" />\n\n<div class=\"content-ad\"></div>\n\n## KAN 생성 및 훈련\n\n```js\nfrom kan import KAN\n\nmodel = KAN(width=[2,2], grid=3, k=3)\n\ndef train_acc():\n    return torch.mean((torch.argmax(model(dataset['train_input']), \n    dim=1) == dataset['train_label']).float())\n\ndef test_acc():\n    return torch.mean((torch.argmax(model(dataset['test_input']), \n    dim=1) == dataset['test_label']).float())\n\nresults = model.train(dataset, opt=\"LBFGS\", steps=20, \n          metrics=(train_acc, test_acc), \n          loss_fn=torch.nn.CrossEntropyLoss())\n```\n\n## 모델로부터 심볼릭 공식 획득\n\n이후, 모델이 데이터로부터 학습한 내용을 나타내는 심볼릭 공식이 유도됩니다.\n\n<div class=\"content-ad\"></div>\n\n```python\nformula1, formula2 = model.symbolic_formula()[0]\n```\n\n## 정확도 계산하기\n\n마지막으로 학습된 공식에서 정확도를 얻을 수 있습니다.\n\n```python\ndef acc(formula1, formula2, X, y):\n    batch = X.shape[0]\n    correct = 0\n    for i in range(batch):\n\n        logit1 = np.array(formula1.subs('x_1', X[i,0]).subs('x_2', X[i,1])).astype(np.float64)\n        logit2 = np.array(formula2.subs('x_1', X[i,0]).subs('x_2', X[i,1])).astype(np.float64)\n\n        correct += (logit2 > logit1) == y[i]\n\n    return correct/batch\n\n# 정확도 출력\nprint('학습 데이터 정확도:', acc(formula1, formula2, dataset['train_input'], dataset['train_label']))\n\nprint('테스트 데이터 정확도:', acc(formula1, formula2, dataset['test_input'], dataset['test_label']))\n```\n\n<div class=\"content-ad\"></div>\n\n## 결과\n\n```js\n수식의 학습 정확도: tensor(0.9700)\n수식의 테스트 정확도: tensor(0.9660)\n```\n\n# 결론\n\n요약하자면, 콜모고로프-아놀드 네트워크(KANs)는 신경망 구조에서 패러다임 전환을 나타냅니다. KANs는 잠재력을 최대로 발휘하기 위해 추가 연구와 실험이 필요하지만, 앞으로 몇 년 동안 기계 학습과 과학적 발견을 진전시키는 데 유용한 도구로서의 가능성을 갖고 있습니다.\n\n<div class=\"content-ad\"></div>\n\n계속 발전하는 이 분야에서 KAN은 혁신의 선두에 서 있습니다. 지능 시스템의 미래를 형성하고 복잡한 데이터 분석과 모델링 방식을 혁명화하고 있습니다.","ogImage":{"url":"/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_0.png"},"coverImage":"/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_0.png","tag":["Tech"],"readingTime":6},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<h2>신경망에 대해 알고 있던 모든 것을 잊어버리세요, KAN이 규칙을 다시 쓸 예정입니다</h2>\n<p><img src=\"/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_0.png\" alt=\"image\"></p>\n<h1>소개:</h1>\n<p>머신 러닝의 계속 변화하는 풍경 속에서 최근 발표된 \"KAN: Kolmogorov-Arnold Network\"라는 연구 논문은 열광적인 열기를 불러일으켰습니다. 이 혁신적인 접근 방식은 다층 퍼셉트론(MLP)의 전통적인 지혜에 도전하여 신경망 구조에 대한 새로운 시각을 제공합니다.</p>\n<div class=\"content-ad\"></div>\n<h1>콜모고로프-아놀드 네트워크 (KAN's)란 무엇인가요:</h1>\n<p>이 혁신적인 개념의 핵심에는 Vladimir Arnold와 Andrey Kolmogorov가 개발한 수학 이론인 콜모고로프-아놀드 표현 정리가 있습니다. 이 정리는 복잡한 다변수 함수를 보다 간단한 일차원 함수로 분해할 수 있음을 주장하여 KAN의 독특한 구조의 기초를 제공합니다.</p>\n<p><img src=\"/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_1.png\" alt=\"이미지\"></p>\n<p>이제 당연한 질문은 이 \"더 간단한 일차원 함수\"가 무엇인가요. 수학 또는 컴퓨터 그래픽을 조금 알고 있는 사람이라면, 우리가 말하는 것은 옛날부터 신뢰받는 조각별 다항식인 Spline입니다.</p>\n<div class=\"content-ad\"></div>\n<p><img src=\"https://miro.medium.com/v2/resize:fit:1400/1*1VcxJSh_CYAPc9-0os2-pA.gif\" alt=\"image\"></p>\n<h1>KAN의 시크릿 소스, 스플라인!</h1>\n<p>스플라인은 연속 점들을 연결하여 부드러운 곡선을 생성할 수 있는 수학적 함수입니다. 스플라인은 인접 세그먼트 사이의 연속성과 부드러움을 보장하면서 곡선의 모양을 조절하는 유연성을 제공합니다.</p>\n<p>스플라인을 생성하기 위해 일반적으로 곡선의 경로를 정의하는 일련의 제어점을 시작점으로 삼습니다. 그런 다음, B-스플라인이나 베지에 곡선과 같은 기저 함수를 사용하여 이러한 제어점 사이의 경로를 보간하거나 근사합니다.</p>\n<div class=\"content-ad\"></div>\n<p><img src=\"https://miro.medium.com/v2/resize:fit:1400/1*B1MXmHF8xD_WP3GJNwbfDQ.gif\" alt=\"이미지\"></p>\n<p>기본적으로 스플라인은 복잡한 곡선이나 표면을 정밀하고 유연하게 표현하는 다재다능한 도구를 제공하여 다양한 분야에서 귀중하게 활용됩니다.</p>\n<p>하지만, KAN 아키텍처에서 이러한 스플라인을 어떻게 사용하고 적용할까요?</p>\n<h1>KAN 작동 방식을 이해하는 가장 간단한 방법</h1>\n<div class=\"content-ad\"></div>\n<p>전통적인 MLP들과 달리 KAN은 고정된 활성화 함수를 학습 가능한 기능(B-Splines)으로 대체하여 네트워크의 가장자리를 따라 작동합니다.</p>\n<p>이 적응형 아키텍처를 통해 KAN은 복잡한 함수를 효과적으로 모델링하면서 해석 가능성을 유지하고 필요한 매개변수의 수를 줄일 수 있습니다.</p>\n<p><img src=\"https://miro.medium.com/v2/resize:fit:1200/1*5hfRk7kjl-CZvyhpbfKlsw.gif\" alt=\"image\"></p>\n<p>MLP의 경우 신호를 전달하는 수동적인 수단으로 기능하는 것과 달리, KAN의 뉴런들은 학습 프로세스의 적극적인 참여자로서 동적으로 동작을 조정하여 마주치는 데이터에 대응합니다.</p>\n<div class=\"content-ad\"></div>\n<p>네트워크의 가장자리에 배치된 학습 가능한 활성화 함수를 도입하여 가능해진 이 혁신적인 전환은, 네트워크의 에지에 배치된 학습 가능한 활성화 함수를 통해 가능케 되었습니다.</p>\n<p><img src=\"/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_2.png\" alt=\"이미지\"></p>\n<p>B-스플라인의 표현력을 이용하여, 이러한 함수들은 KAN에 무궁무진한 유연성과 적응성을 부여하여, 복잡한 데이터 환경을 쉽게 탐색할 수 있게 만들어줍니다.</p>\n<h1>KAN의 주요 장점:</h1>\n<div class=\"content-ad\"></div>\n<h2>향상된 확장성</h2>\n<p>KAN은 특히 고차원 데이터 시나리오에서 MLP에 비해 우수한 확장성을 보여줍니다. 복잡한 함수를 간단한 구성 요소로 분해하는 능력으로 대용량 데이터를 효율적으로 처리할 수 있어서 방대한 양의 정보가 포함된 작업에 이상적입니다.</p>\n<h2>향상된 정확성</h2>\n<p>더 적은 매개변수를 사용하더라도 KAN은 다양한 작업에 걸쳐 전통적인 MLP보다 더 높은 정확도와 낮은 손실을 달성합니다. 이는 데이터 내에서 관계를 적응적으로 모델링하는 능력 때문에, 보다 정확한 예측과 보다 잘 일반화된 결과를 얻을 수 있다고 이해됩니다.</p>\n<div class=\"content-ad\"></div>\n<h2>해석 가능한 모델</h2>\n<p>KAN의 구조는 해석 가능성을 용이하게 하여 연구자들이 학습된 패턴을 효과적으로 나타내는 상징적인 공식을 도출할 수 있게 합니다. 블랙박스 모델과는 달리, KAN은 입력 특성이 네트워크 전반에 걸쳐 어떻게 변환되는지에 대한 통찰을 제공하여 투명성과 이해를 높입니다.</p>\n<p>이제 KAN이 무엇이며 왜 인공지능 분야에서 큰 문제인지를 알게 되었지만, 세상은 이론과 논문에서 멋져 보이는 모델로만 움직이는 것이 아닙니다.</p>\n<p>하지만 KAN의 가장 좋은 점은 새로운 Python 라이브러리 \"PyKAN\"을 사용하여 자신의 데이터 과학 문제에 쉽고 간단하게 적용할 수 있다는 것입니다.</p>\n<div class=\"content-ad\"></div>\n<p>위의 텍스트를 친근한 어조로 한국어로 번역하겠습니다.</p>\n<p>우리의 토론을 파이썬으로 이 아키텍처를 어떻게 구현할 수 있는지 예제와 함께 마무리해봅시다.</p>\n<h1>Python에서 KAN의 구현 (PyKAN):</h1>\n<p>우리의 데모를 위해 분류 문제를 사용해봅시다.</p>\n<h2>데이터셋 생성</h2>\n<div class=\"content-ad\"></div>\n<p>sklearn 라이브러리의 \"make_moons\" 함수를 사용하여 합성 데이터 세트를 생성할 예정이에요.</p>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">import</span> matplotlib.<span class=\"hljs-property\">pyplot</span> <span class=\"hljs-keyword\">as</span> plt\n<span class=\"hljs-keyword\">from</span> sklearn.<span class=\"hljs-property\">datasets</span> <span class=\"hljs-keyword\">import</span> make_moons\n<span class=\"hljs-keyword\">import</span> torch\n<span class=\"hljs-keyword\">import</span> numpy <span class=\"hljs-keyword\">as</span> np\n\ndataset = {}\ntrain_input, train_label = <span class=\"hljs-title function_\">make_moons</span>(n_samples=<span class=\"hljs-number\">1000</span>, shuffle=<span class=\"hljs-title class_\">True</span>, noise=<span class=\"hljs-number\">0.1</span>, random_state=<span class=\"hljs-title class_\">None</span>)\ntest_input, test_label = <span class=\"hljs-title function_\">make_moons</span>(n_samples=<span class=\"hljs-number\">1000</span>, shuffle=<span class=\"hljs-title class_\">True</span>, noise=<span class=\"hljs-number\">0.1</span>, random_state=<span class=\"hljs-title class_\">None</span>)\n\ndataset[<span class=\"hljs-string\">'train_input'</span>] = torch.<span class=\"hljs-title function_\">from_numpy</span>(train_input)\ndataset[<span class=\"hljs-string\">'test_input'</span>] = torch.<span class=\"hljs-title function_\">from_numpy</span>(test_input)\ndataset[<span class=\"hljs-string\">'train_label'</span>] = torch.<span class=\"hljs-title function_\">from_numpy</span>(train_label)\ndataset[<span class=\"hljs-string\">'test_label'</span>] = torch.<span class=\"hljs-title function_\">from_numpy</span>(test_label)\n\nX = dataset[<span class=\"hljs-string\">'train_input'</span>]\ny = dataset[<span class=\"hljs-string\">'train_label'</span>]\nplt.<span class=\"hljs-title function_\">scatter</span>(X[:,<span class=\"hljs-number\">0</span>], X[:,<span class=\"hljs-number\">1</span>], c=y[:])\n</code></pre>\n<h2>결과 (시각화된 데이터셋)</h2>\n<img src=\"/assets/img/2024-06-20-KolmogorovArnoldNetworksKANAreAboutToChangeTheAIWorldForever_3.png\">\n<div class=\"content-ad\"></div>\n<h2>KAN 생성 및 훈련</h2>\n<pre><code class=\"hljs language-js\"><span class=\"hljs-keyword\">from</span> kan <span class=\"hljs-keyword\">import</span> <span class=\"hljs-variable constant_\">KAN</span>\n\nmodel = <span class=\"hljs-title function_\">KAN</span>(width=[<span class=\"hljs-number\">2</span>,<span class=\"hljs-number\">2</span>], grid=<span class=\"hljs-number\">3</span>, k=<span class=\"hljs-number\">3</span>)\n\ndef <span class=\"hljs-title function_\">train_acc</span>():\n    <span class=\"hljs-keyword\">return</span> torch.<span class=\"hljs-title function_\">mean</span>((torch.<span class=\"hljs-title function_\">argmax</span>(<span class=\"hljs-title function_\">model</span>(dataset[<span class=\"hljs-string\">'train_input'</span>]), \n    dim=<span class=\"hljs-number\">1</span>) == dataset[<span class=\"hljs-string\">'train_label'</span>]).<span class=\"hljs-title function_\">float</span>())\n\ndef <span class=\"hljs-title function_\">test_acc</span>():\n    <span class=\"hljs-keyword\">return</span> torch.<span class=\"hljs-title function_\">mean</span>((torch.<span class=\"hljs-title function_\">argmax</span>(<span class=\"hljs-title function_\">model</span>(dataset[<span class=\"hljs-string\">'test_input'</span>]), \n    dim=<span class=\"hljs-number\">1</span>) == dataset[<span class=\"hljs-string\">'test_label'</span>]).<span class=\"hljs-title function_\">float</span>())\n\nresults = model.<span class=\"hljs-title function_\">train</span>(dataset, opt=<span class=\"hljs-string\">\"LBFGS\"</span>, steps=<span class=\"hljs-number\">20</span>, \n          metrics=(train_acc, test_acc), \n          loss_fn=torch.<span class=\"hljs-property\">nn</span>.<span class=\"hljs-title class_\">CrossEntropyLoss</span>())\n</code></pre>\n<h2>모델로부터 심볼릭 공식 획득</h2>\n<p>이후, 모델이 데이터로부터 학습한 내용을 나타내는 심볼릭 공식이 유도됩니다.</p>\n<div class=\"content-ad\"></div>\n<pre><code class=\"hljs language-python\">formula1, formula2 = model.symbolic_formula()[<span class=\"hljs-number\">0</span>]\n</code></pre>\n<h2>정확도 계산하기</h2>\n<p>마지막으로 학습된 공식에서 정확도를 얻을 수 있습니다.</p>\n<pre><code class=\"hljs language-python\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title function_\">acc</span>(<span class=\"hljs-params\">formula1, formula2, X, y</span>):\n    batch = X.shape[<span class=\"hljs-number\">0</span>]\n    correct = <span class=\"hljs-number\">0</span>\n    <span class=\"hljs-keyword\">for</span> i <span class=\"hljs-keyword\">in</span> <span class=\"hljs-built_in\">range</span>(batch):\n\n        logit1 = np.array(formula1.subs(<span class=\"hljs-string\">'x_1'</span>, X[i,<span class=\"hljs-number\">0</span>]).subs(<span class=\"hljs-string\">'x_2'</span>, X[i,<span class=\"hljs-number\">1</span>])).astype(np.float64)\n        logit2 = np.array(formula2.subs(<span class=\"hljs-string\">'x_1'</span>, X[i,<span class=\"hljs-number\">0</span>]).subs(<span class=\"hljs-string\">'x_2'</span>, X[i,<span class=\"hljs-number\">1</span>])).astype(np.float64)\n\n        correct += (logit2 > logit1) == y[i]\n\n    <span class=\"hljs-keyword\">return</span> correct/batch\n\n<span class=\"hljs-comment\"># 정확도 출력</span>\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">'학습 데이터 정확도:'</span>, acc(formula1, formula2, dataset[<span class=\"hljs-string\">'train_input'</span>], dataset[<span class=\"hljs-string\">'train_label'</span>]))\n\n<span class=\"hljs-built_in\">print</span>(<span class=\"hljs-string\">'테스트 데이터 정확도:'</span>, acc(formula1, formula2, dataset[<span class=\"hljs-string\">'test_input'</span>], dataset[<span class=\"hljs-string\">'test_label'</span>]))\n</code></pre>\n<div class=\"content-ad\"></div>\n<h2>결과</h2>\n<pre><code class=\"hljs language-js\">수식의 학습 정확도: <span class=\"hljs-title function_\">tensor</span>(<span class=\"hljs-number\">0.9700</span>)\n수식의 테스트 정확도: <span class=\"hljs-title function_\">tensor</span>(<span class=\"hljs-number\">0.9660</span>)\n</code></pre>\n<h1>결론</h1>\n<p>요약하자면, 콜모고로프-아놀드 네트워크(KANs)는 신경망 구조에서 패러다임 전환을 나타냅니다. KANs는 잠재력을 최대로 발휘하기 위해 추가 연구와 실험이 필요하지만, 앞으로 몇 년 동안 기계 학습과 과학적 발견을 진전시키는 데 유용한 도구로서의 가능성을 갖고 있습니다.</p>\n<div class=\"content-ad\"></div>\n<p>계속 발전하는 이 분야에서 KAN은 혁신의 선두에 서 있습니다. 지능 시스템의 미래를 형성하고 복잡한 데이터 분석과 모델링 방식을 혁명화하고 있습니다.</p>\n</body>\n</html>\n"},"__N_SSG":true}