{"pageProps":{"post":{"title":"2024년에 AI 배우는 로드맵","description":"","date":"2024-06-22 04:41","slug":"2024-06-22-RoadmaptoLearnAIin2024","content":"\n\n## AI를 배우고 싶나요?\n\n![AI 학습 로드맵](/assets/img/2024-06-22-RoadmaptoLearnAIin2024_0.png)\n\nAI를 배우고 싶지만 어떻게 시작해야 할지 모르시나요?\n\n저는 2020년에 무료 데이터 과학, 기계 학습 및 AI MOOC의 베스트 20을 작성했어요. 하지만 많은 강의를 듣는 것이 답은 아니라는 것을 깨달았죠.\n\n<div class=\"content-ad\"></div>\n\n튜토리얼 지옥을 벗어나서 진짜로 배우려면 손을 더럽히고, 알고리즘을 제로부터 짜고, 논문들을 구현하며, AI를 활용하여 재미있는 부수 프로젝트를 해결하는 게 중요해요.\n\n본 문서는 이 철학을 따르는 무료 커리큘럼을 작성하려고 노력했어요. 저는 이 중 일부 강좌를 진행하고 있는데요, 함께 공부하고 싶다면 트위터나 링크드인을 통해 연락해주세요!\n\n그리고 이 내용에 빠진 부분이 있다고 생각되면 댓글을 남겨주세요!\n\n하지만 먼저, 커리큘럼에 대한 몇 가지 주의사항과 학습 팁을 전해드릴게요.\n\n<div class=\"content-ad\"></div>\n\n# Top-down 방식\n\n이 교육과정은 top-down 방식을 따릅니다 — 코드를 먼저 작성하고 이론을 나중에 다룹니다.\n\n저는 필요에 의해 배우는 것을 좋아합니다. 그래서, 무언가를 해결해야 하거나 프로토 타입을 만들어야 할 때, 필요한 정보를 넓고 넒게 찾아서 해당 정보를 공부하고 이해한 후에 행동으로 옮깁니다.\n\n예를 들어, 저는 기본 수준에서 LLMs를 이해하는 AI 엔지니어가 되고 싶습니다. 이를 위해서는 transformer를 처음부터 코딩하고 GPU에서 LLMs를 세밀하게 튜닝하는 기술이 필요합니다. 지금은 그것을 할 수 없습니다. 왜냐하면 제 지식에는 여전히 빈틈이 있기 때문에 그 빈틈을 채우고자 하는 목표가 있습니다.\n\n<div class=\"content-ad\"></div>\n\n이것은 NLP에 중점을 둔 것입니다. 컴퓨터 비전이나 강화 학습과 같은 다른 AI 전문화를 찾고 계신 경우, 아래에 댓글을 남기거나 Twitter 또는 Linkedin에서 DM으로 연락해주세요. 추천 몇 가지를 전해 드릴게요.\n\n링크를 많이 던지기 전에 제가 무언가를 배우기 시작하기 전에 중요한 두 가지를 알았더라면 좋았을 텐데요.\n\n# 공개로 배우세요\n\n배워야 할 것이 많고, 특히 AI에서는 매주 새로운 혁명적인 논문과 아이디어들이 나오기 때문에 학습이 끝나지 않을 것입니다.\n\n<div class=\"content-ad\"></div>\n\n가장 큰 실수는 혼자서 배우는 것입니다. 그렇게 하면 자신에게 어떤 기회도 만들지 못합니다. 완료했다고 말할 수 있는 것을 제외하고는 보여줄 것이 없습니다. 더 중요한 것은 정보를 어떻게 활용하여 공유할지, 그 정보에서 어떤 혁신적인 아이디어와 해결책이 나왔는지입니다.\n\n그러니까, 공개적으로 배워야 합니다.\n\n종합하자면, 만드는 습관을 가져야 합니다.\n\n이것은 다음을 의미할 수 있습니다:\n\n<div class=\"content-ad\"></div>\n\n- 블로그와 튜토리얼 작성\n- 해커톤 참여 및 다른 사람들과 협업\n- 디스코드 커뮤니티에서 질문하고 대답하기\n- 열정적으로 하는 사이드 프로젝트에 참여\n- 새롭게 발견한 흥미로운 것에 대해 트윗하기\n\n그리고 트위터에 대해 이야기할 때,\n\n# 트위터 사용하기\n\n적절한 사람을 팔로우하고 올바르게 활용한다면, 오늘날 누구나 함께 있어야 할 가치가 가장 높은 소셜 플랫폼입니다.\n\n<div class=\"content-ad\"></div>\n\n누구를 팔로우해야 하는지 궁금하다면 Suhail이 제작한 이 AI 목록을 확인해보세요.\n\nTwitter를 어떻게 사용해야 할지 궁금하다면 Near의 \"Twitter 성공 가이드\"를 읽어보세요.\n\nTwitter에서 사람들에게 다이렉트 메시지를 보내려면 진실하고 간결하며 구체적인 요청을 하는 게 중요해요. Sriram Krishnan의 \"차가운 이메일 작성 방법\" 가이드도 DM에 적용할 수 있어요.\n\n트윗하는 법이 알고 싶다면, Instructor의 창시자 Jason이 작성한 \"트윗의 구성 요소\"를 읽어보세요. 그는 0명에서 단 몇 달 사이에 14,000명의 팔로워를 얻었답니다.\n\n<div class=\"content-ad\"></div>\n\n만약 이 문구를 읽고 계시다면, 트위터로 저를 팔로우해 주세요!\n\n무엇을 하고 있는지 메시지를 보내주세요! 멋진 프로젝트에 함께 참여하는 것을 항상 기대하고 있습니다.\n\n이제 시작해 봅시다.\n\n## 목차\n\n<div class=\"content-ad\"></div>\n\n- 수학\n- 도구\n   - Python\n   - PyTorch\n- 머신 러닝\n   - 처음부터 작성\n   - 경쟁\n   - 사이드 프로젝트 수행\n   - 배포\n   - 부가적인 활동\n- 딥러닝\n   - Fast.ai\n   - 더 많은 경쟁 참여\n   - 논문 구현\n   - 컴퓨터 비전\n   - NLP\n- 대규모 언어 모델\n   - Neural Networks: Zero to Hero 시청\n   - 무료 LLM 부트캠프\n   - LLM으로 빌드\n   - 해커톤 참여\n   - 논문 읽기\n   - 처음부터 Transformers 작성\n   - 일부 좋은 블로그\n   - Umar Jamil 시청\n   - 오픈소스 모델 실행 방법 익히기\n   - 프롬프트 엔지니어링\n   - LLM 세밀 조정\n   - RAG\n- 최신 정보 유지 방법\n- 유용한 다른 커리큘럼/리스트들 \n\n# 수학\n\n<div>\n   <img src=\"/assets/img/2024-06-22-RoadmaptoLearnAIin2024_1.png\" />\n</div>\n\n머신 러닝은 선형 대수, 미적분, 확률, 통계의 세 가지 수학 기초를 중시합니다. 각각이 알고리즘이 효과적으로 동작하도록 하는데 중요한 역할을 합니다.\n\n<div class=\"content-ad\"></div>\n\n- 선형 대수학: 데이터의 표현과 조작을 위한 수학적 도구로, 행렬과 벡터가 알고리즘이 정보를 해석하고 처리하는 언어를 형성합니다.\n- 미적분학: 기계 학습에서 최적화를 위한 엔진으로, 알고리즘이 그래디언트와 변화율을 이해하여 학습하고 개선할 수 있도록 합니다.\n- 확률과 통계: 불확실성 하에서의 의사 결정을 위한 기초로, 알고리즘이 결과를 예측하고 무작위성과 변동성 모델을 통해 데이터에서 학습할 수 있도록 합니다.\n\n이는 프로그래머 관점에서 수학에 대한 멋진 시리즈입니다: Weights & Biases의 수학을 통한 기계 학습(코드)\n\n선형 대수학에 대한 코드 중심 접근 방식을 원한다면, fast.ai 창시자들에 의한 Computational Linear Algebra(비디오, 코드)를 참고하세요.\n\n파이썬을 활용한 응용 기계 학습을 위한 선형 대수학 소개서를 함께 읽어보세요.\n\n<div class=\"content-ad\"></div>\n\n만약 전통적인 것을 더 선호한다면, 잉글랜드의 임페리얼 칼리지의 강의인 선형대수학 및 다변수 미적분을 참고해보세요.\n\n3Blue1Brown의 Essence of Linear Algebra 및 Essence of Calculus를 시청해보세요.\n\n통계학에 대한 기본 개념을 알고 싶다면 StatQuest의 Statistics Fundamentals를 시청해보세요.\n\n보충 자료\n\n<div class=\"content-ad\"></div>\n\n- 책: 수학 머신러닝을 위한\r\n- 논문: 딥러닝에 필요한 행렬 미적분\n\n# 도구\n\n![도구 이미지](/assets/img/2024-06-22-RoadmaptoLearnAIin2024_2.png)\n\n## Python\n\n<div class=\"content-ad\"></div>\n\n초보자분들은 여기서 시작하세요: Practical Python Programming.\n\n이미 Python에 익숙하신 분은 Advanced Python Mastery를 선택해보세요.\n\n두 강의 모두 David Beazley가 집필한 Python Cookbook의 저자로 유명한 강의입니다.\n\n이후에는 James Powell의 강연 몇 개를 보세요.\n\n<div class=\"content-ad\"></div>\n\n파이썬 디자인 패턴을 읽어보세요.\n\n추가 정보\n\n- 책: 유창한 파이썬, 2판 (코드)\n- 팔로우할 팟캐스트: Real Python 및 Talk Python\n\n## PyTorch\n\n<div class=\"content-ad\"></div>\n\n알라딘 페르손의 파이토치 튜토리얼을 시청해보세요\n\n파이토치 웹사이트는 정말 멋진 곳이에요.\n\n- 파이토치 예제\n- 공식 파이토치 튜토리얼\n- FAQ 페이지\n\n퍼즐로 지식을 테스트해보세요\n\n<div class=\"content-ad\"></div>\n\n- srush/Tensor-Puzzles: 퍼즐을 해결하세요. PyTorch 실력을 향상시키세요\n\n부가 정보\n\n- 책: 딥러닝을 위한 PyTorch 프로그래밍\n\n# 기계 학습\n\n<div class=\"content-ad\"></div>\n\n\n![이미지](/assets/img/2024-06-22-RoadmaptoLearnAIin2024_3.png)\n\n100페이지짜리 머신 러닝 책을 읽어보세요.\n\n## 처음부터 써보기\n\n읽으면서 알고리즘을 처음부터 짜보세요.\n\n\n<div class=\"content-ad\"></div>\n\n아래의 저장소들을 살펴보세요\n\n- eriklindernoren/ML-From-Scratch\n- JeremyNixon/oracle\n- trekhleb/homemade-machine-learning\n\n도전하고 싶다면, 이 코스를 따라가며 PyTorch를 제작해보세요.\n\n- MiniTorch: 머신러닝 엔지니어링 DIY 코스 (동영상, 코드)\n\n<div class=\"content-ad\"></div>\n\n## 경쟁\n\n학습한 내용을 경쟁에서 실습해 보세요.\n\n- Bitgrit 및 Kaggle과 같은 플랫폼에서 ML 경쟁에 참여하세요. 이 기사에서 더 많은 정보를 확인할 수 있습니다.\n- 지난 우승 솔루션을 살펴보고 연구하세요\n\n## 사이드 프로젝트 만들기\n\n<div class=\"content-ad\"></div>\n\n위키 보이키가 쓴 글 'Getting machine learning to production' 을 읽어보세요.\n\n그녀는 또한 책을 위한 의미론적 검색인 Viberary를 만들면서 배운 것에 대해 썼습니다.\n\n데이터셋을 구하고 모델을 만드세요 (즉, NASA 지구 데이터를 얻기 위해 earthaccess를 사용하세요).\n\nStreamlit으로 UI를 만들어 Twitter에 공유하세요.\n\n<div class=\"content-ad\"></div>\n\n## 배포하세요\n\n모델을 제품으로 출시하세요. 실험을 추적하세요. 모델을 어떻게 모니터링하는지 배우세요. 데이터 및 모델 드리프트를 직접 경험해보세요.\n\n다음은 일부 훌륭한 자원입니다\n\n- Made With ML\n- DataTalksClub/mlops-zoomcamp: 무료 MLOps 강의\n- chiphuyen/machine-learning-systems-design\n- Evidently AI — ML 시스템 디자인: 300개의 사례 연구\n- stas00/ml-engineering: 머신러닝 엔지니어링 온라인 서적\n\n<div class=\"content-ad\"></div>\n\n## 부가정보\n\n- PyTorch와 Scikit-Learn을 사용한 기계학습 (코드)\n- [1811.12808] 기계학습에서의 모델 평가, 모델 선택 및 알고리즘 선택\n- 머신러닝 면접서 · MLIB\n\n# 딥러닝\n\n![AI 학습을 위한 지도](/assets/img/2024-06-22-RoadmaptoLearnAIin2024_4.png)\n\n<div class=\"content-ad\"></div>\n\n위에서 아래로 내려오는 방식이 좋다면, fast.ai부터 시작해보세요.\n\n## Fast.ai\n\n- fast.ai (파트1, 파트2) + W&B 스터디 그룹\n\nfast.ai를 좋아하셨나요? Full Stack Deep Learning도 확인해보세요.\n\n<div class=\"content-ad\"></div>\n\n더 포괄적이고 전통적인 강의를 찾고 계시다면, François Fleuret의 UNIGE 14x050 - 딥 러닝을 확인해보세요.\n\n이론을 필요로 할 때는 이런 책들이 좋습니다.\n\n- Dive into Deep Learning (PyTorch, NumPy/MXNet, JAX, TensorFlow 코드 예시 포함)\n- Ian Goodfellow, Yoshua Bengio, Aaron Courville의 Deep Learning\n- Neural networks and deep learning\n- Understanding Deep Learning (실습 노트북과 함께)\n\n트위터를 스크롤하는 대신 핸드폰에서 The Little Book of Deep Learning을 읽어보세요.\n\n<div class=\"content-ad\"></div>\n\n신경망이 수렴되는 동안 이를 읽어보세요.\n\n- 신경망 훈련을 위한 레시피\n- 심층 신경망: 33년 전과 33년 후\n\n### 더 많은 경연에 참여하세요\n\n- PlantTraits2024 — FGVC11 | Kaggle (컴퓨터 비전)\n\n<div class=\"content-ad\"></div>\n\n## 논문 구현\n\nlabml.ai Annotated PyTorch Paper Implementations을 확인해보세요.\n\nPapers with Code는 훌륭한 자료입니다. 그들의 웹사이트에서 BERT가 설명되어 있습니다.\n\n아래는 딥러닝 내 특화된 자원들입니다.\n\n<div class=\"content-ad\"></div>\n\n## 컴퓨터 비전\n\n많은 사람들이 CS231n: 딥 러닝을 위한 컴퓨터 비전을 추천합니다. 도전적이지만 극복한다면 가치가 있어요.\n\n## 강화학습\n\n강화학습에 대해 이 두 가지가 좋아요:\n\n<div class=\"content-ad\"></div>\n\n- OpenAI에서 제공하는 Deep RL 시작하기\n- 🤗 Hugging Face의 Deep Reinforcement Learning Course\n\n## 자연어 처리\n\n다른 훌륭한 Stanford 강의, CS 224N | 딥러닝을 활용한 자연어 처리\n\nHugging Face NLP Course를 배워보세요\n\n<div class=\"content-ad\"></div>\n\n이 멋진 NLP 항목들을 확인해보세요.\n\n좋은 기사와 설명들\n\n- BERT 연구 - Ep. 1 - 주요 개념 및 소스 · Chris McCormick\n- The Illustrated Word2vec - Jay Alammar\n- The Illustrated BERT, ELMo, 등 (NLP가 전이 학습을 해결한 방법)\n- LSTM 네트워크 이해 - colah의 블로그\n- PyTorch RNN Scratch 구현 - Jake Tae\n\n부가적인 정보\n\n<div class=\"content-ad\"></div>\n\n- Natural Language Processing with Transformers Book\n\n# Large Language Models\n\n![Image](/assets/img/2024-06-22-RoadmaptoLearnAIin2024_5.png)\n\nFirst, watch [1hr Talk] Intro to Large Language Models by Andrej.\n\n<div class=\"content-ad\"></div>\n\n그 다음 Alexander Rush의 '5가지 공식으로 큰 언어 모델'을 알아보세요 — Cornell Tech\n\n## 신경망 시청: 제로부터 히어로로\n\n0부터 역전파를 설명하고 코딩한 다음, 제로에서 GPT를 직접 작성하는 방법까지 알려줍니다.\n\nAndrzej Karpathy의 '신경망: 제로에서 히어로로'\n\n<div class=\"content-ad\"></div>\n\n그는 방금 새 비디오를 공개했어요 → GPT 토크나이저 만들기에 도전해보세요\n\n그리고 Jay Mody의 'NumPy로 GPT를 60줄로 살펴보기'도 함께 확인해보세요.\n\n## 무료 LLM 부트캠프\n\nFull Stack Deep Learning에서 무료로 제공된 유료 LLM 부트캠프를 소개합니다.\n\n<div class=\"content-ad\"></div>\n\n이 프로그램은 즉시 엔지니어링, LLMOps, LLM을 위한 UX, 그리고 1시간 안에 LLM 앱을 출시하는 방법을 가르칩니다.\n\n부트 캠프를 마치고 나서 무언가를 만들고 싶어질 것입니다.\n\n## LLM과 함께 빌드하기\n\nLLM과 함께 앱을 만들고 싶나요?\n\n<div class=\"content-ad\"></div>\n\n거대한 언어 모델을 활용한 애플리케이션 개발\nAndrew Ng 저\n\nHuyen Chip의 제작용 LLM 애플리케이션 빌딩 읽기\n\n또한 Eugene Yan의 LLM 기반 시스템 및 제품을 구축하기 위한 패턴\n\n레시피를 위해 OpenAI Cookbook을 참조하세요.\n\n<div class=\"content-ad\"></div>\n\nVercel AI 템플릿을 사용하여 시작해보세요.\n\n## 해커톤 참여\n\nlablab.ai는 매주 새로운 AI 해커톤을 개최합니다. 팀을 꾸리고 싶다면 알려주세요!\n\n더 심층적으로 이론에 대해 공부하고 모든 것이 어떻게 작동하는지 이해하고 싶다면:\n\n<div class=\"content-ad\"></div>\n\n## 논문 읽기\n\n세바스찬 라슈카의 대규모 언어 모델 이해에 대한 훌륭한 기사가 있습니다. 그는 읽어야 할 몇 가지 논문을 나열하였습니다.\n\n그는 또한 최근 2024년 1월에 읽어야 할 논문에 대한 다른 기사를 발행했으며, 이 기사는 미스트랄 모델을 다루고 있습니다.\n\n그의 서브스택 Ahead of AI를 팔로우하세요.\n\n<div class=\"content-ad\"></div>\n\n## 제로부터 Transformer 구현하기.\n\n개요를 읽으려면 The Transformer Family Version 2.0 | Lil’Log를 참조해주세요.\n\n가장 편한 형식을 선택하고 제로부터 구현해보세요.\n\n논문\n\n<div class=\"content-ad\"></div>\n\n- 어텐션만 해라\n- 이해할 수 있는 트랜스포머\n- 하버드의 주석 달린 트랜스포머\n- 트랜스포머처럼 생각하기\n\n블로그\n\n- 제로 부터 트랜스포머 만들기 — 첫 번째 파트: 어텐션 메커니즘 (파트 2) (코드)\n- 세바스찬 라쉬카 박사의 대형 언어 모델의 셀프 어텐션 메커니즘을 이해하고 코딩하기\n- 제로 부터 트랜스포머를 만들기\n\n비디오\n\n<div class=\"content-ad\"></div>\n\n- 파이토치로부터 Transformer를 완전히 설명하여 트레이닝 및 추론을 구현하기\n- NLP: BERT와 Transformer를 스크래치에서 구현하기\n\n이제는 전적으로 Transformer를 코딩할 수 있어요. 하지만 더 많은 것이 기다리고 있어요.\n\n이 스탠포드 CS25 — Transformers United 비디오들을 확인해보세요.\n\n## 몇 가지 좋은 블로그들\n\n<div class=\"content-ad\"></div>\n\n- 점근적 하강법으로 미친듯이 — 처음부터 LLM 구축하기\n- 일러스트로 보는 Transformer — Jay Alammar\n- 어텐션과 Transformer에 대한 직관적인 이해 by Eugene Yan\n- GPT 가속화하기 — KV 캐시 | 불패를 향한 발전\n- 자가 어텐션을 넘어서: 작은 언어 모델이 다음 토큰을 예측하는 방법\n- 처음부터 Llama 만들기 (또는 울지 않고 논문 구현하기) | Brian Kitano\n- LoRA 개선하기: 처음부터 Weight-Decomposed Low-Rank Adaptation (DoRA) 구현하기\n\n## Watch Umar Jamil\n\n그의 깊이 있는 훌륭한 비디오를 통해 논문을 설명합니다. 또한 코드도 보여줍니다.\n\n- LoRA: 대규모 언어 모델에 대한 저랭크 적응 — 시각적 설명 + PyTorch 코드로 처음부터\n- Mistral / Mixtral 설명: 슬라이딩 윈도우 어텐션, 희소한 전문가 혼합, 롤링 버퍼\n- 어텐션만으로 충분하다 (Transformer) — 모델 설명(수학 포함), 추론 및 훈련\n- LLaMA 설명: KV-Cache, 로터리 위치 임베딩, RMS Norm, 그룹화된 쿼리 어텐션, SwiGLU\n- 검색 증강 생성 (RAG) 설명: 임베딩, 문장 BERT, 벡터 데이터베이스(HNSW)\n\n<div class=\"content-ad\"></div>\n\nLLM과 관련된 몇 가지 더 링크를 추가했어요. 이 링크들이 모두를 다 소개한 건 아니에요. LLM에 대한 더 포괄적인 실러버스는 LLM 실러버스를 참고해보세요.\n\n## 오픈소스 모델을 실행하는 방법을 배워보세요.\n\nollama를 사용하세요: Llama 2, Mistral, 그리고 다른 대형 언어 모델을 로컬에서 사용해보세요.\n\n최근에 파이썬 및 자바스크립트 라이브러리가 출시되었어요.\n\n<div class=\"content-ad\"></div>\n\n## 프롬프트 엔지니어링\n\n가벼운 톤으로 요청하신 내용을 한국어로 번역해드리겠습니다.\n\n## 프롬프트 엔지니어링\n\n프롬프트 엔지니어링 | Lil’Log 읽기\n\nIse Fulford(OpenAI)와 Andrew Ng에 의한 개발자를 위한 ChatGPT 프롬프트 엔지니어링\n\nDeepLearning.ai에서는 무료로 수강할 수 있는 다른 짧은 강의도 제공합니다.\n\n<div class=\"content-ad\"></div>\n\n## LLM 세밀 조정\n\n허깅페이스 세밀 조정 가이드를 읽어보세요.\n\n좋은 안내서: 세밀 조정 — GenAI 안내서\n\n악소로틀을 확인해보세요.\n\n<div class=\"content-ad\"></div>\n\n이 글은 좋아요: Fine-tune a Mistral-7b model with Direct Preference Optimization | Maxime Labonne가 쓴 글\n\n## RAG\n\nAnyscale에서 좋은 글: Production을 위한 RAG 기반 LLM 애플리케이션 구축\n\nAman Chadha가 작성한 검색 증강 생성에 대한 포괄적인 개요\n\n<div class=\"content-ad\"></div>\n\n# 최신 정보를 얻는 방법\n\n뉴스레터 + 팟캐스트 + 트위터의 조합\n\n논문을 위해서는 AK(@_akhaliq)를 팔로우할 수 있습니다.\n\n팟캐스트는 Swyx와 Alessio가 진행하는 Latent Space가 최고로 생각됩니다.\n\n<div class=\"content-ad\"></div>\n\n그들의 디스코드에 가입해보세요.\n\n그들은 Smol Talk이라는 뉴스레터도 운영하고 있어요. 이 뉴스레터는 모든 주요 AI 디스코드를 요약합니다.\n\n내가 좋아하는 다른 뉴스레터들은:\n\n- The Batch | DeepLearning.AI | AI News & Insights\n- Deep Learning Weekly\n- Interconnects | Nathan Lambert\n- AI Tidbits | Sahar Mor\n\n<div class=\"content-ad\"></div>\n\n이 기사에 더 많은 내용이 있습니다.\n\n# 유용할 수 있는 다른 커리큘럼/목록.\n\n내 목록은 철저한 것이 아니었지만, 여전히 더 찾고 싶다면 몇 가지가 있습니다.\n\n- openai/syllabus.md\n- AI Canon | Andreessen Horowitz\n- AI Learning Curation — LLM Utils\n- Threshold to the AI Multiverse | Open DeepLearning\n- louisfb01/start-llms: 2023년 LLM 스킬을 개선하기 위한 완벽한 가이드\n\n<div class=\"content-ad\"></div>\n\n이제 충분한 시간을 들여서 쓰고 정리를 했으니, 이제는 많은 것을 얻을 차례입니다. 배우고 무언가를 만들어 봐요.\n\n이것이 당신의 인공지능 여정에 도움이 되기를 바래요!\n\n만약 여기까지 읽었다면, 꼭 연락하거나 댓글을 남겨주세요 :)\n\n새로운 소식을 받기 위해 bitgrit 데이터 과학 게시물을 팔로우하는 것을 잊지 마세요!\n\n<div class=\"content-ad\"></div>\n\n최신 데이터 과학과 인공 지능 분야의 최신 소식을 다른 데이터 과학자들과 함께 논의하고 싶으신가요? 우리의 디스코드 서버에 참여해보세요!\n\n워크숍 및 다가오는 대회 소식을 받아보려면 Bitgrit를 팔로우해주세요!\n\n디스코드 | 웹사이트 | 트위터 | 링크드인 | 인스타그램 | 페이스북 | 유튜브","ogImage":{"url":"/assets/img/2024-06-22-RoadmaptoLearnAIin2024_0.png"},"coverImage":"/assets/img/2024-06-22-RoadmaptoLearnAIin2024_0.png","tag":["Tech"],"readingTime":12},"content":"<!doctype html>\n<html lang=\"en\">\n<head>\n<meta charset=\"utf-8\">\n<meta content=\"width=device-width, initial-scale=1\" name=\"viewport\">\n</head>\n<body>\n<h2>AI를 배우고 싶나요?</h2>\n<p><img src=\"/assets/img/2024-06-22-RoadmaptoLearnAIin2024_0.png\" alt=\"AI 학습 로드맵\"></p>\n<p>AI를 배우고 싶지만 어떻게 시작해야 할지 모르시나요?</p>\n<p>저는 2020년에 무료 데이터 과학, 기계 학습 및 AI MOOC의 베스트 20을 작성했어요. 하지만 많은 강의를 듣는 것이 답은 아니라는 것을 깨달았죠.</p>\n<div class=\"content-ad\"></div>\n<p>튜토리얼 지옥을 벗어나서 진짜로 배우려면 손을 더럽히고, 알고리즘을 제로부터 짜고, 논문들을 구현하며, AI를 활용하여 재미있는 부수 프로젝트를 해결하는 게 중요해요.</p>\n<p>본 문서는 이 철학을 따르는 무료 커리큘럼을 작성하려고 노력했어요. 저는 이 중 일부 강좌를 진행하고 있는데요, 함께 공부하고 싶다면 트위터나 링크드인을 통해 연락해주세요!</p>\n<p>그리고 이 내용에 빠진 부분이 있다고 생각되면 댓글을 남겨주세요!</p>\n<p>하지만 먼저, 커리큘럼에 대한 몇 가지 주의사항과 학습 팁을 전해드릴게요.</p>\n<div class=\"content-ad\"></div>\n<h1>Top-down 방식</h1>\n<p>이 교육과정은 top-down 방식을 따릅니다 — 코드를 먼저 작성하고 이론을 나중에 다룹니다.</p>\n<p>저는 필요에 의해 배우는 것을 좋아합니다. 그래서, 무언가를 해결해야 하거나 프로토 타입을 만들어야 할 때, 필요한 정보를 넓고 넒게 찾아서 해당 정보를 공부하고 이해한 후에 행동으로 옮깁니다.</p>\n<p>예를 들어, 저는 기본 수준에서 LLMs를 이해하는 AI 엔지니어가 되고 싶습니다. 이를 위해서는 transformer를 처음부터 코딩하고 GPU에서 LLMs를 세밀하게 튜닝하는 기술이 필요합니다. 지금은 그것을 할 수 없습니다. 왜냐하면 제 지식에는 여전히 빈틈이 있기 때문에 그 빈틈을 채우고자 하는 목표가 있습니다.</p>\n<div class=\"content-ad\"></div>\n<p>이것은 NLP에 중점을 둔 것입니다. 컴퓨터 비전이나 강화 학습과 같은 다른 AI 전문화를 찾고 계신 경우, 아래에 댓글을 남기거나 Twitter 또는 Linkedin에서 DM으로 연락해주세요. 추천 몇 가지를 전해 드릴게요.</p>\n<p>링크를 많이 던지기 전에 제가 무언가를 배우기 시작하기 전에 중요한 두 가지를 알았더라면 좋았을 텐데요.</p>\n<h1>공개로 배우세요</h1>\n<p>배워야 할 것이 많고, 특히 AI에서는 매주 새로운 혁명적인 논문과 아이디어들이 나오기 때문에 학습이 끝나지 않을 것입니다.</p>\n<div class=\"content-ad\"></div>\n<p>가장 큰 실수는 혼자서 배우는 것입니다. 그렇게 하면 자신에게 어떤 기회도 만들지 못합니다. 완료했다고 말할 수 있는 것을 제외하고는 보여줄 것이 없습니다. 더 중요한 것은 정보를 어떻게 활용하여 공유할지, 그 정보에서 어떤 혁신적인 아이디어와 해결책이 나왔는지입니다.</p>\n<p>그러니까, 공개적으로 배워야 합니다.</p>\n<p>종합하자면, 만드는 습관을 가져야 합니다.</p>\n<p>이것은 다음을 의미할 수 있습니다:</p>\n<div class=\"content-ad\"></div>\n<ul>\n<li>블로그와 튜토리얼 작성</li>\n<li>해커톤 참여 및 다른 사람들과 협업</li>\n<li>디스코드 커뮤니티에서 질문하고 대답하기</li>\n<li>열정적으로 하는 사이드 프로젝트에 참여</li>\n<li>새롭게 발견한 흥미로운 것에 대해 트윗하기</li>\n</ul>\n<p>그리고 트위터에 대해 이야기할 때,</p>\n<h1>트위터 사용하기</h1>\n<p>적절한 사람을 팔로우하고 올바르게 활용한다면, 오늘날 누구나 함께 있어야 할 가치가 가장 높은 소셜 플랫폼입니다.</p>\n<div class=\"content-ad\"></div>\n<p>누구를 팔로우해야 하는지 궁금하다면 Suhail이 제작한 이 AI 목록을 확인해보세요.</p>\n<p>Twitter를 어떻게 사용해야 할지 궁금하다면 Near의 \"Twitter 성공 가이드\"를 읽어보세요.</p>\n<p>Twitter에서 사람들에게 다이렉트 메시지를 보내려면 진실하고 간결하며 구체적인 요청을 하는 게 중요해요. Sriram Krishnan의 \"차가운 이메일 작성 방법\" 가이드도 DM에 적용할 수 있어요.</p>\n<p>트윗하는 법이 알고 싶다면, Instructor의 창시자 Jason이 작성한 \"트윗의 구성 요소\"를 읽어보세요. 그는 0명에서 단 몇 달 사이에 14,000명의 팔로워를 얻었답니다.</p>\n<div class=\"content-ad\"></div>\n<p>만약 이 문구를 읽고 계시다면, 트위터로 저를 팔로우해 주세요!</p>\n<p>무엇을 하고 있는지 메시지를 보내주세요! 멋진 프로젝트에 함께 참여하는 것을 항상 기대하고 있습니다.</p>\n<p>이제 시작해 봅시다.</p>\n<h2>목차</h2>\n<div class=\"content-ad\"></div>\n<ul>\n<li>수학</li>\n<li>도구\n<ul>\n<li>Python</li>\n<li>PyTorch</li>\n</ul>\n</li>\n<li>머신 러닝\n<ul>\n<li>처음부터 작성</li>\n<li>경쟁</li>\n<li>사이드 프로젝트 수행</li>\n<li>배포</li>\n<li>부가적인 활동</li>\n</ul>\n</li>\n<li>딥러닝\n<ul>\n<li>Fast.ai</li>\n<li>더 많은 경쟁 참여</li>\n<li>논문 구현</li>\n<li>컴퓨터 비전</li>\n<li>NLP</li>\n</ul>\n</li>\n<li>대규모 언어 모델\n<ul>\n<li>Neural Networks: Zero to Hero 시청</li>\n<li>무료 LLM 부트캠프</li>\n<li>LLM으로 빌드</li>\n<li>해커톤 참여</li>\n<li>논문 읽기</li>\n<li>처음부터 Transformers 작성</li>\n<li>일부 좋은 블로그</li>\n<li>Umar Jamil 시청</li>\n<li>오픈소스 모델 실행 방법 익히기</li>\n<li>프롬프트 엔지니어링</li>\n<li>LLM 세밀 조정</li>\n<li>RAG</li>\n</ul>\n</li>\n<li>최신 정보 유지 방법</li>\n<li>유용한 다른 커리큘럼/리스트들</li>\n</ul>\n<h1>수학</h1>\n<div>\n   <img src=\"/assets/img/2024-06-22-RoadmaptoLearnAIin2024_1.png\">\n</div>\n<p>머신 러닝은 선형 대수, 미적분, 확률, 통계의 세 가지 수학 기초를 중시합니다. 각각이 알고리즘이 효과적으로 동작하도록 하는데 중요한 역할을 합니다.</p>\n<div class=\"content-ad\"></div>\n<ul>\n<li>선형 대수학: 데이터의 표현과 조작을 위한 수학적 도구로, 행렬과 벡터가 알고리즘이 정보를 해석하고 처리하는 언어를 형성합니다.</li>\n<li>미적분학: 기계 학습에서 최적화를 위한 엔진으로, 알고리즘이 그래디언트와 변화율을 이해하여 학습하고 개선할 수 있도록 합니다.</li>\n<li>확률과 통계: 불확실성 하에서의 의사 결정을 위한 기초로, 알고리즘이 결과를 예측하고 무작위성과 변동성 모델을 통해 데이터에서 학습할 수 있도록 합니다.</li>\n</ul>\n<p>이는 프로그래머 관점에서 수학에 대한 멋진 시리즈입니다: Weights &#x26; Biases의 수학을 통한 기계 학습(코드)</p>\n<p>선형 대수학에 대한 코드 중심 접근 방식을 원한다면, fast.ai 창시자들에 의한 Computational Linear Algebra(비디오, 코드)를 참고하세요.</p>\n<p>파이썬을 활용한 응용 기계 학습을 위한 선형 대수학 소개서를 함께 읽어보세요.</p>\n<div class=\"content-ad\"></div>\n<p>만약 전통적인 것을 더 선호한다면, 잉글랜드의 임페리얼 칼리지의 강의인 선형대수학 및 다변수 미적분을 참고해보세요.</p>\n<p>3Blue1Brown의 Essence of Linear Algebra 및 Essence of Calculus를 시청해보세요.</p>\n<p>통계학에 대한 기본 개념을 알고 싶다면 StatQuest의 Statistics Fundamentals를 시청해보세요.</p>\n<p>보충 자료</p>\n<div class=\"content-ad\"></div>\n<ul>\n<li>책: 수학 머신러닝을 위한</li>\n<li>논문: 딥러닝에 필요한 행렬 미적분</li>\n</ul>\n<h1>도구</h1>\n<p><img src=\"/assets/img/2024-06-22-RoadmaptoLearnAIin2024_2.png\" alt=\"도구 이미지\"></p>\n<h2>Python</h2>\n<div class=\"content-ad\"></div>\n<p>초보자분들은 여기서 시작하세요: Practical Python Programming.</p>\n<p>이미 Python에 익숙하신 분은 Advanced Python Mastery를 선택해보세요.</p>\n<p>두 강의 모두 David Beazley가 집필한 Python Cookbook의 저자로 유명한 강의입니다.</p>\n<p>이후에는 James Powell의 강연 몇 개를 보세요.</p>\n<div class=\"content-ad\"></div>\n<p>파이썬 디자인 패턴을 읽어보세요.</p>\n<p>추가 정보</p>\n<ul>\n<li>책: 유창한 파이썬, 2판 (코드)</li>\n<li>팔로우할 팟캐스트: Real Python 및 Talk Python</li>\n</ul>\n<h2>PyTorch</h2>\n<div class=\"content-ad\"></div>\n<p>알라딘 페르손의 파이토치 튜토리얼을 시청해보세요</p>\n<p>파이토치 웹사이트는 정말 멋진 곳이에요.</p>\n<ul>\n<li>파이토치 예제</li>\n<li>공식 파이토치 튜토리얼</li>\n<li>FAQ 페이지</li>\n</ul>\n<p>퍼즐로 지식을 테스트해보세요</p>\n<div class=\"content-ad\"></div>\n<ul>\n<li>srush/Tensor-Puzzles: 퍼즐을 해결하세요. PyTorch 실력을 향상시키세요</li>\n</ul>\n<p>부가 정보</p>\n<ul>\n<li>책: 딥러닝을 위한 PyTorch 프로그래밍</li>\n</ul>\n<h1>기계 학습</h1>\n<div class=\"content-ad\"></div>\n<p><img src=\"/assets/img/2024-06-22-RoadmaptoLearnAIin2024_3.png\" alt=\"이미지\"></p>\n<p>100페이지짜리 머신 러닝 책을 읽어보세요.</p>\n<h2>처음부터 써보기</h2>\n<p>읽으면서 알고리즘을 처음부터 짜보세요.</p>\n<div class=\"content-ad\"></div>\n<p>아래의 저장소들을 살펴보세요</p>\n<ul>\n<li>eriklindernoren/ML-From-Scratch</li>\n<li>JeremyNixon/oracle</li>\n<li>trekhleb/homemade-machine-learning</li>\n</ul>\n<p>도전하고 싶다면, 이 코스를 따라가며 PyTorch를 제작해보세요.</p>\n<ul>\n<li>MiniTorch: 머신러닝 엔지니어링 DIY 코스 (동영상, 코드)</li>\n</ul>\n<div class=\"content-ad\"></div>\n<h2>경쟁</h2>\n<p>학습한 내용을 경쟁에서 실습해 보세요.</p>\n<ul>\n<li>Bitgrit 및 Kaggle과 같은 플랫폼에서 ML 경쟁에 참여하세요. 이 기사에서 더 많은 정보를 확인할 수 있습니다.</li>\n<li>지난 우승 솔루션을 살펴보고 연구하세요</li>\n</ul>\n<h2>사이드 프로젝트 만들기</h2>\n<div class=\"content-ad\"></div>\n<p>위키 보이키가 쓴 글 'Getting machine learning to production' 을 읽어보세요.</p>\n<p>그녀는 또한 책을 위한 의미론적 검색인 Viberary를 만들면서 배운 것에 대해 썼습니다.</p>\n<p>데이터셋을 구하고 모델을 만드세요 (즉, NASA 지구 데이터를 얻기 위해 earthaccess를 사용하세요).</p>\n<p>Streamlit으로 UI를 만들어 Twitter에 공유하세요.</p>\n<div class=\"content-ad\"></div>\n<h2>배포하세요</h2>\n<p>모델을 제품으로 출시하세요. 실험을 추적하세요. 모델을 어떻게 모니터링하는지 배우세요. 데이터 및 모델 드리프트를 직접 경험해보세요.</p>\n<p>다음은 일부 훌륭한 자원입니다</p>\n<ul>\n<li>Made With ML</li>\n<li>DataTalksClub/mlops-zoomcamp: 무료 MLOps 강의</li>\n<li>chiphuyen/machine-learning-systems-design</li>\n<li>Evidently AI — ML 시스템 디자인: 300개의 사례 연구</li>\n<li>stas00/ml-engineering: 머신러닝 엔지니어링 온라인 서적</li>\n</ul>\n<div class=\"content-ad\"></div>\n<h2>부가정보</h2>\n<ul>\n<li>PyTorch와 Scikit-Learn을 사용한 기계학습 (코드)</li>\n<li>[1811.12808] 기계학습에서의 모델 평가, 모델 선택 및 알고리즘 선택</li>\n<li>머신러닝 면접서 · MLIB</li>\n</ul>\n<h1>딥러닝</h1>\n<p><img src=\"/assets/img/2024-06-22-RoadmaptoLearnAIin2024_4.png\" alt=\"AI 학습을 위한 지도\"></p>\n<div class=\"content-ad\"></div>\n<p>위에서 아래로 내려오는 방식이 좋다면, fast.ai부터 시작해보세요.</p>\n<h2>Fast.ai</h2>\n<ul>\n<li>fast.ai (파트1, 파트2) + W&#x26;B 스터디 그룹</li>\n</ul>\n<p>fast.ai를 좋아하셨나요? Full Stack Deep Learning도 확인해보세요.</p>\n<div class=\"content-ad\"></div>\n<p>더 포괄적이고 전통적인 강의를 찾고 계시다면, François Fleuret의 UNIGE 14x050 - 딥 러닝을 확인해보세요.</p>\n<p>이론을 필요로 할 때는 이런 책들이 좋습니다.</p>\n<ul>\n<li>Dive into Deep Learning (PyTorch, NumPy/MXNet, JAX, TensorFlow 코드 예시 포함)</li>\n<li>Ian Goodfellow, Yoshua Bengio, Aaron Courville의 Deep Learning</li>\n<li>Neural networks and deep learning</li>\n<li>Understanding Deep Learning (실습 노트북과 함께)</li>\n</ul>\n<p>트위터를 스크롤하는 대신 핸드폰에서 The Little Book of Deep Learning을 읽어보세요.</p>\n<div class=\"content-ad\"></div>\n<p>신경망이 수렴되는 동안 이를 읽어보세요.</p>\n<ul>\n<li>신경망 훈련을 위한 레시피</li>\n<li>심층 신경망: 33년 전과 33년 후</li>\n</ul>\n<h3>더 많은 경연에 참여하세요</h3>\n<ul>\n<li>PlantTraits2024 — FGVC11 | Kaggle (컴퓨터 비전)</li>\n</ul>\n<div class=\"content-ad\"></div>\n<h2>논문 구현</h2>\n<p>labml.ai Annotated PyTorch Paper Implementations을 확인해보세요.</p>\n<p>Papers with Code는 훌륭한 자료입니다. 그들의 웹사이트에서 BERT가 설명되어 있습니다.</p>\n<p>아래는 딥러닝 내 특화된 자원들입니다.</p>\n<div class=\"content-ad\"></div>\n<h2>컴퓨터 비전</h2>\n<p>많은 사람들이 CS231n: 딥 러닝을 위한 컴퓨터 비전을 추천합니다. 도전적이지만 극복한다면 가치가 있어요.</p>\n<h2>강화학습</h2>\n<p>강화학습에 대해 이 두 가지가 좋아요:</p>\n<div class=\"content-ad\"></div>\n<ul>\n<li>OpenAI에서 제공하는 Deep RL 시작하기</li>\n<li>🤗 Hugging Face의 Deep Reinforcement Learning Course</li>\n</ul>\n<h2>자연어 처리</h2>\n<p>다른 훌륭한 Stanford 강의, CS 224N | 딥러닝을 활용한 자연어 처리</p>\n<p>Hugging Face NLP Course를 배워보세요</p>\n<div class=\"content-ad\"></div>\n<p>이 멋진 NLP 항목들을 확인해보세요.</p>\n<p>좋은 기사와 설명들</p>\n<ul>\n<li>BERT 연구 - Ep. 1 - 주요 개념 및 소스 · Chris McCormick</li>\n<li>The Illustrated Word2vec - Jay Alammar</li>\n<li>The Illustrated BERT, ELMo, 등 (NLP가 전이 학습을 해결한 방법)</li>\n<li>LSTM 네트워크 이해 - colah의 블로그</li>\n<li>PyTorch RNN Scratch 구현 - Jake Tae</li>\n</ul>\n<p>부가적인 정보</p>\n<div class=\"content-ad\"></div>\n<ul>\n<li>Natural Language Processing with Transformers Book</li>\n</ul>\n<h1>Large Language Models</h1>\n<p><img src=\"/assets/img/2024-06-22-RoadmaptoLearnAIin2024_5.png\" alt=\"Image\"></p>\n<p>First, watch [1hr Talk] Intro to Large Language Models by Andrej.</p>\n<div class=\"content-ad\"></div>\n<p>그 다음 Alexander Rush의 '5가지 공식으로 큰 언어 모델'을 알아보세요 — Cornell Tech</p>\n<h2>신경망 시청: 제로부터 히어로로</h2>\n<p>0부터 역전파를 설명하고 코딩한 다음, 제로에서 GPT를 직접 작성하는 방법까지 알려줍니다.</p>\n<p>Andrzej Karpathy의 '신경망: 제로에서 히어로로'</p>\n<div class=\"content-ad\"></div>\n<p>그는 방금 새 비디오를 공개했어요 → GPT 토크나이저 만들기에 도전해보세요</p>\n<p>그리고 Jay Mody의 'NumPy로 GPT를 60줄로 살펴보기'도 함께 확인해보세요.</p>\n<h2>무료 LLM 부트캠프</h2>\n<p>Full Stack Deep Learning에서 무료로 제공된 유료 LLM 부트캠프를 소개합니다.</p>\n<div class=\"content-ad\"></div>\n<p>이 프로그램은 즉시 엔지니어링, LLMOps, LLM을 위한 UX, 그리고 1시간 안에 LLM 앱을 출시하는 방법을 가르칩니다.</p>\n<p>부트 캠프를 마치고 나서 무언가를 만들고 싶어질 것입니다.</p>\n<h2>LLM과 함께 빌드하기</h2>\n<p>LLM과 함께 앱을 만들고 싶나요?</p>\n<div class=\"content-ad\"></div>\n<p>거대한 언어 모델을 활용한 애플리케이션 개발\nAndrew Ng 저</p>\n<p>Huyen Chip의 제작용 LLM 애플리케이션 빌딩 읽기</p>\n<p>또한 Eugene Yan의 LLM 기반 시스템 및 제품을 구축하기 위한 패턴</p>\n<p>레시피를 위해 OpenAI Cookbook을 참조하세요.</p>\n<div class=\"content-ad\"></div>\n<p>Vercel AI 템플릿을 사용하여 시작해보세요.</p>\n<h2>해커톤 참여</h2>\n<p>lablab.ai는 매주 새로운 AI 해커톤을 개최합니다. 팀을 꾸리고 싶다면 알려주세요!</p>\n<p>더 심층적으로 이론에 대해 공부하고 모든 것이 어떻게 작동하는지 이해하고 싶다면:</p>\n<div class=\"content-ad\"></div>\n<h2>논문 읽기</h2>\n<p>세바스찬 라슈카의 대규모 언어 모델 이해에 대한 훌륭한 기사가 있습니다. 그는 읽어야 할 몇 가지 논문을 나열하였습니다.</p>\n<p>그는 또한 최근 2024년 1월에 읽어야 할 논문에 대한 다른 기사를 발행했으며, 이 기사는 미스트랄 모델을 다루고 있습니다.</p>\n<p>그의 서브스택 Ahead of AI를 팔로우하세요.</p>\n<div class=\"content-ad\"></div>\n<h2>제로부터 Transformer 구현하기.</h2>\n<p>개요를 읽으려면 The Transformer Family Version 2.0 | Lil’Log를 참조해주세요.</p>\n<p>가장 편한 형식을 선택하고 제로부터 구현해보세요.</p>\n<p>논문</p>\n<div class=\"content-ad\"></div>\n<ul>\n<li>어텐션만 해라</li>\n<li>이해할 수 있는 트랜스포머</li>\n<li>하버드의 주석 달린 트랜스포머</li>\n<li>트랜스포머처럼 생각하기</li>\n</ul>\n<p>블로그</p>\n<ul>\n<li>제로 부터 트랜스포머 만들기 — 첫 번째 파트: 어텐션 메커니즘 (파트 2) (코드)</li>\n<li>세바스찬 라쉬카 박사의 대형 언어 모델의 셀프 어텐션 메커니즘을 이해하고 코딩하기</li>\n<li>제로 부터 트랜스포머를 만들기</li>\n</ul>\n<p>비디오</p>\n<div class=\"content-ad\"></div>\n<ul>\n<li>파이토치로부터 Transformer를 완전히 설명하여 트레이닝 및 추론을 구현하기</li>\n<li>NLP: BERT와 Transformer를 스크래치에서 구현하기</li>\n</ul>\n<p>이제는 전적으로 Transformer를 코딩할 수 있어요. 하지만 더 많은 것이 기다리고 있어요.</p>\n<p>이 스탠포드 CS25 — Transformers United 비디오들을 확인해보세요.</p>\n<h2>몇 가지 좋은 블로그들</h2>\n<div class=\"content-ad\"></div>\n<ul>\n<li>점근적 하강법으로 미친듯이 — 처음부터 LLM 구축하기</li>\n<li>일러스트로 보는 Transformer — Jay Alammar</li>\n<li>어텐션과 Transformer에 대한 직관적인 이해 by Eugene Yan</li>\n<li>GPT 가속화하기 — KV 캐시 | 불패를 향한 발전</li>\n<li>자가 어텐션을 넘어서: 작은 언어 모델이 다음 토큰을 예측하는 방법</li>\n<li>처음부터 Llama 만들기 (또는 울지 않고 논문 구현하기) | Brian Kitano</li>\n<li>LoRA 개선하기: 처음부터 Weight-Decomposed Low-Rank Adaptation (DoRA) 구현하기</li>\n</ul>\n<h2>Watch Umar Jamil</h2>\n<p>그의 깊이 있는 훌륭한 비디오를 통해 논문을 설명합니다. 또한 코드도 보여줍니다.</p>\n<ul>\n<li>LoRA: 대규모 언어 모델에 대한 저랭크 적응 — 시각적 설명 + PyTorch 코드로 처음부터</li>\n<li>Mistral / Mixtral 설명: 슬라이딩 윈도우 어텐션, 희소한 전문가 혼합, 롤링 버퍼</li>\n<li>어텐션만으로 충분하다 (Transformer) — 모델 설명(수학 포함), 추론 및 훈련</li>\n<li>LLaMA 설명: KV-Cache, 로터리 위치 임베딩, RMS Norm, 그룹화된 쿼리 어텐션, SwiGLU</li>\n<li>검색 증강 생성 (RAG) 설명: 임베딩, 문장 BERT, 벡터 데이터베이스(HNSW)</li>\n</ul>\n<div class=\"content-ad\"></div>\n<p>LLM과 관련된 몇 가지 더 링크를 추가했어요. 이 링크들이 모두를 다 소개한 건 아니에요. LLM에 대한 더 포괄적인 실러버스는 LLM 실러버스를 참고해보세요.</p>\n<h2>오픈소스 모델을 실행하는 방법을 배워보세요.</h2>\n<p>ollama를 사용하세요: Llama 2, Mistral, 그리고 다른 대형 언어 모델을 로컬에서 사용해보세요.</p>\n<p>최근에 파이썬 및 자바스크립트 라이브러리가 출시되었어요.</p>\n<div class=\"content-ad\"></div>\n<h2>프롬프트 엔지니어링</h2>\n<p>가벼운 톤으로 요청하신 내용을 한국어로 번역해드리겠습니다.</p>\n<h2>프롬프트 엔지니어링</h2>\n<p>프롬프트 엔지니어링 | Lil’Log 읽기</p>\n<p>Ise Fulford(OpenAI)와 Andrew Ng에 의한 개발자를 위한 ChatGPT 프롬프트 엔지니어링</p>\n<p>DeepLearning.ai에서는 무료로 수강할 수 있는 다른 짧은 강의도 제공합니다.</p>\n<div class=\"content-ad\"></div>\n<h2>LLM 세밀 조정</h2>\n<p>허깅페이스 세밀 조정 가이드를 읽어보세요.</p>\n<p>좋은 안내서: 세밀 조정 — GenAI 안내서</p>\n<p>악소로틀을 확인해보세요.</p>\n<div class=\"content-ad\"></div>\n<p>이 글은 좋아요: Fine-tune a Mistral-7b model with Direct Preference Optimization | Maxime Labonne가 쓴 글</p>\n<h2>RAG</h2>\n<p>Anyscale에서 좋은 글: Production을 위한 RAG 기반 LLM 애플리케이션 구축</p>\n<p>Aman Chadha가 작성한 검색 증강 생성에 대한 포괄적인 개요</p>\n<div class=\"content-ad\"></div>\n<h1>최신 정보를 얻는 방법</h1>\n<p>뉴스레터 + 팟캐스트 + 트위터의 조합</p>\n<p>논문을 위해서는 AK(@_akhaliq)를 팔로우할 수 있습니다.</p>\n<p>팟캐스트는 Swyx와 Alessio가 진행하는 Latent Space가 최고로 생각됩니다.</p>\n<div class=\"content-ad\"></div>\n<p>그들의 디스코드에 가입해보세요.</p>\n<p>그들은 Smol Talk이라는 뉴스레터도 운영하고 있어요. 이 뉴스레터는 모든 주요 AI 디스코드를 요약합니다.</p>\n<p>내가 좋아하는 다른 뉴스레터들은:</p>\n<ul>\n<li>The Batch | DeepLearning.AI | AI News &#x26; Insights</li>\n<li>Deep Learning Weekly</li>\n<li>Interconnects | Nathan Lambert</li>\n<li>AI Tidbits | Sahar Mor</li>\n</ul>\n<div class=\"content-ad\"></div>\n<p>이 기사에 더 많은 내용이 있습니다.</p>\n<h1>유용할 수 있는 다른 커리큘럼/목록.</h1>\n<p>내 목록은 철저한 것이 아니었지만, 여전히 더 찾고 싶다면 몇 가지가 있습니다.</p>\n<ul>\n<li>openai/syllabus.md</li>\n<li>AI Canon | Andreessen Horowitz</li>\n<li>AI Learning Curation — LLM Utils</li>\n<li>Threshold to the AI Multiverse | Open DeepLearning</li>\n<li>louisfb01/start-llms: 2023년 LLM 스킬을 개선하기 위한 완벽한 가이드</li>\n</ul>\n<div class=\"content-ad\"></div>\n<p>이제 충분한 시간을 들여서 쓰고 정리를 했으니, 이제는 많은 것을 얻을 차례입니다. 배우고 무언가를 만들어 봐요.</p>\n<p>이것이 당신의 인공지능 여정에 도움이 되기를 바래요!</p>\n<p>만약 여기까지 읽었다면, 꼭 연락하거나 댓글을 남겨주세요 :)</p>\n<p>새로운 소식을 받기 위해 bitgrit 데이터 과학 게시물을 팔로우하는 것을 잊지 마세요!</p>\n<div class=\"content-ad\"></div>\n<p>최신 데이터 과학과 인공 지능 분야의 최신 소식을 다른 데이터 과학자들과 함께 논의하고 싶으신가요? 우리의 디스코드 서버에 참여해보세요!</p>\n<p>워크숍 및 다가오는 대회 소식을 받아보려면 Bitgrit를 팔로우해주세요!</p>\n<p>디스코드 | 웹사이트 | 트위터 | 링크드인 | 인스타그램 | 페이스북 | 유튜브</p>\n</body>\n</html>\n"},"__N_SSG":true}