{"pageProps":{"posts":[{"title":"레귤러 함수에서 컴포저블을 호출하는 것이 불가능한 이유","description":"","date":"2024-05-15 03:46","slug":"2024-05-15-WhyCallingaComposablefromaRegularFunctionIsntPossible","content":"\n\n이것은 컴파일러입니다!\n\n![image](/assets/img/2024-05-15-WhyCallingaComposablefromaRegularFunctionIsntPossible_0.png)\n\n이 기본 질문에 대한 답변을 제공하려면 구성 가능한 함수의 작동 방식을 깊이 이해해야 합니다.\n\n함수를 @Composable로 표시하면 노드를 추가할 수 있는 슈퍼파워를 가지게 됩니다. 이를 간단히 설명하자면, Compose UI 트리에 노드를 추가할 수 있게 되는 것입니다. 어떻게 노드가 되는지 이해하기 위해 기본적인 컴포저블을 작성해 봅시다.\n\n\n\n```\n```js\n@Composable\nfun IAmAComposable(){\n  Text(\"저는 콤포저블 함수입니다. 왜 함수냐면, 콤포즈는 즐겁거든!! 음, 즐겁지요\")\n}\n```\n\n우리가 정의한 콤포저블은 조합되면 반환할 것이 없지만, 만약 그렇지 않다면 UI는 어떻게 렌더링 될까요? 텍스트 콤포저블이 그 역할을 하고 있나요? 음, 아마요.\n\n조합이 일어날 때 콤포저블 트리 내에 노드가 생성되며, 모든 구현은 콤포저블 내부에 있습니다. 이 트리를 탐색하여 UI를 렌더링합니다. 이는 UI에만 국한되지 않고, 콤포즈 런타임 및 컴파일러를 사용하여 어떠한 종류의 트리 구조에 대해서도 효율적으로 탐색할 수 있습니다. 자세한 내용은 여기를 확인하세요.\n\n하지만 여러분이 여기로 왔는데도 계속 궁금한 점은, 왜 일반 함수에서 콤포저블을 호출할 수 없는 걸까요. 그래서 이에 대한 답변을 해볼게요.\n\n\n\n\n\nAndoroid 개발에서 fragment, activity 및 application context와 같은 다양한 종류의 context는 애플리케이션 내에서 리소스의 라이프사이클과 범위를 관리하는 데 중요한 역할을 합니다.\n\n각 context는 fragment나 activity와 같은 특정 구성요소의 라이프사이클과 관련이 있습니다. 이러한 context를 사용함으로써 서비스 및 리소스에 적절한 범위 내에서 액세스 및 관리되도록 보장할 수 있어서 애플리케이션의 전반적인 효율성과 신뢰성을 향상시킬 수 있습니다.\n\n비슷하게, 컴파일 후 각 콤포저블 함수는 \"콤포저(Composer)\"라는 추가 매개변수를 받습니다. 이 매개변수는 compose 컴파일러를 사용하여 주입됩니다.\n\n```js\n@Composable\nfun IAmAComposable($composer: $Composer<*>){ \n$composer.start(\\\\unique_key_here)\n    IAmComposablesChild($composer)\nText(\"I am a Composable fun, why fun? because compose is fun!! hmm fun ok\", $composer)\n$composer.end()\n}\n\n@Composable\nfun IAmComposablesChild($composer: Composer<*>){\n}\n```\n\n\n\n$composer은 그런 다컬저들에게 전달됩니다. 그때 이 composer은 유일한 키를 받는데요, 이 키는 다시 어떤 컴포저에 속한 노드인지 식별하는 데 사용됩니다. 이는 필수이며 트리 안의 각 노드에서 사용 가능해야 합니다. 위의 설명된 컴포저론, 부모 컴포저부터 트리의 마지막 컴포저까지 같은 composer 인스턴스가 사용될 것입니다.\n\n활동이 여러 프래그먼트를 가질 때와 같이, 모든 프래그먼트들의 활동 컨텍스트가 동일하게 됩니다.\n\n따라서 Composable 함수는 일반 함수에서 호출될 수 없습니다. 각 컴포저는 컴포저 형태의 상위 컨텍스트가 필요하기 때문에, 그 상위 컨텍스트가 없으면 구성이 되지 않습니다. 구성이란 무엇일까요? 그것은 컴포즈 트리를 탐색하고 (필요하다면) 각 노드를 화면에 렌더링하는 것이죠. 부모 노드가 없다면 렌더링할 수 없습니다.\n\n이 composer는 Compose 런타임에 의해 효율적으로 Compose UI 트리를 탐색하는 데 사용됩니다.\n\n\n\n이것은 상당히 간단한 예제와 설명입니다.하지만 이 모든 것을 자세히 배울 수 있습니다. 아래의 참고 자료들을 통해! \n\n즐거운 학습 되세요! ❤️","ogImage":{"url":"/assets/img/2024-05-15-WhyCallingaComposablefromaRegularFunctionIsntPossible_0.png"},"coverImage":"/assets/img/2024-05-15-WhyCallingaComposablefromaRegularFunctionIsntPossible_0.png","tag":["Tech"],"readingTime":3},{"title":"테라폼을 사용한 Sumo Logic 통합","description":"","date":"2024-05-15 03:43","slug":"2024-05-15-Sumologicintegrationusingterraform","content":"\n\n<img src=\"/assets/img/2024-05-15-Sumologicintegrationusingterraform_0.png\" />\n\n프로젝트에서 매우 기술에 능통한 고객을 위해 작업 중입니다. 그들은 매일 많은 수의 API를 활용하여 방대한 기술 생태계를 구축했습니다. 이들 API의 특정 활동을 분석하고 로깅하여 시스템을 더 잘 관리하고 개선하기 위해 다수의 활성 모니터를 가진 경보 시스템을 생성해야 했습니다.\n\n이 경보 시스템에서 그들은 Sumologic을 경보 시스템으로 선택했습니다.\n\n사용 사례:\n제 사용 사례는 다음과 같습니다. Sumologic 대시보드를 통해 모든 이러한 모니터를 수동으로 생성 및 구성했는데, 많은 수의 모니터를 관리하고 생성하는 작업은 번거로운 작업일 수 있습니다. 제 작업은 이 모니터 생성 및 관리 프로세스를 수동 작업에서 자동화된 방식 또는 코드를 통해 관리하는 것으로 변경하는 것이었습니다. 다시 말해, Sumologic 모니터를 Terraform과 통합하는 것입니다.\n\n\n\n아래 섹션에서는 수동으로 작성한 모든 Sumologic 모니터를 테라폼으로 변환하는 데 수행한 모든 단계를 안내할 것입니다.\n\n준비 사항:\n\n- 테라폼에 대한 기본 지식이 충분히 갖춰져 있다면 시작할 수 있습니다(테라폼 문서)\n\nSumologic 모니터:\n\n\n\n테라폼 코드를 올바르게 작성하여 Sumologic 모니터를 만들려면 먼저 Sumologic에서 이러한 모니터를 만드는 데 필요한 필드를 시각화해야 합니다.\n\nSumologic 대시보드에서 모니터를 만드는 \"Create a Monitor\"를 클릭하면 아래 화면이 나타납니다.\n\n![이미지](/assets/img/2024-05-15-Sumologicintegrationusingterraform_1.png)\n\n![이미지](/assets/img/2024-05-15-Sumologicintegrationusingterraform_2.png)\n\n\n\n![이미지](/assets/img/2024-05-15-Sumologicintegrationusingterraform_3.png)\n\n지금 보시는 예제 모니터의 설정을 테라폼 자원인 \"sumologic_monitor\"를 사용하여 생성할 수 있습니다. sumologic_monitor 자원 블록은 실제 모니터 필드와 매핑되는 몇 가지 특정 키-값 인수를 받아들일 것입니다.\n\n다음은 테라폼 코드와 SumoLogic 모니터 필드의 몇 가지 매핑 예시입니다.\n\n테라폼 모니터 생성:\n\n\n\n\n![Sumologic Integration using Terraform - Screenshot 4](/assets/img/2024-05-15-Sumologicintegrationusingterraform_4.png)\n\n```js\nresource \"sumologic_monitor\" \"any_name\" {\n\ntrigger_condition {\n   logs_static_condition {\n        ...\n   }\n}\n```\n\n![Sumologic Integration using Terraform - Screenshot 5](/assets/img/2024-05-15-Sumologicintegrationusingterraform_5.png)\n\n```js\nresource \"sumologic_monitor\" \"any_name\" {\n\ntrigger_condition {\n   logs_static_condition {\n     critical {\n       time_range = \"5m\"\n       alert {\n         thresold = \"0\"\n         thresold_type = \"GreaterThan\"\n       }\n       resolution {\n         thresold = \"0\"\n         thresold_type = \"LessThanOrEqual\"\n         resolution_window = \"5m\" \n       }\n     }\n   }\n}\n``` \n\n\n\n\n\n![image](/assets/img/2024-05-15-Sumologicintegrationusingterraform_6.png)\n\n```js\nresource \"sumologic_monitor\" \"any_name\" {\n  queries {\n    row_id = \"A\"\n    query = \"실행될 조건에 대한 실제 쿼리\"\n  }\n}\n```\n\n![image](/assets/img/2024-05-15-Sumologicintegrationusingterraform_7.png)\n\n통지를 위해 Slack, Webhook, Email 등과 같은 다양한 connection_type을 설정할 수 있습니다. sumologic 대시보드에 이미 있는 연결에 connection_id를 지정하거나 사용자 정의 연결을 만들고 알림 페이로드를 생성할 수 있습니다.\n\n\n\n\n|| Sumologic API를 참조하고 curl을 실행하여 모든 연결을 가져와서 connection_id를 이름으로 필터링할 수 있어요-\n\ncurl -u \"`accessId`:`accessKey`\" -X GET https://api.`deployment`.sumologic.com/api/v1/connections\n\n```js\nresource \"sumologic_monitor\" \"any_name\" {\n notifications: {\n  // 여러 알림 블록을 만들 수 있어요\n  notification: {\n   connection_type = \"Email\" //Slack | Webhook | Email 등\n   connection_id = \"<ID>\" //기존 ID\n  }\n  notification: {\n   connection_type = \"Slack\"\n   //이것은 사용자 정의된 payload에요\n   payload_override = <<JSON \n    {\n     \"service_key\": \"your_pagerduty_api_integration_key\",\n     \"event_type\": \"trigger\",\n     \"description\": \"Alert: Triggered {TriggerType} for Monitor {Name}\",\n     \"client\": \"Sumo Logic\",\n     \"client_url\": \"{QueryUrl}\"\n    }\n   JSON\n  }\n  run_for_trigger_types = [\"Critical\", \"ResolvedCritical\"] //위의 알림 모니터 이미지용 체크박스를 선택할 거에요\n}\n```\n\n<img src=\"/assets/img/2024-05-15-Sumologicintegrationusingterraform_8.png\" />\n\n```js\nresource \"sumologic_monitor\" \"any_name\" {\n name = \"monitor_name\"\n parent_id = \"<ID>\" //모니터가 생성될 폴더의 ID\n description = \"설명 문자열\"\n is_disabled = boolean // 이것은 모니터를 활성화 또는 비활성화할 거에요\n}\n```\n\n\n\n아래는 담당자의 작업 요약입니다:\n\n1. 'init.tf' 또는 'main.tf' 파일을 추가하여 Sumo Logic Terraform 공급자를 설치하고 초기화해야 합니다. main.tf 파일에 다음과 같은 코드를 추가하세요.\n\n```js\nterraform {\n\n backend \"s3\" {}\n\n required_providers {\n  sumologic = {\n   source = \"sumologic/sumologic\"\n   version = \"2.28.2\"\n  }\n }\n\n}\n\nprovider \"sumologic\" {\n access_id = \"\"\n access_key = \"\"\n}\n```\n\n2. 'sumologic-monitor.tf' 파일을 추가하여 위에서 언급한 내용이 포함된 'sumologic_monitor' 리소스를 추가하세요.\n3. 이후에는 테라폼 명령을 실행하면 됩니다.\n\n\n\n```js\nterrafrom init\nterrafrom plan\nterrafrom apply\n```\n\n참고 문서 -\n\n- Sumologic 모니터 생성에 대한 자세한 내용은 다음을 참조하세요: [Sumologic 모니터 생성](https://help.sumologic.com/docs/alerts/monitors/create-monitor/)\n- Terraform을 사용한 Sumologic 모니터 생성에 대한 자세한 내용은 다음을 참조하세요: [Sumologic 모니터 Terraform 문서](https://registry.terraform.io/providers/SumoLogic/sumologic/latest/docs/resources/monitor)\n- Sumologic API에 대한 자세한 내용은 다음을 참조하세요: [Sumologic API](https://api.sumologic.com/docs/#section/Getting-Started/API-Endpoints)","ogImage":{"url":"/assets/img/2024-05-15-Sumologicintegrationusingterraform_0.png"},"coverImage":"/assets/img/2024-05-15-Sumologicintegrationusingterraform_0.png","tag":["Tech"],"readingTime":5},{"title":"Kubernetes 복잡성 해결하기 파트 I","description":"","date":"2024-05-15 03:38","slug":"2024-05-15-NavigatingKubernetesComplexityPartI","content":"\n\n요즘 몇 년 동안 K8s 클러스터의 성장을 목격했습니다. 종종 서비스와 그를 사용하는 기업들... 실패하고 있다는 것을 보게 됩니다. 이러한 애플리케이션들은 작게 시작하여 유기적으로 성장하고 나중에는 느려지기 시작합니다. 디버깅 복잡성이 증가하고, 고객들이 짜증을 내며 불평을 하기 시작하고, 기업들은 성장 문제를 경험하며 등장했을 때와 같이 빠르게 사라지기도 합니다. 어떻게?!? 왜!?! 이 시리즈는 기업이 쿠버네티스 클러스터를 관리할 때 직면하는 어려움을 분석하여 실용적인 솔루션과 전문가의 통찰을 제공합니다. 지수적인 콜 수를 완화하고 소켓 이벤트 트래픽을 제어하는 등 각 기사는 성능을 최적화하고 안정성을 유지하는데 도움이 되는 선제적인 전략을 독자들에게 제공합니다.\n\n![image](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_0.png)\n\nK8s의 문제의 근본 원인은 매우 간단합니다: 복잡성! 그리고 우리는 개발자들을 탓할 수 없습니다 - K8s 위에 구축된 애플리케이션들은 일반적인 애플리케이션이 아니라 복잡한 분산 앱의 일부입니다. 분산 시스템은 쿠버네티스 클러스터 내에서 몇 백 개의 서비스만 작동하는 것보다 훨씬 복잡하며, 전반적인 그림을 파악하기는 매우 어려울 수 있습니다.\n\n![image](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_1.png)\n\n\n\n보통 시스템이 발전할수록 복잡성이 기하급수적으로 증가합니다. 특정 시기에는 내부 또는 외부 요청으로 인해 클러스터에 엄청난 부하가 걸리게 됩니다.\n\n나는 K8s를 좋아해요. 나의 의도는 그것을 깎아내릴 수 있는 것이 아니라, 실제 시스템에서 발생하는 상황들과 그 원인, 그리고 어떻게 방지할 수 있는지를 함께 알아보는 것입니다.\n\n# 1. 기하급수적 호출 수를 줄이기\n\n대부분의 K8s 앱은 다양한 서비스로 구성되어 있으며, 여기에 일반적인 앱 관리 서비스도 포함됩니다. 다음은 그 예시입니다:\n\n\n\n- Customers — 고객 상태 및 계획 확인\n- Users — 사용자 상태 확인\n- Permissions — 권한 관리\n\n이러한 공유 서비스들은 일반적으로 여러 서비스가 요청하여 해당 고객을 대신하여 작업을 중지해야 하는지 확인합니다. 이는 수신 요청 및 내부 서비스에도 적용됩니다.\n\n그래서, 다른 서비스를 호출할 수 있는 API 서비스를 만든다면, 간단한 요청이 여러 요청으로 변할 수 있습니다.\n\n![이미지](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_2.png)\n\n\n\n예를 들어, 들어오는 요청(n)이 첫 번째 레벨에서 다섯 개의 요청(#1, #2, #3, #5, #7)을 생성하고 두 번째 레벨에서 세 개의 추가 요청(#4, #6, #8)을 생성했다고 가정해보겠습니다. 생성된 총 요청 수는 n*8가 될 것입니다. 이것은 매우 간단한 예시입니다. 코드를 깊게 파헤쳐보면 숨겨진 요청들 (DNS, 데이터베이스 쿼리, API 등)을 발견할 수 있을 것입니다.\n\n모든 것을 측정하면 여러분의 애플리케이션이 예상 이상으로 기하급수적으로 복잡함을 발견할 수 있을 것입니다.\n\n요청의 지수적인 효과는 초기 요청보다 여덟 배 더 큰 내부 부하를 만들어 낼 수 있으며, 이는 우리 앱을 다운시킬 수 있습니다.\n\n수식을 해봅시다: 클러스터가 120만 개의 내부 요청을 처리할 수 있다고 가정해봅시다. 매일 클러스터는 10만 개의 외부 요청을 처리하고, 이는 내부 요청을 여덟 배 더 생성합니다 (대략 80만 개의 내부 요청). 이는 클러스터에 추가로 40만 개의 내부 요청을 처리할 여유가 있다는 것을 의미합니다. 이는 상당히 크게 느껴질 수 있지만, 추가로 5만 개의 외부 요청이 더 들어오면 한계점에 다다를 수 있습니다. 더 흥미로운 사실은 각 내부 요청을 줄일수록 한계점과의 거리가 멀어진다는 것인데, 이는 더 작은 자원으로 더 많은 일을 처리하면서 지수적인 증가를 줄일 수 있다는 것을 의미합니다.\n\n\n\n현재로서는 로드가 더 이상 비선형이 아니라 지수적입니다. 추가 요청 몇 개만으로도 앱의 일부가 다운되거나 응답하지 않고 불안정해질 수 있습니다.\n\n이런 일이 일어나지 않도록 어떻게 할 수 있을까요? 다행히 우리가 시도해볼 수 있는 몇 가지 쉬운 전략이 있습니다.\n\n## 컨텍스트 전파 사용\n\n컨텍스트 전파를 사용하면 요청 사이에서 재사용 가능한 정보를 헤더를 통해 주입하고 전파할 수 있습니다. 이를 통해 모든 서비스가 동일한 데이터를 요청하는 대신 요청을 만드는 모든 서비스로 데이터 집합을 전파할 수 있습니다.\n\n일부캐시(near caches)가 익숙할 것입니다. 데이터는 수명이 몇 초간 유지되는 TTL(time-to-live)을 가집니다. 우리는 요청의 시작 시간 초과에 맞게 TTL이 설정된 헤더에서 데이터 전달의 소스로서 컨텍스트 전파를 사용할 수 있습니다. TTL이 만료되면 클라이언트는 데이터를 새로 고침하고 그 후손 자식 요청으로 전파하기 전에 데이터를 갱신할 수 있어야 합니다. 이를 통해 헤더가 Kafka와 같은 다른 시스템으로 전파될 수 있습니다.\n\n예를 들어 고객 정보(#2)를 자식 요청으로 전파하면 하류에서 세 개의 요청을 절약할 수 있습니다.\n\n\n\n\n![Screenshot 1](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_3.png)\n\nThis lets you propagate a previous request downstream:\n\n![Screenshot 2](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_4.png)\n\n## Apply near caching\n\n\n\n\n일반적인 모범 사례에 따르면 정보 제공 서비스는 캐싱과 데이터 관리에 책임을 져야 합니다. 그러나 네이어 캐시는 높은 호출량을 갖는 API에 필수적입니다. 왜냐하면 우리는 보통 같은 메서드를 반복적으로 호출하기 때문이죠. 인스턴스를 확장할 수는 있지만, 아무 것도 무한정으로 확장되지는 않습니다. 그래서 네이어 캐싱을 통해 클러스터를 안정화할 수 있습니다.\n\n네이어 캐싱은 단명한 (가끔 몇 초 동안 유지되는) 클라이언트 측 캐시를 이용한 기술입니다. 만약 일반적인 HTTP 클라이언트에서 전역 캐싱 정책을 정의한다면, 모든 서비스에서 공통 요청에 대해 그 정책을 사용할 수 있습니다. 이는 이미 포화된 인프라에서 요청을 번들로 처리하고 비용을 상당히 절감할 수 있습니다.\n\n요청은 보통 묶음으로 들어옵니다. 고객이 페이지를 로드하기 시작하면, 여러 요청이 일어납니다. 현재 요청 이전에 몇 개의 요청이 이미 이루어졌다면(예: 이 예시에서의 #1 및 #2), 저희의 캐시는 이미 워밍업되어 있기 때문에 다음 요청에서 그 정보를 재활용하여 일부 호출을 절약할 수 있습니다.\n\n그래서 대규모에서 매우 단순한 기술을 사용하여 8개 중 5개의 호출을 절약했습니다. 믿어주세요, 실제 시스템은 이 예시보다 훨씬 복잡하기 때문에 혜택은 더 커질 수 있습니다. 복잡성을 줄이고 지수적인 증가를 최소화하여 8개 중 5개의 요청을 절약했습니다.\n\n\n## 호출 추적 로깅\n\n호출 추적을 로깅하면 요청의 시작부터 끝까지의 단계를 감지하고 분석할 수 있으며 어떤 호출이 이루어지는지 볼 수 있습니다. Grafana Tempo는 여러분의 추적을 저장하고 조회할 수 있는 솔루션 중 하나입니다.\n\n\n\n아래는 마크다운 포맷으로 변경해 드릴게요.\n\n\n![image](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_6.png)\n\n## 대량 요청 실행\n\n동일한 API를 여러 번 호출해야 할 경우, 리소스를 절약하고 네트워크 시간을 절약하기 위해 한 번에 모두 요청하세요.\n\n## 요청 속도 제한 (HTTP 429 '요청이 너무 많음')\n\n\n\n\n글로벌, 고객 및 사용자별로 허용 가능한 속도 제한을 부과하여 클러스터의 사용성에 영향을 줄 수 있는 남용을 방지하세요. 웹 애플리케이션 방화벽 (WAF)을 추가하는 것도 필요합니다. 최근에는 암호화된 HTTPS 데이터를 푸시하여 요청을 실행하는 결정을 서버가 아닌 방화벽이 내리는 데 영향을 미치지 않는 경우가 있습니다.\n\n이러한 조치를 취하면 남용을 방지하고 K8s 클러스터가 받는 부하를 제어할 수 있습니다.\n\n![image](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_7.png)\n\n이렇게 함으로써 WAF가 원치 않는 요청을 차단할 수 있습니다. 다양한 수준에서의 속도 제한은 고객 및 사용자의 요청 남용을 제어하여 클러스터가 지나치게 많은 부하를 처리하지 않도록 합니다. 물론 클러스터 수준에서 불필요하게 차단하길 원치는 않지만, 그 지점에 도달하면 클러스터가 이미 불안정할 수 있습니다. 따라서 모든 요청을 대규모로 실패시키는 것보다 429 상태 코드를 반환하는 것이 나은 대안입니다.\n\n# 2. 소켓 이벤트 트래픽 제어하기\n\n\n\n모든 메이저 웹 애플리케이션은 현재 서버에서 브라우저로 푸시 알림을 받습니다. 브라우저가 거의 실시간 데이터를 받을 수 있다는 것이 멋지다고 생각하지만, 그것들은 전통적인 데스크톱 애플리케이션처럼 보이고 느끼게 만들어줍니다. 그러나 브라우저는 아니라는 것을 명심해야 합니다.\n\n가끔 앱의 능력에 대해 잘못된 가정을 할 때도 있습니다.\n\n\"우리 서버는 백엔드에서 수천 개의 이벤트를 처리할 수 있어요.\" 네... 그런데 당신의 고객 브라우저는 그것을 처리할 수 있을까요? 고객의 머신은 서버가 아닙니다. 그들은 서버와 같은 처리 능력과 메모리를 가지고 있지 않습니다. 클라이언트 측에서 동일한 처리 능력을 모방하려고 한다면 실패로 이어질 것입니다.\n\n![이미지](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_8.png)\n\n\n\n푸시 알림은 최선을 다해 전달되어야 합니다: 프론트엔드로 이벤트를 전송하려고 노력하지만 보장할 수는 없습니다.\n\n고객이 백만 개의 업데이트를 생성하는 시나리오에서는 브라우저로 그만큼의 이벤트를 전달하려고 시도조차 해서는 안 됩니다. 이렇게 하면 대량의 데이터가 브라우저로 전송되어 플러시하는 데 몇 분 또는 심지어 몇 시간이 걸릴 수 있으며 네트워크 레이턴시에도 영향을 미칠 수 있습니다. 결국 좋은 대역폭을 갖춘 곳도 있고 강력한 컴퓨터를 갖춘 곳도 모두가 아니기 때문입니다.\n\n마지막으로 이처럼 많은 정보를 고객의 브라우저로 전달하는 것은 비용이 들 수 있습니다. 일부 데이터 센터는 외부 트래픽에 대해 요금을 부과하기 때문입니다.\n\n가끔은 이러한 이벤트를 듣고 있는 컴포넌트가 있어 업데이트되고 다른 요청을 만들기도 합니다. 몇몇 업데이트는 더 많은 요청을 만들어 눈덩이 효과를 낼 수 있습니다. 때로는 컴포넌트를 숨기지만 계속 청취하도록 유지하는 경우도 있으며, 이로 인해 이벤트 당 렌더링을 생성해 보이지 않게 될 수도 있습니다.\n\n\n\n그래서, 그 대신 어떻게 해야 할까요?\n\n### 아웃바운드 트래픽 속도 제한\n\n너무 많은 데이터를 밀어넣으면 고객의 브라우저와 네트워크가 느려지고 비용이 증가합니다. 그래서 데이터를 수용 가능한 수준으로 유지해야 합니다. 특정 사용자가 여러 브라우저나 탭으로 인한 여러 연결을 가지고 있다면 연결 수로 속도 제한을 나누어 사용자로부터 푸시되는 데이터 양을 제어할 수 있습니다.\n\n## 서버 측 이벤트 삭제\n\n\n\n과거 몇 분 이전의 이벤트는 삭제합니다. 이는 데이터가 쌓여 시작될 때 즉시 데이터를 버린다는 의미입니다. 비상 이벤트는 어떻게 할까요? 우리는 중요한 데이터를 일회용이 아닌 것으로 취급해야 합니다. 그러나 브라우저에서 받아야 할 소규모의 중요한 데이터 묶음에 대해서는 그렇지 않습니다. 예를 들어, 작업 확인과 같은 이벤트들은 다른 이벤트들보다 먼저 도착할 수 있도록 우선순위 레인이 있어야 합니다.\n\n![이미지](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_9.png)\n\n## 모든 필요한 데이터를 보내기\n\n모든 필요한 데이터는 이벤트의 일부여야 합니다. 프론트엔드는 알림을 받은 후 추가 요청을 하지 말아야 합니다. 그렇게 하면 이벤트에 기반한 비선형 요청이 발생합니다. 하나의 이벤트가 도착하면 한 번의 요청을 보내지만, 100k개의 이벤트를 받으면... 문제가 생길 수 있습니다. 특히 수천 명의 활성 사용자가 있는 경우 더욱 그렇습니다.\n\n\n\nAPI 요청을 관리하는 API 클라이언트를 사용하고, 브라우저 측에 가까운 캐시를 유지하여 일정 기간 동안 데이터를 유지하고 동일한 데이터에 대한 반복적인 호출을 피하세요. 가능하면 일부 전역 구성을 사용해주세요.\n\n![이미지](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_10.png)\n\n## 대기 중인 숨겨진 구성 요소를 준비하세요\n\n데이터를 수신하지만 다시 보이고 마지막으로 다시 렌더링 될 때까지 렌더링을 건너뛰세요. 여러 이벤트를 보내고 여러 숨겨진 구성 요소를 렌더링하는 경우, 쓸모없는 구성 요소를 렌더링하여 브라우저 성능에 영향을 줍니다.\n\n\n\n싱글 페이지 애플리케이션도 잘못된 아키텍처 결정으로 성능 문제가 발생할 수 있어요. 데이터와 뷰를 분리해서 업데이트하면서 뷰를 렌더링하지 않고 업데이트할 수 있어요.\n\n![image](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_11.png)\n\n# 3. 자체 프런트엔드 DDoS (분산 서비스 거부)\n\n때로는 개발자들이 영향을 인식하지 못하는 경우가 있어요. 토론이나 회의 중에 나타나는 몇 가지 사소한 문제들이 있어요.\n\n\n\n\"내 컴포넌트에 추가 요청을 딱 하나만 넣었어요.\"\n\n딱 한 개죠? 실제로, 그 컴포넌트가 다른 사용자에게 표시되는 횟수에 따라 다를 수 있습니다. '단 하나'의 추가 요청이 기능을 망가뜨린 것은 처음이 아닙니다. 왜냐하면 그 요청으로 많은 요청이 생성되어 기능이 그렇게 많은 요청을 처리할 준비가 되어있지 않았기 때문입니다. 실제로 라이브로 이를 배포하면 거의 즉시 망가질 것입니다. 또한 사용되는 페이지와 트래픽 양에 따라 달라집니다.\n\n\"내 React 컴포넌트는 내부 상태에 예상치 못한 케이스가 있어서, 지속적인 렌더링으로 인해 API 호출 무한 루프에 빠졌어요.\"\n\n이를 수천 명의 고객들에 대해 곱한다면, 모든 것이 다운될 것입니다. 재밌는 점은 수정을 배포했다 하더라도, 브라우저가 이를 감지하고 Javascript를 새로 고칠 때까지 시간이 걸릴 것이며, 이러한 사고를 완전히 해결하기가 어려울 수 있습니다.\n\n\n\n\"브라우저 DOM에 일부 구성 요소를 캐시하기로 결정했습니다.\"\n\n이론적으로는 괜찮아요. 이론상으로는요!\n\n대부분의 경우에는 숨겨진 구성 요소들이 계속 백그라운드에서 작동하여 이벤트를 수신하고 렌더링하며, 비록 보이지는 않지만 계속 작업을 수행합니다. 더 나쁜 경우에는 때로는 요청이 필요하지 않은 상태로 계속 발생하기도 합니다. 이런 일이 반복되면 모든 것을 느리게 만드는 충분한 수의 요청이 생성됩니다. 이러한 이벤트들이 숨겨진 구성 요소와 API 호출과 결합되면, 완벽한 슬로우다운 현상이 발생합니다: 앞단과 뒷단에서의 느림 현상이 발생합니다.\n\n단일 요청이 문제가 될 수 없을 것 같죠? 그러나 규모를 고려할 때, 수천 명의 사용자가 있는 상황에서는 요청이 수천 개로 변합니다. 그 영향의 크기는 여러 요소에 의해 달라집니다. 해당 구성 요소가 주요 페이지에 사용되는지 혹은 사용자가 많이 이용하는 페이지에 있는지 여부는 어떨까요? 백엔드가 그러한 요청을 처리할 수 있는지? 데이터베이스에 캐싱이 되어 있어서 데이터베이스에 접근할 필요가 없는지? 데이터베이스에는 이러한 요청을 처리할 복제본이 있는지? 프론트엔드 코드가 예기치 않은 시나리오를 방지할 만큼 충분히 커버리지가 되어 있는지?\"\n\n\n\n이 문제를 어떻게 완화할 수 있는지 알아보겠습니다.\n\n## 요청의 적절한 수를 처리할 수 있도록 기능을 준비하세요\n\n캐싱을 추가하고, 계산을 해서 적절하게 확장하세요. 데이터베이스가 도움 없이 모든 요청을 처리할 수 있다고 가정하지 마세요.\n\n## 프론트엔드 구성 요소에는 좋은 코드 커버리지가 필요합니다\n\n\n\n그렇지 않으면 모든 상황에서 잘 작동하지 않을 수 있습니다. 이는 앱을 충돌시킬 수 있는 무한 루프를 발생시킬 수 있습니다. 이러한 무한 루프는 모든 브라우저에서 Javascript 코드를 무효화해야 하기 때문에 감지하고 되돌릴 때 매우 어려울 수 있습니다.\n\n## 충분한 경고가있는 서비스 또는 엔드 포인트 지표\n\n일주일 동안 종단점이 일반적으로 받는 요청의 주간 이동 평균을 계산하고 시간당 청크로 나누세요. 이제 시간별 이동 평균을 사용하세요.\n\n![이미지](/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_12.png)\n\n\n\n마크다운 형식으로 테이블 태그를 변경하실 수 있습니다.\n\n\n\n두 값을 나누면 예상 최대 및 최소 비율이 나오는데, 이는 적응성이 있고 시간에 따라 요청 변동을 따릅니다. 이 비율은 시간당 요청이 주간 요청을 초과하거나 이하한 빈도를 신호합니다.\n\n<img src=\"/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_13.png\" />\n\n```js\n(sum(increase(docbase_api_web_request_count{service=\"docbase-api\"}[1h]))) / \n(sum(increase(docbase_api_web_request_count{service=\"docbase-api\"}[1w]))/7/24)\n```\n\n이제 이러한 요청에 대한 알림을 생성할 수 있습니다. 예를 들어, 임계값을 3.5 또는 4로 설정하면 트래픽의 예상치를 초과하는 경우에 알림을 받게 됩니다 (차트에서 지난 주에는 3을 넘지 않았음을 볼 수 있습니다). 요청 수에 기반한 알림을 설정하는 경우, 트래픽 패턴이 변경될 때마다 요청 번호를 업데이트해야 합니다.\n\n\n\n이 알림을 만들면 일반적으로 감지하기 어려운 트래픽 변화를 모니터링할 수 있습니다. 특히 자체 생성된 DDoS 공격의 경우, 합법적이고 인가된 트래픽이라도 감지하는 데 몇 주가 걸릴 수 있습니다.\n\n# 최종 메모\n\nK8s는 때로 잘못 사용되거나 제대로 이해되지 않을 수 있지만, 좋은 도구입니다. 이를 사용하는 것은 쉽지만, 우리가 원하는 대로 확장하는 것은 훨씬 복잡하며, 예상과 달리 일어나면 혼란스럽고 당황스럽게 만들 수 있습니다.\n\nK8s를 사용할 때 제안하는 바는 상식을 사용하는 것입니다. 상상력을 발휘하고 무엇이 일어나고 있는지, 어떻게 개선할 수 있는지 스스로에게 물어보고, 물론 규모에 맞게 생각하는 것입니다. 그냥 요청만 하는 것이 아닙니다. 그냥 구성 요소만 있는 것이 아닙니다. 모든 것이 제대로 최적화되지 않거나 고려되지 않으면 큰 영향을 줄 수 있습니다.\n\n\n\n\n적절한 도구를 갖추는 것도 매우 중요해요. 추적을 위해 Tempo를 사용하고, 로깅을 위해 Loki를 사용하며, 메트릭 및 경고를 위해 Grafana를 사용하세요. 이 도구들이 없다면, 기본적으로 맹목적일 거예요. K8s를 작동시키려면 백엔드에 OpenTelemetry를, 프론트엔드에는 Faro와 같은 RUM(실 사용자 모니터링) 도구를 사용해야 해요.\n\n쿠버네팅을 즐기세요.\n\n(계속됨…)\n\n참고 문헌:\n\n\n\nhttps://www.meetup.com/pipedrive-talks-lisbon/events/299275446/\n\nhttps://medium.com/dev-beinfra/k8s-pt-4-deployment-istio-aks-33201db9156a\nhttps://www.rawpixel.com/image/12649860/bomb-explosion-effect-png-transparent-background","ogImage":{"url":"/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_0.png"},"coverImage":"/assets/img/2024-05-15-NavigatingKubernetesComplexityPartI_0.png","tag":["Tech"],"readingTime":10},{"title":"최근 놓치고 있는 도커 빌드킷의 기능들","description":"","date":"2024-05-15 03:35","slug":"2024-05-15-RecentDockerBuildKitFeaturesYoureMissingOutOn","content":"\n\n![이미지](/assets/img/2024-05-15-RecentDockerBuildKitFeaturesYoureMissingOutOn_0.png)\n\nBuildKit 도입으로 Docker의 향상된 빌더 백엔드가 도입되었고, 많은 새로운 기능이 Docker에 추가되었습니다. 그 중 많이 알려지지 않은 기능들을 알아야 할 것이며, Docker를 더 잘 활용하기 위해 사용해야 할 것들에 대한 소개입니다.\n\n# 디버깅\n\n가장 일반적인 작업인 디버깅부터 시작해보겠습니다. Docker 빌드의 디버깅은 항상 고통스러운 작업이었습니다. RUN 또는 COPY 명령이 실패하면 일반적으로 문제가 발생한 상황을 확인하고 디버깅하기가 까다로웠습니다. 일반적으로 RUN ls -la와 같은 명령을 추가하여 더 많은 정보를 얻기 위해 시도했습니다. 그러나 이제는 docker buildx debug를 통해 이 상황이 바뀌었습니다.\n\n\n\n```js\nexport BUILDX_EXPERIMENTAL=1\ndocker buildx debug --invoke /bin/sh --on=error build .\n\n[+] Building 1.2s (14/18)                docker:default\n...\n------\n > [builder 5/6] RUN exit 1:\n------\nDockerfile:10\n--------------------\n   8 |     RUN pip3 install -r requirements.txt\n   9 |     \n  10 | >>> RUN exit 1\n  11 |     \n  12 |     COPY . /app\n--------------------\nERROR: process \"/bin/sh -c exit 1\" did not complete successfully: exit code: 1\n[+] Building 0.0s (0/0)                  docker:default\nLaunching interactive container. Press Ctrl-a-c to switch to monitor console\nInteractive container was restarted with process \"u6agxp1ywqapemxrt8iexfv4h\". Press Ctrl-a-c to switch to the new container\n/ # ls -la\ntotal 72\ndrwxr-xr-x    1 root     root          4096 May  5 12:59 .\ndrwxr-xr-x    1 root     root          4096 May  5 12:59 ..\ndrwxr-xr-x    1 root     root          4096 May  4 10:11 app\n...\n```\n\n위 스니펫에서 먼저 실험적인 BuildKit 기능을 BUILDX_EXPERIMENTAL 환경 변수로 활성화합니다. 그런 다음 docker buildx debug를 통해 빌드를 시작합니다. 빌드가 어느 시점에서든 실패하면 컨테이너로 이동하여 실행 문맥을 탐색하고 디버깅할 수 있습니다.\n\n빌드가 실패했을 때만 디버그 세션을 시작하는 --on=error 옵션을 포함했음에 유의하세요.\n\n자세한 내용은 디버깅 문서를 참조하십시오.\n\n\n\n# 환경 변수\n\n만약 이전에 BuildKit으로 빌드를 실행했다면 새롭고 멋진 로그 출력을 눈치챘을 것입니다. 멋져 보이긴 하지만 디버깅할 때는 그리 실용적이지 않죠. 그럴 때는 평범한 로그 출력으로 전환할 수 있는 환경 변수가 있습니다:\n\n```js\nexport BUILDKIT_PROGRESS=plain\n```\n\n원하는 경우 rawjson으로 설정할 수도 있지만, 이는 사람이 직관적으로 읽기 어려울 수 있지만 어떤 방식으로든 로그를 처리하고 싶을 때 유용할 수 있습니다.\n\n\n\n만약 TTY 기반의 동적 출력을 좋아하지만 색상을 싫어한다면, 간단히 다음과 같이 변경할 수 있습니다:\n\n```js\nBUILDKIT_COLORS=\"run=green:warning=yellow:error=red:cancel=cyan\" docker buildx debug --invoke /bin/sh --on=error build .\n```\n\n위와 같이 출력이 변합니다:\n\n<img src=\"/assets/img/2024-05-15-RecentDockerBuildKitFeaturesYoureMissingOutOn_1.png\" />\n\n\n\n기타 환경 변수에 대한 문서를 참조해보세요.\n\n# Exporters\n\nBuildKit은 빌드 결과물이 어떻게 저장될지를 정의하는 수출자(Exporters) 개념을 소개합니다. 가장 유용한 두 가지 옵션은 이미지(image)와 레지스트리(registry)입니다. image는 기대했을 것처럼 빌드 결과물을 컨테이너 이미지로 저장하며, 레지스트리 수출자는 자동으로 지정된 레지스트리로 푸시합니다:\n\n```js\ndocker buildx build --output type=registry,name=martinheinz/testimage:latest .\n```\n\n\n\n우리가 해야 할 일은 --output 옵션을 지정하고 registry의 유형과 대상을 설정하는 것뿐입니다. 이 옵션은 한 번에 여러 레지스트리를 지정하는 것도 지원합니다:\n\n```js\ndocker buildx build --output type=registry,\\\"name=docker.io/martinheinz/testimage,docker.io/martinheinz/testimage2\\\" .\n```\n\n마지막으로, --cache-to 및 --cache-from 옵션을 제공하여 레지스트리에서 기존 이미지를 캐시 소스로 사용할 수도 있습니다:\n\n```js\ndocker buildx build --output type=registry,name=martinheinz/testimage:latest \\\n --cache-to type=inline \\\n --cache-from type=registry,ref=docker.io/martinheinz/testimage .\n\n...\n => CACHED docker-image://docker.io/docker/dockerfile:1.4@sha256:9ba7531bd80fb0a858632727cf7a112fbfd19b17e94c4e84ced81e24ef1a0dbc\n...\n => CACHED [builder 2/5] WORKDIR /app                                                                                                  0.0초\n => CACHED [builder 3/5] COPY requirements.txt /app                                                                                    0.0초\n => CACHED [builder 4/5] RUN --mount=type=cache,target=/root/.cache/pip     pip3 install -r requirements.txt                           0.0초\n => CACHED [builder 5/5] COPY . /app                                                                                                   0.0초\n => CACHED [dev-envs 1/3] RUN <<EOF (apk update...)                                                                                    0.0초\n => CACHED [dev-envs 2/3] RUN <<EOF (addgroup -S docker...)                                                                            0.0초\n => CACHED [dev-envs 3/3] COPY --from=gloursdocker/docker / /                                                                          0.0초\n => preparing layers for inline cache                                                                                                  0.0초\n...\n```\n\n\n\n# 이미지 도구\n\n도커 빌드x의 간편하지만 유용한 서브커맨드인 imagetools는 이미지를 가져오지 않고도 레지스트리의 이미지를 검사할 수 있게 해줍니다. 자세한 내용은 많은 예시를 포함하고 있지만, 저에게 가장 유용한 것은 원격 이미지의 다이제스트를 가져오는 것입니다:\n\n```js\ndocker buildx imagetools inspect alpine --format \"{json .Manifest}\" | jq .digest\n\"sha256:c5b1261d6d3e43071626931fc004f70149baeba2c8ec672bd4f27761f8e1ad6a\"\n```\n\n# 최신 Dockerfile 구문\n\n\n\n빌드킷과 함께 새로운 Dockerfile 구문이 도입되었습니다. 이를 통해 Dockerfile 프론트엔드라는 것이 사용됩니다. 현재 최신 구문을 활성화하려면 Dockerfile 맨 위에 다음과 같은 지시문을 추가해야 합니다:\n\n```js\n# syntax=docker/dockerfile:1.3\nFROM ...\n```\n\n버전을 확인하려면 dockerfile-upstream 도커 허브 저장소를 확인하세요.\n\n\n\n지금부터 소개할 첫 번째 도커 파일 문법 개선 사항은 here-docs입니다. 여기서는 멀티 라인 스크립트를 RUN 및 COPY 명령어에 전달할 수 있게 해줍니다:\n\n```js\n# syntax = docker/dockerfile:1.3-labs\nFROM debian\nRUN <<eot bash\n  apt-get update\n  apt-get install -y vim\neot\n\n# 같은 내용:\nRUN apt-get update && apt-get install -y vim\n```\n\n과거에는 단일 RUN에 여러 명령어를 넣고 싶다면 &&을 사용해야 했지만, 이제는 here-docs를 사용하여 일반 스크립트를 작성할 수 있습니다.\n\n게다가, 첫 번째 줄에서 해석기를 지정할 수 있어 Python 스크립트를 작성할 수도 있습니다:\n\n\n\n```bash\n# syntax = docker/dockerfile:1.3-labs\nFROM python:3.6\nRUN <<eot\n#!/usr/bin/env python\nprint(\"hello world\")\neot\n```\n\n# COPY and ADD Features\n\n새로운 Dockerfile 구문에서는 COPY 및 ADD에 대한 변경 사항과 개선 사항도 더 많이 있습니다.\n\nCOPY는 이제 --parents 옵션을 지원합니다:\n\n\n\n\n```js\n# syntax=docker/dockerfile:1.7.0-labs\nFROM ubuntu\n\nCOPY ./one/two/some.txt /normal/\n\nRUN find /normal\n#10 [3/5] RUN find /normal\n#10 0.223 /normal\n#10 0.223 /normal/some.txt\n\nCOPY --parents ./one/two/some.txt /parents/\n\nRUN find /parents\n#12 [5/5] RUN find /parents\n#12 0.509 /parents\n#12 0.509 /parents/one\n#12 0.509 /parents/one/two\n#12 0.509 /parents/one/two/some.txt\n```\n\n만약 일반 COPY로 중첩된 파일을 복사하면 이미지에는 부모 디렉토리 없이 파일 자체만 포함되며, --parents로 전체 파일 트리가 복사됩니다. 이는 cp --parents의 작동 방식과 유사합니다.\n\n--exclude 옵션을 사용할 수 있는 것과 같이, --parents 옵션도 사용할 수 있습니다:\n\n```js\nCOPY --exclude=*.txt ./some-dir/* ./some-dest\n```\n\n\n\n파일을 복사할 때 제외된 파일 및 패턴을 무시하는 옵션입니다.\n\n마침내 ADD 명령어도 향상되었습니다 - 이제 Git 저장소를 직접 추가할 수 있습니다:\n\n```js\n# syntax=docker/dockerfile:1.7.0-labs\nFROM ubuntu\n\nADD git@github.com:kelseyhightower/helloworld.git /repo\nRUN ls -la /repo\n```\n\n이 Dockerfile을 빌드하면 다음과 같은 결과를 얻을 수 있습니다:\n\n\n\n\ndocker buildx build --ssh default --progress=plain .\n- [2/3] ADD git@github.com:kelseyhightower/helloworld.git /repo\n  - Warning: Permanently added 'github.com' (ED25519) to the list of known hosts.\n  - ref: refs/heads/master HEAD\n    - 96a652519d1aaca11085ca3a7806bead4d2c273f   HEAD\n    - 96a652519d1aaca11085ca3a7806bead4d2c273f   refs/heads/master\n  - ref: refs/heads/master HEAD\n    - 96a652519d1aaca11085ca3a7806bead4d2c273f   HEAD\n    - From github.com:kelseyhightower/helloworld\n      - [new branch]      master     -> master\n      - [new branch]      master     -> origin/master\n  - DONE 7.4s\n- [2/3] ADD git@github.com:kelseyhightower/helloworld.git /repo\n  - DONE 0.0s\n\n\n이것은 비공개 저장소에도 작동합니다.\n\n더 많은 흥미로운 옵션을 문서에서 볼 수 있습니다. 예를 들어, --keep-git-dir이나 --checksum을 통해 아티팩트 체크섬을 유효성 검사할 수 있습니다.\n\n# 보너스: 들여쓰기\n\n\n\n그리고 BuildKit 기능은 아니지만, 최근에 발견한 하나의 사실은 Dockerfile에서 줄을 들여쓰면 잘 작동한다는 것입니다. 이렇게 하면 다단계 빌드를 진행할 때 가독성이 향상되는 효과를 얻을 수 있습니다:\n\n```js\n# syntax=docker/dockerfile:1\nFROM golang:1.21\n  WORKDIR /src\n  \n  COPY main.go .\n  RUN go build -o /bin/hello ./main.go\n\nFROM scratch\n  COPY --from=0 /bin/hello /bin/hello\n  CMD [\"/bin/hello\"]\n```\n\n처음에는 이상하게 보일 수 있지만, 내견에 따르면 더 읽기 쉬워져서 각 단계가 어디에서 시작되고 어떤 명령이 속해 있는지 명확해집니다.\n\n# 결론\n\n\n\n이 기사의 예시는 내가 가장 유용하다고 생각하는 기능들만을 보여줍니다. 그러나 Docker 공식 문서와 BuildKit 문서, 또한 최신 변경 사항을 확인해보십시오. Docker 블로그도 좋은 자료가 있으며 특히 표시된 글들을 확인해보세요.\n\n이 기사는 원래 martinheinz.dev에서 게시되었습니다.\n\n또한 다음 글들을 즐기실 수도 있습니다...","ogImage":{"url":"/assets/img/2024-05-15-RecentDockerBuildKitFeaturesYoureMissingOutOn_0.png"},"coverImage":"/assets/img/2024-05-15-RecentDockerBuildKitFeaturesYoureMissingOutOn_0.png","tag":["Tech"],"readingTime":8},{"title":"데이터 보안 Databricks의 열 수준 암호화","description":"","date":"2024-05-15 03:31","slug":"2024-05-15-DataSecurityColumnLevelEncryptioninDatabricks","content":"\n\n데이터 보안은 모든 데이터 엔지니어링 플랫폼에서 중요한 개념 중 하나입니다. 대부분의 기업들은 데이터 플랫폼의 보안 기능을 구현하기 위해 많은 비용을 투자합니다.\n\n# 왜 데이터 보안이 중요한가요?\n\n- 민감한 정보 보호: 먼저, 민감한 정보를 보호해야 합니다. Databricks는 대량의 데이터를 저장하고 처리하는 데 사용됩니다. 그 중에는 금융 데이터, 개인 정보 또는 지적 재산과 같이 민감한 정보가 포함될 수 있습니다. 그러므로, 민감한 정보가 \"무단 접근\", \"도난\" 또는 \"남용\"으로부터 보호되도록 하는 것이 중요합니다.\n- 규정 준수: 대부분의 산업은 \"규정 준수\"와 같은 일정한 규제를 따릅니다. 그러한 \"규정\"은 민감한 데이터의 생산을 강제합니다. 이러한 \"규정\"을 준수하면 법적 제재를 피하는 데 도움이 됩니다.\n- 데이터 침해 방지: 데이터 침해는 \"재정적 손실\", \"계산적 피해\" 또는 \"법적 책임\"을 포함한 심각한 결과를 초래할 수 있습니다. 적절한 데이터 보안 조치를 통해 데이터 침해를 예방하고 영향을 최소화할 수 있습니다.\n- 고객과의 신뢰 유지: 고객과의 신뢰를 유지하는 것은 어떤 비즈니스에게 가장 중요한 부분 중 하나입니다. 고객과 클라이언트는 그들의 데이터를 기업에 신뢰합니다. 고객 데이터가 안전하다는 것을 보장하는 것은 그들의 신뢰를 유지하고 장기적인 관계를 유도하는 데 중요합니다.\n\n# Databricks 보안 기능\n\n\n\nDatabricks는 다음과 같은 보안 기능을 제공하여 Databricks 플랫폼에 저장되고 처리되는 데이터의 보안과 개인 정보 보호를 보장합니다 -\n\n- 휴식 시 암호화\n- 이동 중 암호화\n- 역할 기반 액세스 제어\n- 다중 인증 요소\n- 감사 로깅\n\n# 열 수준 휴식 중 암호화\n\nDelta Lake가 개발되거나 Databricks 내에서 데이터 웨어하우징 솔루션이 구축될 때마다 데이터를 \"열 수준\"에서 \"암호화\"할 수 있습니다.\n\n\n\n## 단계 1: 델타 테이블 만들기\n\n```js\nfrom delta.tables import *\n\nDeltaTable.create(spark)\\\n  .tableName(\"tbl_Person\")\\\n  .addColumn(\"Person_Id\", \"INT\")\\\n  .addColumn(\"Person_Name\", \"STRING\")\\\n  .addColumn(\"Person_Adhar_No\", \"STRING\")\\\n  .execute()\n```\n\n델타 테이블에서 \"Person_Adhar_No\" 열에는 민감한 정보, 즉 PII(개인 식별 정보)가 포함될 것입니다. 따라서 이 특정 열에 보안이 강제됩니다.\n\n## 단계 2: PII 데이터를 델타 테이블에 삽입하기\n\n\n\n```js\n%sql\nINSERT INTO tbl_Person VALUES(101, \"Oindrila Chakraborty\", \"123456789012\");\nINSERT INTO tbl_Person VALUES(102, \"Soumyajyoti Bagchi\", \"234567890123\");\nINSERT INTO tbl_Person VALUES(103, \"Abhirup Chakraborty\", \"345678901234\");\nINSERT INTO tbl_Person VALUES(104, \"Souvik Roy\", \"456789012345\");\n```\n\n## Step 3: View Data of the Delta Table\n\n```js\n%sql\nSELECT * FROM tbl_person;\n```\n\nOutput -\n\n\n\n<img src=\"/assets/img/2024-05-15-DataSecurityColumnLevelEncryptioninDatabricks_0.png\" />\n\n## 단계 4: \"cryptography\" Python 라이브러리 설치\n\n테이블의 데이터를 쿼리할 때 민감한 정보가 그대로 표시됩니다. 이는 PII 데이터가 오용될 수 있는 보안 위협입니다.\n\n민감한 정보, 즉 PII(개인 식별 정보)가 그대로 표시되는 것을 방지하기 위해 \"Cryptography\"를 사용할 수 있습니다.\n\n\n\n파이썬 라이브러리인 \"cryptography\"를 설치해야 합니다.\n\n```js\npip install cryptography\n```\n\n## 단계 5: \"cryptography\" Python 라이브러리의 \"Fernet\" 라이브러리를 사용하여 암호화/복호화 키 생성\n\n\"암호화\" Python 라이브러리 내부에 있는 \"Fernet\"라는 라이브러리를 사용해야 합니다. \n\"Fernet\" 라이브러리에는 \"generate_key()\", \"encrypt()\", \"decrypt()\" 등 여러 메서드가 있습니다.\n\n\n\n이제 먼저 \"암호화 키\"를 생성해야 합니다. 이 키를 사용하여 데이터를 \"암호화\"하거나 \"복호화\"할 수 있습니다.\n\n```js\nfrom cryptography.fernet import Fernet\n\nkey = Fernet.generate_key()\nk = Fernet(key)\n```\n\n위 코드는 \"암호화 키\"를 생성하고 \"k\"라는 변수에 저장합니다.\n\n## 단계 6: 델타 테이블의 PII 데이터를 암호화하는 UDF 생성\n\n\n\nDelta Table \"tbl_person\"의 열인 \"Person_Adhar_No\"에서 PII 데이터를 받아 들이는 \"encrypt_data\"라는 UDF를 작성해 보겠습니다. 그리고 생성된 \"암호화 키\"도 받아들입니다. 그런 다음, 이 UDF는 수신된 데이터에 대해 암호화를 적용하기 위해 라이브러리 \"Fernet\"의 \"encrypt ()\" 함수를 호출할 것입니다.\n\n```python\ndef encrypt_data(data, key):\n    from cryptography.fernet import Fernet\n    k = Fernet(key)\n\n    data_in_byte = bytes(data, \"utf-8\")\n    encrypted_data = k.encrypt(data_in_byte)\n    encrypted_data = str(encrypted_data.decode(\"ascii\"))\n\n    return encrypted_data\n```\n\n## 단계 7: 델타 테이블의 암호화된 PII 데이터를 복호화하는 UDF 생성\n\n델타 테이블의 열 \"Person_Adhar_No\"에서 이미 암호화된 PII 데이터를 받아 들이는 다른 UDF를 만들어 보겠습니다. 그리고 생성된 \"암호화 키\"도 받아들입니다. 그런 다음, 이 UDF는 이미 암호화된 데이터를 복호화하기 위해 라이브러리 \"Fernet\"의 \"decrypt ()\" 함수를 호출할 것입니다.\n\n\n\n\n```js\ndef decrypt_data(encrypted_data, key):\n  from cryptography.fernet import Fernet\n  k = Fernet(key)\n\n  decrypted_data = k.decrypt(encrypted_data.encode()).decode()\n\n  return decrypted_data\n```\n\n## 단계 8: 생성한 UDF 등록하기\n\n데이터프레임에서 생성한 UDF를 사용하려면 해당 UDF를 등록해야합니다.\n\nUDF를 등록하려면 UDF를 사용하는 \"함수(udf())\"를 사용해야합니다. 이 함수는 생성한 UDF의 \"이름\"과 UDF가 수용하는 \"매개변수의 데이터 유형\"을 입력해야합니다.\n\n\n\n```js\nfrom pyspark.sql.types import StringType\n\nencrypt_func = udf(encrypt_data, StringType())\ndecrypt_func = udf(decrypt_data, StringType())\n```\n\n## 단계 9: 민감한 데이터 암호화\n\n이 예제에서는 먼저 Delta 테이블 \"tbl_person\"을 기반으로 DataFrame을 만듭니다.\n이제 생성된 DataFrame에 \"adhar_encrypted\"라는 추가 열이 추가됩니다. 이를 위해 \"등록된 UDF 함수\"인 \"encrypt_func\"이 호출됩니다.\n\"등록된 UDF 함수\"인 \"encrypt_func\"은 생성된 DataFrame의 \"Person_Adhar_No\" 열과 생성된 \"Encryption Key\"를 인수로 받습니다.\n마지막으로 \"암호화된 DataFrame\"인 \"encrypted_df\"를 표시합니다.\n\n```js\nfrom pyspark.sql.functions import *\n\ndf = spark.table(\"tbl_person\")\nencrypted_df = df.withColumn(\"adhar_encrypted\", encrypt_func(\"Person_Adhar_No\", lit(key)))\ndisplay(encrypted_df)\n```\n\n\n\n아래 이미지에서 볼 수 있듯이, 실제 값은 \"Person_Adhar_No\" 열에 존재하고, 암호화된 값은 \"adhar_encrypted\" 열에 있습니다.\n\n## 단계 10: 이미 암호화된 민감한 데이터 복호화하기\n\n\n\n델타 테이블의 일부 사용자는 원본 데이터를 볼 필요가 있습니다. 따라서 이미 암호화된 데이터를 동일한 \"암호화 키\"를 사용하여 복호화해야 합니다.\n\n이 예시에서는 \"암호화된 DataFrame\"인 \"encrypted_df\"에 또 다른 열인 \"adhar_decrypted\"가 추가되어 최종 \"복호화된 DataFrame\"인 \"decrypted_df\"가 생성됩니다. 이를 위해 \"등록된 UDF 함수\"인 \"decrypt_func\"이 호출될 것입니다. \"등록된 UDF 함수\"인 \"decrypt_func\"은 \"암호화된 DataFrame\"인 \"encrypted_df\"의 열 \"adhar_encrypted\"와 생성된 \"암호화 키\"를 매개변수로 받을 것입니다. 마지막으로 \"복호화된 DataFrame\"인 \"decrypted_df\"를 표시하세요.\n\n```js\ndecrypted_df = encrypted_df.withColumn(\"adhar_decreypted\", decrypt_func(\"adhar_encrypted\", lit(key)))\ndisplay(decrypted_df)\n```\n\n결과 -\n\n\n\n위 이미지를 보면 \"Person_Adhar_No\" 열에 실제 값이 존재하고, \"adhar_encrypted\" 열에 암호화된 값이 있음을 확인할 수 있습니다. 그리고 \"adhar_encrypted\" 열의 복호화된 값은 \"adhar_decrypted\" 열에 있으며, 이 값은 실제 값과 동일합니다.","ogImage":{"url":"/assets/img/2024-05-15-DataSecurityColumnLevelEncryptioninDatabricks_0.png"},"coverImage":"/assets/img/2024-05-15-DataSecurityColumnLevelEncryptioninDatabricks_0.png","tag":["Tech"],"readingTime":6},{"title":"AWS 자격증 취득하기 5가지 간단한 단계","description":"","date":"2024-05-15 03:28","slug":"2024-05-15-HowtogetAWSCertifiedin5SimpleSteps","content":"\n\n<img src=\"/assets/img/2024-05-15-HowtogetAWSCertifiedin5SimpleSteps_0.png\" />\n\nAmazon Web Services (AWS) 자격증 취득은 많은 IT 전문가들에게 갈망하는 목표로, 클라우드 컴퓨팅 분야에서의 경력 여정에서 중요한 이정표를 의미합니다. 클라우드 서비스 분야에서 선도적인 위치에 있는 AWS는 아키텍트, 개발자, 운영 직원 등 다양한 역할을 대상으로 한 광범위한 자격증을 제공합니다.\n\nAWS 자격증은 영예의 표지뿐만 아니라, AWS를 활용하여 혁신을 일으키고 실제 문제를 해결하는 데 대한 소지자의 전문 지식을 입증하는 것입니다.\n\nAWS 자격증 취득 프로세스를 탐색하는 방법에 대한 포괄적인 안내서를 제공하며, 성공을 이루기 위한 통찰력으로 가득한 내용입니다.\n\n\n\n# 1. 전략적 계획과 목표 설정\n\nAWS 자격증 취득은 신중하게 계획을 세우는 것으로 시작합니다. 자격증 취득 여정은 단거리 경주가 아닌 장거리 마라톤이며, 헌신과 전략적 준비가 필요합니다.\n\n먼저, 자신의 커리어 지향점 또는 현재의 직무 역할과 일치하는 AWS 자격증을 식별하십시오. AWS는 기초, 어소시에이트, 프로페셔널, 그리고 스페셜티 수준의 자격증을 제공하며, 각각은 특정한 커리어 경로를 위해 설계되었습니다.\n\n# 적절한 자격증 선택\n\n\n\n- 기초 수준: 초보자에게 이상적인 AWS 인증 클라우드 실무자 자격증은 기본적인 클라우드 개념과 AWS 서비스를 다룹니다.\n- 연계 수준: AWS 솔루션 아키텍트, AWS 개발자 억스시오시에트 및 AWS 시스옵스 관리자와 같은 역할을 위한 것으로, 이러한 인증서는 AWS 상에서 응용 프로그램을 디자인, 배포 및 관리하는 데 더 깊이 들어가게 됩니다.\n- 전문가 수준: 경험이 풍부한 클라우드 전문가를 대상으로 한 이 인증은 AWS 서비스와 최상의 실천 방법에 대한 포괄적인 이해를 요구합니다.\n- 전문 분야 수준: 이 인증은 고급 네트워킹, 보안, 기계 학습, 데이터베이스와 같은 전문 분야에 중점을 두고 있습니다.\n\n# 당신만의 로드맵을 만들어 보세요\n\n각 단계에 대한 현실적인 마감일을 설정하여 자세한 학습 계획을 개요화하세요. 예상치 못한 지연을 위한 여유 시간을 확보하고, 작업, 공부 및 개인 시간을 조화롭게 조합하여 균형 잡힌 접근 방식을 취할 수 있도록 계획을 수립하세요. 여러 인증을 얻고자 한다면, 경력 요구 사항이나 고급 인증을 위해 필요한 기본 지식에 따라 인증을 우선 순위에 맞추세요.\n\n# 2. 고품질 교육 자료로 참여하기\n\n\n\n올바른 교육 자료 선택은 중요합니다. 이상적인 자원은 AWS 개념, 실제 응용 프로그램 및 시험에 특화된 지식을 포괄적으로 다루어야 합니다.\n\n클라우드 서비스의 동적인 성격을 감안하여 콘텐츠가 최신 AWS 기능과 최상의 실천 방법을 반영하고 있는지 확인하세요.\n\n# 교육 과정에서 찾아야 할 것들\n\n- 포괄적인 내용: 시험 청사진을 철저하게 다루며 이론적인 통찰과 실제 응용 프로그램을 모두 제공하는 과정을 선택하세요.\n- 최신 콘텐츠: AWS가 서비스를 자주 업데이트하기 때문에, 코스 자료는 주기적으로 개정되어 최신 상태를 유지해야 합니다.\n- 학습 방식 호환성: 비디오 자습서, 실습 랩 또는 독자 자료를 선호하든, 교육은 학습 방식에 맞게 제공되어 공부 과정이 더욱 효과적이고 흥미롭게 이루어질 수 있도록 해야 합니다.\n\n\n\n디지털 클라우드 트레이닝이 만든 과정은 당신의 학습 경험과 성공 기회를 극대화하기 위해 설계되었습니다. 여정을 시작하려면 저희의 학습 라이브러리를 확인해보세요.\n\n## 추가 자원 활용하기\n\n공식 교육 과정 이외에도 AWS 화이트페이퍼, FAQ, 그리고 AWS 문서와 함께 학습을 보완하세요. AWS 커뮤니티와 포럼, 스터디 그룹, 소셜 미디어를 통해 참여하면 추가적인 통찰과 조언을 얻을 수 있습니다.\n\n## 3. 연습, 연습, 연습\n\n\n\nAWS 자격증 시험을 준비하는 데 모의 시험은 매우 중요합니다. 시험 형식, 문제 유형 및 시간 제약에 익숙해지게 해주며, 무엇보다도 지식의 공백을 파악하여 공부에 더 집중할 수 있게 도와줍니다.\n\n# 모의 시험 혜택 극대화 방법\n\n- 다양성과 양: 다양한 종류의 모의 시험을 실시하여 가능한 많은 문제 유형과 시나리오에 노출되어 보세요. 시간이 제한된 상황에서 정기적인 연습은 실제 시험의 시간 압박을 관리하는 능력을 향상시킵니다.\n- 분석하고 배우기: 각 모의 시험을 철저히 검토하세요. 답이 왜 옳거나 틀린지 이해하는 것은 지식을 확고히 하고 정보를 유지하는 데 도움이 됩니다.\n- 일관성: 초기에 모의 시험을 학습 루틴에 통합하고, 시험 날짜에 점점 가까워질수록 빈도를 점차 증가시키세요.\n\n# 4. 시험 일정 및 준비하기\n\n\n\n당신이 연습 시험에서 꾸준히 좋은 점수를 받고 자료에 대해 자신감을 가졌다면, 자격증 시험을 예약할 시간입니다. 날짜를 선택하면 노력에 대한 구체적인 목표가 설정되어 준비를 고기에 두는 시간이 됩니다.\n\n# 최종 준비 사항\n\n- 약한 부분 복습: 시험을 앞두고 있는 시간을 활용하여 자신이 자신감 없는 영역에 집중하세요. 특정 서비스나 개념에 대한 심화 학습은 미해결된 의문을 해소할 수 있습니다.\n- 편안함과 다시 모이기: 시험 전 마지막 날들에는 복습과 휴식을 균형있게 취하세요. 맑고 푹 쉬었던 마음이 마지막 분사 끝에 감아넣는 것보다 더 도움이 됩니다.\n\n# 5. 시험 당일과 이후\n\n\n\n자신의 지식과 준비를 시험해볼 때가 왔습니다. 자신감을 가지고 시험에 임하며 철저히 준비했다는 것을 알고 있습니다. 각 문제를 주의 깊게 읽고, 시간을 효율적으로 관리하며, 교육적인 추측은 문제를 무답으로 남기는 것보다 나은 선택임을 기억하세요.\n\n# 시험 후\n\n합격이든 불합격이든, 매 시험 시도는 배움의 경험입니다. 성공하면 성취를 축하하고 AWS 생태계에서의 다음 단계를 고려하세요. 합격하지 못했다면, 개선할 부분을 평가하고 지식의 공백을 채우기 위해 다음 시험을 준비하세요.\n\n# 마지막으로\n\n\n\nAWS 인증 과정에 착수하신 것을 축하드립니다! 클라우드 컴퓨팅 분야에서의 전문적인 발전을 위한 약속입니다. 과정은 도전적일 수 있지만, 경력 기회, 전문적인 성장, 그리고 개인적인 만족에 대한 보상은 상당합니다.\n\n본 상세 가이드를 따라가면 시험 대비뿐만 아니라 클라우드 기술 분야에서 번창하는 경력을 위한 기반을 다질 수 있습니다. AWS 인증을 향한 여정은 지속적인 학습과 적응의 마라톤임을 기억해주세요. 호기심을 유지하고, 동기부여를 유지하면 꼭 성공할 수 있을 것입니다. 함께 화이팅하세요!","ogImage":{"url":"/assets/img/2024-05-15-HowtogetAWSCertifiedin5SimpleSteps_0.png"},"coverImage":"/assets/img/2024-05-15-HowtogetAWSCertifiedin5SimpleSteps_0.png","tag":["Tech"],"readingTime":4},{"title":"비디오 게임에서의 내적곱","description":"","date":"2024-05-15 03:26","slug":"2024-05-15-DotProductinVideoGames","content":"\n\n## 내적이란 무엇인가요?\n\n내적은 두 벡터 사이에서 수행할 수 있는 가장 중요한 연산 중 하나입니다.\n\n![image](/assets/img/2024-05-15-DotProductinVideoGames_0.png)\n\n우리는 각 벡터의 해당 구성 요소를 곱하고 모두 합하여 내적을 계산할 수 있습니다.\n\n\n\n\n![image1](/assets/img/2024-05-15-DotProductinVideoGames_1.png)\n\nor by multiplying the length of the two vectors by the cosine of the angle between them\n\n![image2](/assets/img/2024-05-15-DotProductinVideoGames_2.png)\n\nThe result is a scalar that represents the projection of one vector onto another.\n\n\n\n\n\n![image](/assets/img/2024-05-15-DotProductinVideoGames_3.png)\n\nBut things become more interesting if the vectors are both normalized.\nA normalized vector has a length of one.\n\n![image](/assets/img/2024-05-15-DotProductinVideoGames_4.png)\n\nWe can normalize a vector by dividing each component by its length.\n\n\n\n\n\n![image](/assets/img/2024-05-15-DotProductinVideoGames_5.png)\n\nNow we can replace both lengths in our formula with one, and since multiplying by one doesn’t change anything, we are left with the cosine of the angle between the two vectors.\n\n![image](/assets/img/2024-05-15-DotProductinVideoGames_6.png)\n\nIf the vectors are pointing in the same direction, the angle between them is zero, the cosine of zero is one\n\n\n\n\n![](/assets/img/2024-05-15-DotProductinVideoGames_7.png)\n\n만약 두 벡터가 서로 수직이면, 그들 사이의 각은 90도 입니다. 90도의 코사인 값은 0입니다.\n\n![](/assets/img/2024-05-15-DotProductinVideoGames_8.png)\n\n만약 두 벡터가 서로 반대 방향을 가리키면, 그들 사이의 각은 180도 입니다. 180도의 코사인 값은 -1입니다.\n\n\n\n\n![Dot Product in Video Games](/assets/img/2024-05-15-DotProductinVideoGames_9.png)\n\nAnd any other angle will give us a value between 1 and -1\n\n## Dot Product Use Cases\n\n- checking the relativity between two objects\n\n\n\n\n\n<img src=\"/assets/img/2024-05-15-DotProductinVideoGames_10.png\" />\n\n두 캐릭터, 플레이어와 적이 있다고 가정해 봅시다. 플레이어가 적의 앞에 있는지 뒤에 있는지 알고 싶습니다.\n\n<img src=\"/assets/img/2024-05-15-DotProductinVideoGames_11.png\" />\n\n첫 번째로 할 일은 적에서 플레이어로 향하는 방향을 계산하는 것입니다.\n이를 위해 적의 위치에서 플레이어의 위치를 빼면 됩니다. \n이렇게 하면 적에서 플레이어로 향하는 벡터가 생성되며, 그 길이는 적과 플레이어 사이의 거리와 같습니다.\n\n\n\n\n아래는 Markdown 형식으로 표현했습니다.\n\n\n![이미지1](/assets/img/2024-05-15-DotProductinVideoGames_12.png)\n\n그런 다음, 우리는 방향 벡터를 정규화합니다. 다시 말해, 길이를 1로 만듭니다.\n\n![이미지2](/assets/img/2024-05-15-DotProductinVideoGames_13.png)\n\n그런 다음, 방향 벡터와 적의 전진 벡터 사이의 점곱을 계산합니다.\n\n\n\n\n![이미지](/assets/img/2024-05-15-DotProductinVideoGames_14.png)\n\n여기서는 임계값 간격을 설정할 수 있어요. 이 경우 0.85입니다.\n\n![이미지](/assets/img/2024-05-15-DotProductinVideoGames_15.png)\n\n만약 내적 값이 임계값 이상이라면, 플레이어가 적 앞에 있다는 것을 알 수 있고, 적이 플레이어를 따라다니는 등의 행동을 할 수 있어요.\n\n\n\n\n![이미지](/assets/img/2024-05-15-DotProductinVideoGames_16.png)\n\n우리는 임계값을 -0.85로 설정할 수도 있고, 그러면 닷 프로덕트가 임계값보다 작거나 같은지 확인하여 반대로 처리하고, 플레이어가 뒤쪽에 있는지 확인하여 스니크 어택과 같은 특정 행동을 수행할 수 있습니다.\n\n- 조명 시뮬레이션\n\n우리는 닷 프로덕트를 사용하여 물체를 조명(빛의 영향을 받는)할 수 있습니다.\n\n\n\n\n\n![Image](/assets/img/2024-05-15-DotProductinVideoGames_17.png)\n\nTo achieve this, we require a 3D object and a light source.\n\n![Image](/assets/img/2024-05-15-DotProductinVideoGames_18.png)\n\nThe initial step is to calculate the direction from the 3D object to the light source.\n\n\n\n\n\n![이미지](/assets/img/2024-05-15-DotProductinVideoGames_19.png)\n\n그런 다음 빛 벡터를 정규화합니다.\n\n![이미지](/assets/img/2024-05-15-DotProductinVideoGames_20.png)\n\n그런 다음 빛 벡터와 3D 객체의 법선 벡터 간의 내적을 계산하세요.\n\n\n\n\n\n![영상게임에서의 내적](/assets/img/2024-05-15-DotProductinVideoGames_21.png)\n\n그리고 불을 켜주세요.\n","ogImage":{"url":"/assets/img/2024-05-15-DotProductinVideoGames_0.png"},"coverImage":"/assets/img/2024-05-15-DotProductinVideoGames_0.png","tag":["Tech"],"readingTime":4},{"title":"내 첫 번째 프로젝트, 실패했다","description":"","date":"2024-05-15 03:21","slug":"2024-05-15-MyfirstprojectAfailure","content":"\n\n\n![My First Project](/assets/img/2024-05-15-MyfirstprojectAfailure_0.png)\n\nAs a Junior Software Engineer, this was my first project. Throughout the process, I made several mistakes but also gained a great deal of knowledge. For my future self and for anyone who might be interested in learning from others' mistakes, I am listing those blunders and lessons here on my blog.\n\n## Contents Table\n\n- Overview\n- Why is this project being undertaken?\n- What was done?\n- The trickiest technical problem\n- What I have discovered\n- Conclude\n\n\n\n\n프로젝트 Kura의 목적은 무엇인가요?\nKura는 사람들과 기관 사이의 거리를 좁히려는 시도를 하는 것입니다. 대중 의견 데이터에 접근하여 기관이 투명한 결정을 내리고 서비스를 맞춤화하며 대중을 참여시킬 수 있습니다. 개인들은 자신의 의견을 표현하고, 정보를 얻고, 기관과 투명하게 소통할 수 있습니다.\n\n저희는 Duncan이 API를 담당하고, Ibrahim이 데이터베이스를 담당하며, 저는 프론트엔드를 담당하면서 세 명의 팀으로 작업했습니다. (작업을 이렇게 나누는 방법이 최선은 아닙니다. 나중에 이유를 설명하겠습니다.)\n\n왜 이 특정 아이디어를 선택했나요?\n처음에는 이 아이디어를 잘 느끼지 못했는데, Duncan이 더 자세히 설명하고 해결하려는 문제를 설명하자 그것이 그에게 중요한 것이라고 느꼈고, 이것이 제 첫 번째 프로젝트라서 유용한 것을 만드는 것이 어찌나 흥미로웠는지, 이미 프론트엔드로써 홈페이지가 어떻게 보일지, 랜딩 페이지가 어떻게 보일지, 그리고 가입 페이지까지 아이디어로 마구마구 치이고 있더군요. 그녀와 함께 즉시 시작했고, 전 전혀 후회하지 않았습니다; 정말 멋진 경험이었습니다.\n\n그렇다면 결과(성과)는 무엇인가요?\n\n\n\n\n![My First Project: A Failure](/assets/img/2024-05-15-MyfirstprojectAfailure_1.png)\n\n간단합니다. 프론트 엔드에서 플라스크 API 엔드포인트를 가져오며, API는 데이터베이스와 상호 작용하여 요청에 응답합니다.\n\n프론트 엔드에 대해, 프레임워크 없이 (Js, HTML5, CSS3) 작업하는 것을 고려했고 아마도 JQuery와 Jinja일 수도 있습니다. 이는 이러한 영역의 지식을 실습하고 견고하게 하기에 합리적인 선택이었습니다. \n하지만 TypeScript, React, Nextjs 및 Tailwind를 사용했습니다. 이러한 도구들은 TypeScript가 JavaScript와 같다는 장점을 제공했습니다; 사실, 어떤 JS 코드든 파일 형식을 변경하여 TS로 변환할 수 있습니다. 그러나 TypeScript를 사용하면 엄격한 널 체크, 선택적 형식 지정 등과 같은 기능들을 얻습니다.\n그리고 React를 사용하면 상태와 같은 멋진 기능들을 많이 사용할 수 있었습니다. 이는 변수를 기반으로 UI를 직접 업데이트하는 것을 허용합니다.\nJSX와 같은 HTML이지만 더 엄격한 것과 TypeScript 내부에서 작성하고 JS처럼 처리할 수 있는 능력을 가질 수 있는 것과 같은 장점도 있었습니다.\n모든 페이지, 섹션, 및 페이지의 아이템을 컴포넌트로 다루고 이들을 정적 및 동적으로 함께 연결하는 것은 정말 멋있었습니다.\nNextJs 및 이러한 라우팅 시스템 덕분에 새로 고침할 필요 없이 페이지 간에 이동할 수 있는 것도 좋았습니다. 파일 구조는 정말 좋았습니다.\nTailwind를 사용하여 다양한 화면에서 앱을 쉽게 스타일링할 수 있었습니다. 그리고 단순히 아래와 같이 작성하는 것이 더 쉽기 때문에 앱을 응답형으로 만들기가 좋았습니다.\n\n```javascript\nmd:w-[90vw]\n```\n\n\n\n\n중간 크기 화면의 너비를 지정하기 위해 CSS에 직접 쓰는 대신\n\n```js\n@media screen and (min-width: 768px) and (max-width: 991px) {\n  .wrapper {\n    width: 90vw;\n  }\n}\n```\n\n이것이 바로 Tailwind를 사용하는 이유입니다. 이제 쉽게 반응형 앱을 만들 수 있어요\n\n```js\nw-screen md:w-[90vw] lg:w-[70vw]\n```\n\n\n\n아니면 이를 CSS로 변환한다면 시간이 많이 걸릴 것을 상상할 수 있겠죠!\n\n![image 2](/assets/img/2024-05-15-MyfirstprojectAfailure_2.png)\n\n![image 3](/assets/img/2024-05-15-MyfirstprojectAfailure_3.png)\n\n그래서 이러한 기술 세트로 더 빠르고 쉽게 현대적인 결과물을 얻을 수 있다고 생각했습니다.\n\n\n\n그리고 실제로, 원하던 것을 얻었어요:\n\n- 반응형 디자인.\n- 깔끔하고 간단하며 편리한 디자인\n- 로그인/가입, 투표, 투표 생성, 계정 관리, 기록 보기, 즐겨찾기, 기관 계정 탐색, 계정 삭제 및 데이터 수정 기능을 제공합니다.\n\n이 모든 것을 하기 전에 한 가지 작은 문제가 남아 있네요: 이 모든 것을 어떻게 배울 수 있을까요? 두 주 동안에 이것을 하기 좋은 아이디어일까요? 시간은 어디에 남아 있을까요?\n\n## 가장 어려운 기술적 문제에 대해 논의를 시작해 보겠습니다.\n\n\n\n가장 어려운 그리고 가장 재미있는 기술적 도전은 게시 페이지였어요.\n머릿속에 최종 결과물을 시각화하고 그에 따른 디자인을 만들었죠.\n\n![이미지](/assets/img/2024-05-15-MyfirstprojectAfailure_4.png)\n\n하지만 구현은 내가 상정했던 것만큼 쉬운 일이 아니었어요.\n먼저, 그 플러스 기호를 클릭하여 새로운 필드를 추가하세요. 답변이나 새 질문이 될 수 있어요. 그리고 저기 저 작은 마이너스 기호를 클릭하여 제거할 수도 있어요.\n뭔가 예상치 못한 일이 발생하면 다시 돌아와서 계속할 수 있어요, 왜냐면 입력한 데이터가 로컬에 저장되길 원하기 때문이에요.\n데이터를 백엔드로 보내고 시각적 효과를 표시할 수 있게 하기 위해, 게시 버튼을 누를 때 입력한 데이터가 특정한 방식으로 구조화되어야 해요.\n\n데이터를 조직하는 데 어려움을 겪었어요. 알겠어요. 적어도 하나의 질문은 있어야 해요—하나라도 더 좋지만요—각 투표에서.\n각 질문은 적어도 두 개의 답변이 있어야 해요.\n그래서, 이렇게 보였어요:\n\n\n\n\n```javascript\nconst poll = {title, description, \n              questions: {Q1: {title, id, {A1: {id, text}, A2: {id, text}},\n                          ...}\n              }\n```\n\n모든 필드에 고유 식별자를 만들어 사용자 인터페이스에서 그것을 다른 것과 구별되게 설정했습니다. 처음에는 조금 혼란스러웠지만 효과적이었습니다.\n이 단계를 거친 후 모든 것이 간단해졌습니다. 새 설문을 시작하기 전에 로컬 저장소를 확인하고 있을지 모를 데이터를 검색합니다.\n이를 사용자 인터페이스에 생성한 후, 각 요소를 동적 함수에 연결합니다.\n물론, 설문은 상태로 추가되었기 때문에 모든 수정 사항이 사용자 인터페이스에 반영됩니다.\n마지막으로, 결과는 이렇습니다:\n\n![결과](https://miro.medium.com/v2/resize:fit:1400/1*HzGlErv-hjWXWkf95sOWFA.gif)\n\n나쁘지 않네요\n\n\n\n\n## 마지막으로, 실수와 배운 점\n\n**작업을 분할하여 팀을 나누지 마세요**\n이전에 말했듯이, 이 방식으로 팀원 각자에게 작업을 나눠주는 것은 최선의 방법이 아닙니다. 왜냐하면?\n각각이 별도의 프로젝트에서 작업하는 것처럼 작업을 나누는 것은 팀을 나누는 것과 같습니다.\n이렇게 작업을 나눠 놓으면 각자가 완전히 마무리될 때까지 서로 기다려야 하는 상황이 생깁니다.\n혜택은 충분하지 않을 것이며, 혼자서 작업하는 것보다 팀으로 작업하는 것보다는 더 연결되어 있지 않을 수 있습니다.\n그렇다면 다른 선택지가 있을까요?\n우리는 프로젝트를 기능별로 나누어 시작하고, 하나씩 기능을 구축하기 시작할 수 있습니다. 백엔드는 먼저 기본부터 빌드하고, 그런 다음 우리는 모여 회원 가입 페이지를 시작하고, 백엔드는 데이터베이스에서 처리하는 등, API는 자체적으로 처리하는 등, 프론트엔드는 이를 연결하여 테스트를 진행합니다.\n이 방식으로 모두가 참여할 수 있고, 작업은 팀이 아닌 프로젝트로 분할되며, 각 기능은 전체 그룹의 의견을 반영하여 철저히 테스트될 것입니다.\n\n**시간이 부족하다면 알고 있는 것으로 작업하라**\n네 날 동안 이를 처리하고 이 모든 것을 배웠기 때문에 그것을 정말 잘 배웠다고 말할 수 없었습니다. 여기저기서 정보를 얻은 것만큼이었습니다.\n이는 혼란과 스트레스 수준을 높였습니다.\n결과는 만족스러웠지만, 특정 작업에 대해 제 전체 팀이 저에게 의존하고 있었기 때문에 위험한 결정이었습니다.\n이를 이미 알고 있었기 때문에 더 안전한 길을 선택했어야 했습니다. 많은 것을 배웠으니 후회는 없지만 다른 사람들에게는 추천하지 않을 것입니다.\n\n전반적으로, 이 프로젝트는 제 자신에 대해 많은 것을 가르쳐 주었습니다. 프론트엔드 개발을 사랑하지만 백엔드 작업도 그리워합니다.\n스트레스를 주는 상황이 제게는 잘맞습니다.\nJavaScript 언어는 정말 좋습니다; 그저 완벽합니다.\n결국, 프론트엔드 작업이 너무 심심한 것은 아니었습니다; 많은 준비와 작업이 필요합니다.\n이제 자신 있게 코드를 작성할 수 있습니다!\n\n\n\n## 마무리\n\n안녕하세요, 저는 모하메드입니다. 풀스택 엔지니어입니다. 이집트 출신이고 코딩을 좋아합니다. \n\nKura GitHub와 Kura Live를 살펴보세요. \n\nLinkedIn 프로필도 확인해보세요.\n\n![이미지](https://miro.medium.com/v2/resize:fit:960/0*e2M2T539P-PuIGmu.gif)","ogImage":{"url":"/assets/img/2024-05-15-MyfirstprojectAfailure_0.png"},"coverImage":"/assets/img/2024-05-15-MyfirstprojectAfailure_0.png","tag":["Tech"],"readingTime":6},{"title":"Revolut에서 iOS의 기초","description":"","date":"2024-05-15 03:17","slug":"2024-05-15-ThefundamentalsofiOSatRevolut","content":"\n\nRevolut에서의 iOS 개발 뒷면을 살펴보겠습니다. 우리는 고객이 금융 앱을 통해 금융 생활을 관리하는 것에 의존하는 고객들을 위해 우수한 금융 서비스와 원활한 고객 경험을 제공하기 위해 노력하고 있습니다.\n\n우리는 빠르게 고품질 소프트웨어를 제공할 수 있다고 믿습니다. 이를 달성하기 위해 우리는 중요한 원칙들을 따르고 주로 XP (eXtreme Programming)에서 영감을 받은 현대적인 아자일 실천 방법을 적용하고 있습니다.\n\n# 빠르게 제공하기\n\n현재 iOS 플랫폼에서 우리는 어플리케이션과 SDK를 모두 보유하고 있습니다.\n다음은 실시간으로 제공되는 목록입니다:\n\n\n\n\n## Revolut, Revolut `18, Revolut Business, Revolut POS 및 Revolut Pay SDK.\n\n모든 iOS 애플리케이션은 매주 App Store에서 업데이트됩니다. 우리는 지속적 통합 및 지속적 전달의 원칙에 따라 새로운 기능을 빠르게 고객에게 제공합니다. 기능 또는 그 일부가 준비되는 즉시.\n\n우리는 기능 기반 릴리스를 위한 독자적인 프레임워크를 구축했습니다. 우리의 프로세스에 따르면, 상품 소유자는 응용 프로그램의 선택된 버전부터 활성화할 기능을 지정합니다. 그런 다음 응용 프로그램 버전과 해당 기능이 점진적으로 롤아웃되며, 고객 베이스의 소수부터 시작합니다. 이 두 가지 접근 방식인 기능 플래깅과 점진적인 버전 및 기능 롤아웃은 최소한의 위험으로 고객에게 가치를 전달할 수 있도록 합니다. 문제가 발생하면 플래그가 꺼지거나 문제가 있는 변경 사항을 제거하기 위해 오래된 버전을 롤백으로 다시 제출합니다. 또한, 피쳐 플래그는 팀원들이 서로 다른 사용자 경험 간에 쉽게 전환하거나 비교하거나 테스트를 위해 켜거나 끌 수 있도록 합니다.\n\n또한 사전 정의된 지표를 사용하여 새로운 기능을 실험하고 그 영향을 통계적으로 유의한 방식으로 측정할 수 있는 내부 실험 플랫폼을 개발했습니다. 이 플랫폼은 실험이 적절하게 설정되고 결과가 강인한 통계적 프레임워크를 사용하여 생성되는 것을 보장합니다.\n\n\n\n모든 아이디어는 테스트되며, 데이터 기반 논리를 활용하여 결정이 내려지며, 최상의 사용자 경험이 핵심 개발 노력을 받도록 보장합니다. 이로 인해 주요 사용자 중심 기능이 신속하고 집중적으로 개발되는 결과를 얻을 수 있습니다.\n\n# 아키텍처\n\niOS 기본 사항을 탐구할 때, 우리의 iOS 애플리케이션이 더 큰 생태계의 일부에 불과하다는 점을 인식하는 것이 중요합니다. 우리의 목표는 첨단 기술을 육성하여 사용자 경험을 향상시키는 것입니다 — 쉽고 효과적으로 유지합니다. 우리 다양한 앱, 기능 및 팀 간의 일치를 보장하기 위해 시스템 디자인 리뷰(SDR)라는 구조화된 프로세스에 의존합니다.\n\nSDR 프로세스는 솔루션의 아키텍처를 평가하고 리파인하는 데 중요한 메커니즘으로 작용합니다. 아키텍처는 기술적 요소를 원활하게 결합하여 통일되고 효과적인 시스템을 만들어내는 접착제 역할을 합니다. SDR 맥락에서 모바일 아키텍처는 특히 중요하며, iOS 솔루션이 견고하고 확장 가능하며 산업 표준에 부합하는지 보장합니다.\n\n\n\n솔루션 수준의 아키텍처를 이해하는 것은 SDR 프로세스에 효과적으로 참여할 뿐만 아니라 Revolut 내에서 개인 및 전문적 성장의 기회를 제공합니다.\n\niOS 플랫폼 관점에서 모든 제품은 Clean Architecture와 MVVM-C로 구현됩니다.\n\n우리의 앱들은 단일체가 아닙니다. 핵심 모듈, UI 구성요소 및 거래, 결제, 암호화폐, 대출 및 카드와 같은 기능 모듈과 같은 공유 모듈이 포함됩니다.\n\n현재 저희는 다음과 같은 것을 가지고 있습니다:\n\n\n\n- 160개의 공유 모듈\n- Revolut에는 170개의 모듈이 있습니다.\n- Revolut Business에는 80개의 모듈이 있습니다.\n- Revolut `18에는 45개의 모듈이 있습니다.\n\n모든 앱과 공유 모듈은 단일 모노 레포지토리에 저장되어 있으며 각 모듈은 독립적으로 빌드 및 실행될 수 있습니다.\n\n모듈화 아키텍처의 간략한 하이라이트:\n\n- 빠른 빌드 시간 - 각 모듈은 전체 앱을 컴파일하지 않고도 빠르게 개발할 수 있도록 예제 또는 데모 프로젝트를 보유하고 있습니다.\n- 빠른 개발 - 더 빠른 컴파일 및 예제 프로젝트에서 쉽게 화면에 액세스할 수 있어 더 빠른 개발이 가능합니다.\n- 새로운 기능을 시도하기 위한 격리된 환경\n- 몇 초만에 실행되는 테스트\n\n\n\n# 기술 스택\n\n우리는 Swift를 사용하여 개발하고 iOS SDK를 사용합니다. 우리의 목표는 외부 코드에 대한 의존성을 줄여 제3자 프레임워크에 의존하는 것을 최소화하는 것입니다. 예를 들어, 외부 프레임워크에 강하게 의존하는 대신, 핵심 라이브러리에서 가벼운 반응형 접근 방식을 채택했습니다. 이 전략은 Combine의 기능을 반영하며 미래에 SwiftUI로의 원활한 전환을 쉽게 할 것입니다.\n\n우리 앱은 Xcode의 빌드 기능 한계를 크게 초과했으며, 고품질 소프트웨어를 빠르게 제공하는 우리의 주요 원칙과 일치하도록 하기 위해 다양한 섬세하게 조정된 오픈 소스 및 내부 도구를 사용합니다.\n\n우리의 응용 프로그램과 프레임워크를 빠르게 빌드하고 테스트할 수 있도록, 구글의 Bazel로 전환하였습니다. 이는 신뢰할 수 있는 클라우드 및 로컬 모듈 빌드 캐시를 제공합니다.\n\n\n\n우리 내부 도구는 전체 코드 베이스와 쉽게 작업할 수 있는 능력을 제공하는 명령줄 인터페이스로 완전히 Swift로 구축되어 있습니다. 회사의 모든 iOS 엔지니어가 이해하고 수정할 수 있도록 되어 있습니다.\n\n로컬 환경과 유사한 CI 구성이므로 쉽게 빌드, 테스트 및 배포할 수 있습니다. 이는 어디서든 빌드 및 테스트할 수 있음을 의미하며, 추가로 릴리스, 개발, 특정 기능과 같은 모든 브랜치에서 작동하고 TestFlight 및 AppCenter에 배포할 수 있습니다.\n\n개발 규모를 좀 더 잘 이해하기 위해 숫자를 살펴봅시다. 월별 iOS 팀은 약 2,200개의 풀 리퀘스트를 생성하며 이로 인해 거의 4,000~5,000개의 CI 빌드가 이루어집니다.\n\n이처럼 밀도 높은 개발을 하면서 우리는 설정과 모듈 구조를 끊임없이 최적화합니다. 최근에 이러한 최적화로 PR 유효성 검사 시간을 40분에서 10분으로 줄였으며, 결과적으로 매월 거의 2,000~2,500시간의 CI 시간을 줄이게 되었습니다.\n\n\n\n아래는 우리가 사용하는 다른 도구 및 기술들에 대한 정보도 중요합니다:\n\n- Git\n- Xcode\n- Figma\n- 데이터 저장을 위한 CoreData (저희의 모든 응용 프로그램은 오프라인 보기를 제공하기 때문에 인터넷 연결이 불가능할 때 CoreData 캐시 데이터베이스에서 데이터를 화면에 표시할 수 있습니다. 예를 들어 고객이 카드 세부 정보를 조회해야 할 때)\n- SwiftLint, TeamCity 및 기타\n\n# 교차 기능 팀\n\n우리는 서로 다른 팀과 위치에 흩어진 120명 이상의 고통령 iOS 개발자를 보유하고 있습니다. 각 팀은 유지 및 보수를 책임지는 코드 소유권을 갖고 있습니다. 각 팀은 일반적으로 iOS, Android, 웹, 백엔드 개발자, 제품 소유자, 디자이너 및 데이터 분석가로 구성되어 있습니다. 따라서 각 팀은 아이디어를 제공하고 제품이나 기능으로 변환할 수 있는 작은 스타트업처럼 구성되어 있습니다.\n\n\n\n팀원들은 개발한 기능에 대해 완전한 통제권을 갖습니다. 엔지니어로서 교차 기능 팀의 일원이 되는 것은 제품에 영향을 미치고 의사 결정에 참여하며 전문 지식 이외의 기술 학습에 참여할 기회를 갖는 것을 의미합니다.\n\n팀의 생산성을 높이기 위해 분산된 작업 방식에 대해 방해 없이 개발하는 데 많은 도구를 사용합니다. 각 팀이 각자의 설정과 프로세스를 가지고 있지만, 일반적으로 우리는 Agile 방법론을 따르고 있으며 Slack에서 소통하고 Confluence에 개발 자산을 저장하며 Jira에서 진행 상황을 추적합니다.\n\n# 품질\n\n빠른 고품질 소프트웨어 전달을 보장하기 위해 우리는 품질 보증 프로세스의 자동화를 극대화하는 것을 우선시합니다. 우리의 테스트 피라미드는 견고한 기반을 형성하며, iOS 제품에 사용되는 모든 테스트는 Swift로 작성되고 XCTest 및 XCUITest와 같은 네이티브 SDK를 활용합니다. 또한 구문 달콤함과 문서 주도식 테스트 개발을 위해 Quick + Nimble과 같은 프레임워크를 결합하여 문맥과 행동 주도식 테스트를 특징으로 합니다. 더불어 재사용 가능한 디자인 구성 요소를 위해 SnapshotTestCases를 구현합니다.\n\n\n\n우리의 자동화된 테스트 피라미드 부분에 대한 몇 가지 숫자가 있습니다:\n\n- 가장 낮은 수준에서는 약 12,000개의 단위 테스트 스위트가 있으며, 개별 구성 요소를 확인하는 데 150,000개 이상의 별도의 테스트 케이스가 있습니다.\n- 중간 및 상위 수준에서는 UI 테스트 스위트가 있으며 통합 및 응용 프로그램의 UI/UX 부분을 커버합니다.\n- Revolut: 1,800 UI 테스트 케이스\n- Revolut Business: 430 UI 테스트 케이스\n- Revolut `18: 760 UI 테스트 케이스\n\n또한 제품의 품질을 보증하는 것은 모든 직원들간의 공동 책임임을 중요하게 생각합니다. 특정 QA 엔지니어가 없더라도, 우리의 개발자, 제품 소유자, 디자이너 및 다른 모든 직원들은 고품질을 유지하기 위해 철저한 조치를 취합니다. 그들은 수동 교차 확인 및 매일 앱 사용 테스트를 포함한 다양한 테스트 방법을 업무 프로세스에 통합합니다. 이 자동화 및 협업 접근 방식을 채택함으로써 우리는 신뢰성 있고 사용자 친화적인 제품을 고객들에게 제공하는 의무를 지키고 있습니다.\n\n# 보안\n\n\n\n모든 팀원들이 Revolut의 성공이 얼마나 심각하게 우리가 보안 위험에 대처하는지에 달려있음을 이해하고 있습니다. 우리는 사용자 데이터 추적 및 분석에 대한 내부 솔루션을 우선적으로 다루어 개인 데이터가 제3자에게 노출되지 않도록 보장합니다. 우리는 데이터를 활용하여 고객 경험을 향상시키는 데 기여하며, 사용자 흐름을 최적화하거나 UI 요소의 배치를 최적화하는 등의 작업을 합니다.\n\n특히 iOS에 대해서는 모든 민감한 데이터와 자격 증명을 KeyChain에 안전하게 저장하고 최대한 모든 것을 암호화합니다. 게다가, API 엔드포인트 및 로컬 저장소를 세심하게 설계하여 데이터 전송량과 저장된 데이터를 최소화합니다.\n\n# 디자인 일관성\n\n모든 UI 구성 요소는 응용 프로그램 내에서 높은 재사용성을 위해 설계되고 있는데, 이러한 구성 요소는 애플리케이션의 시각적인 일관성을 유지하기 위해 별도의 모듈에 포함되어 있습니다. 이러한 모듈은 개발되는 모든 플랫폼에서 네이티브로 구현되어, 동일한 UI 및 UX 구현을 보장합니다. 이 접근 방식을 디자인 시스템이라고 합니다. 우리는 이 시스템을 핵심 원리로서 원자적 디자인을 고려하여 개발하였습니다.\n\n\n\n디자인 시스템은 코드 양과 개발 시간을 줄여주는 자원 절약 도구로 작용합니다. 개발자들은 이제 더 이상 코드를 중복으로 작성하거나 컴포넌트를 처음부터 다시 만드는 시간을 보낼 필요가 없습니다. 대신 레볼루트 디자인 시스템 앱을 활용할 수 있습니다. 이 앱은 모든 기존 UI 컴포넌트를 보여주며, 개발자들이 쉽게 필요한 컴포넌트를 선택하고 재사용할 수 있도록 도와줍니다.\n\n# 레볼루트에 합류하세요\n\niOS용 세계적 수준의 금융 앱을 만들고 싶나요?\n레볼루트에서의 경력 기회를 살펴보고, 가장 재능 있는 개발자들로 구성된 팀에 합류해보세요.\n\n# 링크\n\n\n\n우리 애플리케이션:\nRevolut\nRevolut `18\nRevolut Business\nRevolut POS\nRevolut Pay SDK\n\n접근 방식:\n- [실용적인 테스트 피라미드](https://martinfowler.com/articles/practical-test-pyramid.html)\n- [Atomic 웹 디자인](https://bradfrost.com/blog/post/atomic-web-design/)\n\n도구:\n- [Bazel](https://bazel.build/)\n- [SwiftLint](https://github.com/realm/SwiftLint)\n- [Quick](https://github.com/Quick/Quick)\n- [iOS 스냅샷 테스트 케이스](https://github.com/uber/ios-snapshot-test-case)\n- [TeamCity](https://www.jetbrains.com/teamcity/)\n- [Confluence](https://www.atlassian.com/software/confluence)\n- [Slack](https://slack.com/)\n- [Jira](https://www.atlassian.com/software/jira)\n\nRevolut에 대해 더 알아보기:\n- [Revolut 엔지니어링 소개](https://medium.com/revolut/under-the-hood-engineering-at-revolut-2dc183c04228)\n- [Revolut 채용 정보](https://www.revolut.com/careers)\n- [Revolut YouTube 채널](https://www.youtube.com/watch?v=SPDnhMg7kMk&t=1898s)","ogImage":{"url":"/assets/img/2024-05-15-ThefundamentalsofiOSatRevolut_0.png"},"coverImage":"/assets/img/2024-05-15-ThefundamentalsofiOSatRevolut_0.png","tag":["Tech"],"readingTime":7},{"title":"핵심 구성 요소 경쟁사 분석에서 배운 것들","description":"","date":"2024-05-15 03:15","slug":"2024-05-15-BuildingBlocksLearningsfromtheCompetitorAnalysis","content":"\n\n## Asgardeo Android SDK 개발 여정 — 에피소드 2\n\n![Image](/assets/img/2024-05-15-BuildingBlocksLearningsfromtheCompetitorAnalysis_0.png)\n\n이전 에피소드에서 Asgardeo Android SDK 개발 여정 중 모바일 SDK를 통한 응용프로그램 네이티브 인증의 경쟁사 분석에 대해 논의했습니다.\n\n아직 읽지 않으셨다면 아래 링크에서 확인할 수 있습니다.\n\n\n\nhttps://achinthaisuru444.medium.com/a-deep-dive-into-mobile-sdks-for-app-native-authentication-a-competitor-analysis-d315f0ba89b9\n\n안녕하세요! 이번 에피소드에서는 Android SDK 개발 과정 중에 우리가 한 아키텍처 결정 사항에 대해 자세히 살펴보도록 하겠습니다.\n\n## 네이티브 우선 접근\n\n우리의 경쟁사 분석 결과, 현재 트렌드는 Flutter나 React Native와 같은 크로스 플랫폼 개발 도구를 향해 가고 있지만, 산업은 여전히 안정성과 지원을 갖춘 네이티브 Android 및 iOS를 활용한 네이티브 개발을 주로 중점적으로 다루고 있음을 확인했습니다. 따라서, 고객에게 최상의 서비스를 제공하기 위한 조직으로서, 우리는 네이티브 프로그래밍 언어에 우선 순위를 두기로 결정했습니다.\n\n\n\n안녕하세요! 안드로이드가 전 세계적으로 우세한 플랫폼이기 때문에 먼저 안드로이드 SDK를 개발하기로 결정했습니다. 이후 iOS SDK 개발에 이어 교차 플랫폼 개발 기술을 위한 SDK를 개발할 예정입니다.\n\n## 코어 vs UI Kit\n\n대부분의 경쟁사들은 UI 키트가 아닌 코어 SDK에 초점을 맞춘 이유는 앱 네이티브 인증을 선택하는 고객들이 종종 제공된 UI가 아닌 자체 UI를 개발하는 것을 선호하기 때문입니다. 이러한 통찰을 바탕으로, 저희는 먼저 코어 SDK 개발을 우선순위로 두고, 이후 UI 키트 개발을 계획하게 되었습니다.\n\n## 프로젝트 전체 디자인\n\n\n\n\n![Architecture](/assets/img/2024-05-15-BuildingBlocksLearningsfromtheCompetitorAnalysis_1.png)\n\n우리는 위 다이어그램에 표시된대로 총 모바일 SDK 아키텍처를 설계했습니다. 이 아키텍처를 통해 안드로이드와 iOS에서 앱 네이티브 인증 로직을 구현하고 이를 크로스 플랫폼 기술에서 재사용함으로써 개발 프로세스를 간소화할 수 있습니다.\n\n## 저장소 아키텍처\n\n대부분의 경쟁사는 SDK를 독립된 저장소에서 개발하는 반면, 우리는 모든 모바일 SDK에 대해 단일 저장소를 사용하기로 결정했습니다. 이 결정은 네이티브 및 크로스 플랫폼 SDK 간 변경 사항의 전파를 용이하게 하기 위해 내려졌습니다. 우리가 예상하는 한 가지 도전 과제는 다양한 SDK를 다른 플랫폼 (예: 안드로이드는 Maven Central 및 Flutter는 pub.dev로)에 발행해야 한다는 점입니다. 우리는 이 도전 과제를 각 기술에 대해 별도의 GitHub actions를 실행하여 해결할 계획입니다.\n\n\n\n\n## 결론\n\n저희의 건축적인 결정은 산업 트렌드와 사용자 선호도에 대한 깊은 이해를 반영하고 있습니다. 네이티브 우선 접근과 핵심 기능 중심으로 우선순위를 정하면 맞춤화를 위한 견고한 기반을 마련할 수 있습니다. 단일 저장소(monorepo)의 도입은 플랫폼 간 통합을 간소화합니다. 다음 회에서는 이러한 통찰력을 적용 가능한 단계로 번역하여 보다 향상된 인증 경험을 제공할 예정입니다. 함께 기대해 주세요.","ogImage":{"url":"/assets/img/2024-05-15-BuildingBlocksLearningsfromtheCompetitorAnalysis_0.png"},"coverImage":"/assets/img/2024-05-15-BuildingBlocksLearningsfromtheCompetitorAnalysis_0.png","tag":["Tech"],"readingTime":2}],"page":"16","totalPageCount":71,"totalPageGroupCount":4,"lastPageGroup":20,"currentPageGroup":0},"__N_SSG":true}